doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database,query_name,query_value
10.1109/MELECON53508.2022.9842871,A Citizen Science Approach for the Collection of Data to Train Deep Learning Models,IEEE,Conferences,"Machine learning techniques that give good predictions require a considerable amount of data, which sometimes can be a challenge to collect. In this study, citizen science is being introduced as an auxiliary technique to provide more data for the training of a deep learning network for the classification of Maltese Flora; a field which to this date lacks sufficient training data. In the first part of this study, we investigate the training of a deep learning model that makes use of a limited training dataset utilising techniques such as data augmentation, data scraping and transfer learning. This improved experimented off-the-shelf model generated a low accuracy highlighting the relevance of the initial hypothesis that citizen science is needed for the improvement of deep-learning models. In the second phase, citizen science was used as a data crowdsourcing technique through a mobile communication system. A study was conducted to determine the opinion of the public with only a small percentage showing a lack of interest in participating. Therefore, a dynamic educational application was implemented for the public exploiting Artificial Intelligence advancements to identify Maltese Flora in real-time whilst gathering images used to enhance the dataset. The deep learning model was re-trained on this dataset showing a significant increase in performance. Visualizations of the current Maltese flora distribution were also generated utilizing this data. This study demonstrated that the use of citizen science is essential for the improvement of deep learning models so that they can be employed in more widespread applications.",https://ieeexplore.ieee.org/document/9842871/,2022 IEEE 21st Mediterranean Electrotechnical Conference (MELECON),14-16 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IC3IOT53935.2022.9767897,"A Deep study of Data science related problems, application and machine learning algorithms utilized in Data science",IEEE,Conferences,"Data Science study utilized for gathering information as data, taking out data from other systems, accumulating information, signifying and safeguarding data collected are used by organizations for marketing purposes and in high-tech implementations. Name of data science denotes a combination of databases and software engineering as well as a number of types of qualitative, quantitative entities and non-mathematical entities are furthermore necessary. Data science and its importance, components in data science included, life cycle of data science, Application of data science, various algorithms in machine learning are used with data science and implementation of machine learning algorithm in real life cases are also described. Finally, wound up with how to decode an obstacle in data Science using machine learning algorithms.",https://ieeexplore.ieee.org/document/9767897/,"2022 International Conference on Communication, Computing and Internet of Things (IC3IoT)",10-11 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBAIE52039.2021.9389899,An Open-Source Programming Language-Based Interactive Device: Popular Science of the Five Cereals for Children,IEEE,Conferences,"In this paper, Arduino is used in combination with switch, lighting and sound facilities to realize human-computer interaction. Arduino is an open-source electronics platform that integrates hardware and software. Given its versatility, expressiveness and operability, designers and artists are free to turn their ideas into reality on this platform, using programming languages to create high-quality interactive installations. In response to children's difficulty telling the difference between the five cereals, this paper seeks to educate children on crops in the form of human-computer interaction through the design and manufacture of a popular science-themed interactive device. Through the external hardware configuration (pressure induction, lamp and sound), children are guided to knowing and grasping the growth stages of common plants. In this way, children's perceptions of nature and crops can be constructed through a combination of technology and art.",https://ieeexplore.ieee.org/document/9389899/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISAIAM53259.2021.00012,Application of children Artificial Intelligence science popularization books based on Augmented Reality technology,IEEE,Conferences,"Children’s books are enlightenment books for children’s education, and the educational significance of popular science books is even more important. With the development of global intelligent technology, parents pay more attention to children’s intelligent education, and books combined with science and technology become more popular. As one of the important tools in the process of children’s growth, books play an important role in children’s early education. However, most of the popular science books are still natural universe, animal world, military education and other subjects. Today, with the development of intelligent technology, it has become an inevitable thing to carry out artificial intelligence science popularization for children. Therefore, this article uses multimedia technology, uses Kudan SDK to develop AR applications in Unity, explores the application of AR technology in popular science books, and uses artificial intelligence as the theme for creation. It mainly includes the cognitive analysis of artificial intelligence, ar software system design and the design exploration of AR and books for 7-11 year olds, so that children can understand and learn the relevant knowledge of AI in the technical environment.",https://ieeexplore.ieee.org/document/9516578/,2021 International Symposium on Artificial Intelligence and its Application on Media (ISAIAM),21-23 May 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IEEECONF53024.2021.9733750,Augmented Reality Applications in the Training of Computer Science Professionals,IEEE,Conferences,"Various technological resources support different levels of the educational process. This proposal describes an augmented reality application for a data architecture course, a fundamental subject for bachelor degree students studying computer information management at public universities and computer engineering in higher education institutions for technology. We followed the methodology of educational software. The application was developed in Unity, considering five concordant themes in the curricula of both universities (linear, non-linear, recursion, sorting, and search). The objective was to analyze the incorporation of the educational resource. For this, three instruments were used: (1) to examine the students&#x0027; knowledge level about the subject before and after the resource intervention, (2) a rubric to understand their perception of the quality of mobile educational applications, and (3) the technology acceptance model, which allowed identifying attitudes towards the information technology system based on two previously established variables: perceived usefulness and perceived ease of use. The results are encouraging, verifying that technological tools contribute to the training of computer scientists.",https://ieeexplore.ieee.org/document/9733750/,2021 Machine Learning-Driven Digital Technologies for Educational Innovation Workshop,15-17 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2016.7840859,Building a research data science platform from industrial machines,IEEE,Conferences,"Data Science research has a long history in academia which spans from large-scale data management, to data mining and data analysis using technologies from database management systems (DBMS's). While traditional HPC offers tools on leveraging existing technologies with data processing needs, the large volume of data and the speed of data generation pose significant challenges. Using the Hadoop platform and tools built on top of it drew immense interest from academia after it gained success in industry. Georgia Institute of Technology received a donation of 200 compute nodes from Yahoo. Turning these industrial machines into a research Data Science Platform (DSP) poses unique challenges, such as: nontrivial hardware design decisions, configuration tool choices, node integration into existing HPC infrastructure, partitioning resource to meet different application needs, software stack choices, etc. We have 40 nodes up and running, 24 running as a Hadoop and Spark cluster, 12 running as a HBase and OpenTSDB cluster, the others running as service nodes. We successfully tested it against Spark Machine Learning algorithms using a 88GB image dataset, Spark DataFrame and GraphFrame with a Wikipedia dataset, and Hadoop MapReduce wordcount on a 300GB dataset. The OpenTSDB cluster is for real-time time series data ingestion and storage for sensor data. We are working on bringing up more nodes. We share our first-hand experience gained in our journey, which we believe will benefit and inspire other academic institutions.",https://ieeexplore.ieee.org/document/7840859/,2016 IEEE International Conference on Big Data (Big Data),5-8 Dec. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICoDT252288.2021.9441481,Classy AA-NECTAR: Personalized Ubiquitous E-Learning Recommender System with Ontology and Data Science Techniques,IEEE,Conferences,"Learners have different learning styles each tailored to their own personality. Incompatibility of learning and teaching style is inconvenient. This paper integrates learner behavior modeling, academic web crawling and content retrieval using state of the art technology. This research work aims to propose a personalized ubiquitous learning model to identify learner learning styles and deploy type of content that is corresponding to the learner's learning style. Felder-Solomon model is one of the models being used for the learner profiling. This gives ease not only to the learners but the pedagogical instructors as well for not making different type of content. Real time monitoring makes the self-adaptive system learn through the learner's gestures and self-adjusts autonomously. Learners' aptitude increases, saving time and inconvenience. This will give an easy access to certifying organizations to get more capable skill oriented people.",https://ieeexplore.ieee.org/document/9441481/,2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2),20-21 May 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC48688.2020.00026,DSLE: A Smart Platform for Designing Data Science Competitions,IEEE,Conferences,"During the last years an increasing number of university-level and post-graduation courses on Data Science have been offered. Practices and assessments need specific learning environments where learners could play with data samples and run machine learning and data mining algorithms. To foster learner engagement many closed-and open-source platforms support the design of data science competitions. However, they show limitations on the ability to handle private data, customize the analytics and evaluation processes, and visualize learners' activities and outcomes. This paper presents Data Science Lab Environment (DSLE, in short), a new open-source platform to design and monitor data science competitions. DSLE offers a easily configurable interface to share training and test data, design group works or individual sessions, evaluate the competition runs according to customizable metrics, manage public and private leaderboards, monitor participants' activities and their progress over time. The paper describes also a real experience of usage of DSLE in the context of a 1st-year M.Sc. course, which has involved around 160 students.",https://ieeexplore.ieee.org/document/9202557/,"2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)",13-17 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DSAA.2015.7344825,Data science foundry for MOOCs,IEEE,Conferences,"In this paper, we present the concept of data science foundry for data from Massive Open Online Courses. In the foundry we present a series of software modules that transform the data into different representations. Ultimately, each online learner is represented using a set of variables that capture his/her online behavior. These variables are captured longitudinally over an interval. Using this representation we then build a predictive analytics stack that is able to predict online learners behavior as the course progresses in real time. To demonstrate the efficacy of the foundry, we attempt to solve an important prediction problem for Massive Open Online Courses (MOOCs): who is likely to stopout? Across a multitude of courses, with our complex per-student behavioral variables, we achieve a predictive accuracy of 0.7 AUCROC and higher for a one-week-ahead prediction problem. For a two-to-three-weeks-ahead prediction problem, we are able to achieve 0.6 AUCROC. We validate, via transfer learning, that these predictive models can be used in real time. We also demonstrate that we can protect the models using privacy-preserving mechanisms without losing any predictive accuracy.",https://ieeexplore.ieee.org/document/7344825/,2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA),19-21 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GCCE.2017.8229475,Deductively verifying embedded software in the era of artificial intelligence = machine learning + software science,IEEE,Conferences,"Today Google collects big data, and develops new business using both cloud computing such as search engine and artificial intelligence such as machine learning. The study of artificial intelligence mainly on deep learning is prosperous and is expected to make smart life now and in the future. The mainstream of the present artificial intelligence is machine learning, and the foundation is inductive inference. On the other hand, artificial intelligence from old days is deductive inference, and the deductive inference is the foundation of software science. In this paper, from the viewpoint of “artificial intelligence = machine learning + software science”, we grasp computer technologies. We pay attention to software science, especially deductive inference of embedded systems, and explain deductive verifications for guaranteeing the reliability of embedded systems.",https://ieeexplore.ieee.org/document/8229475/,2017 IEEE 6th Global Conference on Consumer Electronics (GCCE),24-27 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAICA52286.2021.9498218,Eco-climate Intelligent Monitoring System of an Agricultural Science-And-Technology Park Based on Internet of Things,IEEE,Conferences,"An agricultural science and technology park (ASTP) is a new mode of agricultural development supported by science and technology. At present, research focuses on diseases and insect pests, intelligent irrigation, greenhouse environment-specific crop monitoring, and other individual issues, in which the utilization efficiency of agricultural information technology is low. The purpose of this study is to fully grasp the change in the ecological climate of ASTPs and improve their intelligence level. This study, based on the Internet of Things of agricultural information transmission and control, designs a greenhouse climatic and agricultural science and technology park and unifies the field intelligent control and scientific research and production integration management platforms. Standardized planting and a field monitoring center for large data visualization analysis for scientific research and production are used to achieve real-time online mining analysis, monitoring, and early warning and decision support services. A software terminal is used to prompt on-site management measures and early warning according to weather changes. After one growing season, the labor force was reduced by 20%, the use of pesticides by 20%, and the use of water resources and fertilizers decreased. Practical application shows that the system runs stably and meets the demands of ecological environment monitoring in ASTPs.",https://ieeexplore.ieee.org/document/9498218/,2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA),28-30 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCI-CC.2014.6921432,From information revolution to intelligence revolution: Big data science vs. intelligence science,IEEE,Conferences,"The hierarchy of human knowledge is categorized at the levels of data, information, knowledge, and intelligence. For instance, given an AND-gate with 1,000-input pins, it may be described very much differently at various levels of perceptions in the knowledge hierarchy. At the data level on the bottom, it represents a 21,000 state space, known as `big data' in recent terms, which appears to be a big issue in engineering. However, at the information level, it just represents 1,000 bit information that is equivalent to the numbers of inputs. Further, at the knowledge level, it expresses only two rules that if all inputs are one, the output is one; and if any input is zero, the output is zero. Ultimately, at the intelligence level, it is simply an instance of the logical model of an AND-gate with arbitrary inputs. This problem reveals that human intelligence and wisdom are an extremely efficient and a fast convergent induction mechanism for knowledge and wisdom elicitation and abstraction where data are merely factual materials and arbitrary instances in the almost infinite state space of the real world. Although data and information processing have been relatively well studied, the nature, theories, and suitable mathematics underpinning knowledge and intelligence are yet to be systematically studied in cognitive informatics and cognitive computing. This will leads to a new era of human intelligence revolution following the industrial, computational, and information revolutions. This is also in accordance with the driving force of the hierarchical human needs from low-level material requirements to high-level ones such as knowledge, wisdom, and intelligence. The trend to the emerging intelligent revolution is to meet the ultimate human needs. The basic approach to intelligent revolution is to invent and embody cognitive computers, cognitive robots, and cognitive systems that extend human memory capacity, learning ability, wisdom, and creativity. Via intelligence revolution, an interconnected cognitive intelligent Internet will enable ordinary people to access highly intelligent systems created based on the latest development of human knowledge and wisdom. Highly professional systems may help people to solve typical everyday problems. Towards these objectives, the latest advances in abstract intelligence and intelligence science investigated in cognitive informatics and cognitive computing are well positioned at the center of intelligence revolution. A wide range of applications of cognitive computers have been developing in ICIC [http://www.ucalgary.ca/icic/] such as, inter alia, cognitive computers, cognitive robots, cognitive learning engines, cognitive Internet, cognitive agents, cognitive search engines, cognitive translators, cognitive control systems, cognitive communications systems, and cognitive automobiles.",https://ieeexplore.ieee.org/document/6921432/,2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing,18-20 Aug. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSEI50228.2020.9142534,How to Use Stock Data for Data Science Education: A Simulated Trading Platform in Classroom,IEEE,Conferences,"The research hereby presents an innovate practice to enhance data science education by integrating an in-house-developed stock trading platform. Students of Data Science area usually face the difficulty of understanding the complex of real-time data and sophisticated statistical indicators and models. Another difficulty is students are easy to lost interests and patience during the process of learning programming and analysis process, such as R-language. Stock market, as a huge data source and an important data disciplinary, is comparatively easy to attract student attentions. Thus, we developed an intuitive trading platform for education purpose. The platform contains three components: an exploring window, a control windows and a report window. The exploring window shows current and historical stock price trends and related indicators. Several representative stocks from different sectors can be picked and specific time frames can be assigned. The control window allows students to develop their own trading strategies. A trading strategy can be created by either intuitive way, or through single or combinations of indicators, or be built generically though plug-in R-programing module. The report window demonstrates the expected return of a stock in a specific time frame through a specific strategy. A more comprehensive report with detailed transaction information is also provided for back-testing purpose. Students are involved into the development of the software and get experience for R-programming. Preliminary version of the product has been tested and surveyed in a data science classroom. About ten junior Data Science students have practiced and provided feedback. The positive survey results show the feasibility of the approach. In the future, artificial intelligent component will be integrated into the platform.",https://ieeexplore.ieee.org/document/9142534/,2020 IEEE 2nd International Conference on Computer Science and Educational Informatization (CSEI),12-14 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIKE.2018.00015,Machine Learning Models to Enhance the Science of Cognitive Autonomy,IEEE,Conferences,"Intelligent Autonomous Systems (IAS) are highly cognitive, reflective, multitask-able, and effective in knowledge discovery. Examples of IAS include software systems that are capable of automatic reconfiguration, autonomous vehicles, network of sensors with reconfigurable sensory platforms, and an unmanned aerial vehicle (UAV) respecting privacy by deciding to turn off its camera when pointing inside a private residence. Research is needed to build systems that can monitor their environment and interactions, learn their capabilities and limitations, and adapt to meet the mission objectives with limited or no human intervention. The systems should be fail-safe and should allow for graceful degradations while continuing to meet the mission objectives. In this paper, we provide an overview of our proposed new methodologies and workflows, and survey the existing approaches and new ones that can advance the science of autonomy in smart systems through enhancements in real-time control, auto-reconfigurability, monitoring, adaptability, and trust. This paper also provides the theoretical framework behind IAS.",https://ieeexplore.ieee.org/document/8527447/,2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),26-28 Sept. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COGINF.2006.365669,On Intelligence Science and Recent Progresses,IEEE,Conferences,"Summary form only given. Intelligence science is a cross-discipline that dedicates to joint research on basic theory and technology of intelligence by brain science, cognitive science, artificial intelligence and others. Brain science explores the essence of brain, research on the principle and model of natural intelligence in molecular, cell and behavior level. Cognitive science studies human mental activity, such as perception, learning, memory, thinking, consciousness etc. In order to implement machine intelligence, Artificial intelligence attempts simulation, extension and expansion of human intelligence using artificial methodology and technology. The above three disciplines work together to explore new concept, new theory, new methodology. It will be successful and create a brilliant future in the 21 century. Brain science points out that perceptive lobes have special function separately, the occipital lobe processes the visual information, the temporal lobe processes auditory information, the parietal lobe processes the information from the somatic sensors. All of three lobes deal with information perceived from the physical world. Each lobe is covered with cortex where the bodies of neurons are located. Cortex consists of primary, intermediate and advanced areas at least. Information is processed in the primary area first, then is passed to intermediate and advanced areas. Comparing with computer system, the brain is the same as hardware and the mind looks like software. Most work in cognitive science assumes that the mind has mental representations analogous to computer data structures, and computational procedures similar to computational algorithms. Connectionists have proposed novel ideas to use neurons and their connections as inspirations for data structures, and neuron firing and spreading activation as inspirations for algorithms. Cognitive science then works with a complex 3-way analogy among the mind, the brain, and computers. Mind, brain, and computation can each be used to suggest new ideas about the others. There is no single computational model of mind, since different kinds of computers and programming approaches suggest different ways in which the mind might work. The mind contains perception, rational, consciousness and emotion. The long-term scientific goal of artificial intelligence is human-level intelligence. In this lecture, we will discuss basic research topics related to intelligence science, such as learning, memory, thought, language, consciousness etc. We also report the recent progresses containing: visual perception; introspective learning; linguistic cognition; consciousness model; and platform of agent-grid intelligence",https://ieeexplore.ieee.org/document/4216384/,2006 5th IEEE International Conference on Cognitive Informatics,17-19 July 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IRI.2009.5211603,Ontology-based information model development for science information reuse and integration,IEEE,Conferences,"Scientific digital libraries serve complex and evolving research communities. Justifications for the development of scientific digital libraries include the desire to preserve science data and the promises of information interconnectedness, correlative science, and system interoperability. Shared ontologies are fundamental to fulfilling these promises. We present a tool framework, a set of principles, and a real world case study where shared ontologies are used to develop and manage science information models and subsequently guide the implementation of scientific digital libraries. The tool framework, based on an ontology modeling tool, has been used to formalize legacy information models as well as design new models. Within this framework, the information model remains relevant within changing domains and thereby promotes the interoperability, interconnectedness, and correlation desired by scientists.",https://ieeexplore.ieee.org/document/5211603/,2009 IEEE International Conference on Information Reuse & Integration,10-12 Aug. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FIE.2018.8658596,Personalizing Computer Science Education by Leveraging Multimodal Learning Analytics,IEEE,Conferences,"This Research Full Paper implements a framework that harness sources of programming learning analytics on three computer programming courses a Higher Education Institution. The platform, called PredictCS, automatically detects lower-performing or “at-risk” students in programming courses and automatically and adaptively sends them feedback. This system has been progressively adopted at the classroom level to improve personalized learning. A visual analytics dashboard is developed and accessible to Faculty. This contains information about the models deployed and insights extracted from student's data. By leveraging historical student data we built predictive models using student characteristics, prior academic history, logged interactions between students and online resources, and students' progress in programming laboratory work. Predictions were generated every week during the semester's classes. In addition, during the second half of the semester, students who opted-in received pseudo real-time personalised feedback. Notifications were personalised based on students' predicted performance on the course and included a programming suggestion from a top-student in the class if any programs submitted had failed to meet the specified criteria. As a result, this helped students who corrected their programs to learn more and reduced the gap between lower and higher-performing students.",https://ieeexplore.ieee.org/document/8658596/,2018 IEEE Frontiers in Education Conference (FIE),3-6 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSEET49119.2020.9206229,Project-Based Learning in a Machine Learning Course with Differentiated Industrial Projects for Various Computer Science Master Programs,IEEE,Conferences,"Graduating computer science students with skills sufficient for industrial needs is a priority in higher education teaching. Project-based approaches are promising to develop practical and social skills, needed to address real-world problems in teams. However, rapid technological transition makes an initial training of contemporary methods challenging. This affects the currently much-discussed machine learning domain as well. The study at hand describes a re-framed teaching approach for a machine learning course, offered to various computer science master programs. Project-based learning is introduced with differentiated projects provided by industrial partners that address the diverse study programs. Course attendees are supported with manuals, tools, and tutoring, passing through the Cross Industry Standard Process for Data Mining (CRISP-DM). Observations made during two iterations are reported, accompanied by a first empiric evaluation of student experiences.",https://ieeexplore.ieee.org/document/9206229/,2020 IEEE 32nd Conference on Software Engineering Education and Training (CSEE&T),9-12 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WORKS49585.2019.00006,Provenance Data in the Machine Learning Lifecycle in Computational Science and Engineering,IEEE,Conferences,"Machine Learning (ML) has become essential in several industries. In Computational Science and Engineering (CSE), the complexity of the ML lifecycle comes from the large variety of data, scientists' expertise, tools, and workflows. If data are not tracked properly during the lifecycle, it becomes unfeasible to recreate a ML model from scratch or to explain to stackholders how it was created. The main limitation of provenance tracking solutions is that they cannot cope with provenance capture and integration of domain and ML data processed in the multiple workflows in the lifecycle, while keeping the provenance capture overhead low. To handle this problem, in this paper we contribute with a detailed characterization of provenance data in the ML lifecycle in CSE; a new provenance data representation, called PROV-ML, built on top of W3C PROV and ML Schema; and extensions to a system that tracks provenance from multiple workflows to address the characteristics of ML and CSE, and to allow for provenance queries with a standard vocabulary. We show a practical use in a real case in the O&G industry, along with its evaluation using 239,616 CUDA cores in parallel.",https://ieeexplore.ieee.org/document/8943505/,2019 IEEE/ACM Workflows in Support of Large-Scale Science (WORKS),17-17 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCSA.2007.90,The 2007 International Conference Computational Science and its Applications - Title,IEEE,Conferences,The following topics are dealt with: computational intelligence; high performance technical computing; information systems; Web based learning; component based software engineering; software process model; computational geometry; distributed computing; digital content security; data storage devices; data storage systems; intelligent design technology; intelligent data mining; information services; information technologies; mobile multimedia networks; pattern recognition; ubiquitous computing; computer graphics; computational science; wireless sensor networks; virtual reality; optimization; mobile communication; molecular simulations.,https://ieeexplore.ieee.org/document/4301111/,2007 International Conference on Computational Science and its Applications (ICCSA 2007),26-29 Aug. 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData50022.2020.9378128,~PB&J~ - Easy Automation of Data Science/Machine Learning Workflows,IEEE,Conferences,"The ability to process large amounts of data efficiently is a must in modern Big Data, Data Science and Machine Learning (ML). Easy and succinct workflow expression with highly efficient scaling is key. Existing systems such as Apache Spark and Beam were created for this type of work but have steep learning curve and tremendous operating complexity. Having a simpler tool with less overhead that is well-matched to the typical workflow definition and execution requirements of data science/ML projects will be beneficial.We propose a new framework PB&J that enables succinct definition and data-parallel scale-out execution of workflows with ease. PB&J is easy to learn as it builds on the native Unix shell, with the addition of just a few operators. PB&J supports Maximal Parallelism with its ability to do true pipelining, and fault recovery with Minimal Redo. It is well-matched to the typical data science/ML processing requirements by leveraging the existing command line executables and Python modules. We illustrate the features and strengths of PB&J with real-life Deep Learning data processing workflows. We compare it to existing frameworks such as Apache Spark, Apache Beam, Swift/T and Apache Airflow in terms of ease of authoring, efficiency, scalability and fault recovery.",https://ieeexplore.ieee.org/document/9378128/,2020 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1093/comjnl/bxy082,Algorithmic Government: Automating Public Services and Supporting Civil Servants in using Data Science Technologies,OUP,Journals,"The data science technologies of artificial intelligence (AI), Internet of Things (IoT), big data and behavioral/predictive analytics, and blockchain are poised to revolutionize government and create a new generation of GovTech start-ups. The impact from the ‘smartification’ of public services and the national infrastructure will be much more significant in comparison to any other sector given government's function and importance to every institution and individual. Potential GovTech systems include Chatbots and intelligent assistants for public engagement, Robo-advisors to support civil servants, real-time management of the national infrastructure using IoT and blockchain, automated compliance/regulation, public records securely stored in blockchain distributed ledgers, online judicial and dispute resolution systems, and laws/statutes encoded as blockchain smart contracts. Government is potentially the major ‘client’ and also ‘public champion’ for these new data technologies. This review paper uses our simple taxonomy of government services to provide an overview of data science automation being deployed by governments world-wide. The goal of this review paper is to encourage the Computer Science community to engage with government to develop these new systems to transform public services and support the work of civil servants.",https://ieeexplore.ieee.org/document/8852885/,The Computer Journal,March 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACCESS.2019.2929800,EXTES: An Execution-Time Estimation Scheme for Efficient Computational Science and Engineering Simulation via Machine Learning,IEEE,Journals,"In recent years, computational science and engineering (CSE) simulations using high-performance computing resources are actively exploited to solve complex domain-specific problems. Thanks to the remarkable advance of IT technology, the CSE community is challenging more complex and difficult problems than ever before, by running these simulations online. In this regard, we often witness that 1) online simulation users suffer from knowing little about the estimated termination time of their launched simulations and 2) the limited computing resources are squandered by wrong input that leads the simulations to run forever. To address such issues, we propose a novel execution time estimation scheme, termed EXTES, using machine learning techniques for more efficient online CSE simulations. With a large amount of existing provenance data, the EXTES scheme trains a suite of models rooted from classification, regression, and a hybrid of the two and utilize these models to estimate the execution time for specified input parameters for simulations. In the experiments on real simulation data, our proposed models achieved about 73% accuracy on average in execution time estimation across 16 simulation programs taken from a variety of CSE fields. In the meantime, the overhead incurred by the training and estimation is almost negligible.",https://ieeexplore.ieee.org/document/8766089/,IEEE Access,2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACCESS.2019.2899985,Using Machine Learning Ensemble Methods to Predict Execution Time of e-Science Workflows in Heterogeneous Distributed Systems,IEEE,Journals,"Effective planning and optimized execution of the e-Science workflows in distributed systems, such as the Grid, need predictions of execution times of the workflows. However, predicting the execution times of e-Science workflows in heterogeneous distributed systems is a challenging job due to the complex structure of workflows, variations due to input problem-sizes, and heterogeneous and dynamic nature of the shared resources. To this end, we propose two novel workflow execution time-prediction methods based on the machine learning ensemble models. In this paper, we showcase our approach for two different real Grid environments. Our approach can effectively predict the execution time of the scientific workflow applications in the Grid for various problem sizes, Grid sites, and runtime environments. We characterized the workflow performance in the Grid using the attributes that define structure of workflow as well as the execution environment. Contrary to common ensembles, our ensemble systems employed three strong learners, which balance the weaknesses of each other by their strengths to model the workflow execution times. The proposed methods have been thoroughly evaluated for three real-world e-science workflow applications. The experimental results demonstrated that our proposed multi-model ensemble models can significantly decrease the prediction error (by 50%, on average) as compared with methods based on the radial basis function neural network, local learning, and performance templates. The proposed methods can also be applied with similar effectiveness and without any major modification for other heterogeneous distributed environments, such as the Cloud.",https://ieeexplore.ieee.org/document/8643927/,IEEE Access,2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TITB.2004.826724,Using XML technology for the ontology-based semantic integration of life science databases,IEEE,Journals,"Several hundred internet accessible life science databases with constantly growing contents and varying areas of specialization are publicly available via the internet. Database integration, consequently, is a fundamental prerequisite to be able to answer complex biological questions. Due to the presence of syntactic, schematic, and semantic heterogeneities, large scale database integration at present takes considerable efforts. As there is a growing apprehension of extensible markup language (XML) as a means for data exchange in the life sciences, this article focuses on the impact of XML technology on database integration in this area. In detail, a general architecture for ontology-driven data integration based on XML technology is introduced, which overcomes some of the traditional problems in this area. As a proof of concept, a prototypical implementation of this architecture based on a native XML database and an expert system shell is described for the realization of a real world integration scenario.",https://ieeexplore.ieee.org/document/1303558/,IEEE Transactions on Information Technology in Biomedicine,June 2004,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SKG.2011.31,5W1H-based Conceptual Modeling Framework for Domain Ontology and Its Application on STPO,IEEE,Conferences,"It is laborious and time consuming to build domain ontology, which models a specific domain and specifies the concepts in a particular subject. In this paper, a 5W1H-based conceptual modeling framework for domain ontology is proposed, which is used to analysis domain concepts and relations from six aspects including Who, When, Where, What, Why and How. The definition of domain ontology, domain concept and domain relation are also presented. According to the framework, the conceptual model of Science & Technology Project Ontology (STPO) in science and technology domain is designed, in which main concepts and relations within the STPO are clearly described. From the analysis, the 5W1H conceptual modeling framework can be mapped to the class model in Object-Oriented method, which is used to model things in real world. Application shows that the framework is effective to model domain knowledge and scalable to business changes and user requirements.",https://ieeexplore.ieee.org/document/6088118/,"2011 Seventh International Conference on Semantics, Knowledge and Grids",24-26 Oct. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MELECON53508.2022.9842871,A Citizen Science Approach for the Collection of Data to Train Deep Learning Models,IEEE,Conferences,"Machine learning techniques that give good predictions require a considerable amount of data, which sometimes can be a challenge to collect. In this study, citizen science is being introduced as an auxiliary technique to provide more data for the training of a deep learning network for the classification of Maltese Flora; a field which to this date lacks sufficient training data. In the first part of this study, we investigate the training of a deep learning model that makes use of a limited training dataset utilising techniques such as data augmentation, data scraping and transfer learning. This improved experimented off-the-shelf model generated a low accuracy highlighting the relevance of the initial hypothesis that citizen science is needed for the improvement of deep-learning models. In the second phase, citizen science was used as a data crowdsourcing technique through a mobile communication system. A study was conducted to determine the opinion of the public with only a small percentage showing a lack of interest in participating. Therefore, a dynamic educational application was implemented for the public exploiting Artificial Intelligence advancements to identify Maltese Flora in real-time whilst gathering images used to enhance the dataset. The deep learning model was re-trained on this dataset showing a significant increase in performance. Visualizations of the current Maltese flora distribution were also generated utilizing this data. This study demonstrated that the use of citizen science is essential for the improvement of deep learning models so that they can be employed in more widespread applications.",https://ieeexplore.ieee.org/document/9842871/,2022 IEEE 21st Mediterranean Electrotechnical Conference (MELECON),14-16 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COGINF.2007.4341895,A Cognitive Psychology Approach for Balancing Elicitation Goals,IEEE,Conferences,"The difference between success and failure in a project depends on the initial identification and construction of goals, which are the mechanism of identifying software requirements. The result of applying goal-oriented methods, which are top-down requirements analysis, is in most cases a goal graph. Goal graphs are implemented from customers needs as initial goals to requirements specifications as final goals. Their analysis includes negotiation as an important issue, which becomes extremely difficult, as clients often cannot know exactly what they need. To overcome this situation, aiming at improving stakeholder's negotiation, we reduce the gap of misunderstanding between them by the use of cognitive science. The objective of this paper is to introduce a cognitive approach to help in the solution of discordances among stakeholders when applying goal- oriented methods. We depict our proposal with a real case study.",https://ieeexplore.ieee.org/document/4341895/,6th IEEE International Conference on Cognitive Informatics,6-8 Aug. 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISORC49007.2020.00030,A Cross-Layer Review of Deep Learning Frameworks to Ease Their Optimization and Reuse,IEEE,Conferences,"Machine learning and especially Deep Learning (DL) approaches are at the heart of many domains, from computer vision and speech processing to predicting trajectories in autonomous driving and data science. Those approaches mainly build upon Neural Networks (NNs), which are compute-intensive in nature. A plethora of frameworks, libraries and platforms have been deployed for the implementation of those NNs, but end users often lack guidance on what frameworks, platforms and libraries to use to obtain the best implementation for their particular needs. This paper analyzes the DL ecosystem providing a structured view of some of the main frameworks, platforms and libraries for DL implementation. We show how those DL applications build ultimately on some form of linear algebra operations such as matrix multiplication, vector addition, dot product and the like. This analysis allows understanding how optimizations of specific linear algebra functions for specific platforms can be effectively leveraged to maximize specific targets (e.g. performance or power-efficiency) at application level reusing components across frameworks and domains.",https://ieeexplore.ieee.org/document/9112939/,2020 IEEE 23rd International Symposium on Real-Time Distributed Computing (ISORC),19-21 May 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIIC51459.2021.9415186,A Data Augmented Bayesian Network for Node Failure Prediction in Optical Networks,IEEE,Conferences,"Failures in optical network backbone can cause significant interruption in internet data traffic. Hence, it is very important to reduce such network outages. Prediction of such failures would be a step forward to avoid such disruption of internet services for users as well as operators. Several research proposals are available in the literature which are applications of data science and machine learning techniques. Most of the techniques rely on significant amount of real time data collection. Network devices are assumed to be equipped to collect data and these are then analysed by different algorithms to predict failures. Every network element which is already deployed in the field may not have these data gathering or analysis techniques designed into them initially. However, such mechanisms become necessary later when they are already deployed in the field. This paper proposes a Bayesian network based failure prediction of network nodes, g., routers etc., using very basic information from the log files of the devices and applying power law based data augmentation to complement for scarce real time information. Numerical results show that network node failure prediction can be performed with high accuracy using the proposed mechanism.",https://ieeexplore.ieee.org/document/9415186/,2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),13-16 April 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HPCC/SmartCity/DSS.2018.00201,A Deep Learning Approach to Sensory Navigation Device for Blind Guidance,IEEE,Conferences,"Sensory navigation device is an important trend in the field of machine learning and data science. Nowadays, more and more sensory navigation devices are built for blind people. The core of such sensory navigation devices for blind people usually is implemented by an Image Recognition Method. To build an image recognition model, many tools and online machine learning platforms are proposed. However, these tools or platforms are not able to completely satisfy the requirements for sensory navigation device. To build a sensory navigation device with satisfying requirements for blind people, an ability of reducing the cost of model training and a capability of user-centric image recognition are the two main issues. Therefore, to address the above issues, we propose a novel approach, namely, DLSNF (Deep-Learning-based Sensory Navigation Framework). Our proposed DLSNF is built based on the YOLO architecture to deal with the reducing cost of model training and NVIDIA Jetson TX2 to take the user-centric image recognition into account. Based on our proposed DLSNF, the real-time image recognition can be trained well and conduct a sensory navigation to help blind people. At the same time, the train model is embedded in NVIDIA Jetson TX2 which is the fastest, most power-efficient embedded AI computing device. For the experiments, we evaluated our proposed DLSNF with a real-world dataset consisting of 4,570 images collected by part-time workers. The extensive experimental results show that our proposed DLSNF more effectively and efficiently beyond the existing baselines.",https://ieeexplore.ieee.org/document/8622939/,2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),28-30 June 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IC3IOT53935.2022.9767897,"A Deep study of Data science related problems, application and machine learning algorithms utilized in Data science",IEEE,Conferences,"Data Science study utilized for gathering information as data, taking out data from other systems, accumulating information, signifying and safeguarding data collected are used by organizations for marketing purposes and in high-tech implementations. Name of data science denotes a combination of databases and software engineering as well as a number of types of qualitative, quantitative entities and non-mathematical entities are furthermore necessary. Data science and its importance, components in data science included, life cycle of data science, Application of data science, various algorithms in machine learning are used with data science and implementation of machine learning algorithm in real life cases are also described. Finally, wound up with how to decode an obstacle in data Science using machine learning algorithms.",https://ieeexplore.ieee.org/document/9767897/,"2022 International Conference on Communication, Computing and Internet of Things (IC3IoT)",10-11 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IDAP.2018.8620736,A Framework Based on Compiler Design Techniques for Programming Learning Environments,IEEE,Conferences,"It has been observed that the studies for starting programming learning at an early age have increased in recent years. Programming that enhances the high level cognitive skills of individuals is seen as a competency that must be acquired for everyone nowadays. In current programming learning environments, programming is usually done using visual components. However, it is emphasized that there is little contribution to the transition to actual programming languages by programming with visual components in the studies carried out. For this reason, a new programming learning environment has been developed in this study in which everyone can learn programming. To facilitate programming learning and contribute to the transition of actual programming languages, a new programming language is described which is simple syntax and similar to real programming languages. This language is controlled in terms of meaning and grammar with lexical and syntax analysis steps. The specified compiler design techniques are implemented using finite state machines. Analysis of the created programming language is performed by regular expressions. Instead of providing a free workspace for the user, an environment with quests covering programming concepts is presented. This quest based environment aims at the successful learning process by guiding to the user through feedbacks. The programming learning environment has been developed as an open source software by using computer science and engineering techniques and it is a framework for researchers seeking to develop a similar environment.",https://ieeexplore.ieee.org/document/8620736/,2018 International Conference on Artificial Intelligence and Data Processing (IDAP),28-30 Sept. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITE50838.2020.9231486,A Genetic Algorithm-based AutoML Approach for Large-scale Traffic Speed Prediction,IEEE,Conferences,"With the continuous innovation of computer science as well as the big data acquisition technology, machine learning (ML), developed as a state-of-art framework, now has been comprehensively applied in speed prediction tasks. However, ML methods usually require intensive hyper-parameter tuning, which hinders the practical deployment of ML models. In view of this, this paper proposes an automated machine learning (AutoML) framework for speed prediction, which enables the prediction work to be accomplished in a much more timesaving and convenient way as well as in high prediction accuracy. The proposed framework utilizes the Genetic Algorithm (GA) following its four major procedures: Genome coding, Crossover, Mutation and Selection to automatically search for the optimal neural network architectures and hyperparameters. The proposed framework is examined on a real-world large-scale dataset in the city of Berlin, Germany. The experimental results demonstrate that the proposed method outperforms other benchmarking methods by a significant margin. Sensitivity analysis is also conducted to show the robustness of the proposed method. This study demonstrates the great penitential of using AutoML in traffic speed prediction and other related transportation applications.",https://ieeexplore.ieee.org/document/9231486/,2020 IEEE 5th International Conference on Intelligent Transportation Engineering (ICITE),11-13 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SYNASC.2009.12,A Hierarchy of Tractable Subclasses for SAT and Counting SAT Problems,IEEE,Conferences,"Finding subclasses of formulae for which the SAT problem can be solved in polynomial time has been an important problem in computer science. We present a new hierarchy of propositional formulæ subclasses for which the SAT and counting SAT problems can be solved in polynomial time. Our tractable subclasses are those propositional formulae in conjunctive normal form where any set of k + 1 clauses are related, i.e., there exists at least one literal in one clause that appears negated in another clause of the considered set of k + 1 clauses. We say this subclass of formulæ is of rank k and it is different from previously known subclasses that are solvable in polynomial time. This is an improvement over the SAT Dichotomy Theorem and the counting SAT Dichotomy Theorem, since our subclass can be moved out from the ¿P-complete class to the P class. The membership problem for this new subclass can be solved in O(n·lk+1), where n, l and k are the number of variables, clauses and the rank (1 ¿ k ¿ l - 1), respectively. We give an efficient algorithm to approximate the number of assignments for any arbitrary conjunctive normal form propositional formula by an upper bound.",https://ieeexplore.ieee.org/document/5460868/,2009 11th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing,26-29 Sept. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC.2019.8914223,A Julia Package for manipulating Brain-Computer Interface Data in the Manifold of Positive Definite Matrices,IEEE,Conferences,"The Riemannian geometry of positive definite matrices yields state-of-the-art classification accuracy for brain-computer interface (BCI) data. The use of this framework is steadily increasing in the BCI community, sustained by its excellent classification accuracy and ability to operate transfer learning. Currently, open-source code libraries exist for the Matlab and Python programming language. Julia is a young open-source cross-platform language specifically conceived for scientific computing, which is rapidly gaining momentum in the data science community thanks to its efficiency and compatibility with the best available computing protocols. By means of this article we present and release a state-of-the-art open-source Julia package for the Riemannian geometry of positive definite matrices, named PosDefManifold. It supports nine metrics for the manifold of both real and complex positive definite matrices and includes all fundamental tools for manipulating data in them.",https://ieeexplore.ieee.org/document/8914223/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CESA.2006.4281933,A Knowledge-Based Approach for Semantic Service Composition,IEEE,Conferences,"The successful application of grid and Web service technologies to real-world problems, such as e-Science, requires not only the development of a common vocabulary and meta-data framework as the basis for inter-agent communication and service integration but also the access and use of a rich repository of domain-specific knowledge for problem solving. Both requirements are met by the respective outcomes of ontological and knowledge engineering initiatives. In this paper we discuss a novel, knowledge-based approach to resource synthesis (service composition), which draws on the functionality of semantic Web services to represent and expose available resources. The approach we use exploits domain knowledge to guide the service composition process and provide advice on service selection and instantiation. The approach has been implemented in a prototype workflow construction environment that supports the runtime recommendation of a service solution, service discovery via semantic service descriptions, and knowledge-based configuration of selected services. The use of knowledge provides a basis for full automation of service composition via conventional planning algorithms. Workflows produced by this system can be executed through a domain-specific direct mapping mechanism or via a more fluid approach such as WSDL- based service grounding. The approach and prototype have been used to demonstrate practical benefits in the context of the Geodise initiative.",https://ieeexplore.ieee.org/document/4281933/,"The Proceedings of the Multiconference on ""Computational Engineering in Systems Applications""",4-6 Oct. 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GLOBECOM46510.2021.9685807,A Machine Learning Approach for Rate Prediction in Multicast File-stream Distribution Networks,IEEE,Conferences,"Large-volume scientific data is one of the prominent driving forces behind next generation networking. In particular, Software Defined Network (SDN) makes leveraging path-based network multicast services practically feasible. In our prior work, we have developed a cross-layer architecture for supporting reliable file-streams multicasting over SDN-enabled Layer-2 network, and implemented the architecture for a meteorology data distribution application in atmospheric science. However, it is challenging to determine an optimal rate for this application with the varying type, volume, and quality of meteorological data. In this paper, we propose a Quality of Service (QoS)-driven rate management pipeline to determine the optimal rate based on the input traffic characteristics and performance constraints. Specifically, the pipeline employs a feedtype classifier using Multi-Layer Perception (MLP) to recognize the type of meteorological data and a delay prediction regressor using stacked Long Short-Term Memory (LSTM) to predict per-file delay for the file-streams. Finally, we determine the optimal rate for the given file-streams using the trained regressor. We implement this pipeline to test the real-world file-stream data collected from a trial deployment, and the results show that our regressor outperforms all baselines by selecting the optimal rate in the presence of varying file set sizes.",https://ieeexplore.ieee.org/document/9685807/,2021 IEEE Global Communications Conference (GLOBECOM),7-11 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SITIS.2019.00066,A Microservice-Based Building Block Approach for Scientific Workflow Engines: Processing Large Data Volumes with DagOnStar,IEEE,Conferences,"The impact of machine learning algorithms on everyday life is overwhelming until the novel concept of datacracy as a new social paradigm. In the field of computational environmental science and, in particular, of applications of large data science proof of concept on the natural resources management this kind of approaches could make the difference between species surviving to potential extinction and compromised ecological niches. In this scenario, the use of high throughput workflow engines, enabling the management of complex data flows in production is rock solid, as demonstrated by the rise of recent tools as Parsl and DagOnStar. Nevertheless, the availability of dedicated computational resources, although mitigated by the use of cloud computing technologies, could be a remarkable limitation. In this paper, we present a novel and improved version of DagOnStar, enabling the execution of lightweight but recurring computational tasks on the microservice architecture. We present our preliminary results motivating our choices supported by some evaluations and a real-world use case.",https://ieeexplore.ieee.org/document/9067951/,2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS),26-29 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAI52893.2021.9639638,A Modelling & Simulation Tier Design for the EMULSION IoT Platform,IEEE,Conferences,"This paper ♠ introduces some design aspects of the EMULSION IoT platform, which is an example of the new IoT platforms of horizontal type, evolving as a replacement of the existing vertical-type IoT platforms. The EMULSION’s architectural overview, main characteristics, and multi-tiered structure are presented, with attention dedicated to its modelling & simulation tier.♠This publication has emanated from joint research conducted with the financial support of the Bulgarian National Science Fund (BNSF) under the Grant No. (КП-06-ИП-КИТАЙ/1) and the S&T Major Project of the Science and Technology Ministry of China, Grant No. 2017YFE0135700.",https://ieeexplore.ieee.org/document/9639638/,2021 International Conference Automatics and Informatics (ICAI),30 Sept.-2 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MENACOMM50742.2021.9678232,A Novel Classification of Machine Learning Applications in Healthcare,IEEE,Conferences,"In recent years, machine learning has become widely used in various applications and research. It plays a crucial role in numerous fields such as medical science and the healthcare system. In such scenarios, machine learning is used to diagnose sizeable medical data patterns or predict diseases. This paper presents a survey about different machine learning algorithms with their applications in various domains and shows the advantages of machine learning techniques that help create efficient support infrastructure for medical fields and improve healthcare services. This survey&#x2019;s main objective is to highlight the previous work of machine learning algorithms implemented in the healthcare system and provide all necessary information to the researchers who want to explore machine learning in the healthcare system.",https://ieeexplore.ieee.org/document/9678232/,2021 3rd IEEE Middle East and North Africa COMMunications Conference (MENACOMM),3-5 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICI.2009.31,A Novel Clustering Algorithm for Graphs,IEEE,Conferences,"Graph or network clustering is one of the fundamental multimodal combinatorial problems that have many applications in computer science. Many algorithms have been devised to obtain a reasonable approximate solution for the problem. Current approaches, however, suffer from the local optimum drawback and then have difficulty splitting two clusters with very confused structures. In this paper we propose a novel genetic-based algorithm incorporating with modularity(QN) for the quality of partitioning of graphs. The theoretical analysis and experimental results on synthetic and real networks demonstrate superior performance over Newman's fast agglomerative algorithms in accuracy.",https://ieeexplore.ieee.org/document/5376354/,2009 International Conference on Artificial Intelligence and Computational Intelligence,7-8 Nov. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICACITE53722.2022.9823457,A Novel Implementation of Esophagus Diagnosis Using Deep Learning,IEEE,Conferences,"The presented work is a systematic review on recent technologies in deep learning for Barrett&#x0027;s esophagus (BE), a disease which affects the food pipe. Evaluation of this disorder can be made easy with the help of model developed with deep learning and artificial intelligence. The dysplasia and adenocarcinoma exhibits a complex pattern for detecting through endoscopic diagnosis. The diagnosis and automatic detection using computer analysis is beneficial for assisting the endoscopy procedure. The deep learning technique developed through manual and automated segmentation for the evaluation of BE disorders. The review is done by compilation of works published in Springer, Binda Wi, IEEEXplore, and Association for Computing Machinery, Science Direct and Pubmed on the category of automatic detection of regions for classification purposes. The problem statement, methodology, objective and result of the selected work have been analyzed.",https://ieeexplore.ieee.org/document/9823457/,2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),28-29 April 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GLOBECOM38437.2019.9013255,A Reinforcement Learning Based Network Scheduler for Deadline-Driven Data Transfers,IEEE,Conferences,"We consider a science network that runs applications requiring data transfers to be completed within a given deadline. The underlying network is a software defined network (SDN) that supports fine grain real-time network telemetry. Deadline-aware data transfer requests are made to a centralized network controller that schedules the flows by setting pacing rates of the deadline flows and metering the background traffic at the ingress routers. The goal of the scheduling algorithm is to maximize the number of flows that meet the deadline while maximizing the network utilization. In this paper, we develop a Reinforcement Learning (RL) agent based network controller and compare its performance with well-known heuristics. For a network consisting of a single bottleneck link, we show that the RL-agent based network controller performs as well as Earliest Deadline First (EDF), which is known to be optimal. We also show that the RL-agent performs significantly better than an idealized TCP protocol in which the bottleneck link capacity is equally shared among the competing flows. We also study the sensitivity of the RL-agent controller for different parameter settings and reward functions.",https://ieeexplore.ieee.org/document/9013255/,2019 IEEE Global Communications Conference (GLOBECOM),9-13 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICIRCA48905.2020.9183088,A Survey of Application of ML and Data Mining Techniques for Smart Irrigation System,IEEE,Conferences,"This paper reviews our current research in agriculture analytics on an open-source platform using data mining and machine learning techniques. Various sensors are used to collect data that provides real-time analytics on the weather forecast, soil moisture, air temperature, PH, humidity. The smart irrigation system is paired with different hardware and development application. The science of machine learning and data mining plays a significant role here. It is a data analysis process using multiple models and algorithms to trained data directly. Machine learning and data mining to hold the irrigation system in r leaner manner. For instance, it optimizes the use of water and provides a critical amount of water and fertility to increase production efficiency, reduce manpower involvement, and reduce crop diseases. The survey tests the effect of applicable techniques and how these techniques boost efficiency.",https://ieeexplore.ieee.org/document/9183088/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMITCon.2019.8862251,A Survey: How Python Pitches in IT-World,IEEE,Conferences,"This paper lights on Python amongst other different programming paradigms used in the IT World, which enhances development speed. Although, Python was conceptualized in the late 1980s and after its implementation in 1989, it has emerged as a new multi-paradigm language platform with advent of Big Data. Python includes various data structures, standard libraries with the implementation of sentiment analysis and data science code. The real aim is to provide awareness to all the programmers about various facts of python language. It tells how Python works with various commercial and social communities and provides complete and desirable results. There are many areas and applications where Python makes its own stand as compared to other programming languages.",https://ieeexplore.ieee.org/document/8862251/,"2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)",14-16 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICIEVicIVPR52578.2021.9564229,A Vision-Based Lane Detection Approach for Autonomous Vehicles Using a Convolutional Neural Network Architecture,IEEE,Conferences,"Autonomous vehicles no longer belong to the realm of science fiction. They have become a prominent area of research in the last two decades because of the integration of Artificial Intelligence in the automobile industry. Apart from the development of various complex learning algorithms, the advancement of cameras, sensors, and geolocation technology as well as the escalation in the capacity of machines have played a crucial role in bringing this technology into reality. We have had significant breakthroughs in the development of autonomous cars within the last ten years. However, despite the success of multiple prototypes in navigating within the borders of a delimited area, researchers are yet to overcome several drawbacks before embodying them in the transport system; and one of those hurdles lies in the lane detection system of the cars. Therefore, in this article, we present an intelligent lane detection algorithm incorporating fully-connected Neural Networks with a secondary layer protection scheme to detect the borders of a lane. We achieved over 98% classification accuracy using the proposed lane detection model. We also implemented the model in a small prototype to take a look at its performance. Experimental results infer that the algorithm is capable of lane detection and ready for practical use.",https://ieeexplore.ieee.org/document/9564229/,"2021 Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",16-20 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IMIS.2016.116,A Wireless Body Sensor Network and Its Applications: Rehearsal with a Smartphone,IEEE,Conferences,"Wireless body sensor network (WBSN) technologies are considered one of attracting research areas in computer science. When combined with the healthcare application, it provides high value technology of comprehensive healthcare monitoring solution in extreme situations including high altitude or disaster area enabling the ground controller to monitor remote pilots or earthquake victims in real time by combination of wireless sensors and sensor networks. Sensor networks are irregular clusters of communicating sensor nodes, which collect and process information from onboard sensors, and they can share some of this information with neighboring nodes. By recent technological advances in the integration of ultra-low power networks of miniatured sensors, embedded microcontrollers and radio interfaces on an all-in-one chip can collect important physiologic informations from the surrounding environment efficiently. In addition, the sensed physiological data transmitted to a remote healthcare provider can be modulated and fed back by processing software such as artificial intelligence system enriching capability of the sensor network. In this study, we develop a wireless body sensor network which integrates different physiological sensors with radiointerface to sense physiological data from a human body, and then rehearses to transmits the data to a remote healthcare cloud through a smartphone as an interface. Test results for simulated measurements of wireless transmission and emulation in a smartphone are given and discussed.",https://ieeexplore.ieee.org/document/7794501/,2016 10th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS),6-8 July 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIMSEC.2011.6010129,A broad-spectrum temperature tester based on SCM,IEEE,Conferences,"With the development of the modern science and technology, the requirements of temperature control are higher and higher. In most cases, we need real-time detection of the environmental temperature and communications. In order to adapt to the rapid development of technology, temperature tester need to be more effective and accurate. This paper describes the system board based on a broad spectrum of MSP430 MCU temperature measurement instrument, the major technical indicators of the system and some related tests are discussed in detail. The results show that the system is accurate, sensitive, efficient, stable, reliable and suitable for the application of intelligent automated environment.",https://ieeexplore.ieee.org/document/6010129/,"2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)",8-10 Aug. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COGINF.2010.5599732,A mind model for brain-like computer,IEEE,Conferences,"Mind is all mankind's spiritual activities, including emotion, will, perception, consciousness, representation, learning, memory, thinking, intuition, etc. Mind model is for explaining what individuals operate in the cognitive process for something in the real world. It is the internal sign or representation for external realistic world. If the neural network is a hardware of the brain system, then the mind model is the software of the brain system. The key issue in intelligence science is to construct the mind model of the brain system, which will guide the development of brain-like computer in engineering through structure, dynamics, function and behavioral reverse engineering of the brain. This paper will discuss the computational model of memory and consciousness in the mind model named Consciousness And Memory model(CAM).",https://ieeexplore.ieee.org/document/5599732/,9th IEEE International Conference on Cognitive Informatics (ICCI'10),7-9 July 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACIIW.2019.8925291,A multi-layer artificial intelligence and sensing based affective conversational embodied agent,IEEE,Conferences,"Building natural and conversational virtual humans is a task of formidable complexity. We believe that, especially when building agents that affectively interact with biological humans in real-time, a cognitive science-based, multilayered sensing and artificial intelligence (AI) systems approach is needed. For this demo, we show a working version (through human interaction with it) our modular system of natural, conversation 3D virtual human using AI or sensing layers. These including sensing the human user via facial emotion recognition, voice stress, semantic meaning of the words, eye gaze, heart rate, and galvanic skin response. These inputs are combined with AI sensing and recognition of the environment using deep learning natural language captioning or dense captioning. These are all processed by our AI avatar system allowing for an affective and empathetic conversation using an NLP topic-based dialogue capable of using facial expressions, gestures, breath, eye gaze and voice language-based two-way back and forth conversations with a sensed human. Our lab has been building these systems in stages over the years.",https://ieeexplore.ieee.org/document/8925291/,2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),3-6 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITSC.2017.8317664,A new modelling framework over temporal graphs for collaborative mobility recommendation systems,IEEE,Conferences,"Over the years, collaborative mobility proved to be an important but challenging component of the smart cities paradigm. One of the biggest challenges in the smart mobility domain is the use of data science as an enabler for the implementation of large scale transportation sharing solutions. In particular, the next generation of Intelligent Transportation Systems (ITS) requires the combination of artificial intelligence and discrete simulations when exploring the effects of what-if decisions in complex scenarios with millions of users. In this paper, we address this challenge by presenting an innovative data modelling framework that can be used for ITS related problems. We demonstrate that the use of graphs and time series in multi-dimensional data models can satisfy the requirements of descriptive and predictive analytics in real-world case studies with massive amounts of continuously changing data. The features of the framework are explained in a case study of a complex collaborative mobility system that combines carpooling, carsharing and shared parking. The performance of the framework is tested with a large-scale dataset, performing machine learning tasks and interactive realtime data visualization. The outcome is a fast, efficient and complete architecture that can be easily deployed, tested and used for research as well in an industrial environment.",https://ieeexplore.ieee.org/document/8317664/,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),16-19 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN.2000.859443,A recurrent neural network for solving nonlinear projection equations,IEEE,Conferences,"In this paper, we are concerned with the nonlinear projection equations of the following form P/sub /spl chi//(u-F(u))=u. Despite the particular structure of the feasible set /spl chi/, the problem is still a very general problem in mathematics programming. Moreover, there are a number of important applications which lead to this special class of variational inequalities such as equilibrium models arising in fields of economics and transportation science, etc. Various numerical solution procedures for the problem have been investigated over decades. Because of the nature of digital computers, conventional algorithms are time-consuming for large-scale optimization problems. It is well-known that one promising approach to optimization problems in real time is to employ artificial neural networks implemented in hardware. Recurrent neural networks for solving optimization problems are readily hardware-implementable. Thus, neural networks are a top choice of real-time solvers for optimization problems. Since the seminal work of Hopfield and Tank (1985), the neural network approach to optimization has been investigated and many neural networks for optimization problems have been proposed.",https://ieeexplore.ieee.org/document/859443/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GLOCOM.2002.1188542,A scalable on-line multilevel distributed network fault detection/monitoring system based on the SNMP protocol,IEEE,Conferences,"Traditional centralized network management solutions do not scale to present-day large-scale computer/communication networks. Decentralization/distributed solutions can solve some of these problems (Goldszmidt, G. and Yemini, Y., 1995), and thus there is considerable interest in distributed/decentralized network management applications. We present the design and evaluation of an SNMP-based distributed network fault detection/monitoring system. We integrate into the SNMP framework our ML-ADSD algorithm (Su, M.-S. et al., Proc. 39th Annual Allerton Conf. on Commun., Control, and Computers, 2001; Su, ""Multilevel distributed diagnosis and the design of a distributed network fault detection system based on the SNMP protocol"", Ph.D. Thesis, School of Computer Science, University of Oklahoma, 2002) for fault diagnosis in a distributed processor system. The algorithm uses the multilevel paradigm and requires only minor modifications to be scalable to networks of varying sizes. The system is fault tolerant, allowing processor failure and/or recovery during the diagnosis process. We have implemented the system on an Ethernet network of 32 machines. Our results show that the diagnosis latency (or time to termination) is much better than that of earlier solutions. Also, the system's bandwidth utilization is insignificant, demonstrating the practicality of its deployment in a real network. We have successfully integrated three modern disciplines: network management, distributed computing and system level diagnosis.",https://ieeexplore.ieee.org/document/1188542/,"Global Telecommunications Conference, 2002. GLOBECOM '02. IEEE",17-21 Nov. 2002,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICVRV47840.2019.00064,ARTowerDefend: A Shooting Mobile Game Based on Augmented Reality,IEEE,Conferences,"The rapid development of science and technology in today's era has led to the development and application of augmented reality. This article analyzes an Android augmented reality game “ARTowerDefend”. From design to implementation, it describes the clever application of augmented reality in all aspects. Utilizing the Unity game engine combined with GoogleARcore and multiple applications of artificial intelligence to achieve game highlights and innovation, giving players a great sense of gaming experience.",https://ieeexplore.ieee.org/document/9212902/,2019 International Conference on Virtual Reality and Visualization (ICVRV),18-19 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FCCM.2017.58,Accelerating Large-Scale Graph Analytics with FPGA and HMC,IEEE,Conferences,"Graph analytics that explores the relationship among interconnected entities is becoming increasingly important due to its broad applicability from machine learning to social science. However, one major challenge for graph processing systems is the irregular data access pattern of graph computation which can significantly degrade the performance. The algorithms, software, and hardware that have been tailored for mainstream parallel applications are, as a result, generally not effective for massive-scale sparse graphs from the real world due to their complexity and irregularity. To address the performance issues in large-scale graph analytics, we combine the emerging Hybrid Memory Cube (HMC) with a modern FPGA in order to achieve exceptional random access performance without any loss of flexibility or efficiency in computation. In particular, we develop collaborative software/hardware techniques to perform a level-synchronized breadth first search (BFS) on the FPGA-HMC platform. From the software perspective, we develop an architecture-aware graph clustering algorithm that fully exploits the platform's capability to improve data locality and memory access efficiency. For each input graph, this algorithm provides an efficient data layout that allows the FPGA to coalesce memory requests into the largest possible HMC payload requests so that the number of memory requests, which is the primary factor in runtime, can be minimized. From the hardware perspective, we further improve the FPGA-HMC graph processor architecture by adding a merging unit. The merging unit takes the best advantage of the increased data locality resulting from graph clustering. We evaluated the performance of our BFS implementation using the AC-510 development kit from Micron over a set of benchmarks from a wide range of applications. We observed that the combination of the clustering algorithm and the merging hardware achieved 2.8 × average performance improvement compared to the latest FPGA-HMC based graph processing system.",https://ieeexplore.ieee.org/document/7966655/,2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),30 April-2 May 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ELINFOCOM.2016.7562974,Accelerating forwarding computation of artificial neural network using CUDA,IEEE,Conferences,"Recently, graphics processing units (GPUs) are widely used for accelerating general purpose workloads using programming models such as open computing language (OpenCL) or compute unified device architecture (CUDA). In this paper, we accelerated the Artificial Neural Network (ANN) algorithm, one of the popular algorithm in machine learning and cognitive science, since the ANN algorithm needs to be faster for solving more complex problem or operating in real-time. The ANN algorithm has great potential for GPU acceleration since it is constructed with large data-parallel computations. We implemented forwarding computation of ANN in CUDA and optimized it using scratchpad memory of GPUs and leveraging the thread block size. As a results, our method shows 2.32 times faster performance compared to conventional CPU.",https://ieeexplore.ieee.org/document/7562974/,"2016 International Conference on Electronics, Information, and Communications (ICEIC)",27-30 Jan. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2014.7004374,Access-averse framework for computing low-rank matrix approximations,IEEE,Conferences,"Low-rank matrix approximations play important roles in many statistical, scientific, and engineering applications. To compute such approximations, different algorithms have been developed by researchers from a wide range of areas including theoretical computer science, numerical linear algebra, statistics, applied mathematics, data analysis, machine learning, and physical and biological sciences. In this paper, to combine these efforts, we present an “access-averse” framework which encapsulates some of the existing algorithms for computing a truncated singular value decomposition (SVD). This framework not only allows us to develop software whose performance can be tuned based on domain specific knowledge, but it also allows a user from one discipline to test an algorithm from another, or to combine the techniques from different algorithms. To demonstrate this potential, we implement the framework on multicore CPUs with multiple GPUs and compare the performance of two representative algorithms, blocked variants of matrix power and Lanczos methods. Our performance studies with large-scale graphs from real applications demonstrate that, when combined with communication-avoiding and thick-restarting techniques, the Lanczos method can be competitive with the power method, which is one of the most popular methods currently used for these applications. InIn addition, though we only focus on the truncated SVDs, the two computational kernels used in our studies, the sparse-matrix dense-matrix multiply and tall-skinny QR factorization, are fundamental building blocks for computing low-rank approximations with other objectives. Hence, our studies may have a greater impact beyond the truncated SVDs.",https://ieeexplore.ieee.org/document/7004374/,2014 IEEE International Conference on Big Data (Big Data),27-30 Oct. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IISA.2018.8633586,Adding Value to Sensor Data of Civil Engineering Structures: Automatic Outlier Detection,IEEE,Conferences,"This paper discusses the problem of outlier detection in datasets generated by sensors installed in large civil engineering structures. Since outlier detection can be implemented after the acquisition process, it is fully independent of particular acquisition processes as well as sit scales to new or updated sensors. It shows a method of using machine learning techniques to implement an automatic outlier detection procedure, demonstrating and evaluating the results in a real environment, following the Design Science Research Methodology. The proposed approach makes use of Manual Acquisition System measurements and combine them with a clustering algorithm (DBSCAN) and baseline methods (Multiple Linear Regression and thresholds based on standard deviation) to create a method that is able to identify and remove most of the outliers in the datasets used for demonstration and evaluation. This automatic procedure improves data quality having a direct impact on the decision processes with regard to structural safety.",https://ieeexplore.ieee.org/document/8633586/,"2018 9th International Conference on Information, Intelligence, Systems and Applications (IISA)",23-25 July 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IGARSS.2011.6048931,Aggregation of parallel computing and hardware/software co-design techniques for high-performance remote sensing applications,IEEE,Conferences,"Developing computationally efficient processing techniques for massive volumes of hyperspectral data is critical for space-based Earth science and planetary exploration. In particular, many remote sensing imaging applications require a response in real time in areas such as environmental modeling and assessment, target detection for military and homeland defense/security purposes, and risk prevention and response. This paper propose the aggregation of parallel computing and HW/SW co-design techniques using processor arrays (PAs) units as specialized hardware architectures for the real time enhancement of remote sensing imagery. An extended descriptive experiment design regularization (DEDR) method that incorporates projections onto convex solution sets (POCS) for spatial spectrum pattern (SSP) reconstruction is used to be efficiently implemented (i.e., HW-level) via the new proposition of the aggregation techniques. Finally, it is reported and discussed the Xilinx Virtex-5 FPGA implementation and high-performance issues related to real time enhancement of large-scale real-world RS imagery.",https://ieeexplore.ieee.org/document/6048931/,2011 IEEE International Geoscience and Remote Sensing Symposium,24-29 July 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDABI53623.2021.9655815,An Application on Ensemble Learning Using KNIME,IEEE,Conferences,"Machine learning is the science of computers behaving and learning like humans with the knowledge and data of people&#x2019;s observations, without being directly programmed. In fact, machine learning is inspired by the learning processes of humans. Among machine learning methods, Bayes&#x2019; theorem is an important subject studied in probability theory.Naive Bayes classifier is based on Bayes theorem. The way the algorithm works is that it calculates the probability of each state for an element and classifies it according to its highest probability value. Decision tree is a method based on classification by decomposing the data set according to common features. It consists of &#x201C;branches&#x201D;, &#x201C;leaves&#x201D; and &#x201C;roots&#x201D;, just like real-world trees. In decision trees, the superstructure is the root and the substructure is the leaves. It creates a structure that allows the branches to decide between the root and the leaf. Ensemble learning algorithms improve classification performance by combining many machine learning methods. In this study, decision trees from data mining techniques and naive bayes technique were applied on 215 data set &#x201C;Academic and Employability Factors Affecting Placement&#x201D;. As a result of this study, the decision tree accuracy rate is 91,892, the naive bayes accuracy rate is 94,595 and the ensemble learning result is 97,297. Thus, a better result is obtained than the result of both algorithms used. The program is implemented on &#x201C;Knime&#x201D; program called as &#x201C;end-to-end data science&#x201D;.",https://ieeexplore.ieee.org/document/9655815/,2021 International Conference on Data Analytics for Business and Industry (ICDABI),25-26 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/INCOS.2009.51,An Architecture for Adaptive Collaboration Support Guided by Learning Design,IEEE,Conferences,"A CSCL environment provides support to manage collaborative tasks. However, these systems do not usually provide the personalization features required to adapt the learning experience to the student needs, a drawback that can affect the collaboration objective and ultimately a successful learning. To alleviate this disadvantage we propose an architecture that provides adaptive collaboration support for a CSCL environment framed in an open and standards-based LMS. Our proposal combines adaptation rules defined in IMS Learning Design specification and dynamic support through recommendations via an accessible and adaptive guidance system. The implementation offers CSCL courses following a methodology called Collaborative Logical Framework. This system has been tested on a real world scenario at the Madrid Science Week 2009.",https://ieeexplore.ieee.org/document/5369352/,2009 International Conference on Intelligent Networking and Collaborative Systems,4-6 Nov. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00111,An Assessment of the Usability of Machine Learning Based Tools for the Security Operations Center,IEEE,Conferences,"Gartner, a large research and advisory company, anticipates that by 2024 80% of security operation centers (SOCs) will use machine learning (ML) based solutions to enhance their operations.11https://www.ciodive.com/news/how-data-science-tools-can-lighten-the-load-for-cybersecurity-teams/572209/ In light of such widespread adoption, it is vital for the research community to identify and address usability concerns. This work presents the results of the first in situ usability assessment of ML-based tools. With the support of the US Navy, we leveraged the national cyber range-a large, air-gapped cyber testbed equipped with state-of-the-art network and user emulation capabilities-to study six US Naval SOC analysts' usage of two tools. Our analysis identified several serious usability issues, including multiple violations of established usability heuristics for user interface design. We also discovered that analysts lacked a clear mental model of how these tools generate scores, resulting in mistrust a and/or misuse of the tools themselves. Surprisingly, we found no correlation between analysts' level of education or years of experience and their performance with either tool, suggesting that other factors such as prior background knowledge or personality play a significant role in ML-based tool usage. Our findings demonstrate that ML-based security tool vendors must put a renewed focus on working with analysts, both experienced and inexperienced, to ensure that their systems are usable and useful in real-world security operations settings.",https://ieeexplore.ieee.org/document/9291520/,"2020 International Conferences on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics)",2-6 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW.2009.26,An Effective Network Partitioning Algorithm Based on Two-Point Diffusing Strategy,IEEE,Conferences,"The network modeling and analysis have played important roles in fields of physics, sociology, biology, and computer science. Recently, community structure has been considered as an important character for complex networks, and its detection can bring great benefit in real world affairs. In the paper, a new heuristic algorithm based on two-point diffusing strategy is proposed. At first, two pseudo-core points are identified according to the clue of the longest path in a network. Then, two embryonic communities and an undecided node set are generated through performing diffusing operation on such two points. Subsequently, an experience rule is used to classify the undecided nodes to form the final community structure. In addition, the effectiveness and efficiency are validated by comparison experiments with four real-world networks. The experiment results show that our TPD algorithm can yield better community partition results and shorter computing time than the existing classical community detecting algorithms.",https://ieeexplore.ieee.org/document/5360433/,2009 IEEE International Conference on Data Mining Workshops,6-6 Dec. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICACITE53722.2022.9823643,An Empirical Analysis of Python Programming for Advance Computing,IEEE,Conferences,"Python is an object-oriented, scripting, and interpretive programming language that may be used for mentoring and real-world applications. This paper focusses primarily on Python software packages used in data science, pattern recognition, and IoT. This paper will first explain Python as a language, then introduce Data Science, Machine learning, and IOT, describing prominent packages in the Data Science and Machine learning community, such as NumPy, SciPy, TensorFlow, Keras, Matplotlib. This paper will also demonstrate the significance of Python in the development of the industry. Throughout, we shall utilize many code samples. We review so many research papers to analyze the usage of python in different fields and easily import packages in the programming software.",https://ieeexplore.ieee.org/document/9823643/,2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),28-29 April 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2019.8935648,An Multi-client Web-based Interactive HCI for Interactive Supercomputing,IEEE,Conferences,"Importance of the real-time data analysis even in the HPC area rapidly increase in the recent data intensive science. Once the real-time data analysis becomes available, the interactive feedback to the data source will be happening to make thing improve. In order to realize such an environment for scientific simulation, the framework for interactive supercomputing has been developed so far. However, user interaction of that framework was limited to a certain closed environment. In this paper, web-based ubiquitous interface that allows simultaneous sharing of on-going simulation among multiple users is proposed.",https://ieeexplore.ieee.org/document/8935648/,"2019 20th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",8-11 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBAIE52039.2021.9389899,An Open-Source Programming Language-Based Interactive Device: Popular Science of the Five Cereals for Children,IEEE,Conferences,"In this paper, Arduino is used in combination with switch, lighting and sound facilities to realize human-computer interaction. Arduino is an open-source electronics platform that integrates hardware and software. Given its versatility, expressiveness and operability, designers and artists are free to turn their ideas into reality on this platform, using programming languages to create high-quality interactive installations. In response to children's difficulty telling the difference between the five cereals, this paper seeks to educate children on crops in the form of human-computer interaction through the design and manufacture of a popular science-themed interactive device. Through the external hardware configuration (pressure induction, lamp and sound), children are guided to knowing and grasping the growth stages of common plants. In this way, children's perceptions of nature and crops can be constructed through a combination of technology and art.",https://ieeexplore.ieee.org/document/9389899/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/OCEANS44145.2021.9705666,An Underwater Simulation Server Oriented to Cooperative Robotic Interventions: The Educational Approach,IEEE,Conferences,"Experiments that require the use of Supervised Autonomous Underwater Vehicles for Intervention (I-AUV) are not easy to be performed, specially when deployed in the sea or in scenarios where the robot might face lack of space and communication (e.g. interior of pipes). Also, there are some applications where the robots need to cooperate in a closed manner, for example when transporting and assembling big pipes. In fact, these two scenarios are being studied in the context of the H2020-ElPeacetolero and TWINBOT (TWIN roBOTs for cooperative underwater intervention mission) [1] projects, being necessary to have a simulation tool that offer more realistic rendering and being compatible with the real robot Application Programming Interface.This paper presents a new underwater simulation server, implemented using video game and robotic techniques, which operates by enabling the researchers control the robots in the scene in a simple and efficient manner, while using HTTP commands that have demonstrated a huge facility in the project integration process. Moreover, this simplicity has allowed the application of the simulation server in the educational context. The use of this tool has resulted to be very adequate for the students, who have used it to learn computer science and artificial intelligence algorithms to solve problems like a cooperative transportation robotic task. As case study, four educational experiments are presented, performed by master’s degree students, focusing on user interfaces, image compression for underwater channels, autonomous cooperative grasping and robot arm movement in a AUV.",https://ieeexplore.ieee.org/document/9705666/,OCEANS 2021: San Diego – Porto,20-23 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBDACI.2017.8070822,An approach towards data visualization based on AR principles,IEEE,Conferences,"In today's era, the computer science and technology has evolved upto a great extent. Augmented Reality (AR) is a technology evolved from artificial intelligence and also follows the principle of pervasive computing. AR can be achieved by encapsulating algorithms and snippets into smart devices such as laptops, android phones and other smart devices. The digitization of data can be done in a very aesthetic way by this new technology. AR and big data share a logical and mature relationship that inevitably converges them. The paper describes the advantages of merging AR and big data to invent new interesting applications is starting to have a tangible presence. The main aim is to uncover the problems and ease the issues in visualization of Big Data and at the same time the objective of finding valid solutions for the problems in Big Data Visualization remains. The sections mentioned below elaborates the present tools, techniques and platforms which can be used for Visualization in Big Data. We reveal disadvantages of currently existing visualization methods based on the results. Based on the results, a not so common approach is proposed: the capabilities and methods of virtual and augmented reality could be implemented to achieve Visualization of the big data. We also discuss about the applications of AR and big data and fields where it is used. Further in later sections we discuss about the user interface with presence of tangibility, advantages and disadvantages of trending technologies, such as VR and AR displays on the Big Data visualization.",https://ieeexplore.ieee.org/document/8070822/,2017 International Conference on Big Data Analytics and Computational Intelligence (ICBDAC),23-25 March 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/VSMM.2012.6365917,An ecosystem of tools and methods for archeological research,IEEE,Conferences,"The present paper describes the design strategies of an ecosystem of tools and services, currently under construction, developed in cooperation among archaeologists and computer science experts of the Università degli Studi di Milano and architects and topographers of the Politecnico di Milano. This ecosystem is based on the archaeological experience carried out in Tarquinia since 1982 in the frame of the “Tarquinia Project”. The project takes into account the analysis and processing of multifaceted archaeological evidences in a context-oriented environment, in which interdisciplinary contributions of several scientist are combined and integrated, in order to grasp the original system of interaction of different branches of the ancient reality. Such a cooperation needs a system of ""query/communication"" able to integrate archaeological data, artefacts and architectural structures (subsoil and over-ground), cartographic and photographic documentation and scientific contents, achieved in the past and implemented during the field research. The proposed ecosystem aims to provide a set of services for federating different existing data-sources (GIS, including 3D tools), through the definition of a semantic network of relationships among landscapes, stratigraphic layers, structures and artefacts of an excavation site (ArchMatrix). This ecosystem is based on an innovative global design method, focused on the management of raw-data captured and analyzed by different experts in a collaborative way. The aim is to develop a solution able to support analyses and studies grounded in the real needs of the archaeological investigation, by enabling archaeologists in producing archaeological and historical interpretations starting from the real core of the documentation they deal with. In such a framework, the present paper focuses on a novel approach to identify the object of the archaeological research, starting from the needs of field archaeology, and on the design of a system meant to solve problems according to an integrated approach in a unique context of analysis.",https://ieeexplore.ieee.org/document/6365917/,2012 18th International Conference on Virtual Systems and Multimedia,2-5 Sept. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE51474.2020.00073,Analysis of 3D Image Reconstruction System Based on Virtual Reality Technology,IEEE,Conferences,"With the continuous development of science and technology, two-dimensional image technology can no longer meet people's needs, so three-dimensional image reconstruction technology has been studied by people. Three-dimensional image reconstruction has been applied in many fields. For example: medical, military, detection, etc. This article mainly introduces the research of 3D geological simulation system based on virtual reality technology and virtual reality technology.",https://ieeexplore.ieee.org/document/9403827/,2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),30 Oct.-1 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IMITEC50163.2020.9334099,Application of Bellman's Equation in Ant-Like Robotic Device Path Decisions,IEEE,Conferences,"Swarm Intelligence is about emergency of collective intelligence from groups of homogeneous robotic devices deployed for a purpose. Ant Colony Systems, in particular, are inspiring. They commonly have drawn inspiration from the behaviors of real ants in nature in order to construct routes between the food sources and the nest. There are still gaps in alternative options for path decision in ant agents. Bellman's equation has been successfully used to solve path decision problems in machine learning. We proposed to investigate impact of a Bellman's equation inspired algorithm for path decision on stigmergic ant agent robotic devices. A design science research paradigm was used to design our research experiment in which a simulated environment was designed to simulate the behavior of ant agents when using a Bellman's equation inspired algorithm for path decision. We introduced a reward function to the orientation process of ant agents. Reward function rewards a decision made when an ant moves from one point to an adjacent cell. The Bellman's inspired algorithm for ant orientation led to convergence of ant agents even though there was reduced quality of convergence. Evaluation of results show that Bellman's equation can be used in path decision processes for ant agent robotic devices. Our results contributed to adding an alternative way of implementing path decision for ant agents. This will help in growing the knowledge around ant agents and finding better ways to implementing path decisions for ant agents.",https://ieeexplore.ieee.org/document/9334099/,2020 2nd International Multidisciplinary Information Technology and Engineering Conference (IMITEC),25-27 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/USSEC53120.2021.9655754,Application of Long Short-Term Memory for Energy Load Prediction in the Microgrid Using Python Software,IEEE,Conferences,"The development of distributed power supply systems, microgrids is recognized as relevant and requires intensive study. Research on microgrid management systems is inextricably linked with data science. The paper presents a study of the use of software for predicting the load consumed by a typical microgrid over a monthly interval. The formulation of the problem of forecasting time series, applied to classical stationary series, is described. The process of data processing using the open-source machine software libraries NumPy, Keras is presented. A class is developed in the Python environment based on the use of recurrent neural networks-long short-term memory, the applicability for the task is shown. The model was trained using iterative optimization of the series value, and the data sampling window. The satisfactory accuracy of forecasting based on the developed model is shown. The conclusions for further study of the applicability of this algorithm in the practice of managing distributed power supply systems are presented.",https://ieeexplore.ieee.org/document/9655754/,2021 Ural-Siberian Smart Energy Conference (USSEC),13-15 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSME.2019.00057,Application of Philosophical Principles in Linux Kernel Customization,IEEE,Conferences,"Philosophical principles are very useful in customization of Linux kernel, e.g., the answer for the question: ""For the pointer to the start address of page table, is it a physical address or a virtual address?"" can be derived by one simple philosophical principle: the depth of recursion is limited. This is because if the pointer were a virtual address, there would be another new page table to store the translation information of this virtual address, but who was responsible for storing the translation information of the start address of this new page table? This would result an infinite recursion. So the pointer definitely is a physical address. In fact, the usefulness of philosophical principles comes from the reduction of searching space. And this reduction is very important in customization of Linux kernel, for it could cut down the size of the new code needed to be read. This is especially valuable when considering that Linux kernel is continuously updating and huge now. Another example to further demonstrate the reduction of searching space in customization is showed in the following: in customization of file system in kernel version 3.10, the question: ""Does the Linux kernel itself maintain the consistency between the buffer cache and the page cache?"". This is a hard problem in practice, for without any guidance of philosophical principle, a developer has to read all of the code in Linux kernel to get a precise answer. The tricky part of this question is that if the developer only read a part of the codes and doesn't find any mechanisms for maintenance of cache consistency, the conclusion of non-existence of such mechanisms still can not be drawn, for there's still a possibility that such mechanisms exist in the codes not explored. Besides, if the developer search internet to find the answer, assume that the developer is lucky enough, he/she finally finds one program example on a web page shows that the inconsistency may raise between buffer cache and page cache. He/she still can not get the conclusion that Linux kernel does not maintain such consistency, because that program example maybe is only valid in a specific scenario, e.g. in kernel version 2.26, not 3.10. But we can get a satisfied answer by using the philosophical principle: the cost of management process should be far less than the value created by being managed process. By this principle, it can be drawn that Linux kernel doesn't maintain the consistency between the buffer cache and page cache in kernel 3.10. This is because that the data in buffer cache and page cache is highly dependent on application logic, so if Linux kernel wanted to maintain such consistency, it would have to track all these applications, which cost was much higher than the benefits that these applications could produce. However, the successful application of philosophical principles depends on two factors: firstly, establishment of a mapping between concepts in Linux system and well-known concepts in human society. This is not a new idea, e.g. the word of ""cost"" is a concept first appeared in human society, not in computer science, but nowadays, developers establish a mapping between this concept and concepts in computer science. Although the idea is very old, it is still very effective. Since well-known concepts in human society are familiar to most developers and are what they have in common, the cost of applying philosophical principles is reduced. Besides this, already existing cause-effect relations among concepts in human society can be highly possible to be reused in philosophical deduction in Linux kernel. E.g, in the mapping we established, process is treated as a human and since in religion of human society, God creates humankind, it is natural to derive that there's one process that creates all other processes in Linux system with high probability. Secondly, a concrete model with many qualitative and quantitative details should be the basis of philosophical deduction. We build such model according to our past experiences and the construction of the model follows the philosophical principle: unfold the complexity only when it is necessary. E.g., in this model, for a specific detail, it is covered only when it is required in practice. This is to lower down the cost of modelling huge and continuously evolving Linux kernel. This model is very important, without it, philosophical deduction is impossible. But it is really a hard work, according to our experiences, it needs at least 6-years of work on Linux kernel for one developer to build it. Although philosophical principles are very useful in practice, there's a big gap on the recognition of philosophical principles between academic researchers and industry practioners. E.g., some academic researcher seriously doubts whether the mapping above, which mentioned God, is helpful. In fact, it is, for by this mapping, a developer will know that the existence of the process, which is the origin of all other processes, is highly possible and also that process maybe is not easily observed. This is true, for that process is the process which PID is zero and that process can not be observed by Linux command: ""ps -e"". That process is a very valuable point of customization, e.g., by modifying that process, all processes in the Linux will be affected. Why does this big gap exist? We believe there're at least three reasons: i. The bias on philosophical principles. This usually comes from the observation that some developers establish wrong mapping between the philosophical principles and the objects in real world. But is that true for those that has been verified many times in practice? ii. Wrong expectations. E.g., hope to get the precise answer when applying philosophical principles, instead of reducing the searching space. iii. Some academic researchers do not realize that a good philosophical principle usually is the result of a deep learning process of many years by human brain. Finally, we suggest that more efforts should be put on the studying of philosophical principles in program understanding and we believe that in the near future, the philosophical principles plus AI will be a trend in program understanding.",https://ieeexplore.ieee.org/document/8919057/,2019 IEEE International Conference on Software Maintenance and Evolution (ICSME),29 Sept.-4 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISAIAM53259.2021.00012,Application of children Artificial Intelligence science popularization books based on Augmented Reality technology,IEEE,Conferences,"Children’s books are enlightenment books for children’s education, and the educational significance of popular science books is even more important. With the development of global intelligent technology, parents pay more attention to children’s intelligent education, and books combined with science and technology become more popular. As one of the important tools in the process of children’s growth, books play an important role in children’s early education. However, most of the popular science books are still natural universe, animal world, military education and other subjects. Today, with the development of intelligent technology, it has become an inevitable thing to carry out artificial intelligence science popularization for children. Therefore, this article uses multimedia technology, uses Kudan SDK to develop AR applications in Unity, explores the application of AR technology in popular science books, and uses artificial intelligence as the theme for creation. It mainly includes the cognitive analysis of artificial intelligence, ar software system design and the design exploration of AR and books for 7-11 year olds, so that children can understand and learn the relevant knowledge of AI in the technical environment.",https://ieeexplore.ieee.org/document/9516578/,2021 International Symposium on Artificial Intelligence and its Application on Media (ISAIAM),21-23 May 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RTSE.1998.766515,Application of mobile autonomous robots to artificial intelligence and information systems curricula,IEEE,Conferences,"Applies pedagogical ideas of teaching curricula by using strategies of themes and breadth-first coverage, together with the technology of intelligent agents (e.g. mobile autonomous robots), to a system of courses in computer science (artificial intelligence) and information systems (systems engineering). The project brings the issues and constraints of real-time systems, especially the programming component, to students in computer science and information systems curricula. This project's background started in June 1997 and continued during the first part of the 1997-1998 academic year. The actual project work started in January 1998 and is still continuing.",https://ieeexplore.ieee.org/document/766515/,Proceedings Real-Time Systems Education III,21-21 Nov. 1998,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICE.2018.8436264,Applying Entrepreneurial Teaching Methods to Advanced Technical STEM Courses,IEEE,Conferences,"A vast majority of Science, Technology, Engineering, Mathematics (STEM) courses and pedagogical frameworks concentrate on teaching the fundamental concepts and theoretical underpinnings of the tools related to the subject. While this aspect is important, we recognize that the teaching methods in a majority of the STEM courses today are broken; there is a major discrepancy between the skills and mindsets in technical classes and the ones that are useful to solve actual problems in “the real world”. Therefore, we suggest a new teaching framework called Data-X where entrepreneurial teaching methods developed in the Berkeley Method of Entrepreneurship are applied to advanced technical topics. Through inductive learning and by practicing story creation, stakeholder generation, adaptation, ideation, innovation processes, and by having a diverse mix of students being coached by a network of expert advisors, this highly applied teaching method empowers students to pursue and find solutions to open-ended projects and problems. The Data-X framework has been implemented and tested for three semesters in a UC Berkeley course called Applied Data Science for Venture Applications. In the class the students pick up, become comfortable, and utilize state-of-the-art tools in Data Science, Machine Learning, and Artificial Intelligence. The results, feedback, and testimonials we have received upon offering the class have been overwhelmingly positive, and we propose that the ideas and concepts behind Data-X can help fix many problems in modern STEM education.",https://ieeexplore.ieee.org/document/8436264/,"2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)",17-20 June 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EDUCON.2014.6826199,Applying learning analytics to simplify serious games deployment in the classroom,IEEE,Conferences,"In this paper we present our approach to introduce educational videogames as class exercises in face-to-face education. The main objective is to simplify teachers' task when using games by providing real-time information of the actual students' use of the games while in the classroom. The approach is based on defining the educational goals for the exercise/game precisely, designing a game that captures these goals, establishing relations between game interactions and educational goals and finally, create data capturing and visualizations of the relevant information to support the teacher. We applied this approach to a real case study, creating an educational videogame about the XML markup language that substituted the usual exercises in a Web Technologies class. This was tested with 34 computer science students with positive and promising results.",https://ieeexplore.ieee.org/document/6826199/,2014 IEEE Global Engineering Education Conference (EDUCON),3-5 April 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCCS.2018.8586801,Approving Psycho-Neuro-Computer Systems to prevent (Systemic Vs Individualistic Perspective) Cybercrimes in Information Highway,IEEE,Conferences,"In this paper the authors described the importance of Schizophrenia in Medical Systems versus Computer Systems. Dissimilar Schizophrenias were identified. The schizophrenia is thoughtful, consequently it could be discovered in future. But there is no Intelligence Quotient (IQ). The author contrasting this perception with present research work i.e., Cybercrimes in Higher Educations. This encouraging Psycho-Neuro-Computer Systems are very essential things to control and prevent the Cybercrimes in Cyber space. On each successive day the thoughts, feelings, behavior of humans are going in destructive manner. Especially in internet by using this Communication Technologies and facilities the Cybercrimes are ever-increasing very quickly. The Online Networking Systems are anguish, the people who have Schizophrenia is a serious psychological disorder in which people understand reality abnormally. Schizophrenia may result in some combination of illusions and tremendously disordered thinking and behavior that damages daily functioning, and can be disabling. The author developing positive psychology between the higher education students and faculties to reduce the Online Cybercrimes. In our research Cognitive Systems are showing main role which is interrelated with computer science and psychology. It provides us with a systematic foundation in the principles, ethics, morals, values and techniques used by intelligent systems (both natural and artificial) to interact with the web world. My research required Emotional Intelligence (or) Knowledge (or) Emotional Quotient (EQ) use emotions to enhance positive thoughts. People with high emotions can control, evaluate towards negative thoughts and perceive others emotions and thoughts, uniform estimation calculated of cleverness.",https://ieeexplore.ieee.org/document/8586801/,"2018 IEEE 3rd International Conference on Computing, Communication and Security (ICCCS)",25-27 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCSA50381.2020.00019,Architecture Design of a Smart Farm System Based on Big Data Appliance Machine Learning,IEEE,Conferences,"The size of the world's population increased at a Revolution. The modern expansion of human numbers started but environmental degradation with lack of urban services. To satisfy the growing of human food, worldwide demand for grain the area under production should be increased, and productivity must be improved on yields area firstly. To evaluate the Smart Farming sub-use cases' overall outcome, each economic and environmental benefits, social aspects, and the technical evolution path were evaluated. We have like an significant improvement in the economic outcome of the farm. This paper proposed an implementation of BMS (Big Data Application Machine Learning-based Smart Farm System) with an emphasis on crop productivity and the importance of farmers' income increase. Increasing crop productivity is also important to increase essentials' income, enhance farmer field-level insights, and actionable knowledge to produce when the crop is of the best quality or selling it with a good price. Therefore, in the Smart Farm system proposed in this paper specially in case of big data science, we need to consider data analysis and machine learning as the most important steps and then we can include the value of big data science. Machine learning is an essential ability to learn from data and provide data-driven information, decisions, and forecasts. Traditional approaches to machine learning were developed in a different era, like the data set that fully integrates memory. In addition to the characteristics of Big Data, they create obstacles to traditional techniques. One of the objectives of this document is to summarize the challenges of machine learning with Big Data.",https://ieeexplore.ieee.org/document/9257527/,2020 20th International Conference on Computational Science and Its Applications (ICCSA),1-4 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/CISTI49556.2020.9141124,Artificial Intelligence Applied to Software Testing: A Literature Review,IEEE,Conferences,"In the last few years Artificial Intelligence (AI) algorithms and Machine Learning (ML) approaches have been successfully applied in real-world scenarios like commerce, industry and digital services, but they are not a widespread reality in Software Testing. Due to the complexity of software testing, most of the work of AI/ML applied to it is still academic. This paper briefly presents the state of the art in the field of software testing, applying ML approaches and AI algorithms. The progress analysis of the AI and ML methods used for this purpose during the last three years is based on the Scopus Elsevier, web of Science and Google Scholar databases. Algorithms used in software testing have been grouped by test types. The paper also tries to create relations between the main AI approaches and which type of tests they are applied to, in particular white-box, grey-box and black-box software testing types. We conclude that black-box testing is, by far, the preferred method of software testing, when AI is applied, and all three methods of ML (supervised, unsupervised and reinforcement) are commonly used in black-box testing being the “clustering” technique, Artificial Neural Networks and Genetic Algorithms applied to “fuzzing” and regression testing.",https://ieeexplore.ieee.org/document/9141124/,2020 15th Iberian Conference on Information Systems and Technologies (CISTI),24-27 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GCAT52182.2021.9587507,Artificial Intelligence Based Predictive Threat Hunting In The Field of Cyber Security,IEEE,Conferences,"Artificial intelligence (AI) is a broad field of computer science that focuses on designing smart machines capable of performing tasks typically requiring human intelligence. Despite the fact that security solutions are growing progressively modern and stable, cyberattacks are still evolving and are at their extreme. The main reason is that conventional methods of malware detection fail. Cyber attackers are actively developing new ways to prevent defence programmes from infecting malware networks and servers. Most anti-malware and antivirus applications currently use signature-based detection to identify attacks, which is unsuccessful in detecting new threats. This is where Artificial Intelligence is most handy. The standardised models for threatened hunting and performance quantification from the start of hazard hunting to the end still allow methodological rigour and completeness to be studied remain undefined. The organised practise of hazard hunts seeks to disclose the presence of TTP in the field of detection that has not already been detected. In this study, a realistic and comprehensive model is outlined to detect attackers in six stages: aim, scale, equipment, planning, execution and input. This study describes Threat Hunting in an ecosystem as the constructive, analyst-driven scanning mechanism for attackers TTP. The model has been checked for real-world data sets using a variety of threats. The effectiveness and practicality of this research have been shown with and without a blueprint through danger hunts. In addition, the article presents an analysis of the concept of threat hunting based on data from Ukrainian electricity grid attacks in an online environment to highlight the effects of this model on threat hunting in a simulated environment. The findings of this analysis include an effective and repetitive way to search for and quantify honesty, coverage and rigour.",https://ieeexplore.ieee.org/document/9587507/,2021 2nd Global Conference for Advancement in Technology (GCAT),1-3 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IVS.2018.8500457,Artificial Intelligence Course Design: iSTREAM-based Visual Cognitive Smart Vehicles,IEEE,Conferences,"New intelligent era calls for new learners and thus urgently needs a series of artificial intelligence. As a good educational platform for teaching artificial intelligence, smart cars have aroused concern and practices of all parties. However, at present, most courses and training pay more attention to basic knowledge and technology of smart cars, seldom to training based on artificial intelligence curriculum system and comprehensive competency integrating science, technology, art and management. Therefore, based on concept of iSTREAM (intelligence for Science, Technology, Robotics, Engineering, Art, and Management) and Raspberry intelligent vehicle teaching platform, this paper introduced a smart car-themed artificial intelligence courses including basic courses, specialized courses, specialized technical courses and elective courses. This course can guide learners to develop smart cars based on visual cognition, in-depth learning, VR and 3D printing integrated artistic creativity. It combines disciplines such as science, technology, art, games and management to upgrade a single knowledge and technology course into a comprehensive competency course that integrates knowledge, skills, emotion and management. Practice in Beijing NO.13 and NO.101 High School shows that this course allows students to experience scientific research process, learn artificial intelligence related knowledge and skills, understand scientific way of thinking and scientific research methods, stimulate learners' responsibility and scientific passion, and cultivate leadership skills through self-learning and partly project management.",https://ieeexplore.ieee.org/document/8500457/,2018 IEEE Intelligent Vehicles Symposium (IV),26-30 June 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EHB52898.2021.9657707,Artificial Intelligence Expert System Based on Continuous Glucose Monitoring (CGM) Data for Auto-Adaptive Adjustment Therapy Protocol – How to Make Sensors and Patients to Think Forward and Work Together?,IEEE,Conferences,"Worldwide adoption of continuous glucose monitoring (CGM) portable miniature sensors in routine clinical practice is increasing for type 1 diabetes treatment in children. The commonly used sensors provide the blood glucose concentration and its change rate in real time (samples every 5 minutes or even 1 minute). Due to these sensors we are in position to collect a significant amount of data from various patients. To better process the data, artificial intelligence (AI) techniques are used to personalize the patient's recommendation and to create decision support expert system with self-adjustment. The focus of this paper is the system’s architecture and use case scenarios of a research project aimed to develop an Artificial Intelligence expert system based on continuous glucose monitoring (CGM) data. The project is developed by a mixed team composed by medical doctors in France and computer science specialists in Romania. By regularly analyze and interpret the CGM data, the decision support expert system will generate detailed reports for doctor and patient use and real-time alerts. One of the key components is the implementation of an auto-adaptive adjustment therapy protocol for type 1 diabetes treatment in children.",https://ieeexplore.ieee.org/document/9657707/,2021 International Conference on e-Health and Bioengineering (EHB),18-19 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICACITE51222.2021.9404749,Artificial Intelligence and Robotics: Impact & Open issues of automation in Workplace,IEEE,Conferences,"In engineering province robotics is one of the cognitive perspective to human communication or it concern with synod of perception of action. In Today's Tech World Artificial Intelligence is an essential tool which provides effective analytical business solutions & plays significant role in the domain of robotics and have several similarities like human behavior which may drive the real world. This paper shows the significant blend of Artificial Intelligence and robotics which transform entire industries, technological improvement of robotics application & utilization. It also focuses on different aspects of targets like marketing, home appliances, medical science, Smart agriculture and many more which includes open issues and technological challenges arises by this combination and conclude that robotics with AI can work in real world with real objects. Further AI based robotics are very important area in economics and organizational consequence, implementation of automation in any organizational design give impact on overall economy and infrastructure provide a wider direction for further research on Robotics and IoT are two terms each covering a myriad of technologies and concepts.",https://ieeexplore.ieee.org/document/9404749/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/I-SMAC.2018.8653700,Artificial Neural Network for Prediction of Breast Cancer,IEEE,Conferences,"Technologies play a vital role in cancer care. Data mining approach has helped a lot in medical science due to its high efficiency in the prediction of the future health condition, and also helps in reduction of medical cost and improving the health of people and quality in real time which helps in saving lives' of people. Breast Tissue is the reason due to which breast cancer develops. It takes the second place for the most cancer diagnoses in the women after skin cancer. There are humungous data and information which gives an opportunity for analysing and understanding the process and make some researches using machine learning techniques. The main part of this paper is to create a tool for early prediction of breast cancer with the highest accuracy possible and low error rate. This was done by applying machine learning algorithms and with help of Artificial Neural Network (ANN) using Wisconsin Breast Cancer (Diagnostic) Dataset. Experimental results show that ANN gives the accuracy up to 98% with low error rate. The Experiment is conducted using Dev.-C++ software and implemented using C-language.",https://ieeexplore.ieee.org/document/8653700/,"2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), 2018 2nd International Conference on",30-31 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TENCON.2018.8650180,Automata Generating Mobile Application (A.G.M.A),IEEE,Conferences,"Finite state machine is a model of computation based on a theoretical machine, made of one or more states. Computing Science students and practitioners use it to model real world objects and simulate problems in several disciplines such as mathematics, artificial intelligence, games or linguistics. Based on the assessment made by the proponents, little percentage of the students who took the course were able to retain knowledge on its theoretical foundation, while none on the application side. It was further supported by some literature that some computing students find difficulties in learning this course. The main reason is the knowledge retention because they cannot remember their previous lessons. This research can be a useful contribution in designing a better e-learning application particularly for the Computing Science students. Given the right feature, the mobile application can benefit both the educational institution, students and faculty members. In view of this study, it is highly recommended to pursue the development of the application, implement it and conduct a pre- and post-test assessment on the knowledge retention of students who will utilize this system. Provide a wider population and test other parameters to determine what really affects the student's knowledge retention.",https://ieeexplore.ieee.org/document/8650180/,TENCON 2018 - 2018 IEEE Region 10 Conference,28-31 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EDOCW49879.2020.00022,Automatic Generation of Conceptual Enterprise Models,IEEE,Conferences,"The world organizations operate in is becoming increasingly complex and uncertain, due to technical disruptions, changes in operational environments and social structures, global markets, or, as recently seen, through global diseases. Those changes require the development of smart technological and human systems, based on Conceptual Enterprise Models. Through the increasing complexity, modeling is difficult for human actors and therefore requiring machine-support, for example through Artificial Intelligence approaches, leading to Hybrid Intelligence systems and automated generation of Conceptual Models. While various approaches for the automated generation of Conceptual Enterprise Models exist, for example in requirements engineering, process mining or in the context of Digital Twins, the approaches mostly support only parts of the modeling process. Additionaly, the approaches lack a common base, such as standardized frameworks. Therefore, my further research aims at showing how conceptual modeling can be automated, developing a modeling standard for Digital Twins in enterprise context, showing its technical feasibility and evaluating the implementation in real-world use cases. The research is performed through design science research, systematic literature research, argumentative-deductive reasoning, prototyping and use cases. At this stage, a first literature review is completed, and the next research steps are in preparation.",https://ieeexplore.ieee.org/document/9233131/,2020 IEEE 24th International Enterprise Distributed Object Computing Workshop (EDOCW),5-5 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FIE.2006.322654,Autonomous Robots as a Generic Teaching Tool,IEEE,Conferences,"An undergraduate bioengineering laboratory course using small autonomous robots has been developed to demonstrate control theory, learning, and behavior. The lab consists of several modules that demonstrate concepts in classical control theory, fuzzy logic, neural network control, and genetic algorithms. The autonomous agents are easy-to-build, inexpensive kit robots. Each robot functions independently in a real-world environment. Students program and retrieve data wirelessly using handheld computers. The hands-on nature of the lab modules engages students in ways that lectures, readings and software simulations cannot. By interacting with these robots, students directly experience the effects of unexpected environmental factors on designs and deviations from software simulations. The robots are easily adapted for use in many different aspects of two-year college and K-12 STEM education. Students are motivated to understand engineering, math and science principles in order to control the robots. Examples of use of the robots and modules by a local community college are presented",https://ieeexplore.ieee.org/document/4117154/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCICC53683.2021.9811311,Autonomous Software Requirement Specifications towards AI Programming,IEEE,Conferences,"Autonomous software requirement specifications and code generation are not only an ultimate goal of AI Programming (AIP), but also a persistent challenge to theories and technologies of software engineering. A cognitive system is demanded to autonomously elicit and rigorously refine software requirements in order to generate a set of formal specifications as the front-end of AIP. This paper presents a novel methodology for the design of an Intelligent Tool for Autonomous Software Specifications (ITASS) based on latest advances in software science and intelligent mathematics. ITASS is implemented as an interactive system for capturing software requirements and generating mathematic-based specifications for code generation in the back-end of the AIP system. The ITASS methodology and experiments are demonstrated for solving real-world and complex software engineering problems enabled by the AIP theories underpinned by intelligent mathematics.",https://ieeexplore.ieee.org/document/9811311/,2021 IEEE 20th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),29-31 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1049/cp.2012.1047,Autority aware expert search: Algorithm and system for NSFC,IET,Conferences,"This paper describes the peer reviewer finding algorithm used in an aided system to assist the proposal reviewing task in the National Science Foundation of China (NSFC)[1]. We propose a new probabilistic language model in which expert authority is taken into consideration, by introducing a prior probability of candidate into the model. Application codes representing research areas are defined by NSFC and are available for both experts and proposals. We integrate code information into our model as we add a code probability term into the model, thus promote rankings of experts with matched code. All proposals submitted to NSFC are written in Chinese, and since Chinese word segmentation is non-trivial task whose accuracy affects the final results heavily, we try to improve segment accuracy by adding domain-specific terms to a user-editable dictionary. Terminologies are extracted from certain field of bibliography data in NSFC system. Experiments show that our algorithm is effective in real world system like NSFC.",https://ieeexplore.ieee.org/document/6492654/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DSAA.2019.00070,"Bighead: A Framework-Agnostic, End-to-End Machine Learning Platform",IEEE,Conferences,"With the increasing need to build systems and products powered by machine learning inside organizations, it is critical to have a platform that provides machine learning practitioners with a unified environment to easily prototype, deploy, and maintain their models at scale. However, due to the diversity of machine learning libraries, the inconsistency between environments, and various scalability requirement, there is no existing work to date that addresses all of these challenges. Here, we introduce Bighead, a framework-agnostic, end-to-end platform for machine learning. It offers a seamless user experience requiring only minimal efforts that span feature set management, prototyping, training, batch (offline) inference, real-time (online) inference, evaluation, and model lifecycle management. In contrast to existing platforms, it is designed to be highly versatile and extensible, and supports all major machine learning frameworks, rather than focusing on one particular framework. It ensures consistency across different environments and stages of the model lifecycle, as well as across data sources and transformations. It scales horizontally and elastically in response to the workload such as dataset size and throughput. Its components include a feature management framework, a model development toolkit, a lifecycle management service with UI, an offline training and inference engine, an online inference service, an interactive prototyping environment, and a Docker image customization tool. It is the first platform to offer a feature management component that is a general-purpose aggregation framework with lambda architecture and temporal joins. Bighead is deployed and widely adopted at Airbnb, and has enabled the data science and engineering teams to develop and deploy machine learning models in a timely and reliable manner. Bighead has shortened the time to deploy a new model from months to days, ensured the stability of the models in production, facilitated adoption of cutting-edge models, and enabled advanced machine learning based product features of the Airbnb platform. We present two use cases of productionizing models of computer vision and natural language processing.",https://ieeexplore.ieee.org/document/8964147/,2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA),5-8 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACOMP.2019.00011,Blueprinting the Workflow of Medical Diagnosis through the Lens of Machine Learning Perspective,IEEE,Conferences,"The association of machine learning into medical data and healthcare communities embraces substantial improvement in both health care and machine learning itself. Many companies are racing to integrate machine learning into medical diagnosis process that boosts the automatic medical decision, reducing the inferior effects of data overload and increasing the accurate prediction and time effectiveness. It is one of today's most rapidly growing technical fields, lying at the intersection between health care and computer science in general. Thus, there is an urgent need to optimize medical processes, guidelines and workflows to increase the workload capacity while reducing costs and improving efficiencies. Moreover, no medical doctor or experts can manually keep pace today due to increasingly large and complex datasets. In this paper, the authors aim at addressing the mentioned issue by proposing a workflow of medical diagnosis through the lens of the machine learning perspective. An intensive comparison has been conducted applying 5 well-known machine learning algorithms on 8 real-world categorized datasets. A mobile application has been also deployed to enhance the incorporation from hospital experts.",https://ieeexplore.ieee.org/document/9044271/,2019 International Conference on Advanced Computing and Applications (ACOMP),26-28 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2016.7840859,Building a research data science platform from industrial machines,IEEE,Conferences,"Data Science research has a long history in academia which spans from large-scale data management, to data mining and data analysis using technologies from database management systems (DBMS's). While traditional HPC offers tools on leveraging existing technologies with data processing needs, the large volume of data and the speed of data generation pose significant challenges. Using the Hadoop platform and tools built on top of it drew immense interest from academia after it gained success in industry. Georgia Institute of Technology received a donation of 200 compute nodes from Yahoo. Turning these industrial machines into a research Data Science Platform (DSP) poses unique challenges, such as: nontrivial hardware design decisions, configuration tool choices, node integration into existing HPC infrastructure, partitioning resource to meet different application needs, software stack choices, etc. We have 40 nodes up and running, 24 running as a Hadoop and Spark cluster, 12 running as a HBase and OpenTSDB cluster, the others running as service nodes. We successfully tested it against Spark Machine Learning algorithms using a 88GB image dataset, Spark DataFrame and GraphFrame with a Wikipedia dataset, and Hadoop MapReduce wordcount on a 300GB dataset. The OpenTSDB cluster is for real-time time series data ingestion and storage for sensor data. We are working on bringing up more nodes. We share our first-hand experience gained in our journey, which we believe will benefit and inspire other academic institutions.",https://ieeexplore.ieee.org/document/7840859/,2016 IEEE International Conference on Big Data (Big Data),5-8 Dec. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CBI.2013.34,Business and Information Systems Engineering -- In Quest for Research and Education Agenda in Europe,IEEE,Conferences,"The new complex digital and information services systems and industries are calling for new transdisciplinary approaches on how to achieve technical, social, and cultural knowledge and skills to serve future needs of the industry and society. The leading digital industry is in demand of engineer's with knowledge and capabilities to collaborate and move between highly complex digital business and technical systems domains. The new reality is under constant transformation, highly intangible and nonlinear interconnected system. Transformative digital business innovations, rapidly evolving business models, architectures enabled business model scalability and ultra large-scale of systems are the new characteristics of this software-dominant-logic. This paper aims at covering contemporary challenges of the interdisciplinary in business, service, software and systems engineering by analyzing different research ontologies and curriculum models. The paper analyses recent Computer Science (CS) and Information Systems (IS) curriculum developments and reflects through different ontologies and recent research. Paper uses Service Design and Engineering (SDE) as a didactic and curriculum model for future Information Systems Engineering (ISE) and Business and Information Systems Engineering (BISE). The new curriculums serve the needs of global information start-ups, businesses, governments, and societies. This paper aims at describing the ontological foundations and conflicts, the axiology of the new curriculum model and proposes an integrated multi-ontology as the foundation for BISE new curriculum.",https://ieeexplore.ieee.org/document/6642875/,2013 IEEE 15th Conference on Business Informatics,15-18 July 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICCSA50499.2020.9316494,Challenges and Opportunities for Composable AI-Integrated Applications at the Digital Continuum: Keynote,IEEE,Conferences,"Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. Cyberinfrastructure is everywhere in diverse forms. From IoT to extreme scale computing, data and computing has never been as distributed with potential for real-time integration via fast networking and container management. The growth of new processors over the last decade including GPUs, FPGAs, and edge accelerators opened the way to a diverse set of applications using machine learning on top of distributed nontraditional hardware. The common theme to these applications, mostly composed of artificial intelligence (AI) workloads, is their need to run in specialized environments for reasons such as on demand or 24×7 nature of the tasks they are performing, and difficulties regarding their portability, latency, privacy and performance optimization. In many data-driven scientific applications there is a need for integration of these AI-workloads with traditional high-throughput computing (HTC) or high-performance computing (HPC) tasks for AI-integrated science. This talk will discuss example AI-integrated applications, describe some of the new systems that enabled these applications, and overview our recent research to enable composable applications including an application development methodology, intelligent middleware and workflow composition.",https://ieeexplore.ieee.org/document/9316494/,2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA),2-5 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FiCloudW.2017.79,Changes of Cyber-Attacks Techniques and Patterns after the Fourth Industrial Revolution,IEEE,Conferences,"In this paper, we predicted the changes of cyber-attacks techniques and patterns after the fourth industrial revolution with the epochal shift of information and communication technology and innovation of science and technology. Cyber space will be hyper-connection, cross-domain, and super intelligence space as connecting everything in the world due to a fusion of information and communication technologies such as artificial intelligence, internet of things, and cyber-physical systems. Cyber-attacks will use all electronic devices including wireless or wire networks, hardware, software, and cyber-physical systems as a route. The hacking tool's functions will evolve into a variety of forms reflecting human thought and behavioral procedures. The attack target will not be limited to a specific object. The purpose of the cyber-attack is to focus on secondary effects and indirect attacks as well as direct attacks.",https://ieeexplore.ieee.org/document/8113773/,2017 5th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW),21-23 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/REET51203.2020.00007,Chatbot-based Interview Simulator: A Feasible Approach to Train Novice Requirements Engineers,IEEE,Conferences,"Introduction: Although the interview is the most important and widely used requirements elicitation technique, novice engineers do not receive adequate training in Requirements Engineering (RE) courses. Objectives: Develop an AI-based interview simulator for helping novice requirements engineers in gaining interview skills. Methods: The research is based on the Design Science Methodology for Information Systems. The simulator is the outcome of six cycles; in each cycle, a proof of concept with additional features is created. Each cycle finishes with evaluation and improvement suggestions. Results: The simulator has been tested with students and results have been promising. The interview simulator understands context-free questions, retrieving the right information related to RE concepts such as goals, tasks, users, benefits, and constraints. The simulator also answers questions based on the context, makes summaries of the conversation, responds to meta-questions, and adds ambiguity and incompleteness to the conversation. Conclusions: The results have been promising. The simulator has been tested with degree and master level students. They were able to create a requirements specification using the simulator, and the feedback has been generally positive. The simulator will be tested in a real RE course in the academic year 2020-2021. Once it proves effective in the classroom, it will be opened to the RE community for free use and improvement.",https://ieeexplore.ieee.org/document/9216178/,2020 10th International Workshop on Requirements Engineering Education and Training (REET),31-31 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICIP42928.2021.9506200,Classification of RIGID and Non-Rigid Transformations with Autoencoder Representations,IEEE,Conferences,"Feature matching in transformed images is critical to many fields of computer science, from autonomous robots to video analysis. However, most widely used feature matching algorithms vary in their ability to track features depending on whether rigid or non-rigid image transformations occur. This makes it critical, especially in real-time calculations, to be able to identify what kind of transformation is taking place quickly in order to deploy the best feature matching algorithm for that type of transformation. The proposed research uses a combined autoencoder and neural network classification model to classify rigid or non-rigid transformations in order to improve feature matching on the image pairs. This system is the first to perform this kind of analysis with representation learning and opens new ways to improving feature matching performance. We show that using this method improves the amount of feature matches found between correctly identified image pairs.",https://ieeexplore.ieee.org/document/9506200/,2021 IEEE International Conference on Image Processing (ICIP),19-22 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/Informatics47936.2019.9119306,Classification of Tire Tread Images by Using Neural Networks,IEEE,Conferences,"Image classification represents a complex problem which occurs in variety of science and real life applications. Neural network is one of the excellent tools which could be used to solve this problem. The research presented in this paper is motivated by several consultations with active crime scene investigators. During these consultations, it became apparent, that criminology department is in critical need of advanced software for tire tread print identification. The current software used by crime scene investigators is outdated, time demanding and hard to work with. Application for tire tread print identification should be one of results of project created on the basis of our work with criminology department. This paper presents one of the first steps of this identification - tire tread position identification.",https://ieeexplore.ieee.org/document/9119306/,2019 IEEE 15th International Scientific Conference on Informatics,20-22 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AFRICON46755.2019.9134020,Cloud-Based Business Intelligence for a Cellular IoT Network,IEEE,Conferences,"This paper presents a cloud-based business intelligence (BI) implementation for a cellular Internet of Things (IoT) network. A Design Science Research (DSR) paradigm, combined with elaborated Action Design Research (eADR) was used to ensure a workable artifact is delivered. The real-world problem is that, in the cellular network considered here, network health status was not initially visible in an intelligent and actionable way. The network health status is used to ensure service availability and includes different health indicators, of which measurements are made at regular intervals. Not all IoT edge devices have health indicators available, but the network under evaluation provided sufficient data from which to extract anomalies. Experiments were conducted to identify the most appropriate anomaly detection technique from three options, namely SARIMA, SVM and LSTM techniques. Anomalies were linked to system operational failures, in turn to be addressed by appropriate standard operating procedures of a larger main-tenance system. Finally, a clustering algorithm was evaluated for automated recognition of anomalous events, showing that anomalies may be clustered in a useful way using the Mean-Shift clustering algorithm, and also identifying additional health indicators that support anomaly classification.",https://ieeexplore.ieee.org/document/9134020/,2019 IEEE AFRICON,25-27 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICeLeTE.2013.6644359,Clustering moodle data as a tool for profiling students,IEEE,Conferences,"This paper describes the first step of a research project with the aim of predicting students' performance during an online curriculum on a LMS and keeping them from falling behind. Our research project aims to use data mining, machine learning and artificial intelligence methods for monitoring students in e-learning trainings. This project takes the shape of a partnership between computer science / artificial intelligence researchers and an IT firm specialized in e-learning software. We wish to create a system that will gather and process all data related to a particular e-learning course. To make monitoring easier, we will provide reliable statistics, behaviour groups and predicted results as a basis for an intelligent virtual tutor using the mentioned methods. This system will be described in this article. In this step of the project, we are clustering students by mining Moodle log data. A first objective is to define relevant clustering features. We will describe and evaluate our proposal. A second objective is to determine if our students show different learning behaviours. We will experiment whether there is an overall ideal number of clusters and whether the clusters show mostly qualitative or quantitative differences. Experiments in clustering were carried out using real data obtained from various courses dispensed by a partner institute using a Moodle platform. We have compared several classic clustering algorithms on several group of students using our defined features and analysed the meaning of the clusters they produced.",https://ieeexplore.ieee.org/document/6644359/,2013 Second International Conference on E-Learning and E-Technologies in Education (ICEEE),23-25 Sept. 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDCS.2018.00118,Cognified Distributed Computing,IEEE,Conferences,"Cognification - the act of transforming ordinary objects or processes into their intelligent counterparts through Data Science and Artificial Intelligence - is a disruptive technology that has been revolutionizing disparate fields ranging from corporate law to medical diagnosis. Easy access to massive data sets, data analytics tools and High-Performance Computing (HPC) have been fueling this revolution. In many ways, cognification is similar to the electrification revolution that took place more than a century ago when electricity became a ubiquitous commodity that could be accessed with ease from anywhere in order to transform mechanical processes into their electrical counterparts. In this paper, we consider two particular forms of distributed computing - Data Centers and HPC systems - and argue that they are ripe for cognification of their entire ecosystem, ranging from top-level applications down to low-level resource and power management services. We present our vision for what ""Cognified Distributed Computing"" might look like and outline some of the challenges that need to be addressed and new technologies that need to be developed in order to make it a reality. In particular, we examine the role cognification can play in tackling power consumption, resiliency and management problems in these systems. We describe intelligent software-based solutions to these problems powered by on-line predictive models built from streamed real-time data. While we cast the problem and our solutions in the context of large Data Centers and HPC systems, we believe our approach to be applicable to distributed computing in general. We believe that the traditional systems research agenda has much to gain by crossing discipline boundaries to include ideas and techniques from Data Science, Machine Learning and Artificial Intelligence.",https://ieeexplore.ieee.org/document/8416381/,2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS),2-6 July 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HICSS.1996.495429,Combining neural networks with other prediction techniques,IEEE,Conferences,"The complexity and the inherent heterogeneity of real world problems are still one of the major challenges in computer science. Due to the necessity of using different data processing technologies general interest in hybrid systems is a fast growing research area. To support the integration of intercommunicating hybrids the paper suggests the use of distributed software architectures. The main advantages of the approach presented in the paper are the encapsulation of different paradigms, the separation of control and domain knowledge and the reduction of the complexity of individual problem solvers. The first section of the paper gives an overview of the state of the art in hybrid processing. A taxonomy of currently known hybrid system approaches is discussed. Because of the special importance of distributed artificial intelligence (DAI) the author examines issues and research directions in this field and concludes with the presentation of DAI as an integrative paradigm. The author then describes a case study. He gives an overview of the domain (economics) and discuss some prediction methods usually used in this area. After introducing some simple economic relationships and a description of how to use neural networks in multivariate prediction the paper shows how connectionist techniques are embedded in a distributed problem solving framework, called PREDICTOR. The last section shows an example in which a hybrid system out performs the homogenous approaches by combining them intelligently. PREDICTOR is a case study of how to design a so called intercommunicating hybrid system.",https://ieeexplore.ieee.org/document/495429/,Proceedings of HICSS-29: 29th Hawaii International Conference on System Sciences,3-6 Jan. 1996,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICICIP.2011.6008299,Comparison on driving behavior between manned and unmanned ground vehicles,IEEE,Conferences,"In order to enhance the traffic road safety, applying the artificial intelligence theory and the technology in road traffic control system, that is intelligent driving vehicle, may effectively decrease traffic accidents, which are caused by drivers' neglect, fatigue and so on. This article is based on cognitive science to analyze driving behaviors. First, we estimated the Information Processing Model of Intelligent Vehicle. Second, based on prototype pattern recognition theory, we also built Pattern Recognition Model of Intelligent Driving Behavior, which provided the advantageous basis for the further research on intelligent vehicle. Third, virtual scene simulation system was established by using Creator and Vega Prime. Finally, according to test data, we investigated the features of speed and latitudinal distance in both artificial and intelligent U-Turn driving behavior. Our results describe that the intelligent vehicle does have the ability of cognizance, and it can make correct reactions corresponding to the driving environment, but its intelligence still needs improving.",https://ieeexplore.ieee.org/document/6008299/,2011 2nd International Conference on Intelligent Control and Information Processing,25-28 July 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICAI.2019.8701407,Comparitive Analysis and Implication of UAV and AI in Forensic Investigations,IEEE,Conferences,"Unmanned Aerial Vehicles (UAVs) are having applications in different areas including remote sensing, real-time monitoring, environmental monitoring, agriculture, land use surveys, traffic surveillance, metereology and goods deleivery etc. In this study a comparative analysis is being made on various investigation techniques in forensic science with and without the use of UAVs. The analysis and impact of telecommunication and related aspects of a UAV is being examined in the area of forensic science to investigate the complex crime scenes more sophisticatedly and to help the investigators and forensic professionals in the proper scrutiny and mapping of the scene of crime. The present study is focused on the estimation of the practicality of the use of UAV and AI in crime scene investigation (CSI), feasibility of UAV in forensic science and its logistical implementation.",https://ieeexplore.ieee.org/document/8701407/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCIT.2007.152,Concept Analysis of OWL Ontology Based on the Context Family Model,IEEE,Conferences,"The core of the semantic Web is ontology, which supports interoperability among semantic Web applications and enables developer to reuse and share domain knowledge. The process of building an ontology is a high-cost process. The reality is that the construction of ontologies is an art rather than a science. Therefore, methodologies and supporting tools are essential to help the developer construct suitable ontologies for the given purposes and to verify the ontology its fitness of purpose and its reusability. In this paper we propose a novel approach for analyzing ontologies based on the formal concept analysis (FCA) with context family model and build a new tool that extracts main elements (class, property and individual etc.) from the source code of Web ontology language (OWL) and then detects some structural problems. By using the tool, ontology developer can build and/or reconstruct ""well-defined"" and ""good"" ontologies.",https://ieeexplore.ieee.org/document/4420373/,2007 International Conference on Convergence Information Technology (ICCIT 2007),21-23 Nov. 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW.2018.00152,Constructing Graph Node Embeddings via Discrimination of Similarity Distributions,IEEE,Conferences,"The problem of unsupervised learning node embeddings in graphs is one of the important directions in modern network science. In this work we propose a novel framework, which is aimed to find embeddings by discriminating distributions of similarities (DDoS) between nodes in the graph. The general idea is implemented by maximizing the earth mover distance between distributions of decoded similarities of similar and dissimilar nodes. The resulting algorithm generates embeddings which give a state-of-the-art performance in the problem of link prediction in real-world graphs.",https://ieeexplore.ieee.org/document/8637376/,2018 IEEE International Conference on Data Mining Workshops (ICDMW),17-20 Nov. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BDEE52938.2021.00029,Construction and Implementation of Embodied Mixed-Reality Learning Environments,IEEE,Conferences,"As the research paradigm of cognitive science changes from disembodied to embodied, people realize that the body and its interaction with the environment have an important effect on learning activities more and more intensely. Focus on obtaining physical experience, embodied learning encourages the participation of the body’s sensor-motor system and the multimodal interaction between the body and the environment, and it puts forward some new requirements for the design and construction of learning environments. At the same time, the development of artificial intelligence, mixed reality, human-computer interaction and other technologies in recent years has provided a good support for the construction and application of embodied learning environments, especially the functions of virtual-real fusion, natural interaction and dynamic generation of the mixed reality. For this reason, we proposed to design embedded mixed -reality learning environments (EMRLE) for supporting and promoting embodied activities by using these technologies and the embodied cognitive theory. Through combing the origin and background of EMRLE, on the one hand, we can analyze the construction goals, basic characteristics, construction models and realization methods of EMRLE from two dimensions of theory and technology; on the other hand, combined with the existing relevant research and application status in the world, the main forms of EMRLE in education and teaching practice and its teaching activity design cases can be summarized to further demonstrate and analyze the necessity, rationality and technical feasibility of EMRLE construction. For this reason, embodied learning activities designed on the basis of building EMRLE also provide new ideas for promoting the innovation of teaching and learning forms.",https://ieeexplore.ieee.org/document/9626334/,2021 International Conference on Big Data Engineering and Education (BDEE),12-14 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE53849.2021.00027,Construction and Research of Virtual Forest Environment Based on Spatial Data,IEEE,Conferences,"Virtual Forest environment is a virtual geographical environment in the application of scientific forestry practices; it is a combination of forestry science and virtual geographical environment. Based on forestry spatial data and virtual reality technology, it constructs forest objects and expresses extremely complex forest phenomena. This article introduces how to create a virtual environment object of forest, forest-related technology, the virtual environments research, and pointes out the importance of creating a virtual forest environment.",https://ieeexplore.ieee.org/document/9696141/,2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),24-26 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMAP49528.2020.9248454,Crowd Sourcing as an Improvement of N-Grams Text Document Classification Algorithm,IEEE,Conferences,"A common task in a world of natural language processing is text classification useful for e.g. spam filters, documents sorting, science articles classification or plagiarism detection. This can still be done best and most accurately by human, on the other hand, we can of ten accept certain error in the classification in exchange for its speed. Here, natural language processing mechanism transforms the text in natural language to a form understandable by a classifier such as K-Nearest Neighbour, Decision Trees, Artificial Neural Network or Support Vector Machines. We can also use this human element to help automated classification to improve its accuracy by means of crowdsourcing. This work deals with classification of text documents and its improvement through crowdsourcing. Its goal is to design and implement text documents classifier prototype based on documents similarity and to design evaluation and crowdsourcing-based classification improvement mechanism. For classification the N-grams algorithm has been chosen, which was implemented in Java. Interface for crowdsourcing was created using CMS WordPress. In addition to data collection, the purpose of interface is to evaluate classification accuracy, which leads to extension of classifier test data set, thus the classification is more successful. We have tested our approach on two data sets with promising preliminary results even across different languages. This led to a real-world implementation started at the beginning of 2019 in cooperation of two universities: VSB-TUO and OSU.",https://ieeexplore.ieee.org/document/9248454/,2020 15th International Workshop on Semantic and Social Media Adaptation and Personalization (SMA,29-30 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIVR46125.2019.00070,CrowdAR Table - An AR Table for Interactive Crowd Simulation,IEEE,Conferences,In this paper we describe a prototype implementation of an augmented reality (AR) system for accessing and interacting with crowd simulation software. We identify a target audience and tasks (access to the software in a science museum) motivate the choice of AR system (an interactive table complemented with handheld AR via smartphones) and describe its implementation. Our system has been realized in a prototypical implementation verifying its feasibility and potential. Detailed user testing will be part of our future work.,https://ieeexplore.ieee.org/document/8942269/,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),9-11 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC48688.2020.00026,DSLE: A Smart Platform for Designing Data Science Competitions,IEEE,Conferences,"During the last years an increasing number of university-level and post-graduation courses on Data Science have been offered. Practices and assessments need specific learning environments where learners could play with data samples and run machine learning and data mining algorithms. To foster learner engagement many closed-and open-source platforms support the design of data science competitions. However, they show limitations on the ability to handle private data, customize the analytics and evaluation processes, and visualize learners' activities and outcomes. This paper presents Data Science Lab Environment (DSLE, in short), a new open-source platform to design and monitor data science competitions. DSLE offers a easily configurable interface to share training and test data, design group works or individual sessions, evaluate the competition runs according to customizable metrics, manage public and private leaderboards, monitor participants' activities and their progress over time. The paper describes also a real experience of usage of DSLE in the context of a 1st-year M.Sc. course, which has involved around 160 students.",https://ieeexplore.ieee.org/document/9202557/,"2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)",13-17 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCE-Berlin47944.2019.8966202,Data generators: a short survey of techniques and use cases with focus on testing,IEEE,Conferences,"The process of data generation plays a significant role in various areas of computer science. Software testing is probably the seminal example for usage of artificially created data. An appropriate data generator is suitable and necessary for almost every type of testing (including automated): the regression tests, null value tests, coverage, security and performance test. With the rise of data science, the data generation is as well used in machine learning, data mining, and data visualization. Other industries such as financial and health-care have great benefits from artificial data as well. Important aspect of the generated data is that the data needs to be realistic but not real, which embrace the confidentiality and privacy. In this paper, we give a short survey on the different types of generators from the architecture point of view and their intended usage, as well as we list their pros and cons. Finally, we give an overview of the used data generation algorithms and the best practices in different areas.",https://ieeexplore.ieee.org/document/8966202/,2019 IEEE 9th International Conference on Consumer Electronics (ICCE-Berlin),8-11 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DSAA.2015.7344825,Data science foundry for MOOCs,IEEE,Conferences,"In this paper, we present the concept of data science foundry for data from Massive Open Online Courses. In the foundry we present a series of software modules that transform the data into different representations. Ultimately, each online learner is represented using a set of variables that capture his/her online behavior. These variables are captured longitudinally over an interval. Using this representation we then build a predictive analytics stack that is able to predict online learners behavior as the course progresses in real time. To demonstrate the efficacy of the foundry, we attempt to solve an important prediction problem for Massive Open Online Courses (MOOCs): who is likely to stopout? Across a multitude of courses, with our complex per-student behavioral variables, we achieve a predictive accuracy of 0.7 AUCROC and higher for a one-week-ahead prediction problem. For a two-to-three-weeks-ahead prediction problem, we are able to achieve 0.6 AUCROC. We validate, via transfer learning, that these predictive models can be used in real time. We also demonstrate that we can protect the models using privacy-preserving mechanisms without losing any predictive accuracy.",https://ieeexplore.ieee.org/document/7344825/,2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA),19-21 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GCCE.2017.8229475,Deductively verifying embedded software in the era of artificial intelligence = machine learning + software science,IEEE,Conferences,"Today Google collects big data, and develops new business using both cloud computing such as search engine and artificial intelligence such as machine learning. The study of artificial intelligence mainly on deep learning is prosperous and is expected to make smart life now and in the future. The mainstream of the present artificial intelligence is machine learning, and the foundation is inductive inference. On the other hand, artificial intelligence from old days is deductive inference, and the deductive inference is the foundation of software science. In this paper, from the viewpoint of “artificial intelligence = machine learning + software science”, we grasp computer technologies. We pay attention to software science, especially deductive inference of embedded systems, and explain deductive verifications for guaranteeing the reliability of embedded systems.",https://ieeexplore.ieee.org/document/8229475/,2017 IEEE 6th Global Conference on Consumer Electronics (GCCE),24-27 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2018.8622509,Deep Learning for Enhancing Fault Tolerant Capabilities of Scientific Workflows,IEEE,Conferences,"In the history of Computer Science, the act of `delegation' has been the greatest multiplier of society's problem-solving ability. A scientist working on detecting anomalies in a phenomenon, does not need to re-invent matrix multiplication techniques to solve her problem. Scientific workflows provide ultimate `delegation' mechanism - where a domain scientist can completely forget the specifics of `how' her program will execute on a large cluster in an efficient and cost-effective manner and can instead focus on the mathematical formulation and theoretical robustness of her solution. We present here an approach that directly aims to make the execution of Scientific Workflows more reliable, robust and efficient. We aim that the work presented in this paper will propel the larger effort, from the scientific workflow community, of making scientific workflow execution as simple, efficient and robust as a JOIN operation in a modern database. Specifically, we apply Deep Learning techniques to develop a mechanism that forecasts the final state (success or failure) of a dynamic job in a large-scale particle physics experiment, with minimal data gathering, and as early as possible in job's life cycle. The key advantage of having a predictive mechanism to identify and anticipate failure-prone jobs is the potential for designing intelligent Fault Tolerance mechanisms to handle anomalous events. We achieve a 14% improvement in computational resources utilization, and an overall classification accuracy of 85% on real tasks executed in a High Energy Physics Computing workflow. To the best of our knowledge, this is the most exhaustive and first of its kind study of neural network architectures in context of a real-dataset profiled from a large-scale scientific workflow.",https://ieeexplore.ieee.org/document/8622509/,2018 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ETFA.2019.8869108,Deployment of territorial structures to reduce gender gap in technology and some real cases in Catalonia,IEEE,Conferences,"Gender gap in computer science related fields is one of the most critical among all technological areas. This paper describes the methodology used to create gender commissions and providing them of a territorial structure around informatics engineering and artificial intelligence, two close areas where the presence of women is critical both at professional level, as well as training level. Territorial structure provides an additional potential very useful for the impact of the activities of the commission. Here the creation of two gender structures in Catalonia is presented.",https://ieeexplore.ieee.org/document/8869108/,2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),10-13 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MLBDBI54094.2021.00110,Design and Application of Rehabilitation Psychology Practical Teaching System Based on VR Technology,IEEE,Conferences,"Research purposes: The characteristics of VR technology, such as immersion, interaction, construction and sociality, make its application in the field of education have unique advantages. How to make use of the advantages of VR technology to design a functional, purposeful and interesting practical experience teaching in the teaching of Rehabilitation Psychology is an important research direction of psychology curriculum reform. Based on the innovative teaching mode of Rehabilitation Psychology, this paper aims to improve the teaching method and content of the course by using VR virtual reality, so as to provide reference for the reform of teaching mode. Research methods: 122 college students majoring in applied psychology and 85 college students majoring in rehabilitation medicine in our university were selected as the research objects. Based on the latest research results of computer science, psychology and other related subjects, this paper analyzes and compares the teaching scheme design, implementation and results of the practical course of rehabilitation psychology with that of the traditional course of rehabilitation psychology by comprehensively using the methods of literature analysis, teaching action research, teaching experience summary and teaching reflection. Conclusion: The teaching experience system of Rehabilitation Psychology based on VR Virtual Reality is effective, so it is feasible to integrate VR Virtual Reality into the experimental teaching of psychology. This study provide a research basis for exploring innovative teaching mode and teaching reform of applied psychology specialty.",https://ieeexplore.ieee.org/document/9731082/,"2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)",3-5 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSSE.2019.8823516,Design and Implementation of Chatbot Framework For Network Security Cameras,IEEE,Conferences,"In recent years, with the development of science and technology Internet Protocol camera is getting and getting popular and widely used. In this paper, we present a chatbot framework to help user get the human detection information from the cameras via Facebook messenger instead of observing 24/7 called Security Bot (Sbot). To build Sbot, we design a system including camera network, Human Detection Server (HDS), and Sbot server. In the system, Sbot transfer information between user and HDS using Facebook Messenger Platform. In the human detection task, we use SSD-MobileNet1 network architecture for detecting human in real-time and updating dataset for retraining using transfer learning method with more case taken from surveillance camera.",https://ieeexplore.ieee.org/document/8823516/,2019 International Conference on System Science and Engineering (ICSSE),20-21 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IEEECONF53024.2021.9733780,Design and Implementation of an Educational Technology Kit Aligned to the Conceptual Framework of Educational Mechatronics,IEEE,Conferences,"Educational systems continuously seek new educational technologies that improve their students&#x0027; knowledge and help them acquire the necessary skills for the new industrial era. Studies indicate that technology plays a significant role in student performance when implemented correctly, stimulates better interactions between instructors and the students, and encourages cooperative learning, collaboration, problem-solving, and communication competencies. A necessary skill for a good learning process is spatial thinking. Studies show that students who do not have good spatial thinking will have more trouble passing science, technology, engineering, and mathematics (STEM) courses. This paper presents the design and implementation of a novel educational kit to aid in the development of spatial thinking, specifically applied to the two-dimensional Cartesian Coordinate Systems (2D-CACSET) designed, from its conception, to apply the Educational Mechatronics Conceptual Framework (EMCF). This innovative 2D-CACSET comprises two Tags, four Anchors, and a Listener that use a real-time location system based on Ultra-Wide Band (UWB) technology as a cornerstone of operation. In addition, it has a 2D dashboard and a Graphical User Interface that allow mechatronic concepts from the concrete, graphic and abstract levels of thinking. Thus, in this practice, students acquired knowledge and developed skills to apply when working with more complex prototypes throughout their lives.",https://ieeexplore.ieee.org/document/9733780/,2021 Machine Learning-Driven Digital Technologies for Educational Innovation Workshop,15-17 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WCCIT.2013.6618739,Design and application of academic frontier-based approach in engineering courses,IEEE,Conferences,"The reform of teaching approach has been the focus of modern opening educational reform and research. The real science thrives on both revolutionary and frontier progress that the textbook can not include. Based on the analysis of the characteristics of several the engineering courses, we build the academic frontier-based approach (AFA) for the purpose of combination of the basic and academic frontier knowledge by the application of the theory of constructivist learning. AFA is a learner-centred instructional approach used to promote active and deep learning by involving learners in learning academic frontier topics in an open and collaborative environment. The design and implementation of the approach enrich the teaching mode and the content of the key curriculums in depth, have an effective role in expansion knowledge, fun learning, and dig the potential of the learners in the group and team.",https://ieeexplore.ieee.org/document/6618739/,2013 World Congress on Computer and Information Technology (WCCIT),22-24 June 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FUZZ.2003.1209341,Design enhancement by fuzzy logic in architecture,IEEE,Conferences,"Fuzzy logic systems find application especially in engineering systems due to their suitability for applications dealing with the concept of Takagi-Sugeno fuzzy model. However, the fuzzy concept is particularly valid also in the areas where information is qualitative. Exact science applications deal with the information by modeling and thereafter identifying the relationships in the model by suitable computation. In contrast, the fuzzy logic employment in soft sciences is not as straightforward as it is in exact sciences and special care should be taken in the former case. Analogous to exact sciences, the majority of soft information sources belongs to soft sciences where the quantities dealt with are usually not measurable in the engineering sense. Therefore, for soft sciences fuzzy logic is an important means for dealing with associated imprecise information processing. In spite of this, the employment of fuzzy logic in soft sciences is not common. In this work, aspects of fuzzy logic implementation in the areas of soft sciences is pointed out. This is exemplified by a design application in building technology using a soft design data set from a real life environment.",https://ieeexplore.ieee.org/document/1209341/,"The 12th IEEE International Conference on Fuzzy Systems, 2003. FUZZ '03.",25-28 May 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITAIC49862.2020.9339101,Design of Embedded Real-time Target Tracking System Based on KNN Algorithm,IEEE,Conferences,"With the rapid development of science and technology, more and more high-tech products have been applied to all aspects of life. In the field of security and defense, video monitoring plays an important role. In order to solve the problem of real-time and miniaturization of target tracking system, this paper applies a tracking algorithm based on KNN(k-nearest neighbor) background splitter combined with Kalman filter. When tracking a moving target, it is important to determine the moving target in the initial frame. In this paper, the motion detection method in KNN background segmentation is adopted to automatically initialize the moving target. Kalman filter can predict the motion state of the moving target in the next frame according to the information of the moving target in the current frame, and track the target with the predicted value as the input of CamShift algorithm. The implementation of the tracking algorithm on the embedded raspberry pi platform is beneficial to the miniaturization of smart devices. The experimental results show that the algorithm has better tracking ability, faster operation speed and stronger robustness for moving targets in raspberry pi embedded environment, which improves the performance of the algorithm and gets good effects.",https://ieeexplore.ieee.org/document/9339101/,2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),11-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TENCON.2016.7848657,"Development of a predictive model for on-demand remote river level nowcasting: Case study in Cagayan River Basin, Philippines",IEEE,Conferences,"DOST-Advanced Science and Technology Institute has installed various hydro-meteorological devices, such as Automated Rain Gauge(ARG), Water Level Monitoring Stations (WLMS), and Tandem Stations, all over the Philippines since 2010. While the stations provide valuable near real-time data for monitoring major riven basins, ahead-of-time flood estimations are of interest for early warning purposes especially for local communities situated along the river basin. This study addresses the need on developing a predictive model that can provide an ahead of time nowcasting system for water level and flood hazard to provide a decision support tool for the local communities. A data driven approach using machine learning is implemented to generate ahead-of-time water level estimation. Results from the testing data shows that the resulting model was able to provide an accurate ahead of time water level prediction without relying on rainfall-runoff models.",https://ieeexplore.ieee.org/document/7848657/,2016 IEEE Region 10 Conference (TENCON),22-25 Nov. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SERVICES.2019.00036,Dimensional Situation Analytics: An Introduction and Its Application Prospects,IEEE,Conferences,"Dimensional situation analytics provides a formal framework to analyze situations from Data Information Knowl-edge Wisdom (DIKW) point of view. To date, the advent of big data driven applications opens up many frontiers in artificial intelligence and computer science, and yet it also raises a series of challenges due to theirs empirical and experimental nature. In particular, to systematically and analytically understand the logical connection through which intelligence and knowledge is derived from data and information deterministically is one of the far-reaching future objectives in computer science. Starting from an earlier result on Dimensional Situation Analytics (DSA), where the initial efforts targeted at the integration of situations and DIKW ontology, this paper brings the prospect of real world applications of DSA into perspective. A good example is UAV path planning for efficient radiation detection and monitoring, which links the pervious result, i.e., the DSA formal framework, with real world experimentation and thereof further explores on the effectiveness and future work for the DSA.",https://ieeexplore.ieee.org/document/8817250/,2019 IEEE World Congress on Services (SERVICES),8-13 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MLHPC49564.2019.00013,DisCo: Physics-Based Unsupervised Discovery of Coherent Structures in Spatiotemporal Systems,IEEE,Conferences,"Extracting actionable insight from complex unlabeled scientific data is an open challenge and key to unlocking data-driven discovery in science. Complementary and alternative to supervised machine learning approaches, unsupervised physics-based methods based on behavior-driven theories hold great promise. Due to computational limitations, practical application on real-world domain science problems has lagged far behind theoretical development. However, powerful modern supercomputers provide the opportunity to narrow the gap between theory and practical application. We present our first step towards bridging this divide - DisCo - a high-performance distributed workflow for the behavior-driven local causal state theory. DisCo provides a scalable unsupervised physics-based representation learning method that decomposes spatiotemporal systems into their structurally relevant components, which are captured by the latent local causal state variables. In several firsts we demonstrate the efficacy of DisCo in capturing physically meaningful coherent structures from observational and simulated scientific data. To the best of our knowledge, DisCo is also the first application software developed entirely in Python to scale to over 1000 machine nodes, providing good performance along with ensuring domain scientists' productivity. Our capstone experiment, using newly developed and optimized DisCo workflow and libraries, performs unsupervised spacetime segmentation analysis of CAM5.1 climate simulation data, processing an unprecedented 89.5 TB in 6.6 minutes end-to-end using 1024 Intel Haswell nodes on the Cori supercomputer obtaining 91% weak-scaling and 64% strong-scaling efficiency. This enables us to achieve state-of-the-art unsupervised segmentation of coherent spatiotemporal structures in complex fluid flows.",https://ieeexplore.ieee.org/document/8950692/,2019 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC),18-18 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPS.2018.00068,Do Developers Understand IEEE Floating Point?,IEEE,Conferences,"Floating point arithmetic, as specified in the IEEE standard, is used extensively in programs for science and engineering. This use is expanding rapidly into other domains, for example with the growing application of machine learning everywhere. While floating point arithmetic often appears to be arithmetic using real numbers, or at least numbers in scientific notation, it actually has a wide range of gotchas. Compiler and hardware implementations of floating point inject additional surprises. This complexity is only increasing as different levels of precision are becoming more common and there are even proposals to automatically reduce program precision (reducing power/energy and increasing performance) when results are deemed """"good enough.'"""" Are software developers who depend on floating point aware of these issues? Do they understand how floating point can bite them? To find out, we conducted an anonymous study of different groups from academia, national labs, and industry. The participants in our sample did only slightly better than chance in correctly identifying key unusual behaviors of the floating point standard, and poorly understood which compiler and architectural optimizations were non-standard. These surprising results and others strongly suggest caution in the face of the expanding complexity and use of floating point arithmetic.",https://ieeexplore.ieee.org/document/8425212/,2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS),21-25 May 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSNet47905.2019.9108976,Dynamic security management driven by situations: An exploratory analysis of logs for the identification of security situations,IEEE,Conferences,"Situation awareness consists of ""the perception of the elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their status in the near future"". Being aware of the security situation is then mandatory to launch proper security reactions in response to cybersecurity attacks. Security Incident and Event Management solutions are deployed within Security Operation Centers. Some vendors propose machine learning based approaches to detect intrusions by analysing networks behaviours. But cyberattacks like Wannacry and NotPetya, which shut down hundreds of thousands of computers, demonstrated that networks monitoring and surveillance solutions remain insufficient. Detecting these complex attacks (a.k.a. Advanced Persistent Threats) requires security administrators to retain a large number of logs just in case problems are detected and involve the investigation of past security events. This approach generates massive data that have to be analysed at the right time in order to detect any accidental or caused incident. In the same time, security administrators are not yet seasoned to such a task and lack the desired skills in data science. As a consequence, a large amount of data is available and still remains unexplored which leaves number of indicators of compromise under the radar. Building on the concept of situation awareness, we developed a situation-driven framework, called dynSMAUG, for dynamic security management. This approach simplifies the security management of dynamic systems and allows the specification of security policies at a high-level of abstraction (close to security requirements). This invited paper aims at exposing real security situations elicitation, coming from networks security experts, and showing the results of exploratory analysis techniques using complex event processing techniques to identify and extract security situations from a large volume of logs. The results contributed to the extension of the dynSMAUG solution.",https://ieeexplore.ieee.org/document/9108976/,2019 3rd Cyber Security in Networking Conference (CSNet),23-25 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCI-CC.2017.8109760,Early diagnosis of mild cognitive impairment: A case study in approaches to inductive-logic programming,IEEE,Conferences,"Recent rapid advances in data collection routines in clinical science have led to a trend of storing patient data in a heterogeneous database. The lack of existing computing tools to enable operability to use machine learning on these heterogeneous data sources is a barrier to the healthcare sciences. Healthcare data is usually complex and highly context-dependent, and it requires modern computational tools to handle the complexity of such data. This study sought to utilize the data collected from virtual reality (VR)-based software and a leap-motion device used for learning in mild cognitive impairment (MCI) cases to enable early detection of MCI by analyzing the classification rules for errors (action slips) based on finger-action transitions when performing instrumental activities of daily living (IADL). Finger motion was recorded as a time-series database. An induction technique known as Inductive-Logic Programming (ILP), which uses logical and clausal language to represent the training data, was then used to discover a concise classification rule using logical programming. We were able to generate rules on how action transitions of the finger in the experiments were related to the pattern of micro-errors that indicate the difference of error regarding the length of the no-motion state of the finger.",https://ieeexplore.ieee.org/document/8109760/,2017 IEEE 16th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),26-28 July 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAICA52286.2021.9498218,Eco-climate Intelligent Monitoring System of an Agricultural Science-And-Technology Park Based on Internet of Things,IEEE,Conferences,"An agricultural science and technology park (ASTP) is a new mode of agricultural development supported by science and technology. At present, research focuses on diseases and insect pests, intelligent irrigation, greenhouse environment-specific crop monitoring, and other individual issues, in which the utilization efficiency of agricultural information technology is low. The purpose of this study is to fully grasp the change in the ecological climate of ASTPs and improve their intelligence level. This study, based on the Internet of Things of agricultural information transmission and control, designs a greenhouse climatic and agricultural science and technology park and unifies the field intelligent control and scientific research and production integration management platforms. Standardized planting and a field monitoring center for large data visualization analysis for scientific research and production are used to achieve real-time online mining analysis, monitoring, and early warning and decision support services. A software terminal is used to prompt on-site management measures and early warning according to weather changes. After one growing season, the labor force was reduced by 20%, the use of pesticides by 20%, and the use of water resources and fertilizers decreased. Practical application shows that the system runs stably and meets the demands of ecological environment monitoring in ASTPs.",https://ieeexplore.ieee.org/document/9498218/,2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA),28-30 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/eScience.2019.00047,Efficient Runtime Capture of Multiworkflow Data Using Provenance,IEEE,Conferences,"Computational Science and Engineering (CSE) projects are typically developed by multidisciplinary teams. Despite being part of the same project, each team manages its own workflows, using specific execution environments and data processing tools. Analyzing the data processed by all workflows globally is a core task in a CSE project. However, this analysis is hard because the data generated by these workflows are not integrated. In addition, since these workflows may take a long time to execute, data analysis needs to be done at runtime to reduce cost and time of the CSE project. A typical solution in scientific data analysis is to capture and relate the data in a provenance database while the workflows run, thus allowing for data analysis at runtime. However, the main problem is that such data capture competes with the running workflows, adding significant overhead to their execution. To mitigate this problem, we introduce in this paper a system called ProvLake, which adopts design principles for providing efficient distributed data capture from the workflows. While capturing the data, ProvLake logically integrates and ingests them into a provenance database ready for analyses at runtime. We validated ProvLake in a real use case in the O&G industry encompassing four workflows that process 5 TB datasets for a deep learning classifier. Compared with Komadu, the closest solution that meets our goals, our approach enables runtime multiworkflow data analysis with much smaller overhead, such as 0.1%.",https://ieeexplore.ieee.org/document/9041720/,2019 15th International Conference on eScience (eScience),24-27 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSCC.2019.8843619,Enhancing STEM Education using Augmented Reality and Machine Learning,IEEE,Conferences,"Learning Science, Technology, Engineering and Mathematics (STEM) in the 21st century has been evolved from the conventional textbook to the interactive platform using electronic devices. This paper presents the implementation of a mobile application system, named AUREL (Augmented Reality Learning) in enhancing the learning experience by projecting Augmented Reality (AR) objects onto 2D images. This AR visualization is used to improve the understanding of STEM subjects and increases the enthusiasm of students towards STEM subjects. In this implementation, Google's Cloud Tensor Processing Units (TPUs) are used to train specific datasets alongside Cloud Vision API to detect a wide range of objects. ML Kit for Firebase is used to host the custom TensorFlow Lite models for specific use cases for better accuracy. On the other hand, Google Cloud Platform (GCP) is used to harvest STEM data, manage STEM 3D information and data processing. Subsequently, the processed information will be displayed in AR in the mobile application using ARCore's Sceneform SDK. The application of AUREL could be extended to all science subjects so that students can learn using an interactive platform.",https://ieeexplore.ieee.org/document/8843619/,2019 7th International Conference on Smart Computing & Communications (ICSCC),28-30 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPCC.1989.102101,"Esperanto, to simplify and clarify international communication",IEEE,Conferences,"Esperanto can solve the problem of the international language barrier. Esperanto, designed explicitly for this purpose, is a real and elegant language, fully operational, proven in practice, and ready for general application by the public at large. Application of the fringe benefits to public education inherent in Esperanto would provide the means for the painless implementation of the needed international language. The practical use of Esperanto as a language of science and technology is discussed.<>",https://ieeexplore.ieee.org/document/102101/,"International Professional Communication Conference 'Communicating to the World.',",18-20 Oct. 1989,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
,Exploiting intelligent decision supports for model-driven biomedical system analysis,IEEE,Conferences,"Both linear modeling and nonlinear modeling provide special means to simplify problem-solving in science and engineering, which also represents a critical stage for intelligent decision support systems. Model-driven decision support systems have numerous real world applications, such as the feature extraction, image compression, pattern recognition, medical diagnosis and telecommunication. In this article, an intelligent decision support system has been exploited for biomedical system analysis. The PCA (Principal Component Analysis) and ICA (Independent Component Analysis) based linear and nonlinear models have been implemented onto the sample characterization of the biomedical systems for decision making, together with applications of neural networks training. The result indicates the effectiveness of the proposed approaches, where the merit and drawback are discussed between linear and nonlinear modeling. Numerical simulations have also been made.",https://ieeexplore.ieee.org/document/6615809/,2013 8th Iberian Conference on Information Systems and Technologies (CISTI),19-22 June 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISMSIT.2018.8567057,FPGA-Based Multi Heart Diseases Classification System with the Aid of LabVIEW,IEEE,Conferences,"Electrocardiography (ECG) is one of the most important recording processes used in medicine; it provides a clear description of situation of the heart. The development of technological and computer science, which led to the emergence of high-resolution screens placed on the wrist and able to record the heart signal, increased the importance of developing a real time and portable multi heart diseases diagnosis system. In this paper, we propose an FPGA-based multi heart diseases classification system that identify eight different heart malfunctions depending on the standard ECG features. Our proposed ECG system, achieved with the aid of LabView, consists of three parts: Acquisition System, Feature Extraction and Making Decision using two different classifiers; Threshold Decision (TD) and Numeral Virtual Generalizing Random-Access Memory (NVG-RAM) weightless neural network. The proposed classifiers were implemented using Verilog HDL and Xilinx Spartan 3AN FPGA. The FPGA mapping showed that TD classifier occupy 1% of the hardware platform slices with execution time of 16 ns, while the NVG-RAM classifier utilize 21% of the FPGA slices with an increase of the execution time equal to 12.81 μs. On the other hand, the NVG-RAM outperforms the TD algorithm and the other proposed classifiers in the literature. In case of the experimental data, the probability of correct classification (PCC) of heart conditions was 100% for NVG-RAM and 98.84% for TD classifier. Whereas, the success rates in case of generated data for the executed TD and NVG-RAM classifiers were 98% and 100 %, respectively.",https://ieeexplore.ieee.org/document/8567057/,2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT),19-21 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISDFS.2019.8757511,Face Verification and Recognition for Digital Forensics and Information Security,IEEE,Conferences,"In this paper, we present an extensive evaluation of face recognition and verification approaches performed by the European COST Action MULTI-modal Imaging of FOREnsic SciEnce Evidence (MULTI-FORESEE). The aim of the study is to evaluate various face recognition and verification methods, ranging from methods based on facial landmarks to state-of-the-art off-the-shelf pre-trained Convolutional Neural Networks (CNN), as well as CNN models directly trained for the task at hand. To fulfill this objective, we carefully designed and implemented a realistic data acquisition process, that corresponds to a typical face verification setup, and collected a challenging dataset to evaluate the real world performance of the aforementioned methods. Apart from verifying the effectiveness of deep learning approaches in a specific scenario, several important limitations are identified and discussed through the paper, providing valuable insight for future research directions in the field.",https://ieeexplore.ieee.org/document/8757511/,2019 7th International Symposium on Digital Forensics and Security (ISDFS),10-12 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMC53470.2022.9753712,Face-Crypt Messenger: Enhancing Security of Messaging Systems using AI based Facial Recognition and Encryption,IEEE,Conferences,"Information Security has always been a major discipline in the field of Computer Science. Many software has been developed around the world for fulfilling various tasks. However, it is important to ensure the security of the data involved in using that particular software. In the recent times, the issue of security related to chat systems has been trending. There have been instances where an unauthorized user has viewed the messages of a particular user. That is where this project presents a pragmatic solution. This project implements a chat system which authorizes a user into the application using facial authentication. The user messages are encoded using cryptographic algorithms. In case of sending a secret message, only the user, whose face matches with that at the time of sign-up can view the message. This feature is implemented using Machine Learning algorithms.",https://ieeexplore.ieee.org/document/9753712/,2022 6th International Conference on Computing Methodologies and Communication (ICCMC),29-31 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SPMB47826.2019.9037834,Fast Automatic Artifact Annotator for EEG Signals Using Deep Learning,IEEE,Conferences,"Electroencephalogram (EEG) is a widely used non-invasive brain signal acquisition technique that measures voltage fluctuations from neuron activities of the brain. EEGs are typically used to diagnose and monitor disorders such as epilepsy, sleep disorders, and brain death and also to help the advancement of various fields of science such as cognitive science, and psychology. EEG signals usually suffer from a variety of artifacts caused by eye movements, chewing, muscle movements, and electrode pops, which disrupts the diagnosis and hinders precise representation of brain activities. This paper proposes a deep learning based model to detect the presence of the artifacts and to classify the kind of the artifact to help clinicians resolve problems regarding artifacts immediately during the signal collection process. The model is optimized to map the 1-second segments of raw EEG signals to detect 4 different kinds of artifacts and the real signal. The model achieves a 5-class classification accuracy of 67.59%, and a true positive rate of 80% with a 25.82% false alarm for binary artifact classification with time-lapse. The model is lightweight and could potentially be deployed in portable machines.",https://ieeexplore.ieee.org/document/9037834/,2019 IEEE Signal Processing in Medicine and Biology Symposium (SPMB),7-7 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CANOPIEHPC54579.2021.00007,Feasibility of Running Singularity Containers with Hybrid MPI on NASA High-End Computing Resources,IEEE,Conferences,"This work investigates the feasibility of a Singularity container-based solution to support a customizable computing environment for running users' MPI applications in “hybrid” MPI mode-where the MPI on the host machine works in tandem with MPI inside the container-on NASA's High-End Computing Capability (HECC) resources. Two types of real-world applications were tested: traditional High-Performance Computing (HPC) and Artificial Intelligence/Machine Learning (AI/ML). On the traditional HPC side, two JEDI containers built with Intel MPI for Earth science modeling were tested on both HECC in-house and HECC AWS Cloud CPU resources. On the AI/ML side, a NVIDIA TensorFlow container built with OpenMPI was tested with a Neural Collaborative Filtering recommender system and the ResNet-50 computer image system on the HECC in-house V100 GPUs. For each of these applications and resource environments, multiple hurdles were overcome after lengthy debugging efforts. Among them, the most significant ones were due to the conflicts between a host MPI and a container MPI and the complexity of the communication layers underneath. Although porting containers to run with a single node using just the container MPI is quite straightforward, our exercises demonstrate that running across multiple nodes in hybrid MPI mode requires knowledge of Singularity, MPI libraries, the operating system image, and the communication infrastructure such as the transport and network layers, which are traditionally handled by support staff of HPC centers and hardware or software vendors. In conclusion, porting and running Singularity containers on HECC resources or other data centers with similar environments is feasible but most users would need help to run them in hybrid MPI mode.",https://ieeexplore.ieee.org/document/9652607/,2021 3rd International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC),14-14 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCST50977.2020.00021,Food object recognition and intelligent billing system based on Cascade R-CNN,IEEE,Conferences,"With the development of information technology and artificial intelligence, using science and technology to change the low efficiency of the catering industry is a very effective means. The existing system of food identification and intelligent billing in the market includes artificial billing, RFID induction, photo recognition, etc. Based on the Cascade R-CNN algorithm and computer vision technology, this paper proposes an intelligent food identification and intelligent billing system. First, the database is created for algorithm training, then the mobile device is used to collect the food image, and the depth neural network is used to identify the food in the image. Finally, the price calculation result of each is found and returned to the user. In this paper, the basic principle and implementation method of the system are described in detail, and the experimental phenomenon is analyzed. The experimental results show that the system has good accuracy.",https://ieeexplore.ieee.org/document/9262826/,2020 International Conference on Culture-oriented Science & Technology (ICCST),28-31 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/NCCC49330.2021.9428820,FoodieCal: A Convolutional Neural Network Based Food Detection and Calorie Estimation System,IEEE,Conferences,"According to recent studies across the world, we can see that a healthy diet is the key to having a sound health and body. People nowadays are more concerned with their diets than ever before. With the advancement of science, it is now viable to construct a unique food identification system for keeping track of day to day calorie intake. However, building this kind of system creates several complications on constructing and implementing the model. In our paper, we have developed a new neural network based model which will predict the food items from a given image and show us the estimated calorie of the detected food items. In order to achieve our goal, we have prepared a dataset of around 23000 images for 23 different food categories. For this, we have built a system which can detect multiple foods by training CNN with features extracted by Inception V3. We have achieved 89.48% accuracy for this model and we deployed our system on a webpage. The user has to upload an image of food item in the webpage and our system will predict the food item along with the estimated calories in real time.",https://ieeexplore.ieee.org/document/9428820/,2021 National Computing Colleges Conference (NCCC),27-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RTSE.1998.766514,Formal methods in the classroom: the logic of real-time software design,IEEE,Conferences,"In recent years, much progress has been made towards the development of mathematical methods (""formal methods"") through which it is possible, in principle, to specify and design software to conform to specifications. In this paper, we provide an overview of how formal methods-and particularly real-time formal methods-can be used throughout the software development cycle, and what methods and tools can be introduced in the computer science curriculum to support software development.",https://ieeexplore.ieee.org/document/766514/,Proceedings Real-Time Systems Education III,21-21 Nov. 1998,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMULT.2010.5629720,Framework and Key Technologies for the Construction of a Virtual Mine,IEEE,Conferences,"The application of virtual reality technology is a trend that holds considerable promise as demonstrated in many applications. This technology includes the means to visually integrate and interact with diverse multidimensional data in 3D and time context, extend real-time decision-making into mine maintenance, implement virtual mine-planning simulations, training simulations, and risk management. Virtual mine is the result of integrating various disciplines including mine science, information science, artificial intelligence, computer science and 3S techniques, which will radically change the traditional mine production and our lifestyles. The functions and main characters of virtual mine are analyzed. A framework for a virtual mine operation system is provided. Key techniques concerned in the implementation of virtual mine are discussed in detail. The future development of virtual mine is prospected.",https://ieeexplore.ieee.org/document/5629720/,2010 International Conference on Multimedia Technology,29-31 Oct. 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCI-CC.2014.6921432,From information revolution to intelligence revolution: Big data science vs. intelligence science,IEEE,Conferences,"The hierarchy of human knowledge is categorized at the levels of data, information, knowledge, and intelligence. For instance, given an AND-gate with 1,000-input pins, it may be described very much differently at various levels of perceptions in the knowledge hierarchy. At the data level on the bottom, it represents a 21,000 state space, known as `big data' in recent terms, which appears to be a big issue in engineering. However, at the information level, it just represents 1,000 bit information that is equivalent to the numbers of inputs. Further, at the knowledge level, it expresses only two rules that if all inputs are one, the output is one; and if any input is zero, the output is zero. Ultimately, at the intelligence level, it is simply an instance of the logical model of an AND-gate with arbitrary inputs. This problem reveals that human intelligence and wisdom are an extremely efficient and a fast convergent induction mechanism for knowledge and wisdom elicitation and abstraction where data are merely factual materials and arbitrary instances in the almost infinite state space of the real world. Although data and information processing have been relatively well studied, the nature, theories, and suitable mathematics underpinning knowledge and intelligence are yet to be systematically studied in cognitive informatics and cognitive computing. This will leads to a new era of human intelligence revolution following the industrial, computational, and information revolutions. This is also in accordance with the driving force of the hierarchical human needs from low-level material requirements to high-level ones such as knowledge, wisdom, and intelligence. The trend to the emerging intelligent revolution is to meet the ultimate human needs. The basic approach to intelligent revolution is to invent and embody cognitive computers, cognitive robots, and cognitive systems that extend human memory capacity, learning ability, wisdom, and creativity. Via intelligence revolution, an interconnected cognitive intelligent Internet will enable ordinary people to access highly intelligent systems created based on the latest development of human knowledge and wisdom. Highly professional systems may help people to solve typical everyday problems. Towards these objectives, the latest advances in abstract intelligence and intelligence science investigated in cognitive informatics and cognitive computing are well positioned at the center of intelligence revolution. A wide range of applications of cognitive computers have been developing in ICIC [http://www.ucalgary.ca/icic/] such as, inter alia, cognitive computers, cognitive robots, cognitive learning engines, cognitive Internet, cognitive agents, cognitive search engines, cognitive translators, cognitive control systems, cognitive communications systems, and cognitive automobiles.",https://ieeexplore.ieee.org/document/6921432/,2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing,18-20 Aug. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCAD45719.2019.8942082,High-performance Hardware Architecture for Tensor Singular Value Decomposition: Invited Paper,IEEE,Conferences,"Tensor provides a brief and natural representation for large-scale multidimensional data by way of appropriate low-rank approximations, thus we can discover significant latent structures of complex data and generalize data representation. To date, tensor has gained tremendous success in various science and technology fields, especially in machine learning and big data applications. However, tensor computation, especially tensor decomposition, is usually expensive due to the inherent large-size characteristic of tensors, and hence would potentially hinder their future wide deployment. In this paper, we develop a hardware architecture to accelerate tensor singular value decomposition (t-SVD), which is a new tensor decomposition technique that has been successfully applied to high-dimensional data classification and video recovery. Specifically, design consideration of each key computing unit is analyzed and discussed. Then, the proposed t-SVD hardware architecture is implemented and synthesized using CMOS 28nm technology. Comparison with real-world CPU-based implementations shows that the proposed hardware accelerator is expected to provide average 14× speedup on various t-SVD workloads.",https://ieeexplore.ieee.org/document/8942082/,2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),4-7 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSEI50228.2020.9142534,How to Use Stock Data for Data Science Education: A Simulated Trading Platform in Classroom,IEEE,Conferences,"The research hereby presents an innovate practice to enhance data science education by integrating an in-house-developed stock trading platform. Students of Data Science area usually face the difficulty of understanding the complex of real-time data and sophisticated statistical indicators and models. Another difficulty is students are easy to lost interests and patience during the process of learning programming and analysis process, such as R-language. Stock market, as a huge data source and an important data disciplinary, is comparatively easy to attract student attentions. Thus, we developed an intuitive trading platform for education purpose. The platform contains three components: an exploring window, a control windows and a report window. The exploring window shows current and historical stock price trends and related indicators. Several representative stocks from different sectors can be picked and specific time frames can be assigned. The control window allows students to develop their own trading strategies. A trading strategy can be created by either intuitive way, or through single or combinations of indicators, or be built generically though plug-in R-programing module. The report window demonstrates the expected return of a stock in a specific time frame through a specific strategy. A more comprehensive report with detailed transaction information is also provided for back-testing purpose. Students are involved into the development of the software and get experience for R-programming. Preliminary version of the product has been tested and surveyed in a data science classroom. About ten junior Data Science students have practiced and provided feedback. The positive survey results show the feasibility of the approach. In the future, artificial intelligent component will be integrated into the platform.",https://ieeexplore.ieee.org/document/9142534/,2020 IEEE 2nd International Conference on Computer Science and Educational Informatization (CSEI),12-14 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AISP53593.2022.9760596,Human Activity Recognition with Privacy Preserving using Deep Learning Algorithms,IEEE,Conferences,"Human activity recognition is an extensively researched topic in the field of computer vision. Recognizing human activities without revealing a person&#x2019;s identity is one such use case. To solve this, we propose a practical method for human activity recognition (HAR) while maintaining anonymity. It captures and distributes data from a variety of sources while respecting the privacy of the individuals concerned. At the core of our approach is (DBN-RGMAA) based on deep neural networks, which are not only more accurate but can also be deployed in real-time video surveillance systems. Hence, this work presents a deep learning-based scheme for privacy-preserving human activities. Initially, for extracting the features from raw video data, a Deep Belief Network (DBN) is used. To increase the HAR identification rate, Hybrid Deep Fuzzy Hashing Algorithm (HDFHA) is employed to capture dependencies between two actions. Finally, the privacy model enhances the privacy of humans while permitting a highly accurate approach towards action recognition by the Recursive Genetic Micro-Aggregation Approach (RGMAA). The implementation is executed and the performances are evaluated by Accuracy, Precision, Recall, and F1 Score. A dataset named HMDB51 is used for empirical study. Our experiments using the Python data science platform reveal that the OPA-PPAR outperforms existing methods.",https://ieeexplore.ieee.org/document/9760596/,2022 2nd International Conference on Artificial Intelligence and Signal Processing (AISP),12-14 Feb. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DEST.2010.5610664,Hybrid ontologies and social semantics,IEEE,Conferences,"Semantic Web, Social Web, and new economic challenges are causing major shifts in the pervasive fabric that the internet has become, in particular for the business world. The internet's new role as participatory medium and its ubiquity lead to dense tri-sortal communities of humans and businesses mixed with computer systems, and semantically interoperating in a well-defined sense. Many of the challenges and ongoing (r)evolutions appear to produce as yet seemingly contradictory requirements and thus produce potentially very interesting research areas. We argue that linguistics, community-based real world “social” semantics and pragmatics, scalability, the tri-sortal nature of the communities involved, the balance between usability and reusability, and the methodological requirements for non-disruptive adoption by enterprises of the new technologies provide vectors for fundamental computer science research, for interesting new artefacts, and for new valorisations of enterprise interoperability. We posit that one such development will likely result in hybrid ontologies and their supporting social implementation environments -such as semantic wikis- that accommodate the duality and co-existence of formal reasoning requirements inside systems on the one hand and of declarative knowledge manipulation underlying human communication and agreement on the other hand.",https://ieeexplore.ieee.org/document/5610664/,4th IEEE International Conference on Digital Ecosystems and Technologies,13-16 April 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/Cluster48925.2021.00104,Hybrid workflow of Simulation and Deep Learning on HPC: A Case Study for Material Behavior Determination,IEEE,Conferences,"Nowadays, machine learning (ML), especially deep learning(DL) methods, provide ever more real-life solutions. However, the lack of training data is often a crucial issue for these learning algorithms, the performance accuracy of which relies on the amount and the quality of the available data. This is particularly true when applying ML/DL based methods for specific areas e.g. material characteristics identification, as it requires huge cost of time and manual power getting observational data from real life. In the mean while, simulations on HPC have already been commonly used in computational science due to the fact that it has the ability of generating sufficient and noise free data, which can be used for training the ML/DL based models. However, in order to achieve accurate simulation results the input parameters usually have to be determined and validated by a large number of tests. Furthermore, the evaluation and validation of such input parameters for the simulation often require a deep understanding of the domain specific knowledge, software and programming skills, which can in turn be solved by ML/DL based methods. In this paper, a novel hybrid workflow combining a multi-task neural network and the simulation on high performance computers(HPC) is proposed, which can address the problem of data sparsity and reduce the demand for expertise, resources, and time in determining the validated parameters for simulation. This work is demonstrated through experiments on determination of material behaviors, and the results prove a promising performance (MSE = 0.0386) through this workflow.",https://ieeexplore.ieee.org/document/9556083/,2021 IEEE International Conference on Cluster Computing (CLUSTER),7-10 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC.2018.00073,IT Professional 20th Anniversary Panel: The New Realities of AI,IEEE,Conferences,"Summary form only given, as follows. A complete record of the panel discussion was not made available for publication as part of the conference proceedings. Artificial intelligence (AI) is now creating a lot of excitement and hype among professionals and across all kinds of business and industry, as well as among individuals. It is no longer just the theme of science fiction essays and movies. It is emerging as new, innovative approach for solving challenging problems that we encounter in practice, and as an enabler of disruptive innovations and smarter world. AI’s renaissance is driven by recent complementary developments, including major advances in the AI arena, realistic expectations, and recent success in its applications. AI is also raising some major concerns, real and perceived. Nevertheless, AI is trending to become a new normal and is increasingly being adopted in many applications despite its concerns and limitations. This panel will examine the new realities of AI and offer its perspectives and recommendations. It’ll deliberate on: Where is AI headed? What new applications and innovations will emerge, and how they might impact? What are the risks and concerns? How we can leverage AI for good, and address its major risks and concerns? How do we get prepared for the new AI age?",https://ieeexplore.ieee.org/document/8377698/,2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC),23-27 July 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HPEC43674.2020.9286139,Identifying Execution Anomalies for Data Intensive Workflows Using Lightweight ML Techniques,IEEE,Conferences,"Today's computational science applications are increasingly dependent on many complex, data-intensive operations on distributed datasets that originate from a variety of scientific instruments and repositories. To manage this complexity, science workflows are created to automate the execution of these computational and data transfer tasks, which significantly improves scientific productivity. As the scale of workflows rapidly increases, detecting anomalous behaviors in workflow executions has become critical to ensure timely and accurate science products. In this paper, we present a set of lightweight machine learning-based techniques, including both supervised and unsupervised algorithms, to identify anomalous workflow behaviors. We perform anomaly analysis on both workflow-level and task-level datasets collected from real workflow executions on a distributed cloud testbed. Results show that the workflow-level analysis employing k-means clustering can accurately cluster anomalous, i.e. failure-prone and poorly performing workflows into statistically similar classes with a reasonable quality of clustering, achieving over 0.7 for Normalized Mutual Information and Completeness scores. These results affirm the selection of the workflow-level features for workflow anomaly analysis. For task-level analysis, the Decision Tree classifier achieves >80% accuracy, while other tested classifiers can achieve >50% accuracy in most cases. We believe that these promising results can be a foundation for future research on anomaly detection and failure prediction for scientific workflows running in production environments.",https://ieeexplore.ieee.org/document/9286139/,2020 IEEE High Performance Extreme Computing Conference (HPEC),22-24 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAACI50733.2020.00040,Image Segmentation Technology and Its Application in Digital Image Processing,IEEE,Conferences,"With the development of electronic technology, computer software and hardware technology, image processing and technology related to human vision, the technology of machine vision image processing has also achieved rapid development. With the rapid development of science and technology, digital image processing technology has been widely used in various fields, among which image segmentation is an extremely important technology. Image segmentation is an important intermediate technology in digital image processing. It relies on the underlying technology of image digital processing to serve high-level applications such as pattern recognition. Processing the information interaction between machine and the real world is the first step in the study of artificial intelligence, and the goal of computer vision research is to make the computer have the ability to perceive and understand image information similar to human. This paper expounds the basic principle of image segmentation technology, analyzes and discusses the methods of image segmentation, and studies the application of image segmentation technology in digital image processing.",https://ieeexplore.ieee.org/document/9355361/,2020 International Conference on Advance in Ambient Computing and Intelligence (ICAACI),12-13 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/NetCIT54147.2021.00088,Implementation of Recruitment Website Data Analysis System Based on Web Crawler,IEEE,Conferences,"With continuous development of science and technology, China is in the era of big data. In order to extract useful information from massive data, we must use data analysis system. The data analysis system greatly improves the use efficiency of data, and can get the hidden information in the data through the analysis of some complex data. This topic designs a recruitment website data analysis system based on web crawler, uses web crawler to collect the recruitment information in the recruitment website, analyzes the recruitment information, and finally displays the relevant information. The system uses the proceptron algorithm in deep learning to realize the salary prediction function for job seekers. In this system, the crawler function is written in Python language, and multi-threaded, anti-crawler and other technologies are used to crawl the data of the recruitment website. The application of this system can extract, store, analyze and display the complex and diverse recruitment information in the recruitment website, so that job seekers can more comprehensively understand the post information and find the most suitable job.",https://ieeexplore.ieee.org/document/9731330/,"2021 International Conference on Networking, Communications and Information Technology (NetCIT)",26-27 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCES51350.2021.9489023,Information Detection in Brain Using Wavelet Features and K-Nearest Neighbor,IEEE,Conferences,"Brain signals provide information about the various activities happening in brain at the time of occurrence of different events. Information specifically known to a person can be assessed using electroencephalogram (EEG) signals. Recognition of specific domain knowledge can be useful for screening individuals by job placement and law enforcement agencies. An individual possessing specific domain knowledge in real life can benefit the society with his/her knowledge and can be distinguished from the individuals possessing no domain knowledge. There is a huge demand of computer science professionals in information technology organizations, government institutions, security agencies, research laboratories, and private organizations. Hence, in the present work it is proposed to detect the knowledge of computer science in the subjects using brain signals. The text stimuli related to computer science domain was presented to the participants on a computer screen. Wavelet decomposition was used to extract features in the delta frequency band of EEG signals. Principal component analysis (PCA) gives reduced dimensionality of wavelet features and leads to better classification than the original features. It is observed that k-nearest neighbor (k-NN) classifier performs significantly better than other classifiers with a classification accuracy of 80%. These results show the efficacy and easy implementation of wavelet features with k-NN classifier in effectively recognizing the experts of a particular field.",https://ieeexplore.ieee.org/document/9489023/,2021 6th International Conference on Communication and Electronics Systems (ICCES),8-10 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/Inforino53888.2022.9782936,Instrumental Software Environment for Teaching Students the Technology of Designing Intelligent Decision Support Systems,IEEE,Conferences,"The transition to the ""Digital economy"" requires training of specialists in the field of modern information technologies using artificial intelligence. The National Research University ""Moscow Power Engineering Institute"" in a department of ""Applied Mathematics and Computer Science"" in the master's program ""Artificial Intelligence"" provides training of students in methods and tools for designing intelligent systems, including their most complex representatives &#x2013; intelligent decision support systems in real time. This paper considers the application of the Decision-making Modeling System developed at the Department of Applied Mathematics and Artificial Intelligence, used by students when performing laboratory classes in the disciplines ""Methods and decision support systems"" and ""Intelligent decision support systems"".",https://ieeexplore.ieee.org/document/9782936/,2022 VI International Conference on Information Technologies in Engineering Education (Inforino),12-15 April 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCP.2018.8516592,Intelligent Decision Support for Pervasive Home Monitoring and Assisted Living,IEEE,Conferences,"The current trend of population ageing leads to an increasingly larger population of older adults, who understandabl desire to continue living an independent and fulfilling life in their home and within their communities. While traditionally seen as a societal issue, we are currently at a point where advancement in science and technology enables us to augment human help with ambient assisted living solutions. This paper is the result of research and development undertaken within the framework of a European Union research project targeting the development of a cyber-physical system for assisted living and home monitoring. The system integrates an unobtrusive networkof wireless sensors with server software to provide ambient monitoring, location detection and real-time alerting. The present paper is focused on the system's intelligent software components.The first is a business rules engine that can be configured to send real-time alerts in the case of certain ambient conditions or whe the location of the monitored person shows signification alteration from their usual movement patterns. The second component is a artificial intelligence-based location predictor, used to provide the monitored person's location. Discrepancies between actual an expected location are used by the rule engine to trigger real-time alerts to caregivers.",https://ieeexplore.ieee.org/document/8516592/,2018 IEEE 14th International Conference on Intelligent Computer Communication and Processing (ICCP),6-8 Sept. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/APPEEC.2009.4918442,Intelligent Implementation Technologies on Sensing Dam Safety Based on Neural Network,IEEE,Conferences,"The equipments on sensing dam safety works usually under extremely bad working conditions. The reliability, stability and accuracy, etc, are very difficult to be guaranteed. The signal is sensitive to noise. The fault is often caused. Micro-electronics technology, computer science and artificial intelligence technologies provide strong technical support and security on improving the shortage of technologies on sensing dam safety, raising the level of automation, intelligent of dam safety monitoring. The Artificial Neural Network (ANN) has strong nonlinear fitting ability, learning function and parallel processing ability. Above excellent features of ANN are used to implement the adaptive suppression for noise and self-diagnosis for faults of sensors. The intelligent principle, method and realization way are presented. The constitution and training algorithm of an adaptive neural network filter are proposed. With this filter, the useful quantitative information can be extracted automatically from noise data. The information can describe the characteristics of detected objects. A fault diagnosis method of nonlinear observer is proposed. The nonlinear dynamic relation between input and output of the system can be obtained by use of the learning function of radial basis function neural network. The error can be calculated and the logical judgment can be made in real time with the proposed observer.",https://ieeexplore.ieee.org/document/4918442/,2009 Asia-Pacific Power and Energy Engineering Conference,27-31 March 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GCCE.2015.7398635,Intelligent control of USM using a modified NN with PSO,IEEE,Conferences,"As aging society problem goes severe In not only Japan but also the whole world, more and more attentions are attracted to the social and welfare fields. Many researches on science and technology for elders are implemented in rencent years. With the background, there are a lot of needs for techonologies with novel features for improvement. In this paper, a control method with attractive features for the actuator of Ultrasonic Motors (USMs) is introduced. In medical and welfare areas, the USMs are expected to play more important roles owing to their special characteristics. In this research, an intelligent PID control method using Neural Network (NN) combined with type Particle Swarm Optimization (PSO) is developed for the control of USM. In the method, the intelligent controller is designed based on variable gain type PID control using NN. The learning of the NN unit is implemented by the PSO. The gains of PID control are adjusted by the proposed method in real-time. The effectiveness of the method is verified by experimental results.",https://ieeexplore.ieee.org/document/7398635/,2015 IEEE 4th Global Conference on Consumer Electronics (GCCE),27-30 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2018.8508264,Interactive Kernel Dimension Alternative Clustering on GPUs,IEEE,Conferences,"Machine learning has seen tremendous growth in recent years thanks to two key advances in technology: massive data generation and highly-parallel accelerator architectures. The rate that data is being generated is exploding across multiple domains, including medical research, environmental science, web-search, and e-commerce. Many of these advances have benefited from emergent web-based applications, and improvements in data storage and sensing technologies. Innovations in parallel accelerator hardware, such as GPUs, has made it possible to process massive amounts of data in a timely fashion. Given these advanced data acquisition technology and hardware, machine learning researchers are equipped to generate and sift through much larger and complex datasets quickly. In this work, we focus on accelerating Kernel Dimension Alternative Clustering algorithms using GPUs. We conduct a thorough performance analysis by using both synthetic and real-world datasets, while also modifying both the structure of the data, and the size of the datasets. Our GPU implementation reduces execution time from minutes to seconds, which enables us to develop a web-based application for users to, interactively, view alternative clustering solutions.",https://ieeexplore.ieee.org/document/8508264/,2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),28-31 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CIMCA.2006.133,International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce - Title,IEEE,Conferences,"The following topics are dealt with: intelligent agents and ontologies; data mining, knowledge discovery and decision making; intelligent systems; Web technologies and Web services; virtual reality and games; image processing and image understanding techniques; adaptive control and automation; modelling, prediction and control; multi-agent systems and computational intelligence; agent systems, personal assistant agents and profiling; fuzzy systems for industrial automation; control strategies; neural network applications; clustering, classification, data mining and risk analysis; dynamics systems; innovative control systems, hardware design and implementation; robotics and automation; e-business, e-commerce, innovative Web applications; Web databases; diagnosis and medical applications; learning systems; optimization, hybrid systems, genetic algorithms and evolutionary computation control applications; online learning and ERP; knowledge acquisition and classification; nanomechatronics; simulation and control; mobile network applications; information retrieval; Bayesian networks; human computer interaction; cognitive science; mobile agents; knowledge management; intelligent control; e-search and navigation; security.",https://ieeexplore.ieee.org/document/4052645/,2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06),28 Nov.-1 Dec. 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1049/icp.2022.0311,Introducing self-sustainable cloud platform for data management and extraction of actionable knowledge for smart healthcare industry: a COVID-19 case study,IET,Conferences,"The novel COVID-19 is a highly contagious disease. Data scientists worldwide are attempting to respond to the pandemic by building Artificial Intelligence (AI) solutions like forecasting pandemic growth, speculating possible mutations, identifying the symptoms caused, and many more. The models require vast quantities of data to make predictions. For a newly identified virus, it may take many months or sometimes years to collect related data and prepare it for data analysis purposes, which can further delay the process of making AI solutions. Hence, there is a need for a pipeline system which can facilitate a quick transmission of medical data from healthcare providers to data scientists. This paper proposes a cloud computing platform that allows smart cities to respond to the pandemic faster, with the collaboration of public health centers and data scientists. The platform provides a structured way of identifying and utilizing collaboration opportunities between health centers and the data science community, generating actionable knowledge. The system consists of two parts: 1) The software on the hospital's side, allowing real-time data gathering and automated uploading to cloud servers, 2) The cloud system to facilitate data storing along with model building and deploying. Customers can use the deployed models on a prepaid basis, the money collected will be divided among data scientists and data providers. This unique feature ensures the healthy participation of data providers in the process of making healthcare solutions for the smart cities. A sponsor can also sponsor a project. Hence, the system will sustain on its own with the involvement of stakeholders.",https://ieeexplore.ieee.org/document/9770607/,4th Smart Cities Symposium (SCS 2021),21-23 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IEEM45057.2020.9309776,Job Shop Scheduling Problem Neural Network Solver with Dispatching Rules,IEEE,Conferences,"Job Shop Scheduling Problem (JSSP) is an optimization problem in computer science and operations research. Many problems in real-world manufacturing processes can be translated into JSSP. In recent years, Machine Learning has shown great promises in solving optimization problems and can be used to solve JSSP instances. In this paper, an Artificial Neural Network (ANN) was designed and trained to solve JSSP instances using the priority of the operations as the learning output. Dispatching rules were implemented to break ties during the decoding of the priorities. Our experiment results showed that a hybrid algorithm that combines the best of ANN with dispatching rules and standalone dispatching rule-based heuristic outperforms previously reported results.",https://ieeexplore.ieee.org/document/9309776/,2020 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM),14-17 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCPCT.2013.6529027,Knowledge representation: Predicate logic implementation using sentence-type for natural languages,IEEE,Conferences,"Representing the content of the text is really an important issue of knowledge representation. Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human languages. It processes the data through lexical analysis, Syntax analysis, Semantic analysis, Discourse processing, Pragmatic analysis. This paper compares various knowledge representation schemes. The algorithm in this paper splits the English sentences into phrases and then represents these in predicate logic by considering the types of sentences (Simple, Interrogative, Exclamatory, Passive etc.). The algorithm has been tested on real sentences of English. The algorithm has achieved an accuracy of 75%. This representation would be used in future for Semantic based Text summarization.",https://ieeexplore.ieee.org/document/6529027/,"2013 International Conference on Circuits, Power and Computing Technologies (ICCPCT)",20-21 March 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SSCI44817.2019.9002803,Learning of Multivariate Beta Mixture Models via Entropy-based component splitting,IEEE,Conferences,"Finite mixture models are progressively employed in various fields of science due to their high potential as inference engines to model multimodal and complex data. To develop them, we face some crucial issues such as choosing proper distributions with enough flexibility to well-fit the data. To learn our model, two other significant challenges, namely, parameter estimation and defining model complexity have to be addressed. Some methods such as maximum likelihood and Bayesian inference have been widely considered to tackle the first problem and both have some drawbacks such as local maxima or high computational complexity. Simultaneously, the proper number of components was determined with some approaches such as minimum message length. In this work, multivariate Beta mixture models have been deployed thanks to their flexibility and we propose a novel variational inference via an entropy-based splitting method. The performance of this approach is evaluated on real-world applications, namely, breast tissue texture classification, cytological breast data analysis, cell image categorization and age estimation.",https://ieeexplore.ieee.org/document/9002803/,2019 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2018.00055,Legal Reasoning in Answer Set Programming,IEEE,Conferences,"Answer Set Programming is a declarative problem solving approach, initially tailored to modelling problems in the area of Knowledge Representation and Reasoning. In this article, we provide a knowledge-based system, capable of representing and reasoning about legal knowledge in the context of Answer Set Programming - thus, modelling non-monotonicity that is inherent in legal arguments. The work, although limited to a specific indicative domain, namely, university regulations, has a variety of extensions. The overall approach constitutes a representative implementation of the Answer Set Programming's modelling methodology, as well as an enhancing of the bond between Artificial Intelligence and Legal Science, bringing us a step closer to a successful development of an automated legal reasoning system for real-world applications.",https://ieeexplore.ieee.org/document/8576053/,2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI),5-7 Nov. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2012.81,Lessons Learned from Collaborative Research in Software Engineering: A Student's Perspective,IEEE,Conferences,"Time zone, different work schedule, limited real-time information sharing, steep learning curve and different personal specialties, these are common limitations in the collaborative studies, especially when a researcher has just been introduced to the research field or working in a different environment (i.e. Internship programs). This paper introduces you with the experiences, challenges, difficulties, lessons learned, common fallacies and pitfalls in the collaborative software engineering research through the experience of 2-months collaborative research program between Kasetsart University in Thailand and Nara Institute of Science and Technology in Japan. Good mentoring and flat-style communication between professors and students are good indicators of the high quality result in the internship program. These information can be useful to professors, young researchers and internship students who will be conducting researches in such manner.",https://ieeexplore.ieee.org/document/6299327/,"2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",8-10 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PDP50117.2020.00041,Lessons learned from comparing C-CUDA and Python-Numba for GPU-Computing,IEEE,Conferences,"Python as programming language is increasingly gaining importance, especially in data science, scientific, and parallel programming. It is faster and easier to learn than classical programming languages such as C. However, usability often comes at the cost of performance and applications written in Python are considered to be much slower than applications written in C or FORTRAN. Further, it does not allow the usage of GPUs-besides of pre-compiled libraries.However, the Numba package promises performance similar to C code for compute intensive parts of a Python application and it supports CUDA, which allows the use of GPUs inside a Python application.In this paper we compare the performance of Numba-CUDA and C -CUDA for different kinds of applications. For compute intensive benchmarks, the performance of the Numba version only reaches between 50% and 85% performance of the CCUDA version, despite the reduction operation, where the Numba version outperforms CUDA. Analyzing the PTX code and CUDA performance counters revealed that index-calculation is one limiting factor in Numba. Another problem is the type interference for single precision computations, as some values are computed in double precision. By optimizing this within the Numba package, the performance of Numba improves. However, C-CUDA applications still outperform the Numba versions. Further analysis with the CloverLeav Mini App shows that Numba performance further decreases for applications with multiple different compute kernels. The non-GPU part slows down these applications, due to the slow Python interpreter. This leads to a worse GPU utilization.Today Python is widely used in industry and academia and has been the first choice of coding languages among software programmers in the last years. Currently, according to the TIOBE index [5], it is the 3rd most popular programming language and the number one in IEEE Spectrum's fifth annual interactive ranking of the top programming languages [4]. One reason for this is that is easier to learn than classical programming languages like C. However, the other reason is the increasing popularity of Data Science, where Python is the most used language. A collection of libraries such as NumPy [22], and Matplotlib [1] or Scipy [8] provide a rich set of functions for scientific computing [16]. Packages like Dask [19], PyCompss [21] and MPI for Python [6] allow running Python applications on large, parallel machines, promising high performance. However, the performance of Python is considered slow compared to compiled languages such as C, C++, and FORTRAN, especially for heavy computations. In recent years, more and more tools have been developed to counter this prejudice. Numpy [22], for example, uses C-like arrays to store data and offers fast functions implemented in C to speed up calculations. The CuPy [14] package provides a similar set of functions, but these functions are implemented for GPUs using CUDA. The SciPy library is based on NumPy and provides a rich set on functionalities for scientific computing. Still, the high performance of these libraries is provided by the underling C-implementations. Internally, they use libraries like OpenBlas or IntelMKL to reach high performance and therefore, they are limited by the functions which are provided by theses libraries. Therefore, a performance problem always arises when the required functionality is not implemented within these libraries. In this case, the application falls back to the Python interpreter. Compared to ""bare metal"" code, interpreted code is slow. In addition, in Python it is not possible to use GPUs or other accelerators directly, as the Python interpreter cannot execute code on these machines. Therefore, the usage is only possible with precompiled libraries. To overcome this limitation, different approaches where developed to mix C, CUDA or OpenCL with Python. Cython [2] allows integrating C-code in Python applications to improve performance of critical sections. It also allows an easy development of wrappers for C-libraries. Similar, packages such as PyCuda and PyOpenCL [9] support wrappers for CUDA or OpenCL code within a Python script. Both approaches require the mixture of different programming languages.Numba [10] follows a different approach. Instead of merging C/CUDA code with Python, it allows the development of efficient applications for both, CPUs and GPUs in Python style. When a Python script using Numba is executed, marked functions are compiled just-in-time (JIT) using the LLVM framework. Using Python for GPU programming can mean a considerable simplification in the development of parallel applications.But often a simplification of comes at the expense of performance, and one expects a performance loss from Python compared to pure C code. In this paper, we want to understand the differences between native C-CUDA code and CUDA-code written in Python with Numba. We also want to share some basic tips how to improve the performance of applications written in Numba.We will first analyse a few micro benchmarks in detail. We are using these simple benchmarks, as it is easier to understand the differences with small code examples. We will use the collected information to derive some optimization for Numba. Finally, we evaluate and compare the performance of a more application like mini-app, written in C-CUDA and Numba accelerated Python. We will evaluate if our insights from the microbenchmarks to real applications.",https://ieeexplore.ieee.org/document/9092407/,"2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)",11-13 March 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISSC55427.2022.9826147,Log4jPot: Effective Log4Shell Vulnerability Detection System,IEEE,Conferences,"The global digital landscape is changing rapidly with the advances in science and technology. A plethora of new breakthroughs are being made every day in several different fields, such as Internet infrastructure, Web 3.0, and AR/VR technologies. With these ever-increasing digital advancements, cybersecurity threats and vulnerabilities are also being exploited daily. In recent times, another critical vulnerability &#x201C;Log4jshell&#x201D; is identified in the logging tool Log4j. The ubiquity of this logging tool among many worldwide online services has exposed millions of devices to this vulnerability. In order to address this critical issue, the paper presents a framework for improving system security against Log4j attacks. The proposed framework deploys an in-house honeypot to detect and defend against various types of Log4j payloads. Experimental results prove the efficiency and accuracy of Log4j payload detection with an average execution time of 80.104 milliseconds for all utilized HTTP methods. In addition, the paper describes Log4shell vulnerabilities, webhooks, and provides a comparative assessment with previously proposed solutions.",https://ieeexplore.ieee.org/document/9826147/,2022 33rd Irish Signals and Systems Conference (ISSC),9-10 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CONFLUENCE.2019.8776981,Logistic Regression based DFS for Trip Advising Software (ASCEND),IEEE,Conferences,"Graphs have played a pivotal role in the field of computer science and has been an efficient method for representing and modeling abstractions in various fields. They can be used to represent several real life models. Several domains in today's world use the concept of graphs extensively such as GPS Navigation systems, Computer networks, WebCrawler, Social Networking websites, peer to peer networking, medical and biological field, neural networks etc. Taking into account the numerous applications of the concept of graphs in today's world, graph searching becomes inevitably significant. In this scenario it is important to note that several graph searching algorithms that were proposed to give exhaustive searches doesn't provide the most satisfying outcome in terms of asymptotic time complexity. Through this paper we intend to highlight the significance of machine learning as a useful tool that can be incorporated in various graph searching algorithms that can reduce its complexity. We classify the existing graph searching techniques as subsets or modifications of two major conventional graph searching algorithms namely BFS(Breadth First Search) and DFS(Depth First Search) and suggest the application of logistic regression to improve their performance. It is confounding that only few research papers explore the application of machine learning to the aforementioned graph searching algorithms. Hence, it is evident that there exists scope for future research on this topic and we aim to suggest directions for the same.",https://ieeexplore.ieee.org/document/8776981/,"2019 9th International Conference on Cloud Computing, Data Science & Engineering (Confluence)",10-11 Jan. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRAI54018.2021.9651371,Lower Limb Prosthesis Gait Cycle Prediction Analysis Using Gyroscope and Load Cell,IEEE,Conferences,"Prediction of the accurate and continuous ankle angles during gait cycle is a great challenge faced in biomedical science. To overcome this challenge, potential of two sensors i.e., a gyroscope and load cell (strain gauge) in predicting ankle angles and load during a Gait cycle was evaluated. Precision values presented by the gyroscope are 95% accurate however values offered by the load cell have a precision of around 88.2%. In addition to this, the image of the current Gait stance is also displayed in real-time. The results obtained using these sensors proved the ability of the method to be efficient and capable in the prediction of Gait cycle ankle angles. This accuracy model can be further refined as a future work for implementation in balance-based calculations and control of lower limb prosthesis.",https://ieeexplore.ieee.org/document/9651371/,2021 International Conference on Robotics and Automation in Industry (ICRAI),26-27 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DEST.2010.5610637,MADBE: A Multi-Agent Digital Business Ecosystem,IEEE,Conferences,"In this paper we propose MADBE, a Multi-Agent Digital Business Ecosystem. The purpose of this system is to provide a digital software environment for small organisations where they can interact and collaborate with each other and create new joint ventures. We believe that a multidisciplinary approach based on biology, computer science, and business concepts is necessary to produce an evolutionary self-organising system for networked business of small and medium sized enterprises (SMEs). In particular, we propose the first multi-agent digital business ecosystem based on ecological metaphors, which will enable us to define certain characteristics, based on real nature interactions and will also permit us to study the resulting network of businesses from an ecological perspective. An interaction-centred approach based on interaction protocols for knowledge sharing is adopted for the implementation of this system.",https://ieeexplore.ieee.org/document/5610637/,4th IEEE International Conference on Digital Ecosystems and Technologies,13-16 April 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIKE.2018.00015,Machine Learning Models to Enhance the Science of Cognitive Autonomy,IEEE,Conferences,"Intelligent Autonomous Systems (IAS) are highly cognitive, reflective, multitask-able, and effective in knowledge discovery. Examples of IAS include software systems that are capable of automatic reconfiguration, autonomous vehicles, network of sensors with reconfigurable sensory platforms, and an unmanned aerial vehicle (UAV) respecting privacy by deciding to turn off its camera when pointing inside a private residence. Research is needed to build systems that can monitor their environment and interactions, learn their capabilities and limitations, and adapt to meet the mission objectives with limited or no human intervention. The systems should be fail-safe and should allow for graceful degradations while continuing to meet the mission objectives. In this paper, we provide an overview of our proposed new methodologies and workflows, and survey the existing approaches and new ones that can advance the science of autonomy in smart systems through enhancements in real-time control, auto-reconfigurability, monitoring, adaptability, and trust. This paper also provides the theoretical framework behind IAS.",https://ieeexplore.ieee.org/document/8527447/,2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),26-28 Sept. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DSPA53304.2022.9790767,Machine Learning Technologies for Bakery Management Decisions,IEEE,Conferences,"The paper discusses using Deep Stream technologies in tasks for predicting best locations for deployment the bakeries. Such methods provides the calculation of people going through possible bakery and use convolutional neural networks for detection people and some effective algorithms for counting. The proposed solution allows deploying successful bakeries and keeping money in real production. Furthermore a lot of applied data science models were used for data analysis in these conditions. The paper discusses in detail the regression, factorial, cluster and discriminant analysis on the example of real data on the operation of a chain of bakeries with changes to preserve trade secrets. The analysis made it possible to simplify the decision-making process for managers among many factors. Moreover, the proposed method made it possible to predict profitability when opening a new point and explore various models of its development. Comparison results are provided for 3 models. The choice was made in favor of one of them. This choice resulted in the opening of a profitable bakery with a high profit margin for the retail market. The regression, factor and cluster analysis results show good opportunities to apply the results of the analysis for making management decisions when choosing the location of bakeries.",https://ieeexplore.ieee.org/document/9790767/,2022 24th International Conference on Digital Signal Processing and its Applications (DSPA),30 March-1 April 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/SPA.2019.8936736,Machine Learning for Embodied Agents: From Signals to Symbols and Actions,IEEE,Conferences,"The aim of this tutorial lecture is to show the role of machine learning and some other AI-related techniques in embodied autonomous agents, and autonomous robots in particular. In this tutorial we bring to the forefront the aspects of robotics that are closely related to computer science. We believe that the progress in algorithms and data processing methods together with the rapid increase in the available computing power were the driving forces behind the successes of modern robotics in the last decade. During this period robots of various classes migrated from university laboratories to commercial companies and then to our everyday life, as now everybody can buy an autonomous vacuum cleaner or lawnmower, while self-driving cars and drones for goods delivery are waiting for proper legal regulations to enter the market. Robotics and Artificial Intelligence already went a long path of mutual inspiration and common development, starting from the symbolic AI (aka Good Old-Fashioned Artificial Intelligence) and its extensive use in early autonomous robots, such as Shakey the robot, created in SRI International by Nils Nilsson, considered one of the ""fathers"" of modern AI. We briefly characterize the range of the most important applications of typical AI methods in modern robotics, including motion planning algorithms [2,3], interpretation of sensory data leading to creation of a world model [4 ,5], and classical learning methods, such as reinforcement learning [6]. However, what made robotics a part of the new wave of AI applications was the recent ""revolution"" of machine learning, mostly grounded in the enormous success of the deep learning paradigm and its many variants that proved to outclass classic methods in a broad range of problems related to the processing of images and other types of signals. The quick adoption of the recent advances in Machine Learning (ML) in robotics seems to be motivated by the fact that ML gives the possibility to infer solutions from data, as opposed to the classic model-based paradigm that was for decades used in robotics. Whereas the modelbased solutions are mathematically elegant and theoretically provable (with respect to stability, convergence, etc.) they often fail once confronted with real-world problems and real sensory data, as their underlying mathematical models are only a very rough approximation of the real world. Therefore, a wider adoption of ML in robotics gives a chance to make robots more robust and adaptive. On the other hand, we should try to use the new techniques without discarding the knowledge and expertise we already have - machine learning methods can benefit a lot from the prior knowledge and the known structure of the problem that has to be solved by learning. This knowledge and structure can be adopted from the model-based methods that a re already well-established in robotics. In the lecture robots are understood in a broad sense, as all embodied agents that have means to physically interact with the environment. They can be either manipulators, mobile robots, aerial vehicles, self-driving cars, and various ""smart"" devices and sensors. In the second part of the lecture attention is paid to specific problems that appear in application of machine learning to embodied agents, such as the need to search a for solution in huge, multi-dimensional spaces (""curse of dimensionality""), and the ever-present problem of representation and incorporation of uncertainty in the processing of real-world data. Some examples of applications of autonomous robots are given, which were successful due to the use of AI - in particular the probabilistic representation of knowledge and machine learning. The most prominent examples are the DARPA competitions: ""Grand Challenge"", ""Urban Challenge"" and ""Robotics Challenge"" (DRC), and the ""Amazon Picking Challenge"", which proves the interest of large corporations in the development of AI-based robotics [7]. In the third part of the lecture new research directions offered by machine learning and the increased availability of training data are discussed. An overview of the most popular application areas of ML in robotics and other autonomous systems is presented along with the typical machine learning paradigms applied in these areas. The focus is on deep learning, mostly using convolutional neural networks to process various sensory data. We discuss three aspects of embodied agents that make machine learning in robotics quite specific with respect to other application areas, such as medical images or natural language processing. The first aspect is dealing with the ""open world"", in which autonomous robots usually operate. This situation breaks the assumptions underlying some popular ML methods, and creates the need to face the problem of unknown classes identification [8] incremental learning [9], and the uncertainty of sensory data [10]. We also stress out that an embodied agent has the ability to actively acquire information [11]. The second aspect is the inference about the scene seen by the agent, where in the case of robotics, semantics and geometry intermingle [12], because the robot has to work in a three-dimensional world, although it often perceives it through twodimensional images [13,14]. The third aspect of our analysis is related to the most important feature of robots that distinguishes them from all other learning agents (software-based). Robots are embodied agents, that is they have a physical ""body"", and are subject to physical constraints, such as the maximum speed of motion or maximum range of perception. Therefore, in ML for robots analysis of the spatio-temporal dependencies in data is very important [15]. Robots support advanced learning methods thanks to the possibility of interaction with the environment - a simple example is active vision with moving camera, a much more complex one is manipulation with active testing of the behavior of objects (repositioning, pushing) [16]. At the end of the lecture, in the context of specific needs and limitations characteristic to the applications of ML in robotics, new concepts of machine learning (e.g. deep reinforcement learning [17], interactive perception [18]) are presented. The lecture is summarized with a brief discussion of the most important challenges and open problems of ML applied to embodied agents.",https://ieeexplore.ieee.org/document/8936736/,"2019 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)",18-20 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FIE44824.2020.9273981,Machine learning for middle-schoolers: Children as designers of machine-learning apps,IEEE,Conferences,"This Research to Innovative Practice Full Paper presents a multidisciplinary, design-based research study that aims to develop and study pedagogical models and tools for integrating machine-learning (ML) topics into education. Although children grow up with ML systems, few theoretical or empirical studies have focused on investigating ML and data-driven design in K-12 education to date. This paper presents the theoretical grounds for a design-oriented pedagogy and the results from exploring and implementing those theoretical ideas in practice through a case study conducted in Finland. We describe the overall process in which middle-schoolers (N = 34) co-designed and made ML applications for solving meaningful, everyday problems. The qualitative content analysis of the pre-and post-tests, student interviews, and the students' own ML design ideas indicated that co-designing real-life applications lowered the barriers for participating in some of the core practices of computer science. It also supported children in exploring abstract ML concepts and workflows in a highly personalized and embodied way. The article concludes with a discussion on pedagogical insights for supporting middle-schoolers in becoming innovators and software designers in the age of ML.",https://ieeexplore.ieee.org/document/9273981/,2020 IEEE Frontiers in Education Conference (FIE),21-24 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIIoT54504.2022.9817247,Major threats to the continued adoption of Artificial Intelligence in today&#x0027;s hyperconnected world,IEEE,Conferences,"From the golden era of science fiction which dates to the late 1930s, scientific and technological advances in artificial intelligence (AI), along with one of its key subsets, machine learning (ML) have been growing significantly, especially in recent years. In 2021 alone, notable feats included an AI program capable of creating images from seen or previously unseen textual captions, an AI model that effectively integrates computer vision and natural language processing, and a novel AI framework for diagnosing dementia in 24 hours with real-world feasibility underway amongst a host of other fascinating breakthroughs. This paper briefly delves into AI/ML and recaps some key essentials, covering AI and ML subfields, ML methods, industries where AI/ML finds relevance, key stages and the common technical challenges in ML development. Importantly, the paper shifts attention from the latter to underscore the duo of transparency and ethics in AI, highlighting specifically what these are and why they are important, subsequently positing a PESTEL (Political, Economic, Social, Technological, Environmental and Legal) framework for AI design, build and implementation. It is anticipated that the upshot of this would be the facilitation of continuous adoption and long-term sustainability of AI/ML.",https://ieeexplore.ieee.org/document/9817247/,2022 IEEE World AI IoT Congress (AIIoT),6-9 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SmartWorld.2018.00087,Mining the Critical Conditions for New Hypotheses of Materials from Historical Reaction Data,IEEE,Conferences,"The new findings in material science often require a high research cost for the following two aspects. First is that the chemical reaction craft needs continuous optimization and may consume lots of valuable reactants and apparatus during daily experiments. Second, the success of a designed experiment relies heavily on researchers' experience. With the starting of the Materials Genome Initiative (MGI) project, researchers are beginning to record historical reaction data, and seek new solutions via computer techniques, such as data mining and machine learning. In this paper, we study the reaction data of inorganic-organic hybrid materials from the Dark Reaction Project from Haverford College with simple machine learning algorithms (i.e., Bayes Net, SVM and C4.5), ensemble learning models (i.e., Random Forest, Stacking, Gradient Boosting Decision Tree (GBDT) and XGBoost), and deep neural network models. Besides accuracy of the prediction models, we also analyze the reaction conditions that have important reflecting in chemistry with different ranking algorithms. With a series of evaluation, we find that the welldesigned stacking-based ensemble learning model can reach the highest prediction accuracy of 61% (8% higher than GBDT and 5% higher than XGBoost) on the top50 subsets based on 'symmetrical uncertainty ranking' on the standalone data set which was not used in the Dark Reaction Project before.",https://ieeexplore.ieee.org/document/8560065/,"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",8-12 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICNISC54316.2021.00053,Motion Detection and Object Detection: Yolo (You Only Look Once),IEEE,Conferences,"Recently, the field of artificial intelligence has seen many advances thanks to deep learning and image processing. It is now possible to recognize images or even find objects inside an image with a standard GPU. Image processing is a recent science that aims to provide specialists from different areas, as to the general public, tools for manipulating these digital data from the real world. The detection of moving objects is a crucial step for systems based on image processing. The movements detected by the classic algorithms are not necessarily interesting for a thorough information search, and the need to distinguish the coherent movements of parasitic movements exists in most cases. In this paper we are going to use a simply webcam and YOLO algorithm for this implementation. The YOLOv3 (Version 3) model makes predictions with a single network evaluation, making this method extremely fast, running in real time with a capable GPU. From there we&#x0027;ll use OpenCV, Python, and deep learning to apply the YOLOv3 object to images and apply YOLOv3 to video streams.",https://ieeexplore.ieee.org/document/9603899/,2021 7th Annual International Conference on Network and Information Systems for Computers (ICNISC),23-25 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CEC.2019.8789969,Multiobjective memetic algorithm for vital nodes identification in complex networks,IEEE,Conferences,"Vital nodes identification, that is, finding a set of nodes whose absence would cause a collapse of the network, is a significant project in network science. Despite there are a plenty of methods to identify the vital nodes, two major problems still need to be solved, that is how to select these nodes and how to determine the number of them. In this study, we focus on dealing with these two problems via proposing a multiobjective memetic algorithm for vital nodes identification task. First, vital nodes identification task is modeled as a biobjective optimization problem by analyzing the characteristic of vital nodes. Then, a memetic strategy and specific evolutionary operators inspired by multiple centralities are designed to execute local and global search. In addition, a long-tail property is found from the Pareto front of this bi-objective optimization problem, and the simulation results always show an obvious knee region. Hence, an adaptive learning method to determine the size of vital nodes is designed by searching for the knee point. At last, the proposed framework is tested on the scale free networks and real-life networks, and the simulation results validate its effectivity in contrast with the state-of-art greedy methods.",https://ieeexplore.ieee.org/document/8789969/,2019 IEEE Congress on Evolutionary Computation (CEC),10-13 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CEE-SECR.2009.5501170,Neuro-automata based controlling,IEEE,Conferences,"Artificial intelligence - one of the most interesting theoretical and applied areas of computer science. There is a wide range of techniques and approaches for creation of artificial intelligence in the applications and real-time control systems. In this paper, we propose a realization of neuro-automata controlling based on neural networks and automaton paradigm and considering an example of how this paradigm could be used in real application.",https://ieeexplore.ieee.org/document/5501170/,2009 5th Central and Eastern European Software Engineering Conference in Russia (CEE-SECR),28-29 Oct. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COGINF.2006.365669,On Intelligence Science and Recent Progresses,IEEE,Conferences,"Summary form only given. Intelligence science is a cross-discipline that dedicates to joint research on basic theory and technology of intelligence by brain science, cognitive science, artificial intelligence and others. Brain science explores the essence of brain, research on the principle and model of natural intelligence in molecular, cell and behavior level. Cognitive science studies human mental activity, such as perception, learning, memory, thinking, consciousness etc. In order to implement machine intelligence, Artificial intelligence attempts simulation, extension and expansion of human intelligence using artificial methodology and technology. The above three disciplines work together to explore new concept, new theory, new methodology. It will be successful and create a brilliant future in the 21 century. Brain science points out that perceptive lobes have special function separately, the occipital lobe processes the visual information, the temporal lobe processes auditory information, the parietal lobe processes the information from the somatic sensors. All of three lobes deal with information perceived from the physical world. Each lobe is covered with cortex where the bodies of neurons are located. Cortex consists of primary, intermediate and advanced areas at least. Information is processed in the primary area first, then is passed to intermediate and advanced areas. Comparing with computer system, the brain is the same as hardware and the mind looks like software. Most work in cognitive science assumes that the mind has mental representations analogous to computer data structures, and computational procedures similar to computational algorithms. Connectionists have proposed novel ideas to use neurons and their connections as inspirations for data structures, and neuron firing and spreading activation as inspirations for algorithms. Cognitive science then works with a complex 3-way analogy among the mind, the brain, and computers. Mind, brain, and computation can each be used to suggest new ideas about the others. There is no single computational model of mind, since different kinds of computers and programming approaches suggest different ways in which the mind might work. The mind contains perception, rational, consciousness and emotion. The long-term scientific goal of artificial intelligence is human-level intelligence. In this lecture, we will discuss basic research topics related to intelligence science, such as learning, memory, thought, language, consciousness etc. We also report the recent progresses containing: visual perception; introspective learning; linguistic cognition; consciousness model; and platform of agent-grid intelligence",https://ieeexplore.ieee.org/document/4216384/,2006 5th IEEE International Conference on Cognitive Informatics,17-19 July 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IRI.2009.5211603,Ontology-based information model development for science information reuse and integration,IEEE,Conferences,"Scientific digital libraries serve complex and evolving research communities. Justifications for the development of scientific digital libraries include the desire to preserve science data and the promises of information interconnectedness, correlative science, and system interoperability. Shared ontologies are fundamental to fulfilling these promises. We present a tool framework, a set of principles, and a real world case study where shared ontologies are used to develop and manage science information models and subsequently guide the implementation of scientific digital libraries. The tool framework, based on an ontology modeling tool, has been used to formalize legacy information models as well as design new models. Within this framework, the information model remains relevant within changing domains and thereby promotes the interoperability, interconnectedness, and correlation desired by scientists.",https://ieeexplore.ieee.org/document/5211603/,2009 IEEE International Conference on Information Reuse & Integration,10-12 Aug. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2015.7363882,Open research challenges with Big Data — A data-scientist's perspective,IEEE,Conferences,"In this paper, we discuss data-driven discovery challenges of the Big Data era. We observe that recent innovations in being able to collect, access, organize, integrate, and query massive amounts of data from a wide variety of data sources have brought statistical data mining and machine learning under more scrutiny and evaluation for gleaning insights from the data than ever before. In that context, we pose and debate the question - Are data mining algorithms scaling with the ability to store and compute? If yes, how? If not, why not? We survey recent developments in the state-of-the-art to discuss emerging and outstanding challenges in the design and implementation of machine learning algorithms at scale. We leverage experience from real-world Big Data knowledge discovery projects across domains of national security, healthcare and manufacturing to suggest our efforts be focused along the following axes: (i) the `data science' challenge - designing scalable and flexible computational architectures for machine learning (beyond just data-retrieval); (ii) the ` science of data' challenge - the ability to understand characteristics of data before applying machine learning algorithms and tools; and (iii) the `scalable predictive functions' challenge - the ability to construct, learn and infer with increasing sample size, dimensionality, and categories of labels. We conclude with a discussion of opportunities and directions for future research.",https://ieeexplore.ieee.org/document/7363882/,2015 IEEE International Conference on Big Data (Big Data),29 Oct.-1 Nov. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISCID.2016.1055,Path Planning for UUV in Dynamic Environment,IEEE,Conferences,"From naval operations to ocean science missions, the importance of autonomous vehicles is increasing with the advances in underwater robotics technology. Due to the dynamic and intermittent underwater environment and physical limitations of underwater unmanned vehicle (UUV), feasible and optimal path planning is crucial for autonomous underwater operations. According to different mission, the path planning method of UUV is divided into two categories: the point to point path planning and the complete coverage path planning. The objective of this thesis is to develop and demonstrate an efficient underwater path planning method that is adapted to complicated ocean environment. In this thesis, existing path planning method for the fields of ocean science and robotics are first reviewed, and then local dynamic obstacle avoidance method is proposed to avoid dynamic obstacles. Based on this again, the path planning of UUV in local dynamic environment can be efficiently implemented by adopting rolling window path planning method and local dynamic obstacle avoidance method. This method with the guide point strategy combines global path planning with local dynamic path planning, so that not only the requirements of real-time on-line path planning for UUV are met, the global optimality is also considered. A navigation route for UUV is planned in advance by using priori environmental information based on ant colony algorithm, so it provides the reference information for the selection of guide point. In order to solved the problem of area coverage search, a complete coverage path planning method is proposed by combining ant colony algorithm with biologically inspires neural network. In order to demonstrate underwater path planning method, all of the above ideas and methods developed were tested in simulation experiments.",https://ieeexplore.ieee.org/document/7830329/,2016 9th International Symposium on Computational Intelligence and Design (ISCID),10-11 Dec. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CERMA.2006.73,Pedagogical Virtual Agents to Support Training of Human Groups,IEEE,Conferences,"From the last decade, intelligent virtual environments (IVEs) have become a quite popular tool for applying computer science to education. The intelligence of the systems generated using IVEs usually falls on the denominated pedagogical virtual agent. Pedagogical virtual agents have characteristics that allow to increase the computer's ability to engage and motivate students along their learning process. In this paper, a human groups (teams) training strategy is presented, supporting one of its stages by the use of a pedagogical virtual agent playing the role of team leader",https://ieeexplore.ieee.org/document/4019729/,"Electronics, Robotics and Automotive Mechanics Conference (CERMA'06)",26-29 Sept. 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICALT.2004.1357653,Pedagogical embodied conversational agent,IEEE,Conferences,"A virtual reality instructor that autonomously trains a human learner in network virtual environments, respond to multi-modal input across computer networks, and applies proven pedagogical techniques during instruction has the potential to improve human learning performance anytime, anywhere, and at any pace. Building virtual instructors, however, have challenged researchers because of multidisciplinary expertise required in areas such as education, cognitive science, sociology, artificial intelligence, 3D computer graphics, linguistics, and more. This paper discusses a model for building human computer interactive virtual instructor systems using an innovative, system/software architecture.",https://ieeexplore.ieee.org/document/1357653/,"IEEE International Conference on Advanced Learning Technologies, 2004. Proceedings.",30 Aug.-1 Sept. 2004,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISMSIT50672.2020.9254863,Personalized Quality of Experience (QOE) Management using Data Driven Architecture in 5G Wireless Networks,IEEE,Conferences,"the aim of this paper is to Personalized Quality of Experience (QOE) Management using Data driven Architecture in 5G Wireless Networks that consume less resources. The proposed research will be the part of the overall research project, which focuses on addressing a problem that many organizations experience that introduce an Enterprise Architecture to support the integration of different services across the enterprise. With the rapid growth in mobile network usage and video streaming being the most popular service, Quality of Experience of video in mobile networks is of extreme importance to both service providers and their customers. The ability to effectively predict Quality of Experience of video is key for QoE adaptation and higher levels of customer satisfaction. In this work machine learning algorithms were used to create models that predict QoE with network QoS parameters, including wireless-specific and 5Gspecific parameters. An 5G simulation that reflects the current mobile traffic landscape was created to obtain the data set for training. An objective tool for video QoE evaluation was used to gather QoE data necessary to train the prediction models. Support Vector Machines, Random Forest, Gradient Boosted Trees and Neural Networks were chosen as the machine learning algorithms for Quality of Experience prediction, and it was shown that they achieve high accuracy. Influence of wireless-specific parameters on QoE prediction was also investigated, and it was discovered that they are suitable for use in Quality of Experience prediction models.The problem is that; organizations do not know where they either have or may encounter weaknesses in their Enterprise Architecture with Data Driven Architecture (DDA). The framework presented is based on concepts from Wireless Networks with Driven Architecture will be designed to support both Transitional Gap Analysis (TGA) and Comparative Gap Analysis (CGA). TGA is supported by comparing a baseline Data Driven Architecture (DDA) to a target QoE where both DDA have been defined from the management perspective. DDA is facilitated by mapping a QoE to two or more 5G networks. The research methodology used in the paper is design science research for the QoE management based 5G network. The QOE for implementation of 5th generation network and apply it in many different real-world organizations. The goal of the paper is to present a framework in the form an implementation and management model, called QOE, that visualizes the gaps (weaknesses) in proposed or existing enterprise architectures and to support a comparative analysis process for different a5Grnative solution approaches. a set of requirements on the QOE management can be presented and the frameworks are applied on Matlab for implementation.",https://ieeexplore.ieee.org/document/9254863/,2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT),22-24 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNAMS53716.2021.9732126,Point-of-care Ultrasound (POCUS) Device Utilisation at the Edge in Lower and Middle Income Countries,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The genomics revolution in Africa began almost a decade ago to identify genetic and environmental determinants of human disease and wellness. This momentum is accelerating to advance science globally through large initiatives on the continent of Africa, for example, Human Hereditary and Health in Africa (H3Africa), Data Science Initiative for Africa (DSI-Africa), African Open Science Platform (AOSP), and the recent call by the Wellcome Trust (WT) for the setting up African Population Cohort Consortia (APCC) amongst others. All these efforts are aimed at transforming &#x201C;data- poor Africa&#x201D; into a data-rich Africa. We want to tackle multiple SDGs, centred on health and wellness and climate change, for effective policy implementation for maximum impact. To harness these opportunities, we will leverage cutting-edge technologies and innovative methods to deliver better tools for disease diagnosis and prognosis; and novel targeted treatmentand prevention that is suitable for LMICs settings. This talk highlights real-life examples and challenges for incorporating handheld or point of care ultrasound (POCUS) device data into routine healthcare and research participant surveillance, and the opportunities for application of deep learning/AI for aiding clinical decision making leveraging the emerging Mobile fog computing (MFC) approaches.",https://ieeexplore.ieee.org/document/9732126/,"2021 Eighth International Conference on Social Network Analysis, Management and Security (SNAMS)",6-9 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SDS54264.2021.9732135,Point-of-care Ultrasound (POCUS) Device Utilisation at the Edge in Lower and Middle Income Countries,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The genomics revolution in Africa began almost a decade ago to identify genetic and environmental determinants of human disease and wellness. This momentum is accelerating to advance science globally through large initiatives on the continent of Africa, for example, Human Hereditary and Health in Africa (H3Africa), Data Science Initiative for Africa (DSI-Africa), African Open Science Platform (AOSP), and the recent call by the Wellcome Trust (WT) for the setting up African Population Cohort Consortia (APCC) amongst others. All these efforts are aimed at transforming &#x201C;data- poor Africa&#x201D; into a data-rich Africa. We want to tackle multiple SDGs, centred on health and wellness and climate change, for effective policy implementation for maximum impact. To harness these opportunities, we will leverage cutting-edge technologies and innovative methods to deliver better tools for disease diagnosis and prognosis; and novel targeted treatmentand prevention that is suitable for LMICs settings. This talk highlights real-life examples and challenges for incorporating handheld or point of care ultrasound (POCUS) device data into routine healthcare and research participant surveillance, and the opportunities for application of deep learning/AI for aiding clinical decision making leveraging the emerging Mobile fog computing (MFC) approaches.",https://ieeexplore.ieee.org/document/9732135/,2021 Eighth International Conference on Software Defined Systems (SDS),6-9 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FMEC54266.2021.9732567,Point-of-care Ultrasound (POCUS) Device Utilisation at the Edge in Lower and Middle Income Countries,IEEE,Conferences,"Summary form only given, as follows. A complete record of the tutorial workshop was not made available for publication as part of the conference proceedings. The genomics revolution in Africa began almost a decade ago to identify genetic and environmental determinants of human disease and wellness. This momentum is accelerating to advance science globally through large initiatives on the continent of Africa, for example, Human Hereditary and Health in Africa (H3Africa), Data Science Initiative for Africa (DSI-Africa), African Open Science Platform (AOSP), and the recent call by the Wellcome Trust (WT) for the setting up African Population Cohort Consortia (APCC) amongst others. All these efforts are aimed at transforming &#x201C;data-poor Africa&#x201D; into a data-rich Africa. We want to tackle multiple SDGs, centered on health and wellness and climate change, for effective policy implementation for maximum impact. To harness these opportunities, we will leverage cutting-edge technologies and innovative methods to deliver better tools for disease diagnosis and prognosis; and novel targeted treatment and prevention that is suitable for LMICs settings. This talk highlights real-life examples and challenges for incorporating handheld or point of care ultrasound (POCUS) device data into routine healthcare and research participant surveillance, and the opportunities for application of deep learning/AI for aiding clinical decision making leveraging the emerging Mobile fog computing (MFC) approaches.",https://ieeexplore.ieee.org/document/9732567/,2021 Sixth International Conference on Fog and Mobile Edge Computing (FMEC),6-9 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GUCON50781.2021.9573606,Possible Role of AI and IoT in Smart Buildings,IEEE,Conferences,"There are an increasing number of Artificial Intelligence (AI) and Internet of Things (IoT) devices and applications which are used across the globe in different areas. One such area is IoT-enabled smart buildings. There is a growing interest among government and non-government organizations in IoT-enabled smart buildings. Despite the perceived benefits of being smart, there is also a key concern of human safety in an emergency situation. This research aims to address this important concern and will develop an initial framework, called here the Safe'Tech, for human safety in IoT enabled smart buildings. The SafeTech will be developed and evaluated using the well-known design science research method. The SafeTech will comprise of both a design and software prototype solution, which can be used to ensure the safety of humans during an emergency through the collection, processing and communication of real-time data from the IoT sensors embedded in the smart building such as smart campus and shopping centre. The SafeTech will interact with the smart building through sensors and collect the state of the physical environment and sense any emergency and then also interact with the humans in the smart building and inform and direct them about the emergency and guide them for the safe evacuation. The applicability and evaluation of the framework software prototype will be demonstrated with the help of smart building scenarios in both Australia and Qatar, involving the fire emergency exercise and automatic and directed evacuation using the SafeTech. This research has several implications, in particular, the impact of reducing human life loss or injury reduction.",https://ieeexplore.ieee.org/document/9573606/,"2021 IEEE 4th International Conference on Computing, Power and Communication Technologies (GUCON)",24-26 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSEET49119.2020.9206229,Project-Based Learning in a Machine Learning Course with Differentiated Industrial Projects for Various Computer Science Master Programs,IEEE,Conferences,"Graduating computer science students with skills sufficient for industrial needs is a priority in higher education teaching. Project-based approaches are promising to develop practical and social skills, needed to address real-world problems in teams. However, rapid technological transition makes an initial training of contemporary methods challenging. This affects the currently much-discussed machine learning domain as well. The study at hand describes a re-framed teaching approach for a machine learning course, offered to various computer science master programs. Project-based learning is introduced with differentiated projects provided by industrial partners that address the diverse study programs. Course attendees are supported with manuals, tools, and tutoring, passing through the Cross Industry Standard Process for Data Mining (CRISP-DM). Observations made during two iterations are reported, accompanied by a first empiric evaluation of student experiences.",https://ieeexplore.ieee.org/document/9206229/,2020 IEEE 32nd Conference on Software Engineering Education and Training (CSEE&T),9-12 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WI.2018.00013,Proposed Computational Classification System of Human Cognitive Biases,IEEE,Conferences,"Despite our aspirations to do so, we humans don't always make optimal or rational decisions. Researchers from psychology, behavioral economics, anthropology, decision sciences, and other related fields have described many human cognitive biases which help to explain such decisions. Most of the time, these cognitive biases are relatively harmless and relatively costless. However, sometimes they do result in significant costs to individuals, companies, governments and societies in the form of wasted or misdirected money, time, effort, and sometimes even in the form of lives lost. The antidote to such decisions has long been recognized to lie in algorithmic decision making. Until relatively recently, though, requirements and complexity of such algorithms have limited their deployment in real-world situations. However, we now enjoy a convergence of computing power, decrease in computing costs, and computational and predictive methods born of data science, artificial intelligence (AI), and machine learning (ML), such that we can begin to mitigate some of the most negative effects of some of these cognitive biases. This paper proposes a method for classifying these human cognitive biases for purposes of mitigation by means of computing methods, describes some of these biases that are most ripe for mitigation through computing, and proposes future research directions that build upon this work.",https://ieeexplore.ieee.org/document/8609688/,2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI),3-6 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WORKS49585.2019.00006,Provenance Data in the Machine Learning Lifecycle in Computational Science and Engineering,IEEE,Conferences,"Machine Learning (ML) has become essential in several industries. In Computational Science and Engineering (CSE), the complexity of the ML lifecycle comes from the large variety of data, scientists' expertise, tools, and workflows. If data are not tracked properly during the lifecycle, it becomes unfeasible to recreate a ML model from scratch or to explain to stackholders how it was created. The main limitation of provenance tracking solutions is that they cannot cope with provenance capture and integration of domain and ML data processed in the multiple workflows in the lifecycle, while keeping the provenance capture overhead low. To handle this problem, in this paper we contribute with a detailed characterization of provenance data in the ML lifecycle in CSE; a new provenance data representation, called PROV-ML, built on top of W3C PROV and ML Schema; and extensions to a system that tracks provenance from multiple workflows to address the characteristics of ML and CSE, and to allow for provenance queries with a standard vocabulary. We show a practical use in a real case in the O&G industry, along with its evaluation using 239,616 CUDA cores in parallel.",https://ieeexplore.ieee.org/document/8943505/,2019 IEEE/ACM Workflows in Support of Large-Scale Science (WORKS),17-17 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISSRE52982.2021.00055,PyGuard: Finding and Understanding Vulnerabilities in Python Virtual Machines,IEEE,Conferences,"Python has become one of the most popular pro-gramming languages in the era of data science and machine learning, and is also widely deployed in safety-critical fields like medical treatment, autonomous driving systems, etc. However, as the official and most widely used Python virtual machine, CPython, is implemented using C language, existing research has shown that the native code in CPython is highly vulnerable, thus defeats Python&#x0027;s guarantee of safety and security. This paper presents the design and implementation of PyGuard, a novel software prototype to find and understand real-world security vulnerabilities in the CPython virtual machines. With PyGuard, we carried out an empirical study of 10 different versions of CPython virtual machines (from version 3.0 to the latest 3.9). By scanning a total of 3,358,391 lines native code, we have identified 598 new vulnerabilities. Based on our study, we describe a taxonomy to classify vulnerabilities in CPython virtual machines. Our taxonomy provides a guidance to construct automated and accurate bug-finding tools. We also suggest systematic remedies that can mediate the threats posed by these vulnerabilities.",https://ieeexplore.ieee.org/document/9700331/,2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE),25-28 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/I-SMAC49090.2020.9243322,Quantum Neural Networks for Dynamic Route Identification to avoid traffic,IEEE,Conferences,"Computation is the primary task performed for the evaluation of the solution for a specific problem, and in realtime, having better challenges to implementing the solution path with the better computational mechanisms. The concept of quantum computation mechanism using the neural networks is having the highest amount of the success rate in prediction models design and implementation. The idea of a dynamic routing mechanism using quantum computing and neural networks are the main essence. A better prediction model is performed for this specific kind of problem, which needs a particular focus on the latest problem-solving mechanisms. The problem-solving tools like neural networks will dynamically perform with real-time data, but a new add-on is needed to add like big data to implement the live data. The live data can help implement and understand the importance of solving the problem like dynamic routing mechanism. There is a chance of random growth in such a field of computer science. This computational mechanism using quantum computing and the neural network will track the live operations and form the dynamic route changes in the real-time scenario. This real-time scenario worked with a 95% accuracy rate. The accuracy will differ based on the number of connecting nodes are being considered to evaluate the hidden layers of the problem-solving mechanism.",https://ieeexplore.ieee.org/document/9243322/,"2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)",7-9 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2004.103,Quartet based phylogeny reconstruction with answer set programming,IEEE,Conferences,"Evolution is an important subarea of study in biological science, where given a set of species, the goal is to reconstruct their evolutionary history, or phylogeny. Many kinds of data associated with the species can be deployed for this task and many reconstruction methods have been proposed and examined in the literature. One very recent approach is to build a local phylogeny for every subset of 4 species, which is called a quartet for these 4 species, and then to assemble a phylogeny for the whole set of species satisfying these predicted quartets. In general, those predicted quartets might not always agree each other; and thus the objective function becomes to satisfy a maximum number of predicted quartets. This is the well-known maximum quartet consistency (MQC) problem, which is studied by a lot of researchers in the last two decades. We present a new equivalent representation for the MQC problem, that is, to search for an ultrametric matrix to satisfy the maximum number of those predicted quartets. We examine a few number of structural properties of the MQC problem in this new representation, through formulating it into answer set programming (ASP), a recent powerful logic programming tool for modeling and solving searching problems. The efficiency and usefulness of our approach are confirmed by our computational experiments on the artificial data as well as two real datasets.",https://ieeexplore.ieee.org/document/1374243/,16th IEEE International Conference on Tools with Artificial Intelligence,15-17 Nov. 2004,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DigitalHeritage.2013.6744821,REVEAL: One future for heritage documentation,IEEE,Conferences,"It can be frustrating to ensure that cultural heritage work, from archaeological excavations to historic surveys, is documented fully and that the evidence is recorded properly and thoroughly. Automated computer-based documentation and research tools would seem to offer many benefits. They can be more accurate and cost effective, saving time and ensuring that all finds and their contexts are appropriately and fully recorded. And if designed well, new digital field data acquisition systems can enable new types of hypothesis testing, new insight into the past, and new visualizations that in turn can lead to a paradigm shift in how heritage sites are managed and information disseminated. There have been many computer-based data collection systems for heritage management; many databases, many digital archives, and many digital publication options. REVEAL is special. REVEAL (Reconstruction and Exploratory Visualization: Engineering meets ArchaeoLogy), is the product of a US National Science Foundation collaboration among the Institute for the Visualization of History, Brown University's Division of Engineering, Laboratory for Man/Machine Systems, and the University of North Carolina, Charlotte's Department of Electrical and Computer Engineering. The project uses computer-vision, pattern-recognition, and machine-learning research to augment applications for archaeology and the humanities. REVEAL is a single piece of (free and open-source) software that coordinates all data types (e.g., photos, drawings, 3D models, and tabular information) with semi-automated tools for documenting sites, trenches and objects, recording excavation and site-evaluation progress, researching and analyzing the collected evidence, and creating 3D models and virtual worlds. Search and retrieval, building interactive visualizations, and testing hypo",https://ieeexplore.ieee.org/document/6744821/,2013 Digital Heritage International Congress (DigitalHeritage),28 Oct.-1 Nov. 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC-IT.2009.40,Rapid Prototyping of Planning & Scheduling Tools,IEEE,Conferences,"The Advanced Planning and Scheduling Initiative, or APSI, is an ESA programme to design and implement an Artificial Intelligence (AI) software infrastructure for planning and scheduling that can generically support different types and classes of space mission operations. The goal of the APSI is twofold: (1)~creating a software framework to improve the cost-effectiveness and flexibility of mission planning support tool development; (2)~bridging the gap between AI planning and scheduling technology and the world of space mission planning. A key aspect of the success of this project is the presence of a flexible timeline representation module that allows to exploit alternatives in the modeling of mission features. This paper shows an example of such a flexibility by using a real problem in the space realm - the HERSCHEL Science Long Term Planning process.",https://ieeexplore.ieee.org/document/5226820/,2009 Third IEEE International Conference on Space Mission Challenges for Information Technology,19-23 July 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCCE.2008.4580693,Real time implementation of NARMA L2 feedback linearization and smoothed NARMA L2 controls of a single link manipulator,IEEE,Conferences,"Robotics is a field of modern technology which requires knowledge in vast areas such as electrical engineering, mechanical engineering, computer science as well as finance. Nonlinearities and parametric uncertainties are unavoidable problems faced in controlling robots in industrial plants. Tracking control of a single link manipulator driven by a permanent magnet brushed DC motor is a nonlinear dynamics due to effects of gravitational force, mass of the payload, posture of the manipulator and viscous friction coefficient. Furthermore uncertainties arise because of changes of the rotor resistance with temperature and random variations of friction while operating. Due to this fact classical PID controller can not be used effectively since it is developed based on linear system theory. Neural network control schemes for manipulator control problem have been proposed by researchers; in which their competency is validated through simulation studies. On the other hand, actual real time applications are rarely established. Instead of simulation studies, this paper is aimed to implement neural network controller in real time for controlling a DC motor driven single link manipulator. The work presented in this paper is concentrating on neural NARMA L2 control and its improvement called to as Smoothed NARMA L2 control. As proposed by K. S Narendra and Mukhopadhyay, Narma L2 control is one of the popular neural network architectures for prediction and control. The real time experimentation showed that the Smoothed NARMA L2 is effective for controlling the single link manipulator for both point-to-point and continuous path motion control.",https://ieeexplore.ieee.org/document/4580693/,2008 International Conference on Computer and Communication Engineering,13-15 May 2008,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FIE.1999.839219,Real time object recognition for teaching neural networks,IEEE,Conferences,"Undergraduate students in computer science learn best when they are given the opportunity to apply hardware and software concepts to real world systems, and neural-network applications present attractive possibilities for giving them such opportunity. An example of how to take advantage of these possibilities is given in this paper, which describes a specific neural network technique that has been developed and applied to the problem of identifying real world objects in real time. Those objects can be as simple as paper cut-outs or they can be mechanical objects such as a nut or a bolt. These objects are placed on a plane, and are ""examined"" by an ""identifying system"" consisting of a camera attached to a PC through a video capture card. The pixels collected from the image of the object are fed to a set of neural network nodes for pattern recognition. Patterns are recognized by a multi-layer neural network where the output of a neuron, which can be characterized by sigmoid ""activation function"", is a function of weighted inputs. Lisp is used as the programming language due to its simple syntax and powerful recursive features for processing lists. The binary equivalent of the computed output is evaluated as a recognition signature which is compared to the signature of objects in a list. Of course, the artificial neural network is ""trainable"". To master the technique, the students start by learning about neurons and forward and backpropagation methods, but they soon find themselves ""training"" a multilayered neural network that they themselves have built. The learning experience encompasses video capturing, image handling, filtering, and image compression, and it demystifies neural network programming.",https://ieeexplore.ieee.org/document/839219/,FIE'99 Frontiers in Education. 29th Annual Frontiers in Education Conference. Designing the Future of Science and Engineering Education. Conference Proceedings (IEEE Cat. No.99CH37011,10-13 Nov. 1999,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RADAR.2008.4720778,Real-time autonomous disturbance detection and monitoring system with L-band UAVSAR,IEEE,Conferences,"We developed an autonomous disturbance detection and monitoring system with imaging radar that combines the unique capabilities of imaging radar with high throughput onboard processing technology and onboard automated response capability based on specific science algorithms. This smart sensor development leverages off recently developed technologies in real-time onboard synthetic aperture radar (SAR) processor and onboard automated response software as well as science algorithms previously developed for radar remote sensing applications. In this project, we use a high rate data interface to ingest NASA’s UAVSAR data and compute SAR imagery in real-time complete with motion compensation and antenna beam steering capabilities. NASA’s UAVSAR is a compact, L-band 80 MHz bandwidth, fully polarimetric radar. It is designed for repeat-pass InSAR and has had engineering flights in 2007 and successful science data collections in 2008. The fidelity of the onboard SAR processor is tuned by implementing polarimetric calibration capabilities. Science algorithms are implemented for detecting and monitoring fire disturbances over the US forests. We additionally developed artificial intelligence for decision-making, and adapted existing onboard activity re-planning and execution software to interface with the UAVSAR radar controller. The product of this development is a prototype closed loop smart sensor.",https://ieeexplore.ieee.org/document/4720778/,2008 IEEE Radar Conference,26-30 May 2008,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICICAS51530.2020.00065,Realtime Multi-Person Pose Estimation Based on Android System,IEEE,Conferences,"Human pose estimation has always been a very popular direction. This technology can be applied to human-computer interaction, abnormal behavior detection, intelligent security and other fields, and it will promote the development of artificial intelligence in the future. Human pose estimation has been developed for a long time, and with the advancement of science and technology, many emerging algorithms have spewed out, but most of these algorithms use a multistage network structure. These network structures have achieved better results in accuracy, but the parameters have become larger and larger. It's a big problem that deploying these networks to mobile and embedded devices with limited system resources. We use the MobileNet and TensorFlow Lite frameworks launched by Google to successfully optimize the complex network model and deploy it to Android phones. The human pose estimation can be quickly realized only by using local calculations, avoiding the delay trouble caused by cloud computing solutions.",https://ieeexplore.ieee.org/document/9402763/,"2020 International Conference on Intelligent Computing, Automation and Systems (ICICAS)",11-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICECA52323.2021.9675885,Recent Advancements in Autonomous Emergency Braking: A Survey,IEEE,Conferences,"Background/Objectives: This paper is aimed to present a study on the need for Autonomous Emergency Braking System (AEBS) in Autonomous Vehicles (AVs), terminologies, important AEBS metrics, and recent research on AEBSs in AVs. Methods/Statistical analysis: This paper discusses the AEBS research carried out in the recent past, with integrated technologies. The study articles are sourced from databases like IEEE Xplore, Springer Link, Science Direct, and Elsevier Journal Finder, etc. The keywords used to fetch the relevant articles are: autonomous vehicles, self-driving vehicles, automatic emergency braking, autonomous emergency braking system, and collision avoidance in AVs. The surveyed literature was published between 2009 and 2020. Findings: The observations in this study reveal the following: various tools used to simulate AVs and AEBSs, widely adopted metrics for consideration and evaluation, real-time implementations of AEBS (sensors and prototypes), and different technologies used for the effective implementation. Novelty/Applications: The detailed study on AEBS in this paper emphasizes various interesting factors to make AEBS more robust and reliable. The findings are outlined in the summary section as the future research agenda. Hence, there is a great room for effective AEBS implementation with the blend of our findings.",https://ieeexplore.ieee.org/document/9675885/,"2021 5th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",2-4 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICIP.2009.5414281,Recent advances in remote sensing image processing,IEEE,Conferences,"Remote sensing image processing is nowadays a mature research area. The techniques developed in the field allow many real-life applications with great societal value. For instance, urban monitoring, fire detection or flood prediction can have a great impact on economical and environmental issues. To attain such objectives, the remote sensing community has turned into a multidisciplinary field of science that embraces physics, signal theory, computer science, electronics, and communications. From a machine learning and signal/image processing point of view, all the applications are tackled under specific formalisms, such as classification and clustering, regression and function approximation, image coding, restoration and enhancement, source unmixing, data fusion or feature selection and extraction. This paper serves as a survey of methods and applications, and reviews the last methodological advances in remote sensing image processing.",https://ieeexplore.ieee.org/document/5414281/,2009 16th IEEE International Conference on Image Processing (ICIP),7-10 Nov. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CVIDLICCEA56201.2022.9824310,Research Analysis of Stream Processing System Storm Based on Knowledge Map,IEEE,Conferences,"With the development of the Internet of Things and 5G technology, stream processing systems are more and more widely used, especially the open source Storm platform. A comprehensive understanding of the research status and progress of Storm is of a certain reference value for the academic and industry to carry out related work. Based on bibliometrics theory, this paper takes the citation index of CNKI (China national knowledge infrastructure) and WOS (web of science) databases from 2013 to 2021 as the data source, and the relevant literature of Storm research and application as the research object, which is visualized and analyzed by the CiteSpace software. The knowledge maps are drawn from the aspects of temporal and spatial distribution of literature, distribution of authors and institutions, keyword co-occurrence, citation frequency and keyword prominence, and the research status, research basis, research hotspots and research trends of Storm at home and abroad are analyzed. The research results can provide references for the follow-up theoretical and application research of Storm system.",https://ieeexplore.ieee.org/document/9824310/,"2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)",20-22 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRIS.2018.00047,Research and Application of Traffic Sign Detection and Recognition Based on Deep Learning,IEEE,Conferences,"Nowadays, with the rapid development of society and economy, automobiles have become almost one of the convenient modes of transport for every household. This makes the road traffic environment more and more complicated, and people expect to have an intelligent Vision-assisted applications that provide drivers with traffic sign information, regulate driver operations, or assist in vehicle control to ensure road safety. As one of the more important functions, traffic sign detection and recognition[1], has become a hot research direction of researchers at home and abroad. It is mainly the use of vehicle cameras to capture real-time road images, and then to detect and identify the traffic signs encountered on the road, thus providing accurate information to the driving system. However, the road conditions in the actual scene are very complicated. After many years of hard work, researchers have not yet made the recognition system practical, and further research and improvement are still needed. Traditionally, traffic signage has been detected and categorized using standard computer vision methods, but it also takes considerable time to manually process important features of the image. With the development and progress of science and technology, more and more scholars use deep learning technology to solve this problem. The main reason that the deep learning method is widely accepted is that the model can learn the deep features inside the image autonomously from the training samples, especially for many cases that do not know how to design the feature extractor, such as expression recognition, target detection Wait. Based on the application of road traffic sign detection and recognition, this article focuses on the correctness and high efficiency of detection and recognition. Through Caffe[2] which is the open-source framework, a deep convolution neural network algorithm is proposed to train traffic sign training sets to get a model that can classify traffic signs and to learn and identify the most critical of these traffic signs Features, so as to achieve the purpose of identifying traffic signs in the real scene.",https://ieeexplore.ieee.org/document/8410256/,2018 International Conference on Robots & Intelligent System (ICRIS),26-27 May 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIAM48774.2019.00062,Research and Application of the Intelligent Biogas Monitoring System Based on LoRa Technology,IEEE,Conferences,"In the towns, there are problems such as poor real-time meter reading and biogas management, and this paper constructs an intelligent biogas monitoring system based on LoRa (Long Range) technology to meet biogas science monitoring and management. First, the architecture design is carried out, and the system is divided into a physical acquisition layer, a network link layer, and a management application layer. Then, it is developed for repeaters, gateways, and wireless networks commonly used in LoRa systems to realize biogas data relay, receive commands, and real-time upload. Then, the system adopts a modular design, develops the software protocol for the application layer, and partitions the network nodes in the area. Finally, the electrical drawing design, the power distribution cabinet design, the control port layout of the gas supply process monitoring and control system are carried out, and the application is formed at the demonstration point. Through application, the biogas monitoring system has the advantages of long communication distance, low power consumption, and accurate and timely data collection, and can be applied and promoted.",https://ieeexplore.ieee.org/document/8950841/,2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM),16-18 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CVIDL51233.2020.00-39,Research and Practice of Virtual Simulation Experiment of Computer Major in Colleges,IEEE,Conferences,"At present, in the innovative practice of computer courses and teaching reform in colleges and universities, we have adopted the innovative teaching mode of virtual simulation experiments in programming languages, combined the methods of online and offline, and the combination of virtual and real, to improve the experimental teaching mode and use experiments. The teaching virtual simulation program has set a virtual simulation experiment platform for order language. This can not only achieve the goal of improving experimental teaching, but also make up for the problems of traditional experimental teaching students' lack of initiative and poor theoretical learning effect. This article expounds on the construction of virtual simulation experiment platform and the design innovation of the teaching mode. It reflects on the way of using virtual simulation experiment in the teaching of computer science in colleges and universities, hoping to have reference value for improving the teaching level of virtual experiment teaching.",https://ieeexplore.ieee.org/document/9270549/,"2020 International Conference on Computer Vision, Image and Deep Learning (CVIDL)",10-12 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBAIE52039.2021.9389893,Research and implementation of network information security management system based on face recognition,IEEE,Conferences,"In recent years, with the prosperity and development of social economy and the continuous progress of science and technology, people's identity recognition field has been paid more and more attention, and face recognition has higher security than traditional verification manual, which is a hot research direction of artificial intelligence. In this paper, face recognition is carried out in the order of face preprocessing, face detection and face recognition (training). Face preprocessing mainly includes image graying, image filtering, histogram equalization and other processing steps. Face detection adopts Ada Boost based face detection algorithm[1]. The main face recognition algorithms are studied: lbphface Face recognition algorithm based on LBP, this paper uses this algorithm for face recognition. The design and implementation of the security management system based on face recognition is completed.",https://ieeexplore.ieee.org/document/9389893/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HPBDIS53214.2021.9658461,Research on Graph Network Recommendation Algorithm Based on Random Walk and Convolutional Neural Network,IEEE,Conferences,"As a general form of describing and modeling complex systems, networks widely exist in different scenes and tasks in various fields of the real world. Therefore, how to effectively calculate (graph Computing) and analyze (graph mining) data based on network structure has always been the core basic research direction in the field of computing science and data mining, and has been continuously studied by scholars from computer, sociology, biology and other disciplines. Network representation learning can better analyze the information hidden in complex networks, and with the help of graph neural network, it provides a universal method to solve various practical problems under the background of network structure data, which has attracted the common attention of academia and industry. At the same time, traditional recommendation algorithms generally analyze the user's rating data on items and then make preference recommendations. These methods have some problems, such as difficulty in extracting deep features, single data processing method, etc. These problems will lead to low prediction accuracy and unreasonable results. Therefore, in this paper. The recommendation algorithm for heterogeneous networks based on feature embedding is improved (RW-CNN), and the random walk algorithm of convolution and graph networks in deep learning is used to process the text feature of item names. Firstly, the network topology similarity calculation module is used to measure the consistency and complementarity of each view network, and then the word vector learning technology is used to generate the representation vector of multi view network: the word vector module is used to distinguish the complementarity between views, and the hierarchical hidden state based on multi views is used to extract these information, To retain the unique complementary information of each view; The word vector module is used to recommend multiple views with stronger consistency. Through the middle hidden state shared by multiple views, the graph convolution technology is used to aggregate information and realize the fusion of consistent information. Finally, the learned representation vector is used for link prediction and node classification tasks. The experimental results on a variety of real data sets show that the effect of this model is significantly improved.",https://ieeexplore.ieee.org/document/9658461/,2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS),5-7 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIE53562.2021.00145,Research on improving students&#x2019; interest in learning based on CiteSpace.5.7.R2,IEEE,Conferences,"To comprehensively understand the research situation and research trend in the field of ""learning interest"", this paper uses CiteSpace.5.7.R2 information visualization software as a research tool, selects 2400 literature data from the Web of Science core database from 1975 to 2021 and 984 literature data from the CNKI database from 1900 to 2021 for visual analysis, respectively from the aspects of national cooperation, institutional cooperation, keyword co-occurrence, co-citation network, etc. The results show that the current international research hotspot is the interest development model, the application of virtual reality technology, and so forth. The research hotspot in China is teaching reform. Finally, the paper puts forward the prospect of the research in the field of ""learning interest"" in China: strengthening the cooperation among colleges and universities; using science and technology in teaching, such as virtual reality, to improve students&#x2019; interest in learning.",https://ieeexplore.ieee.org/document/9534593/,2021 2nd International Conference on Artificial Intelligence and Education (ICAIE),18-20 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICESIT53460.2021.9696498,Research on the Application of Artificial Intelligence in Computer Network Technology in Big Data Era,IEEE,Conferences,"The 21st century is an information age, and it is also a data age. The importance of data information resources is highlighted under the background of big data age. While the development of computer and its derivative technology promotes the growth of computer science, it also makes the artificial intelligence technology gradually mature. A lot of problems need to be considered, mainly including the efficiency, real-time. However, the computer network structure is becoming more and more complex, resulting in the low efficiency of computer network communication. With the development of artificial intelligence technology, it provides an effective solution to this problem. Artificial intelligence algorithm can optimize the whole network according to the scale of the network and the deployment of equipment, so as to improve the communication quality and efficiency of computer network.",https://ieeexplore.ieee.org/document/9696498/,2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT),22-24 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE53849.2021.00112,Research on the Application of Artificial Intelligence in Taekwondo Sport,IEEE,Conferences,"As an emerging discipline integrating computer, mathematics, linguistics, psychology, brain science, physics, computer, software, and philosophy, the field of artificial intelligence has grown to be the hottest technology field in China. The Country has been paying great attention to the innovation and development of AI, AI technology has been integrated into various aspects and scenarios such as manufacturing, life and leisure, medical and recreation, road traffic, security and surveillance. Premier Li Keqiang clearly proposed in the Government Work Report to ""expand and strengthen new industrial clusters, implement big data development action, strengthen the research and application of a new generation of artificial intelligence, promote the 'Internet +' in sports and other fields, develop intelligent industries, and expand intelligent life. The national leaders have been promoting a strong sports nation from the height of national strategy, attaching importance to the development of sports industry and emphasizing the importance of Internet + sports and artificial intelligence + sports. Taekwondo, as a popular sport worldwide, has been practiced by more than 200 countries and nearly 80 million people worldwide. However, in the process of rapid development, taekwondo also has some urgent problems that need to be solved, such as the decline in the attractiveness of the event, the difficulty of improving the performance of competition and training. Therefore, it is meaningful to contemplate on how to apply artificial intelligence technology in taekwondo for the healthy development and popularization of the sport in the new era.",https://ieeexplore.ieee.org/document/9696042/,2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),24-26 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASE51524.2021.9678889,Restoring the Executability of Jupyter Notebooks by Automatic Upgrade of Deprecated APIs,IEEE,Conferences,"Data scientists typically practice exploratory programming using computational notebooks, to comprehend new data and extract insights. To do this they iteratively refine their code, actively trying to re-use and re-purpose solutions created by other data scientists, in real time. However, recent studies have shown that a vast majority of publicly available notebooks cannot be executed out of the box. One of the prominent reasons is the deprecation of data science APIs used in such notebooks, due to the rapid evolution of data science libraries. In this work we propose RELANCER, an automatic technique that restores the executability of broken Jupyter Notebooks, in near real time, by upgrading deprecated APIs. RELANCER employs an iterative runtime-error-driven approach to identify and fix one API issue at a time. This is supported by a machine-learned model which uses the runtime error message to predict the kind of API repair needed - an update in the API or package name, a parameter, or a parameter value. Then RELANCER creates a search space of candidate repairs by combining knowledge from API migration examples on GitHub as well as the API documentation and employs a second machine-learned model to rank this space of candidate mappings. An evaluation of RELANCER on a curated dataset of 255 un-executable Jupyter Notebooks from Kaggle shows that RELANCER can successfully restore the executability of 56% of the subjects, while baselines relying on just GitHub examples and just API documentation can only fix 38% and 36% of the subjects respectively. Further, pursuant to its real-time use case, RELANCER can restore execution to 49% of subjects, within a 5 minute time limit, while a baseline lacking its machine learning models can only fix 24%.",https://ieeexplore.ieee.org/document/9678889/,2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE),15-19 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ROBOT.2001.933270,Robotic Antarctic meteorite search: outcomes,IEEE,Conferences,"Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to other planets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learned from the first field demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limited performance in the speed and coverage of autonomous search.",https://ieeexplore.ieee.org/document/933270/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICAI.2019.8701282,Role of Distributed Ledger Technology (DLT) to Enhance Resiliency in Internet of Things (IoT) Ecosystem,IEEE,Conferences,"So far Internet has connected humans and now with technological advancements it is inter connecting `Things'. With more globalization and technological advancement, The Internet of Things (IoT) has been matured into self sustaining and evolving technology that has the capacity to change the way how physical and cyber worlds interact. We can also say IoT is about anything that can connect everything. With Involvement of Global Corporations, new IoT-based systems are being proposed in almost every sector which humans have so far envisioned. The thoughts (or Science Fiction) which was once fictional and unbelievable are becoming reality, whatever we desire will be available at touch of our finger someday. Mankind is moving fast towards connected future, where not only autonomous vehicles but entire cities infrastructure will be completely internet connected to support rapid urbanization. To reap the full benefit of IoT, it is imperative that the infrastructure we depend upon is adequate to deliver the services envisioned and has the necessary resilience, robustness and security. IoT can be described as an large scale, heterogeneous, ultra-complex Ecosystem acting as bridge between cyber and physical worlds. Recently, the Distributed Ledger Technology (Blockchain and Block less-different implementation of Data Structures with cryptographic algorithmic functions) has gained much attention in IoT solutions from security perspective. In This Research Paper we have explained the concepts about the functioning of Distributed Ledger Technology with focus on how it can provide security (for System Resiliency) in IoT Ecosystem.",https://ieeexplore.ieee.org/document/8701282/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPAPS52181.2020.9375539,Role of Joint 5G-IoT Framework for Smart Grid Interoperability Enhancement,IEEE,Conferences,"The ever-growing development in communication technology and very fast advances in data science are transferring the power systems in a new era. The level of autonomy is improving by means of Internet-of-Things (IoT), while the level of intelligence is improving through artificial intelligence. The applications of big data analytics and cloud computing techniques in smart grids are also new topics, which have been paid particular attention recently. These paradigms can be used in both grid-scale and local-scale, while the central grid operation center has interoperability with an abundant number of sub-controllers, and aggregators in a wide variety of scales. On the one hand, the system operator must deal with multiple parameters with different kinds of uncertainties. On the other hand, the new structures are evolving toward transactive energy trading models in microgrids. In such a circumstance, a myriad of elements is producing critical data, which should be acquired, transferred, stored, analyzed, and finally, proper controlling actions must be sent. These data are producing at different intervals, even in a fraction of a second. This matter makes it possible to maintain grid security and better real-time operation as well as to get better demand responsiveness. A smart grid consists of many embedded or interconnected systems that are linked to each other through various communication platforms in the cyber layer. A flexible, highly-autonomous, and intelligent smart grid entails an agile communication system, whether wired or wireless. However, cellular networks have prominent benefits. Hence, 5G technology, which is state-of-the-art technology in this field, can be deployed. The communication infrastructure links many components to each other in cyber-physical smart grids. The velocity of data exchange has a profound importance for some purposes, while 5G technology can be the best solution. The joint integration of IoT and 5G procures more reliability, resiliency, security, and economy.",https://ieeexplore.ieee.org/document/9375539/,2020 15th International Conference on Protection and Automation of Power Systems (IPAPS),30-31 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/eScience.2019.00014,SATVAM: Toward an IoT Cyber-Infrastructure for Low-Cost Urban Air Quality Monitoring,IEEE,Conferences,"Air pollution is a public health emergency in large cities. The availability of commodity sensors and the advent of Internet of Things (IoT) enable the deployment of a city-wide network of 1000's of low-cost real-time air quality monitors to help manage this challenge. This needs to be supported by an IoT cyber-infrastructure for reliable and scalable data acquisition from the edge to the Cloud. The low accuracy of such sensors also motivates the need for data-driven calibration models that can accurately predict the science variables from the raw sensor signals. Here, we offer our experiences with designing and deploying such an IoT software platform and calibration models, and validate it through a pilot field deployment at two mega-cities, Delhi and Mumbai. Our edge data service is able to even-out the differential bandwidths from the sensing devices and to the Cloud repository, and recover from transient failures. Our analytical models reduce the errors of the sensors from a best-case of 63% using the factory baseline to as low as 21%, and substantially advances the state-of-the-art in this domain.",https://ieeexplore.ieee.org/document/9041703/,2019 15th International Conference on eScience (eScience),24-27 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IC_ASET53395.2022.9765866,SMART Calibration Platform for a Set of Metrology Equipments: Application for spectrum analyzer,IEEE,Conferences,"With the great progress it has made, metrology is increasingly essential in various fields such as health, biology, food, chemistry and medicine. If we refer to etymology, ""metrology"" means ""science of measurement"". The business measurement approach should therefore fall within the realm of rigor and rationality by performing periodic calibration. By using new technologies (IT, Machine learning, etc.), work methods can be innovated by modernizing measurement techniques and by introducing the notion of intelligence. ""SMART Metrology"" or ""intelligent metrology"" is therefore required to take care of the automatic calibration and monitoring of equipment and will provide reliable and repeatable measurements, which will be verified by legal metrology. It is therefore used to create SMART measuring instruments that transform measurement results into controlled information. More and more companies are opting for Smart metrology for the simple reason that it modernizes the techniques of taking measurements introducing new concepts, in particular Big Data. This technology offers metrologists the opportunity to develop their profession, allowing them to actively participate in the compliance of measuring instruments and the reliability of measurements in the company. This paper presents a SMART platform for calibrating spectrum analyzers available in a metrology laboratory using Python programming software. This Human Machine Interface (HMI) makes it possible to communicate in real time with the spectrum analyzers, to take measurements automatically, to supervise the instrument remotely in order to carry out the calibration and verification of the equipment and to judge the conformity of the equipment.",https://ieeexplore.ieee.org/document/9765866/,2022 5th International Conference on Advanced Systems and Emergent Technologies (IC_ASET),22-25 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIVR52153.2021.00060,"ScienceVR: A Virtual Reality Framework for STEM Education, Simulation and Assessment",IEEE,Conferences,"This paper addresses the use of Virtual Reality (VR) in Science, Technology, Engineering, and Math (STEM) education. There are limited studies investigating the proper design and effectiveness of VR in STEM education, and current VR frameworks and applications lack explicit links to the established learning theories and assessment mechanisms to evaluate learning outcomes. We present ScienceVR, an educational virtual reality design framework, illustrated through a science laboratory prototype, to bridge some of the gaps identified in the design and development of a VR environment for learning. We established design guidelines and implemented an in-app data collection system to measure users’ learning, performance, and task completion rate. Our evaluation using ANOVA and other non-parametric methods with 36 participants in three groups: immersive VR (IVR), desktop VR(DVR), and 2D indicated improved usability and learning outcomes for the IVR group. Task completion rate in the IVR group was higher (68% compared to DVR with 50%). For memorability, the IVR condition performed better than DVR while for learnability, IVR&DVR performed significantly better than 2D. IVR group has performed better and faster with more accuracy compared to the DVR group in completing the tasks.",https://ieeexplore.ieee.org/document/9644266/,2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),15-17 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICICRS46726.2019.9555857,Security Protocols in Internet of Things (IoT) - A Review,IEEE,Conferences,"The technical and scientific domains have undergone a major revolution in this twenty-first century. With several new spheres have been explored to make lives simpler and solve complex challenges. The area of Computer Science and Information technology has eased people lives by introduction of Artificial Intelligence, Virtual reality. One such useful domains are the Internet of Things (IoT) that has now started a recent trend in making things simpler and easy to access. This has enabled several daily use objects to be smartly connected with various computing devices, and it can also be helpful to control them by a click of a button or sending a simple command. However, every technology gets threat with increased users and to prevent these, various security protocols have been implemented in IoT.",https://ieeexplore.ieee.org/document/9555857/,2019 International Conference on Intelligent Computing and Remote Sensing (ICICRS),19-20 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICECCO.2015.7416901,Selection of the most prominent lines of research in ICT domain,IEEE,Conferences,"The paper is devoted to selection of the most crucial directions of research in ICT domain that could be implemented in the Republic of Kazakhstan. In the paper we evaluated the dynamics of the annual changes in the number of publications and convergence of ICT sub-domains based on data of Scopus, EBSCO (Information Science & Technology Abstracts, Academic Search Complete) and Google Scholar. To analyze the place of Kazakhstan, we considered indexes shown in the Global Competitiveness Report. As a result, the most rapidly developing areas of research were revealed (big data, machine learning, 5G, augmented reality, and etc.). The semantic network of the most modern concepts of the ICT domain was constructed that visualizes the binary relationship between the components and their relative importance. By using comparative analysis of the number of publications in the leading countries and some other countries including Kazakhstan, we selected some key domains which need to be seriously improved onto the way of development science in RK.",https://ieeexplore.ieee.org/document/7416901/,2015 Twelve International Conference on Electronics Computer and Computation (ICECCO),27-30 Sept. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
,Simdex: A Simulator of a Real Self-adaptive job-dispatching System Backend,IEEE,Conferences,"Self-adaptive systems comprise a complex domain of computing systems that are intensively studied but sparsely employed in real applications. Furthermore, recent trends in computer science are steering towards machine learning which has yet to fully penetrate this domain. We would like to present Simdex &#x2013; a realistic simulator of the self-adaptive backend that dispatches computing jobs among multiple workers. It is based on ReCodEx, a system for semi-automated evaluation of coding assignments that have been used for the past 5 years at our School of Computer Science. The simulator replays the workload logs recorded from ReCodEx over that period which provides a quite thorough evaluation and near-to-real feedback for the simulated scenarios. Furthermore, the design of the simulator is highly modular and allows the implementation of different self-adaptive controllers, including ones based on machine learning, as we demonstrate in our examples. CCS CONCEPTS &#x2022; Software and its engineering $\rightarrow$Simulator /interpreter; &#x2022; Computing methodologies $\rightarrow$Self-organization; &#x2022; Computer systems organization $\rightarrow$Self-organizing autonomic computing.",https://ieeexplore.ieee.org/document/9800016/,2022 International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS),22-24 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISMAR.2009.5336511,SixthSense: Integrating information and the real world,IEEE,Conferences,"Pattie Maes is an associate professor in MIT's Program in Media Arts and Sciences and associate head of the Program in Media Arts and Sciences. She founded and directs the Media Lab's Fluid Interfaces research group ‹http://fluid. media.mit.edu/› which develops technologies for seamless integration of the digital world and physical world. Previously, she founded and ran the Software Agents group ‹http://fluid.media.mit.edu/›. Prior to joining the Media Lab, Maes was a visiting professor and a research scientist at the MIT Artificial Intelligence Lab. She holds bachelor's and PhD degrees in computer science from the Vrije Universiteit Brussel in Belgium. Her areas of expertise are human-computer interaction and intelligent user interfaces. Maes is the editor of three books, and is an editorial board member and reviewer for numerous professional journals and conferences. She has received several awards: /Newsweek/ magazine named her one of the “100 Americans to watch for” in the year 2000; /TIME/ Digital selected her as a member of the Cyber-Elite, the top 50 technological pioneers of the hightech world; the World Economic Forum honored her with the title “Global Leader for Tomorrow”; Ars Electronica awarded her the 1995 World Wide Web category prize; and in 2000 she was recognized with the “Lifetime Achievement Award” by the Massachusetts Interactive Media Council.",https://ieeexplore.ieee.org/document/5336511/,2009 8th IEEE International Symposium on Mixed and Augmented Reality,19-22 Oct. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICIRCA.2018.8597327,Smart Cap - Wearable Visual Guidance System for Blind,IEEE,Conferences,"Science and technology always try to make human life easier. The people who are having complete blindness or low vision faces many difficulties during their navigation. Blindness can occur due to many reasons including disease, injury or other conditions that limit vision. The main purpose of this paper is to develop a navigation aid for the blind and the visually impaired people. In this paper, we design and implement a smart cap which helps the blind and the visually impaired people to navigate freely by experiencing their surroundings. The scene around the person will be captured by using a NoIR camera and the objects in the scene will be detected. The earphones will give a voice output describing the detected objects. The architecture of the system includes the processor Raspberry Pi 3, NoIR camera, earphones and a power source. The processor collects the frames of the surroundings and convert it to voice output. The device uses TensorFlow API, open-source machine learning library developed by the Google Brain Team for the object detection and classification. TensorFlow helps in creating machine learning models capable of identifying and classifying multiple objects in a single image. Thus, details corresponding to various objects present within a single frame are obtained using TensorFlow API. A Text to Speech Synthesiser (TTS) software called eSpeak is used for converting the details of the detected object (in text format) to speech output. So the video captured by using the NoIR camera is finally converted to speech signals and thus narration of the scene describing various objects is done. Objects which come under 90 different classes like cell phone, vase, person, couch etc are detected.",https://ieeexplore.ieee.org/document/8597327/,2018 International Conference on Inventive Research in Computing Applications (ICIRCA),11-12 July 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RE.2019.00078,Specifying Requirements through Interaction Design,IEEE,Conferences,"When the requirements and the interaction design of a system are separated, they will most likely not fit together, and the resulting system will be less than optimal. Even if all the real needs are covered in the requirements and also implemented, errors may be induced by human-computer interaction through a bad interaction design and its resulting user interface. Such a system may even not be used at all. Alternatively, a great user interface of a system with features that are not required will not be very useful as well. This tutorial explains joint modeling of (communicative) interaction design and requirements, through discourse models and ontologies. Our discourse models are derived from results of human communication theories, cognitive science and sociology (even without employing speech or natural language). While these models were originally devised for capturing interaction design, it turned out that they can be also viewed as specifying classes of scenarios, i.e., use cases. In this sense, they can also be utilized for specifying requirements. Ontologies are used to define domain models and the domains of discourse for the interactions with software systems. User interfaces for these software systems can be generated semi-automatically from our discourse models, domain-of-discourse models and specifications of the requirements. This is especially useful when user interfaces for different devices are needed. Specific usability requirements can be dealt with in our approach through advanced customization approaches. Hence, inter-action design facilitates requirements engineering to make applications both more useful and usable.",https://ieeexplore.ieee.org/document/8920541/,2019 IEEE 27th International Requirements Engineering Conference (RE),23-27 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HPCS48598.2019.9188104,Staged deployment of interactive multi-application HPC workflows,IEEE,Conferences,"Running scientific workflows on a supercomputer can be a daunting task for a scientific domain specialist. Workflow management solutions (WMS) are a standard method for reducing the complexity of application deployment on high performance computing (HPC) infrastructure. We introduce the design for a middleware system that extends and combines the functionality from existing solutions in order to create a high-level, staged usercentric operation/deployment model. This design addresses the requirements of several use cases in the life sciences, with a focus on neuroscience. In this manuscript we focus on two use cases: 1) three coupled neuronal simulators (for three different space/time scales) with in-transit visualization and 2) a closed-loop workflow optimized by machine learning, coupling a robot with a neural network simulation. We provide a detailed overview of the application-integrated monitoring in relationship with the HPC job. We present here a novel usage model for large scale interactive multi-application workflows running on HPC systems which aims at reducing the complexity of deployment and execution, thus enabling new science.",https://ieeexplore.ieee.org/document/9188104/,2019 International Conference on High Performance Computing & Simulation (HPCS),15-19 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HYDCON48903.2020.9242803,Story and Task Issue Analysis for Agile Machine Learning Projects,IEEE,Conferences,"The usage of Agile methodology in planning and executing machine learning (ML) and data science related software engineering projects is increasing. However, there are very few studies using real data on how effective such planning is or guidelines on how to plan such projects. In this paper, we analyze data taken from several software projects using Scrum tools. We compare the data for data science/ML and non-ML projects, in an attempt to understand if data science and ML projects are planned or executed any differently compared to normal software engineering projects. We also perform a story classification task using machine learning to analyze story logs for agile tasks for several teams. We find there are differences in what makes a good ML story as opposed to a non ML story. After analyzing this data, we propose a few ways in which software projects, whether machine learning related or not, can be better logged and executed using Scrum tools like Jira.",https://ieeexplore.ieee.org/document/9242803/,2020 IEEE-HYDCON,11-12 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ART.2002.1107002,Student projects using ARToolKit,IEEE,Conferences,"This paper describes three student projects developed at the University of Applied Science at Hagenberg (media technology and design) using ARToolKit. All projects were implemented by students during their semester projects or during their master thesis. MusicAR is the first application presented in this paper. It describes the master thesis of a student and shows a nice music learning program for children. The second application is ASR (augmented sound reality), realized by two students during their semester project. ASR allows the user to place 3D sound sources and gives the user an acoustic 3D impression of the sound sources. Finally, two students implemented ARoom, a furnishing program using AR.",https://ieeexplore.ieee.org/document/1107002/,"The First IEEE International Workshop Agumented Reality Toolkit,",29-29 Sept. 2002,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ETCCE51779.2020.9350872,Students Online Exam Proctoring: A Case Study Using 360 Degree Security Cameras,IEEE,Conferences,"Online courses, online exams and online certificates are conducted by various universities and Information Technology (IT) institutes worldwide. Delivery tools have been created for conducting the exams from any place. Applying this will lead saving time and travelling cost. Nowadays, due to the COVID-19 pandemic, there is a big demand on the online courses and exams. This paper introduces a new approach for exam proctoring using 360-degree security camera. Mainly, online exams' security is a major concern. Thus, a delivery tools must not only ensure the identity of a test- taker but also the overall test integrity. In this paper, the usage of the 360-degree security camera over the traditional webcam was investigated in order to enhance the exam security and to minimize the stressful restrictions. To verify this goal, a case study on a group of volunteer students within the college of computer science and engineering was made. In addition, an automated proctoring model that will eliminate the need for a real-time proctoring and remove any scheduling constraints in order to prevent cheating is proposed in this paper. The machine learning algorithms is exploited to enrich the proposed system. A secure frame work using the biometric is applied in order to ensure authentication and running the online exam smoothly.",https://ieeexplore.ieee.org/document/9350872/,"2020 Emerging Technology in Computing, Communication and Electronics (ETCCE)",21-22 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CISIS.2016.114,Study on Cross-Cutting and Systematic Regional Community Networks,IEEE,Conferences,"Currently, the issues for the time being have become complex and diverse in the region, such as the disappearance of the local government by the super aging population is feared. Therefore from being considered as a tool for problem-solving is ICT to progress rapidly, among the information and communication technology such as IOT(internet of things), CPS(cyber physical system), AI(Artificial intelligence), wearable devices, SNS, a variety of communication pattern and the like. On the other hand, the negative aspects of bringing a rapid development of science and technology that makes light and dark, there is a reality that has been manifest. Moreover it influences big impact on future with economic growth in Asia particular in China, and globalization of the world. What can we do in such situation? First is to visualize a variety of initiatives according to find challenges. Second is to construct the cross-cutting and systematic network for problem-solving. The regional community network is important due to mutually complementary and coordination. Their activities in cooperation with Asian countries, aims to lead to the independence of the local ICT companies.",https://ieeexplore.ieee.org/document/7791953/,"2016 10th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)",6-8 July 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FOCS.2017.98,Subdeterminant Maximization via Nonconvex Relaxations and Anti-Concentration,IEEE,Conferences,"Several fundamental problems that arise in optimization and computer science can be cast as follows: Given vectors v1, ..., vm ∈ ℝd and a constraint family B ⊆ 2[m], find a set S ∈ B that maximizes the squared volume of the simplex spanned by the vectors in S. A motivating example is the ubiquitous data-summarization problem in machine learning and information retrieval where one is given a collection of feature vectors that represent data such as documents or images. The volume of a collection of vectors is used as a measure of their diversity, and partition or matroid constraints over [m] are imposed in order to ensure resource or fairness constraints. Even with a simple cardinality constraint (B = (r[m])), the r problem becomes NP-hard and has received much attention starting with a result by Khachiyan [1] who gave an rO(r) approximation algorithm for this problem. Recently, Nikolov and Singh [2] presented a convex program and showed how it can be used to estimate the value of the most diverse set when there are multiple cardinality constraints (i.e., when B corresponds to a partition matroid). Their proof of the integrality gap of the convex program relied on an inequality by Gurvits [3], and was recently extended to regular matroids [4], [5]. The question of whether these estimation algorithms can be converted into the more useful approximation algorithms - that also output a set - remained open. The main contribution of this paper is to give the first approximation algorithms for both partition and regular matroids. We present novel formulations for the subdeterminant maximization problem for these matroids; this reduces them to the problem of finding a point that maximizes the absolute value of a nonconvex function over a Cartesian product of probability simplices. The technical core of our results is a new anti-concentration inequality for dependent random variables that arise from these functions which allows us to relate the optimal value of these nonconvex functions to their value at a random point. Unlike prior work on the constrained subdeterminant maximization problem, our proofs do not rely on real-stability or convexity and could be of independent interest both in algorithms and complexity where anti-concentration phenomena has recently been deployed.",https://ieeexplore.ieee.org/document/8104130/,2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS),15-17 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCICA52458.2021.9697222,Supervised Classification for Analysis and Detection of Potentially Hazardous Asteroid,IEEE,Conferences,"The use of Artificial Intelligence (AI) in solving real- time problems are increasing day by day with the increase in the availability of data and computation power. It is now substantial to use AI-based tools and techniques in space science. Asteroids, rocky objects that orbit around the sun, often produce an array of effects that cause harm to humans and biodiversity on earth. Such effects can cause wind blast, overpressure shock, thermal radiation, cratering, seismic shaking, ejecta deposition, tsunami, and many more. With the availability of data on asteroid parameters and nature, it provides an opportunity to use Machine Learning (ML) to address this problem and reduce the risk. This paper presents a thorough study on the impact of Potentially Hazardous Asteroids (PHAs) and proposes a supervised machine learning method to detect whether an asteroid with specific parameters is hazardous or not. We compare manifold classification algorithms that were implemented on the data. Random forest gave the best performance in terms of accuracy (99.99%) and average F1- score (99.22%).",https://ieeexplore.ieee.org/document/9697222/,2021 International Conference on Computational Intelligence and Computing Applications (ICCICA),26-27 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIE50891.2020.00111,Supplemental Cultivation Plan of Innovation Quality for the Undergraduates of Building Environment and Energy Engineering in the Applied Technology Universities,IEEE,Conferences,"One of the most fundamental qualities for science research and technology development is the innovation quality, which covers many aspects such as consciousness, method and spirit. The innovation quality developed in the undergraduate period would be the most basic foundation in their over forty-years working life. A supplemental cultivation plan with a routine consisting of hardware, programming, simulation and optimization was presented in this paper for the undergraduates of Building Environment and Energy Engineering (BEEE). The hardware manufacture of digital devices was trained to promote the freshmen manipulative capability, while software programming with general-purpose languages was introduced to enhance the comprehension of data analysis in the 2nd academic year. During the period when some professional courses were taught, the building simulation modular could be introduced to enhance the understanding for the building thermal process and its corresponding Heating, Ventilating, Air-conditioning and Refrigeration (HVAC & R) system. A building management system (BMS) would be developed step by step and interactive with virtual building platform. That BMS and its virtual cases could be employed as the testbed for optimization of HVAC & R system, such as energy consumption prediction, fault detection and diagnosis. Python and EnergyPlus were used in the custom training program oriented to the employment direction for the system operation and maintenance. Group achievements and individual cases show that the presented supplemental cultivation plan played a very important role in the cultivation of BEEE graduates' innovative quality. The effect for the graduated students need pay more attention to investigate the long-term effects, and more volunteers will participate in this plan to find out their better future.",https://ieeexplore.ieee.org/document/9262525/,2020 International Conference on Artificial Intelligence and Education (ICAIE),26-28 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW51313.2020.00082,SynC: A Copula based Framework for Generating Synthetic Data from Aggregated Sources,IEEE,Conferences,"A synthetic dataset is a data object that is generated programmatically, and it may be valuable to creating a single dataset from multiple sources when direct collection is difficult or costly. Although it is a fundamental step for many data science tasks, an efficient and standard framework is absent. In this paper, we study a specific synthetic data generation task called downscaling, a procedure to infer high-resolution, harder-to-collect information (e.g., individual level records) from many low-resolution, easy-to-collect sources, and propose a multi-stage framework called SynC (Synthetic Data Generation via Gaussian Copula). For given low-resolution datasets, the central idea of SynC is to fit Gaussian copula models to each of the low-resolution datasets in order to correctly capture dependencies and marginal distributions, and then sample from the fitted models to obtain the desired high-resolution subsets. Predictive models are then used to merge sampled subsets into one, and finally, sampled datasets are scaled according to low-resolution marginal constraints. We make four key contributions in this work: 1) propose a novel framework for generating individual level data from aggregated data sources by combining state-of-the-art machine learning and statistical techniques, 2) perform simulation studies to validate SynC's performance as a synthetic data generation algorithm, 3) demonstrate its value as a feature engineering tool, as well as an alternative to data collection in situations where gathering is difficult through two real-world datasets, 4) release an easy-to-use framework implementation for reproducibility and scalability at the production level that easily incorporates new data.",https://ieeexplore.ieee.org/document/9346329/,2020 International Conference on Data Mining Workshops (ICDMW),17-20 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISCAS.2011.5937705,Systematic configuration and automatic tuning of neuromorphic systems,IEEE,Conferences,"In the past recent years several research groups have proposed neuromorphic Very Large Scale Integration (VLSI) devices that implement event-based sensors or biophysically realistic networks of spiking neurons. It has been argued that these devices can be used to build event-based systems, for solving real-world applications in real-time, with efficiencies and robustness that cannot be achieved with conventional computing technologies. In order to implement complex event-based neuromorphic systems it is necessary to interface the neuromorphic VLSI sensors and devices among each other, to robotic platforms, and to workstations (e.g. for data-logging and analysis). This apparently simple goal requires painstaking work that spans multiple levels of complexity and disciplines: from the custom layout of microelectronic circuits and asynchronous printed circuit boards, to the development of object oriented classes and methods in software; from electrical engineering and physics for analog/digital circuit design to neuroscience and computer science for neural computation and spike-based learning methods. Within this context, we present a framework we developed to simplify the configuration of multi-chip neuromorphic VLSI systems, and automate the mapping of neural network model parameters to neuromorphic circuit bias values.",https://ieeexplore.ieee.org/document/5937705/,2011 IEEE International Symposium of Circuits and Systems (ISCAS),15-18 May 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIMS.2013.4,Table of contents,IEEE,Conferences,"The following topics are dealt with: artificial intelligence; neural networks and fuzzy systems; evolutionary computation; bioinformatics and bioengineering; data and semantic mining; games, VR and visualization; intelligent systems and applications; systems intelligence; control intelligence; e-science and e-systems; robotics, cybernetics, engineering, and manufacturing; operations research; discrete-event and real-time systems; image, speech and signal processing; industry, business, management, human factors and social issues; energy, power, transport, logistics, harbour, shipping and marine simulation; parallel, distributed, and software architectures and systems; mobile-ad hoc wireless networks, Mobicast, sensor placement, and target tracking; performance engineering of computer and communications systems; and circuits and devices.",https://ieeexplore.ieee.org/document/6959881/,"2013 1st International Conference on Artificial Intelligence, Modelling and Simulation",3-5 Dec. 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICOSP.2014.7014957,Table of contents,IEEE,Conferences,The following topics are dealt with: digital signal processing; spectrum estimation & modeling; TF spectrum analysis & wavelet; adaptive filtering; array signal processing; hardware implementation; speech and audio coding; speech synthesis & recognition; music information processing; speech quality improvements; flexible feature control; medical image processing; partial differential equation; video compression & streaming; computer vision; virtual reality; multimedia & human-computer interaction; statistic learning; pattern recognition; artificial intelligence; neural networks; communication signal processing; Internet and wireless communications; biometrics & authentification; bio-medical & cognitive science; security; radar signal processing; sonar signal processing and localization; and sensor networks.,https://ieeexplore.ieee.org/document/7014957/,2014 12th International Conference on Signal Processing (ICSP),19-23 Oct. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CLEI.2017.8226366,Table of contents,IEEE,Conferences,The following topics are dealt with: computer science education; medical image processing; robotics; programming languages; virtual reality; optical network; GSO network; LEO network; computer vision; graph coloring; machine learning; vehicle routing; neural network; computer aided instruction; data mining; service-oriented architecture; software development; social network; e-health; bioinformatics; and business process.,https://ieeexplore.ieee.org/document/8226366/,2017 XLIII Latin American Computer Conference (CLEI),4-8 Sept. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CISIS.2013.4,Table of contents,IEEE,Conferences,The following topics are dealt with: complex system; intelligent system; software intensive system; cooperative communication; relaying; distributed MIMO; adaptive learning; interactive approach; collaborative approach; emotional approach; complex distributed system engineering; parallel system engineering; multicore system engineering; hybrid cloud computing; e-science; intelligent context-aware system; large-scale system; intelligent informatics; biology; medicine; human-computer interaction; intelligent service; sustainable education; information management; tourism; virtual environment; and network-oriented application.,https://ieeexplore.ieee.org/document/6603816/,"2013 Seventh International Conference on Complex, Intelligent, and Software Intensive Systems",3-5 July 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC.2013.4,Table of contents,IEEE,Conferences,The following topics are dealt with: collaborative wireless sensor networks; Internet of Things technology; decision support systems; energy-efficient systems; intelligent Internet systems; human-machine interaction; systems science; soft computing; discrete event systems; healthcare system; distributed manufacturing systems; distributed adaptive systems; granular computing; environmental sensing; decision making; agent-based systems; intelligent real-time automation; medical mechatronics; machine learning; Big Data; medical image processing; medical signal processing; biomedical systems; hybrid metaheuristics; intelligent learning; control systems; unmanned aerial vehicles; collaborative manufacturing and supply chains; computational awareness; pervasive computing; ubiquitous computing; intelligent network computing; complex systems; cybernetic intelligent systems; human-centered transportation systems; driver-vehicle systems; haptics interface; cloud computing; and enterprise systems.,https://ieeexplore.ieee.org/document/6721755/,"2013 IEEE International Conference on Systems, Man, and Cybernetics",13-16 Oct. 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCEA.2010.4,Table of contents - Volume 1,IEEE,Conferences,The following deals with the following topics: algorithms; artificial intelligence; software engineering; bioinformatics; computer graphics; computer architecture; information systems; computer aided instruction; computer games; virtual reality; data security; digital simulation; computer aided design; ethical aspects; database systems; digital libraries; signal processing; image processing; logic design; e-commerce; human computer interaction; embedded systems; Internet; mobile computing; multimedia systems; natural language processing; neural networks; programming languages; robotics; control systems; theoretical computer science; and wireless sensor networks.,https://ieeexplore.ieee.org/document/5445635/,2010 Second International Conference on Computer Engineering and Applications,19-21 March 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCRD.2011.5764067,Table of contents vol. 01,IEEE,Conferences,The following topics are dealt with: computer research and development; event driven programming; artificial intelligence; expert systems; algorithm analysis; high performance computing; automated software engineering; human computer interaction; bioinformatics; scientific computing; image processing; information retrieval; compilers; interpreters; computational intelligence; computer architecture; embedded systems; computer animation; Internet; Web applications; communication/networking; knowledge data engineering; computer system implementation; logics; VLSI; mathematical software; information systems; computer based education; mathematical logic; mobile computing; computer games; multimedia applications; computer graphics; virtual reality; natural language processing; neural networks; computer modeling; parallel computing; distributed computing; computer networks; pattern recognition; computer security; computer simulation; computer vision; probability; statistics; performance evaluation; computer aided design/manufacturing; computing ethics; programming languages; problem complexity; control systems; physical sciences; engineering; discrete mathematics; reconfigurable computing systems; data communications; robotics; automation; system security; cryptography; data compression; data encryption; data mining; database systems; document processing; text processing; educational technology; digital library; technology management; digital signal processing; theoretical computer science; digital systems; logic design; ubiquitous computing; and visualizations.,https://ieeexplore.ieee.org/document/5764067/,2011 3rd International Conference on Computer Research and Development,11-13 March 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDE53745.2022.00322,Tell Me How to Survey: Literature Review Made Simple with Automatic Reading Path Generation,IEEE,Conferences,"Recent years have witnessed the dramatic growth of paper volumes with plenty of new research papers published every day, especially in the area of computer science. How to glean papers worth reading from the massive literature to do a quick survey or keep up with the latest advancement about a specific research topic has become a challenging task. Existing academic search engines return relevant papers by individually calculating the relevance between each paper and query. However, such systems usually omit the prerequisite chains of a research topic and cannot form a meaningful reading path. In this paper, we introduce a new task named Reading Path Generation (RPG) which aims at automatically producing a path of papers to read for a given query. To serve as a research benchmark, we further propose SurveyBank, a dataset consisting of large quantities of survey papers in the field of computer science as well as their citation relationships. Furthermore, we propose a graph-optimization-based approach for reading path generation which takes the relationship between papers into account. Extensive evaluations demonstrate that our approach outperforms other baselines. A real-time Reading Path Generation (RePaGer) system has been also implemented with our designed model. Our source code and SurveyBank dataset can be found here<sup>1</sup><sup>1</sup>https://github.com/JiayuanDing100/Reading-Path-Generation.",https://ieeexplore.ieee.org/document/9835398/,2022 IEEE 38th International Conference on Data Engineering (ICDE),9-12 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCSA.2007.90,The 2007 International Conference Computational Science and its Applications - Title,IEEE,Conferences,The following topics are dealt with: computational intelligence; high performance technical computing; information systems; Web based learning; component based software engineering; software process model; computational geometry; distributed computing; digital content security; data storage devices; data storage systems; intelligent design technology; intelligent data mining; information services; information technologies; mobile multimedia networks; pattern recognition; ubiquitous computing; computer graphics; computational science; wireless sensor networks; virtual reality; optimization; mobile communication; molecular simulations.,https://ieeexplore.ieee.org/document/4301111/,2007 International Conference on Computational Science and its Applications (ICCSA 2007),26-29 Aug. 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCSE51940.2021.9569551,The Integration Development of Artificial Intelligence and Education,IEEE,Conferences,"With the rapid progress and development of modern information science and technology, artificial intelligence technology has become more and more extensive in many fields. How to incorporate artificial intelligence into education has become a hot topic of the whole society. In this paper, analysis of artificial intelligence used to extract application potential and value of intelligent correction, real-time monitoring, education fairness and campus safety. But there are also challenges in personality education, safety ethics, teaching efficiency, etc. In order to make artificial intelligence better serve the education industry, it is necessary to increase the infrastructure construction and environment configuration of artificial intelligence equipment. And then improving the education practitioners’ awareness and correct cognition of the relationship between intelligent machine safety ethics and artificial intelligence.",https://ieeexplore.ieee.org/document/9569551/,2021 16th International Conference on Computer Science & Education (ICCSE),17-21 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITAIC54216.2022.9836597,The Logistics Barcode ID Character Recognition Method Based on AKAZE Feature Localization,IEEE,Conferences,"With the continuous development of science and technology, the rapid rise of e-commerce, and the continuous influx of the logistics industry into our lives. In the transportation of logistics, the sorting is the mainly work, it needs machines or staff using barcode scanners to identify barcodes to achieve sorting. Meantime, it is necessary to align the barcode of the item manually or mechanically with the barcode scanner to accurately identify it. Undoubtedly, a lot of manpower and material resources are required in the sorting process, so the method of computer vision processing is used to achieve automatic detection and identification of barcode ID will have great significance. The authors propose a logistics barcode ID character recognition method based on local positioning of AKAZE features to realize the detection and identification of logistics barcode ID in a long distance and a large range. First, extracting the AKAZE feature of the barcode in the image, using the matching algorithm to localize the barcode area, and then use the OCR (Optical Character Recognition) method based on deep learning to perform the character recognition of the barcode ID. A large number of experiments have been carried out with the real existing parcel barcodes, in which the accuracy rate reaches 99.6&#x0025;, the speed reaches 0.35s/frame. Besides, the detection and identification of barcode IDs of different types and different length codes can be realized. The adoption in the future will further promote the feasibility of the logistics and transportation industry.",https://ieeexplore.ieee.org/document/9836597/,2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),17-19 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ELECTR.1994.472691,The broad use of neural networks in real-time engineering systems,IEEE,Conferences,"Neural networks is a very popular emerging technology that has applications in a wide variety of fields such as: electrical and computer engineering, signal processing, computer science, cognitive science, neurobiology, optics, mathematics, and physics. Properties of this multidisciplinary field, originally inspired by biological systems, are adaptiveness and self organization, massively parallel nature, robustness and fault- and noise-tolerance. This paper, after presenting an overview of neural networks, their properties and advantages over conventional computers, will discuss how novel neural network architectures and implementations can be included in larger systems to provide solutions to scientific and engineering problems. An example of a neural network hearing model is discussed where neural networks and time-frequency analysis are used to extract essential information from complex inputs.<>",https://ieeexplore.ieee.org/document/472691/,Proceedings of ELECTRO '94,10-12 May 1994,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICACITE51222.2021.9404738,The learning approaches using Augmented Reality in learning environments: Meta-Analysis,IEEE,Conferences,"With the emergence of Industrial Revolution 4.0, the educational settings are changing quickly. Augmented Reality (AR) is one of the upcoming technologies. AR enhances the real world by overlaying/augmenting the virtual/digital information over it. It provides the user with the ability to interact with the created virtual world in real space. The aim of this study is to classify the learning approaches implemented through AR technology. The technique used for the analysis is derived from systematic search of online literature databases like Taylor Francis, Web of Science, Springer, ScienceDirect and Scopus. The keywords used for the search include learning approaches, AR, AR in education, AR in learning and teaching and integration approaches. The findings of this research work highlights 4 categories of educational learning approaches that highlight AR. The approaches are experimental learning, game-based, interactive and collaborative learning. The research findings can be referred by other researchers and educators to identify the potential of AR in education and the learning approaches currently used with AR for their further research on how these approaches can be effectively and efficiently implemented in educational settings.",https://ieeexplore.ieee.org/document/9404738/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCI-CC.2017.8109799,The power of cognitive computing: An example of cognitive dynamic regional development modeling,IEEE,Conferences,"This presentation concerns some idea of what could be done, in the author's view, to help make Wang's cognitive informatics a powerful and viable source of tools and techniques for solving various real life problems. First, we give a brief account of cognitive informatics meant as a multidisciplinary field within informatics, or computer science, that is based on results of cognitive and information sciences, and which deals with human information processing mechanisms and processes and their decision theoretic, engineering, etc. applications in broadly perceived computing. We focus on its purpose, i.e. to develop and implement technologies to facilitate and extend the information acquisition, comprehension and processing capacity of humans. Emphasis is on underlying processes in the brain. However, we advocate an extended approach in which though the very cognitive informatics is the foundation, as those processes in the brain are crucial, some sort of an “outer” cognitive informatics is needed which explicitly makes reference not what proceeds “internally” in the brain, because we do not “see” this, but “externally”, i.e. what people can see, judge, evaluate, etc., and what is clearly a result of cognitive information specific processes in the brain. This line of reasoning is in line with the very essence of comprehension, memorizing, learning, choice and decision making, satisfaction with partial truth, allowing for not perfect solutions, etc. dealt with using tools and techniques derived from many areas like psychology, behavioral science, neuroscience, artificial intelligence, linguistics, neuroeconomics etc. In our case, we will concentrate on some cognitive informatics type elements that mostly have been inspired by psychology and behavioral sciences, as our problem is inherently related to human judgments and perceptions, but we will mentioned some inspirations from neuroscience, notably along the lines of neuroeconomics. Cognitive informatics constitutes a foundation of its related new field, cognitive computing, which is basically a new direction in broadly perceived intelligent computing and systems that synergistically combines results from many areas, e.g., information science, computational sciences, computer science, artificial and computational intelligence, cybernetics, systems science, cognitive science, (neuro)psychology, brain science, linguistics, etc. to just mention a few. We try to show on an example of a dynamic systems modeling, more specifically scenario based regional development planning, that cognitive computing can provide new conceptual and implementation vistas. Basically, we consider a region that is characterized by 7 life quality indicators related to economic, social, environmental, etc. qualities, which evolve over some planning horizon due to some investments, mostly by some regional or governmental agencies. There are some scenarios of investment levels over the planning horizon, meant for the development of the particular life quality indexes, and some desired levels of these indexes, both objective, i.e. set by authorities, and subjective, i.e. perceived by the inhabitant groups. As a result of a particular investment scenario, the life quality indexes evolve over the planning horizon, and their temporal evolution is evaluated by the authorities and inhabitants. This evaluation has both an objective, i.e. against the “officially” set thresholds, and subjective, i.e. as perceived by various humans and their groups. Basically, we employ Kacprzyk's fuzzy dynamic programming based approach to the modeling and planning/programming of sustainable regional development, with soft constraints and goals, but we advocated a more sophisticated assessment of variability, stability, balancedness of consecutive investments. In this process we try to develop evaluation measures, and then the optimization type model using concepts that can be effectively and efficiently handled by cognitive computing, notably the inclusion of the so called decision making and behavioral biases, biases in probability and belief, social biases, memory errors, etc. Moreover, we strongly reflect the so called status quo and minimal change biases. By using many results from social sciences, psychology, behavioral economics, neuroeconomics, etc. on human judgments and human centric evaluations, we augment a traditional purely effectiveness and efficiency oriented analysis by a more sophisticated analysis of effects of variability of temporal evolution of some life quality indicators on the human perception of its goodness. The model presented, which has been employed for years as part of large mathematical modeling projects for sustainable regional development in many regions in Asia and Europe, is illustrated on an example with scenario analysis for a rural region plagued by social and economic difficulties in which subsidies should properly be distributed over time to obtain a best overall socioeconomic effect. In this talk we present the model in a different perspective, based first on the basic Wang's cognitive informatics and its Wang and Ruhe's decision making application, and then based on new, more comprehensive cognitive computing. We show that this provides a novel insight.",https://ieeexplore.ieee.org/document/8109799/,2017 IEEE 16th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),26-28 July 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SIIE.2014.7017703,The use of SCRUM for laboratory sessions monitoring and evaluation in a university course enforcing transverse competencies,IEEE,Conferences,"This paper introduces a pilot experience on the use of SCRUM methodology, borrowed from software project development and management, in group laboratory sessions during a university course of agent-based programming (fourth year of the Degree on Computer Science in the University of Granada). It aims to foster a higher awareness of students and to enforce a series of transverse competencies like real, structured and self-organized teamwork, better planning of time during the laboratory sessions. As a side effect, it empowers leadership amongst the members of the team as well as it enables a high quality evaluation of students.",https://ieeexplore.ieee.org/document/7017703/,2014 International Symposium on Computers in Education (SIIE),12-14 Nov. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE53849.2021.00073,Time series simulation method of meteorological elements based on ARIMA model,IEEE,Conferences,"With the development of science and technology and economy, environmental monitoring technology and means are constantly enriched and improved, and the information of meteorological big data is gradually diversified, which brings convenience to the study of meteorological trend that thus provides corresponding guidance for industrial and agricultural production. In recent years, the construction of environmental monitoring stations has been accelerated, and they are popular in the study of meteorological trends in various countries because of their real-time characteristics and wide range of data. In this paper, the characteristics of key meteorological elements at different time scales are statistically analyzed firstly based on the measured meteorological data of regional meteorological stations that meteorological elements have significant tendency and seasonality. Secondly, the obtained meteorological big data is pre-processed to eliminate bad data, and then the probability distribution of meteorological elements and their change rules is extracted. Finally, a time series method based on ARIMA model is proposed to simulate the rule of weather change, so as to obtain the time series of temperature and rainfall in the next ten years, which can provide theoretical and data support for various industries, and help meteorological and security departments to make work plans in time and correctly.",https://ieeexplore.ieee.org/document/9696084/,2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),24-26 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MACISE49704.2020.00022,Toward General AI: Consciousness Computational Modeling Under Uncertainty,IEEE,Conferences,"The modern expert and statistical computing systems of Artificial Intelligence do not understand what they are doing when they operate under uncertainty and changing situations in the fuzzy environment. Towards a solution this problem, we propose the method, model and system of Consciousness Computational Modeling Under Uncertainty for Systems of General Artificial Intelligence. The functionality of this concept is implemented by developed methods and models of organization of neural semantic network Memory, using the self-organized Subject Area Thesaurus (Knowledge Base), of situational Fuzzy Control of data, information, knowledge and objects, Fuzzy Inference, Decision Making, Knowledge Representation, Knowledge Generalization, Knowledge Explanation, Reasoning, Systems Thinking, Cognition, Intelligent User Interface, Computational Systemic Mind, Awareness and Full Understanding of the reality. For modeling of this functionality, the main achievements of Systems Approach, Fuzzy Logic, Situational Control, Linguistics and Computer Science at whole were applied.",https://ieeexplore.ieee.org/document/9195575/,2020 International Conference on Mathematics and Computers in Science and Engineering (MACISE),14-16 Jan. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/OCEANSChennai45887.2022.9775330,Towards Real-time Analysis of Marine Phytoplankton Images Sampled at High Frame Rate by a YOLOX-based Object Detection Algorithm,IEEE,Conferences,"Rapid and quantitative analysis of phytoplankton cells in natural seawater is of great need for marine ecological science research and harmful algae bloom monitoring applications. In this paper, we propose a YOLOX network-based object detection algorithm exclusively for high-throughput real-time analysis of phytoplankton fluorescence images collected by the FluoSieve<sup>&#x00AE;</sup> imaging flow cytometer. Based on an active learning strategy, we first annotate and construct a FluoPhyto dataset of red tide phytoplankton species fluorescence images commonly found in the South and East China Sea, which contains a total of 30,339 images in 32 different categories. Using the dataset, we train the Faster-RCNN, SSD, YOLOv3 and YOLOX networks, and the comparison result shows that the performance of YOLOX network outperforms the other networks, which can reach a mean average precision (mAP) of 90.9%. The trained YOLOX model is then deployed on an embedded GPU module and the inference speed is tested to reach 20 fps with the help of TensorRT optimization, which can hopefully meet the real-time detection requirements of the instrument. In addition, the algorithm is run on the embedded platform for detection of images collected in a red tide event that happened near the Pearl River Estuary, and the key parameters such as abundance and size spectrum of the dominant species, Cochlodinium geminatum, are obtained, which confirms the feasibility and superior performance of the detection algorithm.",https://ieeexplore.ieee.org/document/9775330/,OCEANS 2022 - Chennai,21-24 Feb. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCI-CC.2018.8482093,Towards a Methodology for RTPA-MATLAB Code Generation Based on Machine Learning Rules,IEEE,Conferences,"Autonomous program code generation by machine learning is not only an ultimate goal but also a theoretical challenge to software science and engineering. A methodology and case study for code generation based on Real-Time Process Algebra (RTPA) by machine learning are presented in this paper. It describes a machine learning approach for code generation in MATLAB based on acquired RTPA rules and formal specifications. The design and implementation of the RTPA-MATLAB code generator is introduced, which is implemented by an RTPA parser and an MATLAB code builder. The experimental case studies have demonstrated the novelty of the theories and methodologies for code generation based on machine-learnt programming rules.",https://ieeexplore.ieee.org/document/8482093/,2018 IEEE 17th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),16-18 July 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCGrid.2015.74,Towards a Realistic Scheduler for Mixed Workloads with Workflows,IEEE,Conferences,"Many fields of modern science require huge amounts of computation, and workflows are a very popular tool in e-Science since they allow to organize many small, simple tasks to solve big problems. They are used in astronomy, bioinformatics, machine learning, social network analysis, physics, and many other branches of science. Workflows are notoriously difficult to schedule, and the vast majority of research on workflow scheduling is concerned with scheduling single workflows with known runtimes. The goal of this PhDresearch is to bring more realism to the problem of workflow scheduling in actual systems. First, in real systems, multiple workflows may be contending for the available resources. Second, task runtime estimates are not always known, and task runtime estimates may be wrong. Third, workflows are usually not the only type of jobs submitted to a system, there may for instance also be parallel applications and bags-of-tasks. Accordingly, the purpose of this PhD research is to create and analyze policies for online scheduling of workloads of workflows with and without known task runtimes that also contain jobs of other types. We are in the process of simulating policies, and we will validate our results by means of an implementation and real-world experiments with the KOALA-Workflow processing system.",https://ieeexplore.ieee.org/document/7152549/,"2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",4-7 May 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CISIS.2015.20,Towards an Analytical Framework to Enhance Teaching Support in Digital Systems Design Course,IEEE,Conferences,"Learning digital systems design is a difficult skill that students of Bachelors on Computer Science, Electronic Engineering or Telecommunications have to acquire in the initial courses. The problem aggravates when the student is learning in a virtual environment with no face-to-face interaction with the instructor. In this case, simulators or intelligent tutoring systems, such as Veril UOC [1], are used in order to acquire this skill. This paper describes several improvements introduced in the instructor view of this framework Veril UOC. The new information that can be extracted of the system can improve the personalized feedback that the instructor can perform to the students, and, at the same time, the real-time information gives insights related to the course's operation.",https://ieeexplore.ieee.org/document/7185179/,"2015 Ninth International Conference on Complex, Intelligent, and Software Intensive Systems",8-10 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CA.2001.982382,Towards the Holodeck: building emotional virtual humans for training,IEEE,Conferences,"I describe a collaborative effort between members of the entertainment and research communities to advance the state of immersive training technology. Pulling together Hollywood's expertise in story, visual effects and production, with expertise in graphics, gaming, artificial intelligence, linguistics, cognitive science, and audio processing, a group of researchers, storytellers and graphic artists is trying to approximate the Holodeck (the ultimate training and entertainment device of the 24th century, as popularized by the TV series Star Trek).",https://ieeexplore.ieee.org/document/982382/,Proceedings Computer Animation 2001. Fourteenth Conference on Computer Animation (Cat. No.01TH8596),7-8 Nov. 2001,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC48688.2020.0-230,Training Confidence-Calibrated Classifier via Distributionally Robust Learning,IEEE,Conferences,"Supervised learning via empirical risk minimization, despite its solid theoretical foundations, faces a major challenge in generalization capability, which limits its application in real-world data science problems. In particular, current models fail to distinguish in-distribution and out-of-distribution and give over confident predictions for out-of-distribution samples. In this paper, we propose an distributionally robust learning method to train classifiers via solving an unconstrained minimax game between an adversary test distribution and a hypothesis. We showed the theoretical generalization performance guarantees, and empirically, our learned classifier when coupled with thresholded detectors, can efficiently detect out-of-distribution samples.",https://ieeexplore.ieee.org/document/9201929/,"2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)",13-17 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCAD45719.2019.8942103,Tucker Tensor Decomposition on FPGA,IEEE,Conferences,"Tensor computation has emerged as a powerful mathematical tool for solving high-dimensional and/or extreme-scale problems in science and engineering. The last decade has witnessed tremendous advancement of tensor computation and its applications in machine learning and big data. However, its hardware optimization on resource-constrained devices remains an (almost) unexplored field. This paper presents an hardware accelerator for a classical tensor computation framework, Tucker decomposition. We study three modules of this architecture: tensor-times-matrix (TTM), matrix singular value decomposition (SVD), and tensor permutation, and implemented them on Xilinx FPGA for prototyping. In order to further reduce the computing time, a warm-start algorithm for the Jacobi iterations in SVD is proposed. A fixed-point simulator is used to evaluate the performance of our design. Some synthetic data sets and a real MRI data set are used to validate the design and evaluate its performance. We compare our work with state-of-the-art software toolboxes running on both CPU and GPU, and our work shows 2.16 – 30.2× speedup on the cardiac MRI data set.",https://ieeexplore.ieee.org/document/8942103/,2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),4-7 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CEC.2014.6900322,Type-II opposition-based differential evolution,IEEE,Conferences,"The concept of opposition-based learning (OBL) can be categorized into Type-I and Type-II OBL methodologies. The Type-I OBL is based on the opposite points in the variable space while the Type-II OBL considers the opposite of function value on the landscape. In the past few years, many research works have been conducted on development of Type-I OBL-based approaches with application in science and engineering, such as opposition-based differential evolution (ODE). However, compared to Type-I OBL, which cannot address a real sense of opposition in term of objective value, the Type-II OBL is capable to discover more meaningful knowledge about problem's landscape. Due to natural difficulty of proposing a Type-II-based approach, very limited research has been reported in that direction. In this paper, for the first time, the concept of Type-II OBL has been investigated in detail in optimization; also it is applied on the DE algorithm as a case study. The proposed algorithm is called opposition-based differential evolution Type-II (ODE-II) algorithm; it is validated on the testbed proposed for the IEEE Congress on Evolutionary Computation 2013 (IEEE CEC-2013) contest with 28 benchmark functions. Simulation results on the benchmark functions demonstrate the effectiveness of the proposed method as the first step for further developments in Type-II OBL-based schemes.",https://ieeexplore.ieee.org/document/6900322/,2014 IEEE Congress on Evolutionary Computation (CEC),6-11 July 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SCCC.1999.810151,Virtual guides to assist visitors in the SAGRES virtual museum,IEEE,Conferences,"The SAGRES system is an environment on the Web, that facilitates the presentation of museum information, in a manner adapted to the individual characteristics of each visitor. The interaction with the system may occur individually or in groups of students. The system also offers resources to support some forms of cooperative learning, allowing visitors to interact both synchronously and asynchronously, and both locally, inside the museum, and non-locally, in places geographically distant from the museum. The visitors are assisted by virtual guides, software agents, which monitor the visitors' actions. The agents use the directed improvisation human-computer interaction paradigm to interact with visitors. They improvise, while helping the visitor, a group of behaviors similar to human behaviors (happiness, satisfaction and vibration), making the interaction more friendly. This system has been developed in the Museum of Science and Technology at PUCRS, Porto Alegre, Brazil.",https://ieeexplore.ieee.org/document/810151/,Proceedings. SCCC'99 XIX International Conference of the Chilean Computer Science Society,13-13 Nov. 1999,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FIE.2006.322736,Work in Progress: An Intelligent Tutoring System for Forensic Biology,IEEE,Conferences,"The Interactive Virtual Intelligent System for Scientific Inquiry in a Biology Learning Environment (INVISSIBLE) is software environment being developed as a intelligent tutoring system that provides high school biology students a virtual, hands-on, multimedia learning environment. Using interactive, intelligent software, a student is placed in goal driven scenarios that reflect the authentic experiences of a scientist engaged in using scientific inquiry methods. This paper describes the first of three planned modules, one which involves forensic science and the use of DNA evidence in combination with hairs, fibers, and other evidence in solving a crime scene problem. Core objectives of this module are to increase student learning regarding: (a) knowledge acquisition of content, concepts and principles relevant to genetics, forensic science, and evolutionary biology, (b) relevant scientific process skills and knowledge, and (c) knowledge of nature and methods of science. A demonstration of the software will be given",https://ieeexplore.ieee.org/document/4117057/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/FIE.2010.5673167,Work in progress — A biomedical motif for teaching Artificial Intelligence in Context,IEEE,Conferences,"The majority of the classes in a typical computer science program focus on the computer as an entity and the resulting development infrastructure. Examples include hardware principles, architecture and theory, along with software development tools and processes. Recent studies have suggested that a focus on the computational infrastructure in the absence of an external application domain may reinforce the stereotype of CS student fixation on the computer for some, while alienating a subset of students, especially women, who may be attracted to using the computer to solve broader problems. Recognizing this situation has inspired recent explorations on teaching computer science within an application context. Even classes traditionally focused on techniques and problems beyond the computer itself, such as Computer Graphics and Artificial Intelligence (AI), are often presented as a collection of techniques, programs, and principles without systematic ""real-world"" grounding. Inspired by work on teaching Computer Graphics in context, this work-in-progress describes an infrastructure for embedding a biomedical motif into the traditional Artificial Intelligence course.",https://ieeexplore.ieee.org/document/5673167/,2010 IEEE Frontiers in Education Conference (FIE),27-30 Oct. 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPSW.2019.00142,Workflow-Driven Distributed Machine Learning in CHASE-CI: A Cognitive Hardware and Software Ecosystem Community Infrastructure,IEEE,Conferences,"The advances in data, computing and networking over the last two decades led to a shift in many application domains that includes machine learning on big data as a part of the scientific process, requiring new capabilities for integrated and distributed hardware and software infrastructure. This paper contributes a workflow-driven approach for dynamic data-driven application development on top of a new kind of networked Cyberinfrastructure called CHASE-CI. In particular, we present: 1) The architecture for CHASE-CI, a network of distributed fast GPU appliances for machine learning and storage managed through Kubernetes on the high-speed (10-100Gbps) Pacific Research Platform (PRP); 2) A machine learning software containerization approach and libraries required for turning such a network into a distributed computer for big data analysis; 3) An atmospheric science case study that can only be made scalable with an infrastructure like CHASE-CI; 4) Capabilities for virtual cluster management for data communication and analysis in a dynamically scalable fashion, and visualization across the network in specialized visualization facilities in near real-time; and, 5) A step-by-step workflow and performance measurement approach that enables taking advantage of the dynamic architecture of the CHASE-CI network and container management infrastructure.",https://ieeexplore.ieee.org/document/8778399/,2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),20-24 May 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIVR46125.2019.00065,XR for Augmented Utilitarianism,IEEE,Conferences,"Steady progresses in the AI field create enriching possibilities for society while simultaneously posing new complex challenges of ethical, legal and safety-relevant nature. In order to achieve an efficient human-centered governance of artificial intelligent systems, it has been proposed to harness augmented utilitarianism (AU), a novel non-normative ethical framework grounded in science which can be assisted e.g. by Extended Reality (XR) technologies. While AU provides a scaffold to encode human ethical and legal conceptions in a machine-readable form, the filling in of these conceptions requires a transdisciplinary amalgamation of scientific insights and preconditions from manifold research areas. In this short paper, we present a compact review on how XR technologies could leverage the underlying transdisciplinary AI governance approach utilizing the AU framework. Towards that end, we outline pertinent needs for XR in two hereto related contexts: as experiential testbed for AU-relevant moral psychology studies and as proactive AI Safety measure and enhancing policy-by-simulation method preceding the deployment of AU-based ethical goal functions.",https://ieeexplore.ieee.org/document/8942355/,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),9-11 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData50022.2020.9378023,Zero-Shot Machine Learning Technique for Classification of Multi-User Big Data Workloads,IEEE,Conferences,"During the last decade machine learning has revolutionized computer science applications. Supervised machine learning algorithms have become especially successful in many industries including health, legal, security, finance, travel, and others. Training supervised learning algorithms, however, is expensive because the real world contains a very large number of different classes that need to be covered by the training set. This is especially true for the highly variable, multi-user workload data produced by the strategically vital big data and cloud software stacks. It is very important, however, to be able to accurately classify these complex workloads in order to enable autonomic management and optimization. Zero-Shot Learning (ZSL) is an advanced machine learning approach that enables classification of objects without having to explicitly train on examples of those objects. In this paper we present a new ZSL technique intended to reduce the expense of assembling workload training sets for big data analytic workloads. We demonstrate that multi-user big data workloads can be treated as hybrids of simpler, single-user workload classes, and classified accurately without having to explicitly train on example instances of multi-user workloads. Our technique is able to accurately classify both unseen multi-user workloads, and seen single-user workloads using the same classifier. We demonstrate 83% classification accuracy for the unseen multi-user workloads, and 92% classification accuracy for the seen, single-user workload classes.",https://ieeexplore.ieee.org/document/9378023/,2020 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSMC.2011.6083632,[Copyright notice],IEEE,Conferences,The following topics are dealt with: brain-machine interface; machine learning technology; service systems; homeland security systems; virtual reality; agent-based modeling; human centered transportation systems; awareness science and engineering; soft computing; enterprise information systems; social signal processing; infrastructure system; manufacturing systems; pattern recognition; medical mechatronics; minimally invasive surgery; medical robotics; medical technology; intelligent power systems; discrete event systems; Petri nets; biometrics; bioinformatics; computational intelligence; supply chain management; shared control; fault diagnosis; systems engineering; Internet; support vector machines; knowledge acquisition; cloud computing; grey systems; humanoid robots; redundant manipulators; formal methods; granular computing; wireless sensor networks; nonlinear control systems; gesture-based interaction; software engineering; multi-agent systems; cognitive computing; social robotics; natural language processing; conflict resolution; intelligent transportation systems; human-robot interaction; image processing; medical informatics; decision support systems; assistive technology; human-centered design; data mining; and anti-terrorism applications.,https://ieeexplore.ieee.org/document/6083632/,"2011 IEEE International Conference on Systems, Man, and Cybernetics",9-12 Oct. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UKSim.2012.123,[Cover art],IEEE,Conferences,The following topics are dealt with: neural networks; evolutionary computation; adaptive dynamic programming; re-enforcement learning; bio-informatics; bio-engineering; computational finance; economics; semantic mining; data mining; virtual reality; data visualization; intelligent systems; soft computing; hybrid computing; e-science; e-systems; robotics; cybernetics; manufacturing; engineering; operations research; discrete event systems; real time systems; image processing; speech processing; signal processing; industry; business; social issues; human factors; marine simulation; power systems; logistics;parallel systems; distributed systems; software architectures;Internet modelling; semantic Web; ontologies; mobile ad hoc wireless networks; Mobicast; sensor placement; target tracking; circuits; sensors and devices.,https://ieeexplore.ieee.org/document/6205540/,2012 UKSim 14th International Conference on Computer Modelling and Simulation,28-30 March 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIMS.2014.74,[Keynote Speaker-2] Challenges in Handling and Processing Huge Data,IEEE,Conferences,"Summary form only given, as follows. Data-intensive computing is considered as the fourth paradigm in science. The term “data-intensive computing” did not establish in other communities although they are also confronted with enormous amounts of data. Nowadays, Big Data refers to data sets that are too large, too complex, too distributed for analysing them by conventional methods. One strategy for handling Big Data is known as “software to the data” which is applicable when it is more efficient to bring the analysis tools to the data than, vice versa, to apply traditional methods where, for example, all data are collected at some place and analysed there. The data production rate is expected to increase exponentially for the time being. This is particularly true in science where the resolution power of experiments is steadily improving. Sooner or later it has to be taken into account that it is not feasible to store all data anymore. A new era is on the horizon: Huge Data. Huge Data have to be pre-analysed during the data-taking period in order to extract a sufficiently small subset of data that is worth to be analysed in more detail later on. An effective and efficient preselection in real-time or near-realtime is most critical for successfully handling Huge Data. This is made more challenging if during the pre-analysis that has to be done in parallel, intermediate results have to be exchanged. The talk considers selected challenges of Huge Data. Some examples from different scientific communities are presented. The complete presentation was not made available for publication as part of the conference proceedings.",https://ieeexplore.ieee.org/document/7102425/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIMS.2015.1,[Title page i],IEEE,Conferences,The following topics are dealt with: artificial intelligence; neural networks; fuzzy systems; evolutionary computation; bioinformatics; bioengineering; data mining; semantic mining; games; VR; visualization; intelligent systems applications; hybrid computing; soft computing; intelligent systems control; control intelligence; e-science; e-systems; robotics; cybernetics; manufacturing system; operations research; discrete event systems; real time systems; signal processing; speech processing; image processing; natural language processing; human factors; social issues; shipping; marine simulation; transport; logistics; mobile ad hoc wireless networks; Mobicast; sensor placement; target tracking; software architectures; distributed systems; parallel systems; power simulation; performance engineering; communication systems; and circuits.,https://ieeexplore.ieee.org/document/7604531/,"2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)",2-4 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UKSim.2013.1,[Title page i],IEEE,Conferences,The following topics are dealt with: neural networks; fuzzy systems; evolutionary computation; dynamic programming; reinforcement learning; bioinformatics; bioengineering; computational finance; computational economics; computer games; virtual reality; data visualization; computer networks; intelligent systems; soft computing; intelligent control; e-science; e-systems; robotics; cybernetics; manufacturing systems; operations research; discrete event systems; realtime systems; image processing; speech processing; signal processing; natural language processing; business management; human factors; renewable energy; logistics; parallel architecture; distributed architecture; software architecture; Internet; ontologies; wireless networks; target tracking; performance engineering; circuits; and sensors.,https://ieeexplore.ieee.org/document/6527370/,2013 UKSim 15th International Conference on Computer Modelling and Simulation,10-12 April 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CISIS.2012.1,[Title page i],IEEE,Conferences,The following topics are dealt with: artificial intelligence; agent technology; support systems; software modeling; data mining; database; multimedia system; virtual reality; trusted computing; Web services; data integration; cloud computing; energy aware information systems; ad hoc networks; sensor networks; mesh networks; vehicular networks; complex distributed systems; software intensive system; parallel system; multicore systems; human-robot interaction; intelligent interfaces; network-oriented applications; autonomic distributed systems; semantic Web information; service discovery; service management; intelligent computing; large-scale systems; adaptive learning; collaborative learning; emotion management; intelligent context aware system; hybrid computing infrastructure; e-science applications; service-oriented architecture; knowledge processing; intelligent informatic in biology and medicine; and modern enterprises.,https://ieeexplore.ieee.org/document/6245736/,"2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems",4-6 July 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UKSim.2015.1,[Title page i],IEEE,Conferences,The following topics are dealt with: neural networks; fuzzy systems; evolutionary computation; bioinformatics; bioengineering; data mining; semantic mining; games; VR; visualization; emergent technologies; intelligent systems; control intelligence; e-science; e-systems; robotics; cybernetics; manufacturing; operations research; discrete event systems; real time systems; image processing; speech processing; signal processing; natural language processing; language technologies; human factors; social issues; energy; power; transport; logistics; harbour; shipping; marine simulation; parallel architectures; distributed architectures; software architectures; Internet modelling; semantic Web; ontologies; mobile ad hoc wireless networks; mobicast; sensor placement and target tracking.,https://ieeexplore.ieee.org/document/7576501/,2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim),25-27 March 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICISCE.2017.93,iWalk: Let Your Smartphone Remember You,IEEE,Conferences,"The advance of science and technology brings not only the convenience to people, but also the issues of the property and privacy security. Therefore, the identity recognition technology is particularly important. Walking is one of the most common daily activity of a person, but everyone walks differently. So we designed a new system based on the data of walking called iWalk to identify the user's identity. The most challenging task is to choose the features of walking that can represent each person's identity. IWalk collects data based on accelerometers built into Commercial Off-The-Shelf (COTS) smartphones and uses the Human Activity Recognition (HAR) method to determine whether the current user is the owner of the phone. The data we used for training and evaluation were collected by 16 volunteers from real activities. The results of our experiments show that iWalk can achieve 97. 80 % true positive (TP) rate in judging the identity of the user's segments. Through the judgment of segments, it recognizes the user identity in the final.",https://ieeexplore.ieee.org/document/8110320/,2017 4th International Conference on Information Science and Control Engineering (ICISCE),21-23 July 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData50022.2020.9378128,~PB&J~ - Easy Automation of Data Science/Machine Learning Workflows,IEEE,Conferences,"The ability to process large amounts of data efficiently is a must in modern Big Data, Data Science and Machine Learning (ML). Easy and succinct workflow expression with highly efficient scaling is key. Existing systems such as Apache Spark and Beam were created for this type of work but have steep learning curve and tremendous operating complexity. Having a simpler tool with less overhead that is well-matched to the typical workflow definition and execution requirements of data science/ML projects will be beneficial.We propose a new framework PB&J that enables succinct definition and data-parallel scale-out execution of workflows with ease. PB&J is easy to learn as it builds on the native Unix shell, with the addition of just a few operators. PB&J supports Maximal Parallelism with its ability to do true pipelining, and fault recovery with Minimal Redo. It is well-matched to the typical data science/ML processing requirements by leveraging the existing command line executables and Python modules. We illustrate the features and strengths of PB&J with real-life Deep Learning data processing workflows. We compare it to existing frameworks such as Apache Spark, Apache Beam, Swift/T and Apache Airflow in terms of ease of authoring, efficiency, scalability and fault recovery.",https://ieeexplore.ieee.org/document/9378128/,2020 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDM.2008.72,Fast Counting of Triangles in Large Real Networks without Counting: Algorithms and Laws,IEEE,Conferences,"How can we quickly find the number of triangles in a large graph, without actually counting them? Triangles are important for real world social networks, lying at the heart of the clustering coefficient and of the transitivity ratio. However, straight-forward and even approximate counting algorithms can be slow, trying to execute or approximate the equivalent of a 3-way database join. In this paper, we provide two algorithms, the eigentriangle for counting the total number of triangles in a graph, and the eigentrianglelocal algorithm that gives the count of triangles that contain a desired node. Additional contributions include the following: (a) We show that both algorithms achieve excellent accuracy, with up to sime 1000x faster execution time, on several, real graphs and (b) we discover two new power laws (degree-triangle and triangleparticipation laws) with surprising properties.",https://ieeexplore.ieee.org/document/4781156/,2008 Eighth IEEE International Conference on Data Mining,15-19 Dec. 2008,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICAI.2019.8701334,Finding the Real News in News Streams,IEEE,Conferences,"The current trend of the modern highly mobile society is in the receiving information of any kind by people from one handheld device. This way is simple, convenient, cheap, and practical. The users tend to have only one application on their devices to be universal for any purposes. The social networks have advantages over traditional mass-media instruments such as TV, radio, newspapers, and magazines. This advantage is in the speed of information spreading. Unfortunately, not all of published on-line articles are factual or true. Finding the real news in the news streams is not easy for ordinary users. Even state news agencies do not publish the real news in many cases. In this paper, we discuss different approaches to get the real news from news streams. Among them are the move from the social media to a trusted state agency, the move from one stat agency to several ones to get information on the breaking news from state agencies of different countries. This strategy is the most realistic for the serious users. We introduce the methods to support this strategy and automatically retrieve publications from the trusted sources specified by the user in order to simplify his/her work to obtain the information helping to get and understand the real news better.",https://ieeexplore.ieee.org/document/8701334/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMART52563.2021.9676205,Fine Grainded Sentiment Analysis on COVID-19 Vaccine,IEEE,Conferences,"The most talked about topic of interest in the medical realm as of today, is the debate on the impact that COVID-19 vaccine has on individuals, and their response in encountering the virus. While there are quite a few vaccine variants that have been developed, there has always been a lingering ambiguity in declaring that an individual can be completely immune to the virus. There have been many studies whilom this cognition of analysing the sentiment perception of vaccines, however the data utilization from various sources and the apropos implementation using the language processing methodologies have lagged a great deal. This paper pivots on the data drawn from social media platforms, and optimizes the sentiments using the Natural Language processing Toolkit (NLTK). The process of word embedding, with TFIDF vectorizer commingled with data unsheathing through fine-grained sentiment analysis and machine learning algorithms such as Linear SVC, SVM and Naïve bayes on the covid19 dataset have aided in stratifying the public tweet sentiments based on their polarity, precision, recall, f1-score value and support. The simulations have been implemented using the lexicon, rubric-based analytical tool VADER (Valence Aware Dictionary and sentiment Reasoner) incorporated in Python specifically for optimized extraction of sentiments from data.",https://ieeexplore.ieee.org/document/9676205/,2021 10th International Conference on System Modeling & Advancement in Research Trends (SMART),10-11 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCNC49033.2022.9700613,First Experimental Results on Real-Time Cleaning Activity Monitoring System,IEEE,Conferences,"The COVID-19 pandemic has presented social challenges to establish the new normal lifestyle in our daily lives. The goal of this paper is to enable easy and low-cost monitoring of cleaning activity to keep a clean environment for preventing infection. Although human activity recognition has been a hot research topic in pervasive computing, existing schemes have not been optimized for monitoring cleaning activities. To address this issue, this paper provides an initial concept and preliminary experimental results of cleaning activity recognition using accelerometer data and RFID tags. In the proposed scheme, machine learning technologies and short range wireless communication are employed for recognizing the time and place of wiping as an example of cleaning activities, because it is an important activity for shared places to avoid infection. This paper reports the evaluation results on the recognition accuracy using the proof-of-concept (PoC) implementation to clarify the required sampling rate and time-window size for further experiments. Also, a real-time feedback system is implemented to provide the monitoring results for users. The proposed scheme contributes for efficient monitoring of cleaning activities for creating the new normal era.",https://ieeexplore.ieee.org/document/9700613/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMARTCOMP50058.2020.00080,Flood Detection Framework Fusing The Physical Sensing & Social Sensing,IEEE,Conferences,"We investigate the practical challenge of localized flood detection in real smart city environment using the fusion of physical sensor and social sensing models to depict a reliable and accurate flood monitoring and detection framework. Our proposed framework efficiently utilize the physical and social sensing models to provide the flood-related updates to the city officials. We deployed our flood monitoring system in Ellicott City, Maryland, USA and connect it to the social sensing module to perform the flood-related sensor and social data integration and analysis. Our ground-based sensor network model record and performs the predictive data analytic by forecasting the rise in water level (RMSE=0.2) that demonstrates the severity of upcoming flash floods whereas, our social sensing model helps collect and track the flood-related feeds from Twitter. We employ a pre-trained model and inductive transfer learning based approach to classify the flood-related tweets with 90% accuracy in the use of unseen target flood events. Finally our flood detection framework categorizes the flood relevant localized contextual details into more meaningful classes in order to help the emergency services and local authorities for effective decision making.",https://ieeexplore.ieee.org/document/9239657/,2020 IEEE International Conference on Smart Computing (SMARTCOMP),14-17 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PerComWorkshops51409.2021.9430985,Flood Detection using Semantic Segmentation and Multimodal Data Fusion,IEEE,Conferences,"Real-time flood detection and notifying the citizens about its risk is of utmost importance. This work discusses the real-time deployment of one such notification system called Flood-Bot. FloodBot is a vision-powered flood detection and notification prototype deployed in a flash flood-prone Ellicott City, Maryland. We discuss the real-time deployment of FloodBot and our approach in detecting the flood event using semantic segmentation and multimodal data fusion. We implement the state-of-the-art semantic segmentation model U-Net and its modified version to track landmass with an accuracy of above 80%. We augment the parsed scene data with actual flood level sensor readings and ambient weather data for better scene representation. We validate the deep learning model&#x0027;s outcome using the flood sensor before posting risk message into social media. We then articulate the learning and challenges around our deployment from June &#x2013; November 2020.",https://ieeexplore.ieee.org/document/9430985/,2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),22-26 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/R10-HTC.2018.8629835,Foody - Smart Restaurant Management and Ordering System,IEEE,Conferences,"Customers play a vital role in the contemporary food industry when determining the quality of the restaurant and its food. Restaurants give considerable attention to customers’ feedback about their service, since the reputation of the business depends on it. Key factors of evaluating customer satisfaction are, being able to deliver the services effectively to lessen the time of consumption, as well as maintaining a high quality of service. In most cases of selecting a prominent restaurant, customers focus on their choice of favorite food in addition to available seating and space options. Long waiting times and serving the wrong order is a common mistake that happens in every restaurant that eventually leads to customer dissatisfaction. Objectives of this online application “Foody” is to address these deficiencies and provide efficient and accurate services to the customer, by providing unique menus to each customer considering their taste. This concept is implemented as a mobile application using latest IT concepts such as Business Intelligence, Data Mining, Predictive Analysis and Artificial Intelligence. This includes graphics and 3D modeling that provide existent physical information related to food such as colors, sizes and further user can view the ingredients of the meal as well as the available tables. In addition, the app shows the real-time map to the restaurant. Current table reservation status is indicated by the color change of the table. Unique food recommendation and it’s order for each customer is generated by analyzing their social media information and the system notifies the customer the wait time by calculating it. Preparation of food and allocation is done subjectively. The expected outcome of the research is to develop a fully automated restaurant management system with the mentioned features as well as to avoid confusions between orders, provide better view of food and allow the customer to choose the menu according to their taste in a minimum time.",https://ieeexplore.ieee.org/document/8629835/,2018 IEEE Region 10 Humanitarian Technology Conference (R10-HTC),6-8 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UIC-ATC.2017.8397484,Forecasting car rental demand based temporal and spatial travel patterns,IEEE,Conferences,"Recent years, shared mobility services have gained momentum across the world. Meanwhile, rental car industry has seen great developments in China and has reached a scale of economy. Knowing the rental behavior pattern and forecasting the demand become more important for rental businesses. To this end, in this paper, we aim to analyze the rental mobility pattern by examining multiple factors in a holistic manner. A special goal is to predict the demand of a given region. Specifically, we first analyze regular mobility based on real trips of rental cars. Then, we extract key features from multiple types of rental-related data, such as rental behavior profiles and geo-social information of regions. Next, based on these features, we develop a multi-task learning based regression approach for predicting rental cars' demand. This approach can effectively learn not only fundamental features but also relationships between regions by considering multiple factors. Finally, we conduct extensive experiments on real-world rental trip data collected in Beijing. The experimental results validate the effectiveness of the proposed approach for forecasting rental demand in the real world.",https://ieeexplore.ieee.org/document/8397484/,"2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",4-8 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEngTechnol.2017.8308166,Forecasting of Twitter hashtag temporal dynamics using locally weighted projection regression,IEEE,Conferences,"Popularity of social networks opens great opportunities for market such as advertisement. Using hashtags increasingly used in twits helps us to realize popular topics on the internet. Since most of new hashtags become popular and then fade away quickly, there is a limited time to predict the trend. Therefore, this paper proposes a fast incremental method to forecast the rate of the used hashtags in hour like time series. Two main parts for forecasting system are applied Preprocessing and Supervised Learning. Normalization is one of most popular preprocessing of dataset also proposed to have larger dataset. Moreover, the efficiency of the system under changing number of input (number of past hours from hashtag history) and output (number of next hours which is going to be predicted) are evaluated. Locally Weighted Projection Regression as one of the most powerful machine learning methods with no metaparameter are applied in this paper as real-time learning method. The performance of the system is verified by implementation of “Volume Time Series of Memetracker Phrases and Twitter Hashtags”. The results show that the errors of forecasting system are good enough to understand the trend of the hashtag.",https://ieeexplore.ieee.org/document/8308166/,2017 International Conference on Engineering and Technology (ICET),21-23 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICONSTEM.2017.8261274,Forecasting stock price using soft computing techniques,IEEE,Conferences,"Forecasting stock price is a important challenging task in the real world because more and more money is involved and they are affected by many social, economic, political and psychological factors. Numerous machine learning procedures have been used to fore see developments in stock cost. Machine learning classifiers include expanding the past encounters into the future actives. The proposed framework presents another hereditary calculation for forecast of monetary execution with information sets from a known source. The objective is to deliver a GA-based procedure for expectation of securities exchange execution alongside an acquainted principle classifier from an information set. We developed a genetic fuzzy based model with the ability of rule based extraction to predict next day stock price. We evaluate capacity of the proposed approach by applying it to the banking sector stocks and compare the outcome with the previous models.",https://ieeexplore.ieee.org/document/8261274/,2017 Third International Conference on Science Technology Engineering & Management (ICONSTEM),23-24 March 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SII.2011.6147520,Forming an artificial pheromone potential field using mobile robot and RFID tags,IEEE,Conferences,"In the biological world, social insects such as ants and bees use a volatile substance called pheromone for their foraging or homing tasks. This study deals with how to utilize the concept of the chemical pheromone as an artificial potential field for robotic purposes. This paper first models a pheromone-based potential field, which is constructed through the interaction between mobile robot and RFID tags. The emphasis in the modeling of the system is on the possibility of the practical implementable ideas. The stability analysis of the pheromone potential field is carried out with the aim of implementing the model on a real robotic system. The comprehensive analysis on stability provides the criteria for how the parameters are to be set for the proper potential field, and has also led to a new filter design scheme called pheromone filter. The designed filter satisfies both the stability and accuracy of the field, and facilitates a more straightforward and practical implementation for building and shaping the potential field. The effectiveness of the proposed algorithm is validated through both computer simulation and real experiment.",https://ieeexplore.ieee.org/document/6147520/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PacificVis.2018.00029,FraudVis: Understanding Unsupervised Fraud Detection Algorithms,IEEE,Conferences,"Discovering fraud user behaviors is vital to keeping online websites healthy. Fraudsters usually exhibit grouping behaviors, and researchers have effectively leveraged this behavior to design unsupervised algorithms to detect fraud user groups. In this work, we propose a visualization system, FraudVis, to visually analyze the unsupervised fraud detection algorithms from temporal, intra-group correlation, inter-group correlation, feature selection, and the individual user perspectives. FraudVis helps domain experts better understand the algorithm output and the detected fraud behaviors. Meanwhile, FraudVis also helps algorithm experts to fine-tune the algorithm design through the visual comparison. By using the visualization system, we solve two real-world cases of fraud detection, one for a social video website and another for an e-commerce website. The results on both cases demonstrate the effectiveness of FraudVis in understanding unsupervised fraud detection algorithms.",https://ieeexplore.ieee.org/document/8365989/,2018 IEEE Pacific Visualization Symposium (PacificVis),10-13 April 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCECE.2019.8861892,From natural language to graph queries,IEEE,Conferences,"Automatic code generation can drastically improve software (SW) engineering and SW development projects. In the last decade we have been conducting research which has been advancing the field of code generators for small and mid-size Web-based DBMS systems [4], [5], [7]. We developed a number of tool prototypes for automatic source code debugging by the source-to-source code transformation for real C and C++ applications [8]. Additionally we investigated Natural Language Processing (NLP) for software code generation and application of it to Graph databases. Graph databases are becoming more and more popular for their applications in Artificial Intelligence (AI) systems, social analytics and many other fields. Query languages like Cypher allow users to search them without direct programming. But even queries of modest complexity like “relatives in a family & friends graph” require some skill to write. In this paper we describe the use of natural language as a more intuitive interface for untrained users and demonstrate 3 use-cases, where translation of typical English phrases to OpenCypher and/or specialized graph engines like Huawei EYWA.",https://ieeexplore.ieee.org/document/8861892/,2019 IEEE Canadian Conference of Electrical and Computer Engineering (CCECE),5-8 May 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ROMAN.2017.8172498,Functional imitation task in the context of robot-assisted Autism Spectrum Disorder diagnostics: Preliminary investigations,IEEE,Conferences,"This paper presents a functional imitation task aimed at facilitating Autism Spectrum Disorder (ASD) diagnostics in children. Imitation plays a key role in the development of social skills at a young age, and studies have shown that the ability to imitate is impaired in children with ASD. Therefore, we expect imitation-based tasks to have diagnostic value. In this paper, we introduce two novel elements of human-robot interaction in the context of autism diagnostics. Instead of pure motoric imitation, we propose imitation tasks involving real objects in the environment. The introduction of physical objects strongly emphasizes joint attention skills, another area that is typically impaired in children with ASD. Furthermore, we present simple object detection, manipulation, tracking and gesture recognition algorithms, suitable for real-time, onboard execution on the small-scale humanoid robot NAO. The proposed system paves the way for fully autonomous execution of diagnostic tasks, which would simplify the deployment of robotic assistants in clinical settings. The source code for all described functionalities has been made publicly available as open-source software. We present a preliminary evaluation of the proposed system with a control group of typically developing preschool children and a group of seven children diagnosed with ASD.",https://ieeexplore.ieee.org/document/8172498/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICISS49785.2020.9315885,Generalized method to validate social distancing using median angle proximity methodology,IEEE,Conferences,"Social distancing in industries as well as all public places due to the breakdown of pandemic of COVID-19 is currently of global interest. An advanced global solution for social distancing monitoring among the group of people in real time using computer vision and deep learning is proposed. A state of art method, Median angle proximity method is proposed on the coordinates obtained from the YOLOv3 (You only look once) algorithm to determine the predefined threshold resulting in the social distancing violating bounding boxes. The violating bounding boxes are then saved as single images using deep sort method. All the parts of the work are done using opensource programming language. The work has met all the requirements planned and is considered to be ready for deployment in real time with an average accuracy of 85%",https://ieeexplore.ieee.org/document/9315885/,2020 3rd International Conference on Intelligent Sustainable Systems (ICISS),3-5 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC.2019.10256,Generating Real Time Cyber Situational Awareness Information Through Social Media Data Mining,IEEE,Conferences,"With the rise of the internet many new data sources have emerged that can be used to help us gain insights into the cyber threat landscape and can allow us to better prepare for cyber attacks before they happen. With this in mind, we present an end to end real time cyber situational awareness system which aims to efficiently retrieve security relevant information from the social networking site Twitter.com. This system classifies and aggregates the data retrieved and provides real time cyber situational awareness information based on sentiment analysis and data analytics techniques. This research will assist security analysts to evaluate the level of cyber risk in their organization and proactively take actions to plan and prepare for potential attacks before they happen as well as contribute to the field through a cybersecurity tweet dataset.",https://ieeexplore.ieee.org/document/8753997/,2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC),15-19 Jul 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CGames.2014.6934140,Generating dynamic narratives with real time interactions utilizing mobile technology,IEEE,Conferences,"The popularity of smartphones and other mobile technologies provides unique and exciting opportunities for game developers to create interesting game experiences and simultaneously study how players react and interact to these new environments. By studying and enhancing these new interactive environments and utilizing these technologies, we can break free of traditional game experiences and create newer and more exciting games with the flexibility of mobile devices. This study explores how we expand our idea of what a traditional game should be and poses a newer, fresher look on mobile game play and social connectivity. We have added to the notion of playing a game without actively engaging in it from the foundation of previous research. We have done this in order to build players' unique stories that will allow players to make more meaningful choices throughout their gameplay experience. By offering the player real time choices and active engagement in a mobile game that currently offers none, we expect to increase the levels of enjoyment and usefulness, from both educational and recreational viewpoints.",https://ieeexplore.ieee.org/document/6934140/,"2014 Computer Games: AI, Animation, Mobile, Multimedia, Educational and Serious Games (CGAMES)",28-30 July 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
,Graphical methods for real-time fusion and estimation with soft message data,IEEE,Conferences,"Fusion of observational data acquired by human observers and couched in linguistic form is a modern-day challenge for the fusion community. This paper describes a basic research effort examining various strategies for associating and exploiting such data for intelligence analysis purposes. An overall approach is described that involves Latent Semantic Analysis, Inexact Graph Matching, formal ontology development, and Social Network Analyses. Not all the methods have yet been employed but the exploitation of the developed ontology and graphical techniques have been implemented in a working prototype and preliminary results have shown promise. Planned future research will complete the implementation of the methods described herein and add yet further enhancements.",https://ieeexplore.ieee.org/document/4632405/,2008 11th International Conference on Information Fusion,30 June-3 July 2008,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDE48307.2020.00018,Group Recommendation with Latent Voting Mechanism,IEEE,Conferences,"Group Recommendation (GR) is the task of suggesting relevant items/events for a group of users in online systems, whose major challenge is to aggregate the preferences of group members to infer the decision of a group. Prior group recommendation methods applied predefined static strategies for preference aggregation. However, these static strategies are insufficient to model the complicated decision making process of a group, especially for occasional groups which are formed adhoc. Compared to conventional individual recommendation task, GR is rather dynamic and each group member may contribute differently to the final group decision. Recent works argue that group members should have non-uniform weights in forming the decision of a group, and try to utilize a standard attention mechanism to aggregate the preferences of group members, but they do not model the interaction behavior among group members, and the decision making process is largely unexplored.In this work, we study GR in a more general scenario, that is Occasional Group Recommendation (OGR), and focus on solving the preference aggregation problem and the data sparsity issue of group-item interactions. Instead of exploring new heuristic or vanilla attention-based mechanism, we propose a new social self-attention based aggregation strategy by directly modeling the interactions among group members, namely Group Self-Attention (GroupSA). In GroupSA, we treat the group decision making process as multiple voting processes, and develop a stacked social self-attention network to simulate how a group consensus is reached. To overcome the data sparsity issue, we resort to the relatively abundant user-item and user-user interaction data, and enhance the representation of users by two types of aggregation methods. In the training process, we further propose a joint training method to learn the user/item embeddings in the group-item recommendation task and the user-item recommendation task simultaneously. Finally, we conduct extensive experiments on two real-world datasets. The experimental results demonstrate the superiority of our proposed GroupSA method compared to several state-of-the-art methods in terms of HR and NDCG.",https://ieeexplore.ieee.org/document/9101842/,2020 IEEE 36th International Conference on Data Engineering (ICDE),20-24 April 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2013.55,Grouping Methods for Generating Friendship Based on Network Properties,IEEE,Conferences,"This paper investigates the effect of group work with the assumption of three motivators to make friends. Obeying the assumption we proposed twelve variation of methods for grouping students. The effects are evaluated by some measures from social network analysis and by the changes of real friendship networks, which are observed by a friendship prediction method. The proposed methods brought new friendship among students to classes and made rearrange of community structure.",https://ieeexplore.ieee.org/document/6598501/,"2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",1-3 July 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/VECIMS.2007.4373924,HI3 Project: Design and Implementation of the Lower Level Layers,IEEE,Conferences,"We are interested in the development of human-centered and ubiquitous technologies in social environments. In this line, and in the framework of a global software architecture (HI3) for this type of applications, the paper is devoted to the presentation of the work carried out for the design and implementation of the layer that is more closely linked to the hardware. It is in charge of communicating with the physical layer and it is responsible for the abstraction of the field elements. Special attention has been paid to the coherence with the philosophy, design premises and functionalities of the whole system. We have also determined a hardware configuration that, integrating standards where possible, is better adapted to the requirements of the architecture. The elements introduced here were validated on a real implementation of the system.",https://ieeexplore.ieee.org/document/4373924/,"2007 IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems",25-27 June 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/I4CS.2015.7294480,Happy hour - improving mood with an emotionally aware application,IEEE,Conferences,"Mobile sensing in Cyber-Physical Systems has been evolving proportionally with smartphones. In fact, we are witnessing a tremendous increase in systems that sense various facets of human beings and their surrounding environments. In particular, the detection of human emotions can lead to emotionally-aware applications that use this information to benefit people's daily lives. This work presents the implementation of a Human-inthe- loop emotionally-aware Cyber-Physical System that attempts to positively impact its user's mood through moderate walking exercise. Data from smartphone sensors, a smartshirt's electrocardiogram and weather information from a web API are processed through a machine learning algorithm to infer emotional states. When negative emotions are detected, the application timely suggests walking exercises, while providing real-time information regarding nearby points of interest. This information includes events, background music, attendance, agitation and general mood. In addition, the system also dynamically adapts privacy and networking configurations based on emotions. The sharing of the user's location on social networks and the device's networking interfaces are configured according to user-defined rules in order to reduce frustration and provide a better Quality of Experience.",https://ieeexplore.ieee.org/document/7294480/,2015 15th International Conference on Innovations for Community Services (I4CS),8-10 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2018.8621926,Harnessing the Nature of Spam in Scalable Online Social Spam Detection,IEEE,Conferences,"Disinformation in social networks has been a worldwide problem. Social users are surrounded by a huge volume of malicious links, biased comments, fake reviews, or fraudulent advertisements, etc. Traditional spam detection approaches propose a variety of statistical feature-based models to filter out social spam from a historical dataset. However, they omit the real word situation of social data, that is, social spam is fast changing with new topics or events. Therefore, traditional approaches cannot effectively achieve online detection of the ""drifting"" social spam with a fixed statistic feature set. In this paper, we present Sifter, a system which can detect online social spam in a scalable manner without the labor-intensive feature engineering. The Sifter system is two-fold: (1) a decentralized DHT-based overlay deployment for harnessing the group characteristics of social spam activities within a specific topic/event; (2) a social spam processing with the support of Recurrent Neural Network (RNN) to get rid of the traditional manual feature engineering. Results show that Sifter achieves graceful spam detection performances with the minimal size of data and good balance in group management.",https://ieeexplore.ieee.org/document/8621926/,2018 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN48605.2020.9206610,Heterogeneous Information Network Embedding with Convolutional Graph Attention Networks,IEEE,Conferences,"Heterogeneous Information Networks (HINs) are prevalent in our daily life, such as social networks and bibliography networks, which contain multiple types of nodes and links. Heterogeneous information network embedding is an effective HIN analysis method, it aims at projecting network elements into a lower-dimensional vector space for further machine learning related evaluations, such as node classification, node clustering, and so on. However, existing HIN embedding methods mainly focus on extracting the semantic-related information or close neighboring relations, while the high-level proximity of the network is also important but not preserved. To address the problem, in this paper we propose CGAT, a semi-supervised heterogeneous information network embedding method. We optimize the graph attention network by adding additional convolution layers, thereby we can extract multiple types of semantics and preserve high-level information in HIN embedding at the same time. Also, we utilize label information in HINs for semi-supervised training to better obtain the model parameters and HIN embeddings. Experimental results on real-world datasets demonstrate the effectiveness and efficiency of the proposed model.",https://ieeexplore.ieee.org/document/9206610/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CRV.2010.55,Human Upper Body Pose Recognition Using Adaboost Template for Natural Human Robot Interaction,IEEE,Conferences,"In this paper, we propose a novel Adaboost template to recognize human upper body poses from disparity images for natural human robot interaction (HRI). First, the upper body poses of standing persons are classified into seven categories of views. For each category, a mean template, variance template, and percentage template are generated. Then, the template region is divided into positive and negative regions, corresponding to the region of bodies and surrounding open space. A weak classifier is designed for each pixel in the template. A new EM-like Adaboost learning algorithm is designed to learn the Adaboost template. Different from existing Adaboost classifiers, we show that the Adaboost template can be used not only for recognition but also for adaptive top-down segmentation. By using Adaboost template, only a few positive samples for each category are required for learning. Comparison with conventional template matching techniques has been made. Experimental results show that significant improvements can be achieved in both cases. The method has been deployed in a social robot to estimate human attentions to the robot in real-time human robot interaction.",https://ieeexplore.ieee.org/document/5479162/,2010 Canadian Conference on Computer and Robot Vision,31 May-2 June 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITR51448.2020.9310890,Hybrid Approach and Architecture to Detect Fake News on Twitter in Real-Time using Neural Networks,IEEE,Conferences,"Fake news has been a key issue since the dawn of social media. Currently, we are at a stage where it is merely impossible to differentiate between real and fake news. This directly and indirectly affects people's decision patterns and makes us question the credibility of the news shared via social media platforms. Twitter is one of the leading social networks in the world by active users. There has been an exponential spread of fake news on Twitter in the recent past. In this paper, we will discuss the implementation of a browser extension which will identify fake news on Twitter using deep learning models with a focus on real-world applicability, architectural stability and scalability of such a solution. Experimental results show that the proposed browser extension has an accuracy of 86% accuracy in fake news detection. To the best of our knowledge, our work is the first of its kind to detect fake news on Twitter real-time using a hybrid approach and evaluate using real users.",https://ieeexplore.ieee.org/document/9310890/,2020 5th International Conference on Information Technology Research (ICITR),2-4 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DEST.2010.5610664,Hybrid ontologies and social semantics,IEEE,Conferences,"Semantic Web, Social Web, and new economic challenges are causing major shifts in the pervasive fabric that the internet has become, in particular for the business world. The internet's new role as participatory medium and its ubiquity lead to dense tri-sortal communities of humans and businesses mixed with computer systems, and semantically interoperating in a well-defined sense. Many of the challenges and ongoing (r)evolutions appear to produce as yet seemingly contradictory requirements and thus produce potentially very interesting research areas. We argue that linguistics, community-based real world “social” semantics and pragmatics, scalability, the tri-sortal nature of the communities involved, the balance between usability and reusability, and the methodological requirements for non-disruptive adoption by enterprises of the new technologies provide vectors for fundamental computer science research, for interesting new artefacts, and for new valorisations of enterprise interoperability. We posit that one such development will likely result in hybrid ontologies and their supporting social implementation environments -such as semantic wikis- that accommodate the duality and co-existence of formal reasoning requirements inside systems on the one hand and of declarative knowledge manipulation underlying human communication and agreement on the other hand.",https://ieeexplore.ieee.org/document/5610664/,4th IEEE International Conference on Digital Ecosystems and Technologies,13-16 April 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/APSEC.2002.1182989,IBistro: a learning environment for knowledge construction in distributed software engineering courses,IEEE,Conferences,"We have taught several distributed software engineering project courses with students and real clients. During these projects, students in Pittsburgh and Munich, Germany collaborated in the development of a single system. Our experiences showed that software development is communication intensive and requires the collaboration of many stakeholders. Communication is challenging in distributed contexts: participants do not all know each other and work at different times and locations; the number of participants and their organization change during the project; and participants belong to different communities. Hence, to deal with the global marketplace, it is critical to provide students with distributed collaboration skills. To improve the teaching of collaboration in software engineering, we propose iBistro, an augmented, distributed, and ubiquitous communication space. iBistro aims to overcome problems resulting from miscommunications and information loss in informal or casual meetings. iBistro enables distributed groups to collaborate and cooperate in software projects and therefore provides an environment for learning in diverse aspects such as project management, programming skills, and social skills. With the addition of techniques from artificial intelligence, such as student modeling, and intelligent support mechanisms, such as computer supported group formation, distributed tutoring becomes feasible.",https://ieeexplore.ieee.org/document/1182989/,"Ninth Asia-Pacific Software Engineering Conference, 2002.",4-6 Dec. 2002,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEARS53579.2022.9751864,Identifying Fake News using Machine Learning,IEEE,Conferences,"Fake data is purposely or accidentally transmitted throughout the internet. It has long been a social issue, and in the digital age, the average person now has easy access to all of the information available online. This is affecting a growing population of people who are technologically blind. One of the most serious problems in the modern day is fake news, which has the capacity to affect people's minds and influence their judgments. On web browsers, there are a few plugins that provide real-time information about the veracity of news. The algorithms used to create these plugins have a significant impact on them. The goal is to create a project that will propose which of the three implemented algorithms is the best for further development by the developer. Machine learning classification methods such as SVM, naive bayes, logistic regression, decision tree, and random forest are taught to detect if news is fake or real, and then compared based on metrics.",https://ieeexplore.ieee.org/document/9751864/,2022 International Conference on Electronics and Renewable Systems (ICEARS),16-18 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMC51019.2021.9418419,Image classification for user feedback using Deep Learning Techniques,IEEE,Conferences,"In this digital era, automatic human facial expression recognition is considered as an important component in computer vision. Also, it is challenging for machine learning algorithms, where humans can significantly show their expressions. Henceforth, in machine learning methods, deep learning is considered as a novel technology that can classify the images of human faces into different facial expression recognition categories using convolutional neural networks (CNN). In this system, the facial expression recognition is implemented by using CNN network based model with LeNet architecture to improve the prediction of expression results. Here, the proposed research work has utilized a facial expression dataset, which is loaded from Kaggle web resources and this dataset contains seven facial expression tags such as happy, anger, neutral, fear, sad, disgust, and surprise. In this system, along with emotion classifications, gender classification is also merged. Because automatic gender recognition has relevant to the addition of its usages in software applications whereas in social media and social networking websites. With this system, gender and facial expression recognition are explored through face detection using Convolution Neural Network (CNN).The whole motivation behind the work is to improve the way human movement is detected for different legal purposes. The usage of computer vision on the field of customer service, user security, user feedback and many other things. The gender and expression recognition can be used to deal with many real world problems.",https://ieeexplore.ieee.org/document/9418419/,2021 5th International Conference on Computing Methodologies and Communication (ICCMC),8-10 April 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCWAMTIP53232.2021.9674087,Immersive 4D Intelligent Interactive Platform Based on Deep Learning,IEEE,Conferences,"With the advent of the Internet era, the cost of realizing virtual characters has been greatly reduced. The high cost and low efficiency exhibited by traditional virtual technology can&#x0027;t meet social needs. People are seeking fast, convenient and accurate virtual character reproduction technology. Through researching the characteristics of the characters appearance, language habits, voice tone and so on, the research direction of this paper is to simulate and reshape voice and images, construct a cloud platform-based on user-side and client-side, and integrate deep learning, natural language processing, digital twins and other technologies to an immersive 4D intelligent interactive platform. The platform under in the form of application software provides integrated services of intelligent voice interaction and virtual character interaction. In the industrial diagnosis mode, the transition from traditional video retention and voice retention to a new intelligent voice recognition and simulation mode is realized.",https://ieeexplore.ieee.org/document/9674087/,2021 18th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP),17-19 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIMSEC.2011.6011030,"Impact from Effective distribution coefficient Change on the economic system constituted by two factors, three departments and four categories of residents — CGE model simulation",IEEE,Conferences,"A CGE model is built for the economic system constructed by two factors, three departments and four categories of residents and the impact effect of Effective distribution coefficient Change on this economie system is simulated by virtue of computer simulation. The fixed points of the economic system and the impact on distortion of general equilibrium of the economic system are computed by dint of MATLAB software and self-made program (genetic algorithm is adopted). Results: a Effective distribution coefficient Change may change the equilibrium price system (fixed points) of the economic system, the transaction costs of the economic system (in particular costs of property rights), residents' maximum utility and the department's equilibrium quantity through influence on employment resource quantity, demand structure, production structure, residents' real income and so on of the economic system. Conclusion: By the Effective distribution coefficient Change (Table 2), the total social utility increases, the Production of the three departments and the Effective distribution coefficient are positively correlated",https://ieeexplore.ieee.org/document/6011030/,"2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)",8-10 Aug. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ATC.2011.6027460,Implementing un-identified communication in Ubiquitous phone System,IEEE,Conferences,"Context awareness plays an important role in Ubiquitous applications based on the context information to provide services adapting to users' needs. The advantages of some context-aware smart phone systems, including iCAM[1], contextPhone[2], Live Contact Project [3], Enhanced Telephony[4] and Ubiquitous phone System Ubiphone [5] show themselves to be typical examples of Ubiquitous service ones. Using a context-aware smart phone, we can contact individuals in many ways, including by home, office, or cell phone, short message service (SMS), instance message(IM), and email. Therefore, a human-centered smart phone could discover how best to reach a contact at any given moment. However, in these systems, the users can contact to people in the contact list only, and the context information is managed and referred on only one ontology tree in one domain which contraries to the reality that in Ubiquitous environment. In this environment, the context information such as concepts and relationships are also managed and referred on heterogeneous ontology in several domains, which drive new challenges in the discovery of knowledge sources relevant to a users' request. New efficient technique and approach for developing and extending Ubiquitous phone intelligence is presented in this paper, which combines agent-based technologies and Artificial Neural Networks (ANNs) models to match ontology, helping users search and contact with anyone outside the contact list satisfying the users' requests even there is no social relationship between them.",https://ieeexplore.ieee.org/document/6027460/,The 2011 International Conference on Advanced Technologies for Communications (ATC 2011),2-4 Aug. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCKE.2011.6413358,Improving the accuracy and efficiency of tag recommendation system by applying hybrid methods,IEEE,Conferences,"Recently applications of social tagging systems have increased. These systems allow users to organize, manage and search the required resource freely, thus by combination and integration of recommendation systems in social software, assisting users to appropriately assign tag to resources and try to improve annotation among users. The challenges of recommendation systems are large-scale data, inconsistence data, usage of time-consuming machine learning algorithms, long and unreasonable time of recommendation and not being scalable to the demands of real world applications. Recently more efforts have been conducted to solve these problems. In this paper we proposed a tag recommendation system that is able to work with large-scale data and being applied in real world. The proposed system's evaluation performed on a dataset collected from Delicious.com. The results demonstrated the efficiency and accuracy of proposed system.",https://ieeexplore.ieee.org/document/6413358/,2011 1st International eConference on Computer and Knowledge Engineering (ICCKE),13-14 Oct. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACII.2019.8925479,Imputing Missing Social Media Data Stream in Multisensor Studies of Human Behavior,IEEE,Conferences,"The ubiquitous use of social media enables researchers to obtain self-recorded longitudinal data of individuals in real-time. Because this data can be collected in an inexpensive and unobtrusive way at scale, social media has been adopted as a “passive sensor” to study human behavior. However, such research is impacted by the lack of homogeneity in the use of social media, and the engineering challenges in obtaining such data. This paper proposes a statistical framework to leverage the potential of social media in sensing studies of human behavior, while navigating the challenges associated with its sparsity. Our framework is situated in a large-scale in-situ study concerning the passive assessment of psychological constructs of 757 information workers wherein of four sensing streams was deployed - bluetooth beacons, wearable, smartphone, and social media. Our framework includes principled feature transformation and machine learning models that predict latent social media features from the other passive sensors. We demonstrate the efficacy of this imputation framework via a high correlation of 0.78 between actual and imputed social media features. With the imputed features we test and validate predictions on psychological constructs like personality traits and affect. We find that adding the social media data streams, in their imputed form, improves the prediction of these measures. We discuss how our framework can be valuable in multimodal sensing studies that aim to gather comprehensive signals about an individual's state or situation.",https://ieeexplore.ieee.org/document/8925479/,2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII),3-6 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBDA51983.2021.9402992,"Incremental Real-time Learning Framework for Sentiment Classification: Indian General Election 2019, A Case Study",IEEE,Conferences,"Indian General Election 2019 was one of the major global political events. The prominence of social media in contemporary life, and the ubiquity of political messaging on it has necessitated a systematic study of sentiments and make inferences about future moods and trends. In absence of standard tools or software we propose a machine learning-based generic system framework and REST (Representation State Transfer) plugin component, that extracts and filters authentic tweets from Twitter, captures the prevalent mood, and predicts the sentiment of any live incoming tweet in a resource-constrained setup. The system can predict user sentiments by discovering completely new features from the web, along with the process of continuous incremental learning and improvement of model accuracy.",https://ieeexplore.ieee.org/document/9402992/,2021 IEEE 6th International Conference on Big Data Analytics (ICBDA),5-8 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ROBOT.1991.131908,Instinctive behaviors and personalities in societies of cellular robots,IEEE,Conferences,"A description is presented of the social organization of societies of cellular mobile units featuring instinctive behavior. Each robotic unit has its own personality and lives independently from the others. Useful tasks are carried out through collaboration rather than by individual effort. The behavior of each unit derives from a subsumption-like control structure, which emphasizes the roles of innate personality, external stimuli, and communication. A number of different robotic personalities are described and techniques of implementing them in real robot units are outlined. The implementation of instinctive behavior is described for the case of a robotic vehicle system (ROBBIE).<>",https://ieeexplore.ieee.org/document/131908/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/FRUCT53335.2021.9599974,Intelligent Identification of Fake Accounts on Social Media,IEEE,Conferences,The paper presents an original research of fake accounts on social media using an artificial neural network for their identification. Specifically designed and implemented application was used to identify specific features of fake accounts and study the principles and reasons of their generation. Considering the possible use cases and scenarios of its practical use including everyday social media surfing there was examined a possibility to implement a mobile application based on Java in the Android Studio programming environment. Based on the study of 500 real and 500 fake VKontakte accounts there was determined a number of conclusions on the original features of fake accounts. The provided research allowed extending the list of criteria for identifying fake accounts by an original set of patterns. The developed conclusions allow formulating the statements on what criteria can be used for further identification of fake accounts in practical applications.,https://ieeexplore.ieee.org/document/9599974/,2021 30th Conference of Open Innovations Association FRUCT,27-29 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CIT/IUCC/DASC/PICOM.2015.151,Intelligent Mobile Framework Based on Swarm Computation,IEEE,Conferences,"Mobile Terminal Crowd Sourcing provides social network information and services for users through data processing and data mining. Intelligent engine provides recommendation based on historical information and real-time environment, which are primarily used in intelligent life, mobile social networking, and other fields. Firstly, the concept of intelligent engine is introduced, the research strategy and the overall structure of the mobile terminal crowd sourcing.",https://ieeexplore.ieee.org/document/7363192/,"2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing",26-28 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SEA-STEM53614.2021.9668057,Intelligent Traffic Light System Using Image Processing,IEEE,Conferences,"Nowadays, there are more cars used on the road. Traffic congestion problems can cause the economy and the environment both directly and indirectly problems, also part of the problem of air pollution. The traffic light management system in the current situation has used a fixed waiting time, which inability to be flexible according to the traffic at different times such as in rush hour and other. It is not efficient enough to manage traffic with fixed waiting time. The organizers came up with the idea of developing an intelligent traffic light system with flexibility according to the number of cars in real-time by reducing waiting time. The paper was designed and developed by implementing the intelligent traffic light system using image processing technology to process the appropriate waiting time from each image frame. Lazarus and OpenGL were used to program based on Pascal language. The software has been developed for receiving traffic video at the intersection to process car image segmentation of each frame and to calculate the distance of the length of the car in each route in addition. It is also possible to calculate the appropriate time for green-light and red-light duration and corresponding to the length of the waiting vehicles in each route at the intersection. This investigated software can be used to reduce the waiting time at the traffic light intersection by 45.35%. In addition, the intelligent traffic light system is also a social development towards a smart city. The project has created the learning environment and computational thinking for society through the process of STEM Education with using IoT and Artificial Intelligence.",https://ieeexplore.ieee.org/document/9668057/,2021 2nd SEA-STEM International Conference (SEA-STEM),24-25 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GCCE.2015.7398635,Intelligent control of USM using a modified NN with PSO,IEEE,Conferences,"As aging society problem goes severe In not only Japan but also the whole world, more and more attentions are attracted to the social and welfare fields. Many researches on science and technology for elders are implemented in rencent years. With the background, there are a lot of needs for techonologies with novel features for improvement. In this paper, a control method with attractive features for the actuator of Ultrasonic Motors (USMs) is introduced. In medical and welfare areas, the USMs are expected to play more important roles owing to their special characteristics. In this research, an intelligent PID control method using Neural Network (NN) combined with type Particle Swarm Optimization (PSO) is developed for the control of USM. In the method, the intelligent controller is designed based on variable gain type PID control using NN. The learning of the NN unit is implemented by the PSO. The gains of PID control are adjusted by the proposed method in real-time. The effectiveness of the method is verified by experimental results.",https://ieeexplore.ieee.org/document/7398635/,2015 IEEE 4th Global Conference on Consumer Electronics (GCCE),27-30 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITSC.2017.8317730,Intelligent traffic light control using distributed multi-agent Q learning,IEEE,Conferences,"The combination of Artificial Intelligence (AI) and Internet-of-Things (IoT), which is denoted as AI powered Internet-of-Things (AIoT), is capable of processing huge amount of data generated from large number of devices and handling complex problems in social infrastructures. As AI and IoT technologies are becoming mature, in this paper, we propose to apply AIoT technologies for traffic light control, which is an essential component for intelligent transportation system, to improve the efficiency of smart city's road system. Specifically, various sensors such as surveillance cameras provide real-time information for intelligent traffic light control system to observe the states of both motorized traffic and non-motorized traffic. In this paper, we propose an intelligent traffic light control solution by using distributed multi-agent Q learning, considering the traffic information at the neighboring intersections as well as local motorized and non-motorized traffic, to improve the overall performance of the entire control system. By using the proposed multi-agent Q learning algorithm, our solution is targeting to optimize both the motorized and non-motorized traffic. In addition, we considered many constraints/rules for traffic light control in the real world, and integrate these constraints in the learning algorithm, which can facilitate the proposed solution to be deployed in real operational scenarios. We conducted numerical simulations for a real-world map with real-world traffic data. The simulation results show that our proposed solution outperforms existing solutions in terms of vehicle and pedestrian queue lengths, waiting time at intersections, and many other key performance metrics.",https://ieeexplore.ieee.org/document/8317730/,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),16-19 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EDUCON52537.2022.9766555,Internet of Things Meets Machine Learning: A Water Usage Alert Example,IEEE,Conferences,"The rapid growth of the electronics industry resulted in numerous, amazing and cheap devices, while fluent documentation and user-friendly programming environments are available for them. Modern educational systems worldwide have exploited this dynamic by including in their didactic curricula innovative practices that are usually called STEM actions. Added to this, enriching educational methods with real-world problem solving techniques increases students&#x2019; interest and prepares them for their future role in the society. Apparently, such challenging problems are not missing, with the depletion of natural resources to be one of the most intense ones. In this context, promising modern technological flavors like Internet of Things (IoT) and Machine Learning (ML) can join their potential to form educationally fruitful and also practically important activities targeted at increasing the social awareness for the water misuse problem, like the ones proposed herein. These activities also encourage the deployment of low-cost appliances that, only with minor modifications, can respond to a wide variety real problems in either urban or rural environments.",https://ieeexplore.ieee.org/document/9766555/,2022 IEEE Global Engineering Education Conference (EDUCON),28-31 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DeSE.2011.10,Introducing a Round Robin Tournament into Evolutionary Individual and Social Learning Checkers,IEEE,Conferences,"In recent years, much research attention has been paid to evolving self-learning game players. Fogel's Blondie24 is a demonstration of a real success in this field, inspiring many other scientists. In this paper, artificial neural networks are used as function evaluators in order to evolve game playing strategies for the game of checkers. We introduce a league structure into the learning phase of an individual and learning system based on the Blondie24 architecture. We show that this helps eliminate some of the randomness in the evolution. The best player we evolve is tested against an implementation of an evolutionary checkers program, and also against a player, which utilises the proposed round robin tournament and finally against an individual and social learning checkers program. The results are promising, suggesting many other research directions.",https://ieeexplore.ieee.org/document/6149996/,2011 Developments in E-systems Engineering,6-8 Dec. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN.2003.1223995,Investigating models of social development using a humanoid robot,IEEE,Conferences,"Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a ""theory of mind"". Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements.",https://ieeexplore.ieee.org/document/1223995/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CogInfoCom47531.2019.9089994,Investigating the Social Robots’ Role in Improving Children Attitudes toward Recycling. The case of PeppeRecycle,IEEE,Conferences,"In this paper we investigate the impact of a social robot in the context of serious games in which the robot plays the role of a game opponent by challenging and, at the same time, teaching the child to correctly recycle waste materials. To this aim we performed a study in which we investigated the dimensions that are used to evaluate serious games integrated with those that are typical of the interaction with a social robot. To endow the robot with the capability to play as a game opponent in a real-world context, we implemented an image recognition module based on a Convolutional Neural Network so that the robot could detect and classify the waste material as a child would do, by seeing it. After a preliminary evaluation of the approach, we started a formal experiment in which we measured the effectiveness of game design, the robot evaluation and the evaluation of cognitive and affective elements that can form the pro-environmental attitude and then the tendency to recycling. A primary school classroom was involved in the study and, results obtained so far, are encouraging and drew promising possibilities for robotics education in changing recycling attitude for children since Pepper is positively evaluated as trustful and believable and this allowed to be concentrated on the `memorization' task during the game.",https://ieeexplore.ieee.org/document/9089994/,2019 10th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),23-25 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAICA50127.2020.9182385,KEAN: Knowledge Embedded and Attention-based Network for POI Recommendation,IEEE,Conferences,"In recent years, with the rapid development of location-based social networks (LBSN) in the Internet, point of interest (POI) recommendation has become a hot spot. Most existing researches make use of contextual information to model users' interest preferences. However, the existing methods for extracting various auxiliary information still need to be improved, such as how to treat the users' social relations equally. In order to obtain users' actual preferences more accurately, in POI recommendation, we propose a deep learning framework KEAN (Knowledge Embedded and Attention Based Network) based on knowledge graph and attention model. The framework includes knowledge-graph embedding method, preference extraction network based on attention mechanism and recommendation network. Our study used knowledge-graph embedding method to get the embedding of each user and POI. In addition, an LSTM network based on attention mechanism was proposed, which uses LSTM network to learn the user's preferences according to the user's check-in sequence. Besides, the attention mechanism was used to extract friends' preferences and merge them with the user's preferences to generate end-user preferences. Finally, our model use fully-connected neural networks to realize recommendations. The effectiveness of the model was proved by the experimental results based on real LBSN datasets.",https://ieeexplore.ieee.org/document/9182385/,2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA),27-29 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/VR.2019.8798046,Keynote Speaker: Virtual Reality for Enhancing Human Perceptional Diversity Towards an Inclusive Society,IEEE,Conferences,"We conducted research project towards an inclusive society from the viewpoint of the computational assistive technologies. This project aims to explore AI-assisted human-machine integration techniques for overcoming impairments and disabilities. By connecting assistive hardware and auditory/visual/tactile sensors and actuators with a user-adaptive and interactive learning framework, we propose and develop a proof of concept of our “xDiversity AI platform” to meet the various abilities, needs, and demands in our society. For example, one of our studies is a wheelchair for automatic driving using “AI technology” called “tele wheelchair”. Its purpose is not fully automated driving but labor saving at nursing care sites and nursing care by natural communication. These attempts to solve the challenges facing the body and sense organs with the help of AI and others. In this keynote we explain the case studies and out final goal for the social design and deployment of the assistive technologies towards an inclusive society.",https://ieeexplore.ieee.org/document/8798046/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCTA48790.2019.9478839,Keynote Speech II: Readiness for the Impact of Emerging Technologies,IEEE,Conferences,"Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. The digital world is becoming increasingly intertwined with the physical world of machines, to which it is bringing ubiquitous intelligence and a perpetual flow of information. These trends are driving us towards a very different future. That future has already started. A new wave of social, economic, and psychological changes is expected to abruptly affect almost everything we do. With change, many opportunities come along. Those who anticipate the course of the future, and prepare for it, will be ready to seize these opportunities and will come out winners. Those who chose to ignore the signs of change, will risk losing their livelihood and eventually hurting their families, businesses, and societies. Those who see the storm coming but react by standing still in panic, disgruntlement, and lamentation will be defenseless when the inevitable waves hit their shores. This presentation overviews the trends in technology and applications, including Artificial Intelligence, Big Data Analytics, Robotics, Internet of Things, Industry 4.0, etc. The impact that such advances are likely to have on the high-tech as well as the low-tech job markets is outlined. Some actions and initiatives are proposed and discussed, with the purpose of triggering a larger debate on how individuals, businesses, academic institutions, and governments should prepare for the anticipated massive changes that are already beginning to affect our world.",https://ieeexplore.ieee.org/document/9478839/,2019 29th International Conference on Computer Theory and Applications (ICCTA),29-31 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData47090.2019.9006554,KryptoOracle: A Real-Time Cryptocurrency Price Prediction Platform Using Twitter Sentiments,IEEE,Conferences,"Cryptocurrencies, such as Bitcoin, are becoming increasingly popular, having been widely used as an exchange medium in areas such as financial transaction and asset transfer verification. However, there has been a lack of solutions that can support real-time price prediction to cope with high currency volatility, handle massive heterogeneous data volumes, including social media sentiments, while supporting fault tolerance and persistence in real time, and provide real-time adaptation of learning algorithms to cope with new price and sentiment data. In this paper we introduce KryptoOracle, a novel real-time and adaptive cryptocurrency price prediction platform based on Twitter sentiments. The integrative and modular platform is based on (i) a Spark-based architecture which handles the large volume of incoming data in a persistent and fault tolerant way; (ii) an approach that supports sentiment analysis which can respond to large amounts of natural language processing queries in real time; and (iii) a predictive method grounded on online learning in which a model adapts its weights to cope with new prices and sentiments. Besides providing an architectural design, the paper also describes the KryptoOracle platform implementation and experimental evaluation. Overall, the proposed platform can help accelerate decision-making, uncover new opportunities and provide more timely insights based on the available and ever-larger financial data volume and variety.",https://ieeexplore.ieee.org/document/9006554/,2019 IEEE International Conference on Big Data (Big Data),9-12 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2018.8622221,Large Scale Open Source Video Recommender Tool Using Metadata Surrogates,IEEE,Conferences,"Video and multi-media sharing is a significant activity on social media platforms. Learning patterns of activities using raw video data is computationally intensive and impractical, and manual inspection is not scalable and prohibitively expensive. An alternate strategy is to learn information about video content using far less compute intensive metadata surrogates. This paper describes a video recommender tool implemented in GovCloud using a novel approach of using lightweight video metadata to learn and classify video content. In contrast to popular video recommender systems that use consumption models for classification, the new approach used in our tool is based solely on the video metadata along with domain expertise used to truth a relatively small subset of relevant video content. The tool is very user-friendly and captures practical knowledge of the user resulting in good learning model. The architecture and implementation specifics of the tool is outlined in this paper. The classifier performance using metadata from tens of thousands of real postings exceeds 90% for both recall and ROC metrics. This tool has shown promise in providing a console for aggregating social media videos for analysts to train the system consistent with the context and task at hand.",https://ieeexplore.ieee.org/document/8622221/,2018 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData50022.2020.9377817,Learning Embeddings of Directed Networks with Text-Associated Nodes—with Application in Software Package Dependency Networks,IEEE,Conferences,"A network embedding consists of a vector representation for each node in the network. Its usefulness has been shown in many real-world application domains, such as social networks and web networks. Directed networks with text associated with each node, such as software package dependency networks, are commonplace. However, to the best of our knowledge, their embeddings have hitherto not been specifically studied. In this paper, we propose PCTADW-1 and PCTADW-2, two algorithms based on neural networks that learn embeddings of directed networks with text associated with each node. We create two new node-labeled such networks: The package dependency networks in two popular GNU/Linux distributions, Debian and Fedora. We experimentally demonstrate that the embeddings produced by our algorithms resulted in node classification with better quality than those of various baselines on these two networks. We observe that there exist systematic presence of analogies (similar to those in word embeddings) in the network embeddings of software package dependency networks. To the best of our knowledge, this is the first time that such systematic presence of analogies is observed in network and document embeddings. We further demonstrate that these network embeddings can be novelly used for better understanding software attributes, such as the development process and user interface of software, etc.",https://ieeexplore.ieee.org/document/9377817/,2020 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2016.0048,Learning User Embedding Representation for Gender Prediction,IEEE,Conferences,"Predicting the gender of users in social media has aroused great interests in recent years. Almost all existing studies rely on the the content features extracted from the main texts like tweets or reviews. It is sometimes difficult to extract content information since many users do not write any posts at all. In this paper, we present a novel framework which uses only the users' ids and their social contexts for gender prediction. The key idea is to represent users in the embedding connection space. A user often has the social context of family members, schoolmates, colleagues, and friends. This is similar to a word and its contexts in documents, which motivates our study. However, when modifying the word embedding technique for user embedding, there are two major challenges. First, unlike the syntax in language, no rule is responsible for the composition of the social contexts. Second, new users were not seen when learning the representations and thus they do not have embedding vectors. Two strategies circular ordering and incremental updating are proposed to solve these problems. We evaluate our methodology on two real data sets. Experimental results demonstrate that our proposed approach is significantly better than the traditional graph representation and the state-of-the-art graph embedding baselines. It also outperforms the content based approaches by a large margin.",https://ieeexplore.ieee.org/document/7814608/,2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI),6-8 Nov. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDM.2015.10,Learning User Preferences across Multiple Aspects for Merchant Recommendation,IEEE,Conferences,"With the pervasive use of mobile devices, Location Based Social Networks(LBSNs) have emerged in past years. These LBSNs, allowing their users to share personal experiences and opinions on visited merchants, have very rich and useful information which enables a new breed of location-based services, namely, Merchant Recommendation. Existing techniques for merchant recommendation simply treat each merchant as an item and apply conventional recommendation algorithms, e.g., Collaborative Filtering, to recommend merchants to a target user. However, they do not differentiate the user's real preferences on various aspects, and thus can only achieve limited success. In this paper, we aim to address this problem by utilizing and analyzing user reviews to discover user preferences in different aspects. Following the intuition that a user rating represents a personalized rational choice, we propose a novel utility-based approach by combining collaborative and individual views to estimate user preference (i.e., rating). An optimization algorithm based on a Gaussian model is developed to train our merchant recommendation approach. Lastly we evaluate the proposed approach in terms of effectiveness, efficiency and cold-start using two real-world datasets. The experimental results show that our approach outperforms the state-of-the-art methods. Meanwhile, a real mobile application is implemented to demonstrate the practicability of our method.",https://ieeexplore.ieee.org/document/7373403/,2015 IEEE International Conference on Data Mining,14-17 Nov. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA46639.2022.9811662,Learning to Socially Navigate in Pedestrian-rich Environments with Interaction Capacity,IEEE,Conferences,"Existing navigation policies for autonomous robots tend to focus on collision avoidance while ignoring human-robot interactions in social life. For instance, robots can pass along the corridor safer and easier if pedestrians notice them. Sounds have been considered as an efficient way to attract the attention of pedestrians, which can alleviate the freezing robot problem. In this work, we present a new deep reinforcement learning (DRL) based social navigation approach for autonomous robots to move in pedestrian-rich environments with interaction capacity. Most existing DRL based methods intend to train a general policy that outputs both navigation actions, i.e., expected robot&#x0027;s linear and angular velocities, and interaction actions, i.e., the beep action, in the context of reinforcement learning. Different from these methods, we intend to train the policy via both supervised learning and reinforcement learning. In specific, we first train an interaction policy in the context of supervised learning, which provides a better understanding of the social situation, then we use this interaction policy to train the navigation policy via multiple reinforcement learning algorithms. We evaluate our approach in various simulation environments and compare it to other methods. The experimental results show that our approach outperforms others in terms of the success rate. We also deploy the trained policy on a real-world robot, which shows a nice performance in crowded environments.",https://ieeexplore.ieee.org/document/9811662/,2022 International Conference on Robotics and Automation (ICRA),23-27 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC.2019.8914455,Learning waste Recycling by playing with a Social Robot,IEEE,Conferences,"In this paper we investigate the use of a social robot as an interface to a serious game aiming to train kids in how to recycle materials correctly. Serious games are mostly used to induce motivations and engagement in users and support knowledge transfer during playing. They are especially effective when the goal of the game concerns behavior change. In addition, social robots have been used effectively in educational settings to engage children in the learning process. Following this trend, we designed a serious game in which the social robot Pepper plays with a child to teach him to correctly recycle the materials. To endow the robot with the capability of detecting and classifying the waste material we developed an image recognition module based on a Convolutional Neural Network. Preliminary experimental results show that the implementation of a serious game about recycling into the Pepper robot improves its social behavior. The use of real objects as waste items during the game turns out to be a successful approach not only for perceived learning effectiveness but also for engagement of the children.",https://ieeexplore.ieee.org/document/8914455/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/NCTM.2017.7872829,Linguistic features based personality recognition using social media data,IEEE,Conferences,"Social media has become a prominent platform for opinions and thoughts. This stated that the characteristics of a person can be assessed through social media status updates. The purpose of this research article is to provide a web application in order to detect one's personality using linguistic feature analysis. The personality of a person has classified according to Eysenck's Three Factor personality model. The proposed technique is based on ontology based text classification, linguistic feature-vector matrix using LIWC (Linguistic Inquiry and Word Count) features including semantic analysis using supervised machine learning algorithms and questionnaire based personality detection. This is vital for HR management system when recruiting and promoting employees, R&D Psychologists can use the dynamic ontology for storage purposes and all the other API users including universities and sports clubs. According to the test results the proposed system is in an accuracy level of 91%, when tested with a real world personality detection questionnaire based application, and results demonstrate that the proposed technique can detect the personality of a person with considerable accuracy and a speed.",https://ieeexplore.ieee.org/document/7872829/,2017 6th National Conference on Technology and Management (NCTM),27-27 Jan. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCCN49398.2020.9209681,LogParse: Making Log Parsing Adaptive through Word Classification,IEEE,Conferences,"Logs are one of the most valuable data sources for large-scale service (e.g., social network, search engine) maintenance. Log parsing serves as the the first step towards automated log analysis. However, the current log parsing methods are not adaptive. Without intra-service adaptiveness, log parsing cannot handle software/firmware upgrade because learned templates cannot match new type of logs. In addition, without cross-service adaptiveness, the logs of a new type of service cannot be accurately parsed when this service is newly deployed. We propose LogParse, an adaptive log parsing framework, to support intra-service and cross-service incremental template learning and update. LogParse turns the template generation problem into a word classification problem and learns the features of template words and variable words. We evaluate LogParse on four public production log datasets. The results demonstrate that LogParse supports accurate adaptive template update (increased from 0.559 to nearly 1.0 parsing accuracy), and a trained LogParse is adaptive for a brand new service&#x2019;s log parsing. Because of LogParse&#x2019;s adaptiveness, we also apply LogParse to an interesting application, log compression and deployed log compression in a top cloud service provider. We package LogParse into an open-source toolkit.",https://ieeexplore.ieee.org/document/9209681/,2020 29th International Conference on Computer Communications and Networks (ICCCN),3-6 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CONFLUENCE.2019.8776981,Logistic Regression based DFS for Trip Advising Software (ASCEND),IEEE,Conferences,"Graphs have played a pivotal role in the field of computer science and has been an efficient method for representing and modeling abstractions in various fields. They can be used to represent several real life models. Several domains in today's world use the concept of graphs extensively such as GPS Navigation systems, Computer networks, WebCrawler, Social Networking websites, peer to peer networking, medical and biological field, neural networks etc. Taking into account the numerous applications of the concept of graphs in today's world, graph searching becomes inevitably significant. In this scenario it is important to note that several graph searching algorithms that were proposed to give exhaustive searches doesn't provide the most satisfying outcome in terms of asymptotic time complexity. Through this paper we intend to highlight the significance of machine learning as a useful tool that can be incorporated in various graph searching algorithms that can reduce its complexity. We classify the existing graph searching techniques as subsets or modifications of two major conventional graph searching algorithms namely BFS(Breadth First Search) and DFS(Depth First Search) and suggest the application of logistic regression to improve their performance. It is confounding that only few research papers explore the application of machine learning to the aforementioned graph searching algorithms. Hence, it is evident that there exists scope for future research on this topic and we aim to suggest directions for the same.",https://ieeexplore.ieee.org/document/8776981/,"2019 9th International Conference on Cloud Computing, Data Science & Engineering (Confluence)",10-11 Jan. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSTCEE54422.2021.9708587,Logistic Regression versus XGBoost: Machine Learning for Counterfeit News Detection,IEEE,Conferences,"In this age of globalization, the unstoppable spreading of fake news via the internet is unstoppable. The spread of false news cannot be supported due to the negative consequences. Society is extremely concerning. In addition, itleads to more serious problems and possible threats, like confusion, misunderstandings, defamation and falsehoods that induce users to share inflammatory content. With the convenience and tremendous increase in information gathering on social networks, it is becoming difficult to differentiate between what is false and what is real. Information can be easily disseminated through sharing, which has contributed to the exponential growth of their forgeries. Machine learning played an important role, in classifying information, although there are some limitations. This article explores various machine learning techniques used to detect fake and fabricated messages. The limitations are discussed using deep learning implementation. In this project, the methodology used is model development and Logistic Regression classifier is considered to detect false news. Based on previous research, this classifier performed well in classification tasks. In this approach, TF-IDF feature is used for the construction of this fake news model to get higher accuracy. The goal of this project is to detect false news using NLP and Machine Learning based on the news content of the article. Following the development of the appropriate Machine Learning model to detect fake/true news, it is deployed into a web interface using Python Flask.",https://ieeexplore.ieee.org/document/9708587/,"2021 Second International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)",16-17 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMLA.2015.152,MLaaS: Machine Learning as a Service,IEEE,Conferences,"The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.",https://ieeexplore.ieee.org/document/7424435/,2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA),9-11 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMC.2018.8487992,Machine Learning Based Twitter Spam Account Detection: A Review,IEEE,Conferences,"Online social networks (OSNs) are emerging communication medium for people to establish and manage social relationships. In OSNs, regularly billions of users are involved in social interaction, content and opinion dissemination, networking, recommendations, scouting, alerting, and social campaigns. The popularization of OSNs open up a new perspectives and challenges to the study of social networks, being of interest to many fields. Social network is a place where social activities, business oriented activities, entertainment, and information are exchanged. It establish a worldwide connectivity environment where communities of people share their interests and activities, or who are interested in interests and activities of others Although social network has given immense benefits to people at the same time harming people with various mischievous activities that take place on social platforms. This causes significant economic loss to our society and even threaten the national security. All the social networks Facebook, Twitter, LinkedIn, etc. are highly susceptible to malware activities. Twitter is one of the biggest microblogging networking platform, it has more than half a billion tweets are posted every day in average by millions of users on Twitter. Such a versatility and wide spread of use, Twitter easily get intruded with malicious activities. Malicious activities includes malware intrusion, spam distribution, social attacks, etc. Spammers use social engineering attack strategy to send spam tweets, spam URLs, etc. This made twitter an ideal arena for proliferation of anomalous spam accounts. The impact stimulates researchers to develop a model that analyze, detects and recovers from defamatory actions in twitter. Twitter network is inundated with tens of millions of fake spam profiles which may jeopardize the normal user's security and privacy. To improve real users safety and identification of spam profiles become key parts of the research.",https://ieeexplore.ieee.org/document/8487992/,2018 Second International Conference on Computing Methodologies and Communication (ICCMC),15-16 Feb. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/eIT53891.2022.9837113,Machine Vision Surveillance System - Artificial Intelligence For Covid-19 Norms,IEEE,Conferences,"This paper presents the design and implementation of the Machine Vision Surveillance System Artificial Intelligence (MaViSS-AI) for Covid-19 Norms using jetson nano. This system is designed to be cost-effective, accurate, efficient, and secure. The proposed system tracks and counts humans for monitoring social distancing and detects face masks using object detection methods. We used YOLO as an object detection method and neural network to detect a person and count them. And for social distancing monitoring the concept of the centroid is based on calculating the distance between pairs of centroids, and thus checking whether there are any violations of the threshold or not. To detect the face mask, a YOLO V4 deep learning model is used as the mask detection algorithm. The system also raises alerts when any suspicious event occurs. Given this alert, security personnel can take relevant actions. This research aims to provide a holistic approach to overcoming the real-time challenges encountered during the monitoring of Covid-19 norms.",https://ieeexplore.ieee.org/document/9837113/,2022 IEEE International Conference on Electro Information Technology (eIT),19-21 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIIoT54504.2022.9817247,Major threats to the continued adoption of Artificial Intelligence in today&#x0027;s hyperconnected world,IEEE,Conferences,"From the golden era of science fiction which dates to the late 1930s, scientific and technological advances in artificial intelligence (AI), along with one of its key subsets, machine learning (ML) have been growing significantly, especially in recent years. In 2021 alone, notable feats included an AI program capable of creating images from seen or previously unseen textual captions, an AI model that effectively integrates computer vision and natural language processing, and a novel AI framework for diagnosing dementia in 24 hours with real-world feasibility underway amongst a host of other fascinating breakthroughs. This paper briefly delves into AI/ML and recaps some key essentials, covering AI and ML subfields, ML methods, industries where AI/ML finds relevance, key stages and the common technical challenges in ML development. Importantly, the paper shifts attention from the latter to underscore the duo of transparency and ethics in AI, highlighting specifically what these are and why they are important, subsequently positing a PESTEL (Political, Economic, Social, Technological, Environmental and Legal) framework for AI design, build and implementation. It is anticipated that the upshot of this would be the facilitation of continuous adoption and long-term sustainability of AI/ML.",https://ieeexplore.ieee.org/document/9817247/,2022 IEEE World AI IoT Congress (AIIoT),6-9 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMLA.2015.72,Malware Detection in Android-Based Mobile Environments Using Optimum-Path Forest,IEEE,Conferences,"Nowadays, people use smartphones and tablets with the very same purposes as desktop computers: web browsing, social networking and home-banking, just to name a few. However, we are often facing the problem of keeping our information protected and trustworthy. As a result of their popularity and functionality, mobile devices are a growing target for malicious activities. In such context, mobile malwares have gained significant ground since the emergence and growth of smartphones and handheld devices, becoming a real threat. In this paper, we introduced a recently developed pattern recognition technique called Optimum-Path Forest in the context of malware detection, as well we present ""DroidWare"", a new public dataset to foster the research on mobile malware detection. In addition, we also proposed to use Restricted Boltzmann Machines for unsupervised feature learning in the context of malware identification.",https://ieeexplore.ieee.org/document/7424412/,2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA),9-11 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WETICE.2019.00013,Meaning Extraction in a Domotic Assistant Agent Interacting by Means of Natural Language,IEEE,Conferences,"This paper presents a software architecture to let users interact with their smart home devices, through the commonly used social network channels. The software, called FABULOS, is the result of the combination of components used to interact with devices and social networks, and a rule-based artificial intelligence, which implements the base logic for the automation. The core of the software architecture is the translation service, which has the objective of extracting the meaning of the sentences provided by text and voice messages by users in natural language, transforming them into proper device commands. In order to achieve this, the proposed solution relies on an approach which has the capability to interpret and extract the meaning of the intentions plus the entities involved, associated to the sentences sent by the users. A description of a realistic case-study, which shows an example of how the proposed software behaves in a real interaction with an user, is also included in the paper.",https://ieeexplore.ieee.org/document/8795403/,2019 IEEE 28th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE),12-14 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DTPI52967.2021.9540077,Mechanical Design Paradigm based on ACP Method in Parallel Manufacturing,IEEE,Conferences,"Parallel Manufacturing is a new manufacturing paradigm in industry, deeply integrating informalization, automation, and artificial intelligence. In this paper we propose a new mechanical design paradigm in Parallel Manufacturing based on ACP method. The key is to regard the design procedure based on artificial design and emulation method as two independent procedures, which can be modeled as a parallel system. The design procedure based on ACP method does not include a real system, which is an inventive extension of the traditional parallel system. This method can be implemented with social information by introducing the definition of SDV, SDM, and Intelligent Design Manager, making it highly adaptive for social manufacturing and Parallel Manufacturing.",https://ieeexplore.ieee.org/document/9540077/,2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI),15 July-15 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCSMT54525.2021.00083,Medical Analysis of Social Media Data Based on Spark and Machine Learning in China,IEEE,Conferences,"Social media embracing a huge amount of real-time data of all kinds plays an important role in data analysis in the era of big data. Knowledge between medical workers and ordinary people can be popularized and exchanged via social media. At the same time, the collection and utilization of medical data on social media can effectively grasp the public health situation and provide better help to improve people&#x0027;s health status. From the perspective of medical care and health, this paper uses Weibo, the largest public social media in China, to obtain data for analysis. The study was developed under the Spark framework, using naive Bayes, random forest and two different feature extraction methods to clean, pre-process and classify data. Furthermore, the accuracy rate and F1 Score were used to evaluate the model, to find the most appropriate method. The result of this research shows that the data obtained from Weibo within certain age groups has a good reference value in the public awareness and current situation, and are good for grasping the trend of diseases.",https://ieeexplore.ieee.org/document/9786983/,2021 2nd International Conference on Computer Science and Management Technology (ICCSMT),12-14 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSCI54926.2021.00305,Metricam: Fast and Reliable Social Distancing Analysis in Online Security Cameras,IEEE,Conferences,"Distance measurements taken from 2D camera images are subject to the correct estimation of the camera&#x2019;s perspective, that is, the spatial mapping from 2D points imaged by a camera to the correspondent 3D ones in the real world. Current solutions to solve this 3D reconstruction are either dependent on the estimation of vanishing points through the detection of straight lines on targeted images or by employing sophisticated sensors and deep learning algorithms, which require expensive training on huge annotated datasets. Nevertheless, none of those approaches provide the required level of precision and accuracy for social distancing evaluation. In this paper we present Metricam, a real-time lightweight software system for security cameras that computes a 2D to 3D mapping using computational geometry and uses the DBSCAN clustering algorithm to evaluate social distancing evaluation. With Metricam, we have been able to identify several places prone to agglomeration inside the Butant&#x00E3; campus of the University of S&#x00E3;o Paulo, and provide the local authorities with valuable information to fight off the pandemic.",https://ieeexplore.ieee.org/document/9799026/,2021 International Conference on Computational Science and Computational Intelligence (CSCI),15-17 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2014.6888682,Microcredit risk assessment using crowdsourcing and social networks,IEEE,Conferences,"The task of automated risk assessment is attracting significant attention in the light of the recent microloan popularity growth. The industry requires a real time method for the timely processing of the extensive number of applicants for short-term small loans. Owing to the vast number of applications, manual verification is not a viable option. In cooperation with a microloan company in Azerbaijan, we have researched automated risk assessment using crowdsourcing. The principal concept behind this approach is the fact that a significant amount of information relating to a particular applicant can be retrieved from the social networks. The suggested approach can be divided into three parts: First, applicant information is collected on social networks such as LinkedIn and Facebook. This can only occur with the applicant's permission. Then, this data is processed using a program that extracts the relevant information segments. Finally, these information segments are evaluated using crowdsourcing. We attempted to evaluate the information segments using social networks. To that end, we automatically posted requests on the social networks regarding certain information segments and evaluated the community response by counting “likes” and “shares”. For example, we posted the status, “Do you think that a person who has worked at ABC Company is more likely to repay a loan? Please “like” this post if you agree.” From the results, we were able to estimate public opinion. Once evaluated, each information segment was then given a weight factor that was optimized using available loan-repay test data provided to us by a company. We then tested the proposed system on a set of 400 applicants. Using a second crowdsourcing approach, we were able to confirm that the resulting solution provided a 92.5% correct assessment, with 6.45% false positives and 11.11% false negatives, with an assessment duration of 24 hours.",https://ieeexplore.ieee.org/document/6888682/,"15th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 June-2 July 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICODSE.2018.8705834,Microtask Crowdsourcing Marketplace for Social Network,IEEE,Conferences,"Crowdsourcing is a powerful way to process and collect data that needs human's logic and perception. Crowdsourcing can take part in many hard to compute problems such as data entry, multimedia transcriptions and many case of artificial intelligence. While this is a powerful approach, crowdsourcing needs a relatively large marketplace to works optimum. In context of Indonesia, we hardly hear about task crowdsourcing even though there are some marketplace like poin-web.co.id. In this paper, we propose a social network for crowdsourcing marketplace to penetrate the market. People tends to waste most of their time on social network and game rather than other mobile application in case of mobile usage. The idea is to make crowdsourcing as a filler while people are using social networks like waiting for a chat or scrolling the timeline. And by applying microtask as the task, people will not have much burden on doing the task. On the other hand, he/she will get additional income. We implemented LINE as a basis of our social network marketplace. LINE does provide the most interactive way of provide message. Additionally, the user of LINE in Indonesia is growing in a fast pace. We conduct an experiment focused on worker's coverage and ease of use. By using usability testing as a basis of ease of use evaluation, we received good feedbacks as 90.9% of the users feel easier to answer through LINE and is excited to use the platform in case it goes with real money.",https://ieeexplore.ieee.org/document/8705834/,2018 5th International Conference on Data and Software Engineering (ICoDSE),7-8 Nov. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RO-MAN47096.2020.9223436,Migratable AI: Effect of identity and information migration on users' perception of conversational AI agents,IEEE,Conferences,"Conversational AI agents are proliferating, embodying a range of devices such as smart speakers, smart displays, robots, cars, and more. We can envision a future where a personal conversational agent could migrate across different form factors and environments to always accompany and assist its user to support a far more continuous, personalized and collaborative experience. This opens the question of what properties of a conversational AI agent migrates across forms, and how it would impact user perception. To explore this, we developed a Migratable AI system where a user's information and/or the agent's identity can be preserved as it migrates across form factors to help its user with a task. We validated the system by designing a 2x2 between-subjects study to explore the effects of information migration and identity migration on user perceptions of trust, competence, likeability and social presence. Our results suggest that identity migration had a positive effect on trust, competence and social presence, while information migration had a positive effect on trust, competence and likeability. Overall, users report highest trust, competence, likeability and social presence towards the conversational agent when both identity and information were migrated across embodiments.",https://ieeexplore.ieee.org/document/9223436/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEBE.2018.00015,Mining Emotions of the Public from Social Media for Enhancing Corporate Credit Rating,IEEE,Conferences,"The proliferation of online social media has been changing the ways how individuals interact with corporations. Previous studies have examined how to extract investors' sentiments captured on social media to enhance stock prediction. However, little work was done to leverage public's emotions captured on social media to predict corporate credit risks. Our research fills the current research gap by developing a new computational method to extract public's emotions embedded in social postings to supplement common financial indicators (e.g., return-on-assets) for predicting corporate credit ratings. Grounded in Plutchik's Wheel of Emotions, the proposed computational framework can automatically extract the distribution of eight basic emotions from textual postings on online social media. In particular, one main contribution of our work is the development of the new emotion latent dirichlet allocation (ELDA) model for textual emotion analysis. In addition, we develop an ensemble learning model with random forest (RF) as the basis classifier to improve the performance of corporate credit rating. Based on the real-world data crawled from Twitter, our experimental results confirm that the proposed ELDA model can effectively and efficiently extract public's emotions from social postings to enhance the prediction of corporate credit ratings. To our best knowledge, this is the first successful research of developing a new computational model of extracting public's emotions from social postings to enhance corporate credit risk prediction.",https://ieeexplore.ieee.org/document/8592626/,2018 IEEE 15th International Conference on e-Business Engineering (ICEBE),12-14 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICASI.2017.7988441,Mining tweets for education reforms,IEEE,Conferences,"Microblogging and social networking sites have become a popular means of communication channels among internet users. They provide tools for people to voice their opinions. These sites contain vast amounts of opinionated data, leading to an increased growth in research on sentiment analysis and opinion mining. The study aims at using Twitter, a major and popular platform for microblogging and social communication, to conduct sentiment analysis. Real time data was automatically streamed using the Twitter API to collect the public's sentiments regarding education. A survey was also used to capture the public's opinions. The study will help overcome frustrations during implementation of education policies and reforms by taking into account the public's views and opinions.",https://ieeexplore.ieee.org/document/7988441/,2017 International Conference on Applied System Innovation (ICASI),13-17 May 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IEMCON53756.2021.9623097,Missing Data: Comparison of Multiple-Imputation Algorithms for Social Determinants of Health in Cervical Cancer Stage Detection,IEEE,Conferences,"Social Determinants of Health impact general health conditions within a population. However, missing data affect statistical analysis and forecasting of diseases. Multiple imputation has gained momentum and several machine learning algorithms have been used for data imputation. As most statistical analysis and machine learning software have already implemented these algorithms, their performance is usually taken for granted without further analysis. Furthermore, we notice a discrepancy between how imputation must be carried out and how it is usually performed in real-word practice. Thus, in this work we examine different machine learning algorithms for multiple imputation in two datasets with Social Determinants of Health in Cervical Cancer. The results of this comparison are presented.",https://ieeexplore.ieee.org/document/9623097/,"2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)",27-30 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICETC.2010.5529259,Model construct and case study of interpersonal interaction in virtual learning community,IEEE,Conferences,"Based on the interaction among the members of virtual learning community, the social computing software is a powerful tool. Exploring the connotative features of the model construction and the application process of the Interpersonal interaction among the community members from macro theoretical perspective to micro technical perspective will deepen understanding and value judgments of educational technology about social computing.",https://ieeexplore.ieee.org/document/5529259/,2010 2nd International Conference on Education Technology and Computer,22-24 June 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WI-IAT.2015.242,Modeling Curiosity in Virtual Companions to Improve Human Learners' Learning Experience,IEEE,Conferences,"A key design aspect for virtual learning companions is their believability. A lot of attention has been paid to emotion modeling which is at the core of believability. However, most of the existing emotion models neglect the epistemology-based emotions, which are knowledge-related emotions that affect the human learning process. Studies have shown that curiosity is an important epistemology-based emotion that positively influences social learning. Hence, modeling curiosity in learning companions may improve human learners' learning experience in a virtual environment. However, existing curiosity models assume simplified cognitive processes and fail to capture multiple sources of curiosity stimuli. In this paper, we propose a novel model of curiosity for learning companions to capture salient curiosity stimuli through a psychologically inspired approach. Our model is built based on Berlyne's theory and considers three most salient appraisal variables in a virtual learning environment, including novelty, surprise, and uncertainty. The model is built on planbased knowledge representations augmented with planning. Two internal processes are modeled for learning companions to demonstrate curiosity: curiosity appraisal and learning. The proposed model of curiosity is implemented in a learning companion and evaluated through user studies. The evaluation results show that the learning companion's curiosity significantly improves human learners' learning experience from multiple aspects.",https://ieeexplore.ieee.org/document/7397337/,2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT),6-9 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMS.2010.265,Modeling and Simulating Multi-agent Model Connections: An Application to Information Paradigm,IEEE,Conferences,"This paper presents the information paradigm as a new vision which attempts to connect the conscious experience with the physical world. Two issues concerning this paradigm are investigated: the multi-agent model, which is the base of this theory, and the agent's relations, actually their information states. The relations between them, including their attributes and characteristics, participate in forming so called `baby universe' structures. The simulation of this multi-agent model is done in NetLogo 4.0.4., which is a programmable modeling environment for simulating natural and social phenomena. This environment is particularly well suited for modeling complex systems developing over time. We will simulate fully and partly connected networks in random and circuit arrangements. They will be investigated from mathematical perspective, as a strong support for the theory. As an application to this theory we'll calculate the rest mass ratio of the muon, electron and tauon sub particles, compared with the results obtained at CERN. The integration of the two perspectives offers the appropriate scientific foundation for the new paradigm and see the offering of the new vision of physical reality enabling to resolve some of the main barriers known in contemporary quantum mechanics and artificial intelligence.",https://ieeexplore.ieee.org/document/5421127/,2010 Second International Conference on Computer Modeling and Simulation,22-24 Jan. 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2012.138,Modelling Large Complex Systems Using Multi-agent Technology,IEEE,Conferences,"The paper outlines a method for modelling largescale commercial, social, socio-technological and engineering problems. The method is derived from twelve years of experience in designing and implementing large complex systems for real-time scheduling of taxis, air taxis, car rentals, seagoing tankers, trucks, space crafts; dynamic data mining; dynamic knowledge discovery and semantic search. The same approach has been also used for designing adaptive engineering systems and for research into social issues such as eradication of poverty.",https://ieeexplore.ieee.org/document/6299317/,"2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",8-10 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICACCI.2014.6968416,Modified MapReduce framework for enhancing performance of graph based algorithms by fast convergence in distributed environment,IEEE,Conferences,"The amount of data which is produced is huge in current world and more importantly it is increasing exponentially. Traditional data storage and processing techniques are ineffective in handling such huge data [10]. Many real life applications require iterative computations in general and in particular used in most of machine learning and data mining algorithms over large datasets, such as web link structures and social network graphs. MapReduce is a software framework for easily writing applications which process large amount of data (multi-terabyte) in parallel on large clusters (thousands of nodes) of commodity hardware. However, because of batch oriented processing of MapReduce we are unable to utilize the benefits of MapReduce in iterative computations. Our proposed work is mainly focused on optimizing three factors resulting in performance improvement of iterative algorithms in MapReduce environment. In this paper, we address the key issues based on execution of tasks, the unnecessary creation of new task in each iteration and excessive shuffling of data in each iteration. Our preliminary experiments have shown promising results over the basic MapReduce framework. The comparative study with existing solutions based on MapReduce framework like HaLoop, has also shown better performance w.r.t algorithm run time and amount of data traffic over Hadoop Cluster.",https://ieeexplore.ieee.org/document/6968416/,"2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",24-27 Sept. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TrustCom50675.2020.00243,Monitoring Social Media for Vulnerability-Threat Prediction and Topic Analysis,IEEE,Conferences,"Publicly available software vulnerabilities and exploit code are often abused by malicious actors to launch cyberattacks to vulnerable targets. Organizations not only have to update their software to the latest versions, but do effective patch management and prioritize security-related patching as well. In addition to intelligence sources such as Computer Emergency Response Team (CERT) alerts, cybersecurity news, national vulnerability database (NBD), and commercial cybersecurity vendors, social media is another valuable source that facilitates early stage intelligence gathering. To early detect future cyber threats based on publicly available resources on the Internet, we propose a dynamic vulnerability-threat assessment model to predict the tendency to be exploited for vulnerability entries listed in Common Vulnerability Exposures, and also to analyze social media contents such as Twitter to extract meaningful information. The model takes multiple aspects of vulnerabilities gathered from different sources into consideration. Features range from profile information to contextual information about these vulnerabilities. For the social media data, this study leverages machine learning techniques specially for Twitter which helps to filter out non-cybersecurity-related tweets and also label the topic categories of each tweet. When applied to predict the vulnerabilities exploitation and analyzed the real-world social media discussion data, it showed promising prediction accuracy with purified social media intelligence. Moreover, the AI-enabling modules have been deployed into a threat intelligence platform for further applications.",https://ieeexplore.ieee.org/document/9343128/,"2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",29 Dec.-1 Jan. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CyberSecurity49315.2020.9138894,Moving Targets: Addressing Concept Drift in Supervised Models for Hacker Communication Detection,IEEE,Conferences,"In this paper, we are investigating the presence of concept drift in machine learning models for detection of hacker communications posted in social media and hacker forums. The supervised models in this experiment are analysed in terms of performance over time by different sources of data (Surface web and Deep web). Additionally, to simulate real-world situations, these models are evaluated using time-stamped messages from our datasets, posted over time on social media platforms. We have found that models applied to hacker forums (deep web) presents an accuracy deterioration in less than a 1-year period, whereas models applied to Twitter (surface web) have not shown a decrease in accuracy for the same period of time. The problem is alleviated by retraining the model with new instances (and applying weights) in order to reduce the effects of concept drift. While our results indicated that performance degradation due to concept drift is avoided by 50% relabelling, which is challenging in real-world scenarios, our work paves the way to more targeted concept drift solutions to reduce the re-training tasks.",https://ieeexplore.ieee.org/document/9138894/,2020 International Conference on Cyber Security and Protection of Digital Services (Cyber Security),15-19 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RACSS.2012.6212691,MuGRAM: An approach for multi-labelled graph matching,IEEE,Conferences,"Graph mining has been a widely studied domain over the years. Graph representation of real world problems has enabled the development of simple solutions bringing in better clarity. Graph mining has various sub domains among which graph matching is a prominent one having a number of algorithms. With the rise of new applications involving large sets of networked data, the performance of these algorithms has become important. The graph based representations for social networks and communication networks have led to the evolution of multi-labelled large graphs which are still not completely handled by the existing algorithms. The requirement of a fast and efficient indexing process so as to accommodate dynamic graphs without having to opt for incremental indexing is another major challenge. In this paper, we propose MuGRAM - a multi-labelled graph matching approach aimed at addressing the above mentioned issues. This approach is capable of handling multiple labels for vertices as well as edges of reference graphs. An enhanced indexing method proposed in the paper ensures a fast indexing process. A breadth first search oriented spanning tree along with a novel technique for neighbourhood matching ensures fast query processing. Experimental evaluation of MuGRAM in comparison with some of the recent algorithms in the field highlights its superior performance.",https://ieeexplore.ieee.org/document/6212691/,2012 International Conference on Recent Advances in Computing and Software Systems,25-27 April 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN52387.2021.9534428,Multi-Modal Multi-Instance Multi-Label Learning with Graph Convolutional Network,IEEE,Conferences,"When applying machine learning to tackle realworld problems, it is common to see that objects come with multiple labels rather than a single label. In addition, complex objects can be composed of multiple modalities, e.g. a post on social media may contain both texts and images. Previous approaches typically treat every modality as a whole, while it is not the case in real world, as every post may contain multiple images and texts with quite diverse semantic meanings. Therefore, Multi-modal Multi-instance Multi-label (M3) learning was proposed. Previous attempt at M3 learning argues that exploiting label correlations is crucial. In this paper, we find that we can handle M3 problems using graph convolutional network. Specifically, a graph is built over all labels and each label is initially represented by its word embedding. The main goal for GCN is to map those label embed dings into inter-correlated label classifiers. Moreover, multi-instance aggregation is based on attention mechanism, making it more interpretable because it naturally learns to discover which pattern triggers the labels. Empirical studies are conducted on both benchmark datasets and industrial datasets, validating the effectiveness of our method, and it is demonstrated in ablation studies that the components in our methods are essential.",https://ieeexplore.ieee.org/document/9534428/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIS53314.2022.9742828,Multi-Parameter Smart Health Monitoring System using Internet of Things,IEEE,Conferences,"Low-cost, lightweight, tiny, and intelligent physiological sensor nodes have been designed in the recent technical developments in sensor systems, low power integrated circuits and wireless communications. These sensor nodes can detect analyses and transmit one or more vital signs and can be incorporated smoothly into healthcare social sensor networks. This network promises to change healthcare by enabling cheap, invasive, ongoing ambulatory health surveillance with online medical data updated nearly in real time. Despite several continuous research efforts, several technological, economic and societal issues are essential to the There are still some technological challenges to be addressed in order to develop diverse social sensor networks applicable to medical, economic and social and power efficiency applications. In this proposed work, novel method which is used to track patients in hospitals at home as well. The experimental analysis starts with the implementation of IoT sectors, mainly an Arduino-UNO health observation scheme. Patient&#x2019;s cardiac rates and body temperature is monitor in the proposed work. Arduino-UNO is used as the 8-bit microcontroller, ATMEGA 328. LM 35 is used for body temperature sensing, and XD-58C for cardiac beat rate measurement is used for DIY pulse tracker. Wi-Fi module EP8266 is used to move the data of the patient from the Arduino uno node. For IoT purposes, the BLYNK programmer is used. A new algorithm is proposed which is named as CBHA (Sensor clustering based Human Activities Recognition) that analyze state of the Patient. The data transferred from the WiFi module can be used from anywhere in the app, meaning that doctors can watch patients remotely and take prompt decisions if something goes wrong with the information that has been detected.",https://ieeexplore.ieee.org/document/9742828/,2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS),23-25 Feb. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/LCN52139.2021.9524999,Multi-level Graph Attention Network based Unsupervised Network Alignment,IEEE,Conferences,"Network alignment is the matching of two networks with corresponding nodes that belong to the same user or entity. The most common application is to analyze which accounts belong to the same user in two social networks. Most of existing techniques rely on matrix factorization so that they cannot be scaled to large-scale networks, are constrained by strict constraints, and cannot learn node embedding without a training set. In this paper, we propose an unsupervised network alignment model based on multi-level graph attention networks. The model uses multi-level graph attention network to learn the embedded representation of nodes, satisfying attribute and structure constraints of alignment. Augmented learning process is proposed to simulate attribute noise and structural noise to improve adaptability of the model. Extensive experiments on real datasets show that the proposed model performs better than the state-of-the-art network alignment model. We also demonstrate the robustness of the proposed model.",https://ieeexplore.ieee.org/document/9524999/,2021 IEEE 46th Conference on Local Computer Networks (LCN),4-7 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMARTCOMP50058.2020.00051,Multi-modal Adversarial Training for Crisis-related Data Classification on Social Media,IEEE,Conferences,"Social media platforms such as Twitter are increasingly used to collect data of all kinds. During natural disasters, users may post text and image data on social media platforms to report information about infrastructure damage, injured people, cautions and warnings. Effective processing and analysing tweets in real time can help city organisations gain situational awareness of the affected citizens and take timely operations. With the advances in deep learning techniques, recent studies have significantly improved the performance in classifying crisis-related tweets. However, deep learning models are vulnerable to adversarial examples, which may be imperceptible to the human, but can lead to model's misclassification. To process multi-modal data as well as improve the robustness of deep learning models, we propose a multi-modal adversarial training method for crisis-related tweets classification in this paper. The evaluation results clearly demonstrate the advantages of the proposed model in improving the robustness of tweet classification.",https://ieeexplore.ieee.org/document/9239612/,2020 IEEE International Conference on Smart Computing (SMARTCOMP),14-17 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BIBM52615.2021.9669328,Multi-modal Information Fusion-powered Regional Covid-19 Epidemic Forecasting,IEEE,Conferences,"With the current raging spread of the COVID19, early forecasting of the future epidemic trend is of great significance to public health security. The COVID-19 is virulent and spreads widely. An outbreak in one region often triggers the spread of others, and regions with relatively close association would show a strong correlation in the spread of the epidemic. In the real world, many factors affect the spread of the outbreak between regions. These factors exist in the form of multimodal data, such as the time-series data of the epidemic, the geographic relationship, and the strength of social contacts between regions. However, most of the current work only uses historical epidemic data or single-modal geographic location data to forecast the spread of the epidemic, ignoring the correlation and complementarity in multi-modal data and its impact on the disease spread between regions. In this paper, we propose a Multimodal InformatioN fusion COVID-19 Epidemic forecasting model (MINE). It fuses inter-regional and intra-regional multi-modal information to capture the temporal and spatial relevance of the COVID-19 spread in different regions. Extensive experimental results show that the proposed method achieves the best results compared to state-of-art methods on benchmark datasets.",https://ieeexplore.ieee.org/document/9669328/,2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),9-12 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICECE48499.2019.9058508,Multi-modal Neural Network for Traffic Event Detection,IEEE,Conferences,"Cities are composed of complex systems with Cyber, Physical, and Social (CPS) components. The advances in the Internet of Things (IoTs) and social networking services help people understand the dynamics of cities. Traffic event detection is an important while complex task in transportation modeling and management of smart cities. In this paper, we address the task of detecting traffic events using two types of data, i.e. physical sensor observations and social media text. Unlike most existing studies focused on either analysing sensor observations or social media data, we identify traffic events with both types of data that may complement each other. We propose a Multi-modal Neural Network (MMN) to process sensor observations and social media texts simultaneously and detect traffic events. We evaluate our model with a real-world CPS dataset consisting of sensor observations, event reports, and tweets collected from Twitter about San Francisco over a period of 4 months. The evaluation shows promising results and provides insights into the analysis of multi-modal data for detecting traffic events.",https://ieeexplore.ieee.org/document/9058508/,2019 IEEE 2nd International Conference on Electronics and Communication Engineering (ICECE),9-11 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00189,Multi-network Embedding for Missing Point-of-Interest Identification,IEEE,Conferences,"The large volume of data flowing throughout location-based social networks (LBSNs) provides an opportunity for human mobility behavior understanding and prediction. However, data quality issues (e.g., historical check-in POI missing, data sparsity) limit the effectiveness of existing LBSN-oriented studies, e.g., Point-of-Interest (POI) recommendation or prediction. Contrary to previous efforts in next POI recommendation or prediction, we focus on identifying the missing POI which the user has visited at a past specific time and proposed a multi-network Embedding (MNE) method. Specifically, the model jointly captures temporal cyclic effect, user preference and sequence transition influence in a unified way by embedding five relational information graphs into a shared dimensional space from both POI- and category-instance levels. The proposed model also incorporates region-level spatial proximity to explore geographical influence, and derives the ranking score list of candidates for missing POI identification. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets, and the experimental results show its superiority over other competitors. Significantly, it also proves that the proposed model can be naturally transferred to general next POI recommendation and prediction tasks with competitive performances.",https://ieeexplore.ieee.org/document/9644693/,"2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",30 Sept.-3 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2010.123,Multi-relational Topic Model for Social Recommendation,IEEE,Conferences,"Various attribute and relation information is used in social recommendation systems. However, previous approaches fail to use them in a unified way. In this paper, we propose a unified framework for social recommendation. Entities like users and items are described by their tags. We model each entity using topic models like Latent Dirichlet Allocation(LDA) and then connect these topic models to form a multi-relational network. Various relations between entities in recommender systems such as rating relation or user friend relation can be expressed as edges in the multi-relational network. We evaluate our model on a real-life dataset collected from a commercial recommender website. Experiments validate the generative performance and predictive performance of our model.",https://ieeexplore.ieee.org/document/5670084/,2010 22nd IEEE International Conference on Tools with Artificial Intelligence,27-29 Oct. 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CVPR42600.2020.01469,Multimodal Categorization of Crisis Events in Social Media,IEEE,Conferences,"Recent developments in image classification and natural language processing, coupled with the rapid growth in social media usage, have enabled fundamental advances in detecting breaking events around the world in real-time. Emergency response is one such area that stands to gain from these advances. By processing billions of texts and images a minute, events can be automatically detected to enable emergency response workers to better assess rapidly evolving situations and deploy resources accordingly. To date, most event detection techniques in this area have focused on image-only or text-only approaches, limiting detection performance and impacting the quality of information delivered to crisis response teams. In this paper, we present a new multimodal fusion method that leverages both images and texts as input. In particular, we introduce a cross-attention module that can filter uninformative and misleading components from weak modalities on a sample by sample basis. In addition, we employ a multimodal graph-based approach to stochastically transition between embeddings of different multimodal pairs during training to better regularize the learning process as well as dealing with limited training data by constructing new matched pairs from different samples. We show that our method outperforms the unimodal approaches and strong multimodal baselines by a large margin on three crisis-related tasks.",https://ieeexplore.ieee.org/document/9157116/,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),13-19 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GRC.2009.5255152,Multiview spectral clustering via ensemble,IEEE,Conferences,"Clustering on multiple views is witnessing increasing interests in both real-world application and machine learning community. A typical application is to discover communities of joint interests in social network, such as Facebook and Twitter. The network can be simply modeled as a graph in which the nodes are the people while the links show relationship between the people. There may exist many relationships between a pair of nodes, such as classmates, collaborators, playmates and so on. It is important to consider how to use these graphs together rather than a single graph if we want to understand the network and their participants effectively. Motivated by the fact, we present a clustering algorithm using spectral analysis in which multiple graphs are considered to get the clusters. Our study can also be considered as an instance of multi-views learning. The experimental results on UCI data set and Corel image data demonstrate the promising results that validate our proposed algorithm.",https://ieeexplore.ieee.org/document/5255152/,2009 IEEE International Conference on Granular Computing,17-19 Aug. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TENCON.2009.5396250,Neuro-fuzzy decision trees for content popularity model and multi-genre movie recommendation system over social network,IEEE,Conferences,"In this paper, we propose a framework of multi-genre movie recommender system based on neuro-fuzzy decision tree (NFDT) methodology. The system is capable of recommending list of movies in descending order of preference in response to user queries and profiles. The system also takes care of attempt to vote stuffing using novel application of fuzzy c-means clustering algorithm. Typical user query and profiles consists of content ratings for multiple genres like action, comedy, drama, music and many others. The distinctive point of the proposed approach is to handle recommender system generation as a supervised pattern classification problem, where in user reviews for multiple genres are conditions and overall star ratings are decisions. The entire recommender system is represented in the form of NFDT. Rules represented by NFDT also acts as a tool for understanding the combinations of contents driving popularity (and unpopularity) over certain social network. We have also proposed a modified inference mechanism based on matching and ordering of firing strength of each fuzzy decision tree path in response to user queries. The computational experiments have been presented on a sample real-world movie review database to judge the efficiency of the proposed recommender system.",https://ieeexplore.ieee.org/document/5396250/,TENCON 2009 - 2009 IEEE Region 10 Conference,23-26 Jan. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICECET52533.2021.9698712,OCR Error Correction Using BiLSTM,IEEE,Conferences,"Language models have critical importance in the pre- and post-processing of optical character recognition (OCR). The quality of documents and scanners is important for OCR systems, with inferior quality leading to more erroneous output. For long time intervals of sequences, long short-term memory (LSTM) fulfills the requirements because it can solve problems with long-term dependencies. In this study, we evaluate the performance of error correction for OCR data using LSTM. The results show that we have good performance for correcting error words by using bidirectional LSTM (BiLSTM). We obtain 98.13&#x0025; better performance in correcting error words by using OCRd data and 97.18&#x0025; better performance by using social media data. In this respect, we show that the method we have applied can be used for error corrections.",https://ieeexplore.ieee.org/document/9698712/,"2021 International Conference on Electrical, Computer and Energy Technologies (ICECET)",9-10 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CLEI53233.2021.9639989,ODROM: Object Detection and Recognition supported by Ontologies and applied to Museums,IEEE,Conferences,"In robotics, object detection in images or videos, obtained in real-time from sensors of robots can be used to support the implementation of service robot tasks (e.g., navigation, model its social behavior, recognize objects in a specific domain), usually accomplished in indoor environments. However, traditional deep learning based object detection techniques present limitations in such indoor environments, specifically related to the detection of small objects and the management of high density of multiple objects. Coupled with these limitations, for specific domains (e.g., hospitals, museums), it is important that the robot, apart from detecting objects, extracts and knows information of the targeted objects. Ontologies, as a part of the Semantic Web, are presented as a feasible option to formally represent the information related to the objects of a particular domain. In this context, this work proposes an object detection and recognition process based on a Deep Learning algorithm, object descriptors, and an ontology. ODROM, an Object Detection and Recognition algorithm supported by Ontologies and applied to Museums, is an implementation to validate the proposal. Experiments show that the usage of ontologies is a good way of desambiguating the detection, obtained with a and <tex>$\mathbf{mAP}{@}0.5=0.88$</tex> and a <tex>$\mathbf{mAP}{@}[0.5:0.95]=61\%$</tex>.",https://ieeexplore.ieee.org/document/9639989/,2021 XLVII Latin American Computing Conference (CLEI),25-29 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData52589.2021.9671426,Object Interaction Recommendation with Multi-Modal Attention-based Hierarchical Graph Neural Network,IEEE,Conferences,"Object interaction recommendation from Internet of Things (IoT) is a crucial basis for IoT related applications. While many efforts are devoted to suggesting object for interaction, the majority of models rigidly infer relationships from human social network, overlook the neighbor information in their own object social network and the correlation of multiple heterogeneous features, and ignore multi-scale structure of the network. To tackle the above challenges, this work focuses on object social network, formulates object interaction recommendation as multi-modals object ranking, and proposes Multi-Modal Attention-based Hierarchical Graph Neural Network (MM-AHGNN), that describes object with multiple knowledge of actions and pairwise interaction feature, encodes heterogeneous actions with multi-modal encoder, integrates neighbor information and fuses correlative multi-modal feature by intra-modal hybrid-attention graph convolution and inter-modal transformer encoder, and employs multi-modal multi-scale encoder to integrate multi-level information, for suggesting object interaction more flexibly. With extensive experiments on real-world datasets, we prove that MMAHGNN achieves better recommendation results (improve 3-4% HR@3 and 4-5% NDCG@3) than the most advanced baseline. To our knowledge, our MM-AHGNN is the first research in GNN design for object interaction recommendation. Source codes are available at: https://github.com/gaosaroma/MM-AHGNN.",https://ieeexplore.ieee.org/document/9671426/,2021 IEEE International Conference on Big Data (Big Data),15-18 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTUS.2017.8285967,Ongoing research agenda on the Internet of Things (IoT) in the context of Artificial Intelligence (AI),IEEE,Conferences,"This talk presents our ongoing research agenda on the Internet of Things (IoT) in the context of Artificial Intelligence (AI). sThree initiatives define this agenda: integration of IoT into business process management, agentification of things, and mutation of things. IoT is among the latest ICT developments that is making the boundaries between reality and fiction vanish. According to Mark Weiser, “…The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it”i. And according to Gartnerii, 6.4 billion connected things were in use in 2016, up 3% from 2015, and will reach 20.8 billion by 2020. In the first initiative, we adopt storytelling principles to design and develop Process of Things (PoT). A PoT is specified as a story whose script indicates the characters that things will play as well as the scenes that will feature these things. A PoT also allows things to collaborate by offering value-added services to end-users. A system implementing PoT will be presented during the talk. In the second initiative, we shed the light on some obstacles that are slowing downIoTexpansion and adoption, for instance diversity of things' development technologies and communication standards, users' reluctance and sometimes rejection due to privacy invasion, lack of killer applications that would demonstrate their necessity, lack of an IoT-oriented software engineering discipline, and finally, the passive nature of things. Because of this nature, things are restricted to sending data to third parties or (basic) processing data prior to their transfer to third parties, too. We are examining how to empower things with additional capabilities that would make them proactive. This means that things can for instance, reach out to peers that expose collaborative attitude, form dynamic communities when necessary, avoid peers that expose malicious attitude, be accountable for their actions, etc. While we already see some encouraging signs of thing empowerment through initiatives like semantic things, Internet of social things, Internet of agents, and agents of things, we propose the agentification of things from a conceptual perspective exemplified with norms and an operational perspective exemplified with commitments. In conjunction with thing agentification, we present during the talk the third initiative that examines thing mutation in the sense that things will bind and/or unbind capabilities on the fly (and as they see fit). To ensure mutation success we consider first, the context in which things operate and second, policies that impact things' decisions to bind/unbind capabilities. We motivate mutation decisions with 3 factors: performance so that a thing remains competitive/attractive, adaptation so that a thing remains responsive, and survivability so that a thing remains in business.",https://ieeexplore.ieee.org/document/8285967/,2017 International Conference on Infocom Technologies and Unmanned Systems (Trends and Future Directions) (ICTUS),18-20 Dec. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AiDAS53897.2021.9574386,Online Shopping Preferences Visualization System Using Web Content Mining,IEEE,Conferences,"Recently, social media sites have been attracting people to start and operate online business. It has been gaining more attention especially during this COVID-19 pandemic, where most activities are conducted via online platform. For instance, Instagram is one of the social media platform where people share and post their pictures and videos on their account, but some people take this opportunity to promote their business and shop online via features provided by Instagram. Based on observation, there is no specific function that visualizes the information of Instagram's business accounts to help people in gaining information and making decisions during shopping process. Thus, a system that specifically visualizes Instagram's extracted data was developed using Web Content Mining technique with the assistance of hashtags as data-points and Phantombuster API. Tableau software integrated with JavaScript library is used as a visualization tool to display the users shopping activities. The result of the extracted data was visualized in the form of Bubble Chart, Bar Chart, and Multiple Bar Chart that were placed in different dashboards. The results from the obtained functional testing and users' feedbacks have indicated 64.3% of the respondents agreed that the proposed system helps users in making the right choice during online shopping. However, this system has some limitation that could be further enhanced such as updating the information automatically in real time without using any manpower and to increase the interactivity between system and user instead of using static visualization graphs.",https://ieeexplore.ieee.org/document/9574386/,2021 2nd International Conference on Artificial Intelligence and Data Sciences (AiDAS),8-9 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SSP.2016.7551730,Online low-rank subspace learning from incomplete data using rank revealing ℓ2/ℓ1 regularization,IEEE,Conferences,"Massive amounts of data (also called big data) generated by a wealth of sources such as social networks, satellite sensors etc., necessitate the deployment of efficient processing tools. In this context, online subspace learning algorithms that aim at retrieving low-rank representations of data constitute a mainstay in many applications. Working with incomplete (partially observed) data has recently become commonplace. Moreover, the knowledge of the real rank of the sought subspace is rarely at our disposal a priori. Herein, a novel low-rank subspace learning algorithm from incomplete data is presented. Its main premise is the online processing of incomplete data along with the imposition of low-rankness on the sought subspace via a sophisticated utilization of the group sparsity inducing ℓ2/ℓ1 norm. As is experimentally shown, the resulting scheme is efficient in accurately learning the subspace as well as in unveiling its real rank.",https://ieeexplore.ieee.org/document/7551730/,2016 IEEE Statistical Signal Processing Workshop (SSP),26-29 June 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IMCCC.2015.348,Ontology Based Service Recommendation System for Social Network,IEEE,Conferences,"The development of recommendation systems, such as traditional content-based, collaborative filtering and hybrid recommendation approaches have enabled the practical use of big data processing in WEB 3.0. In this paper, we propose an ontology based service recommendation system for social network. In this paper, implementation methods of the system are explained in detail. In order to extract user interests more exactly, the TF-IDF (term frequency-inverse document frequency) algorithm is improved according to the features of Micro logs and integrated with the Text Rank algorithm. Also, we have improved the Hownet based semantic similarity algorithm with the consideration of the density of sememe tree. Experimental results show that recommendation results of our system can well reflect the real interests of users, and the improved algorithms can make the results more accurate.",https://ieeexplore.ieee.org/document/7406129/,"2015 Fifth International Conference on Instrumentation and Measurement, Computer, Communication and Control (IMCCC)",18-20 Sept. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC.2017.4,Ontology-Based Social Media Analysis for Urban Planning,IEEE,Conferences,"This paper reports a social media analysis study proposed by the Beijing Municipal Institute of Urban Planning and Design. The purpose is to explore techniques that can help the urban planning administrations to improve the social sensing and social perception abilities under the evolving data and technology environments. A framework integrating a comprehensive set of text mining algorithms is presented to conduct topic modeling, text clustering, event evolution detection, sentiment analysis, opinion mining, and information extraction on user-generated contents in Chinese social media. A domain ontology of Beijing urban planning is constructed to facilitate the text mining processes. Evaluations on two large, real-world datasets composed of microblogs and WeChat articles about the residential community and school education in Beijing demonstrate the effectiveness of our framework. The study illustrates the power of combining machine learning with knowledge-based, semantic approaches in analyzing social media for the domain of interest.",https://ieeexplore.ieee.org/document/8029714/,2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC),4-8 July 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISM52913.2021.00035,Open-Domain Trending Hashtag Recommendation for Videos,IEEE,Conferences,"We describe a novel algorithm for an open-domain trending hashtag recommendation task using zero-shot hashtag prediction in an online learning paradigm. Our method utilizes joint representation learning of latent embeddings for features extracted from long-form videos and semantic embeddings of hashtags trending on social platforms. In particular, we apply graph convolutional networks to a link prediction task using videos and hashtags as nodes in a heterogeneous graph. Comparing it to the existing models for closely related tasks, we demonstrate state-of-the-art results in trending hashtag recommendations for videos. The architecture is designed to be modular in a plug-and-play fashion to enable quick and easy incorporation of the latest advances in natural language understanding and image and video processing, with a practical view to its implementation in a real-time, online setting.",https://ieeexplore.ieee.org/document/9666058/,2021 IEEE International Symposium on Multimedia (ISM),29 Nov.-1 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCIS49240.2020.9257675,Optimal Short Term Power Load Forecasting Algorithm by Using Improved Artificial Intelligence Technique,IEEE,Conferences,"Electrical load forecasting plays a significant impact in terms of future power generation systems such as smart grid, power demand approximation, and better energy management system. Therefore, high accuracy is needed for different time horizons related to regulating, dispatch and scheduling of power system grid. However, it is difficult to do energy prediction with high precision because of influencing factors such as climate, social and seasonal factors. Artificial Intelligence (AI) and Support Vector Machine (SVM) are proved to be capable of handle complex systems and deployed worldwide in many applications due to its superiority on other techniques. The improved short term load forecasting algorithm has been introduced in this research to analyze, discuss and deal with the enhanced electrical power system. The related constraints, influential factors are given and the experimental results can be validated by the effective outcome.",https://ieeexplore.ieee.org/document/9257675/,2020 2nd International Conference on Computer and Information Sciences (ICCIS),13-15 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAL.2009.5262851,Optimal control of continuous annealing process using PSO,IEEE,Conferences,"The continuous annealing furnace is one of the main equipments in the continuous annealing production line for iron and steel enterprise, and has a direct impact on the quality of cold-rolled strip steel, production and cost. The temperature control of continuous annealing furnace is a complex industrial process which is difficult to control. It is difficult to obtain a good control result by using the traditional control method, so a temperature control method with good performance is of great significance. Particle swarm optimization (PSO) has evolved recently as an important branch of stochastic techniques to explore the search space for optimization (Kennedy & Eberhart, 1995). The motivation for the development of this method is based on simulation of simplified social behavior such as bird flocking or fish schooling. Nowadays, PSO has been developed to be real competitor with other well-established techniques for population-based evolutionary computation. PSO has many advantages over other evolutionary computation techniques (for example, genetic algorithms (GAs)), such as simpler implementation, faster convergence rate and fewer parameters to adjust. The proposed scheme is applied to the optimal of the continuous annealing process. Simulation shows the proposed approach is effective.",https://ieeexplore.ieee.org/document/5262851/,2009 IEEE International Conference on Automation and Logistics,5-7 Aug. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ECDC.2014.6836746,Out-network traffic terms: A case study in LinkedIn 1,IEEE,Conferences,"Terms in the use of LinkedIn, as one of the important elements in this website will serve an important role in regulating the flow of traffic. The study of the integration of these terms can be a significant step to avoid congestion and (Users') rejection in the network. Integration of Traffic Control Terms (TCT) between LinkedIn and other social networks is one of the best solutions to establish consequent traffic flow out of the network. Depending on the conditions, integration can be done in different ways. This article examines the direct pass and indirect pass methods. Node phase differences are key elements for integration of LinkedIn considered in this review. To calculate the optimal phasing and appropriate phase difference, first the status of a user in LinkedIn has been analyzed using software, and then the results have been simulated by charting. In this article, the Integration of TCT was done based on evaluation of the TCT performance through determining the appropriate phase differences and reference rule and calculating the measurement of Latency (LT) in the main network port. This latency was calculated as the difference of the expected time and real time of connection or login to the network in simulated conditions. The achieved results indicate that in unsaturated conditions using indirect pass method and in saturated conditions, due to rejection of user and inability of network TCT, using indirect pass method is the best choice for integration of the TCT for LinkedIn and other social networks.",https://ieeexplore.ieee.org/document/6836746/,8th International Conference on e-Commerce in Developing Countries: With Focus on e-Trust,24-25 April 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DeSE51703.2020.9450783,Overcoming Speech Anxiety Using Virtual Reality with Voice and Heart Rate Analysis,IEEE,Conferences,"Social phobias are afflictions that millions of people suffer from. One common social phobia is speech anxiety (Glossophobia), which makes it difficult for people to talk in public or with others. To address this problem, this system was created to help people with Glossophobia practice making presentations or having personal interviews with less fear. The objective is to train them before their presentations or interviews by simulating 360° video environments with virtual reality (VR) technology. During the practice, the system analyzes the voice and heart rate of the person to discover any emotional and physical symptoms of speech anxiety using Arduino heart rate sensors, machine learning, and speech recognition techniques. The system will generate advice based on the symptoms to help make the user more confident. Additionally, after several training sessions, the system will present a report showing the progress in the user's performance. The system has been fully implemented and has demonstrated its operational effectiveness.",https://ieeexplore.ieee.org/document/9450783/,2020 13th International Conference on Developments in eSystems Engineering (DeSE),14-17 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/ICMU48249.2019.9006662,PBEM: A Pattern-Based Embedding Model for User Location Category Prediction,IEEE,Conferences,"With the rapid popularity of mobile devices, a vast amount of trajectory-based check-in data are shared in many social network applications, which is an important data source for user location prediction. The location category prediction, a branch of location prediction, is a vital task in a wide range of areas, including urban planning, advertising and recommendation systems. In this paper, we propose a novel two-step Pattern-Based Embedding Model (PBEM) for predicting the next location category that user will go to. Based on the observation that some users behave frequently in a similarity pattern, a new feature termed as user cluster label is defined. In order to mine user's behavior patterns and extract the cluster label, a Category-Importance-Decay learning strategy is proposed and implemented, which provides a quantitative standard for evaluating the importance of each category. Thus, a comprehensive feature set is obtained including user, time, historical location category, text content, and user cluster label, which greatly enhances the robustness of data representation and contains more knowledge. Then the extracted feature set is fed into Recurrent Neural Network (RNN) in a unified framework, which improves the prediction accuracy. We evaluate the performance of PBEM on two real-life trajectory-based check-in datasets. Experimental results demonstrate that the proposed model can outperform the state-of-the-art methods.",https://ieeexplore.ieee.org/document/9006662/,2019 Twelfth International Conference on Mobile Computing and Ubiquitous Network (ICMU),4-6 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPS47924.2020.00100,PCGCN: Partition-Centric Processing for Accelerating Graph Convolutional Network,IEEE,Conferences,"Inspired by the successes of convolutional neural networks (CNN) in computer vision, the convolutional operation has been moved beyond low-dimension grids (e.g., images) to high-dimensional graph-structured data (e.g., web graphs, social networks), leading to graph convolutional network (GCN). And GCN has been gaining popularity due to its success in real-world applications such as recommendation, natural language processing, etc. Because neural network and graph propagation have high computation complexity, GPUs have been introduced to both neural network training and graph processing. However, it is notoriously difficult to perform efficient GCN computing on data parallel hardware like GPU due to the sparsity and irregularity in graphs. In this paper, we present PCGCN, a novel and general method to accelerate GCN computing by taking advantage of the locality in graphs. We experimentally demonstrate that real-world graphs usually have the clustering property that can be used to enhance the data locality in GCN computing. Then, PCGCN proposes to partition the whole graph into chunks according to locality and process subgraphs with a dual-mode computing strategy which includes a selective and a full processing methods for sparse and dense subgraphs, respectively. Compared to existing state-of-the-art implementations of GCN on real-world and synthetic datasets, our implementation on top of TensorFlow achieves up to 8.8× speedup over the fastest one of the baselines.",https://ieeexplore.ieee.org/document/9139807/,2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS),18-22 May 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IDAACS53288.2021.9660949,PER-COVID (PEople pRoximity based on Certified and coOperative VIDeo-intelligence): A Software Tool for Physical Distancing and PPE Monitoring,IEEE,Conferences,"The recent COVID-19 pandemic has led to a growing interest in IT tools for monitoring social distance and for checking the presence of personal protective equipment and whether it is worn properly. Correct monitoring in outdoor and indoor areas is essential to limit the spread of the virus and the risk of being infected. This paper presents PER-COVID, a software platform capable of monitoring crowds of people and the correct use of personal protective equipment in real time using innovative computer vision algorithms. The proposed system architecture and functional characteristics are illustrated, as well as some user interface screens are provided for simple interpretation and monitoring of critical events.",https://ieeexplore.ieee.org/document/9660949/,2021 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS),22-25 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPSW.2017.178,Parallel Computing for Machine Learning in Social Network Analysis,IEEE,Conferences,"Machine learning, especially deep learning, is revolutionizing how many engineering problems are being solved. Three critical ingredients are needed to apply deep machine learning to significant real world problems: i.) large data sets; ii.) software to implement deep learning and; iii.) significant computing cycles. This paper discusses the state of each ingredient with a specific focus on: a.) how deep learning can apply to large-scale social network analysis and; b.) the computing resources required to make such analyses feasible.",https://ieeexplore.ieee.org/document/7965209/,2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),29 May-2 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISPAN.2004.1300454,Particle swarm optimization algorithm in signal detection and blind extraction,IEEE,Conferences,"The particle swarm optimization (PSO) algorithm, which originated as a simulation of a simplified social system, is an evolutionary computation technique. In this paper the binary and real-valued versions of PSO algorithm are exploited in two important signal processing paradigm: multiuser detection (MUD) and blind extraction of sources (BES), respectively. The novel approaches are effective and efficient with parallel processing structure and relatively feasible implementation. Simulation results validate either PSO-MUD or PSO-BES has a significant performance improvement over conventional methods.",https://ieeexplore.ieee.org/document/1300454/,"7th International Symposium on Parallel Architectures, Algorithms and Networks, 2004. Proceedings.",10-12 May 2004,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCIS.2016.7790307,Passengers' choices on airport drop-off service: A decision forecast based on social learning and machine learning,IEEE,Conferences,"Airport drop-off service provided by airlines is a chauffeur-driven service (i.e. Uber and DiDi) as an emerging travel choice for travelers. More and more passenger enjoy the drop-off service. In practice, we find an interesting question: if a passenger has ever choice the drop-off service, whether they are willing to recommend this service to other traveler? Although the acknowledgment that social learning is related to travel decision is promoted, quantitative analysis about how social learning shape and impact the decision of passengers is still limited. We study and estimate a diffusion probability between different passengers by proposing a CCM (Co-travel Link Cascade Model) based on a modified EM iterative algorithm. Then, we segment passengers into three types (Influenced, Unchecked and Immune). The three types of passengers are predicated by approaches of IC-like model, Random Forest model and probabilistic model, respectively. In addition, we also design a parallel implementation of our proposed algorithm in the Apache Spark distributed data processing environment. Experimental results on a real aviation data set demonstrate that CCM can efficiently infer the decision of travelers.",https://ieeexplore.ieee.org/document/7790307/,2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS),17-19 Aug. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCWorkshops50388.2021.9473673,Passive WiFi CSI Sensing Based Machine Learning Framework for COVID-Safe Occupancy Monitoring,IEEE,Conferences,"The COVID-19 pandemic requires social distancing to prevent transmission of the virus. Monitoring social distancing is difficult and expensive, especially in ""travel corridors"" such as elevators and commercial spaces. This paper describes a low-cost and non-intrusive method to monitor social distancing within a given space, using Channel State Information (CSI) from passive WiFi sensing. By exploiting the frequency selective behaviour of CSI with a cubic SVM classifier, we count the number of people in an elevator with an accuracy of 92%, and count the occupancy of an office to 97%. As opposed to using a multi-class counting approach, this paper aggregates CSI for the occupancies below and above a COVID-Safe limit. We show that this binary classification approach to the COVID safe decision problem has similar or better accuracy outcomes with much lower computational complexity, allowing for real-world implementation on IoT embedded devices. Robustness and scalability is demonstrated through experimental validation in practical scenarios with varying occupants, different environment settings and interference from other WiFi devices.",https://ieeexplore.ieee.org/document/9473673/,2021 IEEE International Conference on Communications Workshops (ICC Workshops),14-23 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW51313.2020.00067,Pelican: Continual Adaptation for Phishing Detection,IEEE,Conferences,"An increasing number of people are using social media services and with it comes a more attractive outlet for phishing attacks. Our initial focus is to analyze Twitter as it is one of the most popular social media services. Phishers on Twitter curate tweets that lead users to websites that download malware. This is a major issue as phishers can then gain access to the user's digital identity and perform malicious acts. Phishing attacks have the potential to be similar in different regions, perhaps at different times. We have developed a novel semi-supervised machine learning algorithm, which we call Pelican, that detects potential phishing attacks in real-time on Twitter. Pelican can be used for early detection of potential phishing attacks and is able to detect potential new attacks without pre-existing assumptions about the type of data or understanding of the characteristics of the attacks. The technique uses ensembles and sampling methods to handle class imbalances in real-world applications. The technique continuously detects unusual behaviour or changes in Twitter. We have investigated changes in trends across Twitter to detect changes in online behaviour of potential phishing links. The technique uses a change detector that enables automatic retraining when there is unusual behaviour detected. Pelican is a novel technique that adapts to changes within phishing attacks in real-time. The technique detects 93.94% of the phishing tweets in real-world data that we collected over a 9 month period, which is higher than benchmark algorithms.",https://ieeexplore.ieee.org/document/9346336/,2020 International Conference on Data Mining Workshops (ICDMW),17-20 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/iV.2015.88,Perceived Realism of Crowd Behaviour with Social Forces,IEEE,Conferences,"This paper investigates the development of an urban crowd simulation for the purposes of psychophysical experimentation. Whilst artificial intelligence (AI) is advancing to produce more concise and interesting crowd behaviours, the number or sophistication of the algorithms implemented within a system does not necessarily guarantee its perceptual realism. Human perception is highly subjective and does not always conform to the reality of the situation. Therefore it is important to consider this aspect when dealing with A implementations within a crowd system aimed at humans. In this research an initial two-alternative forced choice (2AFC) with constant stimuli psychophysical experiment is presented. The purpose of the experiment is to assess whether human participants perceive crowd behaviour with a social forces model to be more realistic. Results from the experiment suggest that participants do consider crowd behaviour with social forces to be more realistic. This research could inform the development of crowd-based systems, especially those that consider viewer perception to be important, such as for example video games and other media.",https://ieeexplore.ieee.org/document/7272647/,2015 19th International Conference on Information Visualisation,22-24 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WiMob52687.2021.9606263,Performance Modelling and Assessment for Social VR Conference Applications in 5G Radio Networks,IEEE,Conferences,"One of the most challenging applications targeted by evolving (beyond-)5G technology is virtual reality (VR). Particularly, 'Social VR' applications provide a fully immersive experience and sense of togetherness to users residing at different locations. To support such applications the network must deal with huge traffic demands, while keeping end-to-end latencies low. Moreover, the radio access network must deal with the volatility and vulnerability of mmWave radio channels, where even small movements of the users may have substantial effects on the Quality of Experience. We present an integral modelling framework for feasibility assessment and performance optimization of the radio access network for Social VR applications in indoor office scenarios. Using the presented modelling approach, we conduct an extensive simulation-based assessment to determine the performance impact of head motion, the frequency band (3.5 GHz, 26 GHz) and radio network configurations, and derive the required carrier bandwidth for a range of 'Social VR' scenarios. Insights into these issues are a prerequisite for setting up guidelines for network deployment and configuration as well as for the development of (AI/ML-based) methods for dynamic resource management to optimally support Social VR applications.",https://ieeexplore.ieee.org/document/9606263/,"2021 17th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)",11-13 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/eCrime.2012.6489521,PhishAri: Automatic realtime phishing detection on twitter,IEEE,Conferences,"With the advent of online social media, phishers have started using social networks like Twitter, Facebook, and Foursquare to spread phishing scams. Twitter is an immensely popular micro-blogging network where people post short messages of 140 characters called tweets. It has over 100 million active users who post about 200 million tweets everyday. Phishers have started using Twitter as a medium to spread phishing because of this vast information dissemination. Further, it is difficult to detect phishing on Twitter unlike emails because of the quick spread of phishing links in the network, short size of the content, and use of URL obfuscation to shorten the URL. Our technique, PhishAri, detects phishing on Twitter in realtime. We use Twitter specific features along with URL features to detect whether a tweet posted with a URL is phishing or not. Some of the Twitter specific features we use are tweet content and its characteristics like length, hashtags, and mentions. Other Twitter features used are the characteristics of the Twitter user posting the tweet such as age of the account, number of tweets, and the follower-followee ratio. These twitter specific features coupled with URL based features prove to be a strong mechanism to detect phishing tweets. We use machine learning classification techniques and detect phishing tweets with an accuracy of 92.52%. We have deployed our system for end-users by providing an easy to use Chrome browser extension. The extension works in realtime and classifies a tweet as phishing or safe. In this research, we show that we are able to detect phishing tweets at zero hour with high accuracy which is much faster than public blacklists and as well as Twitter's own defense mechanism to detect malicious content. We also performed a quick user evaluation of PhishAri in a laboratory study to evaluate the usability and effectiveness of PhishAri and showed that users like and find it convenient to use PhishAri in real-world. To the best of our knowledge, this is the first realtime, comprehensive and usable system to detect phishing on Twitter.",https://ieeexplore.ieee.org/document/6489521/,2012 eCrime Researchers Summit,23-24 Oct. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPEC51340.2021.9421213,Pneumatic Training Glove Based on Electromyographic Signal Control,IEEE,Conferences,"In modern society, much public attention is paid to the rights and interests of the disabled, which become a social problem. In order to satisfy the pursuit of disabled for a better quality of life, it is necessary to give them a normal life. For example, people with degeneration or atrophy of hand muscles caused by accidents or other reasons need an auxiliary system to help them recover their hand muscles. However, after consulting a large amount of data, I found that most hospitals in the market use hard levers and springs as mechanical structures, which will result in excessive resistance, poor finger curls, and even aggravate the disease due to improper use. In contrast, the deformable structure is softer. Meanwhile, it can actively bend the fingers of patient through the inflation control method to achieve the purpose of safety and effectiveness. In this paper, the design and casting of pneumatic muscle are completed through independent modeling and pouring in the experiment [1]. At the same time, this paper also provides and tests two machine learning pneumatic muscle control algorithms based on real-time binning, which are idempotent and real-time, and can be fully controlled in combination with the designed pneumatic muscle. Its core signal comes from EMG signals on key muscle groups of the arm. The signal is collected from muscle in real time by wet electrode patch. For the control model of machine learning, we have tested and implemented a variety of gesture postures, including common palm curling and stretching, common finger movements, etc. The pneumatic muscle hand rehabilitation auxiliary glove based on electromyographic signal control has the characteristics such as passive exercise, safety, less pain, individuation, low price, full and effective exercise, etc. The pneumatic muscle-assisted rehabilitation system based on electrical signal control in this paper has broad application prospects and extremely high value.",https://ieeexplore.ieee.org/document/9421213/,"2021 IEEE Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)",14-16 April 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AXMEDIS.2007.19,Poolcasting: A Social Web Radio Architecture for Group Customisation,IEEE,Conferences,"Poolcasting is a social Web radio architecture in which groups of listeners influence in real time the music played on each channel. Poolcasting users contribute to the radio with songs they own, create radio channels and evaluate the proposed music, while an automatic intelligent technique schedules each channel with a group-customised sequence of musically associated songs. The benefits of this approach are multiple: on one hand music producers can increase the exposure of their songs to specific target audiences; on the other hand, music consumers can easily discover new songs that match their preferences and group with people with whom they share similar listening experiences.",https://ieeexplore.ieee.org/document/4402867/,Third International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution (AXMEDIS'07),28-30 Nov. 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PuneCon52575.2021.9686508,Post Cyclone Damage Assessment Using CNN Based Transfer Learning and Grad-CAM,IEEE,Conferences,"Evaluating the aftermath of a cyclone is an expensive, arduous and time-consuming process which delays rehabilitation of affected victims. As multiple requests for grant aids pour in, it is necessary to cross-check the reality of the damage. At present, this investigation is mostly done by the concerned authorities manually. Now-a-days, social media can be considered as a repository for a plethora of post-disaster images. This pool of images may be used as a database to extract features to draw conclusions on the severity of cyclones. Since, tropical cyclones are frequently occurring in the Indian subcontinent, our research can be pivotal in curtailing the efforts of disaster management. The proposed CNN based architecture aims to detect whether an area has been damaged by a cyclone or not, and also the adversity of the same. Transfer learning has been deployed to fine tune the models, VGG-16 and VGG-19 to perform the task. This damage assessment system categorizes the images depicting distinct features like trees, posts, damaged property which have been explicitly cross-validated with Grad-CAM. The proposed model exhibits high accuracy in classifying post catastrophic destruction in a proficient and cost-effective manner.",https://ieeexplore.ieee.org/document/9686508/,2021 IEEE Pune Section International Conference (PuneCon),16-19 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TENCON.2019.8929317,Practical Significance of GA PartCC in Multi-Label Classification,IEEE,Conferences,"Multi-label classification (MLC) can be defined as the objective of learning a classification model which has the capability to infer the accurate labels of new, previously unseen, objects where it is a likely situation that each object of the dataset may rightfully belong to multiple class labels. While single-label classification problems have been thoroughly researched, the same cannot be said for MLC. A gradually increasing number of problems are now being tackled as multi-label, allowing for richer and more accurate knowledge mining in real-world domains, such as medical diagnoses, social media, text classification, etc. Currently, there are two ways of solving MLC problems; Problem Transformation Approach and Algorithm Adaptation Method. Of the two, the former has in its domain Classifier Chains (CC) which is the most effective and popular method of solving MLC problems because of its simplicity in implementation. Unfortunately, CC is not favoured due to 2 drawbacks, [1] ordering of the labels for classification are randomly decided without a fixed logic or algorithm to it which results in varying accuracy, [2] all the labels, even those which may be redundant for a particular dataset are put into the chain despite the probability that some may be carrying irrelevant details. Through the research conducted for the purpose of this study, both challenges are tackled along with others detailed further on simultaneously using Genetic Algorithms (GA) over a Partial CC (PartCC) model, which is a modification over CC. A toxic comments dataset is used since its classification is a multi-label text classification problem with a highly imbalanced dataset. This paper aims to create a prototype model that is capable of detecting various types of toxicity like neutral, toxic, severe toxic, threats, obscenity, insults and identity hate. With the explosion of social media in the modern world and the resulting increasing phenomenon of social media hatred and bullying, there is a need for an advanced prototype model to predict the toxicity of each class of comments.",https://ieeexplore.ieee.org/document/8929317/,TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON),17-20 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCICC46617.2019.9146087,Predicting Link Sign in Online Social Networks based on Social Psychology Theory and Machine Learning Techniques,IEEE,Conferences,"Online social networks provide a great platform for internet users to share their views and ideas. Social media provides a dynamic platform that includes the formation and deformation of connections. Two types of connections, i.e., Positive and Negative, can exist in a social network. Positive connections are a sign of friendship or trust, while negative connections show enmity or distrust. Various applications in several fields have networks containing both positive and negative edges. Reliable prediction of edge sign can greatly influence in recommending friendly relationships while preventing enemy relationships across the network. Prediction of edge signs has been explored previously also. However, we intend to predict the sign of edges based on extracted features of nodes constructed upon theories of social psychology that includes classical balance theory and the status theory. Moreover, we employ emotional information theory and use the combined extracted features from all the theories to analyze networks for better prediction. Our results show that the proposed methodology has obtained significant accuracy when implemented on two real-life datasets, namely Slashdot and Epinions.",https://ieeexplore.ieee.org/document/9146087/,2019 IEEE 18th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),23-25 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW.2016.0026,Predicting User Roles in Social Networks Using Transfer Learning with Feature Transformation,IEEE,Conferences,"How can we recognise social roles of people, given a completely unlabelled social network? We may train a role classification algorithm on another dataset, but then that dataset may have largely different values of its features, for instance, the degrees in the other network may be distributed in a completely different way than in the first network. Thus, a way to transfer the features of different networks to each other or to a common feature space is needed. This type of setting is called transfer learning. In this paper, we present a transfer learning approach to network role classification based on feature transformations from each network's local feature distribution to a global feature space. We implement our approach and show experiments on real-world networks of discussions on Wikipedia as well as online forums. We also show a concrete application of our approach to an enterprise use case, where we predict the user roles in ARIS Community, the online platform for customers of Software AG, the second-largest German software vendor. Evaluation results show that our approach is suitable for transferring knowledge of user roles across networks.",https://ieeexplore.ieee.org/document/7836657/,2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW),12-15 Dec. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMTMA54903.2022.00163,Prediction Method of Pollutant Concentration Based on GA-ELM Model,IEEE,Conferences,"With the rapid development of social economy, air pollution has attracted more and more attention. In order to effectively predict the situation of pollutants and improve pollution prevention and control, this paper presents a prediction model of limit learning machine optimized by genetic algorithm (GA-ELM). Collect the data of an air quality monitoring point, conduct simulation experiments with MATLAB software, finally analyze the prediction results of pollutant concentration, and compare them with the prediction results of WRF-CMAQ system. The results show that GA- ELM model can predict the pollutant concentration more accurately, the fitting degree between the prediction curve and the real value curve is high, and the relative error fluctuates up and down in the range of -0.2~0.2, which further shows that the model has good robustness.",https://ieeexplore.ieee.org/document/9724075/,2022 14th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA),15-16 Jan. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ElConRus51938.2021.9396292,Prediction of Relation Based on Social Network Parsing,IEEE,Conferences,"The problem of searching a potential partner among the particular groups in dating applications is studied in this article. Moreover, the assessment of the current methods is carried out and the ways to improve their efficiency are presented. To begin with, there are two main disadvantages of the dating applications nowadays. The first one is imperfect algorithms of selection and the second one is the lack of ""human touch"". It means, that people with common friends in real life will communicate better in the Internet. Due to that, the major features of the research are searching among the common social circle and processing the data by parsing the social network of the potential partner. As a result, the program compares the personal information of every user and makes the pairs with more similar data. All information is processed by Linear neural network which was trained by results of social surveys .The search algorithm is implemented using specialized libraries for Python 3.8 and public methods of VK.API. Also, there are data and findings in the end of this article.",https://ieeexplore.ieee.org/document/9396292/,2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus),26-29 Jan. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE51474.2020.00055,Prediction of Trust Propagation in Social Commerce based on Ensemble Learning,IEEE,Conferences,"Accurate prediction of trust propagation in social commerce is vital to recommendation and promotion of commodities. Existing prediction models have some shortages, such as simple process of influencing factors of trust and low prediction precision. To address these problems, a prediction model based on Soft-Voting ensemble learning was proposed. Firstly, features of influencing factors of information propagation in social commerce were constructed from user attributes, information text and user interaction. Secondly, XGBoost, LightGBM and Catboost models were trained according to the above constructed features to predict trust propagation in social commerce. Finally, results of XGBoost, LightGBM and Catboost models were integrated using Soft-Voting technique as the final prediction results. An experiment on a real dataset of Sina Weibo was carried out, which proved the higher precision of Soft-Voting ensemble learning compared to those of XGBoost, LightGBM and Catboost models.",https://ieeexplore.ieee.org/document/9403760/,2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),30 Oct.-1 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICAI.2019.8701417,Predictive Framework to Measure Mental Distress Caused by Economic Crises,IEEE,Conferences,"Over the years, research has continuously emphasized that economic calamities are negatively correlated with the mental stability of public. Psychologists and sociologists continue to probe downturns influence of economic crisis on mental health and propose social protection programs to promote recovery. The problem, however, is that more than having a social recovery program, it requires personal level efforts to realize and understand what may be coming ahead and rationally solving it, by being more in control of the situation. Considering this context, there are various aims of this paper to evaluate theoretical as well as conceptual illustrations on the reasons behind the negative associations of an economic downturn on population's mental stability, followed by closely examining critical mental distress factors as well as economic distress factors and establishing connection through literature analysis. The study proposes a framework to intelligently detect economic distress in real time and successfully link it with human distress factors to predict any anticipated alleviation in stress level. The proposed framework is based on cloud architecture and uses software application that will perform intelligent data mining for knowledge acquisition purpose.",https://ieeexplore.ieee.org/document/8701417/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2016.0020,Preference-Like Score to Cope with Cold-Start User in Recommender Systems,IEEE,Conferences,"In recent years, there has been an explosion of social recommender systems (SRS) research. However, the dominant trend of these studies has been towards designing new prediction models. The typical approach is to use social information to build those models for each new user. Due to the inherent complexity of this prediction process, for full cold-start user in particular, the performance of most SRS fall a great deal. We, rather, propose that new users are best served by models already built in system. Selecting a prediction model from a set of strong linked users might offer better results than building a personalized model for full cold-start users. We contribute to this line of work comparing several matrix factorization based SRS under full cold-start user scenario, and proposing a general model selection approach, called ToSocialRec, that leverages existing recommendation models to offer items for new users. Our framework is not only able to handle several social network connection weight metrics, but any metric that can be correlated with preference similarity among users, named here as Preference-like score. We perform experiments on real life datasets that show this technique is as efficient or more than current state-of-the-art techniques for cold-start user. Our framework has also been designed to be easily deployed and leveraged by developers to help create a new wave of SRS.",https://ieeexplore.ieee.org/document/7814580/,2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI),6-8 Nov. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICETCI51973.2021.9574068,Prevention of Emotional Entrapment of Children on Social Media,IEEE,Conferences,"Increasing usage of social media and its widespread reaches across the younger as well as older demographics of the population, along with the added advantage of anonymity, has propelled the pressing need to ensure that these platforms remain a secure place for children so as to safeguard them from issues like child grooming. Over the last few years, the rate of online grooming has seen a massive increase along with an increase in the number of teenage users. The proposed system, Prevention of Emotional Entrapment of Children (PEEC), consists of an age detection module using Deep Neural Network (DNN) as well as a grooming detection module using Support Vector Machine (SVM) to monitor the conversations of only those users who come under the category of minor (below 18). The resultant system gave an accuracy of 84% for age detection and 91% for grooming detection.",https://ieeexplore.ieee.org/document/9574068/,2021 International Conference on Emerging Techniques in Computational Intelligence (ICETCI),25-27 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ARITH.2019.00047,Privacy-Preserving Deep Learning via Additively Homomorphic Encryption,IEEE,Conferences,"We aim at creating a society where we can resolve various social challenges by incorporating the innovations of the fourth industrial revolution (e.g. IoT, big data, AI, robot, and the sharing economy) into every industry and social life. By doing so the society of the future will be one in which new values and services are created continuously, making people's lives more conformable and sustainable. This is Society 5.0, a super-smart society. Security and privacy are key issues to be addressed to realize Society 5.0. Privacy-preserving data analytics will play an important role. In this talk we show our recent works on privacy-preserving data analytics such as privacy-preserving logistic regression and privacy-preserving deep learning. Finally, we show our ongoing research project under JST CREST “AI”. In this project we are developing privacy-preserving financial data analytics systems that can detect fraud with high security and accuracy. To validate the systems, we will perform demonstration tests with several financial institutions and solve the problems necessary for their implementation in the real world.",https://ieeexplore.ieee.org/document/8877418/,2019 IEEE 26th Symposium on Computer Arithmetic (ARITH),10-12 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CASA.2003.1199296,Proceedings 16th International Conference on Computer Animation and Social Agents,IEEE,Conferences,"The following topics are dealt with: social and conversational agents; physics-based animation; interaction, control and planning; AI-based animation and A-life; modeling of groups and crowds; virtual humans: past, present and future; and design issues in games and virtual environments.",https://ieeexplore.ieee.org/document/1199296/,Proceedings 11th IEEE International Workshop on Program Comprehension,8-9 May 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2018.8508242,ProfileGen: Generation of Automatic and Realistic Artificial Profiles,IEEE,Conferences,"One of the most effective approaches for detecting malicious activity in online social networks (OSNs) involves the use of social network honeypots - artificial profiles. Therefore, there is a growing need for the ability to reliably generate realistic artificial honeypot profiles in OSNs. In this research we present `ProfileGen' - a method for the automated generation of profiles for professional social networks, giving particular attention to producing realistic education and employment records. `ProfileGen' creates honeypot profiles that are similar to actual data by extrapolating the characteristics and properties of real data items. Evaluation by 70 domain experts confirms the method's ability to generate realistic artificial profiles that are indistinguishable from real profiles, demonstrating that our method can be applied to generate realistic artificial profiles for a wide range of applications.",https://ieeexplore.ieee.org/document/8508242/,2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),28-31 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSEET49119.2020.9206229,Project-Based Learning in a Machine Learning Course with Differentiated Industrial Projects for Various Computer Science Master Programs,IEEE,Conferences,"Graduating computer science students with skills sufficient for industrial needs is a priority in higher education teaching. Project-based approaches are promising to develop practical and social skills, needed to address real-world problems in teams. However, rapid technological transition makes an initial training of contemporary methods challenging. This affects the currently much-discussed machine learning domain as well. The study at hand describes a re-framed teaching approach for a machine learning course, offered to various computer science master programs. Project-based learning is introduced with differentiated projects provided by industrial partners that address the diverse study programs. Course attendees are supported with manuals, tools, and tutoring, passing through the Cross Industry Standard Process for Data Mining (CRISP-DM). Observations made during two iterations are reported, accompanied by a first empiric evaluation of student experiences.",https://ieeexplore.ieee.org/document/9206229/,2020 IEEE 32nd Conference on Software Engineering Education and Training (CSEE&T),9-12 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MASS.2018.00019,Q-Learning Based Edge Caching Optimization for D2D Enabled Hierarchical Wireless Networks,IEEE,Conferences,"Caching at the edge of mobile networks can significantly offload network traffic while satisfying content requests from mobile users locally. The contents can be requested from the proximity users via Device-to-device (D2D) communications while proactive caching the popular content to local users. However, the assumptions that content popularity is equal to user preference in several existing studies, which are invalid and not rigorous due to the fact that content popularity is calculated by the statistic of user requests within a certain period while user preference reflects the probability of a content requested by the individual user. Motivated by this, in this paper, we study the edge caching optimization of hierarchical wireless networks. Our aiming is to maximize the size of content offload by D2D communications. In particular, the edge caching policy with D2D sharing model based on the analysis of user mobility and social relationship is derived. We first prove the problem is NP-hard and then formulate it as a Markov Decision Process (MDP) problem, finally a Q-learning based distributed content replacement strategy is proposed. The large-scale real trace based experiment results show the effectiveness of our proposed framework.",https://ieeexplore.ieee.org/document/8567541/,2018 IEEE 15th International Conference on Mobile Ad Hoc and Sensor Systems (MASS),9-12 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IntelCIS.2015.7397269,Ranking of news items in rule-stringent social media based on users' importance: A social computing approach,IEEE,Conferences,"In this paper an innovative social media news items ranking scheme is proposed. The proposed unsupervised architecture takes into consideration user-content interactions, since social media posts receive likes, comments and shares from friends and other users. Additionally the importance of each user is modeled, based on an innovative algorithm that borrows ideas from the PageRank algorithm. Finally, a novel content ranking component is introduced, which ranks posted news items based on a social computing method, driven by the importance of the social network users that interact with them. Initial experiments on real life social networks news items illustrate the promising performance of the proposed architecture. Additionally comparisons with three different ranking ways are provided (SUMF, RSN-CO and RSN-nCO), in terms of user satisfaction.",https://ieeexplore.ieee.org/document/7397269/,2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS),12-14 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2017.7989184,Rapidly exploring learning trees,IEEE,Conferences,"Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.",https://ieeexplore.ieee.org/document/7989184/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/I-SMAC.2017.8058261,Real world smart chatbot for customer care using a software as a service (SaaS) architecture,IEEE,Conferences,"It's being very important to listen to social media streams whether it's Twitter, Facebook, Messenger, LinkedIn, email or even company own application. As many customers may be using this streams to reach out to company because they need help. The company have setup social marketing team to monitor this stream. But due to huge volumes of users it's very difficult to analyses each and every social message and take a relevant action to solve users grievances, which lead to many unsatisfied customers or may even lose a customer. This papers proposes a system architecture which will try to overcome the above shortcoming by analyzing messages of each ejabberd users to check whether it's actionable or not. If it's actionable then an automated Chatbot will initiates conversation with that user and help the user to resolve the issue by providing a human way interactions using LUIS and cognitive services. To provide a highly robust, scalable and extensible architecture, this system is implemented on AWS public cloud.",https://ieeexplore.ieee.org/document/8058261/,"2017 International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)",10-11 Feb. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UrgentHPC54802.2021.00009,Real-Time COVID-19 Infection Risk Assessment and Mitigation based on Public-Domain Data,IEEE,Conferences,"A number of models have been developed to predict the spreads of the COVID-19 pandemic and how non-pharmaceutical interventions (NPIs) such as social distancing, facial coverings, and business and school closures can contain this pandemic. Evolutionary artificial intelligence (AI) approaches have recently been proposed to automatically determine the most effective interventions by generating a large number of candidate strategies customized for different countries and locales and evaluating them with predictive models. These epidemiological models and advanced AI techniques assist policy makers by providing them with strategies in balancing the need to contain the pandemic and the need to minimize their economic impact as well as educating the general public about ways to reduce the chance of infection. However, they do not advise an individual citizen at a specific moment and location on taking the best course of actions to accomplish a task such as grocery shopping while minimizing infection.Therefore, this paper describes a new project aiming to develop a mobile-phone-deployable, real-time COVID-19 infection risk assessment and mitigation (RT-CIRAM) system which analyzes up-to-date data from multiple open sources leveraging urgent HPC/cloud computing, coupled with time-critical scheduling and routing techniques. Implementation of a RT-CIRAM prototype is underway, and it will be made available to the public. Facing the increasing spread of the more contagious Delta (B.1.617.2) and Delta Plus (AY.4.2) variants, this personal system will be especially useful for individual citizen to reduce her/his infection risk despite increasing vaccination rates while contributing to containing the spread of the current and future pandemics.",https://ieeexplore.ieee.org/document/9651302/,2021 IEEE/ACM HPC for Urgent Decision Making (UrgentHPC),19-19 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CISAI54367.2021.00190,Real-Time Facial Expression Driving based on 3D Facial Feature Point,IEEE,Conferences,"Facial expression driving can make the expression of virtual characters more real and natural. It is widely used in movies, games and some social software. The existing real-time facial expression driving algorithms have the limitation of physical hardware, prefabricated model or long-time training. In order to get rid of the limitation of existing algorithms, this paper proposes a real-time expression driving algorithm based on 3D facial feature points with RGBD data as input. In the face capture, we use ICP algorithm to get the rigid data of the face and deformation transmission algorithm to capture the non-rigid data of the face. Moreover, the whole face process only takes 0.4ms to complete. Because the calculation of the algorithm is based on 3D feature points of the face, there is no need to prefabricate a specific face model and a lot of time training. Our algorithm can not only use real faces to drive virtual faces, but also use virtual characters to drive virtual faces.",https://ieeexplore.ieee.org/document/9718961/,2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI),17-19 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ic-ETITE47903.2020.394,Real-time Acoustic based Depression Detection using Machine Learning Techniques,IEEE,Conferences,"Depression disorder is predicted to rise to the second leading cause of disability by 2030 as per the identifications of the World Health organization (WHO). Though well trained clinicians, medical and psychological treatments are available for depression treatment, persons or families are reluctant to speak out/reach doctors about this disorder for various social reasons. Diagnosis of depression disorder includes numerous interviews with patient and family, clinical analysis, questionnaires which is time consuming and also demands well trained clinicians. In the present era of Machine learning, automation of depression detection is not complicated and can easily be deployed. However, the automation should use fewer resources, provide accurate results with more reachability. In this paper, acoustic features are used to train a classification model to categorize a human as Depressed or not-Depressed. DIAC-WOZ database available with AVEC2016 challenge is considered for training the classifiers. Prosodic, Spectral and Voice control features are extracted using the COVAREP toolbox and are feature fused. SMOTE analysis is used for overcoming the class imbalance and 93% accuracy is obtained with the SVM algorithm resulting in Depression Classification Model (DCM). An android application cureD Deployed on Cloud is developed to self assess depression using DCM and PHQ-8 questionnaire. The application is tested on real time data of 50 subjects under the supervision of a qualified psychiatrist and an accuracy of 90% is obtained.",https://ieeexplore.ieee.org/document/9077698/,2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE),24-25 Feb. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICNSC.2019.8743331,Real-time Sentiment Analysis On E-Commerce Application,IEEE,Conferences,"Opinion mining is one of the most important tasks of natural language processing, which is also known as sentiment analysis, used to identify about what people have an impression about their services and products in social media platforms. To improve marketing strategies using product reviews, an effective method should be used for predicting the sentiment polarity. In this research article, a Machine learning technique called Support Vector Machine (SVM) is used to design a model and this model has been implemented on an E-commerce application. The data used in this study are online product reviews which are collected from Amazon.com. The experiments of sentiment analysis are performed for two levels of categorization: review level and sentence level. The main focus of this paper is to present a real-time sentimental analysis on the product reviews of e-commerce application so that the user experience can be enhanced.",https://ieeexplore.ieee.org/document/8743331/,"2019 IEEE 16th International Conference on Networking, Sensing and Control (ICNSC)",9-11 May 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITE54466.2022.9759552,Real-time Social Distance Detection using YOLO-v5 with Bird-eye View Perspective to Suppress the Spread of COVID-19,IEEE,Conferences,"The COVID-19 virus outbreak has continued to spread since the end of 2019 worldwide. All people also implement health protocols not to contract this disease. One of the health protocols that must be implemented is to limit interactions between humans to a length of 1&#x2013;2 meters or what is usually done with social distancing. Social distance detection system to ensure that people do not violate social distancing could be a solution to this problem. Using the YOLO-v5 method, which is the latest version of the YOLO (You Only Look Once) method with a detection speed of up to 140 Frames Per Second (FPS) and 90 percent smaller than the previous version, this system detects people who violate social distancing and then gives a voice warning to keep their distance to avoid spreading the COVID-19 virus. The human detection rate in the detection system reaches 93,5&#x0025;, and the accuracy for social distance detection reaches 95&#x0025;. Based on the research that has been done, it can be said that this system can work well for detecting social distance, but the detection will start detecting the distance between the camera and the object exceeding 10 meters.",https://ieeexplore.ieee.org/document/9759552/,2022 2nd International Conference on Information Technology and Education (ICIT&E),22-22 Jan. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/INTECH.2017.8102423,Real-time emotional state detection from facial expression on embedded devices,IEEE,Conferences,"From the last decade, researches on human facial emotion recognition disclosed that computing models built on regression modelling can produce applicable performance. However, many systems need extensive computing power to be run that prevents its wide applications such as robots and smart devices. In this proposed system, a real-time automatic facial expression system was designed, implemented and tested on an embedded device such as FPGA that can be a first step for a specific facial expression recognition chip for a social robot. The system was built and simulated in MATLAB and then was built on FPGA and it can carry out real time continuously emotional state recognition at 30 fps with 47.44% accuracy. The proposed graphic user interface is able to display the participant video and two dimensional predict labels of the emotion in real time together.",https://ieeexplore.ieee.org/document/8102423/,2017 Seventh International Conference on Innovative Computing Technology (INTECH),16-18 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDSP.2015.7251991,Real-time sociometrics from audio-visual features for two-person dialogs,IEEE,Conferences,"This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.",https://ieeexplore.ieee.org/document/7251991/,2015 IEEE International Conference on Digital Signal Processing (DSP),21-24 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MIPRO.2016.7522376,Reciprocal payers identification in banking logs using SAT solvers,IEEE,Conferences,"In this paper we presented solvers for satisfiability testing (SAT) as a novel approach to finding reciprocal payers in banking logs. A term “reciprocal payers” is usually treated as general fraud by using standard techniques such as expert systems, machine learning and in recent times social network analysis. SAT as a technique for data analysis was abandoned due to the unfeasibility of SAT solvers. SAT solvers, however continued to develop in the hardware and software verification communities. We presented a proof-of-concept solution for identification of reciprocal payers (formally called a clique), which is a group of bank clients that issue payments to each other (each member to each member). We do not use real data due to client confidentiality, but the reader can see the principle. In the basic approach it is assumed that each client has only one account, and in the extended, second approach, it was allowed that a client can have more than one account.",https://ieeexplore.ieee.org/document/7522376/,"2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)",30 May-3 June 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IRDS.2002.1043897,Recognizing and remembering individuals: online and unsupervised face recognition for humanoid robot,IEEE,Conferences,"Individual recognition is a widely reported phenomenon in the animal world, where it contributes to successful maternal interaction, parental care, group breeding, cooperation, mate choice, etc. This work addresses the question of how one may implement such social competence in a humanoid robot. We argue that the robot must be able to recognize people and learn about their various characteristics through embodied social interaction. Thus, we proposed an initial implementation of an online and unsupervised face recognition system for Kismet, our sociable robotic platform. We show how specific features of this particular application drove our decision and implementation process, challenged by the difficulty of the face recognition problem, which has so far been explored in the supervised manner. Experimental results are reported to illustrate what was solved and the lessons learned from the current implementation.",https://ieeexplore.ieee.org/document/1043897/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2017.7989267,Recognizing social touch gestures using recurrent and convolutional neural networks,IEEE,Conferences,"Deep learning approaches have been used to perform classification in several applications with high-dimensional input data. In this paper, we investigate the potential for deep learning for classifying affective touch on robotic skin in a social setting. Three models are considered, a convolutional neural network, a convolutional-recurrent neural network and an autoencoder-recurrent neural network. These models are evaluated on two publicly available affective touch datasets, and compared with models built to classify the same datasets. The deep learning approaches provide a similar level of accuracy, and allows gestures to be predicted in real-time at a rate of 6 to 9 Hertz. The memory requirements of the models demonstrate that they can be implemented on small, inexpensive microcontrollers, demonstrating that classification can be performed in the skin itself by collocating computing elements with the sensor array.",https://ieeexplore.ieee.org/document/7989267/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPIN.2019.8911776,Regression Assisted Crowdsourcing Approach for Fingerprint Radio Map Construction,IEEE,Conferences,"Due to the proliferating social and commercial interest on location-based services (LBS), research and development of indoor positioning system (IPS) have been expanded. Most of the efficient IPS methods utilize radio-based solutions to meet the accuracy requirement of indoor LBS. Typically fingerprinting localization is realized, which requires a site survey process where radio signatures of a localization area are annotated with their actual recorded locations. The site survey is time-consuming and labor-intensive that intensifies practical limits and challenges in realizing a reliable and scalable IPS. In this paper, we propose a crowdsourcing-based approach to acquire the training data set for Gaussian process regression (GPR). In particular, we suggest combining access point (AP) proximity information and pedestrian dead reckoning (PDR) to collect labeled data without any human intervention. The crowdsourced training data are fed to model a Gaussian process, which predicts the mean RSS and its corresponding variance across the testbed. To validate the proposed method, we compared the predicted data with the manually measured one and utilized the predicted data for localization using weighted k-nearest neighbor (Wk-NN) and maximum likelihood (ML) based fingerprinting localization. Experimental results obtained by real field deployment show that the average difference between the predicted RSS and manually measured RSS is 3.87 dBm and 80% of the localization estimation error are below 5.5m.",https://ieeexplore.ieee.org/document/8911776/,2019 International Conference on Indoor Positioning and Indoor Navigation (IPIN),30 Sept.-3 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2012.39,Relationships between Periodic Behaviors in Micro-blogging and the Users' Baseline Mood,IEEE,Conferences,"Twitter messages are real-time, spontaneous reports of what the users are feeling, thinking, and doing. The frequency of posting ""Tweets"" oscillates periodically in one-day and seven-day cycles. These periodic patterns may be related to the individual users' baseline affective state. In order to investigate individual periodic behavior in social media, we performed a Fourier series expansion and PCA on intra-week Tweet-frequency changes of 11,570 individuals. Moreover, the relationships between the users' baseline mood and the principal component scores were investigated. High frequency in daytime tweets on weekdays was found to be linked to a low positive affective state. The larger number of posting tweets was related to the negative affective state.",https://ieeexplore.ieee.org/document/6299313/,"2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",8-10 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN52387.2021.9534136,Relevance-Aware Anomalous Users Detection in Social Network via Graph Neural Network,IEEE,Conferences,"Anomalous users detection in social network is an imperative task for security problems. Motivated by the great power of Graph Neural Networks(GNNs), many current researches adopt GNN-based detectors to reveal the anomalous users. However, the increasing scale of social activities, explosive growth of users and manifold technical disguise render the user detection a difficult task. In this paper, we propose an innovate Relevance-aware Anomalous Users Detection model (RAU-GNN) to obtain a fine-grained detection result. RAU-GNN first extracts multiple relations of all types of users in social network, including both benign and anomalous users, and accordingly constructs the multiple user relation graph. Secondly, we employ relevance-aware GNN framework to learn the hidden features of users, and discriminate the anomalous users after discriminating. Concretely, by integrating Graph Convolution Network(GCN) and Graph Attention Network(GAT), we design a GCN-based relation fusion layer to aggregate initial information from different relations, and a GAT-based embedding layer to obtain the high-level embeddings. Lastly, we feed the learned representations to the following GNN layer in order to consolidate the node embedding by aggregating the final users' embeddings. We conduct extensive experiment on real-world datasets. The experimental results show that our approach can achieve high accuracy for anomalous users detection.",https://ieeexplore.ieee.org/document/9534136/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DSC.2018.00139,Representation Learning Based on Influence of Node for Multiplex Network,IEEE,Conferences,"The research of social network and mining of multi-source/ multi-view network has gradually been a focus in the field of social network recently. Existing studies on building social network are mainly based on the single source data, instead of the multi-source data. In this paper, we use multiplex network (e.g. multi-relation network) to model multi-source data, then propose a node learning representation of multiplex network. First, we propose a method of extracting node influence of multiplex network. Next, taking account into the influence of node and the random walk in multiplex network, we propose a biased random walk method to learn the embedding of node in multiplex network. Finally, we compare existing state-of-the-art techniques on edge reconstruction accuracy and link prediction in several real-world networks from diverse domains. Experiments on real datasets validate the effectiveness of our network representation method, enrich the quantity of conserving multilayer network structure information, and make the description of the node embedding in multiplex network more accurate.",https://ieeexplore.ieee.org/document/8411960/,2018 IEEE Third International Conference on Data Science in Cyberspace (DSC),18-21 June 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RE.2019.00009,Requirements We Live By,IEEE,Conferences,"Enlightened requirements engineering (RE) researchers and practitioners generally accept that RE is as much about understanding the world as it is about understanding the software and systems that will be built to inhabit that world. As a result, the RE field has fostered a multi-disciplinary following of researchers and practitioners who are prepared to engage deeply in application domains, to apply a range of technical and socio-technical skills to understand those domains, and to accept that the outcome of an effective RE process may not deliver a software system at all. The RE community has also developed, deployed, and evaluated a wide range of contributions that reflect such enlightenment: conceptual models that reflect the relationships between the world and the machine, domain models and scenarios that reflect understandings of problem domains, and enterprise models that reflect the organisations and processes that build and deploy systems. All these in addition to the models that capture the all-important behaviour of systems and software. It seems to me however that the RE discipline is at a crossroads. The mechanics of the discipline appear to be established - much of the published research is now empirical - or technical, but only in so far as it responds to technological advances elsewhere, such as mobile and ubiquitous technologies represented by the Internet of Things, richer application domains such as Industrie 4.0 and Smart Cities, or more advanced computational techniques that are maturing, such AI, machine learning, and blockchains. As a community, we reassure ourselves that our discipline is safe and thriving, after all RE is a “forever problem”: all systems we wish to build will have requirements, now and forever. But this is to be complacent. RE has no protected status to study and deploy requirements. The formal models we elicit, design, and build are increasingly deployable by other disciplines, as are the values that we seek our modern, AI-driven systems to embody. A new and potentially radical re-framing of our discipline may be needed, and I will speculate what this may look like. It may require letting go of what we have considered to be the boundaries of our discipline, while embracing new but fluid boundaries. I have advocated and explored “software without boundaries” as one such framing that challenges the separation of `world and the machine', not because I don't accept the separation of the `what' and the `how', the `indicative' and the `optative', or the `problem' and the `solution', but because the world we live in no longer accepts these separations. Society, more often than not, does not think of systems, of technology, or indeed of software; it thinks of ways of working, ways of interacting, ways of living. Requirements, such as they are, are `requirements we live by' not requirements of systems in the world. At an extreme, if one believes the AI hype, `the world and the machine' will increasingly be replaced by the `world in the machine'. Where does the RE community stand on this, and what can this community do to contribute to the framing and solving of this new reality? My own work in recent years has evolved to reflect the above. I still revisit, with some pride, the `RE Roadmap' that Steve Easterbrook and I published in 2000 - many of the fundamental RE principles we presented still hold today. But I cringe at how we missed the changing nature of the world in which we operate: a world populated by autonomous and adaptive systems, populated by big data and associated analytics, and populated by stakeholders whose multiple perspectives reflect a multitude of ethical and social values, not all of which are wholesome, and many of which are actively subversive or malicious. My own research on security and privacy requirements only scratches the surface of this evolving reality. I invite the RE community to reflect on how it frames its own research in this context.",https://ieeexplore.ieee.org/document/8920530/,2019 IEEE 27th International Requirements Engineering Conference (RE),23-27 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBAIE52039.2021.9389893,Research and implementation of network information security management system based on face recognition,IEEE,Conferences,"In recent years, with the prosperity and development of social economy and the continuous progress of science and technology, people's identity recognition field has been paid more and more attention, and face recognition has higher security than traditional verification manual, which is a hot research direction of artificial intelligence. In this paper, face recognition is carried out in the order of face preprocessing, face detection and face recognition (training). Face preprocessing mainly includes image graying, image filtering, histogram equalization and other processing steps. Face detection adopts Ada Boost based face detection algorithm[1]. The main face recognition algorithms are studied: lbphface Face recognition algorithm based on LBP, this paper uses this algorithm for face recognition. The design and implementation of the security management system based on face recognition is completed.",https://ieeexplore.ieee.org/document/9389893/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DTPI52967.2021.9540104,Research and practice of lightweight digital twin speeding up the implementation of flexible manufacturing systems,IEEE,Conferences,"Parallel manufacturing in Industry 5.0 requires digital twin to digitize physical systems, building virtual models to open up channels connecting physical systems, information systems, and social systems, and transforming the physical models of the existing production environment to achieve two-way feedback of virtual and real is the current research direction. This paper proposes the modeling idea of lightweight digital twin, extracts core dimensions and performs digital virtual simulation, so as to quickly realize the complete process of two-way feedback, and realize a set of chess flexible parallel manufacturing production lines as a practice for the design of complete lightweight digital twin.",https://ieeexplore.ieee.org/document/9540104/,2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI),15 July-15 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIIS49377.2020.9194885,Research on Dimension Reduction Method of Public Opinion Short Text Representation Model Based on Combined Neural Network,IEEE,Conferences,"With the rapid development of the Internet and the popularization of social software such as Twitter and Weibo, online public opinion has an increasing influence on public opinion in the entire society. In order to effectively prevent and control vicious incidents, real-time monitoring of online public opinion is becoming increasingly important. important. According to the characteristics of short-sentence information in public opinion, this paper proposes an automatic clustering method based on combinatorial neural network to construct a short-sentence representation model of public opinion, and construct word clusters based on the semantic similarity of characteristic words. The test results show that: in the process of mass text analysis and public opinion discovery, this method can effectively reduce the accuracy of the short text public opinion construction representation model by reducing the dimension of the text representation model, while ensuring the real-time acquisition of public opinion while greatly improving Public opinion finds efficiency.",https://ieeexplore.ieee.org/document/9194885/,2020 IEEE International Conference on Artificial Intelligence and Information Systems (ICAIIS),20-22 March 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEIEC54567.2022.9835053,Research on Emergency Navigation Path Planning System for Plateau Regions,IEEE,Conferences,"The study of emergency navigation path planning methods in plateau regions has very important economic and social significance. In this paper, we proposed a system design scheme combining road network database and satellite remote sensing images with a flat plateau region as the research object. The proposed system performs image pre-processing operations on real-time remote sensing images based on historical remote sensing data, road network extraction and land classification using remote sensing semantic segmentation techniques, and rasterized maps are established in combination with the road network database, taking into account the different types of motion carriers and the influence of image noise for fast emergency navigation path planning. The proposed system architecture approach is a reference value for research in related fields.",https://ieeexplore.ieee.org/document/9835053/,2022 IEEE 12th International Conference on Electronics Information and Emergency Communication (ICEIEC),15-17 July 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITBS53129.2021.00178,Research on Feature Extraction and Tendency Analysis of Chinese Language Sentimental Expression in Network Context,IEEE,Conferences,"The current network language only considers the expression of its basic meaning, and lacks in-depth analysis of sentimental characteristics and tendencies. For this reason, this paper investigates the sentimental analysis methods of network language based on the Chinese text information of network social media platform. Through the training of the existing data sets, we complete the data cleaning and feature word extraction. Then, a multi-dimensional fine-grained sentiment classification algorithm is designed by using neural network to reduce the dimension of feature vector. Finally, the structured linguistic features are used to optimize the sentiment score step by step, and the text sentiment classification is implemented, and a tendency analysis model considering the polarity of sentiment is further established. The validity of the model is verified by the real data collected in the network. The results show that the method has a significant advantage in Chinese data sets, and the recognition rate is higher than that of similar sentiment analysis methods.",https://ieeexplore.ieee.org/document/9525484/,"2021 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS)",27-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIID51893.2021.9456477,Research on Privacy Protection Technology in Face Identity Authentication System Based on Edge Computing,IEEE,Conferences,"In today's society, the rapid development of the Internet makes People's Daily life become more intelligent and diversified. Today's society has entered a multifaceted era where everything is interconnected. Artificial intelligence technology is gradually replacing some traditional human services, such as intelligent robot customer service instead of traditional human customer service, intelligent face scanning security check in railway stations instead of traditional manual ticket checking, unmanned supermarket automatic checkout has liberated some social labor costs. All these changes are the result of the development of artificial intelligence technology in today's society. In recent years, unicorn startups focused on biometrics have sprung up all around us, such as BTU and its MEG VII (Face ++). Thanks to the development of Internet and artificial intelligence technology, in many application fields, the traditional access control and identity authentication technology based on password verification is gradually transforming to the scheme based on biometric identification verification. Secure identity authentication is very important to the application of Internet. Face recognition is the most popular technology among all biometric identification technologies. In the field of biometric identification technology, it has become the most widely used technology in the field of identity authentication because of its unique non-invasive, support for infrared and visible light, no need for user cooperation and many other advantages. In the field of education, examinee identification, pedestrian identification detection at the entrance of railway stations, face electronic payment, intelligent video surveillance system, intelligent attendance and access control system, intelligent unmanned supermarkets and customs clearance ports become the pioneer fields of face recognition applications. It can be seen that the era of “national face brushing” has arrived, and the application of face recognition technology will only be more and more widespread in the current era and in the future. However, due to the sensitivity of biometric data and the heterogeneity and openness of network environment, the privacy leakage of biometric data is difficult to avoid. At present, fog computing and edge computing have been paid more and more attention in many fields. In the case that cloud service providers are unable to provide sufficient security, edge computing shows its advantages. In this paper, mobile edge computing is introduced for the first time into the face privacy protection identity authentication system based on cloud server outsourcing computing. It can not only greatly reduce the interaction frequency between users and cloud server, improve the availability and fault tolerance of the system, but also contribute to the implementation of privacy protection scheme. A deep constitutional neural network for face feature extraction is trained using deep learning framework Cafe. Cosine similarity is used to complete face verification. A privacy protection scheme based on the secure nearest neighbor algorithm is proposed, which can not only protect the security of the face feature data at the edge computing node, but also allow the edge computing node to complete the face recognition operation against the encrypted face feature data. In addition, the encryption scheme does not require large computing resources, and the accuracy of face recognition in cipher text is exactly the same as that in explain. At present, most of the solutions either have high computational complexity or poor security performance. How to reduce the computational complexity and improve the real-time performance of the system while ensuring the high security of the private data has important research significance and value. Therefore, in the cloud server outsourcing computing environment, how to complete biometric identification on the premise of protecting the privacy of biological data has become a research hot spot.",https://ieeexplore.ieee.org/document/9456477/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE51474.2020.00084,Research on multi UAV target detection algorithm in the air based on improved CenterNet,IEEE,Conferences,"In recent years, with the rapid development of UAV technology, the following problems and hidden dangers are increasingly prominent: “unauthorized flight” incidents occur frequently, security risks are serious, and social security is threatened. In order to quickly find UAV targets in these events and take relevant measures, this paper proposes a fast UAV target detection algorithm based on improved CenterNet, which can extract the depth features of the collected images, and use Gaussian kernel function to generate keypoint feature map, and output multiple target location information and category information. By modifying the structure and parameters of feature extraction network, the size of the model is greatly reduced and the running speed of the model is accelerated. At the same time, the detection effect of small target is improved obviously after adding DIoU loss. We train and test the algorithm on our own UAV dataset, and the experimental results achieve high accuracy (48.9 AP) and real-time detection speed (143fps). The improved algorithm is easy to be integrated into the mobile terminal or embedded system, providing support for the next step of alarming, jamming and drive away actions.",https://ieeexplore.ieee.org/document/9403787/,2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),30 Oct.-1 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTC46691.2019.8939870,Residual Seq2Seq model for Building energy management,IEEE,Conferences,"According to the UN Department of Economic and Social Affairs (DESA), the global urbanization rate is expected to reach 68% in 30 years from 55% in 2018. As global urbanization progresses, the proportion of total energy consumption consumed in buildings is increasing, and efficient energy management in buildings is becoming increasingly important in terms of efficient use of global natural resources and air quality management. This paper presents an implementation detail of the energy consumption prediction deep learning model for efficient building energy management. The developed model is multilayer LSTM seq2seq model which predicts energy consumption for one day by using environmental data and energy consumption data measured in a real testbed. In a multi-zone building, one zone of data is used, which is characterized by the fact that data patterns over time are not neatly repeated. This paper presents deep learning depth and performance changes as adding layers of seq2seq model in building energy consumption forecasting. In addition, it presents performance comparison with other algorithms.",https://ieeexplore.ieee.org/document/8939870/,2019 International Conference on Information and Communication Technology Convergence (ICTC),16-18 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSAI.2017.8248529,Resource quality prediction based on machine learning algorithms,IEEE,Conferences,"Many resources today are shared freely through social network or cloud storage platforms, which are helpful for uses to acquire data or exchange information. Unfortunately, due to the unrestricted participations, some resources with advertisements or fraud are also uploaded, which force users to hit the ad websites or steal users' data. Therefore, the quality evaluation of one resource is needed for users to judge whether to utilize or install it. In this paper, we implement a system to evaluate the quality based on software install packages, which applies four algorithms to forecast the quality scores. We conduct an extensive experimental study on a real dataset and find that the prediction can be performed in less than one second (0.002s~0.04s) and with a high accuracy (82.84%~90.52%).",https://ieeexplore.ieee.org/document/8248529/,2017 4th International Conference on Systems and Informatics (ICSAI),11-13 Nov. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACII.2013.88,Reversal Learning Based on Somatic Markers,IEEE,Conferences,"One of the main aspects in the field of Artificial Intelligence is the creation of agents with the ability to learn like human beings do. Based on made experiences humans are able to adapt their behaviour in order to solve tasks. Another important aspect of human decision making is the ability to discard learned behaviour when the usual decisions, concerning a stimulus, lead to a bad outcome. For robots intended to be embedded in a social environment, the adaptability of behaviour is an important factor. Research of human decision behaviour shows, that emotions play a decisive role, even for learning and reversal learning. In this paper, improvements and further results of a previously presented framework for decision making based on an emotional memory are presented. The improvements include the reduction of the amount of previous knowledge that has to be implemented and an evaluation concerning reversal learning. For evaluation purposes, a typical reversal learning task, performed by real subjects, has been used. The results show that this framework allows the adaption of behaviour comparable to human subjects and offers decisive improvements, which lead to better results in reversal learning tasks without the need to directly declare a task as such one.",https://ieeexplore.ieee.org/document/6681479/,2013 Humaine Association Conference on Affective Computing and Intelligent Interaction,2-5 Sept. 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICICPI.2016.7859671,Review and study of internet of things: It's the future,IEEE,Conferences,"Internet of things represents a groundbreaking vision of technological, economic and social significance. This paper is designed to help technology enthusiasts navigate the dialogue surrounding the same, be well versed in IoT and understand its potential to change everything we know to be true today. In this new era of technology, Internet of Things (IoT) has the true potential to make computing ubiquitous - a concept introduced by Mark Weiser in early 1990s. Machine to machine, computer to objects, environment to computers, intelligent systems - “The internet of everything”, is where the potential seems to be endless. IoT can be seen as a universal global neural network of connected things in the cloud where smart machines interact and communicate with other machines, objects, infrastructure and the environment. As a result of which, exponential amount of data is generated and processed into actions that has the ability to command and control things making our everyday life much easier. This paper concludes with a discussion around social and commercial issues likely to surface when Internet of Things becomes a household reality.",https://ieeexplore.ieee.org/document/7859671/,2016 International Conference on Intelligent Control Power and Instrumentation (ICICPI),21-23 Oct. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA48506.2021.9560893,Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning,IEEE,Conferences,"Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/&#x223C;cdarpino/socialnavconstrained/",https://ieeexplore.ieee.org/document/9560893/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2017.8022736,Routing algorithm based on ant colony optimization for mobile social network,IEEE,Conferences,"Mobile social network (MSN) is a type of delay tolerant network explicitly considering social characteristics of the terminal nodes. The existing Ad Hoc routing protocols assume that there is at least one complete communication path between the source node and the target node. So they cannot be applied to MSN directly. The key to solve the problem of content distribution in mobile social network is how to transmit the data to the target node in the case of there is no complete communication path between the source node and the target node. As the routing algorithm based on ant colony optimization has great ability to adapt it, it is an effective method to deal with the dynamic topologies of MSN. Based on the social network characteristics of MSN, this paper proposes a new MSN routing algorithm ACOMSN based on ant colony optimization. The algorithm uses the method of processing the node information on the transmission path to get the information list between the node pairs, so as to select the appropriate relay node to provide effective information when forwarding data to other nodes. In addition, ACOMSN designs methodologies for pheromone updating and data forwarding. The simulation experiments on real data sets show that comparing with typical MSN routing algorithms, ACOMSN can effectively improve the critical performance of data transmission with considerable overhead in MSN.",https://ieeexplore.ieee.org/document/8022736/,"2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",26-28 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CLOUD.2009.80,Rule-Based Problem Classification in IT Service Management,IEEE,Conferences,"Problem management is a critical and expensive element for delivering IT service management and touches various levels of managed IT infrastructure. While problem management has been mostly reactive, recent work is studying how to leverage large problem ticket information from similar IT infrastructures to probatively predict the onset of problems. Because of the sheer size and complexity of problem tickets, supervised learning algorithms have been the method of choice for problem ticket classification, relying on labeled (or pre-classified) tickets from one managed infrastructure to automatically create signatures for similar infrastructures. However, where there are insufficient preclassified data, leveraging human expertise to develop classification rules can be more efficient. In this paper, we describe a rule-based crowdsourcing approach, where experts can author classification rules and a social networking-based platform (called xPad) is used to socialize and execute these rules by large practitioner communities. Using real data sets from several large IT delivery centers, we demonstrate that this approach balances between two key criteria: accuracy and cost effectiveness.",https://ieeexplore.ieee.org/document/5283873/,2009 IEEE International Conference on Cloud Computing,21-25 Sept. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UBMYK48245.2019.8965480,Rumor Detection in Social Media Using Machine Learning Methods,IEEE,Conferences,"Throughout history, people have always wondered whether a word or writing is real. Whether or not that word was true depends on the person who spoke it. While the word of a trusted person was respected, the word of an unreliable person was believed to be rumor. Today, with the development of social networks, the amount of information circulating on the internet has increased rapidly. However, the reliability of this data is disputable. It is an undeniable fact that there will be gossip in the environment with so many unconfirmed data. Thus, efficiently detection of rumor is an important and hot topic. In this study, the detection of rumor in online social media is modeled as a classification problem, and the success of supervised machine learning methods in real data is assessed. OneR (One Rule), Naive Bayes, ZeroR, JRip, Random Forest, Sequential Minimal Optimization, and Hoeffding Tree algorithms are applied on rumor detection problem and comprehensive evaluation is provided.",https://ieeexplore.ieee.org/document/8965480/,2019 1st International Informatics and Software Engineering Conference (UBMYK),6-7 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSESS.2018.8663917,Rumor Detection on Twitter with Hierarchical Attention Neural Networks,IEEE,Conferences,"Social media has become an integral part of peoples agenda life, however social media also plays a vital role in communication and information dissemination, making it an ideal platform for spreading rumors. Automatically debunking rumors at their stage of diffusion is known as early rumor detection. However, automatic rumor detection is technically very difficult and uncertain. In this work, we try to build a model to learn extracted features from tweets content by concentrating their posts and generate more meaningful representations to identify different type of rumors. This paper presents a deep hierarchical attention model on the basis of recurrent neural networks (RNN) for rumor representation learning and classification. Extensive experiments on real datasets which collected from social media web sites (mainly on twitter) demonstrate that the deep hierarchical attention based RNN model outperforms state-of-the-arts that rely on hand-crafted features.",https://ieeexplore.ieee.org/document/8663917/,2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS),23-25 Nov. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MASS.2019.00022,SHAD: Privacy-Friendly Shared Activity Detection and Data Sharing,IEEE,Conferences,"Nowadays, there is a growing demand for sharing multimedia data among participants in the same activity. With existing social applications, users need to conduct friending and data sharing operations manually, which is troublesome due to changing attendees and highly diverse data content of different activities. To tackle this issue, in this work we propose a novel system SHAD to achieve privacy-friendly shared activity detection and multimedia data auto-sharing based on users' historical multimodal data. Facing noisy, incomplete and asynchronous data, as well as inaccurate recognition results of machine learning models, we design an algorithm to aggregate multimodal data relevant to the same activity and propose an activity-semantic graph to comprehensively characterize each activity by fusing knowledge of multimodal data. Based on the activity-semantic graph, the privacy-preserving shared activity detection and data sharing method is designed, which protects both raw data and semantic information of data. We implemented our system and conducted comprehensive evaluations with real-life multimodal data (including photos and motion sensor data). The results show the efficacy of our system. We can achieve 94.9% precision and 91.5% recall for shared activity detection.",https://ieeexplore.ieee.org/document/9077362/,2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems (MASS),4-7 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICter53630.2021.9774824,SMART Garbage Bin Kit: Expandable and Intelligent Waste Management System using Deep Learning and IoT for Modern Organizations,IEEE,Conferences,"According to published statistics, Sri Lanka produces garbage around 7000MT per day, and every organization directly contributes this national amount depending on the waste management practices. 'Waste contamination' is a critical issue that affects waste management, and it should be addressed during the garbage collection process. This has led to environmental hazards resulting in health and other social issues. Hence, it is a responsibility of an organization to separate the garbage during the collection process using a suitable technique. In this paper, we are proposing a smart garbage bin kit that automates the separation of garbage collection, which minimizes human error using AI-based technologies. IoT-based devices connected to a smart garbage bin kit guide the user to the correct bin. At the same time, our proposed system can be easily expanded for new special waste categories as well. The other important issue of the current garbage management is improper time management of the garbage removal process in organizations. This happens due to the lack of real-time data on waste bins, and collection is based on the fixed time interval irrespective of the status and location of garbage bins. In the proposed system of SMART Garbage Bin Kit, the group of all interconnected garbage bins is monitored in real-time to identify the optimum collection path considering the location and the status of garbage bins using an optimized algorithm. Hence, the study presented in this paper integrates several intelligent approaches together with IoT based network to build a cutting-edge device, declared as SMART Garbage Bin kit. The prototype system has been built as a part of the research study to demonstrate its feasibility and sustainability.",https://ieeexplore.ieee.org/document/9774824/,2021 21st International Conference on Advances in ICT for Emerging Regions (ICter),2-3 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ANTS.2017.8384099,SMEAD: A secured mobile enabled assisting device for diabetics monitoring,IEEE,Conferences,"Wearable health devices, mobile apps and diagnostic tools revolutionize the medical field by introducing new assisting devices for patients in a way to create comfort, communication and augmented intelligence. Internet of Things involved in this transformation to provide an environment where a patient's vital parameters get transmitted by sensor devices via a gateway onto secure cloud-based platforms where it is stored, aggregated and analyzed. It also helps to store data for millions of patients and performs analysis in real time, ultimately promoting an evidence-based medicine system. Privacy and security are concerns in this environment. Based on the latest trends, this paper introduces a new healthcare paradigm named as SMEAD by developing an end-to-end secured system for assisting diabetic patients. It includes wearables to monitor different parameters thus observe and predict the diabetes status of the patient. The proposed system employs a MEDIBOX which is used to configure the dosage required and provides an alert to the users reminding them to take medication on time. In this case, the insulin dosage is maintained at suitable cooling conditions and is continuously monitored using the mentioned system. To keep all the data secure and to enable access to this data by the doctor and other trusted parties, a Blockchain-based disruptive technology is implemented which facilitates cryptographic security and formalized data access through smart contracts for medical communities. In case of an emergency like missing a dosage, abnormal blood sugar levels or any security lapse, an alert is sent to the caretakers via social networks like Twitter, Facebook or WhatsApp using mobile as a gateway which can continuously communicate the data over the internet that could save patients from fatal effects of the disease.",https://ieeexplore.ieee.org/document/8384099/,2017 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS),17-20 Dec. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MDM48529.2020.00041,STIMULATE: A System for Real-time Information Acquisition and Learning for Disaster Management,IEEE,Conferences,"Real-time information sharing and propagation using social media such as Twitter has proven itself as a potential resource to improve situational awareness in a timely manner for disaster management. Traditional disaster management systems work well for analyzing static and historical information. However, they cannot process dynamic streams of data that are being generated in real-time. This paper presents STIMULATE - a System for Real-time Information Acquisition and Learning for Disaster Management that can (1) fetch and process tweets in real-time, (2) classify those tweets into FEMA defined categories for rescue priorities using pre-trained deep learning models and generate useful insights, (3) find FEMA defined stranded people for rescue missions of varying priorities, and (4) provide an interactive web interface for rescue management given the available resources. The STIMULATE prototype is primarily built using the Python Flask framework for web interaction. Additionally, it is deployed in the cloud environment using Hadoop and MongoDB for scalable storage, and on-demand computing for processing extensive social media data. The deep learning models in the STIMULATE prototype use Python Keras and the TensorFlow library. We use Bi-directional Long Short-Term Memory (BLSTM) and Convolutional Neural Network (CNN) for developing the tweet classifier. Further, we use the Python PyWSGI WebSocket server for rescue scheduling operations. We present a deep learning system trained on hurricane Harvey and Irma datasets only. The tweet classifier is evaluated using 15 different disaster datasets. Finally, we present the results of multiple simulations using synthetic data with different sizes to measure the performance and effectiveness of the tweets processor and rescue scheduling algorithm.",https://ieeexplore.ieee.org/document/9162220/,2020 21st IEEE International Conference on Mobile Data Management (MDM),30 June-3 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPSW52791.2021.00138,ScaDL 2021 Invited Speaker-3: AI for Social Impact: Results from multiagent reasoning and learning in the real world,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. With the maturing of AI and multiagent systems research, we have a tremendous opportunity to direct these advances towards addressing complex societal problems. I focus on the problems of public health and conservation, and address one key cross-cutting challenge: how to effectively deploy our limited intervention resources in these problem domains. I will present results from work around the globe in using AI for HIV prevention, Maternal and Child care interventions, TB prevention and COVID modeling, as well as for wildlife conservation. Achieving social impact in these domains often requires methodological advances. To that end, I will highlight key research advances in multiagent reasoning and learning, in particular in, computational game theory, restless bandits and influence maximization in social networks. In pushing this research agenda, our ultimate goal is to facilitate local communities and non-profits to directly benefit from advances in AI tools and techniques.",https://ieeexplore.ieee.org/document/9460613/,2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),17-21 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMLC.2003.1264525,Scenario-based agent design,IEEE,Conferences,"Application designers, such as non-computer professionals, cannot directly describe interaction by agent communication languages (e.g., KQML and FIPA ACL) for designing proper applied agents. To bridge the gap between agents and their social usage, Q language - a scenario description language for describing interaction among agents and users is emerging. In order to explore Q language's capability in real agent environment, we applied it in the fields such as semantic information searching on the semantic web and agent-mediated negotiation in e-commerce.",https://ieeexplore.ieee.org/document/1264525/,Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693),5-5 Nov. 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCC51575.2020.9345086,Secure and Transparent Public-key Management System for Vehicular Social Networks,IEEE,Conferences,"Vehicular Social Networks (VSNs) are expected to become a reality soon, where commuters having common interests in the virtual community of vehicles, drivers, passengers can share information, both about road conditions and their surroundings. This will improve transportation efficiency and public safety. However, social networking exposes vehicles to different kinds of cyber-attacks. This concern can be addressed through an efficient and secure key management framework. This study presents a Secure and Transparent Public-key Management (ST-PKMS) based on blockchain and notary system, but it addresses security and privacy challenges specific to VSNs. ST-PKMS significantly enhances the efficiency and trustworthiness of mutual authentication. In ST-PKMS, each vehicle has multiple short-lived anonymous public-keys, which are recorded on the blockchain platform. However, public-keys get activated only when a notary system notarizes it, and clients accept only notarized public-keys during mutual authentication. Compromised vehicles can be effectively removed from the VSNs by blocking notarization of their public-keys; thus, the need to distribute Certificate Revocation List (CRL) is eliminated in the proposed scheme. ST-PKMS ensures transparency, security, privacy, and availability, even in the face of an active adversary. The simulation and evaluation results show that the ST-PKMS meets real-time performance requirements, and it is cost-effective in terms of scalability, delay, and communication overhead.",https://ieeexplore.ieee.org/document/9345086/,2020 IEEE 6th International Conference on Computer and Communications (ICCC),11-14 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IWISA.2009.5073107,Self-Organization Behaviors of Intelligent Antagonism Target Team of Air Combat Based on Pi-Calculus,IEEE,Conferences,"In order to improve the reality and the reliability of the current air combat simulation and the airborne weapon system evaluation in uncertain, hostile, complex and dynamic air combat environment, we propose an intelligent antagonism target team of air combat based on MAS (multi-agent system) under presented research results. To improve the social mental attribution of the target team, we develop a BGOP (belief, goal, obligation, plan) model under the basis of the traditional BDI(belief, desire and intention) model, which represents the mental states of each target agent, and which has the mental attributions related to the combat utilities which affecting the command control decision of the target agent firstly, and then an organization structure of the command control system of target team, is presented, and the self-organization process of the target team combat behaviors, such as task-assignment, task-maintain, task-change, and the task-coordination etc. are described by pi-calculus.",https://ieeexplore.ieee.org/document/5073107/,2009 International Workshop on Intelligent Systems and Applications,23-24 May 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2012.66,Semi-Supervised Policy Recommendation for Online Social Networks,IEEE,Conferences,"Fine grain policy settings in social network sites is becoming a very important requirement for managing user's privacy. Incorrect privacy policy settings can easily lead to leaks in private and personal information. At the same time, being too restrictive would reduce the benefits of online social networks. This is further complicated with the growing adoption of social networks and with the rapid growth in information uploading and sharing. The problem of facilitating policy settings has attracted numerous access control, and human computer interaction researchers. The solutions proposed range from usable interfaces for policy settings to automated policy settings. We propose a fine grained policy recommendation system that is based on an iterative semi-supervised learning approach that uses the social graph propagation properties. Active learning and social graph properties were used to detect the most informative instances to be labeled as training sets. We implemented and tested our approach using real Facebook dataset. We compared our proposed approach to supervised learning and random walk approaches. Our proposed approaches provided high accuracy and precision when compared to the other approaches.",https://ieeexplore.ieee.org/document/6425738/,2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,26-29 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigMM.2015.26,Semi-supervised Multimodal Clustering Algorithm Integrating Label Signals for Social Event Detection,IEEE,Conferences,"Photo-sharing social media sites provide new ways for users to share their experiences and interests on the Web, which aggregate large amounts of multimedia resources associated with a wide variety of real-world events in different types and scales. In this work, we aim to tackle social event detection from these large amounts of image collections by devising a semi-supervised multimodal clustering algorithm, denoted by SSMC, which exploits label signals to guide the fusion of the multimodal features. Particularly, SSMC takes advantage of the distribution over the similarities on a small amount of labeled data to represent the images, fusing multiple heterogeneous features seamlessly. As a result, SSMC has low computational complexity in processing multimodal features for both initial and updating stages. Experiments are conducted on the Mediaeval social event detection challenge, and the results show that our approach achieves better performance compared with the baseline algorithms.",https://ieeexplore.ieee.org/document/7153853/,2015 IEEE International Conference on Multimedia Big Data,20-22 April 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CEEICT.2016.7873080,Sentiment analysis on facebook group using lexicon based approach,IEEE,Conferences,"Internet is one of the primary sources of Big Data. Rise of the social networking platforms are creating enormous amount of data in every second where human emotions are constantly expressed in real-time. The sentiment behind each post, comments, likes can be found using opinion mining. It is possible to determine business values from these objects and events if sentiment analysis is done on the huge amount of data. Here, we have chosen FOODBANK which is a very popular Facebook group in Bangladesh; to analyze sentiment of the data to find out their market values.",https://ieeexplore.ieee.org/document/7873080/,2016 3rd International Conference on Electrical Engineering and Information Communication Technology (ICEEICT),22-24 Sept. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2017.8022756,Share-housing allocation information service system based on Pareto optimality,IEEE,Conferences,"Compared to living alone, sharing housing with others is usually much cheaper. Meanwhile, share-housing life would exert mammoth impact on people's social activity and self development by help them save house rental cost and improve their life quality. This paper proposes an allocation information system for share-housing management, which takes into account preference on roommates' living habits, working performance and geography distribution. Moreover, Pareto optimality is utilized to facilitate the effect of share-housing allocation. Results of case study show that the three factors of living habits, working performance as well as geography distribution should be synthetically applied as a decision support for share-housing.",https://ieeexplore.ieee.org/document/8022756/,"2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",26-28 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC51774.2021.00240,Shared-latent Variable Network Alignment,IEEE,Conferences,"The increasing popularity and diversity of social media sites, has encouraged many people to participate in different online social networks to enjoy a variety of services. Linking the same users across different social networks, also known as social network alignment, is a critical task of great research challenges. Many existing works usually focus on finding a projection function from one subspace to another for network alignment, however, the projection functions proposed in their papers are independent and updated individually, which could not effectively exploit the non-parallel data, and yield inferior alignment performance. In this paper, we propose a Shared-latent Variable Network Alignment (SVNA) architecture to effectively exploit the non-parallel data for network alignment, and jointly train projection functions and decoders in a unified framework with the shared latent variable z. Specifically, SVNA first employs the graph convolutional networks to preserve the structural information of the network. By introducing the shared latent variable z, SVNA simultaneously integrates two projection functions and two decoders for jointly training. Both projection functions and decoders share the same latent space, therefore both projection directions can learn from the non-parallel data more effectively. Thereafter, SVNA utilizes the Generative Adversarial Networks (GANs) framework to further train the projection functions, and adopts a probability-based semi-supervised method to achieve the network alignment. Experiments on three real-world datasets show that SVNA generally outperforms the state-of-the-art methods in network alignment task.",https://ieeexplore.ieee.org/document/9529755/,"2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",12-16 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACII.2009.5349428,Simulation of the dynamics of virtual characters' emotions and social relations,IEEE,Conferences,"One of the main challenges is to give life to believable virtual characters. Research shows that emotions and social relations, closely related, play a key role in determining the behavior of individuals. In order to improve the believ-ability of virtual characters' behavior, we propose in this article a method to compute virtual characters emotions based on attitudes and a model of their influence on the dynamics of social relations. Based on this work, a tool aiming at the simulation of the evolution of emotions and social relations of virtual characters have been implemented.",https://ieeexplore.ieee.org/document/5349428/,2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops,10-12 Sept. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EEBDA53927.2022.9744906,Smart Guide Trolley Mango: Smart Blind Guide Device Based on Raspberry Pi,IEEE,Conferences,"Nowadays, life support equipment for the visually impaired is not perfect, and the current blind guide equipment cannot meet the needs of the blind in the face of emergencies. Therefore, this paper proposes an intelligent traction guidance trolley &#x201C;Mango&#x201D;, With good portability and accurate positioning, it is more suitable for the needs of blind people than traditional guidance tools. Mode 1 is the traction and obstacle avoidance mode. This mode firstly plays the current temperature, humidity, location and weather informa2tion to the blind. If the human body infrared sensor detects that the blind person is following, the voice will then broadcast &#x201C;Blind person is following&#x201D; and activa.go automatically advances and executes the tracing algorithm to guide blind along the blind path. Meanwhile, the best way to avoid obstacles is selected according to the ultrasonic obstacle avoidance algorithm, and information about the identified obstacles ahead is broadcast by voice to guide the blind person around the blind path or other obstacles in the walking path. Mode 2 is the remote monitoring mode. This means that by observing the view of the real-time camera, the family or friends of the blind can remotely control the trolley to find them or guide them with the trolley movements by opening the designated website on any computer or mobile phone and entering commands to control the movement of the Mango. In summary, the smart trolley Mango in this paper is a smart guided trolley that can help the blind to travel safely, and provides a new social direction for improving the quality of life of the visually impaired.",https://ieeexplore.ieee.org/document/9744906/,"2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)",25-27 Feb. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2018.8508382,Social Bots for Online Public Health Interventions,IEEE,Conferences,"According to the Center for Disease Control and Prevention, hundreds of thousands initiate smoking each year, and millions live with smoking-related diseases in the United States. Many tobacco users discuss their opinions, habits and preferences on social media. This work conceptualizes a framework for targeted health interventions to inform tobacco users about the consequences of tobacco use. We designed a Twitter bot named Notobot (short for No-Tobacco Bot) that leverages machine learning to identify users posting pro-tobacco tweets and select individualized interventions to curb their tobacco use. We searched the Twitter feed for tobacco-related keywords and phrases, and trained a convolutional neural network using over 4,000 tweets manually labeled as either pro-tobacco or not pro-tobacco. This model achieved a 90% accuracy rate on the training set and 74% on test data. Users posting protobacco tweets were matched with former smokers with similar interests who posted anti-tobacco tweets. Algorithmic matching, leveraging the power of peer influence, allows for the systematic delivery of personalized interventions based on real anti-tobacco tweets from former smokers. Experimental evaluation suggested that our system would perform well if deployed.",https://ieeexplore.ieee.org/document/8508382/,2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),28-31 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIVR52153.2021.00034,Social Crowd Simulation: The Challenge of Fragmentation,IEEE,Conferences,"Crowd simulation is the process of simulating the movement and behavior of a large number of people. This field is continuously being improved by incorporating different theories of how humans move and interact with their surroundings, steadily increasing the realism of the simulation. Furthermore, new techniques for calibrating simulation parameters, and evaluating the accuracy of simulation output, keep being proposed. This paper presents a brief overview of these foundations and argues that a fragmentation of the field into multiple incompatible solutions may impede progress towards comprehensive social behavior models. It finally argues that abstractions of human intent and behavior, proposed within the Embodied Conversational Agents community, may suggest a useful path towards bringing social crowds to new levels of realism.",https://ieeexplore.ieee.org/document/9644355/,2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),15-17 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/APCCAS51387.2021.9687720,Social Distancing Surveillance System via Inverse Perspective Mapping and Fixed-point Quantization,IEEE,Conferences,"During the Coronavirus Disease 2019 (COVID-19) pandemic, many countries have introduced the social distancing policy in public areas to stop the spread of disease by maintaining a physical distance between people. This paper proposes an Artificial Intelligence (AI)-powered social distancing surveillance system that can detect pedestrians through video surveillance and monitor the social distance between them via Inverse Perspective Mapping (IPM) in real-time. The proposed system was deployed on the devices located at the network edge such as IoT devices and mobile devices to enable real-time response with low data transmission latency. To bypass the restriction on the computational and memory capacity for the edge devices, the proposed system was optimized through fixed-point quantization. From the evaluation results, the optimized models are almost 4 times smaller as compared to the original models. The best trade-off between speed and accuracy can be achieved with a 27.1&#x0025; improvement in speed and 2&#x0025; degradation in accuracy.",https://ieeexplore.ieee.org/document/9687720/,2021 IEEE Asia Pacific Conference on Circuit and Systems (APCCAS),22-26 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WISA.2015.48,Social Emotion Analysis System for Online News,IEEE,Conferences,"Social emotion analysis of online users has become an important task for mining public opinions, which aims at detecting the readers' emotions evoked by online news articles. In this paper, we focus on building a social emotion analysis system (SEAS) for online news. The system has implemented a text data crawler for mainstream online news websites, the modules of document preprocessing, document representation, and also integrates successful emotion analysis methods and provides the corresponding performance evaluation. SEAS will automatically analyze the emotions towards certain news articles and output the predicted emotions and probabilities of being classified into these emotion categories. The experiments on the real dataset from online news service demonstrate the high practicability and reliability of SEAS.",https://ieeexplore.ieee.org/document/7396605/,2015 12th Web Information System and Application Conference (WISA),11-13 Sept. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/icABCD49160.2020.9183860,Social Event Invitation and Recommendation for Event based Social Networks,IEEE,Conferences,Event based social networks enable users to make real connections with both the real and virtual worlds. This research aims at providing a way to increase user satisfaction at the events they attend from the event based social network. Two approaches are explained and used to determine the user's interests from the events they have attended and also through the sentiment analysis of the reviews they have given for these events. A profile specific to each user is developed to support event recommendations to users in the system based on a matching profile and a set of at least K friends on the social network. The paper uses content-based filtering by using the events details to make recommendations and collaborative filtering to find users who have similar interests. Lastly the sentiment of event reviews is determined to gain an understanding about how users feel about the events they attended. This sentiment data is integrated into the recommendation of events. The paper also discusses the results achieved and the limitations of the current state of the algorithm.,https://ieeexplore.ieee.org/document/9183860/,"2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)",6-7 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDM.2008.72,Fast Counting of Triangles in Large Real Networks without Counting: Algorithms and Laws,IEEE,Conferences,"How can we quickly find the number of triangles in a large graph, without actually counting them? Triangles are important for real world social networks, lying at the heart of the clustering coefficient and of the transitivity ratio. However, straight-forward and even approximate counting algorithms can be slow, trying to execute or approximate the equivalent of a 3-way database join. In this paper, we provide two algorithms, the eigentriangle for counting the total number of triangles in a graph, and the eigentrianglelocal algorithm that gives the count of triangles that contain a desired node. Additional contributions include the following: (a) We show that both algorithms achieve excellent accuracy, with up to sime 1000x faster execution time, on several, real graphs and (b) we discover two new power laws (degree-triangle and triangleparticipation laws) with surprising properties.",https://ieeexplore.ieee.org/document/4781156/,2008 Eighth IEEE International Conference on Data Mining,15-19 Dec. 2008,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICAI.2019.8701334,Finding the Real News in News Streams,IEEE,Conferences,"The current trend of the modern highly mobile society is in the receiving information of any kind by people from one handheld device. This way is simple, convenient, cheap, and practical. The users tend to have only one application on their devices to be universal for any purposes. The social networks have advantages over traditional mass-media instruments such as TV, radio, newspapers, and magazines. This advantage is in the speed of information spreading. Unfortunately, not all of published on-line articles are factual or true. Finding the real news in the news streams is not easy for ordinary users. Even state news agencies do not publish the real news in many cases. In this paper, we discuss different approaches to get the real news from news streams. Among them are the move from the social media to a trusted state agency, the move from one stat agency to several ones to get information on the breaking news from state agencies of different countries. This strategy is the most realistic for the serious users. We introduce the methods to support this strategy and automatically retrieve publications from the trusted sources specified by the user in order to simplify his/her work to obtain the information helping to get and understand the real news better.",https://ieeexplore.ieee.org/document/8701334/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMART52563.2021.9676205,Fine Grainded Sentiment Analysis on COVID-19 Vaccine,IEEE,Conferences,"The most talked about topic of interest in the medical realm as of today, is the debate on the impact that COVID-19 vaccine has on individuals, and their response in encountering the virus. While there are quite a few vaccine variants that have been developed, there has always been a lingering ambiguity in declaring that an individual can be completely immune to the virus. There have been many studies whilom this cognition of analysing the sentiment perception of vaccines, however the data utilization from various sources and the apropos implementation using the language processing methodologies have lagged a great deal. This paper pivots on the data drawn from social media platforms, and optimizes the sentiments using the Natural Language processing Toolkit (NLTK). The process of word embedding, with TFIDF vectorizer commingled with data unsheathing through fine-grained sentiment analysis and machine learning algorithms such as Linear SVC, SVM and Naïve bayes on the covid19 dataset have aided in stratifying the public tweet sentiments based on their polarity, precision, recall, f1-score value and support. The simulations have been implemented using the lexicon, rubric-based analytical tool VADER (Valence Aware Dictionary and sentiment Reasoner) incorporated in Python specifically for optimized extraction of sentiments from data.",https://ieeexplore.ieee.org/document/9676205/,2021 10th International Conference on System Modeling & Advancement in Research Trends (SMART),10-11 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCNC49033.2022.9700613,First Experimental Results on Real-Time Cleaning Activity Monitoring System,IEEE,Conferences,"The COVID-19 pandemic has presented social challenges to establish the new normal lifestyle in our daily lives. The goal of this paper is to enable easy and low-cost monitoring of cleaning activity to keep a clean environment for preventing infection. Although human activity recognition has been a hot research topic in pervasive computing, existing schemes have not been optimized for monitoring cleaning activities. To address this issue, this paper provides an initial concept and preliminary experimental results of cleaning activity recognition using accelerometer data and RFID tags. In the proposed scheme, machine learning technologies and short range wireless communication are employed for recognizing the time and place of wiping as an example of cleaning activities, because it is an important activity for shared places to avoid infection. This paper reports the evaluation results on the recognition accuracy using the proof-of-concept (PoC) implementation to clarify the required sampling rate and time-window size for further experiments. Also, a real-time feedback system is implemented to provide the monitoring results for users. The proposed scheme contributes for efficient monitoring of cleaning activities for creating the new normal era.",https://ieeexplore.ieee.org/document/9700613/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMARTCOMP50058.2020.00080,Flood Detection Framework Fusing The Physical Sensing & Social Sensing,IEEE,Conferences,"We investigate the practical challenge of localized flood detection in real smart city environment using the fusion of physical sensor and social sensing models to depict a reliable and accurate flood monitoring and detection framework. Our proposed framework efficiently utilize the physical and social sensing models to provide the flood-related updates to the city officials. We deployed our flood monitoring system in Ellicott City, Maryland, USA and connect it to the social sensing module to perform the flood-related sensor and social data integration and analysis. Our ground-based sensor network model record and performs the predictive data analytic by forecasting the rise in water level (RMSE=0.2) that demonstrates the severity of upcoming flash floods whereas, our social sensing model helps collect and track the flood-related feeds from Twitter. We employ a pre-trained model and inductive transfer learning based approach to classify the flood-related tweets with 90% accuracy in the use of unseen target flood events. Finally our flood detection framework categorizes the flood relevant localized contextual details into more meaningful classes in order to help the emergency services and local authorities for effective decision making.",https://ieeexplore.ieee.org/document/9239657/,2020 IEEE International Conference on Smart Computing (SMARTCOMP),14-17 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PerComWorkshops51409.2021.9430985,Flood Detection using Semantic Segmentation and Multimodal Data Fusion,IEEE,Conferences,"Real-time flood detection and notifying the citizens about its risk is of utmost importance. This work discusses the real-time deployment of one such notification system called Flood-Bot. FloodBot is a vision-powered flood detection and notification prototype deployed in a flash flood-prone Ellicott City, Maryland. We discuss the real-time deployment of FloodBot and our approach in detecting the flood event using semantic segmentation and multimodal data fusion. We implement the state-of-the-art semantic segmentation model U-Net and its modified version to track landmass with an accuracy of above 80%. We augment the parsed scene data with actual flood level sensor readings and ambient weather data for better scene representation. We validate the deep learning model&#x0027;s outcome using the flood sensor before posting risk message into social media. We then articulate the learning and challenges around our deployment from June &#x2013; November 2020.",https://ieeexplore.ieee.org/document/9430985/,2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),22-26 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/R10-HTC.2018.8629835,Foody - Smart Restaurant Management and Ordering System,IEEE,Conferences,"Customers play a vital role in the contemporary food industry when determining the quality of the restaurant and its food. Restaurants give considerable attention to customers’ feedback about their service, since the reputation of the business depends on it. Key factors of evaluating customer satisfaction are, being able to deliver the services effectively to lessen the time of consumption, as well as maintaining a high quality of service. In most cases of selecting a prominent restaurant, customers focus on their choice of favorite food in addition to available seating and space options. Long waiting times and serving the wrong order is a common mistake that happens in every restaurant that eventually leads to customer dissatisfaction. Objectives of this online application “Foody” is to address these deficiencies and provide efficient and accurate services to the customer, by providing unique menus to each customer considering their taste. This concept is implemented as a mobile application using latest IT concepts such as Business Intelligence, Data Mining, Predictive Analysis and Artificial Intelligence. This includes graphics and 3D modeling that provide existent physical information related to food such as colors, sizes and further user can view the ingredients of the meal as well as the available tables. In addition, the app shows the real-time map to the restaurant. Current table reservation status is indicated by the color change of the table. Unique food recommendation and it’s order for each customer is generated by analyzing their social media information and the system notifies the customer the wait time by calculating it. Preparation of food and allocation is done subjectively. The expected outcome of the research is to develop a fully automated restaurant management system with the mentioned features as well as to avoid confusions between orders, provide better view of food and allow the customer to choose the menu according to their taste in a minimum time.",https://ieeexplore.ieee.org/document/8629835/,2018 IEEE Region 10 Humanitarian Technology Conference (R10-HTC),6-8 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UIC-ATC.2017.8397484,Forecasting car rental demand based temporal and spatial travel patterns,IEEE,Conferences,"Recent years, shared mobility services have gained momentum across the world. Meanwhile, rental car industry has seen great developments in China and has reached a scale of economy. Knowing the rental behavior pattern and forecasting the demand become more important for rental businesses. To this end, in this paper, we aim to analyze the rental mobility pattern by examining multiple factors in a holistic manner. A special goal is to predict the demand of a given region. Specifically, we first analyze regular mobility based on real trips of rental cars. Then, we extract key features from multiple types of rental-related data, such as rental behavior profiles and geo-social information of regions. Next, based on these features, we develop a multi-task learning based regression approach for predicting rental cars' demand. This approach can effectively learn not only fundamental features but also relationships between regions by considering multiple factors. Finally, we conduct extensive experiments on real-world rental trip data collected in Beijing. The experimental results validate the effectiveness of the proposed approach for forecasting rental demand in the real world.",https://ieeexplore.ieee.org/document/8397484/,"2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",4-8 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEngTechnol.2017.8308166,Forecasting of Twitter hashtag temporal dynamics using locally weighted projection regression,IEEE,Conferences,"Popularity of social networks opens great opportunities for market such as advertisement. Using hashtags increasingly used in twits helps us to realize popular topics on the internet. Since most of new hashtags become popular and then fade away quickly, there is a limited time to predict the trend. Therefore, this paper proposes a fast incremental method to forecast the rate of the used hashtags in hour like time series. Two main parts for forecasting system are applied Preprocessing and Supervised Learning. Normalization is one of most popular preprocessing of dataset also proposed to have larger dataset. Moreover, the efficiency of the system under changing number of input (number of past hours from hashtag history) and output (number of next hours which is going to be predicted) are evaluated. Locally Weighted Projection Regression as one of the most powerful machine learning methods with no metaparameter are applied in this paper as real-time learning method. The performance of the system is verified by implementation of “Volume Time Series of Memetracker Phrases and Twitter Hashtags”. The results show that the errors of forecasting system are good enough to understand the trend of the hashtag.",https://ieeexplore.ieee.org/document/8308166/,2017 International Conference on Engineering and Technology (ICET),21-23 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICONSTEM.2017.8261274,Forecasting stock price using soft computing techniques,IEEE,Conferences,"Forecasting stock price is a important challenging task in the real world because more and more money is involved and they are affected by many social, economic, political and psychological factors. Numerous machine learning procedures have been used to fore see developments in stock cost. Machine learning classifiers include expanding the past encounters into the future actives. The proposed framework presents another hereditary calculation for forecast of monetary execution with information sets from a known source. The objective is to deliver a GA-based procedure for expectation of securities exchange execution alongside an acquainted principle classifier from an information set. We developed a genetic fuzzy based model with the ability of rule based extraction to predict next day stock price. We evaluate capacity of the proposed approach by applying it to the banking sector stocks and compare the outcome with the previous models.",https://ieeexplore.ieee.org/document/8261274/,2017 Third International Conference on Science Technology Engineering & Management (ICONSTEM),23-24 March 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SII.2011.6147520,Forming an artificial pheromone potential field using mobile robot and RFID tags,IEEE,Conferences,"In the biological world, social insects such as ants and bees use a volatile substance called pheromone for their foraging or homing tasks. This study deals with how to utilize the concept of the chemical pheromone as an artificial potential field for robotic purposes. This paper first models a pheromone-based potential field, which is constructed through the interaction between mobile robot and RFID tags. The emphasis in the modeling of the system is on the possibility of the practical implementable ideas. The stability analysis of the pheromone potential field is carried out with the aim of implementing the model on a real robotic system. The comprehensive analysis on stability provides the criteria for how the parameters are to be set for the proper potential field, and has also led to a new filter design scheme called pheromone filter. The designed filter satisfies both the stability and accuracy of the field, and facilitates a more straightforward and practical implementation for building and shaping the potential field. The effectiveness of the proposed algorithm is validated through both computer simulation and real experiment.",https://ieeexplore.ieee.org/document/6147520/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PacificVis.2018.00029,FraudVis: Understanding Unsupervised Fraud Detection Algorithms,IEEE,Conferences,"Discovering fraud user behaviors is vital to keeping online websites healthy. Fraudsters usually exhibit grouping behaviors, and researchers have effectively leveraged this behavior to design unsupervised algorithms to detect fraud user groups. In this work, we propose a visualization system, FraudVis, to visually analyze the unsupervised fraud detection algorithms from temporal, intra-group correlation, inter-group correlation, feature selection, and the individual user perspectives. FraudVis helps domain experts better understand the algorithm output and the detected fraud behaviors. Meanwhile, FraudVis also helps algorithm experts to fine-tune the algorithm design through the visual comparison. By using the visualization system, we solve two real-world cases of fraud detection, one for a social video website and another for an e-commerce website. The results on both cases demonstrate the effectiveness of FraudVis in understanding unsupervised fraud detection algorithms.",https://ieeexplore.ieee.org/document/8365989/,2018 IEEE Pacific Visualization Symposium (PacificVis),10-13 April 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCECE.2019.8861892,From natural language to graph queries,IEEE,Conferences,"Automatic code generation can drastically improve software (SW) engineering and SW development projects. In the last decade we have been conducting research which has been advancing the field of code generators for small and mid-size Web-based DBMS systems [4], [5], [7]. We developed a number of tool prototypes for automatic source code debugging by the source-to-source code transformation for real C and C++ applications [8]. Additionally we investigated Natural Language Processing (NLP) for software code generation and application of it to Graph databases. Graph databases are becoming more and more popular for their applications in Artificial Intelligence (AI) systems, social analytics and many other fields. Query languages like Cypher allow users to search them without direct programming. But even queries of modest complexity like “relatives in a family & friends graph” require some skill to write. In this paper we describe the use of natural language as a more intuitive interface for untrained users and demonstrate 3 use-cases, where translation of typical English phrases to OpenCypher and/or specialized graph engines like Huawei EYWA.",https://ieeexplore.ieee.org/document/8861892/,2019 IEEE Canadian Conference of Electrical and Computer Engineering (CCECE),5-8 May 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ROMAN.2017.8172498,Functional imitation task in the context of robot-assisted Autism Spectrum Disorder diagnostics: Preliminary investigations,IEEE,Conferences,"This paper presents a functional imitation task aimed at facilitating Autism Spectrum Disorder (ASD) diagnostics in children. Imitation plays a key role in the development of social skills at a young age, and studies have shown that the ability to imitate is impaired in children with ASD. Therefore, we expect imitation-based tasks to have diagnostic value. In this paper, we introduce two novel elements of human-robot interaction in the context of autism diagnostics. Instead of pure motoric imitation, we propose imitation tasks involving real objects in the environment. The introduction of physical objects strongly emphasizes joint attention skills, another area that is typically impaired in children with ASD. Furthermore, we present simple object detection, manipulation, tracking and gesture recognition algorithms, suitable for real-time, onboard execution on the small-scale humanoid robot NAO. The proposed system paves the way for fully autonomous execution of diagnostic tasks, which would simplify the deployment of robotic assistants in clinical settings. The source code for all described functionalities has been made publicly available as open-source software. We present a preliminary evaluation of the proposed system with a control group of typically developing preschool children and a group of seven children diagnosed with ASD.",https://ieeexplore.ieee.org/document/8172498/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICISS49785.2020.9315885,Generalized method to validate social distancing using median angle proximity methodology,IEEE,Conferences,"Social distancing in industries as well as all public places due to the breakdown of pandemic of COVID-19 is currently of global interest. An advanced global solution for social distancing monitoring among the group of people in real time using computer vision and deep learning is proposed. A state of art method, Median angle proximity method is proposed on the coordinates obtained from the YOLOv3 (You only look once) algorithm to determine the predefined threshold resulting in the social distancing violating bounding boxes. The violating bounding boxes are then saved as single images using deep sort method. All the parts of the work are done using opensource programming language. The work has met all the requirements planned and is considered to be ready for deployment in real time with an average accuracy of 85%",https://ieeexplore.ieee.org/document/9315885/,2020 3rd International Conference on Intelligent Sustainable Systems (ICISS),3-5 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC.2019.10256,Generating Real Time Cyber Situational Awareness Information Through Social Media Data Mining,IEEE,Conferences,"With the rise of the internet many new data sources have emerged that can be used to help us gain insights into the cyber threat landscape and can allow us to better prepare for cyber attacks before they happen. With this in mind, we present an end to end real time cyber situational awareness system which aims to efficiently retrieve security relevant information from the social networking site Twitter.com. This system classifies and aggregates the data retrieved and provides real time cyber situational awareness information based on sentiment analysis and data analytics techniques. This research will assist security analysts to evaluate the level of cyber risk in their organization and proactively take actions to plan and prepare for potential attacks before they happen as well as contribute to the field through a cybersecurity tweet dataset.",https://ieeexplore.ieee.org/document/8753997/,2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC),15-19 Jul 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CGames.2014.6934140,Generating dynamic narratives with real time interactions utilizing mobile technology,IEEE,Conferences,"The popularity of smartphones and other mobile technologies provides unique and exciting opportunities for game developers to create interesting game experiences and simultaneously study how players react and interact to these new environments. By studying and enhancing these new interactive environments and utilizing these technologies, we can break free of traditional game experiences and create newer and more exciting games with the flexibility of mobile devices. This study explores how we expand our idea of what a traditional game should be and poses a newer, fresher look on mobile game play and social connectivity. We have added to the notion of playing a game without actively engaging in it from the foundation of previous research. We have done this in order to build players' unique stories that will allow players to make more meaningful choices throughout their gameplay experience. By offering the player real time choices and active engagement in a mobile game that currently offers none, we expect to increase the levels of enjoyment and usefulness, from both educational and recreational viewpoints.",https://ieeexplore.ieee.org/document/6934140/,"2014 Computer Games: AI, Animation, Mobile, Multimedia, Educational and Serious Games (CGAMES)",28-30 July 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
,Graphical methods for real-time fusion and estimation with soft message data,IEEE,Conferences,"Fusion of observational data acquired by human observers and couched in linguistic form is a modern-day challenge for the fusion community. This paper describes a basic research effort examining various strategies for associating and exploiting such data for intelligence analysis purposes. An overall approach is described that involves Latent Semantic Analysis, Inexact Graph Matching, formal ontology development, and Social Network Analyses. Not all the methods have yet been employed but the exploitation of the developed ontology and graphical techniques have been implemented in a working prototype and preliminary results have shown promise. Planned future research will complete the implementation of the methods described herein and add yet further enhancements.",https://ieeexplore.ieee.org/document/4632405/,2008 11th International Conference on Information Fusion,30 June-3 July 2008,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDE48307.2020.00018,Group Recommendation with Latent Voting Mechanism,IEEE,Conferences,"Group Recommendation (GR) is the task of suggesting relevant items/events for a group of users in online systems, whose major challenge is to aggregate the preferences of group members to infer the decision of a group. Prior group recommendation methods applied predefined static strategies for preference aggregation. However, these static strategies are insufficient to model the complicated decision making process of a group, especially for occasional groups which are formed adhoc. Compared to conventional individual recommendation task, GR is rather dynamic and each group member may contribute differently to the final group decision. Recent works argue that group members should have non-uniform weights in forming the decision of a group, and try to utilize a standard attention mechanism to aggregate the preferences of group members, but they do not model the interaction behavior among group members, and the decision making process is largely unexplored.In this work, we study GR in a more general scenario, that is Occasional Group Recommendation (OGR), and focus on solving the preference aggregation problem and the data sparsity issue of group-item interactions. Instead of exploring new heuristic or vanilla attention-based mechanism, we propose a new social self-attention based aggregation strategy by directly modeling the interactions among group members, namely Group Self-Attention (GroupSA). In GroupSA, we treat the group decision making process as multiple voting processes, and develop a stacked social self-attention network to simulate how a group consensus is reached. To overcome the data sparsity issue, we resort to the relatively abundant user-item and user-user interaction data, and enhance the representation of users by two types of aggregation methods. In the training process, we further propose a joint training method to learn the user/item embeddings in the group-item recommendation task and the user-item recommendation task simultaneously. Finally, we conduct extensive experiments on two real-world datasets. The experimental results demonstrate the superiority of our proposed GroupSA method compared to several state-of-the-art methods in terms of HR and NDCG.",https://ieeexplore.ieee.org/document/9101842/,2020 IEEE 36th International Conference on Data Engineering (ICDE),20-24 April 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2013.55,Grouping Methods for Generating Friendship Based on Network Properties,IEEE,Conferences,"This paper investigates the effect of group work with the assumption of three motivators to make friends. Obeying the assumption we proposed twelve variation of methods for grouping students. The effects are evaluated by some measures from social network analysis and by the changes of real friendship networks, which are observed by a friendship prediction method. The proposed methods brought new friendship among students to classes and made rearrange of community structure.",https://ieeexplore.ieee.org/document/6598501/,"2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",1-3 July 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/VECIMS.2007.4373924,HI3 Project: Design and Implementation of the Lower Level Layers,IEEE,Conferences,"We are interested in the development of human-centered and ubiquitous technologies in social environments. In this line, and in the framework of a global software architecture (HI3) for this type of applications, the paper is devoted to the presentation of the work carried out for the design and implementation of the layer that is more closely linked to the hardware. It is in charge of communicating with the physical layer and it is responsible for the abstraction of the field elements. Special attention has been paid to the coherence with the philosophy, design premises and functionalities of the whole system. We have also determined a hardware configuration that, integrating standards where possible, is better adapted to the requirements of the architecture. The elements introduced here were validated on a real implementation of the system.",https://ieeexplore.ieee.org/document/4373924/,"2007 IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems",25-27 June 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/I4CS.2015.7294480,Happy hour - improving mood with an emotionally aware application,IEEE,Conferences,"Mobile sensing in Cyber-Physical Systems has been evolving proportionally with smartphones. In fact, we are witnessing a tremendous increase in systems that sense various facets of human beings and their surrounding environments. In particular, the detection of human emotions can lead to emotionally-aware applications that use this information to benefit people's daily lives. This work presents the implementation of a Human-inthe- loop emotionally-aware Cyber-Physical System that attempts to positively impact its user's mood through moderate walking exercise. Data from smartphone sensors, a smartshirt's electrocardiogram and weather information from a web API are processed through a machine learning algorithm to infer emotional states. When negative emotions are detected, the application timely suggests walking exercises, while providing real-time information regarding nearby points of interest. This information includes events, background music, attendance, agitation and general mood. In addition, the system also dynamically adapts privacy and networking configurations based on emotions. The sharing of the user's location on social networks and the device's networking interfaces are configured according to user-defined rules in order to reduce frustration and provide a better Quality of Experience.",https://ieeexplore.ieee.org/document/7294480/,2015 15th International Conference on Innovations for Community Services (I4CS),8-10 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2018.8621926,Harnessing the Nature of Spam in Scalable Online Social Spam Detection,IEEE,Conferences,"Disinformation in social networks has been a worldwide problem. Social users are surrounded by a huge volume of malicious links, biased comments, fake reviews, or fraudulent advertisements, etc. Traditional spam detection approaches propose a variety of statistical feature-based models to filter out social spam from a historical dataset. However, they omit the real word situation of social data, that is, social spam is fast changing with new topics or events. Therefore, traditional approaches cannot effectively achieve online detection of the ""drifting"" social spam with a fixed statistic feature set. In this paper, we present Sifter, a system which can detect online social spam in a scalable manner without the labor-intensive feature engineering. The Sifter system is two-fold: (1) a decentralized DHT-based overlay deployment for harnessing the group characteristics of social spam activities within a specific topic/event; (2) a social spam processing with the support of Recurrent Neural Network (RNN) to get rid of the traditional manual feature engineering. Results show that Sifter achieves graceful spam detection performances with the minimal size of data and good balance in group management.",https://ieeexplore.ieee.org/document/8621926/,2018 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN48605.2020.9206610,Heterogeneous Information Network Embedding with Convolutional Graph Attention Networks,IEEE,Conferences,"Heterogeneous Information Networks (HINs) are prevalent in our daily life, such as social networks and bibliography networks, which contain multiple types of nodes and links. Heterogeneous information network embedding is an effective HIN analysis method, it aims at projecting network elements into a lower-dimensional vector space for further machine learning related evaluations, such as node classification, node clustering, and so on. However, existing HIN embedding methods mainly focus on extracting the semantic-related information or close neighboring relations, while the high-level proximity of the network is also important but not preserved. To address the problem, in this paper we propose CGAT, a semi-supervised heterogeneous information network embedding method. We optimize the graph attention network by adding additional convolution layers, thereby we can extract multiple types of semantics and preserve high-level information in HIN embedding at the same time. Also, we utilize label information in HINs for semi-supervised training to better obtain the model parameters and HIN embeddings. Experimental results on real-world datasets demonstrate the effectiveness and efficiency of the proposed model.",https://ieeexplore.ieee.org/document/9206610/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CRV.2010.55,Human Upper Body Pose Recognition Using Adaboost Template for Natural Human Robot Interaction,IEEE,Conferences,"In this paper, we propose a novel Adaboost template to recognize human upper body poses from disparity images for natural human robot interaction (HRI). First, the upper body poses of standing persons are classified into seven categories of views. For each category, a mean template, variance template, and percentage template are generated. Then, the template region is divided into positive and negative regions, corresponding to the region of bodies and surrounding open space. A weak classifier is designed for each pixel in the template. A new EM-like Adaboost learning algorithm is designed to learn the Adaboost template. Different from existing Adaboost classifiers, we show that the Adaboost template can be used not only for recognition but also for adaptive top-down segmentation. By using Adaboost template, only a few positive samples for each category are required for learning. Comparison with conventional template matching techniques has been made. Experimental results show that significant improvements can be achieved in both cases. The method has been deployed in a social robot to estimate human attentions to the robot in real-time human robot interaction.",https://ieeexplore.ieee.org/document/5479162/,2010 Canadian Conference on Computer and Robot Vision,31 May-2 June 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITR51448.2020.9310890,Hybrid Approach and Architecture to Detect Fake News on Twitter in Real-Time using Neural Networks,IEEE,Conferences,"Fake news has been a key issue since the dawn of social media. Currently, we are at a stage where it is merely impossible to differentiate between real and fake news. This directly and indirectly affects people's decision patterns and makes us question the credibility of the news shared via social media platforms. Twitter is one of the leading social networks in the world by active users. There has been an exponential spread of fake news on Twitter in the recent past. In this paper, we will discuss the implementation of a browser extension which will identify fake news on Twitter using deep learning models with a focus on real-world applicability, architectural stability and scalability of such a solution. Experimental results show that the proposed browser extension has an accuracy of 86% accuracy in fake news detection. To the best of our knowledge, our work is the first of its kind to detect fake news on Twitter real-time using a hybrid approach and evaluate using real users.",https://ieeexplore.ieee.org/document/9310890/,2020 5th International Conference on Information Technology Research (ICITR),2-4 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DEST.2010.5610664,Hybrid ontologies and social semantics,IEEE,Conferences,"Semantic Web, Social Web, and new economic challenges are causing major shifts in the pervasive fabric that the internet has become, in particular for the business world. The internet's new role as participatory medium and its ubiquity lead to dense tri-sortal communities of humans and businesses mixed with computer systems, and semantically interoperating in a well-defined sense. Many of the challenges and ongoing (r)evolutions appear to produce as yet seemingly contradictory requirements and thus produce potentially very interesting research areas. We argue that linguistics, community-based real world “social” semantics and pragmatics, scalability, the tri-sortal nature of the communities involved, the balance between usability and reusability, and the methodological requirements for non-disruptive adoption by enterprises of the new technologies provide vectors for fundamental computer science research, for interesting new artefacts, and for new valorisations of enterprise interoperability. We posit that one such development will likely result in hybrid ontologies and their supporting social implementation environments -such as semantic wikis- that accommodate the duality and co-existence of formal reasoning requirements inside systems on the one hand and of declarative knowledge manipulation underlying human communication and agreement on the other hand.",https://ieeexplore.ieee.org/document/5610664/,4th IEEE International Conference on Digital Ecosystems and Technologies,13-16 April 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/APSEC.2002.1182989,IBistro: a learning environment for knowledge construction in distributed software engineering courses,IEEE,Conferences,"We have taught several distributed software engineering project courses with students and real clients. During these projects, students in Pittsburgh and Munich, Germany collaborated in the development of a single system. Our experiences showed that software development is communication intensive and requires the collaboration of many stakeholders. Communication is challenging in distributed contexts: participants do not all know each other and work at different times and locations; the number of participants and their organization change during the project; and participants belong to different communities. Hence, to deal with the global marketplace, it is critical to provide students with distributed collaboration skills. To improve the teaching of collaboration in software engineering, we propose iBistro, an augmented, distributed, and ubiquitous communication space. iBistro aims to overcome problems resulting from miscommunications and information loss in informal or casual meetings. iBistro enables distributed groups to collaborate and cooperate in software projects and therefore provides an environment for learning in diverse aspects such as project management, programming skills, and social skills. With the addition of techniques from artificial intelligence, such as student modeling, and intelligent support mechanisms, such as computer supported group formation, distributed tutoring becomes feasible.",https://ieeexplore.ieee.org/document/1182989/,"Ninth Asia-Pacific Software Engineering Conference, 2002.",4-6 Dec. 2002,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEARS53579.2022.9751864,Identifying Fake News using Machine Learning,IEEE,Conferences,"Fake data is purposely or accidentally transmitted throughout the internet. It has long been a social issue, and in the digital age, the average person now has easy access to all of the information available online. This is affecting a growing population of people who are technologically blind. One of the most serious problems in the modern day is fake news, which has the capacity to affect people's minds and influence their judgments. On web browsers, there are a few plugins that provide real-time information about the veracity of news. The algorithms used to create these plugins have a significant impact on them. The goal is to create a project that will propose which of the three implemented algorithms is the best for further development by the developer. Machine learning classification methods such as SVM, naive bayes, logistic regression, decision tree, and random forest are taught to detect if news is fake or real, and then compared based on metrics.",https://ieeexplore.ieee.org/document/9751864/,2022 International Conference on Electronics and Renewable Systems (ICEARS),16-18 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMC51019.2021.9418419,Image classification for user feedback using Deep Learning Techniques,IEEE,Conferences,"In this digital era, automatic human facial expression recognition is considered as an important component in computer vision. Also, it is challenging for machine learning algorithms, where humans can significantly show their expressions. Henceforth, in machine learning methods, deep learning is considered as a novel technology that can classify the images of human faces into different facial expression recognition categories using convolutional neural networks (CNN). In this system, the facial expression recognition is implemented by using CNN network based model with LeNet architecture to improve the prediction of expression results. Here, the proposed research work has utilized a facial expression dataset, which is loaded from Kaggle web resources and this dataset contains seven facial expression tags such as happy, anger, neutral, fear, sad, disgust, and surprise. In this system, along with emotion classifications, gender classification is also merged. Because automatic gender recognition has relevant to the addition of its usages in software applications whereas in social media and social networking websites. With this system, gender and facial expression recognition are explored through face detection using Convolution Neural Network (CNN).The whole motivation behind the work is to improve the way human movement is detected for different legal purposes. The usage of computer vision on the field of customer service, user security, user feedback and many other things. The gender and expression recognition can be used to deal with many real world problems.",https://ieeexplore.ieee.org/document/9418419/,2021 5th International Conference on Computing Methodologies and Communication (ICCMC),8-10 April 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCWAMTIP53232.2021.9674087,Immersive 4D Intelligent Interactive Platform Based on Deep Learning,IEEE,Conferences,"With the advent of the Internet era, the cost of realizing virtual characters has been greatly reduced. The high cost and low efficiency exhibited by traditional virtual technology can&#x0027;t meet social needs. People are seeking fast, convenient and accurate virtual character reproduction technology. Through researching the characteristics of the characters appearance, language habits, voice tone and so on, the research direction of this paper is to simulate and reshape voice and images, construct a cloud platform-based on user-side and client-side, and integrate deep learning, natural language processing, digital twins and other technologies to an immersive 4D intelligent interactive platform. The platform under in the form of application software provides integrated services of intelligent voice interaction and virtual character interaction. In the industrial diagnosis mode, the transition from traditional video retention and voice retention to a new intelligent voice recognition and simulation mode is realized.",https://ieeexplore.ieee.org/document/9674087/,2021 18th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP),17-19 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIMSEC.2011.6011030,"Impact from Effective distribution coefficient Change on the economic system constituted by two factors, three departments and four categories of residents — CGE model simulation",IEEE,Conferences,"A CGE model is built for the economic system constructed by two factors, three departments and four categories of residents and the impact effect of Effective distribution coefficient Change on this economie system is simulated by virtue of computer simulation. The fixed points of the economic system and the impact on distortion of general equilibrium of the economic system are computed by dint of MATLAB software and self-made program (genetic algorithm is adopted). Results: a Effective distribution coefficient Change may change the equilibrium price system (fixed points) of the economic system, the transaction costs of the economic system (in particular costs of property rights), residents' maximum utility and the department's equilibrium quantity through influence on employment resource quantity, demand structure, production structure, residents' real income and so on of the economic system. Conclusion: By the Effective distribution coefficient Change (Table 2), the total social utility increases, the Production of the three departments and the Effective distribution coefficient are positively correlated",https://ieeexplore.ieee.org/document/6011030/,"2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)",8-10 Aug. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ATC.2011.6027460,Implementing un-identified communication in Ubiquitous phone System,IEEE,Conferences,"Context awareness plays an important role in Ubiquitous applications based on the context information to provide services adapting to users' needs. The advantages of some context-aware smart phone systems, including iCAM[1], contextPhone[2], Live Contact Project [3], Enhanced Telephony[4] and Ubiquitous phone System Ubiphone [5] show themselves to be typical examples of Ubiquitous service ones. Using a context-aware smart phone, we can contact individuals in many ways, including by home, office, or cell phone, short message service (SMS), instance message(IM), and email. Therefore, a human-centered smart phone could discover how best to reach a contact at any given moment. However, in these systems, the users can contact to people in the contact list only, and the context information is managed and referred on only one ontology tree in one domain which contraries to the reality that in Ubiquitous environment. In this environment, the context information such as concepts and relationships are also managed and referred on heterogeneous ontology in several domains, which drive new challenges in the discovery of knowledge sources relevant to a users' request. New efficient technique and approach for developing and extending Ubiquitous phone intelligence is presented in this paper, which combines agent-based technologies and Artificial Neural Networks (ANNs) models to match ontology, helping users search and contact with anyone outside the contact list satisfying the users' requests even there is no social relationship between them.",https://ieeexplore.ieee.org/document/6027460/,The 2011 International Conference on Advanced Technologies for Communications (ATC 2011),2-4 Aug. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCKE.2011.6413358,Improving the accuracy and efficiency of tag recommendation system by applying hybrid methods,IEEE,Conferences,"Recently applications of social tagging systems have increased. These systems allow users to organize, manage and search the required resource freely, thus by combination and integration of recommendation systems in social software, assisting users to appropriately assign tag to resources and try to improve annotation among users. The challenges of recommendation systems are large-scale data, inconsistence data, usage of time-consuming machine learning algorithms, long and unreasonable time of recommendation and not being scalable to the demands of real world applications. Recently more efforts have been conducted to solve these problems. In this paper we proposed a tag recommendation system that is able to work with large-scale data and being applied in real world. The proposed system's evaluation performed on a dataset collected from Delicious.com. The results demonstrated the efficiency and accuracy of proposed system.",https://ieeexplore.ieee.org/document/6413358/,2011 1st International eConference on Computer and Knowledge Engineering (ICCKE),13-14 Oct. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACII.2019.8925479,Imputing Missing Social Media Data Stream in Multisensor Studies of Human Behavior,IEEE,Conferences,"The ubiquitous use of social media enables researchers to obtain self-recorded longitudinal data of individuals in real-time. Because this data can be collected in an inexpensive and unobtrusive way at scale, social media has been adopted as a “passive sensor” to study human behavior. However, such research is impacted by the lack of homogeneity in the use of social media, and the engineering challenges in obtaining such data. This paper proposes a statistical framework to leverage the potential of social media in sensing studies of human behavior, while navigating the challenges associated with its sparsity. Our framework is situated in a large-scale in-situ study concerning the passive assessment of psychological constructs of 757 information workers wherein of four sensing streams was deployed - bluetooth beacons, wearable, smartphone, and social media. Our framework includes principled feature transformation and machine learning models that predict latent social media features from the other passive sensors. We demonstrate the efficacy of this imputation framework via a high correlation of 0.78 between actual and imputed social media features. With the imputed features we test and validate predictions on psychological constructs like personality traits and affect. We find that adding the social media data streams, in their imputed form, improves the prediction of these measures. We discuss how our framework can be valuable in multimodal sensing studies that aim to gather comprehensive signals about an individual's state or situation.",https://ieeexplore.ieee.org/document/8925479/,2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII),3-6 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBDA51983.2021.9402992,"Incremental Real-time Learning Framework for Sentiment Classification: Indian General Election 2019, A Case Study",IEEE,Conferences,"Indian General Election 2019 was one of the major global political events. The prominence of social media in contemporary life, and the ubiquity of political messaging on it has necessitated a systematic study of sentiments and make inferences about future moods and trends. In absence of standard tools or software we propose a machine learning-based generic system framework and REST (Representation State Transfer) plugin component, that extracts and filters authentic tweets from Twitter, captures the prevalent mood, and predicts the sentiment of any live incoming tweet in a resource-constrained setup. The system can predict user sentiments by discovering completely new features from the web, along with the process of continuous incremental learning and improvement of model accuracy.",https://ieeexplore.ieee.org/document/9402992/,2021 IEEE 6th International Conference on Big Data Analytics (ICBDA),5-8 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ROBOT.1991.131908,Instinctive behaviors and personalities in societies of cellular robots,IEEE,Conferences,"A description is presented of the social organization of societies of cellular mobile units featuring instinctive behavior. Each robotic unit has its own personality and lives independently from the others. Useful tasks are carried out through collaboration rather than by individual effort. The behavior of each unit derives from a subsumption-like control structure, which emphasizes the roles of innate personality, external stimuli, and communication. A number of different robotic personalities are described and techniques of implementing them in real robot units are outlined. The implementation of instinctive behavior is described for the case of a robotic vehicle system (ROBBIE).<>",https://ieeexplore.ieee.org/document/131908/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/FRUCT53335.2021.9599974,Intelligent Identification of Fake Accounts on Social Media,IEEE,Conferences,The paper presents an original research of fake accounts on social media using an artificial neural network for their identification. Specifically designed and implemented application was used to identify specific features of fake accounts and study the principles and reasons of their generation. Considering the possible use cases and scenarios of its practical use including everyday social media surfing there was examined a possibility to implement a mobile application based on Java in the Android Studio programming environment. Based on the study of 500 real and 500 fake VKontakte accounts there was determined a number of conclusions on the original features of fake accounts. The provided research allowed extending the list of criteria for identifying fake accounts by an original set of patterns. The developed conclusions allow formulating the statements on what criteria can be used for further identification of fake accounts in practical applications.,https://ieeexplore.ieee.org/document/9599974/,2021 30th Conference of Open Innovations Association FRUCT,27-29 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CIT/IUCC/DASC/PICOM.2015.151,Intelligent Mobile Framework Based on Swarm Computation,IEEE,Conferences,"Mobile Terminal Crowd Sourcing provides social network information and services for users through data processing and data mining. Intelligent engine provides recommendation based on historical information and real-time environment, which are primarily used in intelligent life, mobile social networking, and other fields. Firstly, the concept of intelligent engine is introduced, the research strategy and the overall structure of the mobile terminal crowd sourcing.",https://ieeexplore.ieee.org/document/7363192/,"2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing",26-28 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SEA-STEM53614.2021.9668057,Intelligent Traffic Light System Using Image Processing,IEEE,Conferences,"Nowadays, there are more cars used on the road. Traffic congestion problems can cause the economy and the environment both directly and indirectly problems, also part of the problem of air pollution. The traffic light management system in the current situation has used a fixed waiting time, which inability to be flexible according to the traffic at different times such as in rush hour and other. It is not efficient enough to manage traffic with fixed waiting time. The organizers came up with the idea of developing an intelligent traffic light system with flexibility according to the number of cars in real-time by reducing waiting time. The paper was designed and developed by implementing the intelligent traffic light system using image processing technology to process the appropriate waiting time from each image frame. Lazarus and OpenGL were used to program based on Pascal language. The software has been developed for receiving traffic video at the intersection to process car image segmentation of each frame and to calculate the distance of the length of the car in each route in addition. It is also possible to calculate the appropriate time for green-light and red-light duration and corresponding to the length of the waiting vehicles in each route at the intersection. This investigated software can be used to reduce the waiting time at the traffic light intersection by 45.35%. In addition, the intelligent traffic light system is also a social development towards a smart city. The project has created the learning environment and computational thinking for society through the process of STEM Education with using IoT and Artificial Intelligence.",https://ieeexplore.ieee.org/document/9668057/,2021 2nd SEA-STEM International Conference (SEA-STEM),24-25 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GCCE.2015.7398635,Intelligent control of USM using a modified NN with PSO,IEEE,Conferences,"As aging society problem goes severe In not only Japan but also the whole world, more and more attentions are attracted to the social and welfare fields. Many researches on science and technology for elders are implemented in rencent years. With the background, there are a lot of needs for techonologies with novel features for improvement. In this paper, a control method with attractive features for the actuator of Ultrasonic Motors (USMs) is introduced. In medical and welfare areas, the USMs are expected to play more important roles owing to their special characteristics. In this research, an intelligent PID control method using Neural Network (NN) combined with type Particle Swarm Optimization (PSO) is developed for the control of USM. In the method, the intelligent controller is designed based on variable gain type PID control using NN. The learning of the NN unit is implemented by the PSO. The gains of PID control are adjusted by the proposed method in real-time. The effectiveness of the method is verified by experimental results.",https://ieeexplore.ieee.org/document/7398635/,2015 IEEE 4th Global Conference on Consumer Electronics (GCCE),27-30 Oct. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITSC.2017.8317730,Intelligent traffic light control using distributed multi-agent Q learning,IEEE,Conferences,"The combination of Artificial Intelligence (AI) and Internet-of-Things (IoT), which is denoted as AI powered Internet-of-Things (AIoT), is capable of processing huge amount of data generated from large number of devices and handling complex problems in social infrastructures. As AI and IoT technologies are becoming mature, in this paper, we propose to apply AIoT technologies for traffic light control, which is an essential component for intelligent transportation system, to improve the efficiency of smart city's road system. Specifically, various sensors such as surveillance cameras provide real-time information for intelligent traffic light control system to observe the states of both motorized traffic and non-motorized traffic. In this paper, we propose an intelligent traffic light control solution by using distributed multi-agent Q learning, considering the traffic information at the neighboring intersections as well as local motorized and non-motorized traffic, to improve the overall performance of the entire control system. By using the proposed multi-agent Q learning algorithm, our solution is targeting to optimize both the motorized and non-motorized traffic. In addition, we considered many constraints/rules for traffic light control in the real world, and integrate these constraints in the learning algorithm, which can facilitate the proposed solution to be deployed in real operational scenarios. We conducted numerical simulations for a real-world map with real-world traffic data. The simulation results show that our proposed solution outperforms existing solutions in terms of vehicle and pedestrian queue lengths, waiting time at intersections, and many other key performance metrics.",https://ieeexplore.ieee.org/document/8317730/,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),16-19 Oct. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EDUCON52537.2022.9766555,Internet of Things Meets Machine Learning: A Water Usage Alert Example,IEEE,Conferences,"The rapid growth of the electronics industry resulted in numerous, amazing and cheap devices, while fluent documentation and user-friendly programming environments are available for them. Modern educational systems worldwide have exploited this dynamic by including in their didactic curricula innovative practices that are usually called STEM actions. Added to this, enriching educational methods with real-world problem solving techniques increases students&#x2019; interest and prepares them for their future role in the society. Apparently, such challenging problems are not missing, with the depletion of natural resources to be one of the most intense ones. In this context, promising modern technological flavors like Internet of Things (IoT) and Machine Learning (ML) can join their potential to form educationally fruitful and also practically important activities targeted at increasing the social awareness for the water misuse problem, like the ones proposed herein. These activities also encourage the deployment of low-cost appliances that, only with minor modifications, can respond to a wide variety real problems in either urban or rural environments.",https://ieeexplore.ieee.org/document/9766555/,2022 IEEE Global Engineering Education Conference (EDUCON),28-31 March 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DeSE.2011.10,Introducing a Round Robin Tournament into Evolutionary Individual and Social Learning Checkers,IEEE,Conferences,"In recent years, much research attention has been paid to evolving self-learning game players. Fogel's Blondie24 is a demonstration of a real success in this field, inspiring many other scientists. In this paper, artificial neural networks are used as function evaluators in order to evolve game playing strategies for the game of checkers. We introduce a league structure into the learning phase of an individual and learning system based on the Blondie24 architecture. We show that this helps eliminate some of the randomness in the evolution. The best player we evolve is tested against an implementation of an evolutionary checkers program, and also against a player, which utilises the proposed round robin tournament and finally against an individual and social learning checkers program. The results are promising, suggesting many other research directions.",https://ieeexplore.ieee.org/document/6149996/,2011 Developments in E-systems Engineering,6-8 Dec. 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN.2003.1223995,Investigating models of social development using a humanoid robot,IEEE,Conferences,"Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a ""theory of mind"". Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements.",https://ieeexplore.ieee.org/document/1223995/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CogInfoCom47531.2019.9089994,Investigating the Social Robots’ Role in Improving Children Attitudes toward Recycling. The case of PeppeRecycle,IEEE,Conferences,"In this paper we investigate the impact of a social robot in the context of serious games in which the robot plays the role of a game opponent by challenging and, at the same time, teaching the child to correctly recycle waste materials. To this aim we performed a study in which we investigated the dimensions that are used to evaluate serious games integrated with those that are typical of the interaction with a social robot. To endow the robot with the capability to play as a game opponent in a real-world context, we implemented an image recognition module based on a Convolutional Neural Network so that the robot could detect and classify the waste material as a child would do, by seeing it. After a preliminary evaluation of the approach, we started a formal experiment in which we measured the effectiveness of game design, the robot evaluation and the evaluation of cognitive and affective elements that can form the pro-environmental attitude and then the tendency to recycling. A primary school classroom was involved in the study and, results obtained so far, are encouraging and drew promising possibilities for robotics education in changing recycling attitude for children since Pepper is positively evaluated as trustful and believable and this allowed to be concentrated on the `memorization' task during the game.",https://ieeexplore.ieee.org/document/9089994/,2019 10th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),23-25 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAICA50127.2020.9182385,KEAN: Knowledge Embedded and Attention-based Network for POI Recommendation,IEEE,Conferences,"In recent years, with the rapid development of location-based social networks (LBSN) in the Internet, point of interest (POI) recommendation has become a hot spot. Most existing researches make use of contextual information to model users' interest preferences. However, the existing methods for extracting various auxiliary information still need to be improved, such as how to treat the users' social relations equally. In order to obtain users' actual preferences more accurately, in POI recommendation, we propose a deep learning framework KEAN (Knowledge Embedded and Attention Based Network) based on knowledge graph and attention model. The framework includes knowledge-graph embedding method, preference extraction network based on attention mechanism and recommendation network. Our study used knowledge-graph embedding method to get the embedding of each user and POI. In addition, an LSTM network based on attention mechanism was proposed, which uses LSTM network to learn the user's preferences according to the user's check-in sequence. Besides, the attention mechanism was used to extract friends' preferences and merge them with the user's preferences to generate end-user preferences. Finally, our model use fully-connected neural networks to realize recommendations. The effectiveness of the model was proved by the experimental results based on real LBSN datasets.",https://ieeexplore.ieee.org/document/9182385/,2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA),27-29 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/VR.2019.8798046,Keynote Speaker: Virtual Reality for Enhancing Human Perceptional Diversity Towards an Inclusive Society,IEEE,Conferences,"We conducted research project towards an inclusive society from the viewpoint of the computational assistive technologies. This project aims to explore AI-assisted human-machine integration techniques for overcoming impairments and disabilities. By connecting assistive hardware and auditory/visual/tactile sensors and actuators with a user-adaptive and interactive learning framework, we propose and develop a proof of concept of our “xDiversity AI platform” to meet the various abilities, needs, and demands in our society. For example, one of our studies is a wheelchair for automatic driving using “AI technology” called “tele wheelchair”. Its purpose is not fully automated driving but labor saving at nursing care sites and nursing care by natural communication. These attempts to solve the challenges facing the body and sense organs with the help of AI and others. In this keynote we explain the case studies and out final goal for the social design and deployment of the assistive technologies towards an inclusive society.",https://ieeexplore.ieee.org/document/8798046/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCTA48790.2019.9478839,Keynote Speech II: Readiness for the Impact of Emerging Technologies,IEEE,Conferences,"Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. The digital world is becoming increasingly intertwined with the physical world of machines, to which it is bringing ubiquitous intelligence and a perpetual flow of information. These trends are driving us towards a very different future. That future has already started. A new wave of social, economic, and psychological changes is expected to abruptly affect almost everything we do. With change, many opportunities come along. Those who anticipate the course of the future, and prepare for it, will be ready to seize these opportunities and will come out winners. Those who chose to ignore the signs of change, will risk losing their livelihood and eventually hurting their families, businesses, and societies. Those who see the storm coming but react by standing still in panic, disgruntlement, and lamentation will be defenseless when the inevitable waves hit their shores. This presentation overviews the trends in technology and applications, including Artificial Intelligence, Big Data Analytics, Robotics, Internet of Things, Industry 4.0, etc. The impact that such advances are likely to have on the high-tech as well as the low-tech job markets is outlined. Some actions and initiatives are proposed and discussed, with the purpose of triggering a larger debate on how individuals, businesses, academic institutions, and governments should prepare for the anticipated massive changes that are already beginning to affect our world.",https://ieeexplore.ieee.org/document/9478839/,2019 29th International Conference on Computer Theory and Applications (ICCTA),29-31 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData47090.2019.9006554,KryptoOracle: A Real-Time Cryptocurrency Price Prediction Platform Using Twitter Sentiments,IEEE,Conferences,"Cryptocurrencies, such as Bitcoin, are becoming increasingly popular, having been widely used as an exchange medium in areas such as financial transaction and asset transfer verification. However, there has been a lack of solutions that can support real-time price prediction to cope with high currency volatility, handle massive heterogeneous data volumes, including social media sentiments, while supporting fault tolerance and persistence in real time, and provide real-time adaptation of learning algorithms to cope with new price and sentiment data. In this paper we introduce KryptoOracle, a novel real-time and adaptive cryptocurrency price prediction platform based on Twitter sentiments. The integrative and modular platform is based on (i) a Spark-based architecture which handles the large volume of incoming data in a persistent and fault tolerant way; (ii) an approach that supports sentiment analysis which can respond to large amounts of natural language processing queries in real time; and (iii) a predictive method grounded on online learning in which a model adapts its weights to cope with new prices and sentiments. Besides providing an architectural design, the paper also describes the KryptoOracle platform implementation and experimental evaluation. Overall, the proposed platform can help accelerate decision-making, uncover new opportunities and provide more timely insights based on the available and ever-larger financial data volume and variety.",https://ieeexplore.ieee.org/document/9006554/,2019 IEEE International Conference on Big Data (Big Data),9-12 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData.2018.8622221,Large Scale Open Source Video Recommender Tool Using Metadata Surrogates,IEEE,Conferences,"Video and multi-media sharing is a significant activity on social media platforms. Learning patterns of activities using raw video data is computationally intensive and impractical, and manual inspection is not scalable and prohibitively expensive. An alternate strategy is to learn information about video content using far less compute intensive metadata surrogates. This paper describes a video recommender tool implemented in GovCloud using a novel approach of using lightweight video metadata to learn and classify video content. In contrast to popular video recommender systems that use consumption models for classification, the new approach used in our tool is based solely on the video metadata along with domain expertise used to truth a relatively small subset of relevant video content. The tool is very user-friendly and captures practical knowledge of the user resulting in good learning model. The architecture and implementation specifics of the tool is outlined in this paper. The classifier performance using metadata from tens of thousands of real postings exceeds 90% for both recall and ROC metrics. This tool has shown promise in providing a console for aggregating social media videos for analysts to train the system consistent with the context and task at hand.",https://ieeexplore.ieee.org/document/8622221/,2018 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData50022.2020.9377817,Learning Embeddings of Directed Networks with Text-Associated Nodes—with Application in Software Package Dependency Networks,IEEE,Conferences,"A network embedding consists of a vector representation for each node in the network. Its usefulness has been shown in many real-world application domains, such as social networks and web networks. Directed networks with text associated with each node, such as software package dependency networks, are commonplace. However, to the best of our knowledge, their embeddings have hitherto not been specifically studied. In this paper, we propose PCTADW-1 and PCTADW-2, two algorithms based on neural networks that learn embeddings of directed networks with text associated with each node. We create two new node-labeled such networks: The package dependency networks in two popular GNU/Linux distributions, Debian and Fedora. We experimentally demonstrate that the embeddings produced by our algorithms resulted in node classification with better quality than those of various baselines on these two networks. We observe that there exist systematic presence of analogies (similar to those in word embeddings) in the network embeddings of software package dependency networks. To the best of our knowledge, this is the first time that such systematic presence of analogies is observed in network and document embeddings. We further demonstrate that these network embeddings can be novelly used for better understanding software attributes, such as the development process and user interface of software, etc.",https://ieeexplore.ieee.org/document/9377817/,2020 IEEE International Conference on Big Data (Big Data),10-13 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2016.0048,Learning User Embedding Representation for Gender Prediction,IEEE,Conferences,"Predicting the gender of users in social media has aroused great interests in recent years. Almost all existing studies rely on the the content features extracted from the main texts like tweets or reviews. It is sometimes difficult to extract content information since many users do not write any posts at all. In this paper, we present a novel framework which uses only the users' ids and their social contexts for gender prediction. The key idea is to represent users in the embedding connection space. A user often has the social context of family members, schoolmates, colleagues, and friends. This is similar to a word and its contexts in documents, which motivates our study. However, when modifying the word embedding technique for user embedding, there are two major challenges. First, unlike the syntax in language, no rule is responsible for the composition of the social contexts. Second, new users were not seen when learning the representations and thus they do not have embedding vectors. Two strategies circular ordering and incremental updating are proposed to solve these problems. We evaluate our methodology on two real data sets. Experimental results demonstrate that our proposed approach is significantly better than the traditional graph representation and the state-of-the-art graph embedding baselines. It also outperforms the content based approaches by a large margin.",https://ieeexplore.ieee.org/document/7814608/,2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI),6-8 Nov. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDM.2015.10,Learning User Preferences across Multiple Aspects for Merchant Recommendation,IEEE,Conferences,"With the pervasive use of mobile devices, Location Based Social Networks(LBSNs) have emerged in past years. These LBSNs, allowing their users to share personal experiences and opinions on visited merchants, have very rich and useful information which enables a new breed of location-based services, namely, Merchant Recommendation. Existing techniques for merchant recommendation simply treat each merchant as an item and apply conventional recommendation algorithms, e.g., Collaborative Filtering, to recommend merchants to a target user. However, they do not differentiate the user's real preferences on various aspects, and thus can only achieve limited success. In this paper, we aim to address this problem by utilizing and analyzing user reviews to discover user preferences in different aspects. Following the intuition that a user rating represents a personalized rational choice, we propose a novel utility-based approach by combining collaborative and individual views to estimate user preference (i.e., rating). An optimization algorithm based on a Gaussian model is developed to train our merchant recommendation approach. Lastly we evaluate the proposed approach in terms of effectiveness, efficiency and cold-start using two real-world datasets. The experimental results show that our approach outperforms the state-of-the-art methods. Meanwhile, a real mobile application is implemented to demonstrate the practicability of our method.",https://ieeexplore.ieee.org/document/7373403/,2015 IEEE International Conference on Data Mining,14-17 Nov. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA46639.2022.9811662,Learning to Socially Navigate in Pedestrian-rich Environments with Interaction Capacity,IEEE,Conferences,"Existing navigation policies for autonomous robots tend to focus on collision avoidance while ignoring human-robot interactions in social life. For instance, robots can pass along the corridor safer and easier if pedestrians notice them. Sounds have been considered as an efficient way to attract the attention of pedestrians, which can alleviate the freezing robot problem. In this work, we present a new deep reinforcement learning (DRL) based social navigation approach for autonomous robots to move in pedestrian-rich environments with interaction capacity. Most existing DRL based methods intend to train a general policy that outputs both navigation actions, i.e., expected robot&#x0027;s linear and angular velocities, and interaction actions, i.e., the beep action, in the context of reinforcement learning. Different from these methods, we intend to train the policy via both supervised learning and reinforcement learning. In specific, we first train an interaction policy in the context of supervised learning, which provides a better understanding of the social situation, then we use this interaction policy to train the navigation policy via multiple reinforcement learning algorithms. We evaluate our approach in various simulation environments and compare it to other methods. The experimental results show that our approach outperforms others in terms of the success rate. We also deploy the trained policy on a real-world robot, which shows a nice performance in crowded environments.",https://ieeexplore.ieee.org/document/9811662/,2022 International Conference on Robotics and Automation (ICRA),23-27 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMC.2019.8914455,Learning waste Recycling by playing with a Social Robot,IEEE,Conferences,"In this paper we investigate the use of a social robot as an interface to a serious game aiming to train kids in how to recycle materials correctly. Serious games are mostly used to induce motivations and engagement in users and support knowledge transfer during playing. They are especially effective when the goal of the game concerns behavior change. In addition, social robots have been used effectively in educational settings to engage children in the learning process. Following this trend, we designed a serious game in which the social robot Pepper plays with a child to teach him to correctly recycle the materials. To endow the robot with the capability of detecting and classifying the waste material we developed an image recognition module based on a Convolutional Neural Network. Preliminary experimental results show that the implementation of a serious game about recycling into the Pepper robot improves its social behavior. The use of real objects as waste items during the game turns out to be a successful approach not only for perceived learning effectiveness but also for engagement of the children.",https://ieeexplore.ieee.org/document/8914455/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/NCTM.2017.7872829,Linguistic features based personality recognition using social media data,IEEE,Conferences,"Social media has become a prominent platform for opinions and thoughts. This stated that the characteristics of a person can be assessed through social media status updates. The purpose of this research article is to provide a web application in order to detect one's personality using linguistic feature analysis. The personality of a person has classified according to Eysenck's Three Factor personality model. The proposed technique is based on ontology based text classification, linguistic feature-vector matrix using LIWC (Linguistic Inquiry and Word Count) features including semantic analysis using supervised machine learning algorithms and questionnaire based personality detection. This is vital for HR management system when recruiting and promoting employees, R&D Psychologists can use the dynamic ontology for storage purposes and all the other API users including universities and sports clubs. According to the test results the proposed system is in an accuracy level of 91%, when tested with a real world personality detection questionnaire based application, and results demonstrate that the proposed technique can detect the personality of a person with considerable accuracy and a speed.",https://ieeexplore.ieee.org/document/7872829/,2017 6th National Conference on Technology and Management (NCTM),27-27 Jan. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCCN49398.2020.9209681,LogParse: Making Log Parsing Adaptive through Word Classification,IEEE,Conferences,"Logs are one of the most valuable data sources for large-scale service (e.g., social network, search engine) maintenance. Log parsing serves as the the first step towards automated log analysis. However, the current log parsing methods are not adaptive. Without intra-service adaptiveness, log parsing cannot handle software/firmware upgrade because learned templates cannot match new type of logs. In addition, without cross-service adaptiveness, the logs of a new type of service cannot be accurately parsed when this service is newly deployed. We propose LogParse, an adaptive log parsing framework, to support intra-service and cross-service incremental template learning and update. LogParse turns the template generation problem into a word classification problem and learns the features of template words and variable words. We evaluate LogParse on four public production log datasets. The results demonstrate that LogParse supports accurate adaptive template update (increased from 0.559 to nearly 1.0 parsing accuracy), and a trained LogParse is adaptive for a brand new service&#x2019;s log parsing. Because of LogParse&#x2019;s adaptiveness, we also apply LogParse to an interesting application, log compression and deployed log compression in a top cloud service provider. We package LogParse into an open-source toolkit.",https://ieeexplore.ieee.org/document/9209681/,2020 29th International Conference on Computer Communications and Networks (ICCCN),3-6 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CONFLUENCE.2019.8776981,Logistic Regression based DFS for Trip Advising Software (ASCEND),IEEE,Conferences,"Graphs have played a pivotal role in the field of computer science and has been an efficient method for representing and modeling abstractions in various fields. They can be used to represent several real life models. Several domains in today's world use the concept of graphs extensively such as GPS Navigation systems, Computer networks, WebCrawler, Social Networking websites, peer to peer networking, medical and biological field, neural networks etc. Taking into account the numerous applications of the concept of graphs in today's world, graph searching becomes inevitably significant. In this scenario it is important to note that several graph searching algorithms that were proposed to give exhaustive searches doesn't provide the most satisfying outcome in terms of asymptotic time complexity. Through this paper we intend to highlight the significance of machine learning as a useful tool that can be incorporated in various graph searching algorithms that can reduce its complexity. We classify the existing graph searching techniques as subsets or modifications of two major conventional graph searching algorithms namely BFS(Breadth First Search) and DFS(Depth First Search) and suggest the application of logistic regression to improve their performance. It is confounding that only few research papers explore the application of machine learning to the aforementioned graph searching algorithms. Hence, it is evident that there exists scope for future research on this topic and we aim to suggest directions for the same.",https://ieeexplore.ieee.org/document/8776981/,"2019 9th International Conference on Cloud Computing, Data Science & Engineering (Confluence)",10-11 Jan. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSTCEE54422.2021.9708587,Logistic Regression versus XGBoost: Machine Learning for Counterfeit News Detection,IEEE,Conferences,"In this age of globalization, the unstoppable spreading of fake news via the internet is unstoppable. The spread of false news cannot be supported due to the negative consequences. Society is extremely concerning. In addition, itleads to more serious problems and possible threats, like confusion, misunderstandings, defamation and falsehoods that induce users to share inflammatory content. With the convenience and tremendous increase in information gathering on social networks, it is becoming difficult to differentiate between what is false and what is real. Information can be easily disseminated through sharing, which has contributed to the exponential growth of their forgeries. Machine learning played an important role, in classifying information, although there are some limitations. This article explores various machine learning techniques used to detect fake and fabricated messages. The limitations are discussed using deep learning implementation. In this project, the methodology used is model development and Logistic Regression classifier is considered to detect false news. Based on previous research, this classifier performed well in classification tasks. In this approach, TF-IDF feature is used for the construction of this fake news model to get higher accuracy. The goal of this project is to detect false news using NLP and Machine Learning based on the news content of the article. Following the development of the appropriate Machine Learning model to detect fake/true news, it is deployed into a web interface using Python Flask.",https://ieeexplore.ieee.org/document/9708587/,"2021 Second International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)",16-17 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMLA.2015.152,MLaaS: Machine Learning as a Service,IEEE,Conferences,"The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.",https://ieeexplore.ieee.org/document/7424435/,2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA),9-11 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMC.2018.8487992,Machine Learning Based Twitter Spam Account Detection: A Review,IEEE,Conferences,"Online social networks (OSNs) are emerging communication medium for people to establish and manage social relationships. In OSNs, regularly billions of users are involved in social interaction, content and opinion dissemination, networking, recommendations, scouting, alerting, and social campaigns. The popularization of OSNs open up a new perspectives and challenges to the study of social networks, being of interest to many fields. Social network is a place where social activities, business oriented activities, entertainment, and information are exchanged. It establish a worldwide connectivity environment where communities of people share their interests and activities, or who are interested in interests and activities of others Although social network has given immense benefits to people at the same time harming people with various mischievous activities that take place on social platforms. This causes significant economic loss to our society and even threaten the national security. All the social networks Facebook, Twitter, LinkedIn, etc. are highly susceptible to malware activities. Twitter is one of the biggest microblogging networking platform, it has more than half a billion tweets are posted every day in average by millions of users on Twitter. Such a versatility and wide spread of use, Twitter easily get intruded with malicious activities. Malicious activities includes malware intrusion, spam distribution, social attacks, etc. Spammers use social engineering attack strategy to send spam tweets, spam URLs, etc. This made twitter an ideal arena for proliferation of anomalous spam accounts. The impact stimulates researchers to develop a model that analyze, detects and recovers from defamatory actions in twitter. Twitter network is inundated with tens of millions of fake spam profiles which may jeopardize the normal user's security and privacy. To improve real users safety and identification of spam profiles become key parts of the research.",https://ieeexplore.ieee.org/document/8487992/,2018 Second International Conference on Computing Methodologies and Communication (ICCMC),15-16 Feb. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/eIT53891.2022.9837113,Machine Vision Surveillance System - Artificial Intelligence For Covid-19 Norms,IEEE,Conferences,"This paper presents the design and implementation of the Machine Vision Surveillance System Artificial Intelligence (MaViSS-AI) for Covid-19 Norms using jetson nano. This system is designed to be cost-effective, accurate, efficient, and secure. The proposed system tracks and counts humans for monitoring social distancing and detects face masks using object detection methods. We used YOLO as an object detection method and neural network to detect a person and count them. And for social distancing monitoring the concept of the centroid is based on calculating the distance between pairs of centroids, and thus checking whether there are any violations of the threshold or not. To detect the face mask, a YOLO V4 deep learning model is used as the mask detection algorithm. The system also raises alerts when any suspicious event occurs. Given this alert, security personnel can take relevant actions. This research aims to provide a holistic approach to overcoming the real-time challenges encountered during the monitoring of Covid-19 norms.",https://ieeexplore.ieee.org/document/9837113/,2022 IEEE International Conference on Electro Information Technology (eIT),19-21 May 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIIoT54504.2022.9817247,Major threats to the continued adoption of Artificial Intelligence in today&#x0027;s hyperconnected world,IEEE,Conferences,"From the golden era of science fiction which dates to the late 1930s, scientific and technological advances in artificial intelligence (AI), along with one of its key subsets, machine learning (ML) have been growing significantly, especially in recent years. In 2021 alone, notable feats included an AI program capable of creating images from seen or previously unseen textual captions, an AI model that effectively integrates computer vision and natural language processing, and a novel AI framework for diagnosing dementia in 24 hours with real-world feasibility underway amongst a host of other fascinating breakthroughs. This paper briefly delves into AI/ML and recaps some key essentials, covering AI and ML subfields, ML methods, industries where AI/ML finds relevance, key stages and the common technical challenges in ML development. Importantly, the paper shifts attention from the latter to underscore the duo of transparency and ethics in AI, highlighting specifically what these are and why they are important, subsequently positing a PESTEL (Political, Economic, Social, Technological, Environmental and Legal) framework for AI design, build and implementation. It is anticipated that the upshot of this would be the facilitation of continuous adoption and long-term sustainability of AI/ML.",https://ieeexplore.ieee.org/document/9817247/,2022 IEEE World AI IoT Congress (AIIoT),6-9 June 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMLA.2015.72,Malware Detection in Android-Based Mobile Environments Using Optimum-Path Forest,IEEE,Conferences,"Nowadays, people use smartphones and tablets with the very same purposes as desktop computers: web browsing, social networking and home-banking, just to name a few. However, we are often facing the problem of keeping our information protected and trustworthy. As a result of their popularity and functionality, mobile devices are a growing target for malicious activities. In such context, mobile malwares have gained significant ground since the emergence and growth of smartphones and handheld devices, becoming a real threat. In this paper, we introduced a recently developed pattern recognition technique called Optimum-Path Forest in the context of malware detection, as well we present ""DroidWare"", a new public dataset to foster the research on mobile malware detection. In addition, we also proposed to use Restricted Boltzmann Machines for unsupervised feature learning in the context of malware identification.",https://ieeexplore.ieee.org/document/7424412/,2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA),9-11 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WETICE.2019.00013,Meaning Extraction in a Domotic Assistant Agent Interacting by Means of Natural Language,IEEE,Conferences,"This paper presents a software architecture to let users interact with their smart home devices, through the commonly used social network channels. The software, called FABULOS, is the result of the combination of components used to interact with devices and social networks, and a rule-based artificial intelligence, which implements the base logic for the automation. The core of the software architecture is the translation service, which has the objective of extracting the meaning of the sentences provided by text and voice messages by users in natural language, transforming them into proper device commands. In order to achieve this, the proposed solution relies on an approach which has the capability to interpret and extract the meaning of the intentions plus the entities involved, associated to the sentences sent by the users. A description of a realistic case-study, which shows an example of how the proposed software behaves in a real interaction with an user, is also included in the paper.",https://ieeexplore.ieee.org/document/8795403/,2019 IEEE 28th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE),12-14 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DTPI52967.2021.9540077,Mechanical Design Paradigm based on ACP Method in Parallel Manufacturing,IEEE,Conferences,"Parallel Manufacturing is a new manufacturing paradigm in industry, deeply integrating informalization, automation, and artificial intelligence. In this paper we propose a new mechanical design paradigm in Parallel Manufacturing based on ACP method. The key is to regard the design procedure based on artificial design and emulation method as two independent procedures, which can be modeled as a parallel system. The design procedure based on ACP method does not include a real system, which is an inventive extension of the traditional parallel system. This method can be implemented with social information by introducing the definition of SDV, SDM, and Intelligent Design Manager, making it highly adaptive for social manufacturing and Parallel Manufacturing.",https://ieeexplore.ieee.org/document/9540077/,2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI),15 July-15 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCSMT54525.2021.00083,Medical Analysis of Social Media Data Based on Spark and Machine Learning in China,IEEE,Conferences,"Social media embracing a huge amount of real-time data of all kinds plays an important role in data analysis in the era of big data. Knowledge between medical workers and ordinary people can be popularized and exchanged via social media. At the same time, the collection and utilization of medical data on social media can effectively grasp the public health situation and provide better help to improve people&#x0027;s health status. From the perspective of medical care and health, this paper uses Weibo, the largest public social media in China, to obtain data for analysis. The study was developed under the Spark framework, using naive Bayes, random forest and two different feature extraction methods to clean, pre-process and classify data. Furthermore, the accuracy rate and F1 Score were used to evaluate the model, to find the most appropriate method. The result of this research shows that the data obtained from Weibo within certain age groups has a good reference value in the public awareness and current situation, and are good for grasping the trend of diseases.",https://ieeexplore.ieee.org/document/9786983/,2021 2nd International Conference on Computer Science and Management Technology (ICCSMT),12-14 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSCI54926.2021.00305,Metricam: Fast and Reliable Social Distancing Analysis in Online Security Cameras,IEEE,Conferences,"Distance measurements taken from 2D camera images are subject to the correct estimation of the camera&#x2019;s perspective, that is, the spatial mapping from 2D points imaged by a camera to the correspondent 3D ones in the real world. Current solutions to solve this 3D reconstruction are either dependent on the estimation of vanishing points through the detection of straight lines on targeted images or by employing sophisticated sensors and deep learning algorithms, which require expensive training on huge annotated datasets. Nevertheless, none of those approaches provide the required level of precision and accuracy for social distancing evaluation. In this paper we present Metricam, a real-time lightweight software system for security cameras that computes a 2D to 3D mapping using computational geometry and uses the DBSCAN clustering algorithm to evaluate social distancing evaluation. With Metricam, we have been able to identify several places prone to agglomeration inside the Butant&#x00E3; campus of the University of S&#x00E3;o Paulo, and provide the local authorities with valuable information to fight off the pandemic.",https://ieeexplore.ieee.org/document/9799026/,2021 International Conference on Computational Science and Computational Intelligence (CSCI),15-17 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2014.6888682,Microcredit risk assessment using crowdsourcing and social networks,IEEE,Conferences,"The task of automated risk assessment is attracting significant attention in the light of the recent microloan popularity growth. The industry requires a real time method for the timely processing of the extensive number of applicants for short-term small loans. Owing to the vast number of applications, manual verification is not a viable option. In cooperation with a microloan company in Azerbaijan, we have researched automated risk assessment using crowdsourcing. The principal concept behind this approach is the fact that a significant amount of information relating to a particular applicant can be retrieved from the social networks. The suggested approach can be divided into three parts: First, applicant information is collected on social networks such as LinkedIn and Facebook. This can only occur with the applicant's permission. Then, this data is processed using a program that extracts the relevant information segments. Finally, these information segments are evaluated using crowdsourcing. We attempted to evaluate the information segments using social networks. To that end, we automatically posted requests on the social networks regarding certain information segments and evaluated the community response by counting “likes” and “shares”. For example, we posted the status, “Do you think that a person who has worked at ABC Company is more likely to repay a loan? Please “like” this post if you agree.” From the results, we were able to estimate public opinion. Once evaluated, each information segment was then given a weight factor that was optimized using available loan-repay test data provided to us by a company. We then tested the proposed system on a set of 400 applicants. Using a second crowdsourcing approach, we were able to confirm that the resulting solution provided a 92.5% correct assessment, with 6.45% false positives and 11.11% false negatives, with an assessment duration of 24 hours.",https://ieeexplore.ieee.org/document/6888682/,"15th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 June-2 July 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICODSE.2018.8705834,Microtask Crowdsourcing Marketplace for Social Network,IEEE,Conferences,"Crowdsourcing is a powerful way to process and collect data that needs human's logic and perception. Crowdsourcing can take part in many hard to compute problems such as data entry, multimedia transcriptions and many case of artificial intelligence. While this is a powerful approach, crowdsourcing needs a relatively large marketplace to works optimum. In context of Indonesia, we hardly hear about task crowdsourcing even though there are some marketplace like poin-web.co.id. In this paper, we propose a social network for crowdsourcing marketplace to penetrate the market. People tends to waste most of their time on social network and game rather than other mobile application in case of mobile usage. The idea is to make crowdsourcing as a filler while people are using social networks like waiting for a chat or scrolling the timeline. And by applying microtask as the task, people will not have much burden on doing the task. On the other hand, he/she will get additional income. We implemented LINE as a basis of our social network marketplace. LINE does provide the most interactive way of provide message. Additionally, the user of LINE in Indonesia is growing in a fast pace. We conduct an experiment focused on worker's coverage and ease of use. By using usability testing as a basis of ease of use evaluation, we received good feedbacks as 90.9% of the users feel easier to answer through LINE and is excited to use the platform in case it goes with real money.",https://ieeexplore.ieee.org/document/8705834/,2018 5th International Conference on Data and Software Engineering (ICoDSE),7-8 Nov. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RO-MAN47096.2020.9223436,Migratable AI: Effect of identity and information migration on users' perception of conversational AI agents,IEEE,Conferences,"Conversational AI agents are proliferating, embodying a range of devices such as smart speakers, smart displays, robots, cars, and more. We can envision a future where a personal conversational agent could migrate across different form factors and environments to always accompany and assist its user to support a far more continuous, personalized and collaborative experience. This opens the question of what properties of a conversational AI agent migrates across forms, and how it would impact user perception. To explore this, we developed a Migratable AI system where a user's information and/or the agent's identity can be preserved as it migrates across form factors to help its user with a task. We validated the system by designing a 2x2 between-subjects study to explore the effects of information migration and identity migration on user perceptions of trust, competence, likeability and social presence. Our results suggest that identity migration had a positive effect on trust, competence and social presence, while information migration had a positive effect on trust, competence and likeability. Overall, users report highest trust, competence, likeability and social presence towards the conversational agent when both identity and information were migrated across embodiments.",https://ieeexplore.ieee.org/document/9223436/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEBE.2018.00015,Mining Emotions of the Public from Social Media for Enhancing Corporate Credit Rating,IEEE,Conferences,"The proliferation of online social media has been changing the ways how individuals interact with corporations. Previous studies have examined how to extract investors' sentiments captured on social media to enhance stock prediction. However, little work was done to leverage public's emotions captured on social media to predict corporate credit risks. Our research fills the current research gap by developing a new computational method to extract public's emotions embedded in social postings to supplement common financial indicators (e.g., return-on-assets) for predicting corporate credit ratings. Grounded in Plutchik's Wheel of Emotions, the proposed computational framework can automatically extract the distribution of eight basic emotions from textual postings on online social media. In particular, one main contribution of our work is the development of the new emotion latent dirichlet allocation (ELDA) model for textual emotion analysis. In addition, we develop an ensemble learning model with random forest (RF) as the basis classifier to improve the performance of corporate credit rating. Based on the real-world data crawled from Twitter, our experimental results confirm that the proposed ELDA model can effectively and efficiently extract public's emotions from social postings to enhance the prediction of corporate credit ratings. To our best knowledge, this is the first successful research of developing a new computational model of extracting public's emotions from social postings to enhance corporate credit risk prediction.",https://ieeexplore.ieee.org/document/8592626/,2018 IEEE 15th International Conference on e-Business Engineering (ICEBE),12-14 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICASI.2017.7988441,Mining tweets for education reforms,IEEE,Conferences,"Microblogging and social networking sites have become a popular means of communication channels among internet users. They provide tools for people to voice their opinions. These sites contain vast amounts of opinionated data, leading to an increased growth in research on sentiment analysis and opinion mining. The study aims at using Twitter, a major and popular platform for microblogging and social communication, to conduct sentiment analysis. Real time data was automatically streamed using the Twitter API to collect the public's sentiments regarding education. A survey was also used to capture the public's opinions. The study will help overcome frustrations during implementation of education policies and reforms by taking into account the public's views and opinions.",https://ieeexplore.ieee.org/document/7988441/,2017 International Conference on Applied System Innovation (ICASI),13-17 May 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IEMCON53756.2021.9623097,Missing Data: Comparison of Multiple-Imputation Algorithms for Social Determinants of Health in Cervical Cancer Stage Detection,IEEE,Conferences,"Social Determinants of Health impact general health conditions within a population. However, missing data affect statistical analysis and forecasting of diseases. Multiple imputation has gained momentum and several machine learning algorithms have been used for data imputation. As most statistical analysis and machine learning software have already implemented these algorithms, their performance is usually taken for granted without further analysis. Furthermore, we notice a discrepancy between how imputation must be carried out and how it is usually performed in real-word practice. Thus, in this work we examine different machine learning algorithms for multiple imputation in two datasets with Social Determinants of Health in Cervical Cancer. The results of this comparison are presented.",https://ieeexplore.ieee.org/document/9623097/,"2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)",27-30 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICETC.2010.5529259,Model construct and case study of interpersonal interaction in virtual learning community,IEEE,Conferences,"Based on the interaction among the members of virtual learning community, the social computing software is a powerful tool. Exploring the connotative features of the model construction and the application process of the Interpersonal interaction among the community members from macro theoretical perspective to micro technical perspective will deepen understanding and value judgments of educational technology about social computing.",https://ieeexplore.ieee.org/document/5529259/,2010 2nd International Conference on Education Technology and Computer,22-24 June 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WI-IAT.2015.242,Modeling Curiosity in Virtual Companions to Improve Human Learners' Learning Experience,IEEE,Conferences,"A key design aspect for virtual learning companions is their believability. A lot of attention has been paid to emotion modeling which is at the core of believability. However, most of the existing emotion models neglect the epistemology-based emotions, which are knowledge-related emotions that affect the human learning process. Studies have shown that curiosity is an important epistemology-based emotion that positively influences social learning. Hence, modeling curiosity in learning companions may improve human learners' learning experience in a virtual environment. However, existing curiosity models assume simplified cognitive processes and fail to capture multiple sources of curiosity stimuli. In this paper, we propose a novel model of curiosity for learning companions to capture salient curiosity stimuli through a psychologically inspired approach. Our model is built based on Berlyne's theory and considers three most salient appraisal variables in a virtual learning environment, including novelty, surprise, and uncertainty. The model is built on planbased knowledge representations augmented with planning. Two internal processes are modeled for learning companions to demonstrate curiosity: curiosity appraisal and learning. The proposed model of curiosity is implemented in a learning companion and evaluated through user studies. The evaluation results show that the learning companion's curiosity significantly improves human learners' learning experience from multiple aspects.",https://ieeexplore.ieee.org/document/7397337/,2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT),6-9 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCMS.2010.265,Modeling and Simulating Multi-agent Model Connections: An Application to Information Paradigm,IEEE,Conferences,"This paper presents the information paradigm as a new vision which attempts to connect the conscious experience with the physical world. Two issues concerning this paradigm are investigated: the multi-agent model, which is the base of this theory, and the agent's relations, actually their information states. The relations between them, including their attributes and characteristics, participate in forming so called `baby universe' structures. The simulation of this multi-agent model is done in NetLogo 4.0.4., which is a programmable modeling environment for simulating natural and social phenomena. This environment is particularly well suited for modeling complex systems developing over time. We will simulate fully and partly connected networks in random and circuit arrangements. They will be investigated from mathematical perspective, as a strong support for the theory. As an application to this theory we'll calculate the rest mass ratio of the muon, electron and tauon sub particles, compared with the results obtained at CERN. The integration of the two perspectives offers the appropriate scientific foundation for the new paradigm and see the offering of the new vision of physical reality enabling to resolve some of the main barriers known in contemporary quantum mechanics and artificial intelligence.",https://ieeexplore.ieee.org/document/5421127/,2010 Second International Conference on Computer Modeling and Simulation,22-24 Jan. 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2012.138,Modelling Large Complex Systems Using Multi-agent Technology,IEEE,Conferences,"The paper outlines a method for modelling largescale commercial, social, socio-technological and engineering problems. The method is derived from twelve years of experience in designing and implementing large complex systems for real-time scheduling of taxis, air taxis, car rentals, seagoing tankers, trucks, space crafts; dynamic data mining; dynamic knowledge discovery and semantic search. The same approach has been also used for designing adaptive engineering systems and for research into social issues such as eradication of poverty.",https://ieeexplore.ieee.org/document/6299317/,"2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",8-10 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICACCI.2014.6968416,Modified MapReduce framework for enhancing performance of graph based algorithms by fast convergence in distributed environment,IEEE,Conferences,"The amount of data which is produced is huge in current world and more importantly it is increasing exponentially. Traditional data storage and processing techniques are ineffective in handling such huge data [10]. Many real life applications require iterative computations in general and in particular used in most of machine learning and data mining algorithms over large datasets, such as web link structures and social network graphs. MapReduce is a software framework for easily writing applications which process large amount of data (multi-terabyte) in parallel on large clusters (thousands of nodes) of commodity hardware. However, because of batch oriented processing of MapReduce we are unable to utilize the benefits of MapReduce in iterative computations. Our proposed work is mainly focused on optimizing three factors resulting in performance improvement of iterative algorithms in MapReduce environment. In this paper, we address the key issues based on execution of tasks, the unnecessary creation of new task in each iteration and excessive shuffling of data in each iteration. Our preliminary experiments have shown promising results over the basic MapReduce framework. The comparative study with existing solutions based on MapReduce framework like HaLoop, has also shown better performance w.r.t algorithm run time and amount of data traffic over Hadoop Cluster.",https://ieeexplore.ieee.org/document/6968416/,"2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",24-27 Sept. 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TrustCom50675.2020.00243,Monitoring Social Media for Vulnerability-Threat Prediction and Topic Analysis,IEEE,Conferences,"Publicly available software vulnerabilities and exploit code are often abused by malicious actors to launch cyberattacks to vulnerable targets. Organizations not only have to update their software to the latest versions, but do effective patch management and prioritize security-related patching as well. In addition to intelligence sources such as Computer Emergency Response Team (CERT) alerts, cybersecurity news, national vulnerability database (NBD), and commercial cybersecurity vendors, social media is another valuable source that facilitates early stage intelligence gathering. To early detect future cyber threats based on publicly available resources on the Internet, we propose a dynamic vulnerability-threat assessment model to predict the tendency to be exploited for vulnerability entries listed in Common Vulnerability Exposures, and also to analyze social media contents such as Twitter to extract meaningful information. The model takes multiple aspects of vulnerabilities gathered from different sources into consideration. Features range from profile information to contextual information about these vulnerabilities. For the social media data, this study leverages machine learning techniques specially for Twitter which helps to filter out non-cybersecurity-related tweets and also label the topic categories of each tweet. When applied to predict the vulnerabilities exploitation and analyzed the real-world social media discussion data, it showed promising prediction accuracy with purified social media intelligence. Moreover, the AI-enabling modules have been deployed into a threat intelligence platform for further applications.",https://ieeexplore.ieee.org/document/9343128/,"2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",29 Dec.-1 Jan. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CyberSecurity49315.2020.9138894,Moving Targets: Addressing Concept Drift in Supervised Models for Hacker Communication Detection,IEEE,Conferences,"In this paper, we are investigating the presence of concept drift in machine learning models for detection of hacker communications posted in social media and hacker forums. The supervised models in this experiment are analysed in terms of performance over time by different sources of data (Surface web and Deep web). Additionally, to simulate real-world situations, these models are evaluated using time-stamped messages from our datasets, posted over time on social media platforms. We have found that models applied to hacker forums (deep web) presents an accuracy deterioration in less than a 1-year period, whereas models applied to Twitter (surface web) have not shown a decrease in accuracy for the same period of time. The problem is alleviated by retraining the model with new instances (and applying weights) in order to reduce the effects of concept drift. While our results indicated that performance degradation due to concept drift is avoided by 50% relabelling, which is challenging in real-world scenarios, our work paves the way to more targeted concept drift solutions to reduce the re-training tasks.",https://ieeexplore.ieee.org/document/9138894/,2020 International Conference on Cyber Security and Protection of Digital Services (Cyber Security),15-19 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RACSS.2012.6212691,MuGRAM: An approach for multi-labelled graph matching,IEEE,Conferences,"Graph mining has been a widely studied domain over the years. Graph representation of real world problems has enabled the development of simple solutions bringing in better clarity. Graph mining has various sub domains among which graph matching is a prominent one having a number of algorithms. With the rise of new applications involving large sets of networked data, the performance of these algorithms has become important. The graph based representations for social networks and communication networks have led to the evolution of multi-labelled large graphs which are still not completely handled by the existing algorithms. The requirement of a fast and efficient indexing process so as to accommodate dynamic graphs without having to opt for incremental indexing is another major challenge. In this paper, we propose MuGRAM - a multi-labelled graph matching approach aimed at addressing the above mentioned issues. This approach is capable of handling multiple labels for vertices as well as edges of reference graphs. An enhanced indexing method proposed in the paper ensures a fast indexing process. A breadth first search oriented spanning tree along with a novel technique for neighbourhood matching ensures fast query processing. Experimental evaluation of MuGRAM in comparison with some of the recent algorithms in the field highlights its superior performance.",https://ieeexplore.ieee.org/document/6212691/,2012 International Conference on Recent Advances in Computing and Software Systems,25-27 April 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN52387.2021.9534428,Multi-Modal Multi-Instance Multi-Label Learning with Graph Convolutional Network,IEEE,Conferences,"When applying machine learning to tackle realworld problems, it is common to see that objects come with multiple labels rather than a single label. In addition, complex objects can be composed of multiple modalities, e.g. a post on social media may contain both texts and images. Previous approaches typically treat every modality as a whole, while it is not the case in real world, as every post may contain multiple images and texts with quite diverse semantic meanings. Therefore, Multi-modal Multi-instance Multi-label (M3) learning was proposed. Previous attempt at M3 learning argues that exploiting label correlations is crucial. In this paper, we find that we can handle M3 problems using graph convolutional network. Specifically, a graph is built over all labels and each label is initially represented by its word embedding. The main goal for GCN is to map those label embed dings into inter-correlated label classifiers. Moreover, multi-instance aggregation is based on attention mechanism, making it more interpretable because it naturally learns to discover which pattern triggers the labels. Empirical studies are conducted on both benchmark datasets and industrial datasets, validating the effectiveness of our method, and it is demonstrated in ablation studies that the components in our methods are essential.",https://ieeexplore.ieee.org/document/9534428/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIS53314.2022.9742828,Multi-Parameter Smart Health Monitoring System using Internet of Things,IEEE,Conferences,"Low-cost, lightweight, tiny, and intelligent physiological sensor nodes have been designed in the recent technical developments in sensor systems, low power integrated circuits and wireless communications. These sensor nodes can detect analyses and transmit one or more vital signs and can be incorporated smoothly into healthcare social sensor networks. This network promises to change healthcare by enabling cheap, invasive, ongoing ambulatory health surveillance with online medical data updated nearly in real time. Despite several continuous research efforts, several technological, economic and societal issues are essential to the There are still some technological challenges to be addressed in order to develop diverse social sensor networks applicable to medical, economic and social and power efficiency applications. In this proposed work, novel method which is used to track patients in hospitals at home as well. The experimental analysis starts with the implementation of IoT sectors, mainly an Arduino-UNO health observation scheme. Patient&#x2019;s cardiac rates and body temperature is monitor in the proposed work. Arduino-UNO is used as the 8-bit microcontroller, ATMEGA 328. LM 35 is used for body temperature sensing, and XD-58C for cardiac beat rate measurement is used for DIY pulse tracker. Wi-Fi module EP8266 is used to move the data of the patient from the Arduino uno node. For IoT purposes, the BLYNK programmer is used. A new algorithm is proposed which is named as CBHA (Sensor clustering based Human Activities Recognition) that analyze state of the Patient. The data transferred from the WiFi module can be used from anywhere in the app, meaning that doctors can watch patients remotely and take prompt decisions if something goes wrong with the information that has been detected.",https://ieeexplore.ieee.org/document/9742828/,2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS),23-25 Feb. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/LCN52139.2021.9524999,Multi-level Graph Attention Network based Unsupervised Network Alignment,IEEE,Conferences,"Network alignment is the matching of two networks with corresponding nodes that belong to the same user or entity. The most common application is to analyze which accounts belong to the same user in two social networks. Most of existing techniques rely on matrix factorization so that they cannot be scaled to large-scale networks, are constrained by strict constraints, and cannot learn node embedding without a training set. In this paper, we propose an unsupervised network alignment model based on multi-level graph attention networks. The model uses multi-level graph attention network to learn the embedded representation of nodes, satisfying attribute and structure constraints of alignment. Augmented learning process is proposed to simulate attribute noise and structural noise to improve adaptability of the model. Extensive experiments on real datasets show that the proposed model performs better than the state-of-the-art network alignment model. We also demonstrate the robustness of the proposed model.",https://ieeexplore.ieee.org/document/9524999/,2021 IEEE 46th Conference on Local Computer Networks (LCN),4-7 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SMARTCOMP50058.2020.00051,Multi-modal Adversarial Training for Crisis-related Data Classification on Social Media,IEEE,Conferences,"Social media platforms such as Twitter are increasingly used to collect data of all kinds. During natural disasters, users may post text and image data on social media platforms to report information about infrastructure damage, injured people, cautions and warnings. Effective processing and analysing tweets in real time can help city organisations gain situational awareness of the affected citizens and take timely operations. With the advances in deep learning techniques, recent studies have significantly improved the performance in classifying crisis-related tweets. However, deep learning models are vulnerable to adversarial examples, which may be imperceptible to the human, but can lead to model's misclassification. To process multi-modal data as well as improve the robustness of deep learning models, we propose a multi-modal adversarial training method for crisis-related tweets classification in this paper. The evaluation results clearly demonstrate the advantages of the proposed model in improving the robustness of tweet classification.",https://ieeexplore.ieee.org/document/9239612/,2020 IEEE International Conference on Smart Computing (SMARTCOMP),14-17 Sept. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BIBM52615.2021.9669328,Multi-modal Information Fusion-powered Regional Covid-19 Epidemic Forecasting,IEEE,Conferences,"With the current raging spread of the COVID19, early forecasting of the future epidemic trend is of great significance to public health security. The COVID-19 is virulent and spreads widely. An outbreak in one region often triggers the spread of others, and regions with relatively close association would show a strong correlation in the spread of the epidemic. In the real world, many factors affect the spread of the outbreak between regions. These factors exist in the form of multimodal data, such as the time-series data of the epidemic, the geographic relationship, and the strength of social contacts between regions. However, most of the current work only uses historical epidemic data or single-modal geographic location data to forecast the spread of the epidemic, ignoring the correlation and complementarity in multi-modal data and its impact on the disease spread between regions. In this paper, we propose a Multimodal InformatioN fusion COVID-19 Epidemic forecasting model (MINE). It fuses inter-regional and intra-regional multi-modal information to capture the temporal and spatial relevance of the COVID-19 spread in different regions. Extensive experimental results show that the proposed method achieves the best results compared to state-of-art methods on benchmark datasets.",https://ieeexplore.ieee.org/document/9669328/,2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),9-12 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICECE48499.2019.9058508,Multi-modal Neural Network for Traffic Event Detection,IEEE,Conferences,"Cities are composed of complex systems with Cyber, Physical, and Social (CPS) components. The advances in the Internet of Things (IoTs) and social networking services help people understand the dynamics of cities. Traffic event detection is an important while complex task in transportation modeling and management of smart cities. In this paper, we address the task of detecting traffic events using two types of data, i.e. physical sensor observations and social media text. Unlike most existing studies focused on either analysing sensor observations or social media data, we identify traffic events with both types of data that may complement each other. We propose a Multi-modal Neural Network (MMN) to process sensor observations and social media texts simultaneously and detect traffic events. We evaluate our model with a real-world CPS dataset consisting of sensor observations, event reports, and tweets collected from Twitter about San Francisco over a period of 4 months. The evaluation shows promising results and provides insights into the analysis of multi-modal data for detecting traffic events.",https://ieeexplore.ieee.org/document/9058508/,2019 IEEE 2nd International Conference on Electronics and Communication Engineering (ICECE),9-11 Dec. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00189,Multi-network Embedding for Missing Point-of-Interest Identification,IEEE,Conferences,"The large volume of data flowing throughout location-based social networks (LBSNs) provides an opportunity for human mobility behavior understanding and prediction. However, data quality issues (e.g., historical check-in POI missing, data sparsity) limit the effectiveness of existing LBSN-oriented studies, e.g., Point-of-Interest (POI) recommendation or prediction. Contrary to previous efforts in next POI recommendation or prediction, we focus on identifying the missing POI which the user has visited at a past specific time and proposed a multi-network Embedding (MNE) method. Specifically, the model jointly captures temporal cyclic effect, user preference and sequence transition influence in a unified way by embedding five relational information graphs into a shared dimensional space from both POI- and category-instance levels. The proposed model also incorporates region-level spatial proximity to explore geographical influence, and derives the ranking score list of candidates for missing POI identification. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets, and the experimental results show its superiority over other competitors. Significantly, it also proves that the proposed model can be naturally transferred to general next POI recommendation and prediction tasks with competitive performances.",https://ieeexplore.ieee.org/document/9644693/,"2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",30 Sept.-3 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2010.123,Multi-relational Topic Model for Social Recommendation,IEEE,Conferences,"Various attribute and relation information is used in social recommendation systems. However, previous approaches fail to use them in a unified way. In this paper, we propose a unified framework for social recommendation. Entities like users and items are described by their tags. We model each entity using topic models like Latent Dirichlet Allocation(LDA) and then connect these topic models to form a multi-relational network. Various relations between entities in recommender systems such as rating relation or user friend relation can be expressed as edges in the multi-relational network. We evaluate our model on a real-life dataset collected from a commercial recommender website. Experiments validate the generative performance and predictive performance of our model.",https://ieeexplore.ieee.org/document/5670084/,2010 22nd IEEE International Conference on Tools with Artificial Intelligence,27-29 Oct. 2010,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CVPR42600.2020.01469,Multimodal Categorization of Crisis Events in Social Media,IEEE,Conferences,"Recent developments in image classification and natural language processing, coupled with the rapid growth in social media usage, have enabled fundamental advances in detecting breaking events around the world in real-time. Emergency response is one such area that stands to gain from these advances. By processing billions of texts and images a minute, events can be automatically detected to enable emergency response workers to better assess rapidly evolving situations and deploy resources accordingly. To date, most event detection techniques in this area have focused on image-only or text-only approaches, limiting detection performance and impacting the quality of information delivered to crisis response teams. In this paper, we present a new multimodal fusion method that leverages both images and texts as input. In particular, we introduce a cross-attention module that can filter uninformative and misleading components from weak modalities on a sample by sample basis. In addition, we employ a multimodal graph-based approach to stochastically transition between embeddings of different multimodal pairs during training to better regularize the learning process as well as dealing with limited training data by constructing new matched pairs from different samples. We show that our method outperforms the unimodal approaches and strong multimodal baselines by a large margin on three crisis-related tasks.",https://ieeexplore.ieee.org/document/9157116/,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),13-19 June 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/GRC.2009.5255152,Multiview spectral clustering via ensemble,IEEE,Conferences,"Clustering on multiple views is witnessing increasing interests in both real-world application and machine learning community. A typical application is to discover communities of joint interests in social network, such as Facebook and Twitter. The network can be simply modeled as a graph in which the nodes are the people while the links show relationship between the people. There may exist many relationships between a pair of nodes, such as classmates, collaborators, playmates and so on. It is important to consider how to use these graphs together rather than a single graph if we want to understand the network and their participants effectively. Motivated by the fact, we present a clustering algorithm using spectral analysis in which multiple graphs are considered to get the clusters. Our study can also be considered as an instance of multi-views learning. The experimental results on UCI data set and Corel image data demonstrate the promising results that validate our proposed algorithm.",https://ieeexplore.ieee.org/document/5255152/,2009 IEEE International Conference on Granular Computing,17-19 Aug. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TENCON.2009.5396250,Neuro-fuzzy decision trees for content popularity model and multi-genre movie recommendation system over social network,IEEE,Conferences,"In this paper, we propose a framework of multi-genre movie recommender system based on neuro-fuzzy decision tree (NFDT) methodology. The system is capable of recommending list of movies in descending order of preference in response to user queries and profiles. The system also takes care of attempt to vote stuffing using novel application of fuzzy c-means clustering algorithm. Typical user query and profiles consists of content ratings for multiple genres like action, comedy, drama, music and many others. The distinctive point of the proposed approach is to handle recommender system generation as a supervised pattern classification problem, where in user reviews for multiple genres are conditions and overall star ratings are decisions. The entire recommender system is represented in the form of NFDT. Rules represented by NFDT also acts as a tool for understanding the combinations of contents driving popularity (and unpopularity) over certain social network. We have also proposed a modified inference mechanism based on matching and ordering of firing strength of each fuzzy decision tree path in response to user queries. The computational experiments have been presented on a sample real-world movie review database to judge the efficiency of the proposed recommender system.",https://ieeexplore.ieee.org/document/5396250/,TENCON 2009 - 2009 IEEE Region 10 Conference,23-26 Jan. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICECET52533.2021.9698712,OCR Error Correction Using BiLSTM,IEEE,Conferences,"Language models have critical importance in the pre- and post-processing of optical character recognition (OCR). The quality of documents and scanners is important for OCR systems, with inferior quality leading to more erroneous output. For long time intervals of sequences, long short-term memory (LSTM) fulfills the requirements because it can solve problems with long-term dependencies. In this study, we evaluate the performance of error correction for OCR data using LSTM. The results show that we have good performance for correcting error words by using bidirectional LSTM (BiLSTM). We obtain 98.13&#x0025; better performance in correcting error words by using OCRd data and 97.18&#x0025; better performance by using social media data. In this respect, we show that the method we have applied can be used for error corrections.",https://ieeexplore.ieee.org/document/9698712/,"2021 International Conference on Electrical, Computer and Energy Technologies (ICECET)",9-10 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CLEI53233.2021.9639989,ODROM: Object Detection and Recognition supported by Ontologies and applied to Museums,IEEE,Conferences,"In robotics, object detection in images or videos, obtained in real-time from sensors of robots can be used to support the implementation of service robot tasks (e.g., navigation, model its social behavior, recognize objects in a specific domain), usually accomplished in indoor environments. However, traditional deep learning based object detection techniques present limitations in such indoor environments, specifically related to the detection of small objects and the management of high density of multiple objects. Coupled with these limitations, for specific domains (e.g., hospitals, museums), it is important that the robot, apart from detecting objects, extracts and knows information of the targeted objects. Ontologies, as a part of the Semantic Web, are presented as a feasible option to formally represent the information related to the objects of a particular domain. In this context, this work proposes an object detection and recognition process based on a Deep Learning algorithm, object descriptors, and an ontology. ODROM, an Object Detection and Recognition algorithm supported by Ontologies and applied to Museums, is an implementation to validate the proposal. Experiments show that the usage of ontologies is a good way of desambiguating the detection, obtained with a and <tex>$\mathbf{mAP}{@}0.5=0.88$</tex> and a <tex>$\mathbf{mAP}{@}[0.5:0.95]=61\%$</tex>.",https://ieeexplore.ieee.org/document/9639989/,2021 XLVII Latin American Computing Conference (CLEI),25-29 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigData52589.2021.9671426,Object Interaction Recommendation with Multi-Modal Attention-based Hierarchical Graph Neural Network,IEEE,Conferences,"Object interaction recommendation from Internet of Things (IoT) is a crucial basis for IoT related applications. While many efforts are devoted to suggesting object for interaction, the majority of models rigidly infer relationships from human social network, overlook the neighbor information in their own object social network and the correlation of multiple heterogeneous features, and ignore multi-scale structure of the network. To tackle the above challenges, this work focuses on object social network, formulates object interaction recommendation as multi-modals object ranking, and proposes Multi-Modal Attention-based Hierarchical Graph Neural Network (MM-AHGNN), that describes object with multiple knowledge of actions and pairwise interaction feature, encodes heterogeneous actions with multi-modal encoder, integrates neighbor information and fuses correlative multi-modal feature by intra-modal hybrid-attention graph convolution and inter-modal transformer encoder, and employs multi-modal multi-scale encoder to integrate multi-level information, for suggesting object interaction more flexibly. With extensive experiments on real-world datasets, we prove that MMAHGNN achieves better recommendation results (improve 3-4% HR@3 and 4-5% NDCG@3) than the most advanced baseline. To our knowledge, our MM-AHGNN is the first research in GNN design for object interaction recommendation. Source codes are available at: https://github.com/gaosaroma/MM-AHGNN.",https://ieeexplore.ieee.org/document/9671426/,2021 IEEE International Conference on Big Data (Big Data),15-18 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTUS.2017.8285967,Ongoing research agenda on the Internet of Things (IoT) in the context of Artificial Intelligence (AI),IEEE,Conferences,"This talk presents our ongoing research agenda on the Internet of Things (IoT) in the context of Artificial Intelligence (AI). sThree initiatives define this agenda: integration of IoT into business process management, agentification of things, and mutation of things. IoT is among the latest ICT developments that is making the boundaries between reality and fiction vanish. According to Mark Weiser, “…The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it”i. And according to Gartnerii, 6.4 billion connected things were in use in 2016, up 3% from 2015, and will reach 20.8 billion by 2020. In the first initiative, we adopt storytelling principles to design and develop Process of Things (PoT). A PoT is specified as a story whose script indicates the characters that things will play as well as the scenes that will feature these things. A PoT also allows things to collaborate by offering value-added services to end-users. A system implementing PoT will be presented during the talk. In the second initiative, we shed the light on some obstacles that are slowing downIoTexpansion and adoption, for instance diversity of things' development technologies and communication standards, users' reluctance and sometimes rejection due to privacy invasion, lack of killer applications that would demonstrate their necessity, lack of an IoT-oriented software engineering discipline, and finally, the passive nature of things. Because of this nature, things are restricted to sending data to third parties or (basic) processing data prior to their transfer to third parties, too. We are examining how to empower things with additional capabilities that would make them proactive. This means that things can for instance, reach out to peers that expose collaborative attitude, form dynamic communities when necessary, avoid peers that expose malicious attitude, be accountable for their actions, etc. While we already see some encouraging signs of thing empowerment through initiatives like semantic things, Internet of social things, Internet of agents, and agents of things, we propose the agentification of things from a conceptual perspective exemplified with norms and an operational perspective exemplified with commitments. In conjunction with thing agentification, we present during the talk the third initiative that examines thing mutation in the sense that things will bind and/or unbind capabilities on the fly (and as they see fit). To ensure mutation success we consider first, the context in which things operate and second, policies that impact things' decisions to bind/unbind capabilities. We motivate mutation decisions with 3 factors: performance so that a thing remains competitive/attractive, adaptation so that a thing remains responsive, and survivability so that a thing remains in business.",https://ieeexplore.ieee.org/document/8285967/,2017 International Conference on Infocom Technologies and Unmanned Systems (Trends and Future Directions) (ICTUS),18-20 Dec. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AiDAS53897.2021.9574386,Online Shopping Preferences Visualization System Using Web Content Mining,IEEE,Conferences,"Recently, social media sites have been attracting people to start and operate online business. It has been gaining more attention especially during this COVID-19 pandemic, where most activities are conducted via online platform. For instance, Instagram is one of the social media platform where people share and post their pictures and videos on their account, but some people take this opportunity to promote their business and shop online via features provided by Instagram. Based on observation, there is no specific function that visualizes the information of Instagram's business accounts to help people in gaining information and making decisions during shopping process. Thus, a system that specifically visualizes Instagram's extracted data was developed using Web Content Mining technique with the assistance of hashtags as data-points and Phantombuster API. Tableau software integrated with JavaScript library is used as a visualization tool to display the users shopping activities. The result of the extracted data was visualized in the form of Bubble Chart, Bar Chart, and Multiple Bar Chart that were placed in different dashboards. The results from the obtained functional testing and users' feedbacks have indicated 64.3% of the respondents agreed that the proposed system helps users in making the right choice during online shopping. However, this system has some limitation that could be further enhanced such as updating the information automatically in real time without using any manpower and to increase the interactivity between system and user instead of using static visualization graphs.",https://ieeexplore.ieee.org/document/9574386/,2021 2nd International Conference on Artificial Intelligence and Data Sciences (AiDAS),8-9 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SSP.2016.7551730,Online low-rank subspace learning from incomplete data using rank revealing ℓ2/ℓ1 regularization,IEEE,Conferences,"Massive amounts of data (also called big data) generated by a wealth of sources such as social networks, satellite sensors etc., necessitate the deployment of efficient processing tools. In this context, online subspace learning algorithms that aim at retrieving low-rank representations of data constitute a mainstay in many applications. Working with incomplete (partially observed) data has recently become commonplace. Moreover, the knowledge of the real rank of the sought subspace is rarely at our disposal a priori. Herein, a novel low-rank subspace learning algorithm from incomplete data is presented. Its main premise is the online processing of incomplete data along with the imposition of low-rankness on the sought subspace via a sophisticated utilization of the group sparsity inducing ℓ2/ℓ1 norm. As is experimentally shown, the resulting scheme is efficient in accurately learning the subspace as well as in unveiling its real rank.",https://ieeexplore.ieee.org/document/7551730/,2016 IEEE Statistical Signal Processing Workshop (SSP),26-29 June 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IMCCC.2015.348,Ontology Based Service Recommendation System for Social Network,IEEE,Conferences,"The development of recommendation systems, such as traditional content-based, collaborative filtering and hybrid recommendation approaches have enabled the practical use of big data processing in WEB 3.0. In this paper, we propose an ontology based service recommendation system for social network. In this paper, implementation methods of the system are explained in detail. In order to extract user interests more exactly, the TF-IDF (term frequency-inverse document frequency) algorithm is improved according to the features of Micro logs and integrated with the Text Rank algorithm. Also, we have improved the Hownet based semantic similarity algorithm with the consideration of the density of sememe tree. Experimental results show that recommendation results of our system can well reflect the real interests of users, and the improved algorithms can make the results more accurate.",https://ieeexplore.ieee.org/document/7406129/,"2015 Fifth International Conference on Instrumentation and Measurement, Computer, Communication and Control (IMCCC)",18-20 Sept. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC.2017.4,Ontology-Based Social Media Analysis for Urban Planning,IEEE,Conferences,"This paper reports a social media analysis study proposed by the Beijing Municipal Institute of Urban Planning and Design. The purpose is to explore techniques that can help the urban planning administrations to improve the social sensing and social perception abilities under the evolving data and technology environments. A framework integrating a comprehensive set of text mining algorithms is presented to conduct topic modeling, text clustering, event evolution detection, sentiment analysis, opinion mining, and information extraction on user-generated contents in Chinese social media. A domain ontology of Beijing urban planning is constructed to facilitate the text mining processes. Evaluations on two large, real-world datasets composed of microblogs and WeChat articles about the residential community and school education in Beijing demonstrate the effectiveness of our framework. The study illustrates the power of combining machine learning with knowledge-based, semantic approaches in analyzing social media for the domain of interest.",https://ieeexplore.ieee.org/document/8029714/,2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC),4-8 July 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISM52913.2021.00035,Open-Domain Trending Hashtag Recommendation for Videos,IEEE,Conferences,"We describe a novel algorithm for an open-domain trending hashtag recommendation task using zero-shot hashtag prediction in an online learning paradigm. Our method utilizes joint representation learning of latent embeddings for features extracted from long-form videos and semantic embeddings of hashtags trending on social platforms. In particular, we apply graph convolutional networks to a link prediction task using videos and hashtags as nodes in a heterogeneous graph. Comparing it to the existing models for closely related tasks, we demonstrate state-of-the-art results in trending hashtag recommendations for videos. The architecture is designed to be modular in a plug-and-play fashion to enable quick and easy incorporation of the latest advances in natural language understanding and image and video processing, with a practical view to its implementation in a real-time, online setting.",https://ieeexplore.ieee.org/document/9666058/,2021 IEEE International Symposium on Multimedia (ISM),29 Nov.-1 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCIS49240.2020.9257675,Optimal Short Term Power Load Forecasting Algorithm by Using Improved Artificial Intelligence Technique,IEEE,Conferences,"Electrical load forecasting plays a significant impact in terms of future power generation systems such as smart grid, power demand approximation, and better energy management system. Therefore, high accuracy is needed for different time horizons related to regulating, dispatch and scheduling of power system grid. However, it is difficult to do energy prediction with high precision because of influencing factors such as climate, social and seasonal factors. Artificial Intelligence (AI) and Support Vector Machine (SVM) are proved to be capable of handle complex systems and deployed worldwide in many applications due to its superiority on other techniques. The improved short term load forecasting algorithm has been introduced in this research to analyze, discuss and deal with the enhanced electrical power system. The related constraints, influential factors are given and the experimental results can be validated by the effective outcome.",https://ieeexplore.ieee.org/document/9257675/,2020 2nd International Conference on Computer and Information Sciences (ICCIS),13-15 Oct. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAL.2009.5262851,Optimal control of continuous annealing process using PSO,IEEE,Conferences,"The continuous annealing furnace is one of the main equipments in the continuous annealing production line for iron and steel enterprise, and has a direct impact on the quality of cold-rolled strip steel, production and cost. The temperature control of continuous annealing furnace is a complex industrial process which is difficult to control. It is difficult to obtain a good control result by using the traditional control method, so a temperature control method with good performance is of great significance. Particle swarm optimization (PSO) has evolved recently as an important branch of stochastic techniques to explore the search space for optimization (Kennedy & Eberhart, 1995). The motivation for the development of this method is based on simulation of simplified social behavior such as bird flocking or fish schooling. Nowadays, PSO has been developed to be real competitor with other well-established techniques for population-based evolutionary computation. PSO has many advantages over other evolutionary computation techniques (for example, genetic algorithms (GAs)), such as simpler implementation, faster convergence rate and fewer parameters to adjust. The proposed scheme is applied to the optimal of the continuous annealing process. Simulation shows the proposed approach is effective.",https://ieeexplore.ieee.org/document/5262851/,2009 IEEE International Conference on Automation and Logistics,5-7 Aug. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ECDC.2014.6836746,Out-network traffic terms: A case study in LinkedIn 1,IEEE,Conferences,"Terms in the use of LinkedIn, as one of the important elements in this website will serve an important role in regulating the flow of traffic. The study of the integration of these terms can be a significant step to avoid congestion and (Users') rejection in the network. Integration of Traffic Control Terms (TCT) between LinkedIn and other social networks is one of the best solutions to establish consequent traffic flow out of the network. Depending on the conditions, integration can be done in different ways. This article examines the direct pass and indirect pass methods. Node phase differences are key elements for integration of LinkedIn considered in this review. To calculate the optimal phasing and appropriate phase difference, first the status of a user in LinkedIn has been analyzed using software, and then the results have been simulated by charting. In this article, the Integration of TCT was done based on evaluation of the TCT performance through determining the appropriate phase differences and reference rule and calculating the measurement of Latency (LT) in the main network port. This latency was calculated as the difference of the expected time and real time of connection or login to the network in simulated conditions. The achieved results indicate that in unsaturated conditions using indirect pass method and in saturated conditions, due to rejection of user and inability of network TCT, using indirect pass method is the best choice for integration of the TCT for LinkedIn and other social networks.",https://ieeexplore.ieee.org/document/6836746/,8th International Conference on e-Commerce in Developing Countries: With Focus on e-Trust,24-25 April 2014,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DeSE51703.2020.9450783,Overcoming Speech Anxiety Using Virtual Reality with Voice and Heart Rate Analysis,IEEE,Conferences,"Social phobias are afflictions that millions of people suffer from. One common social phobia is speech anxiety (Glossophobia), which makes it difficult for people to talk in public or with others. To address this problem, this system was created to help people with Glossophobia practice making presentations or having personal interviews with less fear. The objective is to train them before their presentations or interviews by simulating 360° video environments with virtual reality (VR) technology. During the practice, the system analyzes the voice and heart rate of the person to discover any emotional and physical symptoms of speech anxiety using Arduino heart rate sensors, machine learning, and speech recognition techniques. The system will generate advice based on the symptoms to help make the user more confident. Additionally, after several training sessions, the system will present a report showing the progress in the user's performance. The system has been fully implemented and has demonstrated its operational effectiveness.",https://ieeexplore.ieee.org/document/9450783/,2020 13th International Conference on Developments in eSystems Engineering (DeSE),14-17 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.23919/ICMU48249.2019.9006662,PBEM: A Pattern-Based Embedding Model for User Location Category Prediction,IEEE,Conferences,"With the rapid popularity of mobile devices, a vast amount of trajectory-based check-in data are shared in many social network applications, which is an important data source for user location prediction. The location category prediction, a branch of location prediction, is a vital task in a wide range of areas, including urban planning, advertising and recommendation systems. In this paper, we propose a novel two-step Pattern-Based Embedding Model (PBEM) for predicting the next location category that user will go to. Based on the observation that some users behave frequently in a similarity pattern, a new feature termed as user cluster label is defined. In order to mine user's behavior patterns and extract the cluster label, a Category-Importance-Decay learning strategy is proposed and implemented, which provides a quantitative standard for evaluating the importance of each category. Thus, a comprehensive feature set is obtained including user, time, historical location category, text content, and user cluster label, which greatly enhances the robustness of data representation and contains more knowledge. Then the extracted feature set is fed into Recurrent Neural Network (RNN) in a unified framework, which improves the prediction accuracy. We evaluate the performance of PBEM on two real-life trajectory-based check-in datasets. Experimental results demonstrate that the proposed model can outperform the state-of-the-art methods.",https://ieeexplore.ieee.org/document/9006662/,2019 Twelfth International Conference on Mobile Computing and Ubiquitous Network (ICMU),4-6 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPS47924.2020.00100,PCGCN: Partition-Centric Processing for Accelerating Graph Convolutional Network,IEEE,Conferences,"Inspired by the successes of convolutional neural networks (CNN) in computer vision, the convolutional operation has been moved beyond low-dimension grids (e.g., images) to high-dimensional graph-structured data (e.g., web graphs, social networks), leading to graph convolutional network (GCN). And GCN has been gaining popularity due to its success in real-world applications such as recommendation, natural language processing, etc. Because neural network and graph propagation have high computation complexity, GPUs have been introduced to both neural network training and graph processing. However, it is notoriously difficult to perform efficient GCN computing on data parallel hardware like GPU due to the sparsity and irregularity in graphs. In this paper, we present PCGCN, a novel and general method to accelerate GCN computing by taking advantage of the locality in graphs. We experimentally demonstrate that real-world graphs usually have the clustering property that can be used to enhance the data locality in GCN computing. Then, PCGCN proposes to partition the whole graph into chunks according to locality and process subgraphs with a dual-mode computing strategy which includes a selective and a full processing methods for sparse and dense subgraphs, respectively. Compared to existing state-of-the-art implementations of GCN on real-world and synthetic datasets, our implementation on top of TensorFlow achieves up to 8.8× speedup over the fastest one of the baselines.",https://ieeexplore.ieee.org/document/9139807/,2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS),18-22 May 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IDAACS53288.2021.9660949,PER-COVID (PEople pRoximity based on Certified and coOperative VIDeo-intelligence): A Software Tool for Physical Distancing and PPE Monitoring,IEEE,Conferences,"The recent COVID-19 pandemic has led to a growing interest in IT tools for monitoring social distance and for checking the presence of personal protective equipment and whether it is worn properly. Correct monitoring in outdoor and indoor areas is essential to limit the spread of the virus and the risk of being infected. This paper presents PER-COVID, a software platform capable of monitoring crowds of people and the correct use of personal protective equipment in real time using innovative computer vision algorithms. The proposed system architecture and functional characteristics are illustrated, as well as some user interface screens are provided for simple interpretation and monitoring of critical events.",https://ieeexplore.ieee.org/document/9660949/,2021 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS),22-25 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPSW.2017.178,Parallel Computing for Machine Learning in Social Network Analysis,IEEE,Conferences,"Machine learning, especially deep learning, is revolutionizing how many engineering problems are being solved. Three critical ingredients are needed to apply deep machine learning to significant real world problems: i.) large data sets; ii.) software to implement deep learning and; iii.) significant computing cycles. This paper discusses the state of each ingredient with a specific focus on: a.) how deep learning can apply to large-scale social network analysis and; b.) the computing resources required to make such analyses feasible.",https://ieeexplore.ieee.org/document/7965209/,2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),29 May-2 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ISPAN.2004.1300454,Particle swarm optimization algorithm in signal detection and blind extraction,IEEE,Conferences,"The particle swarm optimization (PSO) algorithm, which originated as a simulation of a simplified social system, is an evolutionary computation technique. In this paper the binary and real-valued versions of PSO algorithm are exploited in two important signal processing paradigm: multiuser detection (MUD) and blind extraction of sources (BES), respectively. The novel approaches are effective and efficient with parallel processing structure and relatively feasible implementation. Simulation results validate either PSO-MUD or PSO-BES has a significant performance improvement over conventional methods.",https://ieeexplore.ieee.org/document/1300454/,"7th International Symposium on Parallel Architectures, Algorithms and Networks, 2004. Proceedings.",10-12 May 2004,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CCIS.2016.7790307,Passengers' choices on airport drop-off service: A decision forecast based on social learning and machine learning,IEEE,Conferences,"Airport drop-off service provided by airlines is a chauffeur-driven service (i.e. Uber and DiDi) as an emerging travel choice for travelers. More and more passenger enjoy the drop-off service. In practice, we find an interesting question: if a passenger has ever choice the drop-off service, whether they are willing to recommend this service to other traveler? Although the acknowledgment that social learning is related to travel decision is promoted, quantitative analysis about how social learning shape and impact the decision of passengers is still limited. We study and estimate a diffusion probability between different passengers by proposing a CCM (Co-travel Link Cascade Model) based on a modified EM iterative algorithm. Then, we segment passengers into three types (Influenced, Unchecked and Immune). The three types of passengers are predicated by approaches of IC-like model, Random Forest model and probabilistic model, respectively. In addition, we also design a parallel implementation of our proposed algorithm in the Apache Spark distributed data processing environment. Experimental results on a real aviation data set demonstrate that CCM can efficiently infer the decision of travelers.",https://ieeexplore.ieee.org/document/7790307/,2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS),17-19 Aug. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCWorkshops50388.2021.9473673,Passive WiFi CSI Sensing Based Machine Learning Framework for COVID-Safe Occupancy Monitoring,IEEE,Conferences,"The COVID-19 pandemic requires social distancing to prevent transmission of the virus. Monitoring social distancing is difficult and expensive, especially in ""travel corridors"" such as elevators and commercial spaces. This paper describes a low-cost and non-intrusive method to monitor social distancing within a given space, using Channel State Information (CSI) from passive WiFi sensing. By exploiting the frequency selective behaviour of CSI with a cubic SVM classifier, we count the number of people in an elevator with an accuracy of 92%, and count the occupancy of an office to 97%. As opposed to using a multi-class counting approach, this paper aggregates CSI for the occupancies below and above a COVID-Safe limit. We show that this binary classification approach to the COVID safe decision problem has similar or better accuracy outcomes with much lower computational complexity, allowing for real-world implementation on IoT embedded devices. Robustness and scalability is demonstrated through experimental validation in practical scenarios with varying occupants, different environment settings and interference from other WiFi devices.",https://ieeexplore.ieee.org/document/9473673/,2021 IEEE International Conference on Communications Workshops (ICC Workshops),14-23 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW51313.2020.00067,Pelican: Continual Adaptation for Phishing Detection,IEEE,Conferences,"An increasing number of people are using social media services and with it comes a more attractive outlet for phishing attacks. Our initial focus is to analyze Twitter as it is one of the most popular social media services. Phishers on Twitter curate tweets that lead users to websites that download malware. This is a major issue as phishers can then gain access to the user's digital identity and perform malicious acts. Phishing attacks have the potential to be similar in different regions, perhaps at different times. We have developed a novel semi-supervised machine learning algorithm, which we call Pelican, that detects potential phishing attacks in real-time on Twitter. Pelican can be used for early detection of potential phishing attacks and is able to detect potential new attacks without pre-existing assumptions about the type of data or understanding of the characteristics of the attacks. The technique uses ensembles and sampling methods to handle class imbalances in real-world applications. The technique continuously detects unusual behaviour or changes in Twitter. We have investigated changes in trends across Twitter to detect changes in online behaviour of potential phishing links. The technique uses a change detector that enables automatic retraining when there is unusual behaviour detected. Pelican is a novel technique that adapts to changes within phishing attacks in real-time. The technique detects 93.94% of the phishing tweets in real-world data that we collected over a 9 month period, which is higher than benchmark algorithms.",https://ieeexplore.ieee.org/document/9346336/,2020 International Conference on Data Mining Workshops (ICDMW),17-20 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/iV.2015.88,Perceived Realism of Crowd Behaviour with Social Forces,IEEE,Conferences,"This paper investigates the development of an urban crowd simulation for the purposes of psychophysical experimentation. Whilst artificial intelligence (AI) is advancing to produce more concise and interesting crowd behaviours, the number or sophistication of the algorithms implemented within a system does not necessarily guarantee its perceptual realism. Human perception is highly subjective and does not always conform to the reality of the situation. Therefore it is important to consider this aspect when dealing with A implementations within a crowd system aimed at humans. In this research an initial two-alternative forced choice (2AFC) with constant stimuli psychophysical experiment is presented. The purpose of the experiment is to assess whether human participants perceive crowd behaviour with a social forces model to be more realistic. Results from the experiment suggest that participants do consider crowd behaviour with social forces to be more realistic. This research could inform the development of crowd-based systems, especially those that consider viewer perception to be important, such as for example video games and other media.",https://ieeexplore.ieee.org/document/7272647/,2015 19th International Conference on Information Visualisation,22-24 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WiMob52687.2021.9606263,Performance Modelling and Assessment for Social VR Conference Applications in 5G Radio Networks,IEEE,Conferences,"One of the most challenging applications targeted by evolving (beyond-)5G technology is virtual reality (VR). Particularly, 'Social VR' applications provide a fully immersive experience and sense of togetherness to users residing at different locations. To support such applications the network must deal with huge traffic demands, while keeping end-to-end latencies low. Moreover, the radio access network must deal with the volatility and vulnerability of mmWave radio channels, where even small movements of the users may have substantial effects on the Quality of Experience. We present an integral modelling framework for feasibility assessment and performance optimization of the radio access network for Social VR applications in indoor office scenarios. Using the presented modelling approach, we conduct an extensive simulation-based assessment to determine the performance impact of head motion, the frequency band (3.5 GHz, 26 GHz) and radio network configurations, and derive the required carrier bandwidth for a range of 'Social VR' scenarios. Insights into these issues are a prerequisite for setting up guidelines for network deployment and configuration as well as for the development of (AI/ML-based) methods for dynamic resource management to optimally support Social VR applications.",https://ieeexplore.ieee.org/document/9606263/,"2021 17th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)",11-13 Oct. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/eCrime.2012.6489521,PhishAri: Automatic realtime phishing detection on twitter,IEEE,Conferences,"With the advent of online social media, phishers have started using social networks like Twitter, Facebook, and Foursquare to spread phishing scams. Twitter is an immensely popular micro-blogging network where people post short messages of 140 characters called tweets. It has over 100 million active users who post about 200 million tweets everyday. Phishers have started using Twitter as a medium to spread phishing because of this vast information dissemination. Further, it is difficult to detect phishing on Twitter unlike emails because of the quick spread of phishing links in the network, short size of the content, and use of URL obfuscation to shorten the URL. Our technique, PhishAri, detects phishing on Twitter in realtime. We use Twitter specific features along with URL features to detect whether a tweet posted with a URL is phishing or not. Some of the Twitter specific features we use are tweet content and its characteristics like length, hashtags, and mentions. Other Twitter features used are the characteristics of the Twitter user posting the tweet such as age of the account, number of tweets, and the follower-followee ratio. These twitter specific features coupled with URL based features prove to be a strong mechanism to detect phishing tweets. We use machine learning classification techniques and detect phishing tweets with an accuracy of 92.52%. We have deployed our system for end-users by providing an easy to use Chrome browser extension. The extension works in realtime and classifies a tweet as phishing or safe. In this research, we show that we are able to detect phishing tweets at zero hour with high accuracy which is much faster than public blacklists and as well as Twitter's own defense mechanism to detect malicious content. We also performed a quick user evaluation of PhishAri in a laboratory study to evaluate the usability and effectiveness of PhishAri and showed that users like and find it convenient to use PhishAri in real-world. To the best of our knowledge, this is the first realtime, comprehensive and usable system to detect phishing on Twitter.",https://ieeexplore.ieee.org/document/6489521/,2012 eCrime Researchers Summit,23-24 Oct. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPEC51340.2021.9421213,Pneumatic Training Glove Based on Electromyographic Signal Control,IEEE,Conferences,"In modern society, much public attention is paid to the rights and interests of the disabled, which become a social problem. In order to satisfy the pursuit of disabled for a better quality of life, it is necessary to give them a normal life. For example, people with degeneration or atrophy of hand muscles caused by accidents or other reasons need an auxiliary system to help them recover their hand muscles. However, after consulting a large amount of data, I found that most hospitals in the market use hard levers and springs as mechanical structures, which will result in excessive resistance, poor finger curls, and even aggravate the disease due to improper use. In contrast, the deformable structure is softer. Meanwhile, it can actively bend the fingers of patient through the inflation control method to achieve the purpose of safety and effectiveness. In this paper, the design and casting of pneumatic muscle are completed through independent modeling and pouring in the experiment [1]. At the same time, this paper also provides and tests two machine learning pneumatic muscle control algorithms based on real-time binning, which are idempotent and real-time, and can be fully controlled in combination with the designed pneumatic muscle. Its core signal comes from EMG signals on key muscle groups of the arm. The signal is collected from muscle in real time by wet electrode patch. For the control model of machine learning, we have tested and implemented a variety of gesture postures, including common palm curling and stretching, common finger movements, etc. The pneumatic muscle hand rehabilitation auxiliary glove based on electromyographic signal control has the characteristics such as passive exercise, safety, less pain, individuation, low price, full and effective exercise, etc. The pneumatic muscle-assisted rehabilitation system based on electrical signal control in this paper has broad application prospects and extremely high value.",https://ieeexplore.ieee.org/document/9421213/,"2021 IEEE Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)",14-16 April 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AXMEDIS.2007.19,Poolcasting: A Social Web Radio Architecture for Group Customisation,IEEE,Conferences,"Poolcasting is a social Web radio architecture in which groups of listeners influence in real time the music played on each channel. Poolcasting users contribute to the radio with songs they own, create radio channels and evaluate the proposed music, while an automatic intelligent technique schedules each channel with a group-customised sequence of musically associated songs. The benefits of this approach are multiple: on one hand music producers can increase the exposure of their songs to specific target audiences; on the other hand, music consumers can easily discover new songs that match their preferences and group with people with whom they share similar listening experiences.",https://ieeexplore.ieee.org/document/4402867/,Third International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution (AXMEDIS'07),28-30 Nov. 2007,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/PuneCon52575.2021.9686508,Post Cyclone Damage Assessment Using CNN Based Transfer Learning and Grad-CAM,IEEE,Conferences,"Evaluating the aftermath of a cyclone is an expensive, arduous and time-consuming process which delays rehabilitation of affected victims. As multiple requests for grant aids pour in, it is necessary to cross-check the reality of the damage. At present, this investigation is mostly done by the concerned authorities manually. Now-a-days, social media can be considered as a repository for a plethora of post-disaster images. This pool of images may be used as a database to extract features to draw conclusions on the severity of cyclones. Since, tropical cyclones are frequently occurring in the Indian subcontinent, our research can be pivotal in curtailing the efforts of disaster management. The proposed CNN based architecture aims to detect whether an area has been damaged by a cyclone or not, and also the adversity of the same. Transfer learning has been deployed to fine tune the models, VGG-16 and VGG-19 to perform the task. This damage assessment system categorizes the images depicting distinct features like trees, posts, damaged property which have been explicitly cross-validated with Grad-CAM. The proposed model exhibits high accuracy in classifying post catastrophic destruction in a proficient and cost-effective manner.",https://ieeexplore.ieee.org/document/9686508/,2021 IEEE Pune Section International Conference (PuneCon),16-19 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/TENCON.2019.8929317,Practical Significance of GA PartCC in Multi-Label Classification,IEEE,Conferences,"Multi-label classification (MLC) can be defined as the objective of learning a classification model which has the capability to infer the accurate labels of new, previously unseen, objects where it is a likely situation that each object of the dataset may rightfully belong to multiple class labels. While single-label classification problems have been thoroughly researched, the same cannot be said for MLC. A gradually increasing number of problems are now being tackled as multi-label, allowing for richer and more accurate knowledge mining in real-world domains, such as medical diagnoses, social media, text classification, etc. Currently, there are two ways of solving MLC problems; Problem Transformation Approach and Algorithm Adaptation Method. Of the two, the former has in its domain Classifier Chains (CC) which is the most effective and popular method of solving MLC problems because of its simplicity in implementation. Unfortunately, CC is not favoured due to 2 drawbacks, [1] ordering of the labels for classification are randomly decided without a fixed logic or algorithm to it which results in varying accuracy, [2] all the labels, even those which may be redundant for a particular dataset are put into the chain despite the probability that some may be carrying irrelevant details. Through the research conducted for the purpose of this study, both challenges are tackled along with others detailed further on simultaneously using Genetic Algorithms (GA) over a Partial CC (PartCC) model, which is a modification over CC. A toxic comments dataset is used since its classification is a multi-label text classification problem with a highly imbalanced dataset. This paper aims to create a prototype model that is capable of detecting various types of toxicity like neutral, toxic, severe toxic, threats, obscenity, insults and identity hate. With the explosion of social media in the modern world and the resulting increasing phenomenon of social media hatred and bullying, there is a need for an advanced prototype model to predict the toxicity of each class of comments.",https://ieeexplore.ieee.org/document/8929317/,TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON),17-20 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCICC46617.2019.9146087,Predicting Link Sign in Online Social Networks based on Social Psychology Theory and Machine Learning Techniques,IEEE,Conferences,"Online social networks provide a great platform for internet users to share their views and ideas. Social media provides a dynamic platform that includes the formation and deformation of connections. Two types of connections, i.e., Positive and Negative, can exist in a social network. Positive connections are a sign of friendship or trust, while negative connections show enmity or distrust. Various applications in several fields have networks containing both positive and negative edges. Reliable prediction of edge sign can greatly influence in recommending friendly relationships while preventing enemy relationships across the network. Prediction of edge signs has been explored previously also. However, we intend to predict the sign of edges based on extracted features of nodes constructed upon theories of social psychology that includes classical balance theory and the status theory. Moreover, we employ emotional information theory and use the combined extracted features from all the theories to analyze networks for better prediction. Our results show that the proposed methodology has obtained significant accuracy when implemented on two real-life datasets, namely Slashdot and Epinions.",https://ieeexplore.ieee.org/document/9146087/,2019 IEEE 18th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),23-25 July 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDMW.2016.0026,Predicting User Roles in Social Networks Using Transfer Learning with Feature Transformation,IEEE,Conferences,"How can we recognise social roles of people, given a completely unlabelled social network? We may train a role classification algorithm on another dataset, but then that dataset may have largely different values of its features, for instance, the degrees in the other network may be distributed in a completely different way than in the first network. Thus, a way to transfer the features of different networks to each other or to a common feature space is needed. This type of setting is called transfer learning. In this paper, we present a transfer learning approach to network role classification based on feature transformations from each network's local feature distribution to a global feature space. We implement our approach and show experiments on real-world networks of discussions on Wikipedia as well as online forums. We also show a concrete application of our approach to an enterprise use case, where we predict the user roles in ARIS Community, the online platform for customers of Software AG, the second-largest German software vendor. Evaluation results show that our approach is suitable for transferring knowledge of user roles across networks.",https://ieeexplore.ieee.org/document/7836657/,2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW),12-15 Dec. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMTMA54903.2022.00163,Prediction Method of Pollutant Concentration Based on GA-ELM Model,IEEE,Conferences,"With the rapid development of social economy, air pollution has attracted more and more attention. In order to effectively predict the situation of pollutants and improve pollution prevention and control, this paper presents a prediction model of limit learning machine optimized by genetic algorithm (GA-ELM). Collect the data of an air quality monitoring point, conduct simulation experiments with MATLAB software, finally analyze the prediction results of pollutant concentration, and compare them with the prediction results of WRF-CMAQ system. The results show that GA- ELM model can predict the pollutant concentration more accurately, the fitting degree between the prediction curve and the real value curve is high, and the relative error fluctuates up and down in the range of -0.2~0.2, which further shows that the model has good robustness.",https://ieeexplore.ieee.org/document/9724075/,2022 14th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA),15-16 Jan. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ElConRus51938.2021.9396292,Prediction of Relation Based on Social Network Parsing,IEEE,Conferences,"The problem of searching a potential partner among the particular groups in dating applications is studied in this article. Moreover, the assessment of the current methods is carried out and the ways to improve their efficiency are presented. To begin with, there are two main disadvantages of the dating applications nowadays. The first one is imperfect algorithms of selection and the second one is the lack of ""human touch"". It means, that people with common friends in real life will communicate better in the Internet. Due to that, the major features of the research are searching among the common social circle and processing the data by parsing the social network of the potential partner. As a result, the program compares the personal information of every user and makes the pairs with more similar data. All information is processed by Linear neural network which was trained by results of social surveys .The search algorithm is implemented using specialized libraries for Python 3.8 and public methods of VK.API. Also, there are data and findings in the end of this article.",https://ieeexplore.ieee.org/document/9396292/,2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus),26-29 Jan. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE51474.2020.00055,Prediction of Trust Propagation in Social Commerce based on Ensemble Learning,IEEE,Conferences,"Accurate prediction of trust propagation in social commerce is vital to recommendation and promotion of commodities. Existing prediction models have some shortages, such as simple process of influencing factors of trust and low prediction precision. To address these problems, a prediction model based on Soft-Voting ensemble learning was proposed. Firstly, features of influencing factors of information propagation in social commerce were constructed from user attributes, information text and user interaction. Secondly, XGBoost, LightGBM and Catboost models were trained according to the above constructed features to predict trust propagation in social commerce. Finally, results of XGBoost, LightGBM and Catboost models were integrated using Soft-Voting technique as the final prediction results. An experiment on a real dataset of Sina Weibo was carried out, which proved the higher precision of Soft-Voting ensemble learning compared to those of XGBoost, LightGBM and Catboost models.",https://ieeexplore.ieee.org/document/9403760/,2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),30 Oct.-1 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AICAI.2019.8701417,Predictive Framework to Measure Mental Distress Caused by Economic Crises,IEEE,Conferences,"Over the years, research has continuously emphasized that economic calamities are negatively correlated with the mental stability of public. Psychologists and sociologists continue to probe downturns influence of economic crisis on mental health and propose social protection programs to promote recovery. The problem, however, is that more than having a social recovery program, it requires personal level efforts to realize and understand what may be coming ahead and rationally solving it, by being more in control of the situation. Considering this context, there are various aims of this paper to evaluate theoretical as well as conceptual illustrations on the reasons behind the negative associations of an economic downturn on population's mental stability, followed by closely examining critical mental distress factors as well as economic distress factors and establishing connection through literature analysis. The study proposes a framework to intelligently detect economic distress in real time and successfully link it with human distress factors to predict any anticipated alleviation in stress level. The proposed framework is based on cloud architecture and uses software application that will perform intelligent data mining for knowledge acquisition purpose.",https://ieeexplore.ieee.org/document/8701417/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTAI.2016.0020,Preference-Like Score to Cope with Cold-Start User in Recommender Systems,IEEE,Conferences,"In recent years, there has been an explosion of social recommender systems (SRS) research. However, the dominant trend of these studies has been towards designing new prediction models. The typical approach is to use social information to build those models for each new user. Due to the inherent complexity of this prediction process, for full cold-start user in particular, the performance of most SRS fall a great deal. We, rather, propose that new users are best served by models already built in system. Selecting a prediction model from a set of strong linked users might offer better results than building a personalized model for full cold-start users. We contribute to this line of work comparing several matrix factorization based SRS under full cold-start user scenario, and proposing a general model selection approach, called ToSocialRec, that leverages existing recommendation models to offer items for new users. Our framework is not only able to handle several social network connection weight metrics, but any metric that can be correlated with preference similarity among users, named here as Preference-like score. We perform experiments on real life datasets that show this technique is as efficient or more than current state-of-the-art techniques for cold-start user. Our framework has also been designed to be easily deployed and leveraged by developers to help create a new wave of SRS.",https://ieeexplore.ieee.org/document/7814580/,2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI),6-8 Nov. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICETCI51973.2021.9574068,Prevention of Emotional Entrapment of Children on Social Media,IEEE,Conferences,"Increasing usage of social media and its widespread reaches across the younger as well as older demographics of the population, along with the added advantage of anonymity, has propelled the pressing need to ensure that these platforms remain a secure place for children so as to safeguard them from issues like child grooming. Over the last few years, the rate of online grooming has seen a massive increase along with an increase in the number of teenage users. The proposed system, Prevention of Emotional Entrapment of Children (PEEC), consists of an age detection module using Deep Neural Network (DNN) as well as a grooming detection module using Support Vector Machine (SVM) to monitor the conversations of only those users who come under the category of minor (below 18). The resultant system gave an accuracy of 84% for age detection and 91% for grooming detection.",https://ieeexplore.ieee.org/document/9574068/,2021 International Conference on Emerging Techniques in Computational Intelligence (ICETCI),25-27 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ARITH.2019.00047,Privacy-Preserving Deep Learning via Additively Homomorphic Encryption,IEEE,Conferences,"We aim at creating a society where we can resolve various social challenges by incorporating the innovations of the fourth industrial revolution (e.g. IoT, big data, AI, robot, and the sharing economy) into every industry and social life. By doing so the society of the future will be one in which new values and services are created continuously, making people's lives more conformable and sustainable. This is Society 5.0, a super-smart society. Security and privacy are key issues to be addressed to realize Society 5.0. Privacy-preserving data analytics will play an important role. In this talk we show our recent works on privacy-preserving data analytics such as privacy-preserving logistic regression and privacy-preserving deep learning. Finally, we show our ongoing research project under JST CREST “AI”. In this project we are developing privacy-preserving financial data analytics systems that can detect fraud with high security and accuracy. To validate the systems, we will perform demonstration tests with several financial institutions and solve the problems necessary for their implementation in the real world.",https://ieeexplore.ieee.org/document/8877418/,2019 IEEE 26th Symposium on Computer Arithmetic (ARITH),10-12 June 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CASA.2003.1199296,Proceedings 16th International Conference on Computer Animation and Social Agents,IEEE,Conferences,"The following topics are dealt with: social and conversational agents; physics-based animation; interaction, control and planning; AI-based animation and A-life; modeling of groups and crowds; virtual humans: past, present and future; and design issues in games and virtual environments.",https://ieeexplore.ieee.org/document/1199296/,Proceedings 11th IEEE International Workshop on Program Comprehension,8-9 May 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2018.8508242,ProfileGen: Generation of Automatic and Realistic Artificial Profiles,IEEE,Conferences,"One of the most effective approaches for detecting malicious activity in online social networks (OSNs) involves the use of social network honeypots - artificial profiles. Therefore, there is a growing need for the ability to reliably generate realistic artificial honeypot profiles in OSNs. In this research we present `ProfileGen' - a method for the automated generation of profiles for professional social networks, giving particular attention to producing realistic education and employment records. `ProfileGen' creates honeypot profiles that are similar to actual data by extrapolating the characteristics and properties of real data items. Evaluation by 70 domain experts confirms the method's ability to generate realistic artificial profiles that are indistinguishable from real profiles, demonstrating that our method can be applied to generate realistic artificial profiles for a wide range of applications.",https://ieeexplore.ieee.org/document/8508242/,2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),28-31 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CSEET49119.2020.9206229,Project-Based Learning in a Machine Learning Course with Differentiated Industrial Projects for Various Computer Science Master Programs,IEEE,Conferences,"Graduating computer science students with skills sufficient for industrial needs is a priority in higher education teaching. Project-based approaches are promising to develop practical and social skills, needed to address real-world problems in teams. However, rapid technological transition makes an initial training of contemporary methods challenging. This affects the currently much-discussed machine learning domain as well. The study at hand describes a re-framed teaching approach for a machine learning course, offered to various computer science master programs. Project-based learning is introduced with differentiated projects provided by industrial partners that address the diverse study programs. Course attendees are supported with manuals, tools, and tutoring, passing through the Cross Industry Standard Process for Data Mining (CRISP-DM). Observations made during two iterations are reported, accompanied by a first empiric evaluation of student experiences.",https://ieeexplore.ieee.org/document/9206229/,2020 IEEE 32nd Conference on Software Engineering Education and Training (CSEE&T),9-12 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MASS.2018.00019,Q-Learning Based Edge Caching Optimization for D2D Enabled Hierarchical Wireless Networks,IEEE,Conferences,"Caching at the edge of mobile networks can significantly offload network traffic while satisfying content requests from mobile users locally. The contents can be requested from the proximity users via Device-to-device (D2D) communications while proactive caching the popular content to local users. However, the assumptions that content popularity is equal to user preference in several existing studies, which are invalid and not rigorous due to the fact that content popularity is calculated by the statistic of user requests within a certain period while user preference reflects the probability of a content requested by the individual user. Motivated by this, in this paper, we study the edge caching optimization of hierarchical wireless networks. Our aiming is to maximize the size of content offload by D2D communications. In particular, the edge caching policy with D2D sharing model based on the analysis of user mobility and social relationship is derived. We first prove the problem is NP-hard and then formulate it as a Markov Decision Process (MDP) problem, finally a Q-learning based distributed content replacement strategy is proposed. The large-scale real trace based experiment results show the effectiveness of our proposed framework.",https://ieeexplore.ieee.org/document/8567541/,2018 IEEE 15th International Conference on Mobile Ad Hoc and Sensor Systems (MASS),9-12 Oct. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IntelCIS.2015.7397269,Ranking of news items in rule-stringent social media based on users' importance: A social computing approach,IEEE,Conferences,"In this paper an innovative social media news items ranking scheme is proposed. The proposed unsupervised architecture takes into consideration user-content interactions, since social media posts receive likes, comments and shares from friends and other users. Additionally the importance of each user is modeled, based on an innovative algorithm that borrows ideas from the PageRank algorithm. Finally, a novel content ranking component is introduced, which ranks posted news items based on a social computing method, driven by the importance of the social network users that interact with them. Initial experiments on real life social networks news items illustrate the promising performance of the proposed architecture. Additionally comparisons with three different ranking ways are provided (SUMF, RSN-CO and RSN-nCO), in terms of user satisfaction.",https://ieeexplore.ieee.org/document/7397269/,2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS),12-14 Dec. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2017.7989184,Rapidly exploring learning trees,IEEE,Conferences,"Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.",https://ieeexplore.ieee.org/document/7989184/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/I-SMAC.2017.8058261,Real world smart chatbot for customer care using a software as a service (SaaS) architecture,IEEE,Conferences,"It's being very important to listen to social media streams whether it's Twitter, Facebook, Messenger, LinkedIn, email or even company own application. As many customers may be using this streams to reach out to company because they need help. The company have setup social marketing team to monitor this stream. But due to huge volumes of users it's very difficult to analyses each and every social message and take a relevant action to solve users grievances, which lead to many unsatisfied customers or may even lose a customer. This papers proposes a system architecture which will try to overcome the above shortcoming by analyzing messages of each ejabberd users to check whether it's actionable or not. If it's actionable then an automated Chatbot will initiates conversation with that user and help the user to resolve the issue by providing a human way interactions using LUIS and cognitive services. To provide a highly robust, scalable and extensible architecture, this system is implemented on AWS public cloud.",https://ieeexplore.ieee.org/document/8058261/,"2017 International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)",10-11 Feb. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UrgentHPC54802.2021.00009,Real-Time COVID-19 Infection Risk Assessment and Mitigation based on Public-Domain Data,IEEE,Conferences,"A number of models have been developed to predict the spreads of the COVID-19 pandemic and how non-pharmaceutical interventions (NPIs) such as social distancing, facial coverings, and business and school closures can contain this pandemic. Evolutionary artificial intelligence (AI) approaches have recently been proposed to automatically determine the most effective interventions by generating a large number of candidate strategies customized for different countries and locales and evaluating them with predictive models. These epidemiological models and advanced AI techniques assist policy makers by providing them with strategies in balancing the need to contain the pandemic and the need to minimize their economic impact as well as educating the general public about ways to reduce the chance of infection. However, they do not advise an individual citizen at a specific moment and location on taking the best course of actions to accomplish a task such as grocery shopping while minimizing infection.Therefore, this paper describes a new project aiming to develop a mobile-phone-deployable, real-time COVID-19 infection risk assessment and mitigation (RT-CIRAM) system which analyzes up-to-date data from multiple open sources leveraging urgent HPC/cloud computing, coupled with time-critical scheduling and routing techniques. Implementation of a RT-CIRAM prototype is underway, and it will be made available to the public. Facing the increasing spread of the more contagious Delta (B.1.617.2) and Delta Plus (AY.4.2) variants, this personal system will be especially useful for individual citizen to reduce her/his infection risk despite increasing vaccination rates while contributing to containing the spread of the current and future pandemics.",https://ieeexplore.ieee.org/document/9651302/,2021 IEEE/ACM HPC for Urgent Decision Making (UrgentHPC),19-19 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CISAI54367.2021.00190,Real-Time Facial Expression Driving based on 3D Facial Feature Point,IEEE,Conferences,"Facial expression driving can make the expression of virtual characters more real and natural. It is widely used in movies, games and some social software. The existing real-time facial expression driving algorithms have the limitation of physical hardware, prefabricated model or long-time training. In order to get rid of the limitation of existing algorithms, this paper proposes a real-time expression driving algorithm based on 3D facial feature points with RGBD data as input. In the face capture, we use ICP algorithm to get the rigid data of the face and deformation transmission algorithm to capture the non-rigid data of the face. Moreover, the whole face process only takes 0.4ms to complete. Because the calculation of the algorithm is based on 3D feature points of the face, there is no need to prefabricate a specific face model and a lot of time training. Our algorithm can not only use real faces to drive virtual faces, but also use virtual characters to drive virtual faces.",https://ieeexplore.ieee.org/document/9718961/,2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI),17-19 Sept. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ic-ETITE47903.2020.394,Real-time Acoustic based Depression Detection using Machine Learning Techniques,IEEE,Conferences,"Depression disorder is predicted to rise to the second leading cause of disability by 2030 as per the identifications of the World Health organization (WHO). Though well trained clinicians, medical and psychological treatments are available for depression treatment, persons or families are reluctant to speak out/reach doctors about this disorder for various social reasons. Diagnosis of depression disorder includes numerous interviews with patient and family, clinical analysis, questionnaires which is time consuming and also demands well trained clinicians. In the present era of Machine learning, automation of depression detection is not complicated and can easily be deployed. However, the automation should use fewer resources, provide accurate results with more reachability. In this paper, acoustic features are used to train a classification model to categorize a human as Depressed or not-Depressed. DIAC-WOZ database available with AVEC2016 challenge is considered for training the classifiers. Prosodic, Spectral and Voice control features are extracted using the COVAREP toolbox and are feature fused. SMOTE analysis is used for overcoming the class imbalance and 93% accuracy is obtained with the SVM algorithm resulting in Depression Classification Model (DCM). An android application cureD Deployed on Cloud is developed to self assess depression using DCM and PHQ-8 questionnaire. The application is tested on real time data of 50 subjects under the supervision of a qualified psychiatrist and an accuracy of 90% is obtained.",https://ieeexplore.ieee.org/document/9077698/,2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE),24-25 Feb. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICNSC.2019.8743331,Real-time Sentiment Analysis On E-Commerce Application,IEEE,Conferences,"Opinion mining is one of the most important tasks of natural language processing, which is also known as sentiment analysis, used to identify about what people have an impression about their services and products in social media platforms. To improve marketing strategies using product reviews, an effective method should be used for predicting the sentiment polarity. In this research article, a Machine learning technique called Support Vector Machine (SVM) is used to design a model and this model has been implemented on an E-commerce application. The data used in this study are online product reviews which are collected from Amazon.com. The experiments of sentiment analysis are performed for two levels of categorization: review level and sentence level. The main focus of this paper is to present a real-time sentimental analysis on the product reviews of e-commerce application so that the user experience can be enhanced.",https://ieeexplore.ieee.org/document/8743331/,"2019 IEEE 16th International Conference on Networking, Sensing and Control (ICNSC)",9-11 May 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITE54466.2022.9759552,Real-time Social Distance Detection using YOLO-v5 with Bird-eye View Perspective to Suppress the Spread of COVID-19,IEEE,Conferences,"The COVID-19 virus outbreak has continued to spread since the end of 2019 worldwide. All people also implement health protocols not to contract this disease. One of the health protocols that must be implemented is to limit interactions between humans to a length of 1&#x2013;2 meters or what is usually done with social distancing. Social distance detection system to ensure that people do not violate social distancing could be a solution to this problem. Using the YOLO-v5 method, which is the latest version of the YOLO (You Only Look Once) method with a detection speed of up to 140 Frames Per Second (FPS) and 90 percent smaller than the previous version, this system detects people who violate social distancing and then gives a voice warning to keep their distance to avoid spreading the COVID-19 virus. The human detection rate in the detection system reaches 93,5&#x0025;, and the accuracy for social distance detection reaches 95&#x0025;. Based on the research that has been done, it can be said that this system can work well for detecting social distance, but the detection will start detecting the distance between the camera and the object exceeding 10 meters.",https://ieeexplore.ieee.org/document/9759552/,2022 2nd International Conference on Information Technology and Education (ICIT&E),22-22 Jan. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/INTECH.2017.8102423,Real-time emotional state detection from facial expression on embedded devices,IEEE,Conferences,"From the last decade, researches on human facial emotion recognition disclosed that computing models built on regression modelling can produce applicable performance. However, many systems need extensive computing power to be run that prevents its wide applications such as robots and smart devices. In this proposed system, a real-time automatic facial expression system was designed, implemented and tested on an embedded device such as FPGA that can be a first step for a specific facial expression recognition chip for a social robot. The system was built and simulated in MATLAB and then was built on FPGA and it can carry out real time continuously emotional state recognition at 30 fps with 47.44% accuracy. The proposed graphic user interface is able to display the participant video and two dimensional predict labels of the emotion in real time together.",https://ieeexplore.ieee.org/document/8102423/,2017 Seventh International Conference on Innovative Computing Technology (INTECH),16-18 Aug. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICDSP.2015.7251991,Real-time sociometrics from audio-visual features for two-person dialogs,IEEE,Conferences,"This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.",https://ieeexplore.ieee.org/document/7251991/,2015 IEEE International Conference on Digital Signal Processing (DSP),21-24 July 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MIPRO.2016.7522376,Reciprocal payers identification in banking logs using SAT solvers,IEEE,Conferences,"In this paper we presented solvers for satisfiability testing (SAT) as a novel approach to finding reciprocal payers in banking logs. A term “reciprocal payers” is usually treated as general fraud by using standard techniques such as expert systems, machine learning and in recent times social network analysis. SAT as a technique for data analysis was abandoned due to the unfeasibility of SAT solvers. SAT solvers, however continued to develop in the hardware and software verification communities. We presented a proof-of-concept solution for identification of reciprocal payers (formally called a clique), which is a group of bank clients that issue payments to each other (each member to each member). We do not use real data due to client confidentiality, but the reader can see the principle. In the basic approach it is assumed that each client has only one account, and in the extended, second approach, it was allowed that a client can have more than one account.",https://ieeexplore.ieee.org/document/7522376/,"2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)",30 May-3 June 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IRDS.2002.1043897,Recognizing and remembering individuals: online and unsupervised face recognition for humanoid robot,IEEE,Conferences,"Individual recognition is a widely reported phenomenon in the animal world, where it contributes to successful maternal interaction, parental care, group breeding, cooperation, mate choice, etc. This work addresses the question of how one may implement such social competence in a humanoid robot. We argue that the robot must be able to recognize people and learn about their various characteristics through embodied social interaction. Thus, we proposed an initial implementation of an online and unsupervised face recognition system for Kismet, our sociable robotic platform. We show how specific features of this particular application drove our decision and implementation process, challenged by the difficulty of the face recognition problem, which has so far been explored in the supervised manner. Experimental results are reported to illustrate what was solved and the lessons learned from the current implementation.",https://ieeexplore.ieee.org/document/1043897/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2017.7989267,Recognizing social touch gestures using recurrent and convolutional neural networks,IEEE,Conferences,"Deep learning approaches have been used to perform classification in several applications with high-dimensional input data. In this paper, we investigate the potential for deep learning for classifying affective touch on robotic skin in a social setting. Three models are considered, a convolutional neural network, a convolutional-recurrent neural network and an autoencoder-recurrent neural network. These models are evaluated on two publicly available affective touch datasets, and compared with models built to classify the same datasets. The deep learning approaches provide a similar level of accuracy, and allows gestures to be predicted in real-time at a rate of 6 to 9 Hertz. The memory requirements of the models demonstrate that they can be implemented on small, inexpensive microcontrollers, demonstrating that classification can be performed in the skin itself by collocating computing elements with the sensor array.",https://ieeexplore.ieee.org/document/7989267/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPIN.2019.8911776,Regression Assisted Crowdsourcing Approach for Fingerprint Radio Map Construction,IEEE,Conferences,"Due to the proliferating social and commercial interest on location-based services (LBS), research and development of indoor positioning system (IPS) have been expanded. Most of the efficient IPS methods utilize radio-based solutions to meet the accuracy requirement of indoor LBS. Typically fingerprinting localization is realized, which requires a site survey process where radio signatures of a localization area are annotated with their actual recorded locations. The site survey is time-consuming and labor-intensive that intensifies practical limits and challenges in realizing a reliable and scalable IPS. In this paper, we propose a crowdsourcing-based approach to acquire the training data set for Gaussian process regression (GPR). In particular, we suggest combining access point (AP) proximity information and pedestrian dead reckoning (PDR) to collect labeled data without any human intervention. The crowdsourced training data are fed to model a Gaussian process, which predicts the mean RSS and its corresponding variance across the testbed. To validate the proposed method, we compared the predicted data with the manually measured one and utilized the predicted data for localization using weighted k-nearest neighbor (Wk-NN) and maximum likelihood (ML) based fingerprinting localization. Experimental results obtained by real field deployment show that the average difference between the predicted RSS and manually measured RSS is 3.87 dBm and 80% of the localization estimation error are below 5.5m.",https://ieeexplore.ieee.org/document/8911776/,2019 International Conference on Indoor Positioning and Indoor Navigation (IPIN),30 Sept.-3 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2012.39,Relationships between Periodic Behaviors in Micro-blogging and the Users' Baseline Mood,IEEE,Conferences,"Twitter messages are real-time, spontaneous reports of what the users are feeling, thinking, and doing. The frequency of posting ""Tweets"" oscillates periodically in one-day and seven-day cycles. These periodic patterns may be related to the individual users' baseline affective state. In order to investigate individual periodic behavior in social media, we performed a Fourier series expansion and PCA on intra-week Tweet-frequency changes of 11,570 individuals. Moreover, the relationships between the users' baseline mood and the principal component scores were investigated. High frequency in daytime tweets on weekdays was found to be linked to a low positive affective state. The larger number of posting tweets was related to the negative affective state.",https://ieeexplore.ieee.org/document/6299313/,"2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",8-10 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IJCNN52387.2021.9534136,Relevance-Aware Anomalous Users Detection in Social Network via Graph Neural Network,IEEE,Conferences,"Anomalous users detection in social network is an imperative task for security problems. Motivated by the great power of Graph Neural Networks(GNNs), many current researches adopt GNN-based detectors to reveal the anomalous users. However, the increasing scale of social activities, explosive growth of users and manifold technical disguise render the user detection a difficult task. In this paper, we propose an innovate Relevance-aware Anomalous Users Detection model (RAU-GNN) to obtain a fine-grained detection result. RAU-GNN first extracts multiple relations of all types of users in social network, including both benign and anomalous users, and accordingly constructs the multiple user relation graph. Secondly, we employ relevance-aware GNN framework to learn the hidden features of users, and discriminate the anomalous users after discriminating. Concretely, by integrating Graph Convolution Network(GCN) and Graph Attention Network(GAT), we design a GCN-based relation fusion layer to aggregate initial information from different relations, and a GAT-based embedding layer to obtain the high-level embeddings. Lastly, we feed the learned representations to the following GNN layer in order to consolidate the node embedding by aggregating the final users' embeddings. We conduct extensive experiment on real-world datasets. The experimental results show that our approach can achieve high accuracy for anomalous users detection.",https://ieeexplore.ieee.org/document/9534136/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DSC.2018.00139,Representation Learning Based on Influence of Node for Multiplex Network,IEEE,Conferences,"The research of social network and mining of multi-source/ multi-view network has gradually been a focus in the field of social network recently. Existing studies on building social network are mainly based on the single source data, instead of the multi-source data. In this paper, we use multiplex network (e.g. multi-relation network) to model multi-source data, then propose a node learning representation of multiplex network. First, we propose a method of extracting node influence of multiplex network. Next, taking account into the influence of node and the random walk in multiplex network, we propose a biased random walk method to learn the embedding of node in multiplex network. Finally, we compare existing state-of-the-art techniques on edge reconstruction accuracy and link prediction in several real-world networks from diverse domains. Experiments on real datasets validate the effectiveness of our network representation method, enrich the quantity of conserving multilayer network structure information, and make the description of the node embedding in multiplex network more accurate.",https://ieeexplore.ieee.org/document/8411960/,2018 IEEE Third International Conference on Data Science in Cyberspace (DSC),18-21 June 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/RE.2019.00009,Requirements We Live By,IEEE,Conferences,"Enlightened requirements engineering (RE) researchers and practitioners generally accept that RE is as much about understanding the world as it is about understanding the software and systems that will be built to inhabit that world. As a result, the RE field has fostered a multi-disciplinary following of researchers and practitioners who are prepared to engage deeply in application domains, to apply a range of technical and socio-technical skills to understand those domains, and to accept that the outcome of an effective RE process may not deliver a software system at all. The RE community has also developed, deployed, and evaluated a wide range of contributions that reflect such enlightenment: conceptual models that reflect the relationships between the world and the machine, domain models and scenarios that reflect understandings of problem domains, and enterprise models that reflect the organisations and processes that build and deploy systems. All these in addition to the models that capture the all-important behaviour of systems and software. It seems to me however that the RE discipline is at a crossroads. The mechanics of the discipline appear to be established - much of the published research is now empirical - or technical, but only in so far as it responds to technological advances elsewhere, such as mobile and ubiquitous technologies represented by the Internet of Things, richer application domains such as Industrie 4.0 and Smart Cities, or more advanced computational techniques that are maturing, such AI, machine learning, and blockchains. As a community, we reassure ourselves that our discipline is safe and thriving, after all RE is a “forever problem”: all systems we wish to build will have requirements, now and forever. But this is to be complacent. RE has no protected status to study and deploy requirements. The formal models we elicit, design, and build are increasingly deployable by other disciplines, as are the values that we seek our modern, AI-driven systems to embody. A new and potentially radical re-framing of our discipline may be needed, and I will speculate what this may look like. It may require letting go of what we have considered to be the boundaries of our discipline, while embracing new but fluid boundaries. I have advocated and explored “software without boundaries” as one such framing that challenges the separation of `world and the machine', not because I don't accept the separation of the `what' and the `how', the `indicative' and the `optative', or the `problem' and the `solution', but because the world we live in no longer accepts these separations. Society, more often than not, does not think of systems, of technology, or indeed of software; it thinks of ways of working, ways of interacting, ways of living. Requirements, such as they are, are `requirements we live by' not requirements of systems in the world. At an extreme, if one believes the AI hype, `the world and the machine' will increasingly be replaced by the `world in the machine'. Where does the RE community stand on this, and what can this community do to contribute to the framing and solving of this new reality? My own work in recent years has evolved to reflect the above. I still revisit, with some pride, the `RE Roadmap' that Steve Easterbrook and I published in 2000 - many of the fundamental RE principles we presented still hold today. But I cringe at how we missed the changing nature of the world in which we operate: a world populated by autonomous and adaptive systems, populated by big data and associated analytics, and populated by stakeholders whose multiple perspectives reflect a multitude of ethical and social values, not all of which are wholesome, and many of which are actively subversive or malicious. My own research on security and privacy requirements only scratches the surface of this evolving reality. I invite the RE community to reflect on how it frames its own research in this context.",https://ieeexplore.ieee.org/document/8920530/,2019 IEEE 27th International Requirements Engineering Conference (RE),23-27 Sept. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBAIE52039.2021.9389893,Research and implementation of network information security management system based on face recognition,IEEE,Conferences,"In recent years, with the prosperity and development of social economy and the continuous progress of science and technology, people's identity recognition field has been paid more and more attention, and face recognition has higher security than traditional verification manual, which is a hot research direction of artificial intelligence. In this paper, face recognition is carried out in the order of face preprocessing, face detection and face recognition (training). Face preprocessing mainly includes image graying, image filtering, histogram equalization and other processing steps. Face detection adopts Ada Boost based face detection algorithm[1]. The main face recognition algorithms are studied: lbphface Face recognition algorithm based on LBP, this paper uses this algorithm for face recognition. The design and implementation of the security management system based on face recognition is completed.",https://ieeexplore.ieee.org/document/9389893/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/DTPI52967.2021.9540104,Research and practice of lightweight digital twin speeding up the implementation of flexible manufacturing systems,IEEE,Conferences,"Parallel manufacturing in Industry 5.0 requires digital twin to digitize physical systems, building virtual models to open up channels connecting physical systems, information systems, and social systems, and transforming the physical models of the existing production environment to achieve two-way feedback of virtual and real is the current research direction. This paper proposes the modeling idea of lightweight digital twin, extracts core dimensions and performs digital virtual simulation, so as to quickly realize the complete process of two-way feedback, and realize a set of chess flexible parallel manufacturing production lines as a practice for the design of complete lightweight digital twin.",https://ieeexplore.ieee.org/document/9540104/,2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI),15 July-15 Aug. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICAIIS49377.2020.9194885,Research on Dimension Reduction Method of Public Opinion Short Text Representation Model Based on Combined Neural Network,IEEE,Conferences,"With the rapid development of the Internet and the popularization of social software such as Twitter and Weibo, online public opinion has an increasing influence on public opinion in the entire society. In order to effectively prevent and control vicious incidents, real-time monitoring of online public opinion is becoming increasingly important. important. According to the characteristics of short-sentence information in public opinion, this paper proposes an automatic clustering method based on combinatorial neural network to construct a short-sentence representation model of public opinion, and construct word clusters based on the semantic similarity of characteristic words. The test results show that: in the process of mass text analysis and public opinion discovery, this method can effectively reduce the accuracy of the short text public opinion construction representation model by reducing the dimension of the text representation model, while ensuring the real-time acquisition of public opinion while greatly improving Public opinion finds efficiency.",https://ieeexplore.ieee.org/document/9194885/,2020 IEEE International Conference on Artificial Intelligence and Information Systems (ICAIIS),20-22 March 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICEIEC54567.2022.9835053,Research on Emergency Navigation Path Planning System for Plateau Regions,IEEE,Conferences,"The study of emergency navigation path planning methods in plateau regions has very important economic and social significance. In this paper, we proposed a system design scheme combining road network database and satellite remote sensing images with a flat plateau region as the research object. The proposed system performs image pre-processing operations on real-time remote sensing images based on historical remote sensing data, road network extraction and land classification using remote sensing semantic segmentation techniques, and rasterized maps are established in combination with the road network database, taking into account the different types of motion carriers and the influence of image noise for fast emergency navigation path planning. The proposed system architecture approach is a reference value for research in related fields.",https://ieeexplore.ieee.org/document/9835053/,2022 IEEE 12th International Conference on Electronics Information and Emergency Communication (ICEIEC),15-17 July 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICITBS53129.2021.00178,Research on Feature Extraction and Tendency Analysis of Chinese Language Sentimental Expression in Network Context,IEEE,Conferences,"The current network language only considers the expression of its basic meaning, and lacks in-depth analysis of sentimental characteristics and tendencies. For this reason, this paper investigates the sentimental analysis methods of network language based on the Chinese text information of network social media platform. Through the training of the existing data sets, we complete the data cleaning and feature word extraction. Then, a multi-dimensional fine-grained sentiment classification algorithm is designed by using neural network to reduce the dimension of feature vector. Finally, the structured linguistic features are used to optimize the sentiment score step by step, and the text sentiment classification is implemented, and a tendency analysis model considering the polarity of sentiment is further established. The validity of the model is verified by the real data collected in the network. The results show that the method has a significant advantage in Chinese data sets, and the recognition rate is higher than that of similar sentiment analysis methods.",https://ieeexplore.ieee.org/document/9525484/,"2021 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS)",27-28 March 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIID51893.2021.9456477,Research on Privacy Protection Technology in Face Identity Authentication System Based on Edge Computing,IEEE,Conferences,"In today's society, the rapid development of the Internet makes People's Daily life become more intelligent and diversified. Today's society has entered a multifaceted era where everything is interconnected. Artificial intelligence technology is gradually replacing some traditional human services, such as intelligent robot customer service instead of traditional human customer service, intelligent face scanning security check in railway stations instead of traditional manual ticket checking, unmanned supermarket automatic checkout has liberated some social labor costs. All these changes are the result of the development of artificial intelligence technology in today's society. In recent years, unicorn startups focused on biometrics have sprung up all around us, such as BTU and its MEG VII (Face ++). Thanks to the development of Internet and artificial intelligence technology, in many application fields, the traditional access control and identity authentication technology based on password verification is gradually transforming to the scheme based on biometric identification verification. Secure identity authentication is very important to the application of Internet. Face recognition is the most popular technology among all biometric identification technologies. In the field of biometric identification technology, it has become the most widely used technology in the field of identity authentication because of its unique non-invasive, support for infrared and visible light, no need for user cooperation and many other advantages. In the field of education, examinee identification, pedestrian identification detection at the entrance of railway stations, face electronic payment, intelligent video surveillance system, intelligent attendance and access control system, intelligent unmanned supermarkets and customs clearance ports become the pioneer fields of face recognition applications. It can be seen that the era of “national face brushing” has arrived, and the application of face recognition technology will only be more and more widespread in the current era and in the future. However, due to the sensitivity of biometric data and the heterogeneity and openness of network environment, the privacy leakage of biometric data is difficult to avoid. At present, fog computing and edge computing have been paid more and more attention in many fields. In the case that cloud service providers are unable to provide sufficient security, edge computing shows its advantages. In this paper, mobile edge computing is introduced for the first time into the face privacy protection identity authentication system based on cloud server outsourcing computing. It can not only greatly reduce the interaction frequency between users and cloud server, improve the availability and fault tolerance of the system, but also contribute to the implementation of privacy protection scheme. A deep constitutional neural network for face feature extraction is trained using deep learning framework Cafe. Cosine similarity is used to complete face verification. A privacy protection scheme based on the secure nearest neighbor algorithm is proposed, which can not only protect the security of the face feature data at the edge computing node, but also allow the edge computing node to complete the face recognition operation against the encrypted face feature data. In addition, the encryption scheme does not require large computing resources, and the accuracy of face recognition in cipher text is exactly the same as that in explain. At present, most of the solutions either have high computational complexity or poor security performance. How to reduce the computational complexity and improve the real-time performance of the system while ensuring the high security of the private data has important research significance and value. Therefore, in the cloud server outsourcing computing environment, how to complete biometric identification on the premise of protecting the privacy of biological data has become a research hot spot.",https://ieeexplore.ieee.org/document/9456477/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICBASE51474.2020.00084,Research on multi UAV target detection algorithm in the air based on improved CenterNet,IEEE,Conferences,"In recent years, with the rapid development of UAV technology, the following problems and hidden dangers are increasingly prominent: “unauthorized flight” incidents occur frequently, security risks are serious, and social security is threatened. In order to quickly find UAV targets in these events and take relevant measures, this paper proposes a fast UAV target detection algorithm based on improved CenterNet, which can extract the depth features of the collected images, and use Gaussian kernel function to generate keypoint feature map, and output multiple target location information and category information. By modifying the structure and parameters of feature extraction network, the size of the model is greatly reduced and the running speed of the model is accelerated. At the same time, the detection effect of small target is improved obviously after adding DIoU loss. We train and test the algorithm on our own UAV dataset, and the experimental results achieve high accuracy (48.9 AP) and real-time detection speed (143fps). The improved algorithm is easy to be integrated into the mobile terminal or embedded system, providing support for the next step of alarming, jamming and drive away actions.",https://ieeexplore.ieee.org/document/9403787/,2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),30 Oct.-1 Nov. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICTC46691.2019.8939870,Residual Seq2Seq model for Building energy management,IEEE,Conferences,"According to the UN Department of Economic and Social Affairs (DESA), the global urbanization rate is expected to reach 68% in 30 years from 55% in 2018. As global urbanization progresses, the proportion of total energy consumption consumed in buildings is increasing, and efficient energy management in buildings is becoming increasingly important in terms of efficient use of global natural resources and air quality management. This paper presents an implementation detail of the energy consumption prediction deep learning model for efficient building energy management. The developed model is multilayer LSTM seq2seq model which predicts energy consumption for one day by using environmental data and energy consumption data measured in a real testbed. In a multi-zone building, one zone of data is used, which is characterized by the fact that data patterns over time are not neatly repeated. This paper presents deep learning depth and performance changes as adding layers of seq2seq model in building energy consumption forecasting. In addition, it presents performance comparison with other algorithms.",https://ieeexplore.ieee.org/document/8939870/,2019 International Conference on Information and Communication Technology Convergence (ICTC),16-18 Oct. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSAI.2017.8248529,Resource quality prediction based on machine learning algorithms,IEEE,Conferences,"Many resources today are shared freely through social network or cloud storage platforms, which are helpful for uses to acquire data or exchange information. Unfortunately, due to the unrestricted participations, some resources with advertisements or fraud are also uploaded, which force users to hit the ad websites or steal users' data. Therefore, the quality evaluation of one resource is needed for users to judge whether to utilize or install it. In this paper, we implement a system to evaluate the quality based on software install packages, which applies four algorithms to forecast the quality scores. We conduct an extensive experimental study on a real dataset and find that the prediction can be performed in less than one second (0.002s~0.04s) and with a high accuracy (82.84%~90.52%).",https://ieeexplore.ieee.org/document/8248529/,2017 4th International Conference on Systems and Informatics (ICSAI),11-13 Nov. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACII.2013.88,Reversal Learning Based on Somatic Markers,IEEE,Conferences,"One of the main aspects in the field of Artificial Intelligence is the creation of agents with the ability to learn like human beings do. Based on made experiences humans are able to adapt their behaviour in order to solve tasks. Another important aspect of human decision making is the ability to discard learned behaviour when the usual decisions, concerning a stimulus, lead to a bad outcome. For robots intended to be embedded in a social environment, the adaptability of behaviour is an important factor. Research of human decision behaviour shows, that emotions play a decisive role, even for learning and reversal learning. In this paper, improvements and further results of a previously presented framework for decision making based on an emotional memory are presented. The improvements include the reduction of the amount of previous knowledge that has to be implemented and an evaluation concerning reversal learning. For evaluation purposes, a typical reversal learning task, performed by real subjects, has been used. The results show that this framework allows the adaption of behaviour comparable to human subjects and offers decisive improvements, which lead to better results in reversal learning tasks without the need to directly declare a task as such one.",https://ieeexplore.ieee.org/document/6681479/,2013 Humaine Association Conference on Affective Computing and Intelligent Interaction,2-5 Sept. 2013,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICICPI.2016.7859671,Review and study of internet of things: It's the future,IEEE,Conferences,"Internet of things represents a groundbreaking vision of technological, economic and social significance. This paper is designed to help technology enthusiasts navigate the dialogue surrounding the same, be well versed in IoT and understand its potential to change everything we know to be true today. In this new era of technology, Internet of Things (IoT) has the true potential to make computing ubiquitous - a concept introduced by Mark Weiser in early 1990s. Machine to machine, computer to objects, environment to computers, intelligent systems - “The internet of everything”, is where the potential seems to be endless. IoT can be seen as a universal global neural network of connected things in the cloud where smart machines interact and communicate with other machines, objects, infrastructure and the environment. As a result of which, exponential amount of data is generated and processed into actions that has the ability to command and control things making our everyday life much easier. This paper concludes with a discussion around social and commercial issues likely to surface when Internet of Things becomes a household reality.",https://ieeexplore.ieee.org/document/7859671/,2016 International Conference on Intelligent Control Power and Instrumentation (ICICPI),21-23 Oct. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA48506.2021.9560893,Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning,IEEE,Conferences,"Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/&#x223C;cdarpino/socialnavconstrained/",https://ieeexplore.ieee.org/document/9560893/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2017.8022736,Routing algorithm based on ant colony optimization for mobile social network,IEEE,Conferences,"Mobile social network (MSN) is a type of delay tolerant network explicitly considering social characteristics of the terminal nodes. The existing Ad Hoc routing protocols assume that there is at least one complete communication path between the source node and the target node. So they cannot be applied to MSN directly. The key to solve the problem of content distribution in mobile social network is how to transmit the data to the target node in the case of there is no complete communication path between the source node and the target node. As the routing algorithm based on ant colony optimization has great ability to adapt it, it is an effective method to deal with the dynamic topologies of MSN. Based on the social network characteristics of MSN, this paper proposes a new MSN routing algorithm ACOMSN based on ant colony optimization. The algorithm uses the method of processing the node information on the transmission path to get the information list between the node pairs, so as to select the appropriate relay node to provide effective information when forwarding data to other nodes. In addition, ACOMSN designs methodologies for pheromone updating and data forwarding. The simulation experiments on real data sets show that comparing with typical MSN routing algorithms, ACOMSN can effectively improve the critical performance of data transmission with considerable overhead in MSN.",https://ieeexplore.ieee.org/document/8022736/,"2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",26-28 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CLOUD.2009.80,Rule-Based Problem Classification in IT Service Management,IEEE,Conferences,"Problem management is a critical and expensive element for delivering IT service management and touches various levels of managed IT infrastructure. While problem management has been mostly reactive, recent work is studying how to leverage large problem ticket information from similar IT infrastructures to probatively predict the onset of problems. Because of the sheer size and complexity of problem tickets, supervised learning algorithms have been the method of choice for problem ticket classification, relying on labeled (or pre-classified) tickets from one managed infrastructure to automatically create signatures for similar infrastructures. However, where there are insufficient preclassified data, leveraging human expertise to develop classification rules can be more efficient. In this paper, we describe a rule-based crowdsourcing approach, where experts can author classification rules and a social networking-based platform (called xPad) is used to socialize and execute these rules by large practitioner communities. Using real data sets from several large IT delivery centers, we demonstrate that this approach balances between two key criteria: accuracy and cost effectiveness.",https://ieeexplore.ieee.org/document/5283873/,2009 IEEE International Conference on Cloud Computing,21-25 Sept. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/UBMYK48245.2019.8965480,Rumor Detection in Social Media Using Machine Learning Methods,IEEE,Conferences,"Throughout history, people have always wondered whether a word or writing is real. Whether or not that word was true depends on the person who spoke it. While the word of a trusted person was respected, the word of an unreliable person was believed to be rumor. Today, with the development of social networks, the amount of information circulating on the internet has increased rapidly. However, the reliability of this data is disputable. It is an undeniable fact that there will be gossip in the environment with so many unconfirmed data. Thus, efficiently detection of rumor is an important and hot topic. In this study, the detection of rumor in online social media is modeled as a classification problem, and the success of supervised machine learning methods in real data is assessed. OneR (One Rule), Naive Bayes, ZeroR, JRip, Random Forest, Sequential Minimal Optimization, and Hoeffding Tree algorithms are applied on rumor detection problem and comprehensive evaluation is provided.",https://ieeexplore.ieee.org/document/8965480/,2019 1st International Informatics and Software Engineering Conference (UBMYK),6-7 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICSESS.2018.8663917,Rumor Detection on Twitter with Hierarchical Attention Neural Networks,IEEE,Conferences,"Social media has become an integral part of peoples agenda life, however social media also plays a vital role in communication and information dissemination, making it an ideal platform for spreading rumors. Automatically debunking rumors at their stage of diffusion is known as early rumor detection. However, automatic rumor detection is technically very difficult and uncertain. In this work, we try to build a model to learn extracted features from tweets content by concentrating their posts and generate more meaningful representations to identify different type of rumors. This paper presents a deep hierarchical attention model on the basis of recurrent neural networks (RNN) for rumor representation learning and classification. Extensive experiments on real datasets which collected from social media web sites (mainly on twitter) demonstrate that the deep hierarchical attention based RNN model outperforms state-of-the-arts that rely on hand-crafted features.",https://ieeexplore.ieee.org/document/8663917/,2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS),23-25 Nov. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MASS.2019.00022,SHAD: Privacy-Friendly Shared Activity Detection and Data Sharing,IEEE,Conferences,"Nowadays, there is a growing demand for sharing multimedia data among participants in the same activity. With existing social applications, users need to conduct friending and data sharing operations manually, which is troublesome due to changing attendees and highly diverse data content of different activities. To tackle this issue, in this work we propose a novel system SHAD to achieve privacy-friendly shared activity detection and multimedia data auto-sharing based on users' historical multimodal data. Facing noisy, incomplete and asynchronous data, as well as inaccurate recognition results of machine learning models, we design an algorithm to aggregate multimodal data relevant to the same activity and propose an activity-semantic graph to comprehensively characterize each activity by fusing knowledge of multimodal data. Based on the activity-semantic graph, the privacy-preserving shared activity detection and data sharing method is designed, which protects both raw data and semantic information of data. We implemented our system and conducted comprehensive evaluations with real-life multimodal data (including photos and motion sensor data). The results show the efficacy of our system. We can achieve 94.9% precision and 91.5% recall for shared activity detection.",https://ieeexplore.ieee.org/document/9077362/,2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems (MASS),4-7 Nov. 2019,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICter53630.2021.9774824,SMART Garbage Bin Kit: Expandable and Intelligent Waste Management System using Deep Learning and IoT for Modern Organizations,IEEE,Conferences,"According to published statistics, Sri Lanka produces garbage around 7000MT per day, and every organization directly contributes this national amount depending on the waste management practices. 'Waste contamination' is a critical issue that affects waste management, and it should be addressed during the garbage collection process. This has led to environmental hazards resulting in health and other social issues. Hence, it is a responsibility of an organization to separate the garbage during the collection process using a suitable technique. In this paper, we are proposing a smart garbage bin kit that automates the separation of garbage collection, which minimizes human error using AI-based technologies. IoT-based devices connected to a smart garbage bin kit guide the user to the correct bin. At the same time, our proposed system can be easily expanded for new special waste categories as well. The other important issue of the current garbage management is improper time management of the garbage removal process in organizations. This happens due to the lack of real-time data on waste bins, and collection is based on the fixed time interval irrespective of the status and location of garbage bins. In the proposed system of SMART Garbage Bin Kit, the group of all interconnected garbage bins is monitored in real-time to identify the optimum collection path considering the location and the status of garbage bins using an optimized algorithm. Hence, the study presented in this paper integrates several intelligent approaches together with IoT based network to build a cutting-edge device, declared as SMART Garbage Bin kit. The prototype system has been built as a part of the research study to demonstrate its feasibility and sustainability.",https://ieeexplore.ieee.org/document/9774824/,2021 21st International Conference on Advances in ICT for Emerging Regions (ICter),2-3 Dec. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ANTS.2017.8384099,SMEAD: A secured mobile enabled assisting device for diabetics monitoring,IEEE,Conferences,"Wearable health devices, mobile apps and diagnostic tools revolutionize the medical field by introducing new assisting devices for patients in a way to create comfort, communication and augmented intelligence. Internet of Things involved in this transformation to provide an environment where a patient's vital parameters get transmitted by sensor devices via a gateway onto secure cloud-based platforms where it is stored, aggregated and analyzed. It also helps to store data for millions of patients and performs analysis in real time, ultimately promoting an evidence-based medicine system. Privacy and security are concerns in this environment. Based on the latest trends, this paper introduces a new healthcare paradigm named as SMEAD by developing an end-to-end secured system for assisting diabetic patients. It includes wearables to monitor different parameters thus observe and predict the diabetes status of the patient. The proposed system employs a MEDIBOX which is used to configure the dosage required and provides an alert to the users reminding them to take medication on time. In this case, the insulin dosage is maintained at suitable cooling conditions and is continuously monitored using the mentioned system. To keep all the data secure and to enable access to this data by the doctor and other trusted parties, a Blockchain-based disruptive technology is implemented which facilitates cryptographic security and formalized data access through smart contracts for medical communities. In case of an emergency like missing a dosage, abnormal blood sugar levels or any security lapse, an alert is sent to the caretakers via social networks like Twitter, Facebook or WhatsApp using mobile as a gateway which can continuously communicate the data over the internet that could save patients from fatal effects of the disease.",https://ieeexplore.ieee.org/document/8384099/,2017 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS),17-20 Dec. 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/MDM48529.2020.00041,STIMULATE: A System for Real-time Information Acquisition and Learning for Disaster Management,IEEE,Conferences,"Real-time information sharing and propagation using social media such as Twitter has proven itself as a potential resource to improve situational awareness in a timely manner for disaster management. Traditional disaster management systems work well for analyzing static and historical information. However, they cannot process dynamic streams of data that are being generated in real-time. This paper presents STIMULATE - a System for Real-time Information Acquisition and Learning for Disaster Management that can (1) fetch and process tweets in real-time, (2) classify those tweets into FEMA defined categories for rescue priorities using pre-trained deep learning models and generate useful insights, (3) find FEMA defined stranded people for rescue missions of varying priorities, and (4) provide an interactive web interface for rescue management given the available resources. The STIMULATE prototype is primarily built using the Python Flask framework for web interaction. Additionally, it is deployed in the cloud environment using Hadoop and MongoDB for scalable storage, and on-demand computing for processing extensive social media data. The deep learning models in the STIMULATE prototype use Python Keras and the TensorFlow library. We use Bi-directional Long Short-Term Memory (BLSTM) and Convolutional Neural Network (CNN) for developing the tweet classifier. Further, we use the Python PyWSGI WebSocket server for rescue scheduling operations. We present a deep learning system trained on hurricane Harvey and Irma datasets only. The tweet classifier is evaluated using 15 different disaster datasets. Finally, we present the results of multiple simulations using synthetic data with different sizes to measure the performance and effectiveness of the tweets processor and rescue scheduling algorithm.",https://ieeexplore.ieee.org/document/9162220/,2020 21st IEEE International Conference on Mobile Data Management (MDM),30 June-3 July 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IPDPSW52791.2021.00138,ScaDL 2021 Invited Speaker-3: AI for Social Impact: Results from multiagent reasoning and learning in the real world,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. With the maturing of AI and multiagent systems research, we have a tremendous opportunity to direct these advances towards addressing complex societal problems. I focus on the problems of public health and conservation, and address one key cross-cutting challenge: how to effectively deploy our limited intervention resources in these problem domains. I will present results from work around the globe in using AI for HIV prevention, Maternal and Child care interventions, TB prevention and COVID modeling, as well as for wildlife conservation. Achieving social impact in these domains often requires methodological advances. To that end, I will highlight key research advances in multiagent reasoning and learning, in particular in, computational game theory, restless bandits and influence maximization in social networks. In pushing this research agenda, our ultimate goal is to facilitate local communities and non-profits to directly benefit from advances in AI tools and techniques.",https://ieeexplore.ieee.org/document/9460613/,2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),17-21 June 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICMLC.2003.1264525,Scenario-based agent design,IEEE,Conferences,"Application designers, such as non-computer professionals, cannot directly describe interaction by agent communication languages (e.g., KQML and FIPA ACL) for designing proper applied agents. To bridge the gap between agents and their social usage, Q language - a scenario description language for describing interaction among agents and users is emerging. In order to explore Q language's capability in real agent environment, we applied it in the fields such as semantic information searching on the semantic web and agent-mediated negotiation in e-commerce.",https://ieeexplore.ieee.org/document/1264525/,Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693),5-5 Nov. 2003,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ICCC51575.2020.9345086,Secure and Transparent Public-key Management System for Vehicular Social Networks,IEEE,Conferences,"Vehicular Social Networks (VSNs) are expected to become a reality soon, where commuters having common interests in the virtual community of vehicles, drivers, passengers can share information, both about road conditions and their surroundings. This will improve transportation efficiency and public safety. However, social networking exposes vehicles to different kinds of cyber-attacks. This concern can be addressed through an efficient and secure key management framework. This study presents a Secure and Transparent Public-key Management (ST-PKMS) based on blockchain and notary system, but it addresses security and privacy challenges specific to VSNs. ST-PKMS significantly enhances the efficiency and trustworthiness of mutual authentication. In ST-PKMS, each vehicle has multiple short-lived anonymous public-keys, which are recorded on the blockchain platform. However, public-keys get activated only when a notary system notarizes it, and clients accept only notarized public-keys during mutual authentication. Compromised vehicles can be effectively removed from the VSNs by blocking notarization of their public-keys; thus, the need to distribute Certificate Revocation List (CRL) is eliminated in the proposed scheme. ST-PKMS ensures transparency, security, privacy, and availability, even in the face of an active adversary. The simulation and evaluation results show that the ST-PKMS meets real-time performance requirements, and it is cost-effective in terms of scalability, delay, and communication overhead.",https://ieeexplore.ieee.org/document/9345086/,2020 IEEE 6th International Conference on Computer and Communications (ICCC),11-14 Dec. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/IWISA.2009.5073107,Self-Organization Behaviors of Intelligent Antagonism Target Team of Air Combat Based on Pi-Calculus,IEEE,Conferences,"In order to improve the reality and the reliability of the current air combat simulation and the airborne weapon system evaluation in uncertain, hostile, complex and dynamic air combat environment, we propose an intelligent antagonism target team of air combat based on MAS (multi-agent system) under presented research results. To improve the social mental attribution of the target team, we develop a BGOP (belief, goal, obligation, plan) model under the basis of the traditional BDI(belief, desire and intention) model, which represents the mental states of each target agent, and which has the mental attributions related to the combat utilities which affecting the command control decision of the target agent firstly, and then an organization structure of the command control system of target team, is presented, and the self-organization process of the target team combat behaviors, such as task-assignment, task-maintain, task-change, and the task-coordination etc. are described by pi-calculus.",https://ieeexplore.ieee.org/document/5073107/,2009 International Workshop on Intelligent Systems and Applications,23-24 May 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2012.66,Semi-Supervised Policy Recommendation for Online Social Networks,IEEE,Conferences,"Fine grain policy settings in social network sites is becoming a very important requirement for managing user's privacy. Incorrect privacy policy settings can easily lead to leaks in private and personal information. At the same time, being too restrictive would reduce the benefits of online social networks. This is further complicated with the growing adoption of social networks and with the rapid growth in information uploading and sharing. The problem of facilitating policy settings has attracted numerous access control, and human computer interaction researchers. The solutions proposed range from usable interfaces for policy settings to automated policy settings. We propose a fine grained policy recommendation system that is based on an iterative semi-supervised learning approach that uses the social graph propagation properties. Active learning and social graph properties were used to detect the most informative instances to be labeled as training sets. We implemented and tested our approach using real Facebook dataset. We compared our proposed approach to supervised learning and random walk approaches. Our proposed approaches provided high accuracy and precision when compared to the other approaches.",https://ieeexplore.ieee.org/document/6425738/,2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,26-29 Aug. 2012,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/BigMM.2015.26,Semi-supervised Multimodal Clustering Algorithm Integrating Label Signals for Social Event Detection,IEEE,Conferences,"Photo-sharing social media sites provide new ways for users to share their experiences and interests on the Web, which aggregate large amounts of multimedia resources associated with a wide variety of real-world events in different types and scales. In this work, we aim to tackle social event detection from these large amounts of image collections by devising a semi-supervised multimodal clustering algorithm, denoted by SSMC, which exploits label signals to guide the fusion of the multimodal features. Particularly, SSMC takes advantage of the distribution over the similarities on a small amount of labeled data to represent the images, fusing multiple heterogeneous features seamlessly. As a result, SSMC has low computational complexity in processing multimodal features for both initial and updating stages. Experiments are conducted on the Mediaeval social event detection challenge, and the results show that our approach achieves better performance compared with the baseline algorithms.",https://ieeexplore.ieee.org/document/7153853/,2015 IEEE International Conference on Multimedia Big Data,20-22 April 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/CEEICT.2016.7873080,Sentiment analysis on facebook group using lexicon based approach,IEEE,Conferences,"Internet is one of the primary sources of Big Data. Rise of the social networking platforms are creating enormous amount of data in every second where human emotions are constantly expressed in real-time. The sentiment behind each post, comments, likes can be found using opinion mining. It is possible to determine business values from these objects and events if sentiment analysis is done on the huge amount of data. Here, we have chosen FOODBANK which is a very popular Facebook group in Bangladesh; to analyze sentiment of the data to find out their market values.",https://ieeexplore.ieee.org/document/7873080/,2016 3rd International Conference on Electrical Engineering and Information Communication Technology (ICEEICT),22-24 Sept. 2016,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/SNPD.2017.8022756,Share-housing allocation information service system based on Pareto optimality,IEEE,Conferences,"Compared to living alone, sharing housing with others is usually much cheaper. Meanwhile, share-housing life would exert mammoth impact on people's social activity and self development by help them save house rental cost and improve their life quality. This paper proposes an allocation information system for share-housing management, which takes into account preference on roommates' living habits, working performance and geography distribution. Moreover, Pareto optimality is utilized to facilitate the effect of share-housing allocation. Results of case study show that the three factors of living habits, working performance as well as geography distribution should be synthetically applied as a decision support for share-housing.",https://ieeexplore.ieee.org/document/8022756/,"2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",26-28 June 2017,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/COMPSAC51774.2021.00240,Shared-latent Variable Network Alignment,IEEE,Conferences,"The increasing popularity and diversity of social media sites, has encouraged many people to participate in different online social networks to enjoy a variety of services. Linking the same users across different social networks, also known as social network alignment, is a critical task of great research challenges. Many existing works usually focus on finding a projection function from one subspace to another for network alignment, however, the projection functions proposed in their papers are independent and updated individually, which could not effectively exploit the non-parallel data, and yield inferior alignment performance. In this paper, we propose a Shared-latent Variable Network Alignment (SVNA) architecture to effectively exploit the non-parallel data for network alignment, and jointly train projection functions and decoders in a unified framework with the shared latent variable z. Specifically, SVNA first employs the graph convolutional networks to preserve the structural information of the network. By introducing the shared latent variable z, SVNA simultaneously integrates two projection functions and two decoders for jointly training. Both projection functions and decoders share the same latent space, therefore both projection directions can learn from the non-parallel data more effectively. Thereafter, SVNA utilizes the Generative Adversarial Networks (GANs) framework to further train the projection functions, and adopts a probability-based semi-supervised method to achieve the network alignment. Experiments on three real-world datasets show that SVNA generally outperforms the state-of-the-art methods in network alignment task.",https://ieeexplore.ieee.org/document/9529755/,"2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",12-16 July 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ACII.2009.5349428,Simulation of the dynamics of virtual characters' emotions and social relations,IEEE,Conferences,"One of the main challenges is to give life to believable virtual characters. Research shows that emotions and social relations, closely related, play a key role in determining the behavior of individuals. In order to improve the believ-ability of virtual characters' behavior, we propose in this article a method to compute virtual characters emotions based on attitudes and a model of their influence on the dynamics of social relations. Based on this work, a tool aiming at the simulation of the evolution of emotions and social relations of virtual characters have been implemented.",https://ieeexplore.ieee.org/document/5349428/,2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops,10-12 Sept. 2009,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/EEBDA53927.2022.9744906,Smart Guide Trolley Mango: Smart Blind Guide Device Based on Raspberry Pi,IEEE,Conferences,"Nowadays, life support equipment for the visually impaired is not perfect, and the current blind guide equipment cannot meet the needs of the blind in the face of emergencies. Therefore, this paper proposes an intelligent traction guidance trolley &#x201C;Mango&#x201D;, With good portability and accurate positioning, it is more suitable for the needs of blind people than traditional guidance tools. Mode 1 is the traction and obstacle avoidance mode. This mode firstly plays the current temperature, humidity, location and weather informa2tion to the blind. If the human body infrared sensor detects that the blind person is following, the voice will then broadcast &#x201C;Blind person is following&#x201D; and activa.go automatically advances and executes the tracing algorithm to guide blind along the blind path. Meanwhile, the best way to avoid obstacles is selected according to the ultrasonic obstacle avoidance algorithm, and information about the identified obstacles ahead is broadcast by voice to guide the blind person around the blind path or other obstacles in the walking path. Mode 2 is the remote monitoring mode. This means that by observing the view of the real-time camera, the family or friends of the blind can remotely control the trolley to find them or guide them with the trolley movements by opening the designated website on any computer or mobile phone and entering commands to control the movement of the Mango. In summary, the smart trolley Mango in this paper is a smart guided trolley that can help the blind to travel safely, and provides a new social direction for improving the quality of life of the visually impaired.",https://ieeexplore.ieee.org/document/9744906/,"2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)",25-27 Feb. 2022,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/ASONAM.2018.8508382,Social Bots for Online Public Health Interventions,IEEE,Conferences,"According to the Center for Disease Control and Prevention, hundreds of thousands initiate smoking each year, and millions live with smoking-related diseases in the United States. Many tobacco users discuss their opinions, habits and preferences on social media. This work conceptualizes a framework for targeted health interventions to inform tobacco users about the consequences of tobacco use. We designed a Twitter bot named Notobot (short for No-Tobacco Bot) that leverages machine learning to identify users posting pro-tobacco tweets and select individualized interventions to curb their tobacco use. We searched the Twitter feed for tobacco-related keywords and phrases, and trained a convolutional neural network using over 4,000 tweets manually labeled as either pro-tobacco or not pro-tobacco. This model achieved a 90% accuracy rate on the training set and 74% on test data. Users posting protobacco tweets were matched with former smokers with similar interests who posted anti-tobacco tweets. Algorithmic matching, leveraging the power of peer influence, allows for the systematic delivery of personalized interventions based on real anti-tobacco tweets from former smokers. Experimental evaluation suggested that our system would perform well if deployed.",https://ieeexplore.ieee.org/document/8508382/,2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),28-31 Aug. 2018,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/AIVR52153.2021.00034,Social Crowd Simulation: The Challenge of Fragmentation,IEEE,Conferences,"Crowd simulation is the process of simulating the movement and behavior of a large number of people. This field is continuously being improved by incorporating different theories of how humans move and interact with their surroundings, steadily increasing the realism of the simulation. Furthermore, new techniques for calibrating simulation parameters, and evaluating the accuracy of simulation output, keep being proposed. This paper presents a brief overview of these foundations and argues that a fragmentation of the field into multiple incompatible solutions may impede progress towards comprehensive social behavior models. It finally argues that abstractions of human intent and behavior, proposed within the Embodied Conversational Agents community, may suggest a useful path towards bringing social crowds to new levels of realism.",https://ieeexplore.ieee.org/document/9644355/,2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),15-17 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/APCCAS51387.2021.9687720,Social Distancing Surveillance System via Inverse Perspective Mapping and Fixed-point Quantization,IEEE,Conferences,"During the Coronavirus Disease 2019 (COVID-19) pandemic, many countries have introduced the social distancing policy in public areas to stop the spread of disease by maintaining a physical distance between people. This paper proposes an Artificial Intelligence (AI)-powered social distancing surveillance system that can detect pedestrians through video surveillance and monitor the social distance between them via Inverse Perspective Mapping (IPM) in real-time. The proposed system was deployed on the devices located at the network edge such as IoT devices and mobile devices to enable real-time response with low data transmission latency. To bypass the restriction on the computational and memory capacity for the edge devices, the proposed system was optimized through fixed-point quantization. From the evaluation results, the optimized models are almost 4 times smaller as compared to the original models. The best trade-off between speed and accuracy can be achieved with a 27.1&#x0025; improvement in speed and 2&#x0025; degradation in accuracy.",https://ieeexplore.ieee.org/document/9687720/,2021 IEEE Asia Pacific Conference on Circuit and Systems (APCCAS),22-26 Nov. 2021,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/WISA.2015.48,Social Emotion Analysis System for Online News,IEEE,Conferences,"Social emotion analysis of online users has become an important task for mining public opinions, which aims at detecting the readers' emotions evoked by online news articles. In this paper, we focus on building a social emotion analysis system (SEAS) for online news. The system has implemented a text data crawler for mainstream online news websites, the modules of document preprocessing, document representation, and also integrates successful emotion analysis methods and provides the corresponding performance evaluation. SEAS will automatically analyze the emotions towards certain news articles and output the predicted emotions and probabilities of being classified into these emotion categories. The experiments on the real dataset from online news service demonstrate the high practicability and reliability of SEAS.",https://ieeexplore.ieee.org/document/7396605/,2015 12th Web Information System and Application Conference (WISA),11-13 Sept. 2015,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1109/icABCD49160.2020.9183860,Social Event Invitation and Recommendation for Event based Social Networks,IEEE,Conferences,Event based social networks enable users to make real connections with both the real and virtual worlds. This research aims at providing a way to increase user satisfaction at the events they attend from the event based social network. Two approaches are explained and used to determine the user's interests from the events they have attended and also through the sentiment analysis of the reviews they have given for these events. A profile specific to each user is developed to support event recommendations to users in the system based on a matching profile and a set of at least K friends on the social network. The paper uses content-based filtering by using the events details to make recommendations and collaborative filtering to find users who have similar interests. Lastly the sentiment of event reviews is determined to gain an understanding about how users feel about the events they attended. This sentiment data is integrated into the recommendation of events. The paper also discusses the results achieved and the limitations of the current state of the algorithm.,https://ieeexplore.ieee.org/document/9183860/,"2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)",6-7 Aug. 2020,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
