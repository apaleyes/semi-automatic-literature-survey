id,type,publication,publisher,publication_date,database,title,url,abstract,query_name,query_value
10.1016/j.rcim.2022.102365,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-12-01,sciencedirect,A digital twin-based sim-to-real transfer for deep reinforcement learning-enabled industrial robot grasping,https://api.elsevier.com/content/abstract/scopus_id/85131222861,"Deep reinforcement learning (DRL) has proven to be an effective framework for solving various complex control problems. In manufacturing, industrial robots can be trained to learn dexterous manipulation skills from raw pixels with DRL. However, training robots in the real world is a time-consuming, high-cost and of safety concerns process. A frequently adopted approach for easing this is to train robots through simulations first and then deploy algorithms (or policies) on physical robots. How to transfer policies of robot learning from simulation to the real world is a challenging issue. Digital twin that is able to create a dynamic, up-to-date representation of a physical robotic grasping system provides an effective approach for addressing this issue. In this paper, we focus on the scenario of DRL-based assembly-oriented industrial grasping and propose a digital twin-enabled approach for achieving effective transfer of DRL algorithms to a physical robot. Two parallel training systems, i.e., the physical robotic system and corresponding digital twin system, respectively, are established, which take virtual and real images as inputs. The output of the digital twin system is used to correct the real grasping point so that accurate grasping can be achieved. Experimental results verify the effectiveness of the intelligent grasping algorithm and the digital twin-enabled sim-to-real transfer approach and mechanism.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2022.102371,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-10-01,sciencedirect,A grasps-generation-and-selection convolutional neural network for a digital twin of intelligent robotic grasping,https://api.elsevier.com/content/abstract/scopus_id/85129983234,"Robotic grasping plays an essential role in human-machine cooperation in various household and industrial applications. Although humans can instinctively execute grasps in an accurate, stable, and rapid way even under a constantly changing environment, intelligent grasping remains a challenging task for robots. As a prerequisite for grasping, robots need to correctly identify the best grasping location of unknown objects often based on an artificial intelligence approach, which is still a challenging problem. This paper proposes a new grasps-generation-and-selection convolutional neural network (GGS-CNN), which is trained and implemented in a digital twin of intelligent robotic grasping (DTIRG). By defining a grasp with 3-D position, rotation angle, and gripper width, the GGS-CNN generates grasp candidates by transforming the red–green-blue-depth images (RGB-D images) into feature maps and evaluating the quality of selected grasps. The GGS-CNN is trained in the virtual environment and the real world of the DTIRG to detect accurate grasps. In the grasping tests, the proposed GGS-CNN achieves grasping success rates of 96.7% and 93.8% for grasping single objects and cluttered objects, respectively, and obtains the best grasp from the RGB-D image in less than 40 ms.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2022.102351,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-10-01,sciencedirect,Cloud-edge-device collaboration mechanisms of deep learning models for smart robots in mass personalization,https://api.elsevier.com/content/abstract/scopus_id/85127198043,"Personalized products have gradually become the main business model and core competencies of many enterprises. Large differences in components and short delivery cycles of such products, however, require industrial robots in cloud manufacturing (CMfg) to be smarter, more responsive and more flexible. This means that the deep learning models (DLMs) for smart robots should have the performance of real-time response, optimization, adaptability, dynamism, and multimodal data fusion. To satisfy these typical demands, a cloud-edge-device collaboration framework of CMfg is first proposed to support smart collaborative decision-making for smart robots. Meanwhile, in this context, different deployment and update mechanisms of DLMs for smart robots are analyzed in detail, aiming to support rapid response and high-performance decision-making by considering the factors of data sources, data processing location, offline/online learning, data sharing and the life cycle of DLMs. In addition, related key technologies are presented to provide references for technical research directions in this field.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2022.109245,Journal,Applied Soft Computing,scopus,2022-09-01,sciencedirect,Human action prediction in collaborative environments based on shared-weight LSTMs with feature dimensionality reduction,https://api.elsevier.com/content/abstract/scopus_id/85134563727,"As robots are progressing towards being ubiquitous and an indispensable part of our everyday environments, such as home, offices, healthcare, education, and manufacturing shop floors, efficient and safe collaboration and cohabitation become imperative. Given that, such environments could benefit greatly from accurate human action prediction. In addition to being accurate, human action prediction should be computationally efficient, in order to ensure a timely reaction, and capable of dealing with changing environments, since unstructured interaction and collaboration with humans usually do not assume static conditions. In this paper, we propose a model for human action prediction based on motion cues and gaze using shared-weight Long Short-Term Memory networks (LSTMs) and feature dimensionality reduction. LSTMs have proven to be a powerful tool in processing time series data, especially when dealing with long-term dependencies; however, to maximize their performance, LSTM networks should be fed with informative and quality inputs. Given that, in this paper, we furthermore conducted an extensive input feature analysis based on (i) signal correlation and their strength to act as stand-alone predictors, and (ii) a multilayer perceptron inspired by the autoencoder architecture. We validated the proposed model on a publicly available MoGaze
                        1
                     
                     
                        1
                        
                           https://humans-to-robots-motion.github.io/mogaze/.
                      dataset for human action prediction, as well as on a smaller dataset recorded in our laboratory. Our model outperformed alternatives, such as recurrent neural networks, a fully connected LSTM network, and the strongest stand-alone signals (baselines), and can run in real-time on a standard laptop CPU. Since eye gaze might not always be available in a real-world scenario, we have implemented and tested a multi-layer perceptron for gaze estimation from more easily obtainable motion cues, such as head orientation and hand position. The estimated gaze signal can be utilized during inference of our LSTM-based model, thus making our action prediction pipeline suitable for real-time practical applications.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2022.105164,Journal,Engineering Applications of Artificial Intelligence,scopus,2022-09-01,sciencedirect,Pose estimation and robotic insertion tasks based on YOLO and layout features,https://api.elsevier.com/content/abstract/scopus_id/85133819972,"In this study, we proposed a practical scheme for the challenging robotic cable insertion task. In general, the applied architecture is based on two YOLOs, vision-based pose estimation and admittance control. A precise and effective method was developed to estimate the pose of a manipulated connector. Our method uses a deep convolutional neural network to detect the relevant regions in the image. The characteristics of these relevant regions along with the pins’ layout manifold are combined to conduct the estimation. Practical problems such as error examination and time efficiency were considered in the proposed method for real applications. An admittance controller is introduced to experimentally validate the performance of pose estimation and provide compliant insertion by the proposed architecture. Our method is only based on less prior layout knowledge and does not require a precise model, which facilitates modeling and deployment. In addition, our method is robust to image quality and has low computational complexity, which makes it highly suitable for online manipulation. Besides, our method can handle multiple connector types which can cover most cases in aeronautical manufacturing and guide the design of connectors in the production process. The advantages of our method were demonstrated by extensive testing using both synthetic data and experiments. We also designed an insertion controller and realized a complete insertion task using a PC with a 12 GB RTX 3060 GPU and 32 GB RAM. These experimental results show that our method can achieve precise and reliable estimation with mean absolute errors less than 0.44 deg and 0.36 mm, an estimation accuracy of over 99%, and a successful manipulation rate of over 94%. This reveals that the proposed method displays potential for the challenging robotic cable insertion task.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2022.108163,Journal,Computers and Electrical Engineering,scopus,2022-09-01,sciencedirect,Intelligent energy and ecosystem for real-time monitoring of glaciers,https://api.elsevier.com/content/abstract/scopus_id/85133281340,"The United Nations is deeply concerned about global warming and its impacts on natural resources. Simultaneously, it has been recommended that cutting-edge technologies be employed to predict the impact of climate change on natural reservoirs such as glaciers. With the motivation of the above facts, this study investigates the impact and significance of emerging and cutting-edge technologies like Remote Sensing, the Internet of Things (IoT), Artificial Intelligence (AI), Unmanned Aerial Vehicles (UAVs), and robots implementation for the digitalization in glaciers. The study identified that convergence of AI, Machine Learning (ML), and Deep Learning approaches with Spatio-temporal data empowers to detect non-linear characteristics, especially in high mountainous regions due to their diversity and unpredictable nature. The article suggested valuable recommendations such as establishing an intelligent eco-system in glaciers, low-cost intelligent IoT devices with intelligent energy algorithms, ML empowered edge devices, glacier-resistant rescue robots, and Wearable IoT-based safety guide devices.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2022.104158,Journal,Robotics and Autonomous Systems,scopus,2022-09-01,sciencedirect,Development of an autonomous fog computing platform using control-theoretic approach for robot-vision applications,https://api.elsevier.com/content/abstract/scopus_id/85131700902,"This paper presents the dynamic modelling and linear matrix inequality (LMI) based controller design of a distributed fog computing framework for real-time robot vision applications. A mobile robot vision system acquires the images from an application environment such as a warehouse, where articles are stacked in numerous racks. We characterise the mobile robot vision data (MRVD) using frames per second (FPS) and the image resolution. From the MRVD, object detection is performed by an open-source deep learning (DL) platform for detecting and localising various objects. However, with higher FPS together with high-resolution images, the processing time by the DL algorithm increases significantly. This necessitates the deployment of a distributed computing platform with several computing nodes. In this work, we deploy a distributed fog computing environment (DFCE) for the real-time object detection in an application environment.
                  The processing time required to handle the MRVD is called the service time. However, for efficient auto-scaling performance, the mathematical model of the DFCE, taking into consideration the characteristics of the MRVD is necessary. In this context, we envisage the application of control theory to build the dynamic model of the DFCE. A Linear Parameter Varying (LPV) model is proposed for the DFCE with the service time as the output, the number of fog nodes as the input, and the characteristics of MRVD as the time-varying parameters. At first, an LPV model for the DFCE is derived using system identification, and the model is validated using the real-time test data. The LPV model is converted to a Polytopic LPV (PLPV) model for LMI based controller design. Finally, we develop and validate a Linear Matrix Inequality (LMI) based LPV controller to meet the service time constraints for a given application environment.
                  For localisation and trajectory tracking with obstacle avoidance in the application environment, the mobile robot implements an Extended Kalman Filter (EKF) based simultaneous localisation and mapping (SLAM) and a bug-based path planning algorithm respectively. Finally, we present, detailed controller validation results illustrating the mobile robot navigation together with the auto-scaling control for the fog computing platform to modulate the service time.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2022.109136,Journal,Applied Soft Computing,scopus,2022-08-01,sciencedirect,Dynamic environment prediction on unmanned mobile manipulator robot via ensemble convolutional randomization networks,https://api.elsevier.com/content/abstract/scopus_id/85132884016,"This paper aims to improve the prediction for dynamic environments on unmanned mobile manipulator robot system. When it comes to a simple prediction task, the mobile manipulator robot is undesirable to spend lots of time training a complex neural network. In this paper, the structure of randomization-based neural networks with the convolutional layer named conv-RNet is tested, which reveals that conv-RNet seems to be better than randomization-based neural network with the fully connected layer in terms of accuracy, parameters and computational complexity. Based on the conv-RNet, an ensemble learning architecture named Ensemble convolutional randomization-based neural networks (EC-RNet) is proposed to further optimize the network performance. Here, three problems are mainly solved to optimize this ensemble architecture. The first is how to extract local feature information and decrease the computational complexity. The convolutional layer is used to filter the input to extract features. For producing the fixed number of the hidden layer nodes, the convolutional operation could extract more abundant feature information while maintaining few parameters and low computational complexity than a fully connected operation. The second is how to calculate the number of component learners. Little probability event is used to build a relationship between the number of component learners and the data number in each component dataset. For a given component data, the minimum number of component learners will be determined by this relationship. The third is how to combine the results of component learners to obtain the final result. The confidence level is introduced as the weight to measure the relationship between component results and final results. The combination of component results attaching to different confidence levels is used to calculate the final result. On CIFAR-10, MNIST handwritten digits dataset, and UCI dataset, EC-RNet achieves high accuracy, low computational complexity, and few parameters. Moreover, Experiments on above three datasets show that the proposed EC-RNet+RVFL structure outperforms the proposed EC-RNet+ELM structure. In the real world, the EC-RNet is deployed on the mobile robot and achieves more reliable performance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2022.102833,Journal,Mechatronics,scopus,2022-08-01,sciencedirect,Control framework for collaborative robot using imitation learning-based teleoperation from human digital twin to robot digital twin,https://api.elsevier.com/content/abstract/scopus_id/85130606803,"Despite the deployment of collaborative robots for various industrial processes, their teaching and control remain comparatively difficult tasks compared with general industrial robots. Various imitation learning methods involving the transfer of human poses to a collaborative robot have been proposed. However, most of these methods depend heavily on deep learning-based human recognition algorithms that fail to recognize complicated human poses. To address this issue, we propose an automated/semi-automated vision-based teleoperation framework using human digital twin and a collaborative robot digital twin models. First, a human pose is recognized and reasoned to a human skeleton model using a convolution encoder-decoder architecture. Next, the developed human digital twin model is taught using the skeletons. As human and collaborative robots have different joints and rotation architectures, pose mapping is achieved using the proposed Bezier curve-based smooth approximation. Then, a real collaborative robot is controlled using the developed robot digital twin. Furthermore, the proposed framework works successfully using a human digital twin in the case of recognition failures of human poses. To verify the effectiveness of the proposed framework, transfers of several human poses to a real collaborative robot are tested and analyzed.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.postharvbio.2022.111956,Journal,Postharvest Biology and Technology,scopus,2022-08-01,sciencedirect,Image classification of root-trimmed garlic using multi-label and multi-class classification with deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85129495630,"Garlic root trimming is one of the most tedious tasks in the postharvest processing of garlic since the evaluation of trimming results is done by mainly visual inspection for each label of a garlic bulb. Currently, multi-class classification using a deep convolutional neural network (CNN) can automate the evaluation process. However, it can handle only a single label per a garlic image and cannot be used for evaluation of multi-labels in conventional garlic root trimming practices. This study introduced a modified multi-class model and a multi-label model that utilized CNN to classify two labels of a garlic bulb after root trimming. The first label includes good, bad, untrimmed and scratched classes, and the second label consists of clean and muddy classes. The modified multi-class model achieved a classification accuracy of 82.9% while the multi-label gave a better classification performance of minor classes, with an overall accuracy of 95.2%. With the addition of a background image class, classification accuracies of both multi-class model and multi-label model increased to 91.8% and 98.0%, respectively. The background class significantly enhanced the classification performance of multi-label model when it was deployed to a garlic sorting robot. The utilization of data augmentation, dropout, transfer learning and fine-tuning was confirmed to improve model generalization and performance. Multi-label model is recommended for grading of garlic bulbs with multi-labels of after root trimming. The time to process an image was 0.021 s, which is suitable for a real-time garlic sorting and grading robot. The method shows a potential for development of a smart and fully autonomous robots in the postharvest processing for garlic production.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijhcs.2022.102831,Journal,International Journal of Human Computer Studies,scopus,2022-08-01,sciencedirect,Design patterns for human-AI co-learning: A wizard-of-Oz evaluation in an urban-search-and-rescue task,https://api.elsevier.com/content/abstract/scopus_id/85128204232,"The rapid advancement of technology empowered by artificial intelligence is believed to intensify the collaboration between humans and AI as team partners. Successful collaboration requires partners to learn about each other and about the task. This human-AI co-learning can be achieved by presenting situations that enable partners to share knowledge and experiences. In this paper we describe the development and implementation of a task context and procedures for studying co-learning. More specifically, we designed specific sequences of interactions that aim to initiate and facilitate the co-learning process. The effects of these interventions on learning were evaluated in an experiment, using a simplified virtual urban-search-and-rescue task for a human-robot team. The human participants performed a victim rescue- and evacuation mission in collaboration with a wizard-of-Oz (i.e., a confederate of the experimenter who executed the robot-behavior consistent with an ontology-based AI-model). The designed interaction sequences, formulated as Learning Design Patterns (LDPs), were intended to bring about co-learning. Results show that LDPs support the humans understanding and awareness of their robot partner and of the teamwork. No effects were found on collaboration fluency, nor on team performance. Results are used to discuss the importance of co-learning, the challenges of designing human-AI team tasks for research into this phenomenon, and the conditions under which co-learning is likely to be successful. The study contributes to our understanding of how humans learn with and from AI-partners, and our propositions for designing intentional learning (LDPs) provide directions for applications in future human-AI teams.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2022.102321,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-08-01,sciencedirect,AR-assisted digital twin-enabled robot collaborative manufacturing system with human-in-the-loop,https://api.elsevier.com/content/abstract/scopus_id/85124244817,"The teleoperation and coordination of multiple industrial robots play an important role in today’s industrial internet-based collaborative manufacturing systems. The user-friendly teleoperation approach allows operators from different manufacturing domains to reduce redundant learning costs and intuitively control the robot in advance. Nevertheless, only a few preliminary works have been introduced very recently, let alone its effective implementation in the manufacturing scenarios. To address the gap, this research proposes a novel multi-robot collaborative manufacturing system with human-in-the-loop control by leveraging the cutting-edge augmented reality (AR) and digital twin (DT) techniques. In the proposed system, the DTs of industrial robots are firstly mapped to physical robots and visualize them in the AR glasses. Meanwhile, a multi-robot communication mechanism is designed and implemented, to synchronize the state of robots in the twin. Moreover, a reinforcement learning algorithm is integrated into the robot motion planning to replace the conventional kinematics-based robot movement with corresponding target positions. Finally, three interactive AR-assisted DT modes, including real-time motion control, planned motion control, and robot monitoring mode are generated, which can be readily switched by human operators. Two experimental studies are conducted on (1) a single robot with a commonly used peg-in-hole experiment, and (2) the motion planning of multi-robot collaborative tasks, respectively. From the experimental results, it can be found that the proposed system can well handle the multi-robot teleoperation tasks with high efficiency and owns great potentials to be adopted in other complicated manufacturing scenarios in the near future.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2022.106908,Journal,Computer Methods and Programs in Biomedicine,scopus,2022-07-01,sciencedirect,Prediction of the position of external markers using a recurrent neural network trained with unbiased online recurrent optimization for safe lung cancer radiotherapy,https://api.elsevier.com/content/abstract/scopus_id/85132320728,"Background and Objective: During lung cancer radiotherapy, the position of infrared reflective objects on the chest can be recorded to estimate the tumor location. However, radiotherapy systems have a latency inherent to robot control limitations that impedes the radiation delivery precision. Prediction with online learning of recurrent neural networks (RNN) allows for adaptation to non-stationary respiratory signals, but classical methods such as real-time recurrent learning (RTRL) and truncated backpropagation through time are respectively slow and biased. This study investigates the capabilities of unbiased online recurrent optimization (UORO) to forecast respiratory motion and enhance safety in lung radiotherapy. Methods: We used nine observation records of the three-dimensional (3D) position of three external markers on the chest and abdomen of healthy individuals breathing during intervals from 73s to 222s. The sampling frequency was 10Hz, and the amplitudes of the recorded trajectories range from 6mm to 40mm in the superior-inferior direction. We forecast the 3D location of each marker simultaneously with a horizon value (the time interval in advance for which the prediction is made) between 0.1s and 2.0s, using an RNN trained with UORO. We compare its performance with an RNN trained with RTRL, least mean squares (LMS), and offline linear regression. We provide closed-form expressions for quantities involved in the gradient loss calculation in UORO, thereby making its implementation efficient. Training and cross-validation were performed during the first minute of each sequence. Results: On average over the horizon values considered and the nine sequences, UORO achieves the lowest root-mean-square (RMS) error and maximum error among the compared algorithms. These errors are respectively equal to 1.3mm and 8.8mm, and the prediction time per time step was lower than 2.8ms (Dell Intel core i9-9900K 3.60 GHz). Linear regression has the lowest RMS error for the horizon values 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s, and UORO for horizon values greater than 0.6s. Conclusions: UORO can accurately predict the 3D position of external markers for intermediate to high response times with an acceptable time performance. This will help limit unwanted damage to healthy tissues caused by radiotherapy.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2022.03.026,Journal,Neurocomputing,scopus,2022-06-14,sciencedirect,A review on varying-parameter convergence differential neural network,https://api.elsevier.com/content/abstract/scopus_id/85126975231,"Inspired by the nature of actual dynamics systems with time-varying parameters, varying-parameter convergence differential neural network (termed as VP-CDNN) has been put forward and played a crucial role in obtaining the real-time solution of algebraic equations and optimization problems. Plenty of fruitful literatures report that such a neural network breaks the bottlenecks of the conventional algorithms and presents superior convergence performance and strong anti-noise capability in the time-varying problem solving. This paper presents an overall review about VP-CDNN in different mathematical problems solving such as time-varying quadratic-programming equation, time-varying Sylvester equation, nonlinear and nonconvex equation and so on. Besides its extension forms such as anti-noise VP-CDNN, finite-time VP-CDNN, fuzzy VP-CDNN and discrete-time VP-CDNN are briefly introduced in mathematical problems solving. Additionally, the applications of VP-CDNN in robot motion planning, unmanned aerial vehicles, venture investment and other applications are illustrated for practical implementation. The conclusion summarizes the superiority of VP-CDNN and indicates several future research direction.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2022.e09634,Journal,Heliyon,scopus,2022-06-01,sciencedirect,Smart deployment of IoT-TelosB service care StreamRobot using software-defined reliability optimisation design,https://api.elsevier.com/content/abstract/scopus_id/85131417211,"Intelligent service care robots have increasingly been developed in mission-critical sectors such as healthcare systems, transportation, manufacturing, and environmental applications. The major drawbacks include the open-source Internet of Things (IoT) platform vulnerabilities, node failures, computational latency, and small memory capacity in IoT sensing nodes. This article provides reliable predictive analytics with the optimisation of data transmission characteristics in StreamRobot. Software-defined reliable optimisation design is applied in the system architecture. For the IoT implementation, the edge system model formulation is presented with a focus on edge cluster log-normality distribution, reliability, and equilibrium stability considerations. A real-world scenario for accurate data streams generation from in-built TelosB sensing nodes is converged at a sink-analytic dashboard. Two-phase configurations, namely off-taker and on-demand, link-state protocols are mapped for deterministic data stream offloading. An orphan reconnection trigger mechanism is used for reliable node-to-sink resilient data transmissions. Data collection is achieved, using component-based programming in the experimental testbed. Measurement parameters are derived with TelosB IoT nodes. Reliability validations on remote monitoring and prediction processes are studied considering neural constrained software-defined networking (SDN) intelligence. An OpenFlow-SDN construct is deployed to offload traffic from the edge to the fog layer. At the core, fog detection-to-cloud predictive machine learning (FD-CPML) is used to predict real-time data streams. Prediction accuracy is validated with decision tree, logistic regression, and the proposed FD-CPML. The data streams latency gave 40.00%, 33.33%, and 26.67%, respectively. Similarly, linear predictive scalability behaviour on the network plane gave 30.12%, 33.73%, and 36.15% respectively. The results show satisfactory responses in terms of reliable communication and intelligent monitoring of node failures.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isprsjprs.2022.04.002,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2022-06-01,sciencedirect,Vision based crown loss estimation for individual trees with remote aerial robots,https://api.elsevier.com/content/abstract/scopus_id/85128243118,"With the capability of capturing high-resolution imagery data and the ease of accessing remote areas, aerial robots are becoming increasingly popular for forest health monitoring applications. For example, forestry tasks such as field surveys and foliar sampling which are generally manual and labour intensive can be automated with remotely controlled aerial robots. In this study, we propose two new online frameworks to quantify and rank the severity of individual tree crown loss. The real-time crown loss estimation (RTCLE) model localises and classifies individual trees into their respective crown loss percentage bins. Experiments are conducted to investigate if synthetically generated tree images can be used to train the RTCLE model as real images with diverse viewpoints are generally expensive to collect. Results have shown that synthetic data training helps to achieve a satisfactory baseline mean average precision (mAP) which can be further improved with just some additional real imagery data. We showed that the mAP can be increased approximately from 60% to 78% by mixing the real dataset with the generated synthetic data. For individual tree crown loss ranking, a two-step crown loss ranking (TSCLR) framework is developed to handle the inconsistently labelled crown loss data. The TSCLR framework detects individual trees before ranking them based on some relative crown loss severity measures. The tree detection model is trained with the combined dataset used in the RTCLE model training where we achieved an mAP of approximately 95% suggesting that the model generalises well to unseen datasets. The relative crown loss severity of each tree is estimated, with deep representation learning, by a probabilistic encoder from a fully trained variational autoencoder (VAE) model. The VAE is trained end-to-end to reconstruct tree images in a background agnostic way. Based on a conservative evaluation, the estimated crown loss severity from the probabilistic encoder generally showed moderate agreement with the expert’s estimation across all species of trees present in the dataset. All the software pipelines, the dataset, and the synthetic dataset generation can be found in the GitHub link.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2022.105495,Journal,Computers in Biology and Medicine,scopus,2022-06-01,sciencedirect,Interaction dynamics modeling and adaptive impedance control of robotic exoskeleton for adolescent idiopathic scoliosis,https://api.elsevier.com/content/abstract/scopus_id/85127732896,"Adolescent Idiopathic Scoliosis (AIS), an abnormal lateral curvature of the patient's spine with vertebral rotation, is one of the biggest problems in the orthopedic profession. Non-surgical treatments of AIS, including bracing, has the following limitations: i) sensor-less design and lack of closed-loop control on the motion and forces exerted on the torso result in no adaption to the skeletal changes during the treatment, ii) lack of interaction control may also make the brace inconvenient and insecure for the patient. In this paper, a novel robotic exoskeleton equipped with linear actuators, position, and force sensors is developed to control the motion and forces exerted on the torso. It consists of three Stewart-Gough Platforms (SGP). Robotic AIS rehabilitation is modeled by combining the dynamics formulation of each SGP with the mass-spring-damper model of the thoracic segment and utilizing the inverse dynamics problem to compute the required forces for moving the spine to the desired position. Numerical ADAMS and MATLAB simulations are used to verify the interaction dynamics formulation. In addition, impedance control is used to control the interaction instead of using position and force control separately. A Model Reference Adaptive Impedance Control (MRAIC) is also proposed to compensate for the negative effects of uncertainties existing in the interaction dynamics modeling and improve the interaction control. The performance of the MRAIC is verified and validated using numerical MATLAB simulations and real-time experiments in terms of position tracking and reference impedance model tracking.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2022.102772,Journal,Mechatronics,scopus,2022-06-01,sciencedirect,Design and practical implementation of a Neural Network self-tuned Inverse Dynamic Controller for a 3-DoF Delta parallel robot based on Arc Length Function for smooth trajectory tracking,https://api.elsevier.com/content/abstract/scopus_id/85125853201,"This paper proposes an online Neural Network self-tuned Inverse Dynamic Controller (IDC) for high-speed and smooth trajectory tracking control of a 3-DoF Delta robot. The foregoing approaches provides a suitable controller for a wide range of nonlinear paths and reduce the end-effector oscillations at high speed. To this end, a compact and accurate dynamic model of the system is derived by taking into account actuators and gearbox dynamics. In order to alleviate some drawbacks of a velocity-based controller, such as not being able to track highly dynamic paths, an Inverse Dynamic Controller (IDC) is designed which can perform fast maneuvers accurately. The proposed IDC controller is practically implemented on the robot in following nonlinear paths comparing to the velocity-based controller. Afterward, controller parameters are tuned by resorting to the so-called Arc Length Function (ALF) in order to improve the smoothness of tracking the prescribed path. After that, a Feedforward Neural Network (NN) is trained with the help of the system’s model and Arc Length Function (ALF) to adjust controller coefficients in real-time implementation adaptively. By comparing the Root Mean Square Error (RMSE) results, it can be inferred that the proposed methods can reduce the end-effector oscillations up to 60 percent in practical implementation compared to other dynamic and kinematic methods. As a result, RMSE error is reduced from 0.00603 for the kinematic controller to 0.00063 by applying the NN-IDC.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.urology.2021.10.053,Journal,Urology,scopus,2022-06-01,sciencedirect,Indocyanine Green Drives Computer Vision Based 3D Augmented Reality Robot Assisted Partial Nephrectomy: The Beginning of “Automatic” Overlapping Era,https://api.elsevier.com/content/abstract/scopus_id/85125411428,"Augmented reality robot-assisted partial nephrectomy (AR-RAPN) is limited by the need of a constant manual overlapping of the hyper-accuracy 3D (HA3D) virtual models to the real anatomy. To present our preliminary experience with automatic 3D virtual model overlapping during AR-RAPN. To reach a fully automated HA3D model overlapping, we pursued computer vision strategies, based on the identification of landmarks to link the virtual model. Due to the limited field of view of RAPN, we used the whole kidney as a marker. Moreover, to overcome the limit of similarity of colors between the kidney and its neighboring structures, we super-enhanced the organ, using the NIRF Firefly fluorescence imaging technology. A specifically developed software named “IGNITE” (Indocyanine GreeN automatIc augmenTed rEality) allowed the automatic anchorage of the HA3D model to the real organ, leveraging the enhanced view offered by NIRF technology. Ten automatic AR-RAPN were performed. For all the patients a HA3D model was produced and visualized as AR image inside the robotic console. During all the surgical procedures, the automatic ICG-guided AR technology successfully anchored the virtual model to the real organ without hand-assistance (mean anchorage time: 7 seconds), even when moving the camera throughout the operative field, while zooming and translating the organ. In 7 patients with totally endophytic or posterior lesions, the renal masses were correctly identified with automatic AR technology, performing a successful enucleoresection. No intraoperative or postoperative Clavien >2 complications or positive surgical margins were recorded. Our pilot study provides the first demonstration of the application of computer vision technology for AR procedures, with a software automatically performing a visual concordance during the overlap of 3D models and in vivo anatomy. Its actual limitations, related to the kidney deformations during surgery altering the automatic anchorage, will be overcome implementing the organ recognition with deep learning algorithms.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2021.06.017,Journal,ISA Transactions,scopus,2022-06-01,sciencedirect,Multi-objective optimization technique for trajectory planning of multi-humanoid robots in cluttered terrain,https://api.elsevier.com/content/abstract/scopus_id/85108514869,"Humanoid robots hold a decent advantage over wheeled robots because of their ability to mimic human exile. The presented paper proposes a novel strategy for trajectory planning in a cluttered terrain using the hybridized controller modeled on the basis of modified MANFIS (multiple adaptive neuro-fuzzy inference system) and MOSFO (multi-objective sunflower optimization) techniques. The controller works in a two-step mechanism. The input parameters, i.e., obstacle distances and target direction, are first fed to the MANFIS controller, which generates a steering angle in both directions of an obstacle to dodge it. The intermediate steering angles are obtained based on the training model. The final steering angle to avoid obstacles is selected based on the direction of the target and additional obstacles in the path. It is further works as input for the MOSFO technique, which provides the ultimate steering angle. Using the proposed technique, various simulations are carried out in the WEBOT simulator, which shows a deviation under 5% when the results are validated in real-time experiments, revealing the technique to be robust. To resolve the complication of providing preference to the robot during deadlock condition in multi-humanoids system, the dining philosopher controller is implemented. The efficiency of the proposed technique is examined through the comparisons with the default controller of NAO based on toques produces at various joints that present an average improvement of 6.12%, 7.05% and 15.04% in ankle, knee and hip, respectively. It is further compared against the existed navigational strategy in multiple robot systems that also displays an acceptable improvement in travel length. In comparison in reference to the existing controller, the proposed technique emerges to be a clear winner by portraying its superiority.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2021.06.010,Journal,ISA Transactions,scopus,2022-06-01,sciencedirect,A real-world application of Markov chain Monte Carlo method for Bayesian trajectory control of a robotic manipulator,https://api.elsevier.com/content/abstract/scopus_id/85108508566,"Reinforcement learning methods are being applied to control problems in robotics domain. These algorithms are well suited for dealing with the continuous large scale state spaces in robotics field. Even though policy search methods related to stochastic gradient optimization algorithms have become a successful candidate for coping with challenging robotics and control problems in recent years, they may become unstable when abrupt variations occur in gradient computations. Moreover, they may end up with a locally optimal solution. To avoid these disadvantages, a Markov chain Monte Carlo (MCMC) algorithm for policy learning under the RL configuration is proposed. The policy space is explored in a non-contiguous manner such that higher reward regions have a higher probability of being visited. The proposed algorithm is applied in a risk-sensitive setting where the reward structure is multiplicative. Our method has the advantages of being model-free and gradient-free, as well as being suitable for real-world implementation. The merits of the proposed algorithm are shown with experimental evaluations on a 2-Degree of Freedom robot arm. The experiments demonstrate that it can perform a thorough policy space search while maintaining adequate control performance and can learn a complex trajectory control task within a small finite number of iteration steps.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.116528,Journal,Expert Systems with Applications,scopus,2022-05-15,sciencedirect,A novel autonomous staircase cleaning system with robust 3D-Deep Learning-based perception technique for Area-Coverage,https://api.elsevier.com/content/abstract/scopus_id/85123714419,"Cleaning the staircases is the next big leap for every commercial cleaning robot in order to accomplish a full-fledged cleaning of a constructed buildings. Such an effort could be witnessed in the academic literature where a robotic system can autonomously clean the staircase by ascending. However, none of the existing staircase traversing platforms demonstrated the ability to perform both ascending and descending motion while cleaning, which can significantly improvise the overall robot’s performance. In this paper, we propose a novel reconfigurable cleaning robotic platform called sTetro_plotter, which can perform both ascend and descend motion in the staircases. Pointedly, in this work, we presented a perception framework for the developed robot to traverse on the staircase and perform area coverage autonomously. The framework was constructed with a pointNet++ based feature extractor and classification and regression network to generate a bounding box on the targeted feature. Also, we discussed the process of a staircase descending through tracking the generated bounding box. We implemented a sweeping-based lidar device that can generate a 3D point cloud by sensing its environment. We evaluated the performance of the proposed robot and its perception system through conducting experiments in real-world scenarios. The experimental trials successfully demonstrate the ability of the sTetro_plotter robot to perform autonomous area coverage while traversing on the staircase using the developed perception framework.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2022.107896,Journal,Computers and Electrical Engineering,scopus,2022-05-01,sciencedirect,A grasping posture estimation method based on 3D detection network,https://api.elsevier.com/content/abstract/scopus_id/85126838960,"In robotic grasping tasks, different kinds of objects with different poses and positions are often distributed in the scene, which makes the design a feasible visual solution for robotic grasping very challenging. In this paper, we propose a robotic grasping method based on a 3D detection network, which reduces the influence of different camera positions in image recognition. First, a convolutional neural network is designed to recognize objects in RGB images and calculate the 3D bounding boxes and center points of objects. Second, to further improve the stability of the whole grasping system, we propose a strategy for calculating the best object grasping posture. Finally, robotic control is implemented to grasp objects in real scenes. Experimental results show that the 3D detection accuracy reached 88%, and the successful grasp rate reached 94% in real scenes. In summary, the grasping system designed in this paper can generate appropriate grasping postures effectively and achieve high successful grasp rates, meeting the higher requirements of grasping tasks.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2022.105359,Journal,Computers in Biology and Medicine,scopus,2022-05-01,sciencedirect,A generic neural network model to estimate populational neural activity for robust neural decoding,https://api.elsevier.com/content/abstract/scopus_id/85125477254,"Background
                  Robust and continuous neural decoding is crucial for reliable and intuitive neural-machine interactions. This study developed a novel generic neural network model that can continuously predict finger forces based on decoded populational motoneuron firing activities.
               
                  Method
                  We implemented convolutional neural networks (CNNs) to learn the mapping from high-density electromyogram (HD-EMG) signals of forearm muscles to populational motoneuron firing frequency. We first extracted the spatiotemporal features of EMG energy and frequency maps to improve learning efficiency, given that EMG signals are intrinsically stochastic. We then established a generic neural network model by training on the populational neuron firing activities of multiple participants. Using a regression model, we continuously predicted individual finger forces in real-time. We compared the force prediction performance with two state-of-the-art approaches: a neuron-decomposition method and a classic EMG-amplitude method.
               
                  Results
                  Our results showed that the generic CNN model outperformed the subject-specific neuron-decomposition method and the EMG-amplitude method, as demonstrated by a higher correlation coefficient between the measured and predicted forces, and a lower force prediction error. In addition, the CNN model revealed more stable force prediction performance over time.
               
                  Conclusions
                  Overall, our approach provides a generic and efficient continuous neural decoding approach for real-time and robust human-robot interactions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2022.104743,Journal,Engineering Applications of Artificial Intelligence,scopus,2022-04-01,sciencedirect,"A comprehensive survey of clustering algorithms: State-of-the-art machine learning applications, taxonomy, challenges, and future research prospects",https://api.elsevier.com/content/abstract/scopus_id/85125128146,"Clustering is an essential tool in data mining research and applications. It is the subject of active research in many fields of study, such as computer science, data science, statistics, pattern recognition, artificial intelligence, and machine learning. Several clustering techniques have been proposed and implemented, and most of them successfully find excellent quality or optimal clustering results in the domains mentioned earlier. However, there has been a gradual shift in the choice of clustering methods among domain experts and practitioners alike, which is precipitated by the fact that most traditional clustering algorithms still depend on the number of clusters provided a priori. These conventional clustering algorithms cannot effectively handle real-world data clustering analysis problems where the number of clusters in data objects cannot be easily identified. Also, they cannot effectively manage problems where the optimal number of clusters for a high-dimensional dataset cannot be easily determined. Therefore, there is a need for improved, flexible, and efficient clustering techniques. Recently, a variety of efficient clustering algorithms have been proposed in the literature, and these algorithms produced good results when evaluated on real-world clustering problems. This study presents an up-to-date systematic and comprehensive review of traditional and state-of-the-art clustering techniques for different domains. This survey considers clustering from a more practical perspective. It shows the outstanding role of clustering in various disciplines, such as education, marketing, medicine, biology, and bioinformatics. It also discusses the application of clustering to different fields attracting intensive efforts among the scientific community, such as big data, artificial intelligence, and robotics. This survey paper will be beneficial for both practitioners and researchers. It will serve as a good reference point for researchers and practitioners to design improved and efficient state-of-the-art clustering algorithms.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2022.103512,Journal,Biomedical Signal Processing and Control,scopus,2022-04-01,sciencedirect,A gesture recognition algorithm in a robot therapy for ASD children,https://api.elsevier.com/content/abstract/scopus_id/85123722154,"Children with Autism Spectrum Disorders (ASDs) exhibit significant impairments in gesture imitation. Newest interventions are based on Human-Robot Interaction (HRI) since children with ASD cope well with stylized, rule-based and predictable systems. These collaborative approaches encompass therapy games based on joint exercises, imitation and interaction between robots and children. This paper’s aim was to implement an algorithm to automatically recognize small and similar gestures within a humanoid-robot therapy called IOGIOCO for ASD children. IOGIOCO is a multi-level HRI therapy meant to teach 19 meaningful gestures in a semantic framework based on a feedback interaction. Gestures were tracked as 3D coordinates of body keypoints captured by a Kinect. A Residual Neural Network was implemented and trained on a segmented Dataset acquired within this study to generate the offline model which was then exploited in a real-time classification using a sliding window. Feedback as sound stimuli from NAO robot was provided based on the automatic evaluation of each performance. Clinical acquisitions were carried out on 4 ASD children within the IOGIOCO therapy. Offline recognition was successful: exploiting Artificial Neural Networks we reached 95% of test accuracy for 19 gestures. A real-time recognition on healthy subjects reached 94% accuracy. Clinical applications were evaluated through the F1 score that achieved 79% value. These outcomes were encouraging considering the wide gesture set and all the challenges the therapy raises. This kind of automatic algorithm was able to decrease the therapist workload and increase the robustness of the therapy and engagement of the child.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2022.103496,Journal,Biomedical Signal Processing and Control,scopus,2022-04-01,sciencedirect,An efficient multi-scale CNN model with intrinsic feature integration for motor imagery EEG subject classification in brain-machine interfaces,https://api.elsevier.com/content/abstract/scopus_id/85122946849,"Objective
                  Electroencephalogram (EEG) based motor imagery (MI) classification is an important aspect in brain-machine interfaces (BMIs) which bridges between neural system and computer devices decoding brain signals into recognizable machine commands. However, the MI classification task is challenging due to inherent complex properties, inter-subject variability, and low signal-to-noise ratio (SNR) of EEG signals. To overcome the above-mentioned issues, the current work proposes an efficient multi-scale convolutional neural network (MS-CNN) which can extract the distinguishable features of several non-overlapping canonical frequency bands of EEG signals from multiple scales for MI-BCI classification.
               
                  Approach
                  In the framework, discriminant user-specific features have been extracted and integrated to improve the accuracy and performance of the CNN classifier. Additionally, different data augmentation methods have been implemented to further improve the accuracy and robustness of the model.
               
                  Main results
                  The model achieves an average classification accuracy of 
                        
                           93.74
                           %
                        
                      and Cohen’s kappa-coefficient of 
                        
                           0.92
                        
                      on the BCI competition IV2b dataset outperforming several baseline and current state-of-the-art EEG-based MI classification models.
               
                  Significance
                  The proposed algorithm effectively addresses the shortcoming of existing CNN-based EEG-MI classification models and significantly improves the classification accuracy. The current framework can provide a stimulus for designing efficient and robust real-time human-robot interaction.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cor.2021.105674,Journal,Computers and Operations Research,scopus,2022-04-01,sciencedirect,Balancing and scheduling assembly lines with human-robot collaboration tasks,https://api.elsevier.com/content/abstract/scopus_id/85122478755,"In light of the Industry 5.0 trend towards human-centric and resilient industries, human-robot collaboration (HRC) assembly lines can be used to enhance productivity and workers’ well-being, provided that the optimal allocation of tasks and available resources can be determined. This study investigates the assembly line balancing problem (ALBP), considering HRC. This problem, abbreviated ALBP-HRC, arises in advanced manufacturing systems, where humans and collaborative robots share the same workplace and can simultaneously perform tasks in parallel or in collaboration. Driven by the need to solve the more complex assembly line-balancing problems found in the automotive industry, this study aims to address the ALBP-HRC with the cycle time and the number of operators (humans and robots) as the primary and secondary objective, respectively. In addition to the traditional ALBP constraints, the human and robot characteristics, in terms of task times, allowing multiple humans and robots at stations, and their joint/collaborative tasks are formulated into a new mixed-integer linear programming (MILP) model. A neighborhood-search simulated annealing (SA) is proposed with customized solution representation and neighborhood search operators designed to fit into the problem characteristics. Furthermore, the proposed SA features an adaptive neighborhood selection mechanism that enables the SA to utilize its exploration history to dynamically choose appropriate neighborhood operators as the search evolves. The proposed MILP and SA are implemented on real cases taken from the automotive industry where stations are designed for HRC. The computational results over different problems show that the adaptive SA produces promising solutions compared to the MILP and other swarm intelligence algorithms, namely genetic algorithm, particle swarm optimization, and artificial bee colony. The comparisons of human/robot versus HRC settings in the case study indicate significant improvement in the productivity of the assembly line when multiple humans and robots with collaborative tasks are permissible at stations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.116203,Journal,Expert Systems with Applications,scopus,2022-03-15,sciencedirect,Semantic segmentation based stereo visual servoing of nonholonomic mobile robot in intelligent manufacturing environment,https://api.elsevier.com/content/abstract/scopus_id/85119331942,"In the interest of developing an intelligent manufacturing environment with an agile, efficient, and optimally utilized transportation system, mobile robots need to achieve a certain level of autonomy as they play an important role in carrying out transportation tasks. Bearing this in mind, in the paper we propose a novel stereo visual servoing method for nonholonomic mobile robot control based on semantic segmentation. Semantic segmentation provides a rich body of information required for an adequate decision-making process in a clustered, dynamic, and ever-changing manufacturing environment. The innovative idea behind the new visual servoing system is to utilize semantic information of the scene for visual servoing, as well as for other mobile robot tasks, such as obstacle avoidance, scene understanding, and simultaneous localization and mapping. Semantic segmentation is carried out by exploiting fully convolutional neural networks. The new visual servoing algorithm utilizes an intensity-based image registration procedure, which results in the image transformation matrix. The transformation matrix encompasses the relations of images taken at the current and desired pose, and that information is directly used for visual servoing. The developed algorithm is deployed on our own developed wheeled differential drive mobile robot RAICO (Robot with Artificial Intelligence based COgnition). The experimental evaluation is carried out in the 3D simulation environment and in the laboratory model of the real manufacturing environment. The experimental results show that the accuracy of the proposed approach is improved when compared to the state-of-the-art approaches while being robust to the partial occlusions of the scene and illumination changes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2021.11.003,Journal,Cognitive Systems Research,scopus,2022-03-01,sciencedirect,Neural Policy Style Transfer,https://api.elsevier.com/content/abstract/scopus_id/85120895759,"Style Transfer has been proposed in a number of fields: fine arts, natural language processing, and fixed trajectories. We scale this concept up to control policies within a Deep Reinforcement Learning infrastructure. Each network is trained to maximize the expected reward, which typically encodes the goal of an action, and can be described as the content. The expressive power of deep neural networks enables encoding a secondary task, which can be described as the style. The Neural Policy Style Transfer (NPST)
                        1
                     
                     
                        1
                        NPST: Neural Policy Style Transfer.
                      algorithm is proposed to transfer the style of one policy to another, while maintaining the content of the latter. Different policies are defined via Deep Q-Network architectures. These models are trained using demonstrations through Inverse Reinforcement Learning. Two different sets of user demonstrations are performed, one for content and other for style. Different styles are encoded as defined by user demonstrations. The generated policy is the result of feeding a content policy and a style policy to the NPST algorithm. Experiments are performed in a catch-ball game inspired by the Deep Reinforcement Learning classical Atari games; and a real-world painting scenario with a full-sized humanoid robot, based on previous works of the authors. The implementation of three different Q-Network architectures (Shallow, Deep and Deep Recurrent Q-Network) to encode the policies within the NPST framework is proposed and the results obtained in the experiments with each of these architectures compared.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.resconrec.2021.106022,Journal,"Resources, Conservation and Recycling",scopus,2022-03-01,sciencedirect,Using computer vision to recognize composition of construction waste mixtures: A semantic segmentation approach,https://api.elsevier.com/content/abstract/scopus_id/85118570774,"Timely and accurate recognition of construction waste (CW) composition can provide yardstick information for its subsequent management (e.g., segregation, determining proper disposal destination). Increasingly, smart technologies such as computer vision (CV), robotics, and artificial intelligence (AI) are deployed to automate waste composition recognition. Existing studies focus on individual waste objects in well-controlled environments, but do not consider the complexity of the real-life scenarios. This research takes the challenges of the mixture and clutter nature of CW as a departure point and attempts to automate CW composition recognition by using CV technologies. Firstly, meticulous data collection, cleansing, and annotation efforts are made to create a high-quality CW dataset comprising 5,366 images. Then, a state-of-the-art CV semantic segmentation technique, DeepLabv3+, is introduced to develop a CW segmentation model. Finally, several training hyperparameters are tested via orthogonal experiments to calibrate the model performance. The proposed approach achieved a mean Intersection over Union (mIoU) of 0.56 in segmenting nine types of materials/objects with a time performance of 0.51 s per image. The approach was found to be robust to variation of illumination and vehicle types. The study contributes to the important problem of material composition recognition, formalizing a deep learning-based semantic segmentation approach for CW composition recognition in complex environments. It paves the way for better CW management, particularly in engaging robotics, in the future. The trained models are hosted on GitHub, based on which researchers can further finetune for their specific applications.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artint.2021.103637,Journal,Artificial Intelligence,scopus,2022-02-01,sciencedirect,Online perceptual learning and natural language acquisition for autonomous robots,https://api.elsevier.com/content/abstract/scopus_id/85120333069,"In this work, the problem of bootstrapping knowledge in language and vision for autonomous robots is addressed through novel techniques in grammar induction and word grounding to the perceptual world. In particular, we demonstrate a system, called OLAV, which is able, for the first time, to (1) learn to form discrete concepts from sensory data; (2) ground language (n-grams) to these concepts; (3) induce a grammar for the language being used to describe the perceptual world; and moreover to do all this incrementally, without storing all previous data. The learning is achieved in a loosely-supervised manner from raw linguistic and visual data. Moreover, the learnt model is transparent, rather than a black-box model and is thus open to human inspection. The visual data is collected using three different robotic platforms deployed in real-world and simulated environments and equipped with different sensing modalities, while the linguistic data is collected using online crowdsourcing tools and volunteers. The analysis performed on these robots demonstrates the effectiveness of the framework in learning visual concepts, language groundings and grammatical structure in these three online settings.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.trpro.2022.06.276,Conference Proceeding,Transportation Research Procedia,scopus,2022-01-01,sciencedirect,Artificial Intelligence as a factor of public transportations system development,https://api.elsevier.com/content/abstract/scopus_id/85134239791,"Medical, financial, and assistive software for people with disabilities (speech, character recognition) are just a few of the many commercial applications for artificial intelligence. The functioning of the whole transportation system, including the vehicle, the infrastructure, and the driver/user, may benefit from AI techniques, especially in terms of the dynamic interactions that result in a transportation service.
                  Transport infrastructure is now failing to function properly; we are often faced with issues such as insufficient capacity, low levels of safety and dependability, contamination of the environment and inefficiency of operation. The employment of diverse AI approaches may, however, help establish new, intelligent modes of operation for infrastructures already in place. Many aspects of transportation currently use AI, such as junction management on arterial roadways, trip time estimates, and vehicle fuel injection systems, when learning techniques are applicable. Improved decision-making based on real-time data and improved network utilization are the future ambitions for intelligent urban transportation. The construction of a transportation system that is more dependable, efficient, and environmentally friendly, all while retaining a high degree of connectivity, is also vital.
                  As mobile communications and microprocessors have advanced, it is now feasible to make substantial progress toward developing ITS. Additionally, AI and robotics have made significant contributions to other disciplines, such as planning, problem-solving, rule-based reasoning, and image and speech recognition. Using intelligent vehicles and weapons, it is feasible to carry out complex military tasks with precision and reliability. Adaptation and learning, as well as the disparities between neural and electrical computing processes, are examined in this investigation. Game theory and operations research have been used to develop methods for making choices in the face of uncertainty",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2022.05.040,Conference Proceeding,Procedia CIRP,scopus,2022-01-01,sciencedirect,Process Segmented based Intelligent Anomaly Detection in Highly Flexible Production Machines under Low Machine Data Availability,https://api.elsevier.com/content/abstract/scopus_id/85132288498,"Anomaly detection is a key feature to monitor production systems an avoid downtimes, which has still not been implemented holistically. Especially in highly flexible plants or special process machines, conventional approaches like neuronal network classification or intelligent autoencoder fault detection are not suitable firstly due to the small amount and secondly due to the lack of labeling of data for each process. In this paper a novel concept is presented to segment different processes intelligently in the first step to find fine granular process patterns across process boundaries. Based on these patterns, anomaly detection and further classification are performed. A special feature is the integration of user knowledge, so that classification is possible even with a small amount of data. This approach is validated on an assembly line for electric motor production as well as in a handling robot. This paper shows results from real test series and thus demonstrates the practical suitability of the novel approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-32-385787-1.00006-3,Book,Deep Learning for Robot Perception and Cognition,scopus,2022-01-01,sciencedirect,Introduction,https://api.elsevier.com/content/abstract/scopus_id/85130667754,"Almost everything that we hear about Artificial Intelligence (AI) today is thanks to Machine Learning (ML) and especially the ML algorithms that use neural networks as baseline inference models. This scientific field is called Deep Learning (DL). The core of deep learning is to design, train and deploy end-to-end trainable models that are able to use raw sensor information, build an internal representation of the environment, and perform inference based on this representation. Although this end-to-end training approach has been successfully followed for many different tasks ranging from speech recognition to computer vision and machine translation in the last decade, the big challenge for the next years is to successfully apply the same end-to-end training and deployment approach for robotics, which means to build models that are able to sense and act using a unified deep learning architecture. This chapter provides an introduction to real world problems representation under a deep learning perspective, basic machine learning tasks, shallow and deep learning methodologies, and challenges in adopting deep learning in robotics. Moreover, it provides an introduction to the topics of deep learning for robot perception and cognition covered in the book.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-32-385787-1.00023-3,Book,Deep Learning for Robot Perception and Cognition,scopus,2022-01-01,sciencedirect,Simulation environments,https://api.elsevier.com/content/abstract/scopus_id/85130662736,"Simulation environments have always been a vital part of robotics research, providing tools for modeling and testing novel concepts and algorithms. In the early years, robotic simulators were restricted to 2D environments, without being fully able to simulate the complexity of the real world. Both the progress of computer hardware technologies and the advances in the computer graphics domain, enabled the development of visually realistic and physically accurate simulators. The gradual improvement on the performance of robot perception, cognition, and decision-making algorithms had a great impact on the way that robotic systems understand and interact with their environments, enabling them to even operate autonomously. The demand to simulate such complex robotic systems and the need to collect diverse, large-scale, and realistic data to train and test deep learning algorithms before being deployed on real-world scenarios, pushed modern simulation environments to even higher standards. The aim of this chapter is to present a systematic review of robotic simulation environments, while also presenting their evolution over the years.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-823978-0.00003-4,Book,Applications of Computational Intelligence in Multi-Disciplinary Research,scopus,2022-01-01,sciencedirect,IoT in healthcare ecosystem,https://api.elsevier.com/content/abstract/scopus_id/85130106885,"In recent years, IoT has been revolutionizing the technology landscape, leading to explosive growth in fields like automated manufacturing, asset management, and wearable consumer healthcare products. IoT’s presence can be seen in all domains. Ever since IoT gained its entry into the medical field, there has been a magnificent transformation in the healthcare domain. Personal healthcare is now made a reality with IoT offering solutions in several dimensions like remote healthcare; smart clothing such as smartwatches, smart bands, and smart pants; and telemedicine like smart pills and personal care robots. This chapter gives a comprehensive walkthrough of IoT in the healthcare ecosystem, addressing the different applications of IoT in healthcare, the architecture models, challenges faced by IoT in healthcare, security practices and issues, and the future of IoT in the domain. In the first section, IoT applications in healthcare are discussed, which include patient-centric applications like remote health monitoring and critical care monitoring; and hospital-centric IoT applications such as the deployment of the staff, reducing charting times, and real-time location of medical equipment, subsequently followed by a discussion on how the data collected from the patient-centric and hospital-centric applications contribute to the ease of other domains like health insurance; and then, IoT’s support toward the pharmaceutical industry to restrict counterfeit medicine is discussed. Secondly, the implementation designs of healthcare IoT are discussed. Apart from the traditional cloud services, new offerings like fog and edge computing have seen a spike in recent years. Fog and edge computing are considered intelligent and flexible architectures. The subsequent section deals with architecture designs and the advantages and challenges of the two computing models. The next section demonstrates the actual implementation methodologies of the two applications in the following domains in detail: (1) Heart disease prediction and (2) healthcare IoT-based affective state mining using deep convolutional neural networks. The following section discusses the challenges faced by IoT in the healthcare domain. In general, the challenges can be categorized into technological challenges; people-oriented challenges like the acceptance of IoT in the healthcare domain; and finally, security bottlenecks. The data generated and maintained by the IoT platforms serves as a gold mine for different healthcare professionals for future research and development in the medical field and the health insurance providers and pharmaceutical industries for their benefits. Hence, more emphasis is given to the security and privacy aspects of how the domain handles sensitive data of the patients. The next section provides insights into the security issues along with the cyber threats and attacks faced by healthcare IoT and the defensive mechanisms. Furthermore, this chapter deals with the IoT’s role in combatting the novel coronavirus that has caused an unprecedented global pandemic. Finally, the future of IoT is talked about. With the advent of 5G and an upsurge in artificial intelligence, the different dimensions of the IoT that are expected to see an outburst of growth are discussed.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2022.05.017,Conference Proceeding,Procedia CIRP,scopus,2022-01-01,sciencedirect,Insights and Example Use Cases on Industrial Transfer Learning,https://api.elsevier.com/content/abstract/scopus_id/85128695950,"Despite the high solution potential of machine learning for common problems in automation technology, there are only few examples of its application in real-world manufacturing practice. In order to find the reason for this phenomenon, the authors identify the hurdles for conventional machine learning using four exemplary use cases namely self-learning robots, wear prediction, visual object detection, and predictive quality in manufacturing. While these use-cases differ in principle, the problems engineers face when using conventional machine learning approaches to solve them are related, such as the lack of manifold training data or high dynamics of industrial processes. The authors showcase that utilizing deep transfer learning and continual learning approaches in the industrial context – subsumed under the term industrial transfer learning – can overcome these hurdles. Even for industrial transfer learning, there is a deficiency regarding preconditions for the large-scale deployment of such approaches, but unlike in conventional machine learning, it is principally possible to establish those. The article concludes with a discussion of these prerequisites and makes suggestions as to how they could be fulfilled.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-821750-4.00002-5,Book,"Endorobotics: Design, R and D and Future Trends",scopus,2022-01-01,sciencedirect,Artificial intelligence for medical robotics,https://api.elsevier.com/content/abstract/scopus_id/85128569934,"The shift in surgery toward minimally invasive approaches requires transitioning from an analog world to a digitally transformed system and presents a huge opportunity in this emerging field. Artificial intelligence (AI) in healthcare has the potential to transform the role of doctors and revolutionize the practice of medicine. The convergence between AI and medical robotic technologies creates an interesting area for research and development activities for the medical technology industry.
               Despite rapid improvements in robotic-assisted surgery over the past decade, the level of adoption remains low due to high costs, which is cited as a major challenge. This chapter outlines the current trends and perspectives of AI in medical robotics, with a rapid review of AI-supported robotics in allied health, radiology, rehabilitation medicine, with a specific focus on surgical applications.
               The chapter looks at how AI is being used in medical robotics for teaching and training, through to surgical planning and robotic-assisted surgery, using case studies.
               Some challenges with the use of AI in medicine include the issue of legal liability and attribution of negligence when errors occur. The chapter provides insights on ethical and legal issues of AI in medical robotics, with a discussion around implementation and adoption of this new technology.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2022.01.388,Conference Proceeding,Procedia Computer Science,scopus,2022-01-01,sciencedirect,Real-time Detection of Worker's Emotions for Advanced Human-Robot Interaction during Collaborative Tasks in Smart Factories,https://api.elsevier.com/content/abstract/scopus_id/85127826978,"Human-robot collaboration (HRC) has become increasingly popular in modern assembly systems because of the flexibility of human capabilities and the precision and efficiency of the fellow robot. However, previous research has identified challenges to achieve a genuine and natural human-robot interaction, one being the real-time robot behavior adaptation depending on the worker’s emotions revealed by facial or body signals. Human emotional state recognition has been widely explored in the fields of human–machine interaction and affective computing, but a practical implementation of the technology in real-time during a collaborative task hides complexities and challenges. In this paper, the authors tested and compared twelve different models, all based on Deep Learning and Convolutional Neural Networks (CNN), to recognize emotions using the datasets CK+ and Fer2013. DeepFace algorithm resulted to be the most accurate and was further tested on real subjects in working and industry-like contexts to determine the actual validity and necessary modifications for a possible large-scale industrial application. A discussion about all the main challenges to face for a practical application of this technology on field is presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2022.02.172,Conference Proceeding,Procedia CIRP,scopus,2022-01-01,sciencedirect,Open-Digital-Industrial and Networking pilot lines using modular components for scalable production - ODIN project approach,https://api.elsevier.com/content/abstract/scopus_id/85127520324,"While robots have very well proven their flexibility and efficiency in mass production and are recognized as the production resource of the future, their adoption in lower volume, diverse environment is heavily constrained. The main reason for this is the high integration and deployment complexity that overshadows the performance benefits of this technology. This paper presents the vision of ODIN European funded project which is to strengthen the EU production companies’ trust in utilizing advanced robotics, by demonstrating that novel robot-based production systems are not only technically feasible, but also efficient and sustainable for immediate introduction at the shopfloor. To achieve that, ODIN brings together, by means of hardware and software, the latest technological advancements in the fields of a) collaborating robots and human robot collaborative workplaces, b) autonomous robotics and AI based task planning, c) mobile robots and reconfigurable tooling, d) Digital Twins and Virtual Commissioning and e) Service Oriented Robotics Integration and Communication Architectures. ODIN will provide a systematic approach for integrating these technologies under modular and reconfigurable large-scale robotic pilots. The performance of these robotic pilots will be tested and validated in three case studies, from the automotive, the white goods and the aeronautics industry.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2022.02.162,Conference Proceeding,Procedia CIRP,scopus,2022-01-01,sciencedirect,Operator training framework for hybrid environments: An Augmented Reality module using machine learning object recognition,https://api.elsevier.com/content/abstract/scopus_id/85127505635,"As market demands are characterized by more customized products with shorter lifecycles, it is obligatory for modern operators to manage recurrent product or manufacturing system changes. In contrary to previous years, adaptation to such changes prerequires memorization of more information, and familiarization with more complex systems and resources in a shorter period of time. This manuscript presents a novel operator training framework based on Augmented Reality (AR) technology. More specifically, intuitive instructions enhanced with machine learning-based physical object detection are used for making steeper learning curves and providing hands-on experience to operators. The implemented application also supports a walkthrough mode where users can get familiarized with Information and Communication Technologies (ICT) data streams besides fenceless Human-Robot coexistence in collaborative schemes. An automotive case study is used for evaluating the performance of the training framework through a Human-Robot Collaboration (HRC) assembly scenario.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2022.02.171,Conference Proceeding,Procedia CIRP,scopus,2022-01-01,sciencedirect,AI-based vision system for collision detection in HRC applications,https://api.elsevier.com/content/abstract/scopus_id/85127499215,"Human-Robot Collaboration (HRC) enabling mechanisms require real-time detection of potential collisions among human and robots. Taking under consideration the already existing standards and the literature, most of collision detection techniques require the integration of sensorial systems on the robot aiming to identify the contact events. This paper deals with a novel approach for the identification of human and robot collision based on vision systems. Moreover, Artificial Intelligent (AI) algorithms are required to classify the captured data near real-time and to provide a score about the collision status (contact or non-contact) between a human and the robot. Accordingly, the AI models should be trained using the appropriate image data enabling an accurate classification. The proposed system has been developed in a lab environment. A detailed presentation of the system implementation, its performance and the potential integration in a real industrial environment are discussed in this paper.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.softx.2021.100956,Journal,SoftwareX,scopus,2022-01-01,sciencedirect,tx2_fcnn_node: An open-source ROS compatible tool for monocular depth reconstruction,https://api.elsevier.com/content/abstract/scopus_id/85121968187,"We present tx2_fcnn_node – a Robot Operating System (ROS) compatible tool that is aimed at seamless integration of various monocular depth reconstruction neural networks to the robotic software based on ROS (which is a de-facto standard in the area of robotics). Our tool simplifies the process of deploying, evaluating, and comparing depth reconstruction neural networks both on real robots and in simulation. We complement our software with a set of the precompiled neural networks which can be used off the shelf, with some of them being able to demonstrate near real-time performance when running onboard compact embedded platforms, e.g. Nvidia Jetson TX2, that are often used nowadays both in academia and industry.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.automatica.2021.110007,Journal,Automatica,scopus,2022-01-01,sciencedirect,An analytic layer-wise deep learning framework with applications to robotics,https://api.elsevier.com/content/abstract/scopus_id/85118989490,"Deep learning (DL) has achieved great success in many applications, but it has been less well analyzed from the theoretical perspective. The unexplainable success of black-box DL models has raised questions among scientists and promoted the emergence of the field of explainable artificial intelligence (XAI). In robotics, it is particularly important to deploy DL algorithms in a predictable and stable manner as robots are active agents that need to interact safely with the physical world. This paper presents an analytic deep learning framework for fully connected neural networks, which can be applied for both regression problems and classification problems. Examples for regression and classification problems include online robot control and robot vision. We present two layer-wise learning algorithms such that the convergence of the learning systems can be analyzed. Firstly, an inverse layer-wise learning algorithm for multilayer networks with convergence analysis for each layer is presented to understand the problems of layer-wise deep learning. Secondly, a forward progressive learning algorithm where the deep networks are built progressively by using single hidden layer networks is developed to achieve better accuracy. It is shown that the progressive learning method can be used for fine-tuning of weights from convergence point of view. The effectiveness of the proposed framework is illustrated based on classical benchmark recognition tasks using the MNIST and CIFAR-10 datasets and the results show a good balance between performance and explainability. The proposed method is subsequently applied for online learning of robot kinematics and experimental results on kinematic control of UR5e robot with unknown model are presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2021.104514,Journal,Engineering Applications of Artificial Intelligence,scopus,2022-01-01,sciencedirect,Instance-based defense against adversarial attacks in Deep Reinforcement Learning,https://api.elsevier.com/content/abstract/scopus_id/85118104144,"Deep Reinforcement Learning systems are now a hot topic in Machine Learning for their effectiveness in many complex tasks, but their application in safety-critical domains (e.g., robot control or self-autonomous driving) remains dangerous without mechanism to detect and prevent risk situations. In Deep RL, such risk is mostly in the form of adversarial attacks, which introduce small perturbations to sensor inputs with the aim of changing the network-based decisions and thus cause catastrophic situations. In the light of these dangers, a promising line of research is that of providing these Deep RL algorithms with suitable defenses, especially when deploying in real environments. This paper suggests that this line of research could be greatly improved by the concepts from the existing research field of Safe Reinforcement Learning, which has been postulated as a family of RL algorithms capable of providing defenses against many forms of risks. However, the connections between Safe RL and the design of defenses against adversarial attacks in Deep RL remain largely unexplored. This paper seeks to explore precisely some of these connections. In particular, this paper proposes to reuse some of the concepts from existing Safe RL algorithms to create a novel and effective instance-based defense for the deployment stage of Deep RL policies. The proposed algorithm uses a risk function based on how far a state is from the state space known by the agent, that allows identifying and preventing adversarial situations. The success of the proposed defense has been evaluated in 4 Atari games.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heares.2021.108371,Journal,Hearing Research,scopus,2021-12-01,sciencedirect,Electrical impedance guides electrode array in cochlear implantation using machine learning and robotic feeder,https://api.elsevier.com/content/abstract/scopus_id/85117569953,"Cochlear Implant provides an electronic substitute for hearing to severely or profoundly deaf patients. However, postoperative hearing outcomes significantly depend on the proper placement of electrode array (EA) into scala tympani (ST) during cochlear implant surgery. Due to limited intra-operative methods to access array placement, the objective of the current study was to evaluate the relationship between EA complex impedance and different insertion trajectories in a plastic ST model. A prototype system was designed to measure bipolar complex impedance (magnitude and phase) and its resistive and reactive components of electrodes. A 3-DoF actuation system was used as an insertion feeder. 137 insertions were performed from 3 different directions at a speed of 0.08 mm/s. Complex impedance data of 8 electrode pairs were sequentially recorded in each experiment. Machine learning algorithms were employed to classify both the full and partial insertion lengths. Support Vector Machine (SVM) gave the highest 97.1% accuracy for full insertion. When a real-time prediction was tested, Shallow Neural Network (SNN) model performed better than other algorithms using partial insertion data. The highest accuracy was found at 86.1% when 4 time samples and 2 apical electrode pairs were used. Direction prediction using partial data has the potential of online control of the insertion feeder for better EA placement. Accessing the position of the electrode array during the insertion has the potential to optimize its intraoperative placement that will result in improved hearing outcomes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2021.103891,Journal,Robotics and Autonomous Systems,scopus,2021-12-01,sciencedirect,Hybrid autonomous controller for bipedal robot balance with deep reinforcement learning and pattern generators[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85116222985,"Recovering after an abrupt push is essential for bipedal robots in real-world applications within environments where humans must collaborate closely with robots. There are several balancing algorithms for bipedal robots in the literature, however most of them either rely on hard coding or power-hungry algorithms. We propose a hybrid autonomous controller that hierarchically combines two separate, efficient systems, to address this problem. The lower-level system is a reliable, high-speed, full state controller that was hardcoded on a microcontroller to be power efficient. The higher-level system is a low-speed reinforcement learning controller implemented on a low-power onboard computer. While one controller offers speed, the other provides trainability and adaptability. An efficient control is then formed without sacrificing adaptability to new dynamic environments. Additionally, as the higher-level system is trained via deep reinforcement learning, the robot could learn after deployment, which is ideal for real-world applications. The system’s performance is validated with a real robot recovering after a random push in less than 5 s, with minimal steps from its initial positions. The training was conducted using simulated data.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejrs.2021.08.007,Journal,Egyptian Journal of Remote Sensing and Space Science,scopus,2021-12-01,sciencedirect,Smart farming for improving agricultural management,https://api.elsevier.com/content/abstract/scopus_id/85114414365,"The food shortage and the population growth are the most challenges facing sustainable development worldwide. Advanced technologies such as artificial intelligence (AI), the Internet of Things (IoT), and the mobile internet can provide realistic solutions to the challenges that are facing the world. Therefore, this work focuses on the new approaches regarding smart farming (SF) from 2019 to 2021, where the work illustrates the data gathering, transmission, storage, analysis, and also, suitable solutions. IoT is one of the essential pillars in smart systems, as it connects sensor devices to perform various basic tasks. The smart irrigation system included those sensors for monitoring water level, irrigation efficiency, climate, etc. Smart irrigation is based on smart controllers and sensors as well as some mathematical relations. In addition, this work illustrated the application of unmanned aerial vehicles (UAV) and robots, where they can be achieved several functions such as harvesting, seedling, weed detection, irrigation, spraying of agricultural pests, livestock applications, etc. real-time using IoT, artificial intelligence (AI), deep learning (DL), machine learning (ML) and wireless communications. Moreover, this work demonstrates the importance of using a 5G mobile network in developing smart systems, as it leads to high-speed data transfer, up to 20 Gbps, and can link a large number of devices per square kilometer. Although the applications of smart farming in developing countries are facing several challenges, this work highlighted some approaches the smart farming. In addition, the implementation of Smart Decision Support Systems (SDSS) in developing countries supports the real-time analysis, mapping of soil characteristics and also helps to make proper decision management. Finally, smart agriculture in developing countries needs more support from governments at the small farms and the private sector.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.115498,Journal,Expert Systems with Applications,scopus,2021-12-01,sciencedirect,Real-time human pose estimation on a smart walker using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85109217957,"Rehabilitation is important to improve quality of life for mobility-impaired patients. Smart walkers are a commonly used solution that should embed automatic and objective tools for data-driven human-in-the-loop control and monitoring. However, present solutions focus on extracting few specific metrics from dedicated sensors with no unified full-body approach. We investigate a general, real-time, full-body pose estimation framework based on two RGB+D camera streams with non-overlapping views mounted on a smart walker equipment used in rehabilitation. Human keypoint estimation is performed using a two-stage neural network framework. The 2D-Stage implements a detection module that locates body keypoints in the 2D image frames. The 3D-Stage implements a regression module that lifts and relates the detected keypoints in both cameras to the 3D space relative to the walker. Model predictions are low-pass filtered to improve temporal consistency. A custom acquisition method was used to obtain a dataset, with 14 healthy subjects, used for training and evaluating the proposed framework offline, which was then deployed on the real walker equipment. An overall keypoint detection error of 3.73 pixels for the 2D-Stage and 44.05 mm for the 3D-Stage were reported, with an inference time of 26.6 ms when deployed on the constrained hardware of the walker. We present a novel approach to patient monitoring and data-driven human-in-the-loop control in the context of smart walkers. It is able to extract a complete and compact body representation in real-time and from inexpensive sensors, serving as a common base for downstream metrics extraction solutions, and Human-Robot interaction applications. Despite promising results, more data should be collected on users with impairments, to assess its performance as a rehabilitation tool in real-world scenarios.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2021.08.115,Journal,Neurocomputing,scopus,2021-11-20,sciencedirect,HuRAI: A brain-inspired computational model for human-robot auditory interface,https://api.elsevier.com/content/abstract/scopus_id/85114916023,"The deep learning era endows immense opportunities for ubiquitous robotic applications by leveraging big data generated from widespread sensors and ever-growing computing capability. While the growing demands for natural human-robot interaction (HRI) as well as concerns for energy efficiency, real-time performance, and data security motive novel solutions. In this paper, we present a brain-inspired spiking neural network (SNN) based Human-Robot Auditory Interface, namely HuRAI. The HuRAI integrates the voice activity detection, speaker localization and voice command recognition systems into a unified framework that can be implemented on the emerging low-power neuromorphic computing (NC) devices. Our experimental results demonstrate superior modeling capabilities of SNNs, achieving accurate and rapid prediction for each task. Moreover, the energy efficiency analysis reveals a compelling prospect, with up to three orders of magnitude energy savings, over the equivalent artificial neural networks that running on the state-of-the-art Nvidia graphics processing unit (GPU). Therefore, integrating the algorithmic power of large-scale SNN models and the energy efficiency of NC devices offers an attractive solution for real-time, low-power robotic applications.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.11.182,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-11-01,sciencedirect,Electromyographic Classification to Control the SPAR Glove,https://api.elsevier.com/content/abstract/scopus_id/85124583160,"The SeptaPose Assistive and Rehabilitative (SPAR) Glove has been developed to assist individuals with upper extremity impairment arising from neuromuscular injury. The glove detects user intent via the MYO wearable electromyography (EMG) device. In this manuscript, pattern recognition tools infer the desired hand pose from EMG activity. The ability of the measurement and classification methods to distinguish between hand poses was evaluated with nine able-bodied participants and three participants with spinal cord injury (SCI) in an offline experiment. The strong performance of the proposed intent detection method is shown in the steady-state classification accuracy, presented as confusion matrices, as well as the average confidence for each classification. Building upon the strong performance in detecting pose, a pilot study with two participants with SCI presents the initial results of the real-time implementation of the system, which suggests directions for future work in improving the steady-state classification accuracy through expanded measurement and a refined taxonomy to enable intuitive control.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106460,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,Multi-Modality guidance based surgical navigation for percutaneous endoscopic transforaminal discectomy,https://api.elsevier.com/content/abstract/scopus_id/85118353932,"Objective
                  Fluoroscopic guidance is a critical step for the puncture procedure in percutaneous endoscopic transforaminal discectomy (PETD). However, two-dimensional observations of the three-dimensional anatomic structure suffer from the effects of projective simplification. To accurately assess the spatial relations between the patient vertebra tissues and puncture needle, a considerable number of fluoroscopic images from different orientations need to be acquired by the surgeons. This process significantly increases the radiation risk for both the patient and surgeons.
               
                  Methods
                  In this paper, we propose an augmented reality (AR) surgical navigation system for PETD based on multi-modality information, which contains fluoroscopy, optical tracking, and depth camera. To register the fluoroscopic image with the intraoperative video, we design a lightweight non-invasive fiducial with markers and detect the markers based on the deep learning method. It can display the intraoperative video fused with the registered fluoroscopic images. We also present a self-adaptive calibration and transformation method between a 6-DOF optical tracking device and a depth camera, which are in different coordinate systems.
               
                  Results
                  With the substantially reduced frequency of fluoroscopy imaging, the system can accurately track and superimpose the virtual puncture needle on fluoroscopy images in real-time. From operating theatre in vivo animal experiments, the results illustrate that the system average positioning accuracy can reach 1.98mm and the orientation accuracy can reach 1.19
                        
                           
                           ∘
                        
                     . From the clinical validation results, the system significantly lower the frequency of fluoroscopy imaging (42.7%) and reduce the radiation risk for both the patient and surgeons.
               
                  Conclusion
                  Coupled with the user study, both the quantitative and qualitative results indicate that our navigation system has the potential to be highly useful in clinical practice. Compared with the existing navigation systems, which are usually equipped with a variety of large and high-cost medical equipments, such as O-arm, cone-beam CT, and robots, our navigation system does not need special equipment and can be implemented with common equipment in the operating room, such as C-arm, desktop, etc., even in small hospitals.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2021.07.021,Journal,Neural Networks,scopus,2021-11-01,sciencedirect,Continual learning for recurrent neural networks: An empirical evaluation,https://api.elsevier.com/content/abstract/scopus_id/85111476234,"Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning (CL) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on CL for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for CL with sequential data based on existing datasets, whose characteristics resemble real-world applications.
                  We also provide a broad empirical evaluation of CL and Recurrent Neural Networks in class-incremental scenario, by testing their ability to mitigate forgetting with a number of different strategies which are not specific to sequential data processing. Our results highlight the key role played by the sequence length and the importance of a clear specification of the CL scenario.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2021.07.012,Journal,Acta Astronautica,scopus,2021-11-01,sciencedirect,"A review of space surgery - What have we achieved, current challenges, and future prospects",https://api.elsevier.com/content/abstract/scopus_id/85110745640,"Major surgical events/incidents onboard are rare but can be catastrophic to any mission. National Aeronautics and Space Administration (NASA) uses the Integrated Medical Model (IMM) to develop an integrated, quantified, evidence-based decision support tool useful for crew health and mission planners to assess risk and design medical systems. In 2017, the IMM of the NASA Human Research Program included a list of 100 medical conditions that could be anticipated during space flight. Of those conditions, 27 are expected to need surgical treatment. Consequently, there has been a continuing interest in surgical capabilities for exploration space flight. The surgical system capabilities aboard all space stations and analogue flights have been designed and implemented with an emphasis on stabilisation, medical evacuation, and ATLS capabilities. However, with future missions to the Moon and Mars, evacuation is not a possibility and astronauts will need to troubleshoot, adapt, and self-administer complex surgical care autonomously.
                  This narrative review aims to examine the published work on surgical care in space, discuss the inherent challenges, and identify scope for future studies. The review evaluates and analyses results from several landmark experiments covering important technical aspects such as basic surgical skills, laparoscopic surgery, robotic surgery, and tele surgery. Relevant studies for the review were identified from the MEDLINE, PubMed, and EMBASE databases. Eligible studies were published between 1960 and June 2021 and were identified using the terms “space surgery”, “microgravity”, “zero gravity”, “weightlessness”, “parabolic flight”, “neutral buoyancy”, and “spaceflight”. Only articles in English were selected and references cited in the selected publications were followed up and included where appropriate. Documents available in the public domain and/or archives of National Space agencies were also included. The search yielded a total of 86 hits including review articles, commentaries, studies, meeting summaries and technical reports submitted to National Space agencies. Results were then filtered for eligible papers relevant to this narrative review. Challenges on a long-duration mission will be unique, unlike anything we have faced so far in the last 60 years of space travel. Despite the progress in space surgery in the last 40 years, there are several challenges to achieving a fully functional surgical care system on any mission outside Low Earth Orbit. The microgravity environment presents unique challenges related to altered physiology as well as mechanics and techniques pertinent to surgical care. Some of the challenges include but are not limited to crew selection, role of prophylactic surgery, adaptation to zero gravity, lack of ground support, training and maintenance of surgical skills and limitation of weight and volume for hardware. Ultrasound imaging, 3D printing and AI-based surgical assistance coupled with robotic surgery have shown promise, but their real efficacy and functionality remains to be tested.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jhlste.2020.100275,Journal,"Journal of Hospitality, Leisure, Sport and Tourism Education",scopus,2021-11-01,sciencedirect,Industry 4.0 technologies in tourism education: Nurturing students to think with technology,https://api.elsevier.com/content/abstract/scopus_id/85092173436,"The Industry 4.0 revolution is bringing major transformations in the tourism systems design suitable for technologically oriented consumers. Indeed, methods and technologies introduced by Big Data, Automation, Virtual and augmented reality, Robotics and ICT well fit with the Tourism 4.0 paradigm. However, tourism students are not yet trained on techniques, issues and methods related to the Industry 4.0 framework.
                  Hence, relying on a careful examination of the literature on tourism market trends linked to the offer of innovative technological services, we identified conceptual, methodological, technological and practical skills to be developed in an academic curriculum for Tourism Science students. Learning path were focused on: i) processes of data acquisition from social media, ii) data analysis using Machine Learning techniques and iii) data design into significant elements useful to implement communication systems in the tourism field.
               
                  Results
                  showed that the most of participants achieved a medium-high evaluation for the implementation of the communication systems, applying appropriately techniques and tools learned along the course. Furthermore, the high percentage of students satisfaction registered in relation to the course, revealed that students enjoyed this experience. Outcomes reflects the acquisition and the awareness of those skills that will enable students to be conscious protagonists of their role in tourism 4.0.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2021.05.010,Journal,Neural Networks,scopus,2021-10-01,sciencedirect,Robot navigation as hierarchical active inference,https://api.elsevier.com/content/abstract/scopus_id/85109109629,"Localization and mapping has been a long standing area of research, both in neuroscience, to understand how mammals navigate their environment, as well as in robotics, to enable autonomous mobile robots. In this paper, we treat navigation as inferring actions that minimize (expected) variational free energy under a hierarchical generative model. We find that familiar concepts like perception, path integration, localization and mapping naturally emerge from this active inference formulation. Moreover, we show that this model is consistent with models of hippocampal functions, and can be implemented in silico on a real-world robot. Our experiments illustrate that a robot equipped with our hierarchical model is able to generate topologically consistent maps, and correct navigation behaviour is inferred when a goal location is provided to the system.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2021.102176,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-10-01,sciencedirect,Robotic grasping: from wrench space heuristics to deep learning policies,https://api.elsevier.com/content/abstract/scopus_id/85104603575,"The robotic grasping task persists as a modern industry problem that seeks autonomous, fast implementation, and efficient techniques. Domestic robots are also a reality demanding a delicate and accurate human–machine interaction, with precise robotic grasping and handling. From decades ago, with analytical heuristics, to recent days, with the new deep learning policies, grasping in complex scenarios is still the aim of several works’ that propose distinctive approaches. In this context, this paper aims to cover recent methodologies’ development and discuss them, showing state-of-the-art challenges and the gap to industrial applications deployment. Given the complexity of the related issue associated with the elaborated proposed methods, this paper formulates some fair and transparent definitions for results’ assessment to provide researchers with a clear and standardised idea of the comparison between the new proposals.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2021.106350,Journal,Computers and Electronics in Agriculture,scopus,2021-09-01,sciencedirect,Collision-free path planning for a guava-harvesting robot based on recurrent deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85111285188,"In unstructured orchard environments, picking a target fruit without colliding with neighboring branches is a significant challenge for guava-harvesting robots. This paper introduces a fast and robust collision-free path-planning method based on deep reinforcement learning. A recurrent neural network is first adopted to remember and exploit the past states observed by the robot, then a deep deterministic policy gradient algorithm (DDPG) predicts a collision-free path from the states. A simulation environment is developed and its parameters are randomized during the training phase to enable recurrent DDPG to generalize to real-world scenarios. We also introduce an image processing method that uses a deep neural network to detect obstacles and uses many three-dimensional line segments to approximate the obstacles. Simulations show that recurrent DDPG only needs 29 ms to plan a collision-free path with a success rate of 90.90%. Field tests show that recurrent DDPG can increase grasp, detachment, and harvest success rates by 19.43%, 9.11%, and 10.97%, respectively, compared to cases where no collision-free path-planning algorithm is implemented. Recurrent DDPG strikes a strong balance between efficiency and robustness and may be suitable for other fruits.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.urology.2021.06.008,Journal,Urology,scopus,2021-09-01,sciencedirect,Robot-assisted Magnetic Resonance Imaging-ultrasound Fusion Transperineal Targeted Biopsy,https://api.elsevier.com/content/abstract/scopus_id/85110653934,"Objective
                  To demonstrate the key steps to perform robot-assisted magnetic resonance imaging-ultrasound fusion transperineal prostate biopsy.
               
                  Materials and methods
                  Men with suspicion of prostate cancer underwent 3-Tesla multi-parametric MRI and were assigned a Prostate Imaging Reporting and Data System v2 score (PI-RADS). The prostate outline and suspicious lesions were marked by our radiologist using our software to produce a 3-dimensional prostate MRI model. All biopsies were performed under general anaesthesia and the real-time transrectal ultrasound model is created and subsequently fused with the MRI model using non-rigid software fusion. Transperineal targeted and systematic biopsy were then performed under stereotactic guidance using our robot-assisted prostate biopsy platform. Our clinically significant prostate cancer (Grade group ≥2) detection rates were previously described.
                        1
                     
                  
               
                  Results
                  Out of the 433 patients who underwent targeted and systematic biopsy, clinically-significant cancer detection rate was 46% (85% for PI- RADS 5 vs 38% for PI-RADS 4 vs 16% for PI-RADS 3; P < .001). Our overall complication rate was 13%, out of which the majority were Clavien-Dindo I (99%). The most common complications encountered were urinary retention (10%) and significant gross hematuria requiring bladder irrigation (2%). A higher prostate volume was associated with greater odds of urinary retention (OR 1.4, 95% CI: 1.21-1.65, P < .001 for every 10 mL increase in prostate volume). There was only 1 reported case of mild urinary tract infection.
               
                  Conclusion
                  Robot-assisted transperineal prostate biopsy has established itself as a reliable and accurate method of prostate cancer detection with minimal morbidity.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2021.103830,Journal,Robotics and Autonomous Systems,scopus,2021-09-01,sciencedirect,Visual recognition of gymnastic exercise sequences. Application to supervision and robot learning by demonstration,https://api.elsevier.com/content/abstract/scopus_id/85109177424,"This work presents a novel software architecture to autonomously identify and evaluate the gymnastic activity that people are carrying out. It is composed of three different interconnected layers. The first corresponds to a Multilayer Perceptron (MLP) trained from a set of angular magnitudes derived from the information provided by the OpenPose library. This library works frame by frame, so some postures may be incorrectly detected due to eventual occlusions. The MLP layer makes it possible to accurately identify the posture a person is performing. A second layer, based on a Hidden Markov Model (HMM) and the Viterbi algorithm, filters the incorrect spurious postures. Thus, the accuracy of the algorithm is improved, leading to a precise sequence of postures. A third layer identifies the current exercise and evaluates whether the person is doing it at a correct speed. This layer uses an innovative Modified Levenshtein Distance (MLD), which considers not only the number of operations to transform a given sequence, but also the nature of the elements participating in the comparison. The system works in real time with little delay, thus recognizing sequences of arbitrary length and providing continuous feedback on the exercises being performed. An experiment carried out consisted in reproducing the output of the second layer on an autonomous Pepper robot that can be used in environments where physical exercise is performed, such as a residence for the elderly or others. It has reproduced different exercises previously executed by an instructor so that people can copy the robot. The article analyzes the current situation of the automated gymnastic activities recognition, presents the architecture, the different experiments carried out and the results obtained. The integration of the three components (MLP, HMM and MLD) results in a robust system that has allowed us to improve the results of previous works.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107520,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Transformative computing for products sales forecast based on SCIM,https://api.elsevier.com/content/abstract/scopus_id/85107761559,"Online agricultural product trading has the characteristics of rapid and diversified transaction data; there is a fuzzy correspondence between sales volume influencing factors and sales volume levels. Based on this, this paper combines the data preprocessing technology of fuzzy membership and optimized deep learning algorithm, adding a self-encoding method with sparseness restriction, and proposes a deep learning sales forecasting model based on transformative computing with fuzzy membership-the super crown model (Super Imperial Crown Model, referred to as SICM). The model uses fuzzy membership to process the weighted relationship between sales influencing factors and sales rank, and uses a sparse autoencoder network to adaptively extract sample features; sales rank classification prediction uses Softmax classifier; BP fine-tuning is used to Achieve parameter optimization. Finally, use the collected transaction data to apply R software to simulate the optimized model and compare and analyze the comprehensive prediction performance. The results show that the super crown model can realize real-time and accurate dynamic sales classification prediction according to the characteristics of current online agricultural product transaction data, effectively overcome the imbalance of supply and demand caused by information imbalance, and promote the study of deep learning in the field of e-commerce transactions effect. Presented algorithm based on transformative computing techniques can be used in optimization of sales processes, management and analysis of sales markets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sysarc.2021.102183,Journal,Journal of Systems Architecture,scopus,2021-09-01,sciencedirect,Memory-efficient deep learning inference with incremental weight loading and data layout reorganization on edge systems,https://api.elsevier.com/content/abstract/scopus_id/85107073021,"Pattern recognition applications such as face recognition and agricultural product detection have drawn a rapid interest on Cyber–Physical–Social-Systems (CPSS). These CPSS applications rely on the deep neural networks (DNN) to conduct the image classification. However, traditional DNN inference models in the cloud could suffer from network delay fluctuations and privacy leakage problems. In this regard, current real-time CPSS applications are preferred to be deployed on edge-end embedded devices. Constrained by the computing power and memory limitations of edge devices, improving the memory management efficacy is the key to improving the quality of service for model inference. First, this study explored the incremental loading strategy of model weights for the model inference. Second, the memory space at runtime is optimized through data layout reorganization from the spatial dimension. In particular, the proposed schemes are orthogonal to existing models. Experimental results demonstrate that the proposed approach reduced the memory consumption by 61.05% without additional inference time overhead.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107465,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Click-event sound detection in automotive industry using machine/deep learning,https://api.elsevier.com/content/abstract/scopus_id/85105315919,"In the automotive industry, despite the robotic systems on the production lines, factories continue employing workers in several custom tasks getting for semi-automatic assembly operations. Specifically, the assembly of electrical harnesses of engines comprises a set of connections between electrical components. Despite the task is easy to perform, employees tend not to notice that a few components are not being connected properly due to physical fatigue provoked by repetitive tasks. This yields a low quality of the assembly production line and possible hazards. In this work, we propose a sound detection system based on machine/deep learning (ML/DL) approaches to identify click sounds produced when electrical harnesses are connected. The purpose of this system is to count the number of connections properly made and to feedback to the employees. We collect and release a public dataset of 25,000 click sounds of 25 ms length at 22 kHz during three months of assembly operations in an automotive production line located in Mexico. Then, we design an ML/DL-based methodology for click sound detection of assembled harnesses under real conditions of a noisy environment (noise level ranging from 
                        
                           −
                           16
                           .
                           67
                        
                      dB to 
                        
                           −
                           12
                           .
                           87
                        
                      dB) including other machinery sounds. Our best ML/DL model (i.e., a combination between five acoustic features and an optimized convolutional neural network) is able to detect click sounds in a real assembly production line with an accuracy of 
                        
                           94
                           .
                           55
                           ±
                           0
                           .
                           83
                        
                      %. To the best of our knowledge, this is the first time a click sounds detection system in assembling electrical harnesses of engines for giving feedback to the workers is proposed and implemented in a real-world automotive production line. We consider this work valuable for the automotive industry on how to apply ML/DL approaches for improving the quality of semi-automatic assembly operations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2021.101437,Journal,Pervasive and Mobile Computing,scopus,2021-08-01,sciencedirect,Porting deep neural networks on the edge via dynamic K-means compression: A case study of plant disease detection,https://api.elsevier.com/content/abstract/scopus_id/85108633572,"Cyber Physical Systems (CPS) totally revolutionized the way we interact with the world providing useful services that can support the human being in many aspects of his life. Artificial Intelligence (AI) is another important player for bringing intelligence to CPS and allows the realization of Intelligent Cyber Physical Systems where smart applications can run. However, the constrained hardware of these devices in terms of memory and computing power makes challenging the deployment and execution of powerful algorithms (e.g., deep neural networks). To address this problem, modern solutions involve the use of compression techniques to reduce the memory footprint of deep learning models while saving the accuracy performance. The proposed work focuses on plant disease detection which represents one of the biggest challenges in smart agriculture; in such a context, the possibility to perform a timely diagnosis on crops suspected to be infected can avoid the spread of diseases, thus saving a lot of time and money during the plantation works. In this paper, we realized an intelligent CPS on top of which we implemented an AI application, called Deep Leaf that exploits Convolutional Neural Networks to detect the main biotic stresses affecting crops. To meet the hardware requirements of the Edge device running our application, we propose a novel dynamic compression algorithm based on K-Means for the reduction of models footprint. Experimental results show that our detector is able to correctly classify the plant health condition with an accuracy of 95% and demonstrate the effectiveness of the proposed compression algorithm which is able to maintain the same accuracy of the original 32 bit float model, with an overall memory size reduction of about 85.2%.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2021.102576,Journal,Mechatronics,scopus,2021-08-01,sciencedirect,Active learning in robotics: A review of control principles,https://api.elsevier.com/content/abstract/scopus_id/85107977387,"Active learning is a decision-making process. In both abstract and physical settings, active learning demands both analysis and action. This is a review of active learning in robotics, focusing on methods amenable to the demands of embodied learning systems. Robots must be able to learn efficiently and flexibly through continuous online deployment. This poses a distinct set of control-oriented challenges—one must choose suitable measures as objectives, synthesize real-time control, and produce analyses that guarantee performance and safety with limited knowledge of the environment or robot itself. In this work, we survey the fundamental components of robotic active learning systems. We discuss classes of learning tasks that robots typically encounter, measures with which they gauge the information content of observations, and algorithms for generating action plans. Moreover, we provide a variety of examples – from environmental mapping to nonparametric shape estimation – that highlight the qualitative differences between learning tasks, information measures, and control techniques. We conclude with a discussion of control-oriented open challenges, including safety-constrained learning and distributed learning.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.renene.2021.04.040,Journal,Renewable Energy,scopus,2021-08-01,sciencedirect,Damage identification of wind turbine blades with deep convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85105896900,"Online early detection of surface damages on blades is critical for the safety of wind turbines, which could avoid catastrophic failures, minimize downtime, and enhance the reliability of the system. Monitoring the health status of blades is attracting more and more attention including on-site cameras and mobile cameras by drones and crawling robots. To deploy fast and efficient damage detection methods from image data, this work presents a hierarchical identification framework for wind turbine blades, which consists of a Haar-AdaBoost step for region proposal and a convolutional neural network (CNN) classifier for damage detection and fault diagnosis. Case studies are carried out on real data set collected from an eastern China wind farm. Results show that (i) the proposed framework can detect and identify the blade damages and outperforms other schemes include SVM and VGG16 models, (ii) sensitive analysis is conducted to validate the robustness of proposed method under limited data conditions, (iii) the proposed scheme is faster than one-step CNN method that directly classifying raw data.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bdr.2021.100241,Journal,Big Data Research,scopus,2021-07-15,sciencedirect,“Brains” for Robots: Application of the Mivar Expert Systems for Implementation of Autonomous Intelligent Robots,https://api.elsevier.com/content/abstract/scopus_id/85107957013,"Recently the contemporary robotic systems can manipulate different objects and make decisions in a range of situations due to significant advances in innovation technologies and artificial intelligence. The new expert technologies can handle millions of instructions on computers and smartphones, which allow them to be used as a tool to create “decision-making systems” for autonomous robots. The goal of this paper was to create a dynamic algorithm of robot actions that can be used in the decision module has been considered. It is proposed to use Mivar expert systems of a new generation for high-level control. The experiment results showed that Mivar decision-making systems can control groups of small robots and even an unmanned autonomous car in real time. The algorithms created in the Mivar environment can be very flexible, and their build-up depends only on engineering approaches. In addition to traditional low-level robot control systems, a Mivar decision-making system has been implemented, which can be considered as universal “Brains” for autonomous intelligent robots and now knowledge bases can be created and various robots can be trained for practical tasks.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2021.110967,Journal,Energy and Buildings,scopus,2021-07-15,sciencedirect,"A non-intrusive approach for fault detection and diagnosis of water distribution systems based on image sensors, audio sensors and an inspection robot",https://api.elsevier.com/content/abstract/scopus_id/85104453372,"Fault diagnosis is important to maintain the normal operation of air-conditioning systems, reduce the energy consumption in buildings, and increase the service life of air-conditioning system equipment. We present a novel approach for fault detection and diagnosis system that relies on image and audio sensors and relevant algorithms.
                  This paper proposes a fault diagnosis algorithm based on a robot that can automatically capture audio and image signals from microphone arrays and cameras during inspection in a chiller room. It includes audio- and image-based fault diagnosis algorithms. The validity of the algorithm combined with sensors is verified using data from actual equipment in a chiller room.
                  The audio-based algorithm, which can monitor the abnormal sound of pumps to detect faults, utilizes Fourier transform, a finite impulse response digital filter, and an autoregressive integrated moving average model. We analyze the frequency domain of the pump signal and set the appropriate threshold to monitor abnormal signals based on the fitted model. Meanwhile, the image-based algorithms are divided into three sections to achieve three functions: 1) an AlexNet convolutional neural network is modified to classify the images of the chiller room equipment obtained by the visible light camera; 2) image morphology methods and trigonometric functions are used to read the dials’ indicators acquired by the visible light camera; and 3) optical character recognition is used to obtain the highest temperature value in the infrared image of the pump captured by the infrared camera, which helps maintenance staff verify the operation of the pump and detect faults as soon as possible.
                  These diagnostic algorithms are non-intrusive, low cost, and easy to deploy. Combined with real-time data collection from the sensors on the robot, the algorithms can effectively improve the intelligence of the equipment room and allocate human resources more reasonably.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2021.108078,Journal,Computer Networks,scopus,2021-07-05,sciencedirect,Transfer reinforcement learning-based road object detection in next generation IoT domain,https://api.elsevier.com/content/abstract/scopus_id/85104603461,"The landscape of fifth generation (5G) and beyond 5G (B5G)-enabled Internet of Things(IoT) is expected to seamlessly and ubiquitously connect everything, which includes 5G, cloud computing, artificial intelligence and other cutting-edge technologies to realize truly intelligent applications in smart cities. In this paper, we present an important key technology for smart city, which is a road target recognition algorithm for smart city applications and designs a set of corresponding programs to assist automatic drivers, pedestrians and visually impaired people in road safety, or to manage city infrastructure. The system can connect robots in cars, wearable devices and body area network in pedestrians or blind people. A target recognition algorithm based on scene fusion is designed to recognize the specific target in the road environment, and transfer reinforcement learning method is used to improve the accuracy and real-time performance of target recognition. The system provides them with travel assistance, identify dangerous or useful objects for them through high-performance target recognition services. It can collect the road visual scene data by road cameras and transmit it to edge devices for training model. The model is collaborated trained in the edge devices and aggregated by the cloud. Based on the transfer reinforcement learning method, the vision-based road target recognition has been implemented, and the accurate and reliable target recognition can be realized. Many details of experiments verify the effectiveness of our technology.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2021.105826,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-07-01,sciencedirect,Automatic Acute Stroke Symptom Detection and Emergency Medical Systems Alerting by Mobile Health Technologies: A Review,https://api.elsevier.com/content/abstract/scopus_id/85107711467,"Objectives
                  To survey recent advances in acute stroke symptom automatic detection and Emergency Medical Systems (EMS) alerting by mobile health technologies.
               
                  Materials and methods
                  Narrative review
               
                  Results
                  Delayed activation of EMS for stroke symptoms by patients and witnesses deprives patients of rapid access to brain-saving therapies and occurs due to public unawareness of stroke features, cognitive and motor deficits produced by the stroke itself, and sleep onset. A promising emerging approach to overcoming the inherent biologic constraints of patient capacity to self-detect and respond to stroke symptoms is continuous monitoring by mobile health technologies with wireless sensors and artificial intelligence recognition systems. This review surveys 11 sensing technologies - accelerometers, gyroscopes, magnetometers, pressure sensors, touch screen and keyboard input detectors, artificial vision, and artificial hearing; and 10 consumer device form factors in which they are increasingly implemented: smartphones, smart speakers, smart watches and fitness bands, smart speakers/voice assistants, home health robots, smart clothing, smart beds, closed circuit television, smart rings, and desktop/laptop/tablet computers.
               
                  Conclusions
                  The increase in computing power, wearable sensors, and mobile connectivity have ushered in an array of mobile health technologies that can transform stroke detection and EMS activation. By continuously monitoring a diverse range of biometric parameters, commercially available devices provide the technologic capability to detect cardinal language, motor, gait, and sensory signs of stroke onset. Intensified translational research to convert the promise of these technologies to validated, accurate real-world deployments are an important next priority for stroke investigation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2021.102629,Journal,Biomedical Signal Processing and Control,scopus,2021-07-01,sciencedirect,Hand gestures recognition from surface electromyogram signal based on self-organizing mapping and radial basis function network,https://api.elsevier.com/content/abstract/scopus_id/85104067433,"Predicting the intention of human hand movements is a practical problem in prosthetic control. In recent years, surface electromyography (sEMG) has been widely used as a signal source in the field of wearable exoskeleton motion recognition and human-computer interaction. However, how to extract the information from sEMG signals and evaluate the intention of human hand movement effectively is still difficult. In order to achieve this goal, this work proposed a processing algorithm based on self-organizing mapping network (SOM) and radial basis neural network (RBF) for feature selection and classification recognition, then the principal component analysis (PCA) to reduce the size of feature vectors was used, finally used for pattern classification from sEMG signals to hand motion. In this research, the classification method mainly used the SOM method to find the hidden nodes centers of the RBF network, the Euclidean distance between the data centers was used to calculate the variance of the node and find the optimal center and radius of the radial basis function, so as to improve the learning performance of RBF network. In the experiment, the MYO armband sensor was used to sample the real sEMG signal data of 6 volunteers under 8 gestures. The experiment result show that the proposed algorithm as a classifier achieves a maximum recognition rate of 100 %, an average recognition accuracy of 96.875 ± 2.7296 %, and a response time of 0.437 s. Meanwhile, the effects of the proposed method on hand motion recognition with different classifiers (RBF with k-means, K-Nearest Neighbor, Multi-Layer Perceptron with Scaled Conjugate Gradient) were compared. The corresponding average accuracy rates were 95.833 ± 3.3244 % (RBF with k-means), 94.583 ± 2.243 % (KNN) and 88.89 ± 1.1324 % (MLP with SCG). Compared with existed methods, the advantages of the method proposed in this research are as follows: 1) This research selects the PCA method and threshold value method based on the short-term average energy (STAE) used to detect the active segment of sEMG signal, so as to select the appropriate feature vector; 2) The proposed algorithm of SOM combined with RBF has higher identification accuracy and efficiency than that of RBF with k-means, which is more conducive to distinguish different actions; 3) While ensuring real-time performance, it can accurately classify gestures that are easy to be confused, indicating that this classification method has a good application prospect in prosthetic control and other fields.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2021.01.028,Journal,Neural Networks,scopus,2021-07-01,sciencedirect,Biomimetic FPGA-based spatial navigation model with grid cells and place cells,https://api.elsevier.com/content/abstract/scopus_id/85101901812,"The mammalian spatial navigation system is characterized by an initial divergence of internal representations, with disparate classes of neurons responding to distinct features including location, speed, borders and head direction; an ensuing convergence finally enables navigation and path integration. Here, we report the algorithmic and hardware implementation of biomimetic neural structures encompassing a feed-forward trimodular, multi-layer architecture representing grid-cell, place-cell and decoding modules for navigation. The grid-cell module comprised of neurons that fired in a grid-like pattern, and was built of distinct layers that constituted the dorsoventral span of the medial entorhinal cortex. Each layer was built as an independent continuous attractor network with distinct grid-field spatial scales. The place-cell module comprised of neurons that fired at one or few spatial locations, organized into different clusters based on convergent modular inputs from different grid-cell layers, replicating the gradient in place-field size along the hippocampal dorso-ventral axis. The decoding module, a two-layer neural network that constitutes the convergence of the divergent representations in preceding modules, received inputs from the place-cell module and provided specific coordinates of the navigating object. After vital design optimizations involving all modules, we implemented the tri-modular structure on Zynq Ultrascale+ field-programmable gate array silicon chip, and demonstrated its capacity in precisely estimating the navigational trajectory with minimal overall resource consumption involving a mere 2.92% Look Up Table utilization. Our implementation of a biomimetic, digital spatial navigation system is stable, reliable, reconfigurable, real-time with execution time of about 32 s for 100k input samples (in contrast to 40 minutes on Intel Core i7-7700 CPU with 8 cores clocking at 3.60 GHz) and thus can be deployed for autonomous-robotic navigation without requiring additional sensors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physrep.2021.03.002,Journal,Physics Reports,scopus,2021-06-25,sciencedirect,"Physical principles of brain–computer interfaces and their applications for rehabilitation, robotics and control of human brain states",https://api.elsevier.com/content/abstract/scopus_id/85103968577,"Brain–computer interfaces (BCIs) development is closely related to physics. In this paper, we review the physical principles of BCIs, and underlying novel approaches for registration, analysis, and control of brain activity. We analyze recent advances in BCI studies focusing on their applications for (i) controlling the movement of robots and exoskeletons, (ii) revealing and preventing brain pathologies, (iii) assessing and controlling psychophysiological states, and (iv) monitoring and controlling normal and pathological cognitive activity.
                  We consider the BCI as a hardware/software communication system that allows interaction of humans or animals with their surroundings without the involvement of peripheral nerves and muscles, using control signals generated from brain cerebral activity. Classifying BCIs into three main types (active, reactive and passive), we describe their functional models and neuroimaging methods, as well as novel techniques for signal enhancement and artifact recognition and avoidance, to improve BCI performance in real time. We also review different BCI applications, including communications, external device control, movement control, neuroprostheses, and assessment of human psychophysiological states.
                  Then, we describe the most common techniques for the analysis and classification of electroencephalographic (EEG) and magnetoencephalographic (MEG) data. Special attention is paid to modern technology based on machine learning and reservoir computing. We discuss main results on the creation and application of BCIs based on invasive and noninvasive EEG recordings. First, we consider neurointerfaces for controlling the movement of robots and exoskeletons. Second, we describe BCIs for diagnosis and control of pathological brain activity, in particular, epilepsy. We also discuss the results on the development of invasive BCIs for predicting and mitigating absence epileptic seizures. After that, we focus on passive neurointerfaces for assessing and controlling a person’s psychophysiological states and cognitive activity. Special attention is given to optogenetic brain interfaces using photostimulation to deliver intervention to specific cell types. We outline the basic principles of optogenetic neurocontrol and extracellular electrophysiology recording. We also describe the state-of-the-art of miniaturized closed-loop optogenetic devices to control normal and pathological brain activities.
                  Further, we discuss the new emerging technological trend in the BCI development which consists in using neurointerfaces to improve the interaction between people, so-called brain-to-brain interfaces (BBIs). Such interfaces can increase the efficiency of collaborative processes when working in a group. We propose a BBI which distributes a cognitive load among all team members working on a common task. This BBI allows sharing the workload among the participants according to their current cognitive performance, estimated from their electrical brain activity. The novel results of the brain-to-brain interaction are promising for the development of a new generation of communication systems based on the neurophysiological brain activity of interacting persons, where the BBI estimates physical conditions of each partner and adapts the assigned task accordingly.
                  Finally, we trace the main historical epochs in BCI development and applications and highlight possible future directions for this research area, including hybrid BCIs.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00005-4,Journal,The Lancet Digital Health,scopus,2021-06-01,sciencedirect,Health information technology and digital innovation for national learning health and care systems,https://api.elsevier.com/content/abstract/scopus_id/85106359380,"Health information technology can support the development of national learning health and care systems, which can be defined as health and care systems that continuously use data-enabled infrastructure to support policy and planning, public health, and personalisation of care. The COVID-19 pandemic has offered an opportunity to assess how well equipped the UK is to leverage health information technology and apply the principles of a national learning health and care system in response to a major public health shock. With the experience acquired during the pandemic, each country within the UK should now re-evaluate their digital health and care strategies. After leaving the EU, UK countries now need to decide to what extent they wish to engage with European efforts to promote interoperability between electronic health records. Major priorities for strengthening health information technology in the UK include achieving the optimal balance between top-down and bottom-up implementation, improving usability and interoperability, developing capacity for handling, processing, and analysing data, addressing privacy and security concerns, and encouraging digital inclusivity. Current and future opportunities include integrating electronic health records across health and care providers, investing in health data science research, generating real-world data, developing artificial intelligence and robotics, and facilitating public–private partnerships. Many ethical challenges and unintended consequences of implementation of health information technology exist. To address these, there is a need to develop regulatory frameworks for the development, management, and procurement of artificial intelligence and health information technology systems, create public–private partnerships, and ethically and safely apply artificial intelligence in the National Health Service.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2021.106918,Journal,Knowledge-Based Systems,scopus,2021-05-23,sciencedirect,Intelligent human action recognition using an ensemble model of evolving deep networks with swarm-based optimization,https://api.elsevier.com/content/abstract/scopus_id/85102146279,"Automatic interpretation of human actions from realistic videos attracts increasing research attention owing to its growing demand in real-world deployments such as biometrics, intelligent robotics, and surveillance. In this research, we propose an ensemble model of evolving deep networks comprising Convolutional Neural Networks (CNNs) and bidirectional Long Short-Term Memory (BLSTM) networks for human action recognition. A swarm intelligence (SI)-based algorithm is also proposed for identifying the optimal hyper-parameters of the deep networks. The SI algorithm plays a crucial role for determining the BLSTM network and learning configurations such as the learning and dropout rates and the number of hidden neurons, in order to establish effective deep features that accurately represent the temporal dynamics of human actions. The proposed SI algorithm incorporates hybrid crossover operators implemented by sine, cosine, and tanh functions for multiple elite offspring signal generation, as well as geometric search coefficients extracted from a three-dimensional super-ellipse surface. Moreover, it employs a versatile search process led by the yielded promising offspring solutions to overcome stagnation. Diverse CNN–BLSTM networks with distinctive hyper-parameter settings are devised. An ensemble model is subsequently constructed by aggregating a set of three optimized CNN–BLSTM​ networks based on the average prediction probabilities. Evaluated using several publicly available human action data sets, our evolving ensemble deep networks illustrate statistically significant superiority over those with default and optimal settings identified by other search methods. The proposed SI algorithm also shows great superiority over several other methods for solving diverse high-dimensional unimodal and multimodal optimization functions with artificial landscapes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103787,Journal,Journal of Biomedical Informatics,scopus,2021-05-01,sciencedirect,Can technological advancements help to alleviate COVID-19 pandemic? a review,https://api.elsevier.com/content/abstract/scopus_id/85104674391,"The COVID-19 pandemic is continuing, and the innovative and efficient contributions of the emerging modern technologies to the pandemic responses are too early and cannot be completely quantified at this moment. Digital technologies are not a final solution but are the tools that facilitate a quick and effective pandemic response. In accordance, mobile applications, robots and drones, social media platforms (such as search engines, Twitter, and Facebook), television, and associated technologies deployed in tackling the COVID-19 (SARS-CoV-2) outbreak are discussed adequately, emphasizing the current-state-of-art. A collective discussion on reported literature, press releases, and organizational claims are reviewed. This review addresses and highlights how these effective modern technological solutions can aid in healthcare (involving contact tracing, real-time isolation monitoring/screening, disinfection, quarantine enforcement, syndromic surveillance, and mental health), communication (involving remote assistance, information sharing, and communication support), logistics, tourism, and hospitality. The study discusses the benefits of these digital technologies in curtailing the pandemic and ‘how’ the different sectors adapted to these in a shorter period. Social media and television’s role in ensuring global connectivity and serving as a common platform to share authentic information among the general public were summarized. The World Health Organization and Governments’ role globally in-line with the prevention of propagation of false news, spreading awareness, and diminishing the severity of the COVID-19 was discussed. Furthermore, this collective review is helpful to investigators, health departments, Government organizations, and policymakers alike to facilitate a quick and effective pandemic response.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2021.106091,Journal,Computers and Electronics in Agriculture,scopus,2021-05-01,sciencedirect,DeepWay: A Deep Learning waypoint estimator for global path generation,https://api.elsevier.com/content/abstract/scopus_id/85103275872,"Agriculture 3.0 and 4.0 have gradually introduced service robotics and automation into several agricultural processes, mostly improving crops quality and seasonal yield. Row-based crops are the perfect settings to test and deploy smart machines capable of monitoring and manage the harvest. In this context, global path generation is essential either for ground or aerial vehicles, and it is the starting point for every type of mission plan. Nevertheless, little attention has been currently given to this problem by the research community and global path generation automation is still far to be solved. In order to generate a viable path for an autonomous machine, the presented research proposes a feature learning fully convolutional model capable of estimating waypoints given an occupancy grid map. In particular, we apply the proposed data-driven methodology to the specific case of row-based crops with the general objective to generate a global path able to cover the extension of the crop completely. Extensive experimentation with a custom made synthetic dataset and real satellite-derived images of different scenarios have proved the effectiveness of our methodology and demonstrated the feasibility of an end-to-end and completely autonomous global path planner.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.autcon.2021.103569,Journal,Automation in Construction,scopus,2021-05-01,sciencedirect,Robotic assembly of timber joints using reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85101596404,"In architectural construction, automated robotic assembly is challenging due to occurring tolerances, small series production and complex contact situations, especially in assembly of elements with form-closure such as timber structures with integral joints. This paper proposes to apply Reinforcement Learning to control robot movements in contact-rich and tolerance-prone assembly tasks and presents the first successful demonstration of this approach in the context of architectural construction. Exemplified by assembly of lap joints for custom timber frames, robot movements are guided by force/torque and pose data to insert a timber element in its mating counterpart(s). Using an adapted Ape-X DDPG algorithm, the control policy is trained entirely in simulation and successfully deployed in reality. The experiments show the policy can also generalize to situations in real world not seen in training, such as tolerances and shape variations. This caters to uncertainties occurring in construction processes and facilitates fabrication of differentiated, customized designs.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2021.103735,Journal,Robotics and Autonomous Systems,scopus,2021-05-01,sciencedirect,Accurate and real-time human-joint-position estimation for a patient-transfer robot using a two-level convolutional neutral network,https://api.elsevier.com/content/abstract/scopus_id/85101411793,"Human-joint-position estimation is crucial for patient-transfer robots. However, high accuracy and real-time property are difficult to achieve simultaneously. To tackle the problem, we develop a new convolutional neural network (CNN), containing two levels of subnetworks, to fuse the information in color and depth images. The first-level subnetwork generates two-dimensional (2D) human joint positions from a color image by the part-affinity-fields method. The second-level subnetwork estimates 3D human-joint positions from 2D ones and corresponding depth images. Here, strong feature-extraction function of the CNN may suppress the negative effect caused by invalid information in depth images. Meanwhile, all the estimations are implemented with the 2D CNNs, which may cause higher time-efficiency than 3D ones (mostly used in previous studies). To assess the validity, first we employed the CNN to estimate human joint positions, and obtained the accuracy and speed of respectively 90.3% and 210 ms (implemented with an affordable processing unit). Then we applied the CNN to a dual-arm nursing-care robot and found that the accuracy and processing speed satisfied the requirements in practical usage; these validated the effectiveness of our proposal and provided a new approach to generate 3D-human-joint positions through information fusion of color and depth images.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2021.101990,Journal,Medical Image Analysis,scopus,2021-05-01,sciencedirect,VR-Caps: A Virtual Environment for Capsule Endoscopy,https://api.elsevier.com/content/abstract/scopus_id/85101407908,"Current capsule endoscopes and next-generation robotic capsules for diagnosis and treatment of gastrointestinal diseases are complex cyber-physical platforms that must orchestrate complex software and hardware functions. The desired tasks for these systems include visual localization, depth estimation, 3D mapping, disease detection and segmentation, automated navigation, active control, path realization and optional therapeutic modules such as targeted drug delivery and biopsy sampling. Data-driven algorithms promise to enable many advanced functionalities for capsule endoscopes, but real-world data is challenging to obtain. Physically-realistic simulations providing synthetic data have emerged as a solution to the development of data-driven algorithms. In this work, we present a comprehensive simulation platform for capsule endoscopy operations and introduce VR-Caps, a virtual active capsule environment that simulates a range of normal and abnormal tissue conditions (e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope designs (e.g., mono, stereo, dual and 360
                        
                           
                           ∘
                        
                      camera), and the type, number, strength, and placement of internal and external magnetic sources that enable active locomotion. VR-Caps makes it possible to both independently or jointly develop, optimize, and test medical imaging and analysis software for the current and next-generation endoscopic capsule systems. To validate this approach, we train state-of-the-art deep neural networks to accomplish various medical image analysis tasks using simulated data from VR-Caps and evaluate the performance of these models on real medical data. Results demonstrate the usefulness and effectiveness of the proposed virtual platform in developing algorithms that quantify fractional coverage, camera trajectory, 3D map reconstruction, and disease classification. All of the code, pre-trained weights and created 3D organ models of the virtual environment with detailed instructions how to setup and use the environment are made publicly available at https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy and a video demonstration can be seen in the supplementary videos (Video-I).",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.biosystemseng.2021.01.014,Journal,Biosystems Engineering,scopus,2021-04-01,sciencedirect,Combining generative adversarial networks and agricultural transfer learning for weeds identification,https://api.elsevier.com/content/abstract/scopus_id/85100388257,"In recent years, automatic weed control has emerged as a promising alternative for reducing the amount of herbicide applied to the field, instead of conventional spraying. The use of artificial intelligence through the implementation of deep learning for early weeds identification has been one of the engines to boost this progress. However, these techniques usually need very large datasets coping with real-world conditions, which are scarce in the agricultural domain. To address the lack of such datasets, this paper proposes a methodology that combines the use of agricultural transfer learning and the creation of artificial images by generative adversarial networks (GANs). Several architectures and configurations have been evaluated on a dataset containing images of tomato and black nightshade. The best configuration was a combination of GANs creating plausible synthetic images and the Xception network, with a performance of 99.07% on the test set and 93.23% on a noisy version of the same set. Other architectures, such as Inception or DenseNet have also been evaluated, and they obtained promising results by using GANs. According to the results, the combination of advanced transfer learning and data augmentation techniques through GANs should be deeply studied in the future with more complex datasets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.10.097,Journal,Neurocomputing,scopus,2021-03-21,sciencedirect,3D-RVP: A method for 3D object reconstruction from a single depth view using voxel and point,https://api.elsevier.com/content/abstract/scopus_id/85097471582,"Three-dimensional object reconstruction technology has a wide range of applications such as augment reality, virtual reality, industrial manufacturing and intelligent robotics. Although deep learning-based 3D object reconstruction technology has developed rapidly in recent years, there remain important problems to be solved. One of them is that the resolution of reconstructed 3D models is hard to improve because of the limitation of memory and computational efficiency when deployed on resource-limited devices. In this paper, we propose 3D-RVP to reconstruct a complete and accurate 3D geometry from a single depth view, where R, V and P represent Reconstruction, Voxel and Point, respectively. It is a novel two-stage method that combines a 3D encoder-decoder network with a point prediction network. In the first stage, we propose a 3D encoder-decoder network with residual learning to output coarse prediction results. In the second stage, we propose an iterative subdivision algorithm to predict the labels of adaptively selected points. The proposed method can output high-resolution 3D models by increasing a small number of parameters. Experiments are conducted on widely used benchmarks of a ShapeNet dataset in which four categories of models are selected to test the performance of neural networks. Experimental results show that our proposed method outperforms the state-of-the-arts, and achieves about 
                        
                           2.7
                           %
                        
                      improvement in terms of the intersection-over-union metric.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enconman.2021.113896,Journal,Energy Conversion and Management,scopus,2021-03-15,sciencedirect,A cascade hybrid PSO feed-forward neural network model of a biomass gasification plant for covering the energy demand in an AC microgrid,https://api.elsevier.com/content/abstract/scopus_id/85100622584,"Agriculture and forestry crop residues represent more than half of the world's residual biomass; these residues turn into synthesis gas (syngas) and are used for power generation. Including Syngas Gensets into hybrid renewable microgrids for electricity generation is an interesting alternative, especially for rural communities where forest and agricultural waste are abundant. However, energy demand is not constant throughout the day. The variations in the energy demand provoke changes in both gasification plant efficiency and biomass consumption. This paper presents an Artificial Neural Network (ANN) based model hybridized with a Particle Swarm Optimization (PSO) algorithm for a Biomass Gasification Plant (BGP) that allows estimating the amount of biomass needed to produce the required syngas to meet the energy demand. The proposed model is compared with two traditional models of ANNs: Feed Forward Back Propagation (FF-BP) and Cascade Forward Propagation (CF-P). ANNs are trained in MATLAB software using a set of historical real data from a BGP located in the Distributed Energy Resources Laboratory of the Universitat Politècnica de València in Spain. The model performance is validated using the Mean Squared Error (MSE) and linear regression analysis. The results show that the proposed model performs 23.2% better in terms of MSE than de other models. The tunning parameters of the optimal PSO algorithm for this application were found. Finally, the model was validated to predict the necessary biomass and syngas to cover the energy demand.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2020.103701,Journal,Robotics and Autonomous Systems,scopus,2021-02-01,sciencedirect,On deep learning techniques to boost monocular depth estimation for autonomous navigation,https://api.elsevier.com/content/abstract/scopus_id/85098871371,"Inferring the depth of images is a fundamental inverse problem within the field of Computer Vision since depth information is obtained through 2D images, which can be generated from infinite possibilities of observed real scenes. Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore structural features and spatial image information, Single Image Depth Estimation (SIDE) is often highlighted in scopes of scientific and technological innovation, as this concept provides advantages related to its low implementation cost and robustness to environmental conditions. In the context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by producing high-quality depth maps, which are essential during the autonomous navigation process in different locations. However, such networks are usually supervised by sparse and noisy depth data, from Light Detection and Ranging (LiDAR) laser scans, and are carried out at high computational cost, requiring high-performance Graphic Processing Units (GPUs). Therefore, we propose a new lightweight and fast supervised CNN architecture combined with novel feature extraction models which are designed for real-world autonomous navigation. We also introduce an efficient surface normals module, jointly with a simple geometric 2.5D loss function, to solve SIDE problems. We also innovate by incorporating multiple Deep Learning techniques, such as the use of densification algorithms and additional semantic, surface normals and depth information to train our framework. The method introduced in this work focuses on robotic applications in indoor and outdoor environments and its results are evaluated on the competitive and publicly available NYU Depth V2 and KITTI Depth datasets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103301,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,IoT enabled cancer prediction system to enhance the authentication and security using cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85094168107,"In recent days, Internet of Things, Cloud Computing, Deep learning, Machine learning and Artificial Intelligence are considered to be an emerging technologies to solve variety of real world problems. These techniques are importantly applied in various fields such as healthcare systems, transportation systems, agriculture and smart cities to produce fruitful results for number of issues in today's environment. This research work focuses on one such application in the field of IoT together with cloud computing. More number of sensors that are deployed in human body is used to collect patient related data such as deviation in body temperature and others which leads to variation in blood cells that turned to be cancerous cells. Main intention of this work is design a cancer prediction system using Internet of Things upon extracting the details of blood results to test whether it is normal or abnormal. In addition to this, encryption is done on the blood results of cancer affected patient and store it in cloud for quick reference through Internet for the doctor or healthcare nurse to handle the patient data secretly. This research work concentrates on enhancing the health care computations and processing. It provides a framework to enhance the performance of the existing health care industry across the globe. As the entire medical data has to be saved in cloud, the traditional medical treatment limitations can be overcome. Encryption and decryption is done using AES algorithm in order to provide authentication and security in handling cancer patients. The main focus is to handle healthcare data effectively for the patient when they are away from the home town since the needed cancer treatment details are stored in cloud. The task completion time is greatly reduce from 400 to 160  by using VMs. CloudSim gives an adaptable simulation structure that empowers displaying and reproduced results.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2020.102029,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-02-01,sciencedirect,Towards manufacturing robotics accuracy degradation assessment: A vision-based data-driven implementation,https://api.elsevier.com/content/abstract/scopus_id/85088120602,"In this manuscript we report on a vision-based data-driven methodology for industrial robot health assessment. We provide an experimental evidence of the usefulness of our methodology on a system comprised of a 6-axis industrial robot, two monocular cameras and five binary squared fiducial markers. The fiducial marker system permits to accurately track the deviation of the end-effector along a fixed non-trivial trajectory. Moreover, we monitor the trajectory deflection using three gradually increasing weights attached to the end-effector. When the robot is loaded with the maximum allowed payload, a deviation of 0.77mm is identified in the Z-coordinate of the end-effector. Tracing trajectory information, we train five supervised learning regression models. Such models are afterwards used to predict the deviation of the end-effector, using the pose estimation provided by the visual tracking system. As a result of this study, we show that this procedure is a stable, robust, rigorous and reliable tool for robot trajectory deviation estimation and it even allows to identify the mechanical element producing non-kinematic errors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejso.2020.04.010,Journal,European Journal of Surgical Oncology,scopus,2021-02-01,sciencedirect,Peroperative personalised decision support and analytics for colon cancer surgery- Short report,https://api.elsevier.com/content/abstract/scopus_id/85083856433,"Advanced instrumentation whether robotic or non-robotic- hasn't itself made for better surgery as all critical measures of operative success depend still on intraoperative surgeon judgement and decision-making. Computer assisted surgery, or digital surgery, refers to the combination of technology with real-time data during an operation and is often assumed to need new hardware platforms to become a reality. However, methods to support personalised surgical endeavour exist now and can be deployed today within standard laparoscopic paradigms. Here we describe in detail the rationale for the deployment of such assistance for surgical step-advancement in our current practice evolution from traditional proximal colon cancer resection to complete mesocolic excision focussing on personalised 3d anatomical display, intraoperative, quantificative fluorescence assessment of intracorporeal anastomoses and postoperative digital feedback to enable reflection and identify areas of technical improvement.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85769-7.00020-3,Book,Cognitive Computing for Human-Robot Interaction: Principles and Practices,scopus,2021-01-01,sciencedirect,Cognitive Computing for Human-Robot Interaction: Principles and Practices,https://api.elsevier.com/content/abstract/scopus_id/85129041468,Unknown,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-820276-0.00010-8,Book,Unmanned Aerial Systems: Theoretical Foundation and Applications: A Volume in Advances in Nonlinear Dynamics and Chaos (ANDC),scopus,2021-01-01,sciencedirect,"Unmanned aerial systems: Autonomy, cognition, and control",https://api.elsevier.com/content/abstract/scopus_id/85126812295,"The increasing trend towards a higher level of autonomy in unmanned aerial systems (UASs) had led to lower requirements for control by the human operator and to an increasing capability to perform complex tasks by reacting to the environmental influences. Nevertheless, current UASs are designed to function in static and predictable environments. Therefore, it is envisaged that the existing uncertainties and dynamic changes, caused when an unmanned aerial vehicle (UAV) is operating in an unknown environment, would reduce its performance significantly. The uncertainties can be also incurred through interaction with other complex and intelligent systems, such as humans. We present a compact literature survey of UAS control and navigation as a basic knowledge to develop UASs from the perspective of the control engineer. Besides, we present several control strategies to maintain a UAS, as well as multi-UASs, under a network setting under various scenarios. Several simulations are given to illustrate the performance of the controllers in MATLAB®. Advances in computing power and algorithms currently enable the development of systems with a high degree of autonomy. Nonetheless, there is a large gap between practical operation in the real-world and laboratory implementation, as safe deployment of UASs requires validation of their behavior under almost all envisaged scenarios. A reliable and autonomous operation of such a system requires design and development of a cognitive control system that acquires knowledge and understanding of the surrounding environment via perception, reasoning, and learning. Cognitive control systems in UASs will enhance their safety and performance. Cognitive control can also be used in cooperative execution of complex tasks where multiple agents such as humans, machines, or both interact. Such UASs will have a great potential to be used in extreme environments such as search and rescue in the case of disaster, nuclear decommissioning operations, deep-sea exploration, mining, etc.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2021.11.057,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,An architecture for sim-to-real and real-to-sim experimentation in robotic systems,https://api.elsevier.com/content/abstract/scopus_id/85121579023,Research in the area of robotic systems has greatly benefited from the use of simulation models. Recent approaches allow the transfer of developed algorithms from simulation to reality (sim-to-real) and increasingly accurate representations of real systems as simulation models (real-to-sim). The paper presents an architecture based on open software that supports simultaneous experiments on real robots and their simulation models. Two illustrative examples are shown: a digital twin of an industrial robot and a sim-to-real transfer in an autonomous mobile robot system. The possibilities of future research on the interaction between robotic systems and their simulation models are discussed.,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.10.086,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-01-01,sciencedirect,Explainable AI methods on a deep reinforcement learning agent for automatic docking,https://api.elsevier.com/content/abstract/scopus_id/85120875018,"Artifical neural networks (ANNs) have made their way into marine robotics in the last years, where they are used in control and perception systems, to name a few examples. At the same time, the black-box nature of ANNs is responsible for key challenges related to interpretability and trustworthiness, which need to be addressed if ANNs are to be deployed safely in real-life operations. In this paper, we implement three XAI methods to provide explanations to the decisions made by a deep reinforcement learning agent: Kernel SHAP, LIME and Linear Model Trees (LMTs). The agent was trained via Proximal Policy Optimization (PPO) to perform automatic docking on a fully-actuated vessel. We discuss the properties and suitability of the three methods, and juxtapose them with important attributes of the docking agent to provide context to the explanations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.08.062,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-01-01,sciencedirect,"Indoor positioning, artificial intelligence and digital twins for enhanced robotics safety",https://api.elsevier.com/content/abstract/scopus_id/85120685413,"Flexible robotics safety solutions allowing the implementation of fenceless robot cells are becoming a reality nowadays. Safety approved sensors such as light curtains, safety scanners, and safety cameras have been deployed already successfully in various industrial robotic solutions. Still, as these safety systems are installed in fixed locations, monitoring predefined regions, the systems can be rigid and inflexible. This paper introduces a novel hybrid safety solution. The solution comprises safety-approved sensors, additional sensors, and artificial intelligence analysis. The system increases flexibility, especially in cases where collaborating humans and robots need monitoring in larger areas. Typically, in such environments, work objects are large and heavy, introducing additional challenges. In addition, the proposed system includes a digital twin implementation that allows a connection between the real and virtual worlds. Already virtual models and robot simulation have been used for designing safe robot applications. However, the efficient use of digital twins in safety planning and safety monitoring is still uncommon.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.10.002,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-01-01,sciencedirect,On differential drive robot learning convex policy with application to path-tracking,https://api.elsevier.com/content/abstract/scopus_id/85120604947,"This paper presents an experimental validation of a learning convex policy for path-tracking on a differential drive robot. An online implementation of the convex control policy (COCP) is provided in the ROS environment using the CVXGEN package that runs on the on-board computer in a real-time application. The control policies are trained in an off-board computer considering a stochastic kinematic description of the robot and using an approximate gradient method for a given cost-to-go metric function. The policy is validated through simulation and experimental evaluation. In addition, to certify the training efficacy, the experiment is also evaluated using the untuned policy. A discussion regarding trajectory errors is presented as well as final considerations for the solver and real-time concerns.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.09.173,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Safe learning for control using control lyapunov functions and control barrier functions: A review,https://api.elsevier.com/content/abstract/scopus_id/85116855071,"Real-world autonomous systems are often controlled using conventional model-based control methods. But if accurate models of a system are not available, these methods may be unsuitable. For many safety-critical systems, such as robotic systems, a model of the system and a control strategy may be learned using data. When applying learning to safety-critical systems, guaranteeing safety during learning as well as testing/deployment is paramount. A variety of different approaches for ensuring safety exists, but the published works are cluttered and there are few reviews that compare the latest approaches. This paper reviews two promising approaches on guaranteeing safety for learning-based robust control of uncertain dynamical systems, which are based on control barrier functions and control Lyapunov functions. While control barrier functions provide an option to incorporate safety in terms of constraint satisfaction, control Lyapunov functions are used to define safety in terms of stability. This review categorises learning-based methods that use control barrier functions and control Lyapunov functions into three groups, namely reinforcement learning, online and offline supervised learning. Finally, the paper presents a discussion of the suitability of the different methods for different applications.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-88506-5.50194-7,Book Series,Computer Aided Chemical Engineering,scopus,2021-01-01,sciencedirect,Attack Detection Using Unsupervised Learning Algorithms in Cyber-Physical Systems,https://api.elsevier.com/content/abstract/scopus_id/85110277992,"Cyber-Physical Systems (CPS) are collections of physical and computer components that are integrated with each other to operate a process safely and efficiently. Examples of CPS include industrial control systems, water systems, robotics systems, smart grid, etc. However, the security aspect of CPS is still a concern that makes them vulnerable to cyber attacks on the control elements, network or physical systems. The work reported here is an attempt towards detecting cyber attacks and improving process monitoring in CPS; using unsupervised machine learning anomaly detection algorithms such as one-class SVM, isolation forest, elliptic envelope. These algorithms are evaluated using the dataset of a real Water Distribution Plant (WADI) built at the iTrust centre at Singapore University of Technology and Design for cyber security research. For modelling purposes, process 1 and 2 of the aforementioned plant were taken into consideration because the implemented attacks were closely related to only these sub-processes. The result of the experiment shows that one-class SVM is found to be the most effective algorithm in determining anomalies for this particular dataset.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2021.01.010,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Analysis of Barriers to Industry 4.0 adoption in Manufacturing Organizations: An ISM Approach,https://api.elsevier.com/content/abstract/scopus_id/85102622489,"Industry 4.0 has enabled technological integration of cyber physical systems and internet based communication in manufacturing value creation processes. As of now, many people use it as a collective term for advanced technologies, i.e. advanced robotics, artificial intelligence, machine learning, big data analytics, cloud computing, smart sensors, internet of things, augmented reality, etc. This substantially improves flexibility, quality, productivity, cost, and customer satisfaction by transforming existing centralized manufacturing systems towards digital and decentralized one. Despite having potential benefits of industry 4.0, the organizations are facing typical obstacles and challenges in adopting new technologies and successful implementation in their business models. This paper aims to identify potential barriers which may hinder the implementation of industry 4.0 in manufacturing organizations. The identified barriers, through comprehensive literature review and on the basis of opinions collected from industry experts, are: poor value-chain integration, cyber-security challenges, uncertainty about economic benefits, lack of adequate skills in workforce, high investment requirements, lack of infrastructure, jobs disruptions, challenges in data management and data quality, lack of secure standards and norms, and resistance to change. Interpretive Structural Modeling (ISM) is used to establish relationships among these barriers to develop a hierarchical model and MICMAC analysis for further classification of identified barriers for better understanding. An analysis of driving and dependence of the barriers may help in clear understanding of these for successful implementation of Industry 4.0 practices in the organizations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aei.2021.101246,Journal,Advanced Engineering Informatics,scopus,2021-01-01,sciencedirect,"A systematic literature review on intelligent automation: Aligning concepts from theory, practice, and future perspectives",https://api.elsevier.com/content/abstract/scopus_id/85099458674,"With the recent developments in robotic process automation (RPA) and artificial intelligence (AI), academics and industrial practitioners are now pursuing robust and adaptive decision making (DM) in real-life engineering applications and automated business workflows and processes to accommodate context awareness, adaptation to environment and customisation. The emerging research via RPA, AI and soft computing offers sophisticated decision analysis methods, data-driven DM and scenario analysis with regard to the consideration of decision choices and provides benefits in numerous engineering applications. The emerging intelligent automation (IA) – the combination of RPA, AI and soft computing – can further transcend traditional DM to achieve unprecedented levels of operational efficiency, decision quality and system reliability. RPA allows an intelligent agent to eliminate operational errors and mimic manual routine decisions, including rule-based, well-structured and repetitive decisions involving enormous data, in a digital system, while AI has the cognitive capabilities to emulate the actions of human behaviour and process unstructured data via machine learning, natural language processing and image processing. Insights from IA drive new opportunities in providing automated DM processes, fault diagnosis, knowledge elicitation and solutions under complex decision environments with the presence of context-aware data, uncertainty and customer preferences. This sophisticated review attempts to deliver the relevant research directions and applications from the selected literature to the readers and address the key contributions of the selected literature, IA’s benefits, implementation considerations, challenges and potential IA applications to foster the relevant research development in the domain.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2020.105908,Journal,Computers and Electronics in Agriculture,scopus,2021-01-01,sciencedirect,Advance research in agricultural text-to-speech: the word segmentation of analytic language and the deep learning-based end-to-end system,https://api.elsevier.com/content/abstract/scopus_id/85097635082,"Agricultural Text-to-Speech (TTS) has attracted increasingly more attention. The application of agricultural TTS and its problems are analyzed in this paper, and the traditional framework of the TTS system and its key technologies, i.e., text analysis, rhythm generation and speech synthesis are discussed. Furthermore, two advancements in agricultural TTS, the word segmentation of analytic language and the deep learning-based end-to-end TTS system, are detailed summarized. Based on the characteristics of agriculture, some appealing research directions are pointed out: how to improve the training speed and synthesis speed of the deep learning models is still the focus; the study on the approaches of weakly-supervised learning in TTS is in fancy; and research on the real-time and high-quality speech synthesis that can be deployed in mobile devices is a key point of agricultural TTS research.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmsy.2020.06.012,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,"A digital twin to train deep reinforcement learning agent for smart manufacturing plants: Environment, interfaces and intelligence",https://api.elsevier.com/content/abstract/scopus_id/85087690907,"Filling the gaps between virtual and physical systems will open new doors in Smart Manufacturing. This work proposes a data-driven approach to utilize digital transformation methods to automate smart manufacturing systems. This is fundamentally enabled by using a digital twin to represent manufacturing cells, simulate system behaviors, predict process faults, and adaptively control manipulated variables. First, the manufacturing cell is accommodated to environments such as computer-aided applications, industrial Product Lifecycle Management solutions, and control platforms for automation systems. Second, a network of interfaces between the environments is designed and implemented to enable communication between the digital world and physical manufacturing plant, so that near-synchronous controls can be achieved. Third, capabilities of some members in the family of Deep Reinforcement Learning (DRL) are discussed with manufacturing features within the context of Smart Manufacturing. Trained results for Deep Q Learning algorithms are finally presented in this work as a case study to incorporate DRL-based artificial intelligence to the industrial control process. As a result, developed control methodology, named Digital Engine, is expected to acquire process knowledges, schedule manufacturing tasks, identify optimal actions, and demonstrate control robustness. The authors show that integrating a smart agent into the industrial platforms further expands the usage of the system-level digital twin, where intelligent control algorithms are trained and verified upfront before deployed to the physical world for implementation. Moreover, DRL approach to automated manufacturing control problems under facile optimization environments will be a novel combination between data science and manufacturing industries.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2020.107061,Journal,Mechanical Systems and Signal Processing,scopus,2021-01-01,sciencedirect,Recovering compressed images for automatic crack segmentation using generative models,https://api.elsevier.com/content/abstract/scopus_id/85086994715,"In a structural health monitoring (SHM) system that uses digital cameras to monitor cracks of structural surfaces, techniques for reliable and effective data compression are essential to ensure a stable and energy-efficient crack images transmission in wireless devices, e.g., drones and robots with high definition cameras installed. Compressive sensing (CS) is a signal processing technique that allows accurate recovery of a signal from a sampling rate much smaller than the limitation of the Nyquist sampling theorem. Different from the popular approach of simultaneously training encoder and decoder using neural network models, the CS theory ensures a high probability of accurate signal reconstruction based on random measurements that is shorter than the length of the original signal under a sparsity constraint. Such method is particularly useful when measurements are expensive, such as wireless sensing of civil structures, because its hardware implementation allows down sampling of signals during the sensing process. Hence, CS methods can achieve significant energy saving for the sensing devices. However, the strong assumption of the signals being highly sparse in an invertible space is relatively hard to guarantee for many real images, such as image of cracks. In this paper, we present a new approach of CS that replaces the sparsity regularization with a generative model that is able to effectively capture a low dimension representation of targeted images. We develop a recovery framework for automatic crack segmentation of compressed crack images based on this new CS method. We demonstrate the remarkable performance of our method that takes advantage of the strong capability of generative models to capture the necessary features required in the crack segmentation task even the backgrounds of the generated images are not well reconstructed. The superior performance of our recovery framework is illustrated by comparisons to three existing CS algorithms. Furthermore, we show that our framework is potentially extensible to other common problems in automatic crack segmentation, such as defect recovery from motion blurring and occlusion.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aprim.2020.04.014,Journal,Atencion Primaria,scopus,2021-01-01,sciencedirect,Artificial intelligence and its applications in medicine II: Current importance and practical applications,https://api.elsevier.com/content/abstract/scopus_id/85086736700,"La tecnología y la medicina siguen un camino paralelo durante las últimas décadas. Los avances tecnológicos van modificando el concepto de salud y las necesidades sanitarias están influyendo en el desarrollo de la tecnología.
                  La inteligencia artificial (IA) está formada por una serie de algoritmos lógicos suficientemente entrenados a partir de los cuales las máquinas son capaces de tomar decisiones para casos concretos a partir de normas generales.
                  Esta tecnología tiene aplicaciones en el diagnóstico y seguimiento de pacientes con una evaluación pronóstica individualizada de los mismos.
                  Además,si combinamos esta tecnología con la robótica, podemos crear máquinas inteligentes que hagan propuestas diagnósticas o que sean mucho más eficientes en su trabajo.
                  Por lo tanto la IA va a ser una tecnología presente en nuestro trabajo cotidiano a través de máquinas o programas informáticos, que de manera más o menos transparente para el usuario, van a ir siendo una realidad cotidiana en los procesos sanitarios. Los profesionales sanitarios tenemos que conocer esta tecnología, sus ventajas y sus inconvenientes, porque va a ser una parte integral de nuestro trabajo.
                  En estos dos artículos pretendemos dar una visión básica de esta tecnología adaptada a los médicos con un repaso de su historia y evolución, de sus aplicaciones reales en el momento actual y una visión de un futuro en el que la IA y el Big Data van a conformar la medicina personalizada que caracterizará al siglo XXI.
               
                  Technology and medicine follow a parallel path during the last decades. Technological advances are changing the concept of health and health needs are influencing the development of technology.
                  Artificial intelligence (AI) is made up of a series of sufficiently trained logical algorithms from which machines are capable of making decisions for specific cases based on general rules.
                  This technology has applications in the diagnosis and follow-up of patients with an individualized prognostic evaluation of them.
                  Furthermore, if we combine this technology with robotics, we can create intelligent machines that make more efficient diagnostic proposals in their work.
                  Therefore, AI is going to be a technology present in our daily work through machines or computer programs, which in a more or less transparent way for the user, will become a daily reality in health processes. Health professionals have to know this technology, its advantages and disadvantages, because it will be an integral part of our work.
                  In these two articles we intend to give a basic vision of this technology adapted to doctors with a review of its history and evolution, its real applications at the present time and a vision of a future in which AI and Big Data will shape the personalized medicine that will characterize the 21st century.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enggeo.2020.105817,Journal,Engineering Geology,scopus,2020-12-05,sciencedirect,"Successful implementations of a real-time and intelligent early warning system for loess landslides on the Heifangtai terrace, China",https://api.elsevier.com/content/abstract/scopus_id/85090411791,"Real-time monitoring and intelligent early warning system are crucial and significant to take mitigation measures and reduce casualties and property losses related to landslides. It is difficult to obtain entire monitoring data in the accelerated deformation phase in a landslide event, and hard to issue early warning information using a traditional monitoring approach with fixed and low sampling frequency. Displacement increments of loess landslides induced by agriculture irrigation on the Heifangtai terrace could be sudden and extremely rapid. Typical landslide types include loess flowslides and loess falls. It is of practical significance to develop a self-adaptive data acquisition monitoring technique and establish a real-time landslide early warning system (LEWS) to meet the needs for risk mitigation of rapid sliding slopes on the Heifangtai terrace. The monitoring technique can wirelessly transmit displacement data and the LEWS was devised using the new artificial intelligence. The LEWS could automatically release the warning information in advance of the event once the early warning parameters exceed default thresholds. In this study, the early warning procedures, real-time monitoring approach, intelligent LEWS, a multiple criteria warning model, warning release and emergency mitigation measures, and performance are introduced in detail. Six loess landslides at Heifangtai and eight landslides in other regions of China have been successfully warned since its implementation in 2012. This study proposed an effective and practical solution for the early warning of loess landslides at Heifangtai. Two typical loess landslides that had successful early warnings at Heifangtai were presented. The successful implementation could serve as a reference for global rapid slope failure cases, considering the complex nature of landslide behaviors and failure mechanisms.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2020.106783,Journal,Applied Soft Computing Journal,scopus,2020-12-01,sciencedirect,Re-training and parameter sharing with the Hash trick for compressing convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85093986069,"As an ubiquitous technology for improving machine intelligence, deep learning has largely taken the dominant position among nowadays most advanced computer vision systems. To achieve superior performance on large-scale datasets, convolutional neural networks (CNNs) are often designed as complex models with millions of parameters. This limits the deployment of CNNs in embedded intelligent computer vision systems, such as intelligent robots that are resource-constrained with real-time computing requirement. This paper proposes a simple and effective model compression scheme to improve the real-time sensing of the surrounding objects. In the proposed framework, the Hash trick is first applied to a modified convolutional layer, and the compression of the convolutional layer is realized via weight sharing. Subsequently, the Hash index matrix is introduced to represent the Hash function, and its relaxation regularization is introduced into the fine-tuned loss function. Through the dynamic retraining of the index matrix, the Hash function can be updated. We evaluate our method using several state-of-the-art CNNs. Experimental results showed that the proposed method can reduce the number of parameters in AlexNet by 24
                        ×
                      with no accuracy loss. In addition, the compressed VGG16 and ResNet50 can achieve a more than 60
                        ×
                      increased speed, which is significant.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.buildenv.2020.107089,Journal,Building and Environment,scopus,2020-12-01,sciencedirect,Adaptive and distributed operation of HVAC systems: Energy and comfort implications of active diffusers as new adaptation capacities,https://api.elsevier.com/content/abstract/scopus_id/85092480326,"Human-aware HAVC operations have been shown to be effective in improving energy efficiency, which is constrained by the HVAC system configuration and operational logic. These constraints can result in a lack of operational flexibility, which in turn reduces the adaptation capacity for energy efficiency. Therefore, in this study, we investigated the energy efficiency implications of novel adaptive capacities for HVAC including the use of proposed active diffusers, which add to the dynamics of the HAVC systems by adjusting the behavior of diffusers using two modalities of (1) binary actuation of air flow (turning flow on and off), and (2) adjusting the flow direction to target individual needs in an environment. Computational fluid dynamics was used to model and simulate the behavior of a “real-world” thermal zone to evaluate five scenarios of adaptive operations using distributed feedback from the environment, as well as active diffusers. Three scenarios used binary actuation at the thermal zone (collection of rooms) level, and two examined the adaptive operations at the diffusers level. Moreover, we examined the integration of distributed feedback at occupant locations into the control loop using averaged temperatures (in the first three scenarios) and individual-level feedback (in scenarios with diffuser level actuation). The coupling of distributed feedback and independent directional flow at the diffuser level considerably improved thermal comfort while reducing energy demands by ~25%—reflecting a considerable impact on improved energy efficiency. These findings demonstrate the potentials that artificial intelligence frameworks could bring about by enabling autonomous adaptive operations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aprim.2020.04.013,Journal,Atencion Primaria,scopus,2020-12-01,sciencedirect,Artificial intelligence and its applications in medicine I: introductory background to AI and robotics,https://api.elsevier.com/content/abstract/scopus_id/85087789087,"La tecnología y la medicina siguen un camino paralelo durante las últimas décadas. Los avances tecnológicos van modificando el concepto de salud y las necesidades sanitarias están influyendo en el desarrollo de la tecnología.
                  La inteligencia artificial (IA) está formada por una serie de algoritmos lógicos suficientemente entrenados a partir de los cuales las máquinas son capaces de tomar decisiones para casos concretos a partir de normas generales.
                  Esta tecnología tiene aplicaciones en el diagnóstico y seguimiento de pacientes con una evaluación pronóstica individualizada de los mismos.
                  Además,si combinamos esta tecnología con la robótica, podemos crear máquinas inteligentes que hagan propuestas diagnósticas o que sean mucho más eficientes en su trabajo.
                  Por lo tanto la IA va a ser una tecnología presente en nuestro trabajo cotidiano a través de máquinas o programas informáticos, que de manera más o menos transparente para el usuario, van a ir siendo una realidad cotidiana en los procesos sanitarios. Los profesionales sanitarios tenemos que conocer esta tecnología, sus ventajas y sus inconvenientes, porque va a ser una parte integral de nuestro trabajo.
                  En estos dos artículos pretendemos dar una visión básica de esta tecnología adaptada a los médicos con un repaso de su historia y evolución, de sus aplicaciones reales en el momento actual y una visión de un futuro en el que la IA y el Big Data van a conformar la medicina personalizada que caracterizará al siglo XXI.
               
                  Technology and medicine follow a parallel path during the last decades. Technological advances are changing the concept of health and health needs are influencing the development of technology.
                  Artificial intelligence (AI) is made up of a series of sufficiently trained logical algorithms from which machines are capable of making decisions for specific cases based on general rules.
                  This technology has applications in the diagnosis and follow-up of patients with an individualized prognostic evaluation of them.
                  Furthermore, if we combine this technology with robotics, we can create intelligent machines that make more efficient diagnostic proposals in their work.
                  Therefore, AI is going to be a technology present in our daily work through machines or computer programs, which in a more or less transparent way for the user, will become a daily reality in health processes. Health professionals have to know this technology, its advantages and disadvantages, because it will be an integral part of our work.
                  In these two articles we intend to give a basic vision of this technology adapted to doctors with a review of its history and evolution, its real applications at the present time and a vision of a future in which AI and Big Data will shape the personalized medicine that will characterize the 21st century.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jns.2020.117081,Journal,Journal of the Neurological Sciences,scopus,2020-11-15,sciencedirect,New technologies and Amyotrophic Lateral Sclerosis – Which step forward rushed by the COVID-19 pandemic?,https://api.elsevier.com/content/abstract/scopus_id/85090005531,"Amyotrophic Lateral Sclerosis (ALS) is a fast-progressive neurodegenerative disease leading to progressive physical immobility with usually normal or mild cognitive and/or behavioural involvement. Many patients are relatively young, instructed, sensitive to new technologies, and professionally active when developing the first symptoms. Older patients usually require more time, encouragement, reinforcement and a closer support but, nevertheless, selecting user-friendly devices, provided earlier in the course of the disease, and engaging motivated carers may overcome many technological barriers. ALS may be considered a model for neurodegenerative diseases to further develop and test new technologies. From multidisciplinary teleconsults to telemonitoring of the respiratory function, telemedicine has the potentiality to embrace other fields, including nutrition, physical mobility, and the interaction with the environment. Brain-computer interfaces and eye tracking expanded the field of augmentative and alternative communication in ALS but their potentialities go beyond communication, to cognition and robotics. Virtual reality and different forms of artificial intelligence present further interesting possibilities that deserve to be investigated. COVID-19 pandemic is an unprecedented opportunity to speed up the development and implementation of new technologies in clinical practice, improving the daily living of both ALS patients and carers.
                  The present work reviews the current technologies for ALS patients already in place or being under evaluation with published publications, prompted by the COVID-19 pandemic.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2020.103624,Journal,Robotics and Autonomous Systems,scopus,2020-11-01,sciencedirect,Associated Reality: A cognitive Human–Machine Layer for autonomous driving,https://api.elsevier.com/content/abstract/scopus_id/85089815046,"Advanced Driver Assistance Systems (ADAS) and Automated and Autonomous Vehicles (AV) are cooperative systems and processes that use: artificial intelligence, cognitive methods, cloud technologies, cooperative vehicle-to-everything-communications (V2X), software–hardwareplatforms, sensor platforms and incipient intelligent transport infrastructures, to get self-driving systems and smart connected mobility services. This paper, to support automated driving systems (assisted, semi-autonomous and fully autonomous vehicles), introduces a cognitive layer called Associated Reality to enhance the involved information, knowledge and communication processes. The architecture defined includes an augmented Local Dynamic Map, with complementary layers, and an augmented Graph Database, with complementary semantic–cognitive relations, for the considered purpose, in cooperative human–machine and machine–machine systems. Virtual augmented landmarks are defined to improve the connectivity and intelligence of the involved spatial-information systems. Different structure landmarks and sequence landmarks (which includes regular, repetitive and periodic landmarks) are defined, categorized and used in diverse visual localization and mapping scenarios, for autonomous driving. In this paper, it is also shown, as a proof-of-concept for vehicle localization and mapping in road tunnels, the visual detection of different sequences of periodic luminaires, using YOLO v3 for the corresponding LED lights detection, or a specific alternative procedure developed with very low computational cost.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.image.2020.115969,Journal,Signal Processing: Image Communication,scopus,2020-10-01,sciencedirect,Re-identification framework for long term visual object tracking based on object detection and classification,https://api.elsevier.com/content/abstract/scopus_id/85089267326,"In this paper, we address the problem of long-term visual object tracking and we present an efficient real-time single object tracking system suitable for integration in autonomous platforms that need to encompass intelligent capabilities. We propose a novel long-term tracking framework for classification based re-detection and tracking, that incorporates state estimation, object re-identification and automated management of tracking and detection results. Our method integrates a novel object re-identification technique which efficiently filters a number of detection candidates and systematically corrects the tracking results. Through extensive experimental validation on the UAV123, UAV20L and TLP datasets, we demonstrate the effectiveness of the proposed system and its advantage over several state-of-the art trackers. The results furthermore highlight the proposed tracker’s ability to handle challenges arising from real-world and long-term scenarios, such as variations in pose, scale, occlusions and out-of-view situations. Furthermore, we propose a variant that is suitable for deployment on autonomous robots, such as Unmanned Aerial Vehicles.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpurol.2020.07.008,Journal,Journal of Pediatric Urology,scopus,2020-10-01,sciencedirect,Near-Infrared fluorescence imaging using indocyanine green (ICG): Emerging applications in pediatric urology,https://api.elsevier.com/content/abstract/scopus_id/85088878077,"Background
                  Near-infrared fluorescence (NIRF) imaging with indocyanine green (ICG) has been recently adopted in pediatric minimally invasive surgery (MIS) in order to improve intra-operative visualization of anatomic structures and facilitate surgery.
               
                  Objective
                  This study aimed to report our preliminary experience using ICG technology in pediatric urology using laparoscopy and robotics.
               
                  Study design
                  ICG technology was adopted in 57 laparoscopic or robotic urological procedures performed in our unit over a 24-month period: 41 (38 laparoscopic - 3 robotic) left varicocele repairs with intra-operative lymphography and 16 renal procedures (12 laparoscopic - 4 robotic) including 9 partial nephrectomies, 3 nephrectomies and 4 renal cyst deroofings.
               
                  Results
                  The ICG solution was injected intravenously in renal procedures or into the testis body in case of varicocele repair. Regarding the timing of the administration, the ICG injection was performed intra-operatively in all cases and allowed the visualization of the anatomic structures in a matter of 30–60 s. The dosage of ICG was 0.3 mg/mL/kg in all indications. All procedures were completed laparoscopically or robotically without conversions. No adverse and allergic reactions to ICG and other complications occurred postoperatively.
               
                  Discussion
                  This paper describes for the first time in pediatric urology that ICG-guided NIRF imaging may be helpful in laparoscopic and robotic procedures. In case of varicocele repair, ICG-enhanced fluorescence allowed to perform a lymphatic-sparing procedure and avoid the risk of postoperative hydrocele. In case of partial nephrectomy, ICG-guided NIRF was helpful to visualize the vascularization of the non-functioning moiety, identify the dissection plane between the two moieties (Fig. 1) and check the perfusion of the residual parenchyma after resection of the non-functioning pole. In case of renal cyst deroofing, ICG-guided NIRF aided to identify the avascular cyst dome and to guide its resection. No real benefits of using ICG-enhanced fluorescence were observed during nephrectomy.
               
                  Conclusion
                  Our preliminary experience confirmed the safety and efficacy of ICG technology in pediatric urology and highlighted its potential advantages as adjunctive surgical technology in patients undergoing laparoscopic or robotic urological procedures. Use of NIRF was also cost-effective as no added costs were required except for the ICG dye (cost 40 eur per bottle). The most common and useful applications in pediatric urology included varicocele repair, partial nephrectomy ad renal cyst deroofing. The main limitation is the specific equipment needed in laparoscopy, that is not available in all centers whereas the robot is equipped with the Firefly® software for NIRF.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2020.106559,Journal,Applied Soft Computing Journal,scopus,2020-10-01,sciencedirect,Use of stochastic nature-inspired population-based algorithms within an online adaptive controller for mechatronic devices,https://api.elsevier.com/content/abstract/scopus_id/85088633066,"Stochastic nature-inspired population-based algorithms are very powerful tools for solving stationary and deterministic, NP-hard optimization problems. These algorithms have rarely been applied to real-world dynamic and uncertain optimization due to their complexity. In this paper, this kind of algorithms were ported onto real hardware (i.e., the velocity controller of a one degree of freedom robot mechanism), where they were used to control the behavior of a non-linear system online. This means that the feedback response from the system must be less than 5 ms. Due to the complexity of the fitness function evaluation, a surrogate linear model was used, implemented as a single-layer artificial neural network, consisting of two phases: learning and simulation. In the first phase, the model of the nonlinear plant is learned during online operation, while in the second, the value of the fitness function needed by the optimization algorithms is predicted. Six algorithms were compared with the PI-controller in our experimental work. This were: classical evolution strategies, contemporary evolution strategies, differential evolution, self-adaptive differential evolution, particle swarm optimization, and the bat algorithm. The results showed that the algorithms outperformed PI-controller in the sense of stability, flexibility and adaptability.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2020.106766,Journal,Computers and Electrical Engineering,scopus,2020-10-01,sciencedirect,Imputation of Missing Values Affecting the Software Performance of Component-based Robots,https://api.elsevier.com/content/abstract/scopus_id/85088022516,"Intelligent robots are foreseen as a technology that would be soon present in most public and private environments. In order to increase the trust of humans, robotic systems must be reliable while both response and down times are minimized. In keeping with this idea, present paper proposes the application of machine learning (regression models more precisely) to preprocess data in order to improve the detection of failures. Such failures deeply affect the performance of the software components embedded in human-interacting robots. To address one of the most common problems of real-life datasets (missing values), some traditional (such as linear regression) as well as innovative (decision tree and neural network) models are applied. The aim is to impute missing values with minimum error in order to improve the quality of data and consequently maximize the failure-detection rate. Experiments are run on a public and up-to-date dataset and the obtained results support the viability of the proposed models.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105643,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,High accurate lightweight deep learning method for gesture recognition based on surface electromyography,https://api.elsevier.com/content/abstract/scopus_id/85087496227,"Background and objectives
                  Surface Electromyography (sEMG) is used mostly for neuromuscular diagnosis, assistive technology, physical rehabilitation, and human-computer interactions. Achieving a precise and lightweight method along with low latency for gesture recognition is still a real-life challenge, especially for rehabilitation and assistive robots. This work aims to introduce a highly accurate and lightweight deep learning method for gesture recognition.
               
                  Methods
                  High-density sEMG, unlike sparse sEMG, does not require accurate electrode placement and provides more physiological information. Then we apply high-density sEMG, which, according to previous studies, leads to sEMG images. In this study, we introduce the Sensor-Wise method, which has a higher capability to extract features compared to the sEMG image method due to its high compatibility with the nature of sEMG signals and the structure of convolutional networks.
               
                  Results
                  The proposed method, because of its optimal structure with only two hidden layers and its high compatibility, has shown no sign of overfitting and was able to reach an accuracy of almost 100% (99.99%) when it was evaluated by CapgMyo DB-a database through 96 electrodes. Using this method, even with 16 electrodes, we were able to reach an accuracy of 99.8%, which was higher than the accuracies reported in the previous studies. Additionally, the method was evaluated by the CSL-HDEMG database, where the accuracy reached 99.55%. Previous studies either introduced expensive computational methods with overfitting or reported lower accuracies compared to this study.
               
                  Conclusions
                  The Sensor- Wise method has high compatibility with the nature of sEMG signals and the structure of convolutional networks. The high accuracy and lightweight structure of this method with only two hidden layers make it a proper option for hardware implementation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.fusengdes.2020.111736,Journal,Fusion Engineering and Design,scopus,2020-10-01,sciencedirect,Combining object detection with generative adversarial networks for in-component anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/85086034398,"Present inspection techniques in place at the Joint European Torus (JET), as well as some of those planned for ITER make use of robotically deployed inspection systems, which typically collect data for offline analysis. This can be a slow, laborious process with subjective or error-prone results. There are significant benefits to be gained through automation or user assistance, for example through prioritisation of samples for analysis.
                  Automated visual anomaly detection is a highly challenging problem due to high dimensionality of the input data, meaning that the normal statistical distribution cannot be directly modelled. We provide a robotic and algorithmic framework that utilizes Generative Adversarial Ngenerative adversarial networks (GANs) to indirectly model this distribution, and hence provide a mechanism to quantify the anomalousness of given image data samples from a tokamak environment.
                  This paper presents an approach to visual anomaly detection that combines multiple deep neural network architectures in order to extract individual components and then classify anomalies. An overview of the architecture and algorithms employed as well as quantitative and qualitative assessments of the performance against data from both a benchmark dataset, and real data gathered from JET components is provided.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jocn.2020.04.125,Journal,Journal of Clinical Neuroscience,scopus,2020-09-01,sciencedirect,Tele-robotics and artificial-intelligence in stroke care,https://api.elsevier.com/content/abstract/scopus_id/85088965193,"In the last forty years, the field of medicine has experienced dramatic shifts in technology-enhanced surgical procedures – from its initial use in 1985 for neurosurgical biopsies to current implementation of systems such as magnetic-guided catheters for endovascular procedures. Systems such as the Niobe Magnetic Navigation system and CorPath GRX have allowed for utilization of a fully integrated surgical robotic systems for perioperative manipulation, as well as tele-controlled manipulation systems for telemedicine. These robotic systems hold tremendous potential for future implementation in cerebrovascular procedures, but lack of relevant clinical experience and uncharted ethical and legal territory for real-life tele-robotics have stalled their adoption for neurovascular surgery, and might present significant challenges for future development and widespread implementation. Yet, the promise that these technologies hold for dramatically improving the quality and accessibility of cerebrovascular procedures such as thrombectomy for acute stroke, drives the research and development of surgical robotics. These technologies, coupled with artificial intelligence (AI) capabilities such as machine learning, deep-learning, and outcome-based analyses and modifications, have the capability to uncover new dimensions within the realm of cerebrovascular surgery.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2020.103799,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-09-01,sciencedirect,Trajectory based lateral control: A Reinforcement Learning case study,https://api.elsevier.com/content/abstract/scopus_id/85087950678,"Reinforcement Learning (RL) has been employed in many applications of robotics and has steadily been gaining traction in the field of Autonomous Driving (AD). This paper proposes a Deep Reinforcement Learning based approach for lateral Vehicle Motion Control (VMC), and explores the generalization capabilities of the approach. The proposed methodology uses a sequence of waypoints generated from a planning module of an AD stack as the input. The network has been trained to predict accurate steering commands to follow the given trajectory. In this paper we detail our implementation and share our learning experience on real-vehicle deployment of the RL based controller. Our experiments yield promising results with an agent trained on less than 4 h of simulated driving experience without any real-world data. The trained agent is able to successfully complete unseen and more complex tracks using different unseen vehicle models. The agent safely reached up to 150km/h in simulation and up to 60km/h in a real-life Sport Utility Vehicle (SUV) weighing more than 2000kg.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2020.103578,Journal,Robotics and Autonomous Systems,scopus,2020-09-01,sciencedirect,Real-time topological localization using structured-view ConvNet with expectation rules and training renewal,https://api.elsevier.com/content/abstract/scopus_id/85086575996,"Mobile service robots possess high potential of providing numerous assistances in the working areas. In an attempt to develop a mobile service robot which is dynamically balanced for faster movement and taller manipulation capability, we designed and prototyped J4.alpha, which is intended for swift navigation and nimble manipulation. Previously, we devised a pure visual method based on a supervised deep learning model for real-time recognition of nodal locations. Four low-resolution RGB cameras are installed around J4.alpha to capture the surrounding visual features for training and detection. As the method is developed for ease of implementation, fast real-time application, accurate detection, and low cost, we further improve the accuracy and the practicality of the method in this study. Specifically, a set of expectation rules are introduced to reject outlier detections, and a scheme of training renewal is devised to effectively react to environmental modifications. In our previous tests, precision and recall rates of the location coordinate detection by the ConvNet models were generally between 0.78 and 0.91; by introducing the expectation rules, precision and recall are improved by approximately 10%. A large scale field test is also carried out here for both corridor and factory scenarios; the performance of the proposed method was tested for detection accuracy and verified for 2 m and 0.5 m nodal intervals. The scheme of training renewal designed for capturing and reflecting environmental modifications was also proved to be effective.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.02.109,Journal,Neurocomputing,scopus,2020-08-04,sciencedirect,Tracking control of redundant mobile manipulator: An RNN based metaheuristic approach,https://api.elsevier.com/content/abstract/scopus_id/85082490397,"In this paper, we propose a topology of Recurrent Neural Network (RNN) based on a metaheuristic optimization algorithm for the tracking control of mobile-manipulator while enforcing nonholonomic constraints. Traditional approaches for tracking control of mobile robots usually require the computation of Jacobian-inverse or linearization of its mathematical model. The proposed algorithm uses a nature-inspired optimization approach to directly solve the nonlinear optimization problem without any further transformation. First, we formulate the tracking control as a constrained optimization problem. The optimization problem is formulated on position-level to avoid the computationally expensive Jacobian-inversion. The nonholonomic limitation is ensured by adding equality constraints to the formulated optimization problem. We then present the Beetle Antennae Olfactory Recurrent Neural Network (BAORNN) algorithm to solve the optimization problem efficiently using very few mathematical operations. We present a theoretical analysis of the proposed algorithm and show that its computational cost is linear with respect to the degree of freedoms (DOFs), i.e., O(m). Additionally, we also prove its stability and convergence. Extensive simulation results are prepared using a simulated model of IIWA14, a 7-DOF industrial-manipulator, mounted on a differentially driven cart. Comparison results with particle swarm optimization (PSO) algorithm are also presented to prove the accuracy and numerical efficiency of the proposed controller. The results demonstrate that the proposed algorithm is several times (around 75 in the worst case) faster in execution as compared to PSO, and suitable for real-time implementation. The tracking results for three different trajectories; circular, rectangular, and rhodonea paths are presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2020.103483,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Agents and robots for collaborating and supporting physicians in healthcare scenarios,https://api.elsevier.com/content/abstract/scopus_id/85087202709,"Monitoring patients through robotics telehealth systems is an interesting scenario where patients’ conditions, and their environment, are dynamic and unknown variables. We propose to improve telehealth systems’ features to include the ability to serve patients with their needs, operating as human caregivers. The objective is to support the independent living of patients at home without losing the opportunity to monitor their health status. Application scenarios are several, and they spread from simple clinical assisting scenarios to an emergency one. For instance, in the case of a nursing home, the system would support in continuously monitoring the elderly patients. In contrast, in the case of an epidemic diffusion, such as COVID-19 pandemic, the system may help in all the early triage phases, significantly reducing the risk of contagion. However, the system has to let medical assistants perform actions remotely such as changing therapies or interacting with patients that need support. The paper proposes and describes a multi-agent architecture for intelligent medical care. We propose to use the beliefs-desires-intentions agent architecture, part of it is devised to be deployed in a robot. The result is an intelligent system that may allow robots the ability to select the most useful plan for unhandled situations and to communicate the choice to the physician for his validation and permission.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2020.105535,Journal,Computers and Electronics in Agriculture,scopus,2020-08-01,sciencedirect,Vineyard trunk detection using deep learning – An experimental device benchmark,https://api.elsevier.com/content/abstract/scopus_id/85086590127,"Research and development in mobile robotics are continuously growing. The ability of a human-made machine to navigate safely in a given environment is a challenging task. In agricultural environments, robot navigation can achieve high levels of complexity due to the harsh conditions that they present. Thus, the presence of a reliable map where the robot can localize itself is crucial, and feature extraction becomes a vital step of the navigation process. In this work, the feature extraction issue in the vineyard context is solved using Deep Learning to detect high-level features – the vine trunks. An experimental performance benchmark between two devices is performed: NVIDIA’s Jetson Nano and Google’s USB Accelerator. Several models were retrained and deployed on both devices, using a Transfer Learning approach. Specifically, MobileNets, Inception, and lite version of You Only Look Once are used to detect vine trunks in real-time. The models were retrained in a built in–house dataset, that is publicly available. The training dataset contains approximately 1600 annotated vine trunks in 336 different images. Results show that NVIDIA’s Jetson Nano provides compatibility with a wider variety of Deep Learning architectures, while Google’s USB Accelerator is limited to a unique family of architectures to perform object detection. On the other hand, the Google device showed an overall Average precision higher than Jetson Nano, with a better runtime performance. The best result obtained in this work was an average precision of 52.98% with a runtime performance of 23.14 ms per image, for MobileNet-V2. Recent experiments showed that the detectors are suitable for the use in the Localization and Mapping context.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.09.104,Journal,Neurocomputing,scopus,2020-07-05,sciencedirect,A data-efficient deep learning approach for deployable multimodal social robots,https://api.elsevier.com/content/abstract/scopus_id/85065221778,"The deep supervised and reinforcement learning paradigms (among others) have the potential to endow interactive multimodal social robots with the ability of acquiring skills autonomously. But it is still not very clear yet how they can be best deployed in real world applications. As a step in this direction, we propose a deep learning-based approach for efficiently training a humanoid robot to play multimodal games—and use the game of ‘Noughts and Crosses’ with two variants as a case study. Its minimum requirements for learning to perceive and interact are based on a few hundred example images, a few example multimodal dialogues and physical demonstrations of robot manipulation, and automatic simulations. In addition, we propose novel algorithms for robust visual game tracking and for competitive policy learning with high winning rates, which substantially outperform DQN-based baselines. While an automatic evaluation shows evidence that the proposed approach can be easily extended to new games with competitive robot behaviours, a human evaluation with 130 humans playing with the Pepper robot confirms that highly accurate visual perception is required for successful game play.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2020.105499,Journal,Computers and Electronics in Agriculture,scopus,2020-07-01,sciencedirect,Implementation of deep-learning algorithm for obstacle detection and collision avoidance for robotic harvester,https://api.elsevier.com/content/abstract/scopus_id/85084730841,"Convolutional neural networks (CNNs) are the current state of the art systems in image semantic segmentation (SS). However, because it requires a large computational cost, it is not suitable for running on embedded devices, such as on rice combine harvesters. In order to detect and identify the surrounding environment for a rice combine harvester in real time, a neural network using Network Slimming to reduce the network model size, which takes wide neural networks as the input model, yielding a compact model (hereafter referred to as “pruned model”) with comparable accuracy, was applied based on an image cascade network (ICNet). Network Slimming performs channel-level sparsity of convolutional layers in the ICNet by imposing L1 regularization on channel scaling factors with the corresponding batch normalization layer, which removes less informative feature channels in the convolutional layers to obtain a more compact model. Then each of the pruned models were evaluated by mean intersection over union (IoU) on the test set. When the compaction ratio is 80%, it gives a 97.4% reduction of model volume size, running 1.33 times faster with comparable accuracy as the original model. The results showed that when the compaction ratio is less than 80%, a more efficient (less computational cost) model with a slightly reduced accuracy in comparison to the original model was achieved. Field tests were conducted with the pruned model (80% compaction ratio) to verify the performance of obstacle detection. Results showed that the average success rate of collision avoidance was 96.6% at an average processing speed of 32.2 FPS (31.1 ms per frame) with an image size of 640 × 480 pixels on a Jetson Xavier. It shows that the pruned model can be used for obstacle detection and collision avoidance in robotic harvesters.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cola.2020.100970,Journal,Journal of Computer Languages,scopus,2020-06-01,sciencedirect,"Visual Programming Environments for End-User Development of intelligent and social robots, a systematic review",https://api.elsevier.com/content/abstract/scopus_id/85085272330,"Robots are becoming interactive and robust enough to be adopted outside laboratories and in industrial scenarios as well as interacting with humans in social activities. However, the design of engaging robot-based applications requires the availability of usable, flexible and accessible development frameworks, which can be adopted and mastered by researchers and practitioners in social sciences and adult end users as a whole. This paper surveys Visual Programming Environments aimed at enabling a paradigm fostering the so-called End-User Development of applications involving robots with social capabilities. The focus of this article is on those Visual Programming Environments that are designed to support social research goals as well as to cater for professional needs of people not trained in more traditional text-based computer programming languages. This survey excludes interfaces aimed at supporting expert programmers, at allowing industrial robots to perform typical industrial tasks (such as pick and place operations), and at teaching children how to code. After having performed a systematic search, sixteen programming environments have been included in this survey. Our goal is two-fold: first, to present these software tools with their technical features and Authoring Artificial Intelligence modeling approaches, and second, to present open challenges in the development of Visual Programming Environments for end users and social researchers, which can be informative and valuable to the community. The results show that the most recent such tools are adopting distributed and Component-Based Software Engineering approaches and web technologies. However, few of them have been designed to enable the independence of end users from high-tech scribes. Moreover, findings indicate the need for (i) more objective and comparative evaluations, as well as usability and user experience studies with real end users; and (ii) validations of these tools for designing applications aimed at working “in-the-wild” rather than only in laboratories and structured settings.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2020.103670,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-06-01,sciencedirect,"Detecting, locating and recognising human touches in social robots with contact microphones",https://api.elsevier.com/content/abstract/scopus_id/85083676413,"There are many situations in our daily life where touch gestures during natural human–human interaction take place: meeting people (shaking hands), personal relationships (caresses), moments of celebration or sadness (hugs), etc. Considering that robots are expected to form part of our daily life in the future, they should be endowed with the capacity of recognising these touch gestures and the part of its body that has been touched since the gesture’s meaning may differ. Therefore, this work presents a learning system for both purposes: detect and recognise the type of touch gesture (stroke, tickle, tap and slap) and its localisation. The interpretation of the meaning of the gesture is out of the scope of this paper.
                  Different technologies have been applied to perceive touch by a social robot, commonly using a large number of sensors. Instead, our approach uses 3 contact microphones installed inside some parts of the robot. The audio signals generated when the user touches the robot are sensed by the contact microphones and processed using Machine Learning techniques. We acquired information from sensors installed in two social robots, Maggie and Mini (both developed by the RoboticsLab at the Carlos III University of Madrid), and a real-time version of the whole system has been deployed in the robot Mini. The system allows the robot to sense if it has been touched or not, to recognise the kind of touch gesture, and its approximate location. The main advantage of using contact microphones as touch sensors is that by using just one, it is possible to “cover” a whole solid part of the robot. Besides, the sensors are unaffected by ambient noises, such as human voice, TV, music etc. Nevertheless, the fact of using several contact microphones makes possible that a touch gesture is detected by all of them, and each may recognise a different gesture at the same time. The results show that this system is robust against this phenomenon. Moreover, the accuracy obtained for both robots is about 86%.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2020.105434,Journal,Computers and Electronics in Agriculture,scopus,2020-06-01,sciencedirect,Dynamic Simulation Tool of fertigation in drip irrigation subunits,https://api.elsevier.com/content/abstract/scopus_id/85083338592,"Agriculture consumes approximately 95 million tonnes of fertilizers and 97,000 tonnes of active ingredients of pesticides and herbicides. Reducing external input systems can result in significant economic, social and environmental impact. Therefore, establishing an optimal fertigation schedule is essential to achieve efficient drip irrigation management and, therefore, achieve an optimal irrigated agriculture management system that ensures productive, environmental and economic viability. The objective of this study was to develop a decision support system (DSS) to facilitate farmers’ decision-making process and optimize the design and management of farm fertigation scheduling. Implemented in MATLAB®, FERTI-DRIP, was tested in a regular irrigation subunit and in an irregular irrigation subunit of a real water user association. Both irrigation subunits were tested with two irrigation emitter types: pressure-compensating emitters and non-pressure-compensating emitters. Thus, FERTI-DRIP was applied to four scenarios to analyse the effect of the size and shape of the irrigation subunit on the fertigation process. The effect of the pressure head in the irrigation subunit and the effect of the fertilizer dynamics during the fertigation event were also analysed. FERTI-DRIP allows users to compute fertilizer quality parameters to determine how to implement fertigation. FERTI-DRIP also allows users to accurately select pre-fertigation and post-fertigation processes to optimize hydraulic stability at the beginning of the fertigation event and ensure that there is no fertilizer remaining in the irrigation system after the fertigation event. FERTI-DRIP can be very helpful for start-time irrigation events, such in the case of sandy soils where pulse drip irrigation should be performed.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2020.02.012,Journal,ISA Transactions,scopus,2020-06-01,sciencedirect,Adaptive tracking control of an unmanned aerial system based on a dynamic neural-fuzzy disturbance estimator,https://api.elsevier.com/content/abstract/scopus_id/85080895180,"The main goal of this study is developing an adaptive controller which can solve the trajectory tracking for a class of quadcopter unmanned aerial system (UAS), namely a quadrotor. The control design introduces a new paradigm for adaptive controllers based on the implementation of a set of differential neural networks (DNNs) in the consequence section of a Takagi–Sugeno (T–S) fuzzy inference system. This dynamic fuzzy inference structure was used to approximate the UAS description. The particular form of interaction between neural networks and fuzzy inference systems proposed in the present work received the name of dynamic neural fuzzy system (DNFS). An adaptive controller based on this DNFS form was the main solution attained in this study. This DNFS controller was focused on the estimation and compensation of the uncertain section of the Quadrotor dynamics and then, forced the UAS to perform a hover flight while the tracking of desired angular positions succeeded, which results in tracking a desired trajectory in the X-Y plane. The control design methodology supported on the Lyapunov stability theory guaranteed ultimate boundedness of the estimation and tracking errors simultaneously. Several experimental tests in an outdoor environment by using a real Quadrotor platform was performed by using an RTK-GPS (Real Time Kinematic) system to determine the position of the vehicle in the X-Y plane. The experimental results confirmed the superior performance of the proposed algorithm based on the combination of DNNs and T–S techniques with respect to classical robust controllers.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.simpat.2019.102015,Journal,Simulation Modelling Practice and Theory,scopus,2020-05-01,sciencedirect,A fog computing model for implementing motion guide to visually impaired,https://api.elsevier.com/content/abstract/scopus_id/85074521783,"A guide dog robot system for visually impaired often needs to process many kinds of information, such as image, voice and other sensor information. Information processing methods based on deep neural network can achieve better results. However, it requires expensive computing and communication resources to meet the real-time requirement. Fog computing has emerged as a promising solution for applications that are data-intensive and delay-sensitive. We propose a fog computing framework named PEN (Phone + Embedded board + Neural compute stick) for the guide dog robot system. The robot’s functions in PEN are wrapped as services and deployed on the appropriate devices. Services are combined as an application in a visual programming language environment. Neural compute stick accelerates image processing speed at low power consumption. A simulation environment and a prototype are built on the framework. The simulated guide dog system is developed for operating in a miniature environment, including a small robot dog, a small wheelchair, model cars, traffic lights, and traffic blockage. The prototype is a full-sized portable guide system that can be used by a visually impaired person in a real environment. Simulation and experiments show that the framework can meet the functional and performance requirements for implementing the guide systems for visually impaired.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2020.103472,Journal,Robotics and Autonomous Systems,scopus,2020-04-01,sciencedirect,Deploying MAVs for autonomous navigation in dark underground mine environments,https://api.elsevier.com/content/abstract/scopus_id/85079573394,"Operating Micro Aerial Vehicles (MAVs) in subterranean environments is becoming more and more relevant in the field of aerial robotics. Despite the large spectrum of technological advances in the field, flying in such challenging environments is still an ongoing quest that requires the combination of multiple sensor modalities like visual/thermal cameras as well as 3D and 2D lidars. Nevertheless, there exist cases in subterranean environments where the aim is to deploy fast and lightweight aerial robots for area reckoning purposes after an event (e.g. blasting in production areas). This work proposes a novel baseline approach for the navigation of resource constrained robots, introducing the aerial underground scout, with the main goal to rapidly explore unknown areas and provide a feedback to the operator. The main proposed framework focuses on the navigation, control and vision capabilities of the aerial platforms with low-cost sensor suites, contributing significantly towards real-life applications. The merit of the proposed control architecture is that it considers the flying platform as a floating object, composing a velocity controller on the 
                        x
                     , 
                        y
                      axes and altitude control to navigate along the tunnel. Two novel approaches make up the cornerstone of the proposed contributions for the task of navigation: (1) a vector geometry method based on 2D lidar, and (2) a Deep Learning (DL) method through a classification process based on an on-board image stream, where both methods correct the heading towards the center of the mine tunnel. Finally, the framework has been evaluated in multiple field trials in an underground mine in Sweden.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aei.2020.101052,Journal,Advanced Engineering Informatics,scopus,2020-04-01,sciencedirect,Deep learning-based method for vision-guided robotic grasping of unknown objects,https://api.elsevier.com/content/abstract/scopus_id/85079340469,"Nowadays, robots are heavily used in factories for different tasks, most of them including grasping and manipulation of generic objects in unstructured scenarios. In order to better mimic a human operator involved in a grasping action, where he/she needs to identify the object and detect an optimal grasp by means of visual information, a widely adopted sensing solution is Artificial Vision. Nonetheless, state-of-art applications need long training and fine-tuning for manually build the object’s model that is used at run-time during the normal operations, which reduce the overall operational throughput of the robotic system. To overcome such limits, the paper presents a framework based on Deep Convolutional Neural Networks (DCNN) to predict both single and multiple grasp poses for multiple objects all at once, using a single RGB image as input. Thanks to a novel loss function, our framework is trained in an end-to-end fashion and matches state-of-art accuracy with a substantially smaller architecture, which gives unprecedented real-time performances during experimental tests, and makes the application reliable for working on real robots. The system has been implemented using the ROS framework and tested on a Baxter collaborative robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.autcon.2020.103078,Journal,Automation in Construction,scopus,2020-04-01,sciencedirect,Complete coverage path planning using reinforcement learning for Tetromino based cleaning and maintenance robot,https://api.elsevier.com/content/abstract/scopus_id/85077924455,"Tiling robotics have been deployed in autonomous complete area coverage tasks such as floor cleaning, building inspection, and maintenance, surface painting. One class of tiling robotics, polyomino-based reconfigurable robots, overcome the limitation of fixed-form robots in achieving high-efficiency area coverage by adopting different morphologies to suit the needs of the current environment. Since the reconfigurable actions of these robots are produced by real-time intelligent decisions during operations, an optimal path planning algorithm is paramount to maximize the area coverage while minimizing the energy consumed by these robots. This paper proposes a complete coverage path planning (CCPP) model trained using deep blackreinforcement learning (RL) for the tetromino based reconfigurable robot platform called hTetro to simultaneously generate the optimal set of shapes for any pretrained arbitrary environment shape with a trajectory that has the least overall cost. To this end, a Convolutional Neural Network (CNN) with Long Short Term Memory (LSTM) layers is trained using Actor Critic Experience Replay (ACER) reinforcement learning algorithm. The results are compared with existing approaches which are based on the traditional tiling theory model, including zigzag, spiral, and greedy search schemes. The model is also compared with the Travelling salesman problem (TSP) based Genetic Algorithm (GA) and Ant Colony Optimization (ACO) schemes. The proposed scheme generates a path with lower cost while also requiring lesser time to generate it. The model is also highly robust and can generate a path in any pretrained arbitrary environments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.09.098,Journal,Neurocomputing,scopus,2020-03-14,sciencedirect,A neuromorphic SLAM architecture using gated-memristive synapses,https://api.elsevier.com/content/abstract/scopus_id/85075974125,"Navigation in GPS-denied environments is a critical challenge for autonomous mobile platforms such as drones. The concept of simultaneous localization and mapping (SLAM) addresses this challenge through real-time mapping of the platform's surroundings as it explores its environment. The computational resources required for traditional SLAM implementations (e.g. graphical processing units) require large size, weight, and power overheads; making it infeasible to employ them in resource-constrained applications. This work proposes a self-learning hardware architecture utilizing a novel gated-memristive device to address the implementation of SLAM in an energy-efficient manner. The gated-memristive devices are implemented as electronic synapses in tandem with novel low-energy spiking neurons to create a spiking neural network (SNN). This work shows how the SNN allows for navigation through an environment via landmark association without needing GPS. In the simple environment in which the network exists, it can successfully determine a direction in which to navigate while only consuming 36 µW of power and only needing to be exposed to each landmark within the environment for 1-2ms in order to remember that location.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.11.007,Journal,Neurocomputing,scopus,2020-03-14,sciencedirect,Neuropod: A real-time neuromorphic spiking CPG applied to robotics,https://api.elsevier.com/content/abstract/scopus_id/85075928379,"Initially, robots were developed with the aim of making our life easier, carrying out repetitive or dangerous tasks for humans. Although they were able to perform these tasks, the latest generation of robots are being designed to take a step further, by performing more complex tasks that have been carried out by smart animals or humans up to date. To this end, inspiration needs to be taken from biological examples. For instance, insects are able to optimally solve complex environment navigation problems, and many researchers have started to mimic how these insects behave. Recent interest in neuromorphic engineering has motivated us to present a real-time, neuromorphic, spike-based Central Pattern Generator of application in neurorobotics, using an arthropod-like robot. A Spiking Neural Network was designed and implemented on SpiNNaker. The network models a complex, online-change capable Central Pattern Generator which generates three gaits for a hexapod robot locomotion in real-time. Reconfigurable hardware was used to manage both the motors of the robot and the low-latency communication interface with the Spiking Neural Networks. Real-time measurements confirm the simulation results, and locomotion tests show that NeuroPod can perform the gaits without any balance loss or added delay.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.103447,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-03-01,sciencedirect,Emotional neural networks with universal approximation property for stable direct adaptive nonlinear control systems,https://api.elsevier.com/content/abstract/scopus_id/85077512941,"Universal approximation, continuity, and differentiability are desirable properties of any computational framework, including those that rise from human cognition and/or are inspired by nature. Emotional machines constitute one such framework, but few studies have addressed their mathematical properties. Here, we propose a Continuous Radial Basis Emotional Neural Network (CRBENN) that benefits from the universal approximation property, continuous output, and simple structure of RBF; while keeping the fast response properties of emotion-based approaches. As such, CRBENN is amenable to a wide array of challenging problems in systems engineering and artificial intelligence. Here, we propose a CRBENN-based direct adaptive robust emotional neuro-control approach (DARENC) for a class of uncertain nonlinear systems. Stability is theoretically established using Lyapunov analysis of the closed-loop system. DARENC is then applied to control two nonlinear systems, and the performance of the controller is numerically compared with several competing fuzzy, neural, and emotional controllers. The simulation results indicate improved tracking performance, better disturbance rejection, and less control effort. Finally, DARENC is implemented on a real-world 3-PSP (spherical–prismatic–spherical) parallel robot in our laboratory. The experimental results show the satisfactory performance of the robot in tracking the desired trajectory with low control effort.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ast.2019.105657,Journal,Aerospace Science and Technology,scopus,2020-03-01,sciencedirect,Reinforcement learning in dual-arm trajectory planning for a free-floating space robot,https://api.elsevier.com/content/abstract/scopus_id/85077502803,"A free-floating space robot exhibits strong dynamic coupling between the arm and the base, and the resulting position of the end of the arm depends not only on the joint angles but also on the state of the base. Dynamic modeling is complicated for multiple degree of freedom (DOF) manipulators, especially for a space robot with two arms. Therefore, the trajectories are typically planned offline and tracked online. However, this approach is not suitable if the target has relative motion with respect to the servicing space robot. To handle this issue, a model-free reinforcement learning strategy is proposed for training a policy for online trajectory planning without establishing the dynamic and kinematic models of the space robot. The model-free learning algorithm learns a policy that maps states to actions via trial and error in a simulation environment. With the learned policy, which is represented by a feedforward neural network with 2 hidden layers, the space robot can schedule and perform actions quickly and can be implemented for real-time applications. The feasibility of the trained policy is demonstrated for both fixed and moving targets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.103427,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-03-01,sciencedirect,Stochastic parallel extreme artificial hydrocarbon networks: An implementation for fast and robust supervised machine learning in high-dimensional data,https://api.elsevier.com/content/abstract/scopus_id/85076620125,"Artificial hydrocarbon networks (AHN) – a supervised learning method inspired on organic chemical structures and mechanisms – have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than 
                        
                           10
                           ,
                           000
                           x
                        
                      times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ress.2019.106700,Journal,Reliability Engineering and System Safety,scopus,2020-03-01,sciencedirect,Optimizing inspection routes in pipeline networks,https://api.elsevier.com/content/abstract/scopus_id/85073997788,"Maintaining an aging network is a challenge for many water utilities due to limited budgets and uncertainty surrounding the physical condition of buried pipeline assets. The deployment of robotic inspections provides high quality data, but these platforms have limited use due to cost and operational constraints. To facilitate cost-efficient inspections, operators need to identify high-risk assets while accounting for the effectiveness of the tools at hand. This paper addresses inspection planning with the goal of finding an optimal route while considering tool limitations. An exact integer programming formulation is presented where only three factors are used to characterize tool constraints. Two classes of solution methods are explored: 1) tree based searches, and 2) integer programming. This paper demonstrates how each method can be used to identify optimal paths within a real water distribution system. Empirical trials suggest that tree-based search methods are the most efficient when the path limit is short, but do not scale well when the path length increases. In contrast, integer-programming methods are more effective for longer path lengths but have scalability issues for large network sizes. Data preprocessing, where the input network size is reduced, can provide large computation time reductions while returning near-optimal solutions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.09.004,Journal,Neurocomputing,scopus,2020-01-02,sciencedirect,Digital neuromorphic real-time platform,https://api.elsevier.com/content/abstract/scopus_id/85072526243,"Hardware implementations of spiking neural networks in portable devices can improve many applications of robotics, neurorobotics or prosthetic fields in terms of power consumption, high-speed processing and learning mechanisms. Analog and digital platforms have been previously proposed to run these networks. Analog designs are closer to biology since they implement the original mathematical model. However, digital platforms are, to some extent, abstractions of this model so far. In this paper, a full digital platform to design, implement and run real-time analog-like spiking neural networks is presented. Specifically, we present the design and implementation of digital circuits to run real-time biologically plausible spiking neural networks on a Field Programmable Gate Array (FPGA). The circuit designed for the neuron implements the Leaky Integrate and Fire (LIF) model. The synapsis implemented is a bi-exponential current-based one. The synaptic circuit design consists of one static memory with the baseline current and a dynamic memory which stores the updated contribution over time of each pre-synaptic connection. All the parameters of both the neuron and the synapse are configurable. The results of the circuits are validated by running the same experiments on the Brian simulator. The circuits, which are totally original and independent of the technology, use only 136 slice registers of hardware resources. Thus, these designs allow the scale of the network. These circuits aim to be the basis of the spiking neural networks on digital devices. This platform allows the user to first simulate their network within the Brian simulator and then, confidently, move to the hardware platform replicating the same performance or even replace their analog platform with the digital one.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2020.12.2306,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Path-following control of fish-like robots: A deep reinforcement learning approach,https://api.elsevier.com/content/abstract/scopus_id/85102821107,"In this paper, we propose a deep reinforcement learning (DRL) approach for path-following control of a fish-like robot. The desired path may be a randomly generated Bézier curve. First, to implement the locomotion control of the fish-like robot, we design a modified Central Pattern Generated (CPG) model, using which the fish achieves varied swimming behaviors just by adjusting a single control input. To reduce the reality gap between simulation and the physical system, using the experimental data of the real fish-like robot, we build a surrogate simulation environment, which also well balances the accuracy and the speed of training. Second, for the path-following control, we select the advantage actor-critic (A2C) approach and train the control policy in the surrogate simulation environment with a straight line as the desired path. Then the trained control policy is directly deployed on a physical fish-like robot to follow a randomly generated Bézier curve. The experimental results show that our proposed approach has good practical applicability in view of its efficiency and feasibility in controlling the physical fishlike robot. This work shows a novel and promising way to control biomimetic underwater robots in the real world.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2020.07.006,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Operator support in human-robot collaborative environments using AI enhanced wearable devices,https://api.elsevier.com/content/abstract/scopus_id/85100836551,"Nowadays, in order to cover the needs of market for product mass customization, industries have started to move to hybrid production cells, involving both robots and human operators. Research has been done during previous years to promote and improve the collaboration between humans and robots, trying to address topics such as safety, awareness and cognitive support in form of Augmented Reality based instructions. Results of previous research show bottlenecks related to the way of interaction of the operators with such supportive systems though. Direct interaction approach with the use of push buttons or indirect-gesture based interaction, which are most often adopted by the researchers, require operators to constantly occupy their hands performing the relevant button presses or gestures. Moreover, previous approaches are hardware dependent and need a lot of customization to work with different hardware. This work tries to address these bottlenecks proposing the usage of wearable devices enhanced with AI in order to support the interaction of human operators with robots in human-robot collaborative environments in a seamless and non-intrusive way, wrapped around a framework called “Operator Support Module” (OSM). Among others, OSM supports a variety of hardware to easily fit in various industrial scenarios. Two case studies will be presented to demonstrate the approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.11.049,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Near Sensors Computation based on Embedded Machine Learning for Electronic Skin,https://api.elsevier.com/content/abstract/scopus_id/85100744258,"The electronic skin system is usually made of distributed tactile sensors integrated with an embedded electronic system for tactile data decoding. Meaningful information e.g. texture classification and pattern recognition can be decoded from tactile data by employing machine learning methods. Near sensors computation using embedded machine learning algorithms may enable the electronic skin system to be used in various application domains such as wearable Internet of Things devices, prosthetics, and robotics. However, embedding machine-learning algorithms is constrained by the high computational complexity of Machine Learning methods. This poses relevant challenges on 1) real-time operation and 2) very low (e.g. pJ/op) power/energy consumption due to the limited energy budget available on wearable/portable systems. In this perspective, the paper presents our recent achievements in the implementation of embedded machine learning methods for near sensors tactile data processing. The paper provides an overview about the implementation on dedicated hardware platforms. Finally, efficient techniques for embedded machine learning highlighting the challenges and perspectives are discussed with major emphasis on energy-efficient intelligent electronic skin systems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.05.140,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Development of real-time diagnosis framework for angular misalignment of robot spot-welding system based on machine learning,https://api.elsevier.com/content/abstract/scopus_id/85095131276,"This paper focuses on the real-time online monitoring and diagnosis framework for the angular misalignment of the robot spot-welding system, which can result in significant quality degradation of a weld nugget such as porosity. The data-driven approach is applied by installing the voltage and current sensors, collecting the associated mass data and processing them under normal and abnormal (angular misalignment) conditions. Two categories of features are extracted from the dynamic resistance (DR) and the voltage and current ones that are decomposed by wavelet transform (WT). The DR features are extracted from the DR profile and some critical features are selected by a t-test methodology. In the case of the WT-based features, the critical ones are selected by a max-relevance and min-redundancy (mRMR) and a sequential backward selection (SBS) wrapper. Consequently, three types of critical feature sets, such as DR features, WT features, and hybrid features combining those, are prepared to train machine learning-based models. Support vector machine (SVM) and probabilistic neural network (PNN) are applied to establish the diagnosis models, and the diagnostic accuracy and robustness are evaluated. Finally, the software for the on-line monitoring and diagnosis for angular misalignment of robot spot-welding system is developed and demonstrates its real-time applicability in an industrial site.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.09.269,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,"Alexa, What classes do I have today? The use of artificial intelligence via smart speakers in education",https://api.elsevier.com/content/abstract/scopus_id/85093364102,"Looking back to the rumours from the early 2000’s, when the world of technology bloomed together with the curiosity towards what was next to come, by 2020, robots should have assisted and supported almost every task from our daily life. While this may seem as a Sci-Fi movie scenario, it is partially a tangible reality, that we quickly got used to, thanks to the introduction of smart speakers.
                  As the world changes, so does the future of our students. In this respects, the evolution of the technology comes up with specific environments for educational purpose. Building smart learning environments supported by e-learning platforms is an important area of research in education domain within our days. The evolution of these smart learning environments is justified by some events (Covid19) that force students to learn remotely.
                  The paper proposes a software application component using Alexa smart speaker, that integrates different services (Amazon Web Services, Microsoft Services) for a proper virtual environment platform, for both students and teachers. It addresses the main concerns of the current educational system, and provides a smart solution through the use of Artificial Intelligence based tools. The proposed approach not only achieves unifying data and knowledge-share mechanisms in a remotely mode, but it brings also a good learning experience, increasing the effectiveness and the efficiency of the learning process.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2020.04.135,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Application of Artificial Intelligence to an Electrical Rewinding Factory Shop,https://api.elsevier.com/content/abstract/scopus_id/85091693237,"The evolution of artificial intelligence (AI) and big data resulted in the full potential realization of technologies through convergence. Tremendous acceptance, adoption and implementation of the United Nations Sustainable Development Goals (SDG) Agenda 2030, has resulted in original equipment manufacturers (OEM) developing various designs of rotary machines in a bid to improve energy efficiency, with more improvements expected in the coming decade. An effective technique to manage energy efficiency in the smart grid is through integration of demand side management, inclusive of optimization of rewinding of an electric motor in a machine shop. This paper aims to conceptualize application of AI and augmented reality (AR) towards process visibility of remanufacturing rotary machine stators by robotic vision. SLT is the triangulation methodology used in laser scanning for 3D modelling, and instantaneous condition assessment of the core. A pre-defined robotic path is used towards identification of features for range image acquisition. Therefore, the potential of industry 4.0 in resuscitation of end-of-life products through service remanufacturers by RE in a rewinding shop are presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2019.11.222,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Design of a robotic walking stick with mobility assistance control technology (MAVI) for visually impaired people,https://api.elsevier.com/content/abstract/scopus_id/85088581669,"The investigation of the present research is a new mechatronic system for a robotic unicycle staff that thanks to a meticulous analysis of the new technologies applied to assistance of technological mobility of people with visual disability as an orthopedic walking stick or a walker. We proceed to contribute with the design of a stick-type mechatronic system coupled to a differential traction platform that facilitates the mobilization of people with motor deficiency by giving them an assistance system to support in the march. It was verified that the design supports the maximum weight established in the parameters of 14[kg] It was shown that the walking stick can be used with people up to a weight of 93[kg]. The performance of the load cells with an experimental work cycle by incorporating an application in Android so the user has a feeling of immersion and to provide the possibility of interacting with the device, being able to establish between the user and the robotic staff a bidirectional transfer in real time of information. The findings of the research, multi-axis load cells will be implemented in the future with a control was applying neural networks to minimize the displacement error.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.04.220,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Design and Fabrication of SHRALA: Social Humanoid Robot Based on Autonomous Learning Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85086626621,"This paper presents the preliminary research work in the Design, Fabrication of a Social Humanoid Robot based on Autonomous Learning Algorithm (SHRALA). Virtual Model of the humanoid robot was developed using Solidworks environment. This model is then fabricated using Creality Ender-3 3D printer. The electronic control circuit was designed and interfaced to computer using ATMEGA 2650 controller board, based on 8-bit AVR microcontroller. In order to easily and efficiently control the SHRALA a Graphical User Interface (GUI) was created using Unity3D editor, where a simple USB joystick was used to actuate the motions of the SHRALA in the virtual environment. The fabricated SHRALA was controlled in real time using a serial communication interface created between the GUI and Arduino Mega 2650 board. The humanoid robot was successfully controlled using the GUI environment and the preliminary results are satisfactory as it is performing the task as per the desired instructions. This research work is a part of the real time humanoid robot development project “SHRALA”, In near future autonomous learning algorithm will also be implemented in the robot and the same will be published as research article in a modular approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.softx.2020.100426,Journal,SoftwareX,scopus,2020-01-01,sciencedirect,Connecting the CoppeliaSim robotics simulator to virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85080071825,"The CoppeliaSim VR Toolbox provides a set of tools to experience CoppeliaSim robot simulation software in Virtual Reality and to return user interactions. Its primary focus is to create a platform that enables the fast prototyping and verification of robotic systems. Moreover, the generality of the toolbox ensures that it can be valuable in other contexts like robotics education, human–robot interaction or reinforcement learning. The software is designed to have a low entry threshold for moderately complex use cases, but can be extended to perform very complex visualizations for more experienced users.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2019.105108,Journal,Computers and Electronics in Agriculture,scopus,2020-01-01,sciencedirect,Fast implementation of real-time fruit detection in apple orchards using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85076234578,"To perform robust and efficient fruit detection in orchards is challenging since there are a number of variances in the working environments. Recently, deep-learning have shown a promising performance in many visual-guided agriculture applications. However, deep-learning based approaches requires labelling on training data, which is a labour-intensive and time-consuming task. In this study, a fast implementation framework of a deep-learning based fruit detector for apple harvesting is developed. The developed framework comprises an auto label generation module and a deep-learning-based fruit detector ‘LedNet’. The Label Generation algorithm utilises the multi-scale pyramid and clustering classifier to assist fast labelling of training data. LedNet adopts feature pyramid network and atrous spatial pyramid pooling to improve the detection performance of the model. A light-weight backbone is also developed and utilised to improve computational efficiency. From the experimental results, LedNet achieves 0.821 and 0.853 on recall and accuracy on apple detection in orchards, and its weights size and inference time are 7.4 M and 28 ms, respectively. The experimental results show that LedNet can perform real-time apple detection in orchards robustly and efficiently.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.06.066,Journal,Expert Systems with Applications,scopus,2019-12-15,sciencedirect,Double Q-PID algorithm for mobile robot control,https://api.elsevier.com/content/abstract/scopus_id/85068505390,"Many expert systems have been developed for self-adaptive PID controllers of mobile robots. However, the high computational requirements of the expert systems layers, developed for the tuning of the PID controllers, still require previous expert knowledge and high efficiency in algorithmic and software execution for real-time applications. To address these problems, in this paper we propose an expert agent-based system, based on a reinforcement learning agent, for self-adapting multiple low-level PID controllers in mobile robots. For the formulation of the artificial expert agent, we develop an incremental model-free algorithm version of the double Q-Learning algorithm for fast on-line adaptation of multiple low-level PID controllers. Fast learning and high on-line adaptability of the artificial expert agent is achieved by means of a proposed incremental active-learning exploration-exploitation procedure, for a non-uniform state space exploration, along with an experience replay mechanism for multiple value functions updates in the double Q-learning algorithm. A comprehensive comparative simulation study and experiments in a real mobile robot demonstrate the high performance of the proposed algorithm for a real-time simultaneous tuning of multiple adaptive low-level PID controllers of mobile robots in real world conditions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2019.05.008,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2019-12-01,sciencedirect,A real-time human-robot interaction framework with robust background invariant hand gesture detection,https://api.elsevier.com/content/abstract/scopus_id/85066259834,"In the light of factories of the future, to ensure productive and safe interaction between robot and human coworkers, it is imperative that the robot extracts the essential information of the coworker. We address this by designing a reliable framework for real-time safe human-robot collaboration, using static hand gestures and 3D skeleton extraction. OpenPose library is integrated with Microsoft Kinect V2, to obtain a 3D estimation of the human skeleton. With the help of 10 volunteers, we recorded an image dataset of alpha-numeric static hand gestures, taken from the American Sign Language. We named our dataset OpenSign and released it to the community for benchmarking. Inception V3 convolutional neural network is adapted and trained to detect the hand gestures. To augment the data for training the hand gesture detector, we use OpenPose to localize the hands in the dataset images and segment the backgrounds of hand images, by exploiting the Kinect V2 depth map. Then, the backgrounds are substituted with random patterns and indoor architecture templates. Fine-tuning of Inception V3 is performed in three phases, to achieve validation accuracy of 99.1% and test accuracy of 98.9%. An asynchronous integration of image acquisition and hand gesture detection is performed to ensure real-time detection of hand gestures. Finally, the proposed framework is integrated in our physical human-robot interaction library OpenPHRI. This integration complements OpenPHRI by providing successful implementation of the ISO/TS 15066 safety standards for “safety rated monitored stop” and “speed and separation monitoring” collaborative modes. We validate the performance of the proposed framework through a complete teaching by demonstration experiment with a robotic manipulator.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patrec.2018.04.009,Journal,Pattern Recognition Letters,scopus,2019-12-01,sciencedirect,A real-time and unsupervised face re-identification system for human-robot interaction,https://api.elsevier.com/content/abstract/scopus_id/85046146958,"In the context of Human-Robot Interaction (HRI), face Re-Identification (face Re-ID) aims to verify if certain detected faces have already been observed by robots. The ability of distinguishing between different users is crucial in social robots as it will enable the robot to tailor the interaction strategy toward the users’ individual preferences. So far face recognition research has achieved great success, however little attention has been paid to the realistic applications of Face Re-ID in social robots. In this paper, we present an effective and unsupervised face Re-ID system which simultaneously re-identifies multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural Networks to extract features, and an online clustering algorithm to determine the face's ID. Its performance is evaluated on two datasets: the TERESA video dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF Dataset). We demonstrate that the optimised combination of techniques achieves an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on YTF dataset. We have implemented the proposed method into a software module in the HCI^2 Framework [1] for it to be further integrated into the TERESA robot [2], and has achieved real-time performance at 10–26 Frames per second.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.05.035,Journal,Expert Systems with Applications,scopus,2019-11-15,sciencedirect,Social mimic optimization algorithm and engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85066806914,"Increase in complexity of real world problems has provided an area to explore efficient methods to solve computer science problems. Meta-heuristic methods based on evolutionary computations and swarm intelligence are instances of techniques inspired by nature. This paper presents a novel social mimic optimization (SMO) algorithm inspired by mimicking behavior to solve optimization problems. The proposed algorithm is evaluated using 23 test functions. Obtained results are compared with 14 known optimization algorithms including Whale optimization algorithm (WOA), Grasshopper optimization algorithm (GOA), Particle Swarm Optimization (PSO), Stochastic fractal search (SFS), Grey Wolf Optimizer (GWO), Optics Inspired Optimization (OIO), League Championship Algorithm (LCA), Wind Driven Optimization (WDO), Harmony search (HS), Firefly Algorithm (FA), Artificial Bee Colony (ABC), Biogeography Based Optimization (BBO), Bat Algorithm (BA), and Teaching Learning Based Optimization (TLBO). Obtained results indicate higher capability of the SMO algorithm in solving high-dimensional decision variables. Furthermore, SMO is used to solve two classic engineering design problems. Three important features of SMO are simple implementation, solving optimization problems with minimum population size and not requiring control parameters. Results of various evaluations show superiority of the proposed method in finding the optimal solution with minimum function evaluations. This superiority is achieved based on reducing number of initial population. The proposed method can be applied to applications like automatic evolution of robotics, automatic control of machines and innovation of machines in finding better solutions with less cost.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ress.2019.106555,Journal,Reliability Engineering and System Safety,scopus,2019-11-01,sciencedirect,A cognitive architecture safety design for safety critical systems,https://api.elsevier.com/content/abstract/scopus_id/85068360978,"This research is presented as a safety analysis of a cognitive architecture with an intelligent decision support model (IDSM) that is embedded into an autonomous non-deterministic safety-critical system.
                  Cognitive technology is currently simulated within safety-critical systems in order to highlight variables of interest, interface with intelligent technologies, and provide an environment that improves the system's cognitive performance. In this research, the safety of the architecture was analyzed on an actual safety-critical system, an unmanned surface vehicle (USV). The safety analysis was conducted in both a simulated and a real world nautical based environment. The objective was to define the safety design of a cognitive architecture. The input to the safety design was provided through an approach that identified and mitigated hazards associated with a USV controlled by a cognitive architecture. This analysis provided a structured, task-oriented approach for the dissemination of information concerning safety requirements. This approach was necessary to achieve a safe execution of the USV's capabilities through a design that reduces the potential for injury to personnel and damage to equipment.
                  Other real time applications that would benefit from advancing the safety of cognitive technologies are unmanned platforms, transportation technologies, and service robotics. The results will provide cognitive science researchers with a reference for safety engineering of artificially intelligent safety-critical systems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2019.104973,Journal,Computers and Electronics in Agriculture,scopus,2019-10-01,sciencedirect,Deep learning-based visual recognition of rumex for robotic precision farming,https://api.elsevier.com/content/abstract/scopus_id/85071398904,"In this paper we address the problem of recognising the Broad-leaved dock (Rumex obtusifolius L.) in grasslands from high-resolution 2D images. We discuss and present the determining factors for developing and implementing weed visual recognition algorithms using deep learning. This analysis, leads to the formulation of the proposed algorithm. Our implementation exploits Transfer Learning techniques for deep learning-based feature extraction, in combination with a classifier for weed recognition. A prototype robotic platform has been used to make available an image dataset from a dairy farm containing broad-leaved docks. The evaluation of the proposed algorithm on this dataset shows that it outperforms competing weed/plant recognition methods in recognition accuracy, while producing low false-positive rates under real-world operation conditions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cola.2019.100908,Journal,Journal of Computer Languages,scopus,2019-10-01,sciencedirect,ML-LUM: A system for land use mapping by machine learning algorithms,https://api.elsevier.com/content/abstract/scopus_id/85071144277,"The land use mapping refers to mapping and assessing changes and patterns of land use. The use of agricultural land maps becomes increasingly important. The governments, private sectors, research agencies, and community groups rely on land use mapping data for natural resource assessment, monitoring, and planning. Finding an effective mapping approach is thereby crucial for natural resource condition monitoring and investment, agricultural productivity, sustainability and planning, biodiversity conservation, natural disaster management, and bio-security.
                  In this paper, four machine learning algorithms, i.e., the classic k-Nearest Neighbour (kNN), Support Vector Machines (SVMs), Convolutional Neural Network (CNN), and newly developed Capsule Network (CapsNet), are applied to classify satellite images for land use. For comprehensively comparing the performance of different algorithms for land use mapping, the experiments have been conducted on real-world datasets. Based on the experiment results, several improvements on the algorithms are proposed in order to fulfil the requirement of a large-scale land mapping. In addition, we design and implement these algorithms for land use mapping in a Machine Learning Land Use Mapping (ML-LUM) system. The system is able to train the models, predict classifications of satellite images, map the land use, display the land use statistic data, and predict production yields. With a friendly graphic user interface for farmers, the system is implemented by using the cloud computing technique for processing large land use data. Furthermore, we present a case study. For the case study, a banana plantation area from a given satellite image is correctly marked and the area size is then calculated, together with predicting banana production.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2019.07.014,Journal,Robotics and Autonomous Systems,scopus,2019-10-01,sciencedirect,A neuromorphic control architecture for a biped robot,https://api.elsevier.com/content/abstract/scopus_id/85069895693,"A neuromorphic control architecture is introduced to govern the motion of a lightweight humanoid robot. The reference trajectories necessary to perform stable gaits are generated by neural modules represented by Chaotic Recurrent Neural Networks CRNN organized in a hierarchical fashion. In the higher layer a body-coordination module generates the trajectories for the central parts of the robot body, in the middle layer the limb-coordination modules generate the Cartesian trajectories for the end effector of each limb, finally in the lower layer the limb modules control the position of the robot joints. Each neural module consists of a reservoir of 
                        
                           N
                           =
                           200
                        
                      leaky-integrator neurons randomly and sparsely connected with fixed synapses. The adaptation occurs in the synapses of readout units by online learning techniques like the delta rule and the Recursive Least Square algorithm RLS. It is demonstrated that the neural modules can learn and reproduce with enough accuracy the trajectories acquired from the simulation of a humanoid robot in V-REP software. With an optimal initialization of the reservoir connection matrix and by using a low computationally expensive learning algorithm such as the delta rule, 
                        
                           Θ
                           
                              (
                              N
                              )
                           
                        
                     , the average of MSE over all lower limbs joints is in the order of 0.1. For the lower-limbs-coordination-module the MSE drops to 0.004 by using the more computational expensive RLS, 
                        
                           Θ
                           
                              (
                              
                                 
                                    N
                                 
                                 
                                    2
                                 
                              
                              )
                           
                        
                     . In case the neural module needs to learn how to adapt the trajectories according to a specific step length and frequency the MSE is 0.06. A comparison between different learning algorithms applied on the CRNN showed better performances by using RLS. This result is confirmed also by a direct comparison with a different neural architecture, the PCPG, however at the expense of a bigger computational complexity. A real test conducted on a small computational unit (Raspberry Pi2) demonstrated that the CRNN can be executed at a frequency of 142 Hz which suffices to feed a PID feedback control loop at the joint level.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2019.105628,Journal,Applied Soft Computing Journal,scopus,2019-10-01,sciencedirect,A real-time decentralized algorithm for task scheduling in multi-agent system with continuous damage,https://api.elsevier.com/content/abstract/scopus_id/85069715361,"In this paper, a common model of task scheduling problems in agent rescue scenario is proposed, in which tasks with continuous dynamic damage are introduced to capture the emerging applications of using rescue robots and other resources to enhance human disaster rescue capability. Beyond this, we mainly focus on finding the optimal task scheduling strategy. We design a heuristic algorithm based on greedy strategy to obtain the optimal dynamic scheduling strategy of agents. Compared with solving global integer programming directly, the computational time is greatly reduced. The proof of the greedy strategy’s validity is also demonstrated under some specific damage functions. By comparing with the two strategies commonly used in real life, it is proved that our strategy is optimal. For practical application, we design an automatic negotiation framework, which realizes the real-time decentralized automated negotiation of agents. Then, using Game Description Language (GDL) as a tool, an automated negotiation algorithm is implemented, which enables agents to adjust the plan dispersedly. Experiments show that the algorithm is more efficient than the centralized algorithm in the case of limited communication.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.05.064,Journal,Neurocomputing,scopus,2019-09-17,sciencedirect,Improving novelty detection with generative adversarial networks on hand gesture data,https://api.elsevier.com/content/abstract/scopus_id/85066314268,"We propose a novel way of solving the issue of classification of out-of-vocabulary gestures using Artificial Neural Networks (ANNs) trained in the Generative Adversarial Network (GAN) framework. A generative model augments the data set in an online fashion with new samples and stochastic target vectors, while a discriminative model determines the class of the samples. The approach was evaluated on the UC2017 SG and UC2018 DualMyo data sets. The generative models’ performance was measured with a distance metric between generated and real samples. The discriminative models were evaluated by their accuracy on trained and novel classes. In terms of sample generation quality, the GAN is significantly better than a random distribution (noise) in mean distance, for all classes. In the classification tests, the baseline neural network was not capable of identifying untrained gestures. When the proposed methodology was implemented, we found that there is a trade-off between the detection of trained and untrained gestures, with some trained samples being mistaken as novelty. Nevertheless, a novelty detection accuracy of 95.4% or 90.2% (depending on the data set) was achieved with just 5% loss of accuracy on trained classes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dsx.2018.07.014,Journal,Diabetes and Metabolic Syndrome: Clinical Research and Reviews,scopus,2019-09-01,sciencedirect,Prevalence of metabolic syndrome in Iranian patients with schizophrenia: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85050864479,"Industry 4.0 is an updated concept of smart production, which is identified with the fourth industrial revolution and the emergence of cyber-physical systems. Industry 4.0 is the next stage in the digitization of productions and industries, where such technologies and concepts as the Internet of things, big data, predictive analytics, cloud computing, machine learning, machine interaction, artificial intelligence, robotics, 3D printing, augmented reality.
                  As an area of therapy with the best market potential and one of the most expensive global diseases, diabetes attracts the best healthcare players, who use innovative technologies.
                  Current trends in digitalization of diabetes management are presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.04.037,Journal,Neurocomputing,scopus,2019-08-04,sciencedirect,LEGION-based image segmentation by means of spiking neural networks using normalized synaptic weights implemented on a compact scalable neuromorphic architecture,https://api.elsevier.com/content/abstract/scopus_id/85065418438,"LEGION (Locally Excitatory, Globally Inhibitory Oscillator Network) topology has demonstrated good capabilities in scene segmentation applications. However, the implementation of LEGION algorithm requires machines with high performance to process a set of complex differential equations limiting its use in practical real-time applications. Recently, several authors have proposed alternative methods based on spiking neural networks (SNN) to create oscillatory neural networks with low computational complexity and highly feasible to be implemented on digital hardware to perform adaptive segmentation of images. Nevertheless, existing SNN with LEGION configuration focus on the membrane model leaving aside the behavior of the synapses although they play an important role in the synchronization of several segments by self-adapting their weights. In this work, we propose a SNN-LEGION configuration along with normalized weight of the synapses to self-adapt the SNN network to synchronize several segments of any size and shape at the same time. The proposed SNN-LEGION method involves a global inhibitor, which is in charge of performing the segmentation process between different objects with different sizes and shapes on time. To validate the proposal, the SNN-LEGION method is implemented on an optimized scalable neuromorphic architecture. Our preliminary results demonstrate that the proposed normalization process of the synaptic weights along with the SNN-LEGION configuration keep the capacity of the LEGION network to separate the segments on time, which can be useful in video processing applications such as vision processing systems for mobile robots, offering lower computational complexity and area consumption compared with previously reported solutions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compind.2019.05.001,Journal,Computers in Industry,scopus,2019-08-01,sciencedirect,Industrial robot control and operator training using virtual reality interfaces,https://api.elsevier.com/content/abstract/scopus_id/85065132267,"Nowadays, we are involved in the fourth industrial revolution, commonly referred to as “Industry 4.0,” where cyber-physical systems and intelligent automation, including robotics, are the keys. Traditionally, the use of robots has been limited by safety and, in addition, some manufacturing tasks are too complex to be fully automated. Thus, human-robot collaborative applications, where robots are not isolated, are necessary in order to increase the productivity ensuring the safety of the operators with new perception systems for the robot and new interaction interfaces for the human. Moreover, virtual reality has been extended to the industry in the last years, but most of its applications are not related to robots. In this context, this paper works on the synergies between virtual reality and robotics, presenting the use of commercial gaming technologies to create a totally immersive environment based on virtual reality. This environment includes an interface connected to the robot controller, where the necessary mathematical models have been implemented for the control of the virtual robot. The proposed system can be used for training, simulation, and what is more innovative, for robot controlling in an integrated, non-expensive and unique application. Results show that the immersive experience increments the efficiency of the training and simulation processes, offering a cost-effective solution.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2019.01.003,Journal,Cognitive Systems Research,scopus,2019-06-01,sciencedirect,The CORTEX cognitive robotics architecture: Use cases,https://api.elsevier.com/content/abstract/scopus_id/85060622773,"CORTEX is a cognitive robotics architecture inspired by three key ideas: modularity, internal modelling and graph representations. CORTEX is also a computational framework designed to support early forms of intelligence in real world, human interacting robots, by selecting an a priori functional decomposition of the capabilities of the robot. This set of abilities was then translated to computational modules or agents, each one built as a network of software interconnected components. The nature of these agents can range from pure reactive modules connected to sensors and/or actuators, to pure deliberative ones, but they can only communicate with each other through a graph structure called Deep State Representation (DSR). DSR is a short-term dynamic representation of the space surrounding the robot, the objects and the humans in it, and the robot itself. All these entities are perceived and transformed into different levels of abstraction, ranging from geometric data to high-level symbolic relations such as “the person is talking and gazing at me”. The combination of symbolic and geometric information endows the architecture with the potential to simulate and anticipate the outcome of the actions executed by the robot. In this paper we present recent advances in the CORTEX architecture and several real-world human-robot interaction scenarios in which they have been tested. We describe our interpretation of the ideas inspiring the architecture and the reasons why this specific computational framework is a promising architecture for the social robots of tomorrow.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2018.12.014,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2019-06-01,sciencedirect,Novel decoupling algorithm based on parallel voltage extreme learning machine (PV-ELM) for six-axis F/M sensors,https://api.elsevier.com/content/abstract/scopus_id/85059099701,"Accurate, time-effective calibration and decoupling procedures of multi-axis Force/Moment (F/M) sensors are critical to the implementation of these sensors. Recently, many decoupling methods have been proposed by researchers, but the inherent coupling relationship among components of multi-axis F/M sensors has not been taken into account. In this paper, we thus proposed a novel Sparse Voltage Maximum Inter-class Variance (SVMIV) algorithm, which took advantage of the inherent relationship nature. Furthermore, a novel nonlinear decoupling method based on the Parallel Voltage-Extreme Learning Machine (PV-ELM) was also presented. To demonstrate the utility of the proposed approach, extensive comparisons were made between the proposed PV-ELM decoupling method and several conventional decoupling approaches such as Least Square (LS), Support Vector Regression (SVR), Back Propagation Neural Network (BPNN), and Extreme Learning Machine (ELM). Results of real decoupling experiments demonstrated that the proposed the PV-ELM decoupling algorithm outperforms linear decoupling algorithms for six-axis F/M sensors. In addition, it was also proved that the PV-ELM decoupling method can decouple the outputs of six-axis F/M sensors with higher precision, faster speed, improved robustness, and faster convergence than the state-of-the-art nonlinear decoupling algorithms such as SVR, BP and ELM. Overall, this paper proposed a novel way to deal with the inherent coupling relationship of six-axis F/M sensors, and the experimental results demonstrated that the maximum I-type and II-type errors were below 0.356% and 0.270%, respectively, of full scale in all measured variables.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.amsu.2019.04.001,Journal,Annals of Medicine and Surgery,scopus,2019-05-01,sciencedirect,"Artificial intelligence, regenerative surgery, robotics? What is realistic for the future of surgery?",https://api.elsevier.com/content/abstract/scopus_id/85064430299,"The potential of surgery lies in the technological advances that would complement it. The landscape of the field will differ depending on the time period being looked at and would no doubt include conjecture. Initial breakthroughs will need to pave the way for future medical technology and apply to the surgical sciences. Within the next 10 years we would expect to see the emergence of big data analysis, cuttingedge image processing techniques for surgical planning and better implementation of virtual and augmented reality in operating theatres for both patient care and teaching purposes. Over the next 50 to 100 years, the use of quantum computing should lead to increased automation in our healthcare systems. The inception of novel biomaterial invention and advanced genetic engineering will usher in the new age of regenerative medicine in the clinical setting. The future of surgery includes many predictions and promises, but it is apparent that the development will lead to bettering outcome and focus on patient care.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2018.11.017,Journal,Robotics and Autonomous Systems,scopus,2019-05-01,sciencedirect,A real-time framework for kinodynamic planning in dynamic environments with application to quadrotor obstacle avoidance,https://api.elsevier.com/content/abstract/scopus_id/85062619374,"The objective of this paper is to present a full-stack, real-time motion planning framework for kinodynamic robots and then show how it is applied and demonstrated on a physical quadrotor system operating in a laboratory environment. The proposed framework utilizes an offline–online computation paradigm, neighborhood classification through machine learning, sampling-based motion planning with an optimal cost distance metric, and trajectory smoothing to achieve real-time planning for aerial vehicles. This framework accounts for dynamic obstacles with an event-based replanning structure and a locally reactive control layer that minimizes replanning events. The approach is demonstrated on a quadrotor navigating moving obstacles in an indoor space and stands as, arguably, one of the first demonstrations of full-online kinodynamic motion planning, with execution cycles of 3 Hz to 5 Hz. For the quadrotor, a simplified dynamics model is used during the planning phase to accelerate online computation. A trajectory smoothing phase, which leverages the differentially flat nature of quadrotor dynamics, is then implemented to guarantee a dynamically feasible trajectory.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.encep.2018.08.002,Journal,Encephale,scopus,2019-04-01,sciencedirect,Toward a motor signature in autism: Studies from human-machine interaction,https://api.elsevier.com/content/abstract/scopus_id/85057386595,"Background
                  Autism spectrum disorder (ASD) is a heterogeneous group of neurodevelopmental disorders which core symptoms are impairments in socio-communication and repetitive symptoms and stereotypies. Although not cardinal symptoms per se, motor impairments are fundamental aspects of ASD. These impairments are associated with postural and motor control disabilities that we investigated using computational modeling and developmental robotics through human-machine interaction paradigms.
               
                  Method
                  First, in a set of studies involving a human–robot posture imitation, we explored the impact of 3 different groups of partners (including a group of children with ASD) on robot learning by imitation. Second, using an ecological task, i.e. a real-time motor imitation with a tightrope walker (TW) avatar, we investigated interpersonal synchronization, motor coordination and motor control during the task in children with ASD (n
                     =29), TD children (n
                     =39) and children with developmental coordination disorder (n
                     =17, DCD).
               
                  Results
                  From the human–robot experiments, we evidenced that motor signature at both groups’ and individuals’ levels had a key influence on imitation learning, posture recognition and identity recognition. From the more dynamic motor imitation paradigm with a TW avatar, we found that interpersonal synchronization, motor coordination and motor control were more impaired in children with ASD compared to both TD children and children with DCD. Taken together these results confirm the motor peculiarities of children with ASD despite imitation tasks were adequately performed.
               
                  Discussion
                  Studies from human-machine interaction support the idea of a behavioral signature in children with ASD. However, several issues need to be addressed. Is this behavioral signature motoric in essence? Is it possible to ascertain that these peculiarities occur during all motor tasks (e.g. posture, voluntary movement)? Could this motor signature be considered as specific to autism, notably in comparison to DCD that also display poor motor coordination skills? We suggest that more work comparing the two conditions should be implemented, including analysis of kinematics and movement smoothness with sufficient measurement quality to allow spectral analysis.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2018.11.006,Journal,Robotics and Autonomous Systems,scopus,2019-02-01,sciencedirect,An improved scheme for eliminating the coupled motion of surgical instruments used in laparoscopic surgical robots,https://api.elsevier.com/content/abstract/scopus_id/85056947027,"Considering the nonlinear characteristics such as backlash hysteresis and coupled motion commonly exist in cable-driven mechanism of laparoscopic surgical robot end-effector, it is a great challenge to control the motion of robotic end-effector precisely during the surgical procedure. Due to the effects of coupled motion, the surgical end-effector will not move accurately as surgeons expected. Previous studies mostly focused on the design of special compensation mechanisms and software compensation algorithms to solve coupled motion problem. However, these approaches are limited because the backlash hysteresis is ignored and the mechanism of end-effector is restricted. This paper shows an improved scheme to eliminate the coupled motion of end-effector and reduce the position tracking error. The proposed decoupling scheme is conducted in three stages. Firstly, the time and frequency domain information of the driving motor current and the motion information of surgical instrument are extracted in real-time. Thereafter, a feedforward neural network is designed to identify the movement stage of end-effector. Finally, a prediction model is designed to predict the coupling error, after that the coupling error can be eliminated by using feedforward compensation control. An experimental platform was set up to verify the effectiveness of the proposed control scheme, and the results of corresponding comparative experiments revealed that the proposed strategy can substantially improve the tracking accuracy.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2018.10.015,Journal,Robotics and Autonomous Systems,scopus,2019-02-01,sciencedirect,Time-dependent genetic algorithm and its application to quadruped's locomotion,https://api.elsevier.com/content/abstract/scopus_id/85056925953,"Genetic algorithms (GAs) are widely used in machine learning and optimization. This paper proposes a time-dependent genetic algorithm (TDGA) based on real-coded genetic algorithm (RCGA) to improve the convergence performance of functions over time such as a foot trajectory. TDGA has several distinguishing features when compared with traditional RCGA. First, individuals are arranged over time, and then the individuals are optimized in sequence. Second, search spaces of design variables are newly comprised of processes of reductions for search spaces. Third, the search space for crossover operations is expanded to avoid local minima traps that can occur in new search spaces up to the previous search space before performing any reduction of search space, and boundary mutation operation is performed to the new search spaces. Computer simulations are implemented to verify the convergence performance of the robot locomotion optimized by TDGA. Then, TDGA optimizes the desired feet trajectories of quadruped robots that climb up a slope and the impedance parameters of admittance control so that quadruped robots can trot stably over irregular terrains. Simulation results clearly represent that the convergence performance is improved by TDGA, which also shows that TDGA could be broadly used in robot locomotion research.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.image.2018.09.013,Journal,Signal Processing: Image Communication,scopus,2019-02-01,sciencedirect,Object instance detection with pruned Alexnet and extended training data,https://api.elsevier.com/content/abstract/scopus_id/85054588872,"Object instance detection has garnered much concern in many practical applications, especially in the field of intelligent service robot. Imagine robots working in real scenes, one may expect the instance detection system to be light-weighted to enable mobile or embedded system deployment. Focusing on reconstructing a smaller learning network from a noted deep model,we have pruned Alexnet to a compressed model with fewer parameters but equivalent accuracy, denoted as BING-Pruned Alexnet(B-PA). Our method first utilizes BING(Binarized Normed Gradient) to compute bounding boxes, then builds a pruned network for recognition by reducing neurons and cutting fully connected layers on the classic architecture Alexnet. Since the training samples for instance detection are limited and of small variation, we extend the training data by combining data augmentation with synthetic generation. In the end, our B-PA network occupies only 5MB, which is 50 times smaller than the original Alexnet, but can still achieve Alexnet-level accuracy when recognizing on GMU Kitchen dataset. Numerical experiments are conducted to compare our algorithm with the state-of-art instance detection algorithms on a self-made BHID database and two public database i.e.,WRGB-D dataset and GMU Kitchen dataset, which demonstrate that B-PA reduces the storage requirements of neural networks substantially while preserving generalization performance on object instance detection.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-819178-1.00035-6,Book,"Precision Medicine for Investigators, Practitioners and Providers",scopus,2019-01-01,sciencedirect,Precision medicine in ophthalmology: An evolving revolution in diagnostic and therapeutic tools,https://api.elsevier.com/content/abstract/scopus_id/85093483812,"Precision medicine refers to a stratification of patients using a wide array of individual-specific data to enable precise targeting of disease subgroups with the best available diagnostic and therapeutic approaches. Within ophthalmology, this strategy is being applied successfully and is most evident in the management of the inherited diseases. This paradigm shift in provision of care is accelerated by the emergence of novel imaging technologies, robotics, and artificial intelligence, as well as emerging technologies that integrate bioinformatics data into clinically relevant knowledge. This knowledge is used in turn to develop a system capable of supporting clinical decision-making and utilization of high-precision therapeutic options in both a personalized and cost-effective way. Examples of the diverse areas making rapid progress toward full implementation of precision medicine include, but are not limited to, ocular genetic diseases, robotic surgery, virtual reality simulations, modern imaging techniques, and the role of healthcare providers.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-815503-5.00008-5,Book,Infrastructure Computer Vision,scopus,2019-01-01,sciencedirect,The future,https://api.elsevier.com/content/abstract/scopus_id/85093476644,"This chapter discusses the future of Infrastructure Computer Vision (ICV). It starts first with an overview of how ICV progressed from the early 1980s up until 2019 and the types of issues addressed given the toolsets at our disposal. The section then continues with an exploration of the current trends in ICV. We attempt to group individual efforts together into trends and provide some context on what enables them, what they make possible, and what the future of those trends might be. We eventually focus on deep learning, consumer-grade ICV applications offered by start-ups, advances in software and hardware development, the new wave of robotics, advances in multi-spectral imaging, and a general note about the cycle of trends using mixed reality as an example. The section then discusses a set of predictions on what might the future look like 10 years from now, and what drivers might facilitate or hinder the realization of those predictions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/C2018-0-01886-1,Book,Multi-robot Exploration for Environmental Monitoring: The Resource Constrained Perspective,scopus,2019-01-01,sciencedirect,Multi-robot exploration for environmental monitoring: The resource constrained perspective,https://api.elsevier.com/content/abstract/scopus_id/85089697302,Unknown,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-816176-0.00045-4,Book,Handbook of Medical Image Computing and Computer Assisted Intervention,scopus,2019-01-01,sciencedirect,Challenges in computer assisted interventions,https://api.elsevier.com/content/abstract/scopus_id/85082596227,"Challenges in design, implementation, clinical evaluation, and deployment of computer assisted intervention solutions are manifold. Some of these challenges will be discussed in this chapter.
               Computer assistance in both surgical procedures and radiology interventions aim at augmenting the clinicians with the overall objective of providing better clinical outcome. Multimodal imaging, robotics, artificial intelligence, and augmented reality play a major role in computer assisted interventions. After a brief analysis of the state-of-the-art and practice in this field, we discuss the challenges in design and development, as well as translation and deployment of the technology, from research projects motivated by clinical needs to solutions routinely used within clinical setups. We also consider the required training of surgeons and the surgical team as a major component for smooth and successful translation. We present simulation as an important tool not only for the design and development of computer assisted intervention solutions but also in their fast and smooth translation into daily practice.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2019.12.501,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,A Study on the Detection of Visible Parts of Cordons Using Deep Learning Networks for Automated Green Shoot Thinning in Vineyards,https://api.elsevier.com/content/abstract/scopus_id/85081061819,"Green shoot thinning operation in vineyards helps to reduce the crop load in favor of optimal quality wines. Mechanical green shoot thinning exists, but it causes cluster removal efficiencies to vary widely between 10-85 % because of difficulty in controlling the thinning end-effector position precisely to cordon trajectories. Automatically positioning the thinning end-effector to cordon trajectories will help to precisely remove the green shoots and to increase the efficiency and performance of the mechanical green shoot thinning operation. However, heavy occlusion of cordons due to shoots/leaves during thinning season makes it challenging to accurately determine the trajectories of cordons. Successfully detecting the visible parts of the cordons during the thinning season will help to estimate the trajectories of cordons for automated/robotics operation. In this study, a total of 390 wine grape vines were selected, and color images of these wine grapes were captured from a fixed distance and height for three weeks during the thinning season in real-time field conditions. Faster R-CNN (Faster regions-convolutional neural network) was deployed through transfer learning and fine tuning using the pre-trained networks (AlexNet, VGG16, VGG19 and ResNet18) to detect the visible parts of the cordons. Results showed that, Faster-RCNN model trained with ResNet18 networks provides higher accuracy in detecting visible parts of cordons compared to other tested networks with faster detection speed. Moreover, the detection accuracy with week 2 dataset was higher compared to that with week 3 and week 4 datasets because of the higher visibility of cordons. These results show the potential of Faster-RCNN model in detecting the visible parts of cordons, which will be used in the future to estimate the trajectories of the cordons for the automated green shoot thinning operation in vineyards.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2019.12.529,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,Autonomous Canal Following by a Micro-Aerial Vehicle Using Deep CNN,https://api.elsevier.com/content/abstract/scopus_id/85081052924,"Globally, large-scale irrigation canal networks serve as the backbone of agriculture in many important river basins. However, these water channels are in a constant threat of erosion, silt accumulation and structural damages over time which significantly reduces the water carrying capacity. Therefore, periodic inspections of the canals are required for critical operations and maintenance tasks. Due to the vast lengths of the channels and time-critical operations, automation has become a necessity. In this paper, we have proposed an aerial autonomous canal traversal system using ResNet50 inspired deep convolutional neural network. Given the uniqueness of our problem, we have generated our dataset for supervised learning and validation and later evaluated the proposed approach on a real canal. We have implemented our approach on a COTS micro-aerial vehicle. We have designed our system in such a way that it takes 200ms from perception to action thereby making the system real-time. We compare the superior performance of our Res Net 50 inspired network with other state-of-the-art CNNs trained on canal datasets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-409547-2.00449-2,Book,Encyclopedia of Analytical Science,scopus,2019-01-01,sciencedirect,Quality assurance | laboratory information management systems,https://api.elsevier.com/content/abstract/scopus_id/85079080236,"In today’s competitive laboratory environment, managers are under increased pressure to deliver high quality data, quickly, and cost effectively, with limited resources. This can only be achieved via laboratory automation. It is more critical than ever to ensure that the modern laboratory is equipped with the latest software Laboratory Information Management Software (LIMS) and tools together with automation technology to ensure that they remain competitive. LIMS together with laboratory automation (positive ID, Robotics, AI, etc.) imparts many benefits that include time savings, resource maximization, efficiency, quality improvements, along with cost reductions. For all businesses that rely on delivering high quality, reliable products, regardless of industry, defects can be responsible for huge losses, from laboratory/company reputation to associated costs of recalls and possibly lawsuits. Compared to manual procedures, automated tasks offer significant benefits which include, reproducibility, increased accuracy, speed (high throughput), enhanced communication, increased responsiveness, automated and effective reporting that results in higher customer satisfaction. Today, LIMS can be delivered on-demand via the Software as a Service (SaaS) model for organizations that either do not have the infrastructure to host the software or who find it more cost effective to utilize the tools hosted in the cloud, eliminating the need for an IT resource. Organizations that employ best practices and implement LIMS have all of their laboratory operational data in a centralized, secure database greatly facilitating access to real-time data, KPIs, document control, quality management as well as regulatory compliance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2018.12.026,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Hybrid artificial intelligence system for the design of highly-automated production systems,https://api.elsevier.com/content/abstract/scopus_id/85072561400,"The automated design of production systems is a young field of research which has not been widely explored by industry nor research in recent decades. Currently, the effort spent in production system design is increasing significantly in automotive industry due to the number of product variants and product complexity. Intelligent methods can support engineers in repetitive tasks and give them more opportunity to focus on work which requires their core competencies. This paper presents a novel artificial intelligence methodology that automatically generates initial production system configurations based on real industrial scenarios in the automotive field of body-in-white production. The hybrid methodology reacts flexibly against data sets of different content and has been implemented in a software prototype.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2019.03.047,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,A Practical Approach of Teaching Digitalization and Safety Strategies in Cyber-Physical Production Systems,https://api.elsevier.com/content/abstract/scopus_id/85065658005,"Digitalization strategies in cyber-physical production systems (CPPS) are one of the key factors of Industry 4.0. The topic not only addresses data preparation, real-time data processing, big data analytics, visualization and machine interface design but also cyber security and safety. Especially, unauthorized access to protected (personal or enterprise) data or unauthorized control of production facilities imply risks when it comes to digitalization. Because of the increased complexity of state-of-the-art technologies, educational institutions need to provide practice-oriented teaching methods in learning factories to help engineers of today understand the impact of those developments.
                  In the light of this fact, this paper presents a practical approach of teaching digitalization strategies in CPPS. Planning, implementing and impacts of digitalization strategies are taught on a use-case with human-robot-collaboration. The objective of the use-case is to realize a real-time obstacle avoidance approach for a collaborative application based on a local positioning system. Here, students not only learn how to model the kinematics of a robot and program a robot but also how to design machine interfaces for real-time data transfer and processing as well as impacts of digitalization on safety and security.
                  The implementation of the use-case is part of the TU Wien teaching portfolio and thus part of its learning factory, where students and apprentices have the possibility to experiment and gain experiences by deliberate error simulations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cirpj.2018.12.002,Journal,CIRP Journal of Manufacturing Science and Technology,scopus,2019-01-01,sciencedirect,"From factory floor to process models: A data gathering approach to generate, transform, and visualize manufacturing processes",https://api.elsevier.com/content/abstract/scopus_id/85058703955,"The need for tools to help guide decision making is growing within the manufacturing industry. The analysis performed by these tools will help operators and engineers to understand the behaviour of the manufacturing stations better and thereby take data-driven decisions to improve them. The tools use techniques borrowed from fields such as Data Analytics, BigData, Predictive Modelling, and Machine Learning. However, to be able to use these tools efficiently, data from the factory floor is required as input. This data needs to be extracted from two sources, the PLCs, and the robots. In practice, methods to extract usable data from robots are rather scarce. The present work describes an approach to capture data from robots, which can be applied to both legacy and current state-of-the-art manufacturing systems. The described approach is developed using Sequence Planner – a tool for modelling and analyzing production systems – and is currently implemented at an automotive company as a pilot project to visualize and examine the ongoing process. By exploiting the robot code structure, robot actions are converted to event streams that are abstracted into operations. We then demonstrate the applicability of the resulting operations, by visualizing the ongoing process in real-time as Gantt charts, that support the operators performing maintenance. And, the data is also analyzed off-line using process mining techniques to create a general model that describes the underlying behaviour existing in the manufacturing station. Such models are used to derive insights about relationships between different operations, and also between resources.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.infsof.2018.08.003,Journal,Information and Software Technology,scopus,2019-01-01,sciencedirect,An extensible framework for software configuration optimization on heterogeneous computing systems: Time and energy case study,https://api.elsevier.com/content/abstract/scopus_id/85051630181,"Context: Application of component based software engineering methods to heterogeneous computing (HC) enables different software configurations to realize the same function with different non–functional properties (NFP). Finding the best software configuration with respect to multiple NFPs is a non–trivial task.
                  
                     Objective: We propose a Software Component Allocation Framework (SCAF) with the goal to acquire a (sub–) optimal software configuration with respect to multiple NFPs, thus providing performance prediction of a software configuration in its early design phase. We focus on the software configuration optimization for the average energy consumption and average execution time.
                  
                     Method: We validated SCAF through its instantiation on a real–world demonstrator and a simulation. Firstly, we verified the correctness of our model through comparing the performance prediction of six software configurations to the actual performance, obtained through extensive measurements with a confidence interval of 95%. Secondly, to demonstrate how SCAF scales up, we performed software configuration optimization on 55 generated use–cases (with solution spaces ranging from 1030 to 3070) and benchmark the results against best performing random configurations.
                  
                     Results: The performance of a configuration as predicted by our framework matched the configuration implemented and measured on a real–world platform. Furthermore, by applying the genetic algorithm and simulated annealing to the weight function given in SCAF, we obtain sub–optimal software configurations differing in performance at most 7% and 13% from the optimal configuration (respectfully).
                  
                     Conclusion: SCAF is capable of correctly describing a HC platform and reliably predict the performance of software configuration in the early design phase. Automated in the form of an Eclipse plugin, SCAF allows software architects to model architectural constraints and preferences, acting as a multi–criterion software architecture decision support system. In addition to said, we also point out several interesting research directions, to further investigate and improve our approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2018.07.006,Journal,Neural Networks,scopus,2018-12-01,sciencedirect,State representation learning for control: An overview,https://api.elsevier.com/content/abstract/scopus_id/85053829041,"Representation learning algorithms are designed to learn abstract features that characterize data. State representation learning (SRL) focuses on a particular kind of representation learning where learned features are in low dimension, evolve through time, and are influenced by actions of an agent. The representation is learned to capture the variation in the environment generated by the agent’s actions; this kind of representation is particularly suitable for robotics and control scenarios. In particular, the low dimension characteristic of the representation helps to overcome the curse of dimensionality, provides easier interpretation and utilization by humans and can help improve performance and speed in policy learning algorithms such as reinforcement learning.
                  This survey aims at covering the state-of-the-art on state representation learning in the most recent years. It reviews different SRL methods that involve interaction with the environment, their implementations and their applications in robotics control tasks (simulated or real). In particular, it highlights how generic learning objectives are differently exploited in the reviewed algorithms. Finally, it discusses evaluation methods to assess the representation learned and summarizes current and future lines of research.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2018.08.011,Journal,Mechatronics,scopus,2018-11-01,sciencedirect,An interactive and intuitive control interface for a tele-operated robot (AVATAR) system,https://api.elsevier.com/content/abstract/scopus_id/85053070319,"Robotic systems, which are controlled by artificial intelligent or tele-operation control interfaces, have been developed to be deployed instead of the human in extreme environments. However, insufficient artificial intelligence performance in unknown and unpredictable environments, and non-intuitive control interfaces with low immersive feedback have prevented wide spread of such robotic systems. In this paper, an intuitive and interactive control interface with inertial measurement units (IMUs), haptic gloves and a head mounted display (HMD) was developed to control a tele-operated robot in remote environments, which was abbreviated as AVATAR system. The tele-operated robot can be operated by a user’s motions which are measured by the wearable interface. Through a kinematic analysis of the user and the tele-operated robot, desired robot joint angles are calculated to follow the user’s motions in real time. Also, dual cameras on the robot head provide 3D visual information around the robot to the user. A grasping force of the robot hands, measured by motor current, is transmitted to the user as vibration feedback to fingertips of the haptic gloves. A long term evolution (LTE) was used as wireless communication between the user and the robot. The performance of the proposed AVATAR system has been verified by experiments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechmachtheory.2018.06.019,Journal,Mechanism and Machine Theory,scopus,2018-11-01,sciencedirect,Grasp configuration planning for a low-cost and easy-operation underactuated three-fingered robot hand,https://api.elsevier.com/content/abstract/scopus_id/85050550185,"This paper proposes a method for modeling and planning the grasping configuration of a robotic hand with underactuated finger mechanisms. The proposed modeling algorithm is based on analysis and mimicking of human grasping experience. Results of the analysis is preprocessed and stored in a database. The grasp configuration planning algorithm can be used within a real time online grasp control as based on artificial neural networks. Namely, shapes and sizes of task objects are described by taxonomy data, which are used to generate grasp configurations. Then, a robot hand grasp control system is designed as based on the proposed grasp planning with close-loop position and force feedback. Simulations and experiments are carried out to show the basic features of the proposed formulation for identifying the grasp configurations while dealing with target objects of different shapes and sizes. It is hoped that the well-trained underactuated robot hand can solve most of grasping tasks in our life. The research approach is aimed to research low-cost easy-operation solution for feasible and practical implementation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2018.06.012,Journal,Safety Science,scopus,2018-11-01,sciencedirect,Occupational health and safety in the industry 4.0 era: A cause for major concern?,https://api.elsevier.com/content/abstract/scopus_id/85049323662,"Real-time communication, Big Data, human–machine cooperation, remote sensing, monitoring and process control, autonomous equipment and interconnectivity are becoming major assets in modern industry. As the fourth industrial revolution or Industry 4.0 becomes the predominant reality, it will bring new paradigm shifts, which will have an impact on the management of occupational health and safety (OHS).
                  In the midst of this new and accelerating industrial trend, are we giving due consideration to changes in OHS imperatives? Are the OHS consequences of Industry 4.0 being evaluated properly? Do we stand to lose any of the gains made through proactive approaches? Are there rational grounds for major concerns? In this article, we examine these questions in order to raise consciousness with regard to the integration of OHS into Industry4.0.
                  It is clear that if the technologies driving Industry 4.0 develop in silos and manufacturers’ initiatives are isolated and fragmented, the dangers will multiply and the net impact on OHS will be negative. As major changes are implemented, previous gains in preventive management of workplace health and safety will be at risk. If we are to avoid putting technological progress and OHS on a collision course, researchers, field experts and industrialists will have to collaborate on a smooth transition towards Industry 4.0.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.05.069,Journal,Neurocomputing,scopus,2018-10-15,sciencedirect,A real-time spike-timing classifier of spatio-temporal patterns,https://api.elsevier.com/content/abstract/scopus_id/85048119736,"Considering the problem of recognizing non-verbal cues in Human–Robot Interaction applications, this paper proposes a novel real-time unsupervised spike timing neural network for recognition and early detection of spatio-temporal human gestures. Two spiking network classifiers one based on Izhikevich neuron model, and the other one based on Integrate-and-Fire-or-Burst neuron model have been implemented in CUDA, and allow the classification to be performed in real-time. To evaluate the performance of this proposal, we test the case of a physical robot observing air-handwritings of human gesture. The proposed approaches run in real-time, thus they are suitable for human–robot applications; they allow real-time early classifying human gestures and actions while they require a very small number of training samples. In comparing to other prominent techniques, our approaches demonstrate superior accuracy and are suitable for early classification of different types of human actions in time-sensitive mobile applications such as robotics.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bica.2018.07.016,Journal,Biologically Inspired Cognitive Architectures,scopus,2018-08-01,sciencedirect,Knowledge acquisition through introspection in Human-Robot Cooperation,https://api.elsevier.com/content/abstract/scopus_id/85051216556,"When cooperating with a team including humans, robots have to understand and update semantic information concerning the state of the environment. The run-time evaluation and acquisition of new concepts fall in the critical mass learning. It is a cognitive skill that enables the robot to show environmental awareness to complete its tasks successfully. A kind of self-consciousness emerges: the robot activates the introspective mental processes inferring if it owns a domain concept or not, and correctly blends the conceptual meaning of new entities. Many works attempt to simulate human brain functions leading to neural network implementation of consciousness; regrettably, some of these produce accurate model that however do not provide means for creating virtual agents able to interact with a human in a teamwork in a human-like fashion, hence including aspects such as self-conscious abilities, trust, emotions and motivations. We propose a method that, based on a cognitive architecture for human-robot teaming interaction, endows a robot with the ability to model its knowledge about the environment it is interacting with and to acquire new knowledge when it occurs.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2018.04.002,Journal,Microprocessors and Microsystems,scopus,2018-07-01,sciencedirect,Modular design of a factor-graph-based inference engine on a System-On-Chip (SoC),https://api.elsevier.com/content/abstract/scopus_id/85045660948,"Factor graphs are probabilistic graphical frameworks for modeling complex and dynamic systems. They can be used in a broad range of application domains, from machine learning and robotics, to signal processing and digital communications. One important aspect that makes a factor graph very useful and very promising to be applied widely is its inference mechanism that is suitable for performing a complex model-based reasoning. However, its features have not fully explored and factor graphs are still used mainly as modeling tools that run on standard computers. Whereas in real applications such as robotics, one needs a practical implementation of such a framework. In this paper, we describe the development of a factor-graph-based inference engine that runs on a System-on-Chip (SoC). Running natively on a low level hardware, our factor graph engine delivers highest performance for real-time applications. We designed the embedded architecture so that it conveys important aspects such as modularity, scalability, flexibility and platform-friendly framework. The proposed architecture has customizable levels of parallelism as well as re-configurable modules that are extensible to accommodate large networks. We optimized the design to achieve high efficiency in terms of clock latency and resources consumption. We have tested our design on Xilinx Zynq-7000 SoCs and the implementation result demonstrates that the proposed framework can potentially be extended into a massively distributed probabilistic computing engine.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2017.11.011,Journal,Expert Systems with Applications,scopus,2018-06-15,sciencedirect,Towards a common implementation of reinforcement learning for multiple robotic tasks,https://api.elsevier.com/content/abstract/scopus_id/85035079318,"Mobile robots are increasingly being employed for performing complex tasks in dynamic environments. Those tasks can be either explicitly programmed by an engineer or learned by means of some automatic learning method, which improves the adaptability of the robot and reduces the effort of setting it up. In this sense, reinforcement learning (RL) methods are recognized as a promising tool for a machine to learn autonomously how to do tasks that are specified in a relatively simple manner. However, the dependency between these methods and the particular task to learn is a well-known problem that has strongly restricted practical implementations in robotics so far. Breaking this barrier would have a significant impact on these and other intelligent systems; in particular, having a core method that requires little tuning effort for being applicable to diverse tasks would boost their autonomy in learning and self-adaptation capabilities. In this paper we present such a practical core implementation of RL, which enables the learning process for multiple robotic tasks with minimal per-task tuning or none. Based on value iteration methods, we introduce a novel approach for action selection, called Q-biased softmax regression (QBIASSR), that takes advantage of the structure of the state space by attending the physical variables involved (e.g., distances to obstacles, robot pose, etc.), thus experienced sets of states accelerate the decision-making process of unexplored or rarely-explored states. Intensive experiments with both real and simulated robots, carried out with the software framework also introduced here, show that our implementation is able to learn different robotic tasks without tuning the learning method. They also suggest that the combination of true online SARSA(λ) (TOSL) with QBIASSR can outperform the existing RL core algorithms in low-dimensional robotic tasks. All of these are promising results towards the possibility of learning much more complex tasks autonomously by a robotic agent.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compind.2018.03.014,Journal,Computers in Industry,scopus,2018-06-01,sciencedirect,Real-time object detection in agricultural/remote environments using the multiple-expert colour feature extreme learning machine (MEC-ELM),https://api.elsevier.com/content/abstract/scopus_id/85044151304,"It is necessary for autonomous robotics in agriculture to provide real time feedback, but due to a diverse array of objects and lack of landscape uniformity this objective is inherently complex. The current study presents two implementations of the multiple-expert colour feature extreme learning machine (MEC-ELM). The MEC-ELM is a cascading algorithm that has been implemented along side a summed area table (SAT) for fast feature extraction and object classification, for a fully functioning object detection algorithm. The MEC-ELM is an implementation of the colour feature extreme learning machine (CF-ELM), which is an extreme learning machine (ELM) with a partially connected hidden layer; taking three colour bands as inputs. The colour implementation used with the SAT enable the MEC-ELM to find and classify objects quickly, with 84% precision and 91% recall in weed detection in the Y’UV colour space and in 0.5 s per frame. The colour implementation is however limited to low resolution images and for this reason a colour level co-occurrence matrix (CLCM) variant of the MEC-ELM is proposed. This variant uses the SAT to produce a CLCM and texture analyses, with texture values processed as an input to the MEC-ELM. This enabled the MEC-ELM to achieve 78–85% precision and 81–93% recall in cattle, weed and quad bike detection and in times between 1 and 2 s per frame. Both implementations were benchmarked on a standard i7 mobile processor. Thus the results presented in this paper demonstrated that the MEC-ELM with SAT grid and CLCM makes an ideal candidate for fast object detection in complex and/or agricultural landscapes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2018.02.010,Journal,Robotics and Autonomous Systems,scopus,2018-06-01,sciencedirect,Visual attention and object naming in humanoid robots using a bio-inspired spiking neural network,https://api.elsevier.com/content/abstract/scopus_id/85044145526,"Recent advances in behavioural and computational neuroscience, cognitive robotics, and in the hardware implementation of large-scale neural networks, provide the opportunity for an accelerated understanding of brain functions and for the design of interactive robotic systems based on brain-inspired control systems. This is especially the case in the domain of action and language learning, given the significant scientific and technological developments in this field. In this work we describe how a neuroanatomically grounded spiking neural network for visual attention has been extended with a word learning capability and integrated with the iCub humanoid robot to demonstrate attention-led object naming. Experiments were carried out with both a simulated and a real iCub robot platform with successful results. The iCub robot is capable of associating a label to an object with a ‘preferred’ orientation when visual and word stimuli are presented concurrently in the scene, as well as attending to said object, thus naming it. After learning is complete, the name of the object can be recalled successfully when only the visual input is present, even when the object has been moved from its original position or when other objects are present as distractors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.01.002,Journal,Neurocomputing,scopus,2018-04-12,sciencedirect,Robot manipulator control using neural networks: A survey,https://api.elsevier.com/content/abstract/scopus_id/85041636063,"Robot manipulators are playing increasingly significant roles in scientific researches and engineering applications in recent years. Using manipulators to save labors and increase accuracies are becoming common practices in industry. Neural networks, which feature high-speed parallel distributed processing, and can be readily implemented by hardware, have been recognized as a powerful tool for real-time processing and successfully applied widely in various control systems. Particularly, using neural networks for the control of robot manipulators have attracted much attention and various related schemes and methods have been proposed and investigated. In this paper, we make a review of research progress about controlling manipulators by means of neural networks. The problem foundation of manipulator control and the theoretical ideas on using neural network to solve this problem are first analyzed and then the latest progresses on this topic in recent years are described and reviewed in detail. Finally, toward practical applications, some potential directions possibly deserving investigation in controlling manipulators by neural networks are pointed out and discussed.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2018.02.005,Journal,Mechatronics,scopus,2018-04-01,sciencedirect,Experimental study on the kinematic control of a cable suspended parallel robot for object tracking purpose,https://api.elsevier.com/content/abstract/scopus_id/85042311625,"In this paper, two novel methods are proposed and compared which allows computation of the position of the end-effector in under-constrained cable-driven parallel robots. In the first method, from the data collected from an inertial measurement unit attached on the end-effector, the forward kinematic problem is reduced to a linear system of equations in which the position of the end-effector can be readily obtained real-time which is a definite asset for control purpose. In what concern the second method, a LoLiMoT neural network is trained with data collected from the simulation environment to solve the forward kinematic problem. Based on the obtained position feedback, an experimental closed loop kinematic control is performed and the proposed method is validated based on the observation of a camera which is mounted on the end-effector. A simple low cost mechanical structure is designed and constructed to measure the cable tensions by use of bending Loadcells. The sensors were calibrated and their data were used to guarantee the existence of minimum force in cables during the end-effector’s motion. At last, an algorithm for tracking a moving object is proposed and implemented. The experimental results verify the efficiency of the proposed methods.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2017.12.016,Journal,Neurocomputing,scopus,2018-03-22,sciencedirect,Use of human gestures for controlling a mobile robot via adaptive CMAC network and fuzzy logic controller,https://api.elsevier.com/content/abstract/scopus_id/85038844344,"Mobile robots with manipulators have been more and more commonly applied in extreme and hostile environments to assist or even replace human operators for complex tasks. In addition to autonomous abilities, mobile robots need to facilitate the human–robot interaction control mode that enables human users to easily control or collaborate with robots. This paper proposes a system which uses human gestures to control an autonomous mobile robot integrating a manipulator and a video surveillance platform. A human user can control the mobile robot just as one drives an actual vehicle in the vehicle’s driving cab. The proposed system obtains human’s skeleton joints information using a motion sensing input device, which is then recognized and interpreted into a set of control commands. This is implemented, based on the availability of training data set and requirement of in-time performance, by an adaptive cerebellar model articulation controller neural network, a finite state machine, a fuzzy controller and purposely designed gesture recognition and control command generation systems. These algorithms work together implement the steering and velocity control of the mobile robot in real-time. The experimental results demonstrate that the proposed approach is able to conveniently control a mobile robot using virtual driving method, with smooth manoeuvring trajectories in various speeds.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physa.2017.11.155,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2018-03-15,sciencedirect,Efficient digital implementation of a conductance-based globus pallidus neuron and the dynamics analysis,https://api.elsevier.com/content/abstract/scopus_id/85042234061,"Balance between biological plausibility of dynamical activities and computational efficiency is one of challenging problems in computational neuroscience and neural system engineering. This paper proposes a set of efficient methods for the hardware realization of the conductance-based neuron model with relevant dynamics, targeting reproducing the biological behaviors with low-cost implementation on digital programmable platform, which can be applied in wide range of conductance-based neuron models. Modified GP neuron models for efficient hardware implementation are presented to reproduce reliable pallidal dynamics, which decode the information of basal ganglia and regulate the movement disorder related voluntary activities. Implementation results on a field-programmable gate array (FPGA) demonstrate that the proposed techniques and models can reduce the resource cost significantly and reproduce the biological dynamics accurately. Besides, the biological behaviors with weak network coupling are explored on the proposed platform, and theoretical analysis is also made for the investigation of biological characteristics of the structured pallidal oscillator and network. The implementation techniques provide an essential step towards the large-scale neural network to explore the dynamical mechanisms in real time. Furthermore, the proposed methodology enables the FPGA-based system a powerful platform for the investigation on neurodegenerative diseases and real-time control of bio-inspired neuro-robotics.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artint.2017.12.001,Journal,Artificial Intelligence,scopus,2018-03-01,sciencedirect,Decentralized Reinforcement Learning of robot behaviors,https://api.elsevier.com/content/abstract/scopus_id/85038868982,"A multi-agent methodology is proposed for Decentralized Reinforcement Learning (DRL) of individual behaviors in problems where multi-dimensional action spaces are involved. When using this methodology, sub-tasks are learned in parallel by individual agents working toward a common goal. In addition to proposing this methodology, three specific multi agent DRL approaches are considered: DRL-Independent, DRL Cooperative-Adaptive (CA), and DRL-Lenient. These approaches are validated and analyzed with an extensive empirical study using four different problems: 3D Mountain Car, SCARA Real-Time Trajectory Generation, Ball-Dribbling in humanoid soccer robotics, and Ball-Pushing using differential drive robots. The experimental validation provides evidence that DRL implementations show better performances and faster learning times than their centralized counterparts, while using less computational resources. DRL-Lenient and DRL-CA algorithms achieve the best final performances for the four tested problems, outperforming their DRL-Independent counterparts. Furthermore, the benefits of the DRL-Lenient and DRL-CA are more noticeable when the problem complexity increases and the centralized scheme becomes intractable given the available computational resources and training time.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2017.10.020,Journal,Safety Science,scopus,2018-03-01,sciencedirect,Safety engineering of computational cognitive architectures within safety-critical systems,https://api.elsevier.com/content/abstract/scopus_id/85034114889,"This paper presents the integration of a cognitive architecture with an intelligent decision support model (IDSM) that is embedded into an autonomous non-deterministic safety critical system. The IDSM will integrate multi-criteria decision making via intelligent technologies like expert systems, fuzzy logic, machine learning and genetic algorithms.
                  Cognitive technology is currently simulated in safety–critical systems to highlight variables of interest, interface with intelligent technologies, and provide an environment that improves a system’s cognitive performance. In this study, the IDSM is being applied to an actual safety–critical system, an unmanned surface vehicle (USV) with embedded artificial intelligence (AI) software. The USV’s safety performance is being researched in a simulated and a real world nautical based environment. The objective is to build a dynamically changing model to evaluate a cognitive architecture’s ability to ensure safe performance of an intelligent safety–critical system. The IDSM does this by finding a set of key safety performance parameters that can be critiqued via safety measurements, mechanisms and methodologies. The uniqueness of this research will be on bounding the decision making associated with the cognitive architecture’s key safety parameters (KSP).
                  Other real-time applications that could benefit from advancing the safety of cognitive technologies are unmanned platforms, transportation technologies, and service robotics. The results will provide cognitive science researchers a reference for safety engineering artificially intelligent safety–critical systems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2017.11.010,Journal,Robotics and Autonomous Systems,scopus,2018-02-01,sciencedirect,Reset-free Trial-and-Error Learning for Robot Damage Recovery,https://api.elsevier.com/content/abstract/scopus_id/85041300580,"The high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In this situation, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require the robot and the environment to be reset to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called “Reset-free Trial-and-Error” (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2017.12.002,Journal,Mechatronics,scopus,2018-02-01,sciencedirect,SLAM in dynamic environments via ML-RANSAC,https://api.elsevier.com/content/abstract/scopus_id/85038213100,"Simultaneous localization and mapping (SLAM) in dynamic environments is an important problem in robotics navigation, yet it is less studied. In this paper, we present a novel approach to segment and track multiple moving objects in real dynamic environments. Detected objects are classified into stationary and moving objects using a state-of-the-art method referred to as multilevel-RANSAC (ML-RANSAC) algorithm. The algorithm is designed to track moving objects in conflict situations while running SLAM. The ML-RANSAC algorithm is developed to robustly estimate velocity and position of the multiple moving objects in an unknown environment whereas the state of the objects (static or dynamic) is not known a priori. The main characteristic of the algorithm is its ability to address both static and dynamic objects in SLAM and to detect and track moving objects (DATMO) without dividing the problem into two separate parts (SLAM and DATMO). We apply the proposed algorithm on two sets of simulated data to validate its performance in situations where the objects are either occluded or placed in dense dynamic scenario. We have compared our method with the true data via simulation studies. Furthermore, we have implemented the algorithm on a Pioneer P3-DX mobile robot navigating a real dynamic environment. Simulation studies as well as real-time experiments suggest that the algorithm is able to track and classify objects accurately while performing SLAM in dynamic environments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2017.01.110,Journal,Neurocomputing,scopus,2018-01-03,sciencedirect,Making physical proofs of concept of reinforcement learning control in single robot hose transport task complete,https://api.elsevier.com/content/abstract/scopus_id/85023642304,"This paper deals with the realization of physical proof of concept experiments in the paradigm of Linked Multi-Component Robotic Systems (LMCRS). The main objective is to demonstrate that the controllers learned through Reinforcement Learning (RL) algorithms with different state space formalizations and different spatial discretizations in a simulator are reliable in a real world configuration of the task of transporting a hose by a single robot. This one is a prototypical example of LMCRS task (extendable to much more complex tasks). We describe how the complete system has been designed and implemented. Two different previously learned RL controllers have been tested solving two different LMCRS control problems, using different state space modeling and discretization step in each case. The physical realizations validate previously published simulation based results, giving a strong argument in favor of the suitability of RL techniques to deal with LMCRS systems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2017.02.098,Journal,Neurocomputing,scopus,2018-01-03,sciencedirect,Real time direct kinematic problem computation of the 3PRS robot using neural networks,https://api.elsevier.com/content/abstract/scopus_id/85022211920,"The reliable calculation of the Direct Kinematic Problem (DKP) is one of the main challenges for the implementation of Real-Time (RT) controllers in Parallel Robots. The DKP estimates the pose of the end effector of the robot in terms of the sensors placed on the actuators. However, this calculation requires the use of time-consuming numerical iterative procedures.
                  Artificial Neural Networks have been proposed to implement the complex DKP equation mapping due to their universal approximator property. However, the proposals in this area do not consider the Real Time implementation of the ANN based solution, and no approximation error vs computational time analysis is carried out.
                  In this work, a methodology that uses Artificial Neural Networks (ANNs) to approximate the DKP is proposed. Based on the 3PRS parallel robot, a comprehensive study is carried out in which several network configurations are proposed to approximate the DKP. Moreover, to demonstrate the effectiveness of the approach, the proposed networks are evaluated considering not only their approximation capabilities, but also their Real Time performance in comparison with the traditional iterative procedures used in robotics.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2018.01.036,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,"Intuitive robot programming through environment perception, augmented reality simulation and automated program verification",https://api.elsevier.com/content/abstract/scopus_id/85061975291,"The increasing complexity of products and machines as well as short production cycles with small lot sizes present great challenges to production industry. Both, the programming of industrial robots in online mode using hand-held control devices or in offline mode using text-based programming requires specific knowledge of robotics and manufacturer-dependent robot control systems. In particular for small and medium-sized enterprises the machine control software needs to be easy, intuitive and usable without time-consuming learning steps, even for employees with no in-depth knowledge of information technology. To simplify the programming of application programs for industrial robots, we extended a cloud-based, task-oriented robot control system with environment perception and plausibility check functions. For the environment perception a depth camera and pointcloud processing hardware were installed. We detect objects located in the robot’s workspace by pointcloud processing with ROS and the PCL and add them to the augmented reality user interface of the robot control. The combination of process knowledge from task-oriented application programming and information about available workpieces from automated image processing enables a plausibility check and verification of the robot program before execution. After a robot program has been approved by the plausibility check, it is tested in an augmented reality simulation for collisions with the detected objects before deployment to the physical robot hardware. Experiments were carried out to evaluate the effectiveness of the developed extensions and confirmed their functionality.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.11.110,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Compositional models for VQA: Can neural module networks really count?,https://api.elsevier.com/content/abstract/scopus_id/85059483400,"Large neural networks trained in an end-to-end fashion usually fail to generalize over novel inputs which were not included in the training data. In contrast, biologically-inspired compositional models offer a more robust solution due to adaptive chaining of logical operations performed by specialized modules. In this paper, we present an implementation of a cognitive architecture based on the End-to-End Module Networks (N2NMNs) model [9] in the humanoid robot Pepper. The architecture is focused on the Visual Question Answering task (VQA), in which the robot answers questions regarding the seen image in natural language. We trained the system on the synthetic CLEVR dataset [10] and tested it on both synthetic images and real-world situations with CLEVR-like objects. We compare between the results and discuss the decrease of accuracy in real-world situations. Furthermore, we propose a new evaluation method, in which we test whether the model’s results for counting objects in each category is consistent with the overall number of seen objects. In summary, our results show that the current visual reasoning models are still far from being applicable in everyday life.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.07.108,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Ambience Inhaling: Speech Noise Inhaler in Mobile Robots using Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85051344062,"Audio based, machine learning human-computer interface with speech recognition systems performs sensibly well with the human voice under clean ambience, but become frail in applied technological implementation involving real-life interface. In mobile robotic systems, the speech machines are normally retrained with new changing acoustic ambience conditions are to be met. To inhale, classify, and track the real-world ambience noise with the new changing acoustic condition, we introduce an Ambience Inhaling (AI) framework in this article. This framework of an AI is to seek out complete noise information from speech data, in contrast with noise-nature discovery. Our proposed framework uses a deep convolutional neural network (CNN) based learning for classification with speech spectrogram patch segments, including a hybrid Harold Hotelling's T-square algorithm with Bayesian statistics for segmentation analysis. We use a symposium presentation-ambience as a test platform. In the symposium presentation-ambience, noise modeling is done with n-gram language having the parameter of n = 2. The impulsive or short-term noise which is superimposed with long-term noise caused degradation in classification. This degradation caused the classification errors. The provision of decision was made. The Gaussian mixture model and hidden Markova model are used with noise-only and noisy speech respectively. Time and frequency pooling are used with spectrogram also. The classification scores of 62.26%, 65.89%, and 69.12% are achieved with 5, 10 and 15 CNN filters respectively. As a significance, an AI is efficient and innovative.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2018.03.022,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,Fostering Robust Human-Robot Collaboration through AI Task Planning,https://api.elsevier.com/content/abstract/scopus_id/85049587790,"Recent advances in Artificial Intelligence (AI) are facilitating the deployment of intelligent systems in manufacturing. In Human-Robot Collaboration (HRC), industrial robots offer accuracy and efficiency while humans guarantee both experience and specialized and not replaceable skills. The seamless coordination of such different abilities constitutes one of the current challenges. This paper presents a dynamic task sequencing system for robust HRC developed within a EU-funded project. The proposed solution uses AI techniques to deal with the temporal variance entailed by the active presence of humans as well as to dynamically adapt task plans according to actual behavior of the pair human-worker/robot. The tool has been deployed in a real pilot plant.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2018.06.088,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Design and Implementation of a Real-Time Autonomous Navigation System Applied to Lego Robots,https://api.elsevier.com/content/abstract/scopus_id/85048935639,"Teaching theoretical concepts of a real-time autonomous robot system may be a challenging task without real hardware support. The paper discusses the application of the Lego Robot for teaching multi interdisciplinary subjects to Mechatronics students. A real-time mobile robot system with perception using sensors, path planning algorithm, PID controller is used as the case to demonstrate the teaching methodology. The novelties are introduced compared to classical robotic classes: (i) the adoption of a project-based learning approach as teaching methodology; (ii) an effective real-time autonomous navigation approach for the mobile robot. However, the extendibility and applicability of the presented approach are not limited to only the educational purpose.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2017.08.002,Journal,Cognitive Systems Research,scopus,2018-01-01,sciencedirect,A computational cognitive framework of spatial memory in brains and robots,https://api.elsevier.com/content/abstract/scopus_id/85034106426,"Computational cognitive models of spatial memory often neglect difficulties posed by the real world, such as sensory noise, uncertainty, and high spatial complexity. On the other hand, robotics is unconcerned with understanding biological cognition. Here, we describe a computational framework for robotic architectures aiming to function in realistic environments, as well as to be cognitively plausible.
                  We motivate and describe several mechanisms towards achieving this despite the sensory noise and spatial complexity inherent in the physical world. We tackle error accumulation during path integration by means of Bayesian localization, and loop closing with sequential gradient descent. Finally, we outline a method for structuring spatial representations using metric learning and clustering. Crucially, unlike the algorithms of traditional robotics, we show that these mechanisms can be implemented in neuronal or cognitive models.
                  We briefly outline a concrete implementation of the proposed framework as part of the LIDA cognitive architecture, and argue that this kind of probabilistic framework is well-suited for use in cognitive robotic architectures aiming to combine spatial functionality and psychological plausibility.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.biosystems.2017.10.001,Journal,BioSystems,scopus,2017-12-01,sciencedirect,Towards a first implementation of the WLIMES approach in living system studies advancing the diagnostics and therapy in personalized medicine,https://api.elsevier.com/content/abstract/scopus_id/85033459793,"The goal of this paper is to advance an extensible theory of living systems using an approach to biomathematics and biocomputation that suitably addresses self-organized, self-referential and anticipatory systems with multi-temporal multi-agents. Our first step is to provide foundations for modelling of emergent and evolving dynamic multi-level organic complexes and their sustentative processes in artificial and natural life systems. Main applications are in life sciences, medicine, ecology and astrobiology, as well as robotics, industrial automation, man-machine interface and creative design. Since 2011 over 100 scientists from a number of disciplines have been exploring a substantial set of theoretical frameworks for a comprehensive theory of life known as Integral Biomathics. That effort identified the need for a robust core model of organisms as dynamic wholes, using advanced and adequately computable mathematics. The work described here for that core combines the advantages of a situation and context aware multivalent computational logic for active self-organizing networks, Wandering Logic Intelligence (WLI), and a multi-scale dynamic category theory, Memory Evolutive Systems (MES), hence WLIMES. This is presented to the modeller via a formal augmented reality language as a first step towards practical modelling and simulation of multi-level living systems. Initial work focuses on the design and implementation of this visual language and calculus (VLC) and its graphical user interface. The results will be integrated within the current methodology and practices of theoretical biology and (personalized) medicine to deepen and to enhance the holistic understanding of life.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmatprotec.2017.07.005,Journal,Journal of Materials Processing Technology,scopus,2017-12-01,sciencedirect,Automated control of welding penetration based on audio sensing technology,https://api.elsevier.com/content/abstract/scopus_id/85023614883,"This paper presents a technology for welding quality control in pulse gas tungsten arc welding (GTAW). An automated welding penetration control system and effective controller are designed to achieve real-time collection and analysis of the welding acoustic signal. A special preprocessing method called “auditory attention” is proposed to optimize the extraction of the arc sound signal, which includes region of interest (ROI) extraction and denoising. The penetration feature extraction is implemented in the preprocessed signal. A sound channel feature based on linear prediction cepstrum coefficient (LPCC) is proposed for inclusion in the feature extraction method. Using these penetration features, a typical back propagation artificial neural network (BPANN) prediction model is introduced for identification of the penetration state during the welding process. Through training using a large number of data, the prediction rate reached 80–90%. The BPANN-piecewise (BPANN-PW) controller is used to achieve online control of welding penetration via arc sound signal for pulse GTAW welding using work-piece of different shapes. The results showed that this controller could adjust the welding current accurately and promptly depending on the variation of the arc sound signal. The controlling effect was good for the online monitoring of automated robotic GTAW welding.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chb.2017.02.064,Journal,Computers in Human Behavior,scopus,2017-12-01,sciencedirect,Shopping with a robotic companion,https://api.elsevier.com/content/abstract/scopus_id/85015734591,"In this paper, we present a robotic shopping assistant, designed with a cognitive architecture, grounded in machine learning systems, in order to study how the human-robot interaction (HRI) is changing the shopping behavior in smart technological stores. In the software environment of the NAO robot, connected to the Internet with cloud services, we designed a social-like interaction where the robot carries out actions with the customer. In particular, we focused our design on two main skills the robot has to learn: the first is the ability to acquire social input communicated by relevant clues that humans provide about their emotional state (emotions, emotional speech), or collected in the Social Media (such as, information on the customer's tastes, cultural background, etc.). The second is the skill to express in turn its own emotional state, so that it can affect the customer buying decision, refining in the user the sense of interacting with a human-like companion. By combining social robotics and machine learning systems the potential of robotics to assist people in real life situations will increase, providing a gentle customers' acceptance of advanced technologies.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2017.08.013,Journal,Engineering Applications of Artificial Intelligence,scopus,2017-11-01,sciencedirect,Gesture recognition system for real-time mobile robot control based on inertial sensors and motion strings,https://api.elsevier.com/content/abstract/scopus_id/85029641125,"Navigating and controlling a mobile robot in an indoor or outdoor environment by using a range of body-worn sensors is becoming an increasingly interesting research area in the robotics community. In such scenarios, hand gestures offer some unique capabilities for human–robot interaction inherent to nonverbal communication with features and application scenarios not possible with the currently predominant vision-based systems. Therefore, in this paper, we propose and develop an effective inertial-sensor-based system, worn by the user, along with a microprocessor and wireless module for communication with the robot at distances of up to 250 m. Possible features describing hand-gesture dynamics are introduced and their feasibility is demonstrated in an off-line scenario by using several classification methods (e.g., random forests and artificial neural networks). Refined motion features are then used in K-means unsupervised clustering for motion primitive extraction, which forms the motion strings used for real-time classification. The system demonstrated an 
                        F
                        1
                      score of 
                        90
                        .
                        05
                        %
                      with the possibility of gesture spotting and null class classification (e.g., undefined gestures were discarded from the analysis). Finally, to demonstrate the feasibility of the proposed algorithm, it was implemented in an Arduino-based 
                        8
                     -bit ATmega2560 microcontroller for control of a mobile, tracked robot platform.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2017.07.038,Journal,Acta Astronautica,scopus,2017-11-01,sciencedirect,Self-supervised learning as an enabling technology for future space exploration robots: ISS experiments on monocular distance learning,https://api.elsevier.com/content/abstract/scopus_id/85026883328,"Although machine learning holds an enormous promise for autonomous space robots, it is currently not employed because of the inherent uncertain outcome of learning processes. In this article we investigate a learning mechanism, Self-Supervised Learning (SSL), which is very reliable and hence an important candidate for real-world deployment even on safety-critical systems such as space robots. To demonstrate this reliability, we introduce a novel SSL setup that allows a stereo vision equipped robot to cope with the failure of one of its cameras. The setup learns to estimate average depth using a monocular image, by using the stereo vision depths from the past as trusted ground truth. We present preliminary results from an experiment on the International Space Station (ISS) performed with the MIT/NASA SPHERES VERTIGO satellite. The presented experiments were performed on October 8th, 2015 on board the ISS. The main goals were (1) data gathering, and (2) navigation based on stereo vision. First the astronaut Kimiya Yui moved the satellite around the Japanese Experiment Module to gather stereo vision data for learning. Subsequently, the satellite freely explored the space in the module based on its (trusted) stereo vision system and a pre-programmed exploration behavior, while simultaneously performing the self-supervised learning of monocular depth estimation on board. The two main goals were successfully achieved, representing the first online learning robotic experiments in space. These results lay the groundwork for a follow-up experiment in which the satellite will use the learned single-camera depth estimation for autonomous exploration in the ISS, and are an advancement towards future space robots that continuously improve their navigation capabilities over time, even in harsh and completely unknown space environments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2017.03.002,Journal,Expert Systems with Applications,scopus,2017-09-01,sciencedirect,Incremental Q-learning strategy for adaptive PID control of mobile robots,https://api.elsevier.com/content/abstract/scopus_id/85015894497,"Expert and intelligent systems are being developed to control many technological systems including mobile robots. However, the PID (Proportional-Integral-Derivative) controller is a fast low-level control strategy widely used in many control engineering tasks. Classic control theory has contributed with different tuning methods to obtain the gains of PID controllers for specific operation conditions. Nevertheless, when the system is not fully known and the operative conditions are variable and not previously known, classical techniques are not entirely suitable for the PID tuning. To overcome these drawbacks many adaptive approaches have been arisen, mainly from the field of artificial intelligent. In this work, we propose an incremental Q-learning strategy for adaptive PID control. In order to improve the learning efficiency we define a temporal memory into the learning process. While the memory remains invariant, a non-uniform specialization process is carried out generating new limited subspaces of learning. An implementation on a real mobile robot demonstrates the applicability of the proposed approach for a real-time simultaneous tuning of multiples adaptive PID controllers for a real system operating under variable conditions in a real environment.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2017.08.1219,Conference Proceeding,IFAC-PapersOnLine,scopus,2017-07-01,sciencedirect,Implementation of Brain Emotional Learning-Based Intelligent Controller for Flocking of Multi-Agent Systems,https://api.elsevier.com/content/abstract/scopus_id/85031823232,"The Brain Emotional Learning Based Intelligent Controller (BELBIC) is a neurobiologically-motivated intelligent controller based on a computational model of emotional learning in mammalian limbic system. The learning capabilities, multi-objective properties, and low computational complexity of BELBIC make it a very promising tool for implementation in real-time applications.
                  Our research combines, in an original way, the BELBIC methodology with a flocking control strategy, in order to perform real-time coordination of multiple Unmanned Aircraft Systems (UAS). The characteristics of BELBIC fit well in this scenario, since almost always the dynamics of the autonomous agents are not fully known, and furthermore, since they operate in close proximity, they are subjected to aggressive external disturbances. Numerical and experimental results based on the coordination of multiple quad rotorcraft UAS platforms demonstrate the applicability and satisfactory performance of the proposed method.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2017.03.028,Journal,Neurocomputing,scopus,2017-06-28,sciencedirect,A real-time FPGA implementation of a biologically inspired central pattern generator network,https://api.elsevier.com/content/abstract/scopus_id/85016031943,"Central pattern generators (CPGs) functioning as biological neuronal circuits are responsible for generating rhythmic patterns to control locomotion. In this paper, a biologically inspired CPG composed of two reciprocally inhibitory neurons was implemented on a reconfigurable FPGA with real-time computational speed and considerably low hardware cost. High-accuracy neural circuit implementation can be computationally expensive, especially for a high-dimensional conductance-based neuron model. Thus, we aimed to present an efficient multiplier-less hardware implementation method for the investigation of real-time hardware CPG (hCPG) networks. In order to simplify the hardware implementation, a modified neuron model without nonlinear parts was given to decrease the complexity of the original model. A simple CPG network involving two chemical coupled neurons was realized which represented the pyloric dilator (PD) and lateral pyloric (LP) neurons in the crustacean pyloric CPG. The implementation results of the hCPG network showed that rhythmic behaviors were successfully reproduced and the resource consumption was dramatically reduced by using our multiplier-less implementation method. The presented FPGA-based implementation of hCPG network with remarkable performance set a prototype for the realization of other large-scale CPG networks and could be applied in bio-inspired robotics and motion rehabilitation for locomotion control.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artint.2015.05.010,Journal,Artificial Intelligence,scopus,2017-06-01,sciencedirect,Representations for robot knowledge in the KNOWROB framework,https://api.elsevier.com/content/abstract/scopus_id/84930599246,"In order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods. These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution. For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base. To this end we propose the KnowRob knowledge processing system for robots. In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in AI research, and propose to re-consider a KR system as a semantically annotated view on information and algorithms that are often already available as part of the robot's control system. We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot's hardware as well as inference procedures that operate on this common representation. The KnowRob system has been released as open-source software and is being used on several robots performing complex object manipulation tasks. We evaluate it through prototypical queries that demonstrate the expressive power and its impact on the robot's performance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2016.11.001,Journal,Robotics and Autonomous Systems,scopus,2017-04-01,sciencedirect,"Reprint of “Cognition, cognitics, and team action—Overview, foundations, and five theses for a better world”",https://api.elsevier.com/content/abstract/scopus_id/85011101312,"Consider now a shift of attention onto cognition. Novel definitions and metrics have been made, and it is time to reap the benefits, and to boost the development of intelligent autonomous systems. Mankind has gained a decisive advantage, in the race for survival and in the perspective of enjoyable lives, when cognitive abilities, i.e. cognition, appeared and started to develop in humans. Now cognition appears also as a crucial faculty to harness, i.e. to implement on machines; this is the field of cognitics. What is learnt about cognition for the purpose of machines, by a mirror effect, also affects the way we may recognize the role of cognition for ourselves, as humans. What is cognition? How does it relate to classical concepts, which appear much less well defined than expected? A summary of critical answers to these questions is sketched below. Then five theses about cognition are summarized: cognition to know the real world, to explore and perceive, to model; cognition for defining alternative worlds and possible futures, visions, and anticausality; cognition for effective control; cognitics for a large scale, technical deployment of cognition; and social cognitics, a foundation for team action and increased momentum for change. The five theses can be seen both as paths toward better insights in human and social nature and also as a roadmap for simultaneous and iterative processes capable to freely foster a better future for individuals and society. The paper finally includes as well an overview of MCS cognition theory, with some additional contributions, notably relating to foundations and time derivative aspects.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isprsjprs.2017.01.002,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2017-03-01,sciencedirect,Appearance learning for 3D pose detection of a satellite at close-range,https://api.elsevier.com/content/abstract/scopus_id/85009110439,"In this paper we present a learning-based 3D detection of a highly challenging specular object exposed to a direct sunlight at very close-range. An object detection is one of the most important areas of image processing, and can also be used for initialization of local visual tracking methods. While the object detection in 3D space is generally a difficult problem, it poses more difficulties when the object is specular and exposed to the direct sunlight as in a space environment. Our solution to a such problem relies on an appearance learning of a real satellite mock-up based on a vector quantization and the vocabulary tree. Our method, implemented on a standard computer (CPU), exploits a full perspective projection model and provides near real-time 3D pose detection of a satellite for close-range approach and manipulation. The time consuming part of the training (feature description, building the vocabulary tree and indexing, depth buffering and back-projection) are performed offline, while a fast image retrieval and 3D-2D registration are performed on-line. In contrast, the state of the art image-based 3D pose detection methods are slower on CPU or assume a weak perspective camera projection model. In our case the dimension of the satellite is larger than the distance to the camera, hence the assumption of the weak perspective model does not hold. To evaluate the proposed method, the appearance of a full scale mock-up of the rear part of the TerraSAR-X satellite is trained under various illumination and camera views. The training images are captured with a camera mounted on six degrees of freedom robot, which enables to position the camera in a desired view, sampled over a sphere. The views that are not within the workspace of the robot are interpolated using image-based rendering. Moreover, we generate ground truth poses to verify the accuracy of the detection algorithm. The achieved results are robust and accurate even under noise due to specular reflection, and able to initialize a local tracking method.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2017.10.014,Conference Proceeding,Procedia Computer Science,scopus,2017-01-01,sciencedirect,Implementation of Blind Speech Separation for Intelligent Humanoid Robot using DUET Method,https://api.elsevier.com/content/abstract/scopus_id/85040022814,"Nowadays, there are many efforts in building intelligent humanoid robot and adding advanced ability such as Blind Speech Separation (BSS). BSS is a problem of separation of several speech signals in a real world from mono or stereo audio record. In this research, we implement BSP system using DUET algorithm which allow to separate any number of sources by using only stereo (two) mixtures. The DUET (Degenerate Unmixing Estimation Technique) algorithm replaces our previous FastICA (Fast Independent Component Analysis) method only success in simulation but failed in the implementation. The main problem of FastICA is that it assumes instantaneous mixing without time delay in the recording process. To deals with audio record in the presence of inevitable time delays, it has to be replaced with DUET algorithm to separate well in real time. Finally, the DUET algorithm is implemented to humanoid robot which is developed using Raspberry Pi and equipped with RaspPi Cam to detect human face. Furthermore, the Cirrus Logic Audio Card is stacked to Raspberry Pi in order to record stereo audio. In our experiments, there are three controlled variables to evaluate algorithm performance, that is: distance, number of sources, and subject’s name. Robot will record stereo audio for four seconds after face is detected by system. The recording is then separated by DUET algorithm and produce two source estimations with average computation time 1.8 seconds. With Google API, the recognition accuracy of separated speech is varying between 40%-70%.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2017.04.039,Journal,Procedia Manufacturing,scopus,2017-01-01,sciencedirect,Digital Twin as Enabler for an Innovative Digital Shopfloor Management System in the ESB Logistics Learning Factory at Reutlingen - University,https://api.elsevier.com/content/abstract/scopus_id/85020859111,"Technologies for mapping the “digital twin” have been under development for approximately 20 years. Nowadays increasingly intelligent, individualized products encourages companies to respond innovatively to customer requirements and to handle the rising product variations quickly.
                  An integrated engineering network, spanning across the entire value chain, is operated to intelligently connect various company divisions, and to generate a business ecosystem for products, services and communities. The conditions for the digital twin are thereby determined in which the digital world can be fed into the real, and the real world back into the digital to deal such intelligent products with rising variations.
                  The term digital twin can be described as a digital copy of a real factory, machine, worker etc., that is created and can be independently expanded, automatically updated as well as being globally available in real time. Every real product and production site is permanently accompanied by a digital twin. First prototypes of such digital twins already exist in the ESB Logistics Learning Factory on a cloud- and app-based software that builds on a dynamic, multidimensional data and information model. A standardized language of the robot control systems via software agents and positioning systems has to be integrated. The aspect of the continuity of the real factory in the digital factory as an economical means of ensuring continuous actuality of digital models looks as the basis of changeability.
                  For the indoor localization sensor combinations that in addition to the hardware already contain the software required for the sensor data fusion should be used. Processing systems, scenario-live-simulations and digital shop floor management results in a mandatory procedural combination. Essential to the digital twin is the ability to consistently provide all subsystems with the latest state of all required information, methods and algorithms.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2017.01.188,Conference Proceeding,Procedia Computer Science,scopus,2017-01-01,sciencedirect,Smartphone Based Data Mining for Fall Detection: Analysis and Design,https://api.elsevier.com/content/abstract/scopus_id/85016131722,"Falls can be devastating to the affected individual, yet a common event and hence one of the major causes of injury or disability within the aged population in Malaysia and worldwide. This paper aims to detect human fall utilizing the built inertial measurement unit (IMU) sensors of a smartphone attached to the subject's body with the signals wirelessly transmitted to remote PC for processing. Matlab's mobile and the Smartphone Sensor Support is used to acquire the data from the smartphone which is then analysed to design an algorithm for the detection of fall. Falls in human are usually characterized by large acceleration. However, focusing only on a large value of the acceleration can result in many false positives from fall-like activities such as sitting down quickly and jumping. Thus, in this work, a threshold based fall detection algorithm is implemented while a supervised machine learning algorithm is used to classify activity daily living (ADL). This combination has been found effective in increasing the accuracy of the fall detection. The aim is to develop and verify the high precision detection algorithm using Matlab Simulink, followed by a few real time testing.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2017.01.213,Conference Proceeding,Procedia Computer Science,scopus,2017-01-01,sciencedirect,Hybrid Agents Implementation for the Control of the Construction Company,https://api.elsevier.com/content/abstract/scopus_id/85016095509,"Planning the project duration together with separate works is an essential element of managing the construction. The final duration depends on multiple factors, including the funds, customer requests, and capabilities of the construction company. In order to avoid additional costs in penalties or additional expenses, the management needs to estimate the real construction duration in advance, before the contract is signed. Further on, these terms need to be monitored both in whole and for the specific jobs in order to be able to edit further stages with regard of the remaining time, resources and used resources ratio. The development of a decision support system for the construction company is a pressing problem due to the growing demand in decision making persons’ labor automation in planning and monitoring the construction processes. The paper presents the model and the application experience for such a system.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2016.09.026,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2016-12-01,sciencedirect,Gesture imitation and recognition using Kinect sensor and extreme learning machines,https://api.elsevier.com/content/abstract/scopus_id/84988699181,"This study presents a framework that recognizes and imitates human upper-body motions in real time. The framework consists of two parts. In the first part, a transformation algorithm is applied to 3D human motion data captured by a Kinect. The data are then converted into the robot’s joint angles by the algorithm. The human upper-body motions are successfully imitated by the NAO humanoid robot in real time.
                  In the second part, the human action recognition algorithm is implemented for upper-body gestures. A human action dataset is also created for the upper-body movements. Each action is performed 10 times by twenty-four users. The collected joint angles are divided into six action classes. Extreme Learning Machines (ELMs) are used to classify the human actions. Additionally, the Feed-Forward Neural Networks (FNNs) and K-Nearest Neighbor (K-NN) classifiers are used for comparison. According to the comparative results, ELMs produce a good human action recognition performance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2016.03.001,Journal,Cognitive Systems Research,scopus,2016-12-01,sciencedirect,Simulation within simulation for agent decision-making: Theoretical foundations from cognitive science to operational computer model,https://api.elsevier.com/content/abstract/scopus_id/84963705117,"This article deals with artificial intelligence models inspired from cognitive science. The scope of this paper is the simulation of the decision-making process for virtual entities. The theoretical framework consists of concepts from the use of internal behavioral simulation for human decision-making. Inspired from such cognitive concepts, the contribution consists in a computational framework that enables a virtual entity to possess an autonomous world of simulation within the simulation. It can simulate itself (using its own model of behavior) and simulate its environment (using its representation of other entities). The entity has the ability to anticipate using internal simulations, in complex environments where it would be extremely difficult to use formal proof methods. Comparing the prediction and the original simulation, its predictive models are improved through a learning process. Illustrations of this model are provided through two implementations. First illustration is an example showing a shepherd, his herd and dogs. The dog simulates the sheep’s behavior in order to make predictions testing different strategies. Second, an artificial 3D juggler plays in interaction with virtual jugglers, humans and robots. For this application, the juggler predicts the behavior of balls in the air and uses prediction to coordinate its behavior in order to juggle.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2016.06.021,Journal,Expert Systems with Applications,scopus,2016-11-15,sciencedirect,Neural networks based reinforcement learning for mobile robots obstacle avoidance,https://api.elsevier.com/content/abstract/scopus_id/84975032535,"This study proposes a new approach for solving the problem of autonomous movement of robots in environments that contain both static and dynamic obstacles. The purpose of this research is to provide mobile robots a collision-free trajectory within an uncertain workspace which contains both stationary and moving entities. The developed solution uses Q-learning and a neural network planner to solve path planning problems. The algorithm presented proves to be effective in navigation scenarios where global information is available. The speed of the robot can be set prior to the computation of the trajectory, which provides a great advantage in time-constrained applications. The solution is deployed in both Virtual Reality (VR) for easier visualization and safer testing activities, and on a real mobile robot for experimental validation. The algorithm is compared with Powerbot's ARNL proprietary navigation algorithm. Results show that the proposed solution has a good conversion rate computed at a satisfying speed.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2016.08.008,Journal,Robotics and Autonomous Systems,scopus,2016-11-01,sciencedirect,"Cognition, cognitics, and team action—Overview, foundations, and five theses for a better world",https://api.elsevier.com/content/abstract/scopus_id/85011032498,"Consider now a shift of attention onto cognition. Novel definitions and metrics have been made, and it is time to reap the benefits, and to boost the development of intelligent autonomous systems. Mankind has gained a decisive advantage, in the race for survival and in the perspective of enjoyable lives, when cognitive abilities, i.e. cognition, appeared and started to develop in humans. Now cognition appears also as a crucial faculty to harness, i.e. to implement on machines; this is the field of cognitics. What is learnt about cognition for the purpose of machines, by a mirror effect, also affects the way we may recognize the role of cognition for ourselves, as humans. What is cognition? How does it relate to classical concepts, which appear much less well defined than expected? A summary of critical answers to these questions is sketched below. Then five theses about cognition are summarized: cognition to know the real world, to explore and perceive, to model; cognition for defining alternative worlds and possible futures, visions, and anticausality; cognition for effective control; cognitics for a large scale, technical deployment of cognition; and social cognitics, a foundation for team action and increased momentum for change. The five theses can be seen both as paths toward better insights in human and social nature and also as a roadmap for simultaneous and iterative processes capable to freely foster a better future for individuals and society. The paper finally includes as well an overview of MCS cognition theory, with some additional contributions, notably relating to foundations and time derivative aspects.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2016.07.031,Journal,Computers and Industrial Engineering,scopus,2016-11-01,sciencedirect,TIMSPAT – Reachability graph search-based optimization tool for colored Petri net-based scheduling,https://api.elsevier.com/content/abstract/scopus_id/84991205081,"The combination of Petri net (PN) modeling with AI-based heuristic search (HS) algorithms (PNHS) has been successfully applied as an integrated approach to deal with scheduling problems that can be transformed into a search problem in the reachability graph. While several efficient HS algorithms have been proposed albeit using timed PN, the practical application of these algorithms requires an appropriate tool to facilitate its development and analysis. However, there is a lack of tool support for the optimization of timed colored PN (TCPN) models based on the PNHS approach for schedule generation. Because of its complex data structure, TCPN-based scheduling has often been limited to simulation-based performance analysis only. Also, it is quite difficult to evaluate the strength and tractability of algorithms for different scheduling scenarios due to the different computing platforms, programming languages and data structures employed. In this light, this paper presents a new tool called TIMSPAT, developed to overcome the shortcomings of existing tools. Some features that distinguish this tool are the collection of several HS algorithms, XML-based model integration, the event-driven exploration of the timed state space including its condensed variant, localized enabling of transitions, the introduction of static place, and the easy-to-use syntax statements. The tool is easily extensible and can be integrated as a component into existing PN simulators and software environments. A comparative study is performed on a real-world eyeglass production system to demonstrate the application of the tool for scheduling purposes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2016.08.003,Journal,Neural Networks,scopus,2016-11-01,sciencedirect,Implementation of Imitation Learning using Natural Learner Central Pattern Generator Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/84984998255,"In this paper a new design of neural networks is introduced, which is able to generate oscillatory patterns. The fundamental building block of the neural network is O-neurons that can generate an oscillation in its transfer functions. Since the natural policy gradient learning has been used in training a central pattern generator paradigm, it is called Natural Learner CPG Neural Networks (NLCPGNN). O-neurons are connected and coupled to each other in order to shape a network and their unknown parameters are found by a natural policy gradient learning algorithm. The main contribution of this paper is design of this learning algorithm which is able to simultaneously search for the weights and topology of the network. This system is capable to obtain any complex motion and rhythmic trajectory via first layer and learn rhythmic trajectories in the second layer and converge towards all these movements. Moreover this two layers system is able to provide various features of a learner model for instance resistance against perturbations, modulation of trajectories amplitude and frequency. Simulation of the learning system in the robot simulator (WEBOTS) that is linked with MATLAB software has been done. Implementation on a real NAO robot demonstrates that the robot has learned desired motion with high accuracy. These results show proposed system produces high convergence rate and low test errors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scico.2016.03.009,Journal,Science of Computer Programming,scopus,2016-11-01,sciencedirect,Model-driven processes and tools to design robot-based generative learning objects for computer science education,https://api.elsevier.com/content/abstract/scopus_id/84971228847,"In this paper, we introduce a methodology to design robot-oriented generative learning objects (GLOs) that are, in fact, heterogeneous meta-programs to teach computer science (CS) topics such as programming. The methodology includes CS learning variability modelling using the feature-based approaches borrowed from the SW engineering domain. Firstly, we define the CS learning domain using the known educational framework TPACK (Technology, Pedagogy And Content Knowledge). By learning variability we mean the attributes of the framework extracted and represented as feature models with multiple values. Therefore, the CS learning variability represents the problem domain. Meta-programming is considered as a solution domain. Both are represented by feature models. The GLO design task is formulated as mapping the problem domain model on the solution domain model. Next, we present the design framework to design GLOs manually or semi-automatically. The multi-level separation of concepts, model representation and transformation forms the conceptual background. Its theoretical background includes: (a) a formal definition of feature-based models; (b) a graph-based and set-based definition of meta-programming concepts; (c) transformation rules to support the model mapping; (d) a computational Abstract State Machine model to define the processes and design tool for developing GLOs. We present the architecture and some characteristics of the tool. The tool enables to improve the GLO design process significantly (in terms of time and quality) and to achieve a higher quality and functionality of GLOs themselves (in terms of the parameter space enlargement for reuse and adaptation). We demonstrate the appropriateness of the methodology in the real teaching setting. In this paper, we present the case study that analyses three robot-oriented GLOs as the higher-level specifications. Then, using the meta-language processor, we are able to produce, from the specifications, the concrete robot control programs on demand automatically and to demonstrate teaching algorithms visually by robot's actions. We evaluate the approach from technological and pedagogical perspectives using the known structural metrics. Also, we indicate the merits and demerits of the approach. The main contribution and originality of the paper is the seamless integration of two known technologies (feature modelling and meta-programming) in designing robot-oriented GLOs and their supporting tools.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.autcon.2016.03.012,Journal,Automation in Construction,scopus,2016-11-01,sciencedirect,"SmartSite: Intelligent and autonomous environments, machinery, and processes to realize smart road construction projects",https://api.elsevier.com/content/abstract/scopus_id/84969580061,"This article presents an overview of the SmartSite research project that adopts machine learning, decision theory and distributed artificial intelligence to design and test a multi-agent system (MAS) for asphalt road construction. SmartSite puts major emphasis on sensing and communication technologies that integrate real-time automated information exchange in the supply chain of road construction. As part of the larger SmartSite project, this article introduces a novel real-time path planning system for compactors and presents the results of several simulation and field realistic experiments conducted to evaluate the system in a sophisticated simulation and harsh construction environment, respectively. The system operates based on Belief-Desire-Intention (BDI) software agents and real-time sensory inputs. The newly developed integrated and information rich process benefits asphalt compactor operators, as they are now capable to control their machinery and react to changing environmental, material-related and process-related disturbances or changes. This improves the quality of the delivery and laying of asphalt material, prevents compactors from over-compacting certain road segments, increases the road's pavement longevity during the operational life cycle phase; refocuses the work tasks of the site managers, and reduces the construction budget and schedule. The system's ability to maneuver an asphalt roller during real-word operation also makes it an important step towards a fully automated asphalt compactor.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2015.12.128,Journal,Neurocomputing,scopus,2016-10-05,sciencedirect,Evaluation of Kinect2 based balance measurement,https://api.elsevier.com/content/abstract/scopus_id/84986569371,"In this paper, the balance measurement software based on Kinect2 sensor has been evaluated. Kinect2 sensor is used to analyze the body data tracked from the user and the user׳s center of mass (CoM) as well as its motion route on a plane has been obtained. The evaluation process includes three steps: (1) compare with golden standard balance measure platform intuitively; (2) compare with Wii balance board in numerical analysis level, and further improve it according to the consideration of BFP (body fat percentage) values of the users with different body types; (3) compare with Wii balance board with various locations of the user in the view of Kinect, the relative position of the user׳s feet and WBB, as well as the stance of the user. The evaluation results have verified the reliability of the balance measurement approach based on Kinect2 sensor.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijleo.2016.06.126,Journal,Optik,scopus,2016-10-01,sciencedirect,Development of a calibrating algorithm for Delta Robot's visual positioning based on artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/84978140749,"Delta robot with vision system can automatically control the end-actuator to accurately grasp moving objects on the conveyor belt. Establishment of the mapping relationship between the image feature space and the robot working space form a closed-loop chain for transformational link between the robot coordinate, camera coordinate and conveyor belt coordinate. The vision system calibration is a basic problem of robot vision research and implementation. The artificial neural networks (ANN) which has learning ability, adaptive ability and nonlinear function approximation ability can establish the nonlinear relationship between space points and pixel points to complete accurate calibration of the vision system. The convergence speed of calibration algorithm affects the real-time visual servo system. The calibration precision, generalization ability and calibration space of algorithm influence the robot grasping accuracy. Therefore, a new calibration technique for delta robot’s vision system was presented in this paper. The algorithm combines ANN with Faugeras vision system calibration technology. The setting of the initial value, network structure and the choice of the activation function is based on the model of Faugeras vision system calibration algorithm, which makes the actual output of the network closer to the target output. Experiments proved that this algorithm has higher calibration accuracy and generalization ability compared with the conventional calibration algorithm, as well as faster convergence speed compared with the conventional artificial neural network structure in the case of high calibration accuracy.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bica.2016.07.006,Journal,Biologically Inspired Cognitive Architectures,scopus,2016-07-01,sciencedirect,Analyzing and discussing primary creative traits of a robotic artist,https://api.elsevier.com/content/abstract/scopus_id/84994896174,"We present a robot aimed at producing a collage formed by a mix of photomontage and digital collage. The artwork is created after a visual and verbal interaction with a human user. The proposed system, through a cognitive architecture, allows the robot to manage the three different phases of the real-time artwork process: (i) taking inspiration from information captured during the postural and verbal interaction with the human user and from the analysis of his/her social web items; (ii) performing a creative process to obtain a model of the artwork; (iii) executing the creative collage composition and providing a significant title. The paper explains, primarily, how the creativity traits of the robot are implemented in the proposed architecture: how ideas are generated through an elaboration that is modulated by affective influences; how the personality and the artistic behavior are modeled by learning and guided by external evaluations; the motivation and the confidence evolution as a function of successes or failures.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.biosystems.2016.05.007,Journal,BioSystems,scopus,2016-07-01,sciencedirect,Robotic action acquisition with cognitive biases in coarse-grained state space,https://api.elsevier.com/content/abstract/scopus_id/84973440991,"Some of the authors have previously proposed a cognitively inspired reinforcement learning architecture (LS-Q) that mimics cognitive biases in humans. LS-Q adaptively learns under uniform, coarse-grained state division and performs well without parameter tuning in a giant-swing robot task. However, these results were shown only in simulations. In this study, we test the validity of the LS-Q implemented in a robot in a real environment. In addition, we analyze the learning process to elucidate the mechanism by which the LS-Q adaptively learns under the partially observable environment. We argue that the LS-Q may be a versatile reinforcement learning architecture, which is, despite its simplicity, easily applicable and does not require well-prepared settings.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2015.11.014,Journal,Applied Soft Computing Journal,scopus,2016-03-01,sciencedirect,Wavenet fuzzy PID controller for nonlinear MIMO systems: Experimental validation on a high-end haptic robotic interface,https://api.elsevier.com/content/abstract/scopus_id/84951836601,"A novel global PID control scheme for nonlinear MIMO systems is proposed and implemented for a robot as study case, this scheme is called AWFPID from its adaptive wavelet fuzzy PID control structure. Basically, it identifies inverse error dynamics using a radial basis neural network with daughter RASP1 wavelets activation function; its output is in cascaded with an infinite impulse response (IIR) filter to prune irrelevant signals and nodes as well as to recover a canonical form. Then, online adaptive fuzzy tuning of a discrete PID regulator is proposed, whose closed-loop guarantees global regulation for nonlinear dynamical plants. The wavelet network includes a fuzzy inference system for online tuning of learning rates. A real-time experimental study on a three degrees of freedom haptic interface, the PHANToM Premium 1.0A, highlights the regulation with smooth control effort without using the mathematical model of the robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2015.11.026,Journal,Neurocomputing,scopus,2016-02-12,sciencedirect,Digital implementations of thalamocortical neuron models and its application in thalamocortical control using FPGA for Parkinson's disease,https://api.elsevier.com/content/abstract/scopus_id/84959510221,"Due to the relay ability of sensory information and communication between cortical regions, the thalamocortical (TC) relay neuron plays an essential role in the therapy of Parkinson׳s disease. This paper first explores a series of efficient methods for the hardware implementation of TC relay neuron models, aiming to reproduce relevant biological behaviors and present appropriate feedback control in neural dynamics in thalamic systems. In addition, a modified two-dimensional TC neuron model is presented for convenient realization to decrease the complexity of the original model and promote the feasibility of the digital design, which shows significance for the large-scale network simulation of TC-based networks and the establishment of digital thalamus. A system-on-a-chip model-based control system is implemented on an FPGA using the modified TC neuron model, which is aimed at the real-time feedback control of tremor dominant Parkinsonian state. In this paper, the hardware syntheses and theoretical researches are given to illustrate the outstanding performance of the presented hardware implementation. The presented platform can be applied in both the brain-machine interface and the robotic control projects, and the proposed modular hardware framework can be extended to the real-time closed-loop treatments of other dyskinesia diseases.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2016.07.425,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,PlaNeural: Spiking Neural Networks that Plan,https://api.elsevier.com/content/abstract/scopus_id/85006365013,"PlaNeural is a spike-based neural network that has the ability to plan. The network is a spreading activation network implemented with Cell Assemblies; this combination has built a dynamic network of nodes that is able to interact with an environment and respond appropriately. PlaNeural uses Cell Assemblies to make decisions and plan - there is no pre-determined code managing the decision process that leads to planning. PlaNeural is the planning component of a virtual robot in a virtual environment. This paper describes PlaNeural's behaviour in two virtual environments, programmed independently of it; actions are completed in a closed-loop. PlaNeural was programmed in PyNN, executed with Nest and on a neuromorphic platform, SpiNNaker. PlaNeural has been tested on two environments and results show a successful performance; in both cases PlaNeural takes appropriate actions to fulfil user selected goals based on environmental changes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2016.07.192,Conference Proceeding,IFAC-PapersOnLine,scopus,2016-01-01,sciencedirect,Proactive Teaching of Mechatronics in Master Courses – Project Case Study,https://api.elsevier.com/content/abstract/scopus_id/84994890825,"University education of young people in very complex branches like robotics is nowadays an issue. Methods like e-learning, distance education etc. are implemented. The authors of the article consider that practice courses play an irreplaceable role in mechatronics education. The paper deals with description of internship concept of French Military Academy of Saint-Cyr for master degree students. A real system of robot arm manipulator playing a Tic Tac Toe game with a human is presented as a case study of a typical issue solved by the students.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2016.05.404,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,An evolutionary algorithm for autonomous robot navigation,https://api.elsevier.com/content/abstract/scopus_id/84978471421,"This paper presents an implementation of an evolutionary algorithm to control a robot with autonomous navigation in avoiding obstacles. The paper describes how the evolutionary system controls the sensors and motors in order to complete this task. A simulator was developed to test the algorithm and its configurations. The tests were performed in a simulated environment containing a set of barriers that were observed by means of a set of sensors. The solution obtained in the simulator was embedded in a real robot, which was tested in an arena containing obstacles. The robot was able to navigate and avoid the obstacles in this environment.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2015.07.017,Journal,Neural Networks,scopus,2015-11-01,sciencedirect,Cost-efficient FPGA implementation of basal ganglia and their Parkinsonian analysis,https://api.elsevier.com/content/abstract/scopus_id/84940021490,"The basal ganglia (BG) comprise multiple subcortical nuclei, which are responsible for cognition and other functions. Developing a brain–machine interface (BMI) demands a suitable solution for the real-time implementation of a portable BG. In this study, we used a digital hardware implementation of a BG network containing 256 modified Izhikevich neurons and 2048 synapses to reliably reproduce the biological characteristics of BG on a single field programmable gate array (FPGA) core. We also highlighted the role of Parkinsonian analysis by considering neural dynamics in the design of the hardware-based architecture. Thus, we developed a multi-precision architecture based on a precise analysis using the FPGA-based platform with fixed-point arithmetic. The proposed embedding BG network can be applied to intelligent agents and neurorobotics, as well as in BMI projects with clinical applications. Although we only characterized the BG network with Izhikevich models, the proposed approach can also be extended to more complex neuron models and other types of functional networks.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2015.06.015,Journal,Journal of Neuroscience Methods,scopus,2015-09-01,sciencedirect,Watching from a distance: A robotically controlled laser and real-time subject tracking software for the study of conditioned predator/prey-like interactions,https://api.elsevier.com/content/abstract/scopus_id/84936742109,"Background
                  The physical distance between predator and prey is a primary determinant of behavior, yet few paradigms exist to study this reliably in rodents.
               
                  New method
                  The utility of a robotically controlled laser for use in a predator–prey-like (PPL) paradigm was explored for use in rats. This involved the construction of a robotic two-dimensional gimbal to dynamically position a laser beam in a behavioral test chamber. Custom software was used to control the trajectory and final laser position in response to user input on a console. The software also detected the location of the laser beam and the rodent continuously so that the dynamics of the distance between them could be analyzed. When the animal or laser beam came within a fixed distance the animal would either be rewarded with electrical brain stimulation or shocked subcutaneously.
               
                  Results
                  Animals that received rewarding electrical brain stimulation could learn to chase the laser beam, while animals that received aversive subcutaneous shock learned to actively avoid the laser beam in the PPL paradigm. Mathematical computations are presented which describe the dynamic interaction of the laser and rodent.
               
                  Comparison with existing methods
                  The robotic laser offers a neutral stimulus to train rodents in an open field and is the first device to be versatile enough to assess distance between predator and prey in real time.
               
                  Conclusions
                  With ongoing behavioral testing this tool will permit the neurobiological investigation of predator/prey-like relationships in rodents, and may have future implications for prosthetic limb development through brain–machine interfaces.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2015.01.002,Journal,Robotics and Autonomous Systems,scopus,2015-09-01,sciencedirect,Autonomous learning of disparity-vergence behavior through distributed coding and population reward: Basic mechanisms and real-world conditioning on a robot stereo head,https://api.elsevier.com/content/abstract/scopus_id/84930764976,"A robotic system implementation that exhibits autonomous learning capabilities of effective control for vergence eye movements is presented. The system, directly relying on a distributed (i.e. neural) representation of binocular disparity, shows a large tolerance to the inaccuracies of real stereo heads and to the changeable environment. The proposed approach combines early binocular vision mechanisms with basic learning processes, such as synaptic plasticity and reward modulation. The computational substrate consists of a network of modeled V1 complex cells that act as oriented binocular disparity detectors. The resulting population response, besides implicit binocular depth cues about the environment, also provides a global signal (i.e. the overall activity of the population itself) to describe the state of the system and thus its deviation from the desired vergence position. The proposed network, by taking into account the modification of its internal state as a consequence of the action performed, evolves following a differential Hebbian rule. The overall activity of the population is exploited to derive an intrinsic signal that drives the weights update. Exploiting this signal implies a maximization of the population activity itself, thus providing an highly effective reward for the developing of a stable and accurate vergence behavior. The role of the different orientations in the learning process is evaluated separately against the whole population, evidencing that the interplay among the differently oriented channels allows a faster learning capability and a more accurate control. The efficacy of the proposed intrinsic reward signal is thus comparatively assessed against the ground-truth signal (the actual disparity) providing equivalent results, and thus validating the approach. Trained in a simulated environment, the proposed network, is able to cope with vergent geometry and thus to learn effective vergence movements for static and moving visual targets. Experimental tests with real robot stereo pairs demonstrate the capability of the architecture not just to directly learn from the environment, but to adapt the control to the stimulus characteristics.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chb.2015.03.062,Journal,Computers in Human Behavior,scopus,2015-09-01,sciencedirect,Comparative study of soft computing techniques for mobile robot navigation in an unknown environment,https://api.elsevier.com/content/abstract/scopus_id/84927168200,"An autonomous mobile robot operating in an unstructured environment must be able to deal with dynamic changes of the environment. Navigation and control of a mobile robot in an unstructured environment are one of the most challenging problems. Fuzzy logic control is a useful tool in the field of navigation of mobile robot. In this research, fuzzy logic controller is optimized by integrating fuzzy logic with other soft computing techniques like genetic algorithm, neural networks, and Particle Swarm Optimization (PSO). Soft computing techniques are used in this work to tune the membership function parameters of fuzzy logic controller to improve the navigation performance. Four methods have been designed and implemented: manually constructed fuzzy logic (M-Fuzzy), fuzzy logic with genetic algorithm (GA-Fuzzy), fuzzy logic with neural network (Neuro-Fuzzy), and fuzzy logic with PSO (PSO-Fuzzy). The performances of these approaches are compared through computer simulations and experiment number of scenarios using Khepera III mobile robot platform. Hybrid fuzzy logic controls with soft computing techniques are found to be most efficient for mobile robot navigation. The GA-Fuzzy technique is found to perform better than the other techniques in most of the test scenarios in terms of travelling time and average speed. The performances of both PSO-Fuzzy and Neuro-Fuzzy are found to be better than the other methods in terms of distance travelled. In terms of bending energy, the PSO-Fuzzy and Neuro-Fuzzy are found to be better in simulation results. Although, the M-Fuzzy is found to be better using real experimental results. Hence, the most important system parameter will dictate which of the four methods to use.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bica.2015.06.007,Journal,Biologically Inspired Cognitive Architectures,scopus,2015-07-01,sciencedirect,"NARLE: Neurocognitive architecture for the autonomous task recognition, learning, and execution",https://api.elsevier.com/content/abstract/scopus_id/84941177769,"Robots controlled by the state of the art cognitive architectures are still far behind animals in their capabilities to learn complex skills and autonomously adapt to unexpected circumstances. The neurocognitive architecture proposed in this paper addresses the problem of learning and execution of hierarchical behaviors and complex skills. Learning is addressed both on the level of individual elementary behaviors and goal-directed sequences of actions. The proposed architecture comprises a Dynamic Neural Fields (DNFs) implementation of the low-level elementary behaviors and a Functional System Network (FSN) tying these behaviors in goal-directed sequences. The DNF framework enables a continuous, dynamical representation of perceptual features and motor parameters, which may be directly coupled to the robot’s sensors and motors. Attractor states and instabilities of the DNFs account for segregation of cognitive states and mark behaviorally relevant events in the continuous flow of sensorimotor dynamics. The FSN, in its turn, comprises dynamical elements that can be arranged in a multilayered network by a learning process, in which new layers and elementary behaviors are added on demand. In our architecture, the FSN controls adaptation processes in the already acquired neural-dynamic elementary behaviors, as well as formation of new elementary behaviors. Combination of the DNF and FSN frameworks in a neurocognitive architecture NARLE enables pervasive learning both on the level of individual behaviors and goal-directed sequence, contributing to the progress towards more adaptive intelligent robotic systems, capable to learn new tasks and extend their behavioral repertoire in stochastic real-world environments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2015.06.036,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-05-01,sciencedirect,Dexrov: Dexterous undersea inspection and maintenance in presence of communication latencies,https://api.elsevier.com/content/abstract/scopus_id/84992521813,"Underwater inspection and maintenance (e.g. in the oil & gas industry) are demanding and costly activities for which ROV based setups are often deployed in addition or in substitution to deep divers - contributing to operations risks and costs cutting. However the operation of a ROV requires significant off-shore dedicated manpower to handle and operate the robotic platform. In order to reduce the burden of operations, DexROV proposes to work out more cost effective and time efficient ROV operations, where manned support is in a large extent delocalized onshore (i.e. from a ROV control center), possibly at a large distance from the actual operations, relying on satellite communications. The proposed scheme also makes provision for advanced dexterous manipulation capabilities, exploiting human expertise when deemed useful. The outcomes of the project will be integrated and evaluated in a series of tests and evaluation campaigns, culminating with a realistic deep sea (1,300 meters) trial.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2014.05.001,Journal,Information Sciences,scopus,2015-02-10,sciencedirect,Multiple chaotic central pattern generators with learning for legged locomotion and malfunction compensation,https://api.elsevier.com/content/abstract/scopus_id/84922243705,"An originally chaotic system can be controlled into various periodic dynamics. When it is implemented into a legged robot’s locomotion control as a central pattern generator (CPG), sophisticated gait patterns arise so that the robot can perform various walking behaviors. However, such a single chaotic CPG controller has difficulties dealing with leg malfunction. Specifically, in the scenarios presented here, its movement permanently deviates from the desired trajectory. To address this problem, we extend the single chaotic CPG to multiple CPGs with learning. The learning mechanism is based on a simulated annealing algorithm. In a normal situation, the CPGs synchronize and their dynamics are identical. With leg malfunction or disability, the CPGs lose synchronization leading to independent dynamics. In this case, the learning mechanism is applied to automatically adjust the remaining legs’ oscillation frequencies so that the robot adapts its locomotion to deal with the malfunction. As a consequence, the trajectory produced by the multiple chaotic CPGs resembles the original trajectory far better than the one produced by only a single CPG. The performance of the system is evaluated first in a physical simulation of a quadruped as well as a hexapod robot and finally in a real six-legged walking machine called AMOSII. The experimental results presented here reveal that using multiple CPGs with learning is an effective approach for adaptive locomotion generation where, for instance, different body parts have to perform independent movements for malfunction compensation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2015.11.171,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-01-01,sciencedirect,Hierarchical Hybrid Control with Classical Planning and Trajectory Optimization,https://api.elsevier.com/content/abstract/scopus_id/84983197460,"One method of control of cyberphysical systems, particularly intelligent mobile robots, involves a hierarchy of high-level classical planning and low-level trajectory optimization. We present a new technique to incorporate trajectory costs in a high-level classical planning problem (CPP). The proposed approach is particularly suited to leverage existing algorithms for solving CPPs and, independently, algorithms for trajectory optimization. To this end, we introduce a family of graphs called lifted planning graphs parametrized by an integer H, and we map paths in these graphs to solutions of the CPP. We show that the overall cost of a high-level plan is a nonincreasing function of H, and that there exists a finite H for which an optimal path in the lifted planning graph is associated with the optimal solution of the CPP. For computational speed and future real-time implementation, we discuss incremental modification of paths in the lifted planning graphs for increasing values of H. We illustrate the proposed ideas with a numerical simulation example involving classical planning for Dubins vehicle routing.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2015.09.198,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,An Improved eXtended Classifier System for the Real-time-input Real-time-output (XCSRR) Stability Control of a Biped Robot,https://api.elsevier.com/content/abstract/scopus_id/84962685209,"In this paper a revised reinforcement learning method is presented for stability control problems with real-value inputs and outputs. The revised eXtended Classifier System for Real-input and Real-output (XCSRR) controller is designed, which is capable of working at fully real-value environment such as stability control of robots. XCSRR is a novel approach to enhance the performance of classifier systems for more practical problems than systems with merely binary behaviour. As a case study, we use XCSRR to control the stability of a biped robot, which is subjected to unknown external forces that would disturb the robot equilibrium. The external forces and the dynamics of the upper body of the biped robot are modelled in MATLAB software to train the XCSRR controller. Theoretical and experimental results of the learning behaviour and the performance of stability control on the robot demonstrate the strength and efficiency of the proposed new approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bica.2015.04.008,Journal,Biologically Inspired Cognitive Architectures,scopus,2015-01-01,sciencedirect,Automatic navigation of wall following mobile robot using Adaptive Resonance Theory of Type-1,https://api.elsevier.com/content/abstract/scopus_id/84960798237,"The automatic navigation of wall following robot is playing important role in various real world tasks such as underwater exploration, unmanned flight, and in automotive industries based on its computational complexity. In this work, a novel navigation approach based on biologically inspired neural network, known as “Adaptive Resonance Theory-1” which was proposed by Carpenter and Grossberg, has been implemented and investigated for navigation of wall following mobile robots. The proposed navigation algorithm is successfully tested with three sensor reading datasets obtained from clockwise navigation of SCITOS G5 mobile robot. Test decision accuracy (%), and simulation time were used as performance analysis parameters for the proposed algorithm and it has been found that the present work can achieve 99.59% of maximum decision accuracy.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2015.04.066,Journal,Neurocomputing,scopus,2015-01-01,sciencedirect,A general CPG network and its implementation on the microcontroller,https://api.elsevier.com/content/abstract/scopus_id/84952631900,"Over the last few years, it has been confirmed by the biologists that Central Pattern Generator (CPG) is the key mechanism of generating adaptive and versatile locomotion in animals. This gives a new inspiration of locomotion control for robots. Although the design of CPG controller using coupled oscillators has been proposed previously, it cannot comprehensively reproduce different rhythmic motion along with smooth transitions to mimic the versatility of animal locomotion. To tackle this problem, we propose a general CPG model emphasizing on its stability analysis, smooth transition and implementation architecture. Global exponential stability of the model is derived by using strict mathematical analysis. Transitions between different oscillating forms are also smooth, and the implementation architecture has low computational cost, thus suitable for microcontrollers. Moreover, all control parameters not only have clear relationships with the physical outputs, but also can be modified online. Both virtual and real robotic fish are developed to verify the effectiveness of our CPG controller together with the proposed implementation architecture, through the experiments of four locomotion gaits and three transitions among them.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2015.07.004,Journal,Neural Networks,scopus,2015-01-01,sciencedirect,Neuromorphic implementations of neurobiological learning algorithms for spiking neural networks,https://api.elsevier.com/content/abstract/scopus_id/84945426263,"The application of biologically inspired methods in design and control has a long tradition in robotics. Unlike previous approaches in this direction, the emerging field of neurorobotics not only mimics biological mechanisms at a relatively high level of abstraction but employs highly realistic simulations of actual biological nervous systems. Even today, carrying out these simulations efficiently at appropriate timescales is challenging. Neuromorphic chip designs specially tailored to this task therefore offer an interesting perspective for neurorobotics. Unlike Von Neumann CPUs, these chips cannot be simply programmed with a standard programming language. Like real brains, their functionality is determined by the structure of neural connectivity and synaptic efficacies. Enabling higher cognitive functions for neurorobotics consequently requires the application of neurobiological learning algorithms to adjust synaptic weights in a biologically plausible way. In this paper, we therefore investigate how to program neuromorphic chips by means of learning. First, we provide an overview over selected neuromorphic chip designs and analyze them in terms of neural computation, communication systems and software infrastructure. On the theoretical side, we review neurobiological learning techniques. Based on this overview, we then examine on-die implementations of these learning algorithms on the considered neuromorphic chips. A final discussion puts the findings of this work into context and highlights how neuromorphic hardware can potentially advance the field of autonomous robot systems. The paper thus gives an in-depth overview of neuromorphic implementations of basic mechanisms of synaptic plasticity which are required to realize advanced cognitive capabilities with spiking neural networks.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-800881-2.00006-2,Book,Household Service Robotics,scopus,2015-01-01,sciencedirect,A Household Service Robot with a Cellphone Interface,https://api.elsevier.com/content/abstract/scopus_id/84944415545,"In this chapter, an efficient and low-cost cellphone-commandable mobile manipulation system is described. Aiming at home use and elderly caring, this system can be easily commanded through a common cellphone network to efficiently grasp objects in a household environment, utilizing several low-cost off-the-shelf devices. Unlike the visual servo technology using a high quality vision system with the associated high cost, the household-service robot would not be able to afford such a high quality vision servo system, and thus it is essential to use some low-cost devices. However, it is extremely challenging to create such a vision system with precise localization, as well as motion control. To tackle this challenge, we developed a real-time vision system with which a reliable grasping algorithm combining machine vision, robotic kinematics and motor control technology is presented. After the target is captured by the arm camera, the arm camera keeps tracking the target while the arm keeps stretching until the end effector reaches the target. However, if the target is not captured by the arm camera, the arm will make a move to help the arm camera capture the target under the guidance of the head camera. This algorithm is implemented on two robot systems: one with a fixed base and another with a mobile base. The results demonstrate the feasibility and efficiency of the algorithm and system we developed, and our study shows the significance of developing a service robot in a modern household environment.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-800881-2.00019-0,Book,Household Service Robotics,scopus,2015-01-01,sciencedirect,Implementation of Cognitive Controls for Robots,https://api.elsevier.com/content/abstract/scopus_id/84944402000,"Engineers have long used control systems utilizing models and feedback loops to control real-world systems. Limitations of model-based controls led to a generation of intelligent control techniques such as adaptive and fuzzy controls. The human brain, on the other hand, is known to process a variety of inputs in parallel, ignoring distractions to focus on the task in hand. This process, known as cognitive control in psychology, is unique to humans and some higher classes of animals. We are interested in implementing such cognitive control functionality in robots. This chapter tries to answer the following question: How could cognitive control functionality be implemented in HAM-inspired robots?",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2015.05.250,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Pso-based distributed algorithm for dynamic task allocation in a robotic swarm,https://api.elsevier.com/content/abstract/scopus_id/84939163993,"Dynamic task allocation in a robotic swarm is a necessary process for proper management of the swarm. It allows the distribution of the identified tasks to be performed, among the swarm of robots, in such a way that a pre-defined proportion of execution of those tasks is achieved. In this context, there is no central unit to take care of the task allocation. So any algorithm proposal must be distributed, allowing every, and each robot in the swarm to identify the task it must perform. This paper proposes a distributed control algorithm to implement dynamic task allocation in a swarm robotics environment. The algorithm is inspired by the particle swarm optimization. In this context, each robot that integrates the swarm must run the algorithm periodically in order to control the underlying actions and decisions. The algorithm was implemented on ELISA III real swarm robots and extensively tested. The algorithm is effective and the corresponding performance is promising.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2014.10.001,Journal,Neural Networks,scopus,2015-01-01,sciencedirect,Trends in extreme learning machines: A review,https://api.elsevier.com/content/abstract/scopus_id/84908682236,"Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of ELM from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to ELM which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, ELM has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, ELM have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in ELM together with its future perspectives.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2014.09.021,Journal,Applied Soft Computing Journal,scopus,2015-01-01,sciencedirect,Learning fuzzy controllers in mobile robotics with embedded preprocessing,https://api.elsevier.com/content/abstract/scopus_id/84908428493,"The automatic design of controllers for mobile robots usually requires two stages. In the first stage, sensorial data are preprocessed or transformed into high level and meaningful values of variables which are usually defined from expert knowledge. In the second stage, a machine learning technique is applied to obtain a controller that maps these high level variables to the control commands that are actually sent to the robot. This paper describes an algorithm that is able to embed the preprocessing stage into the learning stage in order to get controllers directly starting from sensorial raw data with no expert knowledge involved. Due to the high dimensionality of the sensorial data, this approach uses Quantified Fuzzy Rules (QFRs), that are able to transform low-level input variables into high-level input variables, reducing the dimensionality through summarization. The proposed learning algorithm, called Iterative Quantified Fuzzy Rule Learning (IQFRL), is based on genetic programming. IQFRL is able to learn rules with different structures, and can manage linguistic variables with multiple granularities. The algorithm has been tested with the implementation of the wall-following behavior both in several realistic simulated environments with different complexity and on a Pioneer 3-AT robot in two real environments. Results have been compared with several well-known learning algorithms combined with different data preprocessing techniques, showing that IQFRL exhibits a better and statistically significant performance. Moreover, three real world applications for which IQFRL plays a central role are also presented: path and object tracking with static and moving obstacles avoidance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2013.03.060,Journal,Neurocomputing,scopus,2014-05-20,sciencedirect,Autonomous UAV based search operations using constrained sampling evolutionary algorithms,https://api.elsevier.com/content/abstract/scopus_id/84896707806,"This paper introduces and studies the application of Constrained Sampling Evolutionary Algorithms in the framework of an UAV based search and rescue scenario. These algorithms have been developed as a way to harness the power of Evolutionary Algorithms (EA) when operating in complex, noisy, multimodal optimization problems and transfer the advantages of their approach to real time real world problems that can be transformed into search and optimization challenges. These types of problems are denoted as Constrained Sampling problems and are characterized by the fact that the physical limitations of reality do not allow for an instantaneous determination of the fitness of the points present in the population that must be evolved. A general approach to address these problems is presented and a particular implementation using Differential Evolution as an example of CS-EA is created and evaluated using teams of UAVs in search and rescue missions. The results are compared to those of a Swarm Intelligence based strategy in the same type of problem as this approach has been widely used within the UAV path planning field in different variants by many authors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2013.12.003,Journal,Engineering Applications of Artificial Intelligence,scopus,2014-02-01,sciencedirect,Hardware opposition-based PSO applied to mobile robot controllers,https://api.elsevier.com/content/abstract/scopus_id/84892858663,"Adaptation of mobile robot controllers commonly requires the computation of optimal points of operation. Specifically, for miniature mobile robots with serious computational limitations, that are typical of embedded systems, one of the main challenges is the adaptation of efficient computational methods in order to find solutions of complex optimization problems, which demand large execution times. This drawback compels the design of high-performance parallel optimization algorithms which must run over embedded system platforms. This paper describes how adequate hardware implementations of the Particle Swarm Optimization (PSO) algorithm can be useful for real time adaptation of mobile robot controllers. For achieving this, a new architecture is proposed, which is based on an FPGA implementation of the opposition-based learning (OBL) approach applied to the PSO (for short HPOPSO), and which explores the intrinsic parallelism of this algorithm in order to adjust the weights of a neural robot controller in real time according to desired behaviors. The proposed HPOPSO was applied to the learning-from-demonstration problem in which a teacher performs executions of the desired behavior. Effectiveness of the proposed architecture was demonstrated by numerical simulations and the feasibility of the adaptive behavior of the neural robot controller was confirmed for two obstacle avoidance case studies that were preserved when one or more failures on the distance sensors occur. The HPOPSO, which uses the OBL technique, improves the quality of the solutions in comparison with the standard PSO. Comparisons of the adaptation time between hardware and software approaches have demonstrated the suitability of the FPGA implementation of the proposed HPOPSO for attending specific requirements of embedded system applications.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patrec.2013.05.019,Journal,Pattern Recognition Letters,scopus,2014-01-15,sciencedirect,Towards a real-time interface between a biomimetic model of sensorimotor cortex and a robotic arm,https://api.elsevier.com/content/abstract/scopus_id/84893704174,"Brain–machine interfaces can greatly improve the performance of prosthetics. Utilizing biomimetic neuronal modeling in brain machine interfaces (BMI) offers the possibility of providing naturalistic motor-control algorithms for control of a robotic limb. This will allow finer control of a robot, while also giving us new tools to better understand the brain’s use of electrical signals. However, the biomimetic approach presents challenges in integrating technologies across multiple hardware and software platforms, so that the different components can communicate in real-time. We present the first steps in an ongoing effort to integrate a biomimetic spiking neuronal model of motor learning with a robotic arm. The biomimetic model (BMM) was used to drive a simple kinematic two-joint virtual arm in a motor task requiring trial-and-error convergence on a single target. We utilized the output of this model in real time to drive mirroring motion of a Barrett Technology WAM robotic arm through a user datagram protocol (UDP) interface. The robotic arm sent back information on its joint positions, which was then used by a visualization tool on the remote computer to display a realistic 3D virtual model of the moving robotic arm in real time. This work paves the way towards a full closed-loop biomimetic brain-effector system that can be incorporated in a neural decoder for prosthetic control, to be used as a platform for developing biomimetic learning algorithms for controlling real-time devices.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2014.08.002,Journal,Robotics and Autonomous Systems,scopus,2014-01-01,sciencedirect,Integrated neural and robotic simulations. Simulation of cerebellar neurobiological substrate for an object-oriented dynamic model abstraction process,https://api.elsevier.com/content/abstract/scopus_id/84908424049,"Experimental studies of the Central Nervous System (CNS) at multiple organization levels aim at understanding how information is represented and processed by the brain’s neurobiological substrate. The information processed within different neural subsystems is neurocomputed using distributed and dynamic patterns of neural activity. These emerging patterns can be hardly understood by merely taking into account individual cell activities. Studying how these patterns are elicited in the CNS under specific behavioral tasks has become a groundbreaking research topic in system neuroscience. This methodology of synthetic behavioral experimentation is also motivated by the concept of embodied neuroscience, according to which the primary goal of the CNS is to solve/facilitate the body–environment interaction.
                  With the aim to bridge the gap between system neuroscience and biological control, this paper presents how the CNS neural structures can be connected/integrated within a body agent; in particular, an efficient neural simulator based on EDLUT (Ros et al., 2006) has been integrated within a simulated robotic environment to facilitate the implementation of object manipulating closed loop experiments (action–perception loop). This kind of experiment allows the study of the neural abstraction process of dynamic models that occurs within our neural structures when manipulating objects.
                  The neural simulator, communication interfaces, and a robot platform have been efficiently integrated enabling real time simulations. The cerebellum is thought to play a crucial role in human-body interaction with a primary function related to motor control which makes it the perfect candidate to start building an embodied nervous system as illustrated in the simulations performed in this work.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2013.12.003,Journal,Neural Networks,scopus,2014-01-01,sciencedirect,Lagrangian support vector regression via unconstrained convex minimization,https://api.elsevier.com/content/abstract/scopus_id/84891335988,"In this paper, a simple reformulation of the Lagrangian dual of the 2-norm support vector regression (SVR) is proposed as an unconstrained minimization problem. This formulation has the advantage that its objective function is strongly convex and further having only 
                        m
                      variables, where 
                        m
                      is the number of input data points. The proposed unconstrained Lagrangian SVR (ULSVR) is solvable by computing the zeros of its gradient. However, since its objective function contains the non-smooth ‘plus’ function, two approaches are followed to solve the proposed optimization problem: (i) by introducing a smooth approximation, generate a slightly modified unconstrained minimization problem and solve it; (ii) solve the problem directly by applying generalized derivative. Computational results obtained on a number of synthetic and real-world benchmark datasets showing similar generalization performance with much faster learning speed in accordance with the conventional SVR and training time very close to least squares SVR clearly indicate the superiority of ULSVR solved by smooth and generalized derivative approaches.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2013.05.017,Journal,Applied Soft Computing Journal,scopus,2014-01-01,sciencedirect,A hybrid noise suppression filter for accuracy enhancement of commercial speech recognizers in varying noisy conditions,https://api.elsevier.com/content/abstract/scopus_id/84888294149,"Commercial speech recognizers have made possible many speech control applications such as wheelchair, tone-phone, multifunctional robotic arms and remote controls, for the disabled and paraplegic. However, they have a limitation in common in that recognition errors are likely to be produced when background noise surrounds the spoken command, thereby creating potential dangers for the disabled if recognition errors exist in the control systems. In this paper, a hybrid noise suppression filter is proposed to interface with the commercial speech recognizers in order to enhance the recognition accuracy under variant noisy conditions. It intends to decrease the recognition errors when the commercial speech recognizers are working under a noisy environment. It is based on a sigmoid function which can effectively enhance noisy speech using simple computational operations, while a robust estimator based on an adaptive-network-based fuzzy inference system is used to determine the appropriate operational parameters for the sigmoid function in order to produce effective speech enhancement under variant noisy conditions. The proposed hybrid noise suppression filter has the following advantages for commercial speech recognizers: (i) it is not possible to tune the inbuilt parameters on the commercial speech recognizers in order to obtain better accuracy; (ii) existing noise suppression filters are too complicated to be implemented for real-time speech recognition; and (iii) existing sigmoid function based filters can operate only in a single-noisy condition, but not under varying noisy conditions. The performance of the hybrid noise suppression filter was evaluated by interfacing it with a commercial speech recognizer, commonly used in electronic products. Experimental results show that improvement in terms of recognition accuracy and computational time can be achieved by the hybrid noise suppression filter when the commercial recognizer is working under various noisy environments in factories.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2013.01.019,Journal,Neural Networks,scopus,2013-11-01,sciencedirect,Realtime cerebellum: A large-scale spiking network model of the cerebellum that runs in realtime using a graphics processing unit,https://api.elsevier.com/content/abstract/scopus_id/84884150994,"The cerebellum plays an essential role in adaptive motor control. Once we are able to build a cerebellar model that runs in realtime, which means that a computer simulation of 1 s in the simulated world completes within 1 s in the real world, the cerebellar model could be used as a realtime adaptive neural controller for physical hardware such as humanoid robots. In this paper, we introduce “Realtime Cerebellum (RC)”, a new implementation of our large-scale spiking network model of the cerebellum, which was originally built to study cerebellar mechanisms for simultaneous gain and timing control and acted as a general-purpose supervised learning machine of spatiotemporal information known as reservoir computing, on a graphics processing unit (GPU). Owing to the massive parallel computing capability of a GPU, RC runs in realtime, while reproducing qualitatively the same simulation results of the Pavlovian delay eyeblink conditioning with the previous version. RC is adopted as a realtime adaptive controller of a humanoid robot, which is instructed to learn a proper timing to swing a bat to hit a flying ball online. These results suggest that RC provides a means to apply the computational power of the cerebellum as a versatile supervised learning machine towards engineering applications.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bica.2013.07.009,Journal,Biologically Inspired Cognitive Architectures,scopus,2013-10-01,sciencedirect,Emotional biologically inspired cognitive architecture,https://api.elsevier.com/content/abstract/scopus_id/84883206490,"Human-like artificial emotional intelligence is vital for integration of future robots into the human society. This work introduces a general framework for representation and processing of emotional contents in a cognitive architecture, called “emotional biologically inspired cognitive architecture” (eBICA). Unlike in previous attempts, in this framework emotional elements are added virtually to all cognitive representations and processes by modifying the main building blocks of the prototype architectures. The key elements are appraisals associated as attributes with schemas and mental states, moral schemas that control patterns of appraisals and represent social emotions, and semantic spaces that give values to appraisals. Proposed principles are tested in an experiment involving human subjects and virtual agents, based on a simple paradigm in imaginary virtual world. It is shown that with moral schemas, but probably not without them, eBICA can account for human behavior in the selected paradigm. The model sheds light on clustering of social emotions and allows for their elegant mathematical description. The new framework will be suitable for implementation of believable emotional intelligence in artifacts, necessary for emotionally informed behavior, collaboration of virtual partners with humans, and self-regulated learning of virtual agents.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2013.04.005,Journal,Neural Networks,scopus,2013-09-01,sciencedirect,FPGA implementation of a configurable neuromorphic CPG-based locomotion controller,https://api.elsevier.com/content/abstract/scopus_id/84880792738,"Neuromorphic engineering is a discipline devoted to the design and development of computational hardware that mimics the characteristics and capabilities of neuro-biological systems. In recent years, neuromorphic hardware systems have been implemented using a hybrid approach incorporating digital hardware so as to provide flexibility and scalability at the cost of power efficiency and some biological realism. This paper proposes an FPGA-based neuromorphic-like embedded system on a chip to generate locomotion patterns of periodic rhythmic movements inspired by Central Pattern Generators (CPGs). The proposed implementation follows a top-down approach where modularity and hierarchy are two desirable features. The locomotion controller is based on CPG models to produce rhythmic locomotion patterns or gaits for legged robots such as quadrupeds and hexapods. The architecture is configurable and scalable for robots with either different morphologies or different degrees of freedom (DOFs). Experiments performed on a real robot are presented and discussed. The obtained results demonstrate that the CPG-based controller provides the necessary flexibility to generate different rhythmic patterns at run-time suitable for adaptable locomotion.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.suronc.2012.12.003,Journal,Surgical Oncology,scopus,2013-06-01,sciencedirect,"Artificial interfaces (""AI"") in surgery: Historic development, current status and program implementation in the public health sector",https://api.elsevier.com/content/abstract/scopus_id/84878893463,"The past two decades have seen considerable advances in the application of artificial interfaces (AI) in surgery. Several have been developed including AESOP (Automated Endoscopic System for Optimal Positioning), Zeus and the Da Vinci Surgical System (DVSS). Whilst each has advantages DVSS is being used increasingly across multiple surgical specialities. These developments generate many challenges in an era where the emphasis is increasingly on safer and cost-effective surgery. Whilst the role of DVSS is firmly established in urologic and gynaecologic surgery, the role of DVSS in gastrointestinal surgery is evolving. Recent data indicate that it is at least as oncologically effective, whilst providing numerous benefits (e.g. reduced conversion and complication rates) over traditional laparoscopic approaches. The increasing adoption of AI/DVSS worldwide places institutes and health sectors under increasing pressure to adopt and develop such programs. This article provides (1) an update on the current status of AI in surgery in general and in colorectal surgery and (2) an appraisal of the cost implications of the establishment and implementation of AI/DVSS–based provisions in the public health sector. The numerous challenges faced generate many opportunities in the implementation of present and future surgical technologies.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2012.12.005,Journal,Robotics and Autonomous Systems,scopus,2013-05-01,sciencedirect,A survey of bio-inspired robotics hands implementation: New directions in dexterous manipulation,https://api.elsevier.com/content/abstract/scopus_id/84875695547,"Recently, significant advances have been made in ROBOTICS, ARTIFICIAL INTELLIGENCE and other COGNITIVE related fields, allowing to make much sophisticated biomimetic robotics systems. In addition, enormous number of robots have been designed and assembled, explicitly realize biological oriented behaviors. Towards much skill behaviors and adequate grasping abilities (i.e. ARTICULATION and DEXTEROUS MANIPULATION), a new phase of dexterous hands have been developed recently with biomimetically oriented and bio-inspired functionalities. In this respect, this manuscript brings a detailed survey of biomimetic based dexterous robotics multi-fingered hands. The aim of this survey, is to find out the state of the art on dexterous robotics end-effectors, known in literature as (ROBOTIC HANDS) or (DEXTEROUS MULTI-FINGERED) robot hands. Hence, this review finds such biomimetic approaches using a framework that permits for a common description of biological and technical based hand manipulation behavior. In particular, the manuscript focuses on a number of developments that have been taking place over the past two decades, and some recent developments related to this biomimetic field of research. In conclusions, the study found that, there are rich research efforts in terms of KINEMATICS, DYNAMICS, MODELING and CONTROL methodologies. The survey is also indicating that, the topic of biomimetic inspired robotics systems make significant contributions to robotics hand design, in four main directions for future research. First, they provide a genuine world test of models of biologically inspired hand designs and dexterous manipulation behaviors. Second, they provide novel manipulation articulations and mechanisms available for industrial and domestic uses, most notably in the field of human like hand design and real world applications. Third, this survey has also indicated that, there are quite large number of attempts to acquire biologically inspired hands. These attempts were almost successful, where they exposed more novel ideas for further developments. Such inspirations were directed towards a number of topics related (HAND MECHANICS AND DESIGN), (HAND TACTILE SENSING), (HAND FORCE SENSING), (HAND SOFT ACTUATION) and (HAND CONFIGURATION AND TOPOLOGY). FOURTH, in terms of employing AI related sciences and cognitive thinking, it was also found that, rare and exceptional research attempts were directed towards the employment of biologically inspired thinking, i.e. (AI, BRAIN AND COGNITIVE SCIENCES) for hand upper control and towards much sophisticated dexterous movements. Throughout the study, it has been found there are number of efforts in terms of mechanics and hand designs, tactical sensing, however, for hand soft actuation, it seems this area of research is still far away from having a realistic muscular type fingers and hand movements.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2012.07.012,Journal,Computers and Electrical Engineering,scopus,2013-02-01,sciencedirect,Bent fingers' angle calculation using supervised ANN to control electro-mechanical robotic hand,https://api.elsevier.com/content/abstract/scopus_id/84876287763,"The shape of human hand is such that it can perform many tedious tasks easily. It can reach narrow places and can perform difficult operations. It can bend its fingers at different angles to pick or hold different objects and apply force via fingers or palm area. It is very helpful in many difficult applications. However, there is risk of injury to the human hand, or even life in dangerous operations. It is not advisable to gamble of human body parts for applications like land mine removal. Hence, there is a need of a robotic hand which can perform the same operation as a human hand does in real time. This paper discusses a vision-based technique of controlling a robotic hand which has human hand like joints in fingers. The user has to show a gesture to the system with bare hand without any limitation on hand direction and the robotic hand would mimic that gesture. The positions of human hand fingers were calculated using supervised Artificial Neural Network. The preprocessing made the whole algorithm faster by cropping the region of interest from input image frame. The gesture was extracted from the input image and fingertips, centre of palm were detected. The animated simulation of robotic hand is done in Blender® software.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1533/9780857093967.1.208,Book,Joining Textiles: Principles and Applications,scopus,2013-01-01,sciencedirect,Intelligent sewing systems for garment automation and robotics,https://api.elsevier.com/content/abstract/scopus_id/84903011824,"Sewing machine interactions at different speeds have been used to construct qualitative rules mapping fabric properties to optimum sewing machine settings for intelligent sewing machines. the inference procedures of fuzzy logic have been implemented in a neural network to allow for optimisation of output membership functions and, subsequently, self-learning. the technique is successfully applied to develop intelligent sewing machines and further implemented in textile and garment manufacturing. An intelligent manufacturing environment has been put forward in which fabric properties predict the sewability of any fabric, determine the minimum change of fabric properties required, and control in real time the stitching of a garment by using the feedback closed loop of the Neuro-Fuzzy model. the system has been successfully tried in an industrial setting. optimum settings were achieved under static and dynamic machine conditions, including for the properties of difficult fabrics and compensation for mishandling by the operator over the speed range of the sewing machine.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2013.05.187,Conference Proceeding,Procedia Computer Science,scopus,2013-01-01,sciencedirect,Comparing support vector machines and artificial neural networks in the recognition of steering angle for driving of mobile robots through paths in plantations,https://api.elsevier.com/content/abstract/scopus_id/84896966222,"The use of mobile robots turns out to be interesting in activities where the action of human specialist is difficult or dangerous. Mobile robots are often used for the exploration in areas of difficult access, such as rescue operations and space missions, to avoid human experts exposition to risky situations. Mobile robots are also used in agriculture for planting tasks as well as for keeping the application of pesticides within minimal amounts to mitigate environmental pollution. In this paper we present the development of a system to control the navigation of an autonomous mobile robot through tracks in plantations. Track images are used to control robot direction by pre-processing them to extract image features. Such features are then submitted to a support vector machine and an artificial neural network in order to find out the most appropriate route. A comparison of the two approaches was performed to ascertain the one presenting the best outcome. The overall goal of the project to which this work is connected is to develop a real time robot control system to be embedded into a hardware platform. In this paper we report the software implementation of a support vector machine and of an artificial neural network, which so far presented respectively around 93% and 90% accuracy in predicting the appropriate route.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.3182/20130828-3-UK-2039.00025,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2013-01-01,sciencedirect,A new extensive source for web-based control education - Contlab.eu,https://api.elsevier.com/content/abstract/scopus_id/84885206555,"Modern technologies allow to create a networked control system with off-the-shelf mobile devices. As such, there is the possibility of having the role of who offers and who uses a “remote” laboratory played by the same people. Extending recently published ideas, the paper presents a first nucleus of functionalities allowing one to create process simulators and controllers which run on a mobile application, and then share them with others. Some words are also spent on some of the possibilities opened by the proposal, sketching out some interesting didactic activities to propose to the students.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2012.01.014,Journal,Applied Soft Computing Journal,scopus,2012-12-01,sciencedirect,Autonomous real-time landing site selection for Venus and Titan using Evolutionary Fuzzy Cognitive Maps,https://api.elsevier.com/content/abstract/scopus_id/84869086510,"Future science-driven landing missions, conceived to collect in situ data on regions of planetary bodies that have the highest potential to yield important scientific discoveries, will require a higher degree of autonomy. The latter includes the ability of the spacecraft to autonomously select the landing site using real-time data acquired during the descent phase. This paper presents the development of an Evolutionary Fuzzy Cognitive Map (E-FCM) model that implements an artificial intelligence system capable of autonomously selecting a landing site with the highest potential for scientific discoveries constrained by the requirement of soft landing in a region with safe terrains. The proposed E-FCM evolves its internal states and interconnections as a function of real-time data collected during the descent phase, therefore improving the decision process as more accurate information becomes available. The E-FCM is constructed using knowledge accumulated by planetary experts and it is tested on scenarios that simulate the decision process during the descent phase toward the Hyndla Regio on Venus. The E-FCM is shown to quickly reach conclusions that are consistent with what would be the choice of a planetary expert if the scientist were presented with the same information. The proposed methodology is fast and efficient and may be suitable for on-board spacecraft implementation and real-time decision making during the course of robotic exploration of the Solar System.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2012.06.003,Journal,Acta Astronautica,scopus,2012-11-01,sciencedirect,"Robotic Mission to Mars: Hands-on, minds-on, web-based learning",https://api.elsevier.com/content/abstract/scopus_id/84865224510,"Problem-based learning has been demonstrated as an effective methodology for developing analytical skills and critical thinking. The use of scenario-based learning incorporates problem-based learning whilst encouraging students to collaborate with their colleagues and dynamically adapt to their environment. This increased interaction stimulates a deeper understanding and the generation of new knowledge. The Victorian Space Science Education Centre (VSSEC) uses scenario-based learning in its Mission to Mars, Mission to the Orbiting Space Laboratory and Primary Expedition to the M.A.R.S. Base programs. These programs utilize methodologies such as hands-on applications, immersive-learning, integrated technologies, critical thinking and mentoring to engage students in Science, Technology, Engineering and Mathematics (STEM) and highlight potential career paths in science and engineering. The immersive nature of the programs demands specialist environments such as a simulated Mars environment, Mission Control and Space Laboratory, thus restricting these programs to a physical location and limiting student access to the programs. To move beyond these limitations, VSSEC worked with its university partners to develop a web-based mission that delivered the benefits of scenario-based learning within a school environment. The Robotic Mission to Mars allows students to remotely control a real rover, developed by the Australian Centre for Field Robotics (ACFR), on the VSSEC Mars surface. After completing a pre-mission training program and site selection activity, students take on the roles of scientists and engineers in Mission Control to complete a mission and collect data for further analysis. Mission Control is established using software developed by the ACRI Games Technology Lab at La Trobe University using the principles of serious gaming. The software allows students to control the rover, monitor its systems and collect scientific data for analysis. This program encourages students to work scientifically and explores the interaction between scientists and engineers. This paper presents the development of the program, including the involvement of university students in the development of the rover, the software, and the collation of the scientific data. It also presents the results of the trial phase of this program including the impact on student engagement and learning outcomes.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2012.02.029,Journal,Neural Networks,scopus,2012-08-01,sciencedirect,Real-time human-robot interaction underlying neurorobotic trust and intent recognition,https://api.elsevier.com/content/abstract/scopus_id/84861781307,"In the past three decades, the interest in trust has grown significantly due to its important role in our modern society. Everyday social experience involves “confidence” among people, which can be interpreted at the neurological level of a human brain. Recent studies suggest that oxytocin is a centrally-acting neurotransmitter important in the development and alteration of trust. Its administration in humans seems to increase trust and reduce fear, in part by directly inhibiting the amygdala. However, the cerebral microcircuitry underlying this mechanism is still unknown. We propose the first biologically realistic model for trust, simulating spiking neurons in the cortex in a real-time human–robot interaction simulation. At the physiological level, oxytocin cells were modeled with triple apical dendrites characteristic of their structure in the paraventricular nucleus of the hypothalamus. As trust was established in the simulation, this architecture had a direct inhibitory effect on the amygdala tonic firing, which resulted in a willingness to exchange an object from the trustor (virtual neurorobot) to the trustee (human actor). Our software and hardware enhancements allowed the simulation of almost 100,000 neurons in real time and the incorporation of a sophisticated Gabor mechanism as a visual filter. Our brain was functional and our robotic system was robust in that it trusted or distrusted a human actor based on movement imitation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aei.2012.02.005,Journal,Advanced Engineering Informatics,scopus,2012-04-01,sciencedirect,Enabling control software generation by using mechatronics modeling primitives,https://api.elsevier.com/content/abstract/scopus_id/84859593706,"Mechatronic systems are characterized by the synergetic integration of mechanic, electronic, software and control design aspects. The development of control software requires data and information from all design domains in order to create the required integrated functionality. This paper proposes a method that combines function modeling and multi-domain modeling primitives to generate control software automatically. An architecture model, based on the Function-Behavior-State modeling paradigm, provides the decomposition and flow of both functionality and implementation, which serves as input to a knowledge-based engineering application. The control software is subsequently extracted from a virtual product model composed of instantiated modeling primitives. A case study of a mobile robot shows how for a specific application the modeling are defined and how a high-level function model for an environment mapping mission is translated into directly implementable software code. This approach could be extended to real-life mechatronic products, and will improve consistency and reduce development time and cost.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2012.01.002,Journal,Robotics and Autonomous Systems,scopus,2012-04-01,sciencedirect,Automatically composing and parameterizing skills by evolving Finite State Automata,https://api.elsevier.com/content/abstract/scopus_id/84857062242,"We propose a robotics algorithm that is able to simultaneously combine, adapt and create actions to solve a task. The actions are combined in a Finite State Automaton whose structure is determined by a novel evolutionary algorithm. The actions parameters, or new actions, are evolved alongside the FSA topology. Actions can be combined together in a hierarchical fashion. This approach relies on skills that with which the robot is already provided, like grasping or motion planning. Therefore software reuse is an important advantage of our proposed approach. We conducted several experiments both in simulation and on a real mobile manipulator PR2 robot, where skills of increasing complexity are evolved. Our results show that (i) an FSA generated in simulation can be directly applied to a real robot without modifications and (ii) the evolved FSA is robust to the noise and the uncertainty arising from real-world sensors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.proeng.2012.01.475,Conference Proceeding,Procedia Engineering,scopus,2012-03-22,sciencedirect,Vision stability of four-legged robot based on the feedback of motion parameters,https://api.elsevier.com/content/abstract/scopus_id/84863362564,"The motion parameters of the legs of four-legged robot are collected and sent to the robot vision system, which can solve the stabilization problems of the software-based algorithms in searching for the global motion parameters. The motion jitter parameters of the four legs are extracted combined with the software stabilization methods, which work as the basis for solving global motion parameters and provide guidance for the parameters of the solution. The simulation tools of MATLAB SimMechanics toolkits are utilized to analysis stability. Compared with other related algorithms, the results indicate that the proposed algorithm for four-legged robot movement in real time is better and more accurate.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/C2009-0-16511-X,Book,Heuristic Search,scopus,2012-01-01,sciencedirect,Heuristic Search,https://api.elsevier.com/content/abstract/scopus_id/85014151116,Unknown,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.3182/20120403-3-DE-3010.00041,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2012-01-01,sciencedirect,Embedded system for controlling a mini underwater vehicle in autonomous hover mode,https://api.elsevier.com/content/abstract/scopus_id/84866098847,"This work presents the development of a mini underwater vehicle (Triton-PR), the embedded system, and the experiments in real-time for autonomous hover operation. Artificial vision allows the vehicle to obtain the translational position and velocity. The main characteristic of the embedded system is the implementation of low cost devices and materials, besides the number and location of the thrusters was chosen in order to have enough power and generate the rotation and translation movements. The dynamical model of the (Triton-PR) is described by the classic Euler-Lagrange equations, and a PD controller based on saturation functions is proposed for providing autonomous attitude and position of the robot. Finally, the performance of the vehicle is shown in simulation and real-time experimental results.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2011.04.207,Journal,Expert Systems with Applications,scopus,2011-10-01,sciencedirect,Intelligent control based on wavelet decomposition and neural network for predicting of human trajectories with a novel vision-based robotic,https://api.elsevier.com/content/abstract/scopus_id/79959924555,"In this paper, an intelligent novel vision-based robotic tracking model is developed to predict the performance of human trajectories with a novel vision-based robotic tracking system. The developed model is based on wavelet packet decomposition, entropy and neural network. We represent an implementation of a novel vision-based robotic tracking system based on wavelet decomposition and artificial neural (WD-ANN) which can track desired human trajectory pattern in real environments. The input–output data set of the novel vision-based robotic tracking system were first stored and than these data sets were used to predict the robotic tracking based on WD-ANN. In simulations, performance measures were obtained to compare the predicted and human–robot trajectories like actual values for model validation. In statistical analysis, the RMS value is 0.0729 and the R
                     2 value is 99.76% for the WD-ANN model. This study shows that the values predicted with the WD-ANN can be used to predict human trajectory by vision-based robotic tracking system quite accurately. All simulations have shown that the proposed method is more effective and controls the systems quite successful.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2011.02.024,Journal,Expert Systems with Applications,scopus,2011-08-01,sciencedirect,Application of Neuro-Fuzzy Controller for Sumo Robot control,https://api.elsevier.com/content/abstract/scopus_id/79953695631,"This paper proposes the application of Neuro-Fuzzy (NF) hybrid system for Sumo Robot (SR) control. This robot is frequently designed by engineering students for robotic competition. As the relation between sensors output signals and motors control pulses is highly nonlinear in SR, soft computing techniques can be used to define this nonlinear relation and control of the robot in a competition ring. Application of intelligent methods for SR control not only simplifies robot control and improves robot responses during competition, but also encourages engineering students to use intelligent methods for solving real world’s problems. Regarding above rationale, a NF controller for SR control is proposed and implemented. Firstly, a Fuzzy Inference System (FIS) for detecting and tracking of the opponent in the competition ring is developed, which relates sensor output signals to motor control pulses. Secondly, Artificial Neural Networks (ANN) based learning algorithm is used for rule extraction and tuning the FIS parameters. The design approach of the proposed controller is presented in detail, and effectiveness of the controller is demonstrated by hardware implementation and experimental results. The results show that the intelligent control methods can be easily applied in various robot competitions by engineering students.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2011.03.006,Journal,Neurocomputing,scopus,2011-07-01,sciencedirect,Robotic path planning in static environment using hierarchical multi-neuron heuristic search and probability based fitness,https://api.elsevier.com/content/abstract/scopus_id/79957968990,"Path Planning is a classical problem in the field of robotics. The problem is to find a path of the robot given the various obstacles. The problem has attracted the attention of numerous researchers due to the associated complexities, uncertainties and real time nature. In this paper we propose a new algorithm for solving the problem of path planning in a static environment. The algorithm makes use of an algorithm developed earlier by the authors called Multi-Neuron Heuristic Search (MNHS). This algorithm is a modified A⁎ algorithm that performs better than normal A⁎ when heuristics are prone to sharp changes. This algorithm has been implemented in a hierarchical manner, where each generation of the algorithm gives a more detailed path that has a higher reaching probability. The map used for this purpose is based on a probabilistic approach where we measure the probability of collision with obstacle while traveling inside the cell. As we decompose the cells, the cell size reduces and the probability starts to touch 0 or 1 depending upon the presence or absence of obstacles in the cell. In this approach, it is not compulsory to run the entire algorithm. We may rather break after a certain degree of certainty has been achieved. We tested the algorithm in numerous situations with varying degrees of complexities. The algorithm was able to give an optimal path in all the situations given. The standard A⁎ algorithm failed to give results within time in most of the situations presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2011.02.004,Journal,Neural Networks,scopus,2011-06-01,sciencedirect,Learning parametric dynamic movement primitives from multiple demonstrations,https://api.elsevier.com/content/abstract/scopus_id/79953692970,"Learning from demonstration has shown to be a suitable approach for learning control policies (CPs). However, most previous studies learn CPs from a single demonstration, which results in limited scalability and insufficient generalization toward a wide range of applications in real environments. This paper proposes a novel approach to learn highly scalable CPs of basis movement skills from multiple demonstrations. In contrast to conventional studies with a single demonstration, i.e., dynamic movement primitives (DMPs), our approach efficiently encodes multiple demonstrations by shaping a parametric-attractor landscape in a set of differential equations. Assuming a certain similarity among multiple demonstrations, our approach learns the parametric-attractor landscape by extracting a small number of common factors in multiple demonstrations. The learned CPs allow the synthesis of novel movements with novel motion styles by specifying the linear coefficients of the bases as parameter vectors without losing useful properties of the DMPs, such as stability and robustness against perturbations. For both discrete and rhythmic movement skills, we present a unified learning procedure for learning a parametric-attractor landscape from multiple demonstrations. The feasibility and highly extended scalability of DMPs are demonstrated on an actual dual-arm robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2010.12.080,Journal,Expert Systems with Applications,scopus,2011-06-01,sciencedirect,An intelligent framework to manage robotic autonomous agents,https://api.elsevier.com/content/abstract/scopus_id/79951576718,"In this paper a joint application of Artificial Intelligence (AI), robotics and Web services is described. The aim of the work presented here was to create a new integrated framework that keeps advantage on one side of the sensing and exploring capabilities of the robotic systems that work in the real world and, on the other side, of the information available via Web. Robots are conceived like (semi-)autonomous systems able to explore and manipulate a portion of their environment in order to find and collect information and data. On the other hand, the Web, that in a robotic domain is usually considered like a channel of communication (e.g. tele-operation, tele-manipulation), here is conceived also like a source of knowledge. This allows to define a new framework able to manage robotic agents in order to get precise, real-time information from the real world. Besides, software agents may search for and get additional information from the Web logical world. The intelligent administration of these services can be applied in different environments and leads to optimize procedures and solve practical problems. To this end a traffic control application has been defined and a simplified test-case implemented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2010.06.033,Journal,Neurocomputing,scopus,2011-05-01,sciencedirect,Incremental online sparsification for model learning in real-time robot control,https://api.elsevier.com/content/abstract/scopus_id/79956050250,"For many applications such as compliant, accurate robot tracking control, dynamics models learned from data can help to achieve both compliant control performance as well as high tracking quality. Online learning of these dynamics models allows the robot controller to adapt itself to changes in the dynamics (e.g., due to time-variant nonlinearities or unforeseen loads). However, online learning in real-time applications – as required in control – cannot be realized by straightforward usage of off-the-shelf machine learning methods such as Gaussian process regression or support vector regression. In this paper, we propose a framework for online, incremental sparsification with a fixed budget designed for fast real-time model learning. The proposed approach employs a sparsification method based on an independence measure. In combination with an incremental learning approach such as incremental Gaussian process regression, we obtain a model approximation method which is applicable in real-time online learning. It exhibits competitive learning accuracy when compared with standard regression techniques. Implementation on a real Barrett WAM robot demonstrates the applicability of the approach in real-time online model learning for real world systems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.3182/20110828-6-IT-1002.01424,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,Neural Network based system for real-time organ recognition during surgical operation,https://api.elsevier.com/content/abstract/scopus_id/84866753336,"Abstract
                  In this paper we propose (based on testing results) a Neural Network structures that can be used for recognition of presence and absence of internal organ on images received from endoscope. Based on selected NN structure we design two NN-based systems for distinguishing and real-time recognition of internal organs on sequence of endoscopic images during abdominal surgery. First NN-based system proposed in this paper is designed for recognition of several different internal organs on color endoscopic images. Second NN-based system is designed for real-time recognition of presence of a particular internal organ on a sequence of color images (video stream) from endoscope. Restricted connectivity structure of the network makes possible decomposition of the image during the analysis and significantly reduces the number of parameters thus making training easier, faster and more accurate. The algorithms proposed in the paper are implemented in software application and their effectiveness is demonstrated on simulations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.3182/20110828-6-IT-1002.03103,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,UniBot Remote Laboratory: A scalable web-based set-up for education and experimental activities in robotics,https://api.elsevier.com/content/abstract/scopus_id/84866747278,"Abstract
                  The direct work on a real set-ups is an important experience for students in control theory and robotics. On the other hand, for several reasons (space, costs, complexity, etc.), it is not always possible to give students an individual access to laboratory set-ups, for their practical activities. Therefore, in recent years many tele-laboratories have been implemented by different universities, providing experimental set-ups to each student, while minimizing problems related to costs, spaces, and so on. The UniBot Remote Lab has been implemented to provide remote access via TCP connection, to assign to students different time-slots for their experiences, and to reduce the financial effort required by real set-ups. Moreover, the entire framework has been developed with high modularity both from the hardware and software point of view and, even if the basic set-up has been conceived for mobile robotics, different kind of robots or automatic machines can be easily added and be available for experimental activities.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.conengprac.2010.10.002,Journal,Control Engineering Practice,scopus,2011-01-01,sciencedirect,Real time implementation of CTRNN and BPTT algorithm to learn on-line biped robot balance: Experiments on the standing posture,https://api.elsevier.com/content/abstract/scopus_id/78649998184,This paper describes experimental results regarding the real time implementation of continuous time recurrent neural networks (CTRNN) and the dynamic back-propagation through time (BPTT) algorithm for the on-line learning control laws. Experiments are carried out to control the balance of a biped robot prototype in its standing posture. The neural controller is trained to compensate for external perturbations by controlling the torso’s joint motions. Algorithms are embedded in the real time electronic unit of the robot. On-line learning implementations are presented in detail. The results on learning behavior and control performance demonstrate the strength and the efficiency of the proposed approach.,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2010.08.004,Journal,Robotics and Autonomous Systems,scopus,2010-12-31,sciencedirect,Open-ended evolution as a means to self-organize heterogeneous multi-robot systems in real time,https://api.elsevier.com/content/abstract/scopus_id/78649913375,"This work deals with the application of multi-robot systems to real tasks and, in particular, their coordination through interaction based control systems. Within this field, the practical solutions that have been implemented in real robots mainly use strongly coordinated architectures and assignment strategies because of reliability and fault tolerance issues when addressing problems in reality. Emergent approaches have also been proposed with limited success, basically due to the unpredictability of the behaviors obtained. Here, an emergent approach, called r-ASiCo, is presented containing a procedure to produce predictable solutions and thus avoiding the typical problems associated with these techniques. The r-ASico algorithm is the real time version of the Asynchronous Situated Co-evolution algorithm (ASiCo), which exploits natural open-ended evolution to generate emergent complex collective behaviors and deals with systems made up of a huge number of elements and nonlinear interactions. The goal of r-ASiCo is to design the global behavior desired for the robot team as a collective entity and allow the emergence of behaviors through the interaction of the team members using social rules they learn to implement. To this end, r-ASiCo manages a series of features that are inherent to natural evolution based methods such as energy exchange and mating selection procedures, together with a technique to guide the evolution towards a design objective, the principled evaluation function selection procedure. Hence, this paper presents the components and operation of r-ASiCo and illustrates its application through a collective cleaning task example. It was implemented using 8 e-puck robots in two different real scenarios and its results complemented with those of a 30 e-puck case. The results show the capabilities of r-ASiCo to create a self-organized and adaptive multi-robot system configuration that is tolerant to environmental changes and to failures within the robot team.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cviu.2010.03.017,Journal,Computer Vision and Image Understanding,scopus,2010-11-01,sciencedirect,A modified model for the Lobula Giant Movement Detector and its FPGA implementation,https://api.elsevier.com/content/abstract/scopus_id/77957362557,"Bio-inspired vision sensors are particularly appropriate candidates for navigation of vehicles or mobile robots due to their computational simplicity, allowing compact hardware implementations with low power dissipation. The Lobula Giant Movement Detector (LGMD) is a wide-field visual neuron located in the Lobula layer of the Locust nervous system. The LGMD increases its firing rate in response to both the velocity of an approaching object and the proximity of this object. It has been found that it can respond to looming stimuli very quickly and trigger avoidance reactions. It has been successfully applied in visual collision avoidance systems for vehicles and robots. This paper introduces a modified neural model for LGMD that provides additional depth direction information for the movement. The proposed model retains the simplicity of the previous model by adding only a few new cells. It has been simplified and implemented on a Field Programmable Gate Array (FPGA), taking advantage of the inherent parallelism exhibited by the LGMD, and tested on real-time video streams. Experimental results demonstrate the effectiveness as a fast motion detector.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2009.12.003,Journal,Cognitive Systems Research,scopus,2010-09-01,sciencedirect,Cognitive concepts in autonomous soccer playing robots,https://api.elsevier.com/content/abstract/scopus_id/77952550318,"Computational concepts of cognition, their implementation in complex autonomous systems, and their empirical evaluation are key techniques to understand and validate concepts of cognition and intelligence. In this paper we want to describe computational concepts of cognition that were successfully implemented in the domain of soccer playing robots and show the interactions between cognitive concepts, software engineering and real-time application development. Beside a description of the general concepts we will focus on aspects of perception, behavior architecture, and reinforcement learning.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2010.03.008,Journal,Robotics and Autonomous Systems,scopus,2010-07-31,sciencedirect,Policy gradient learning for quadruped soccer robots,https://api.elsevier.com/content/abstract/scopus_id/78049435621,"In real-world robotic applications, many factors, both at low level (e.g., vision, motion control and behaviors) and at high level (e.g., plans and strategies) determine the quality of the robot performance. Consequently, fine tuning of the parameters, in the implementation of the basic functionalities, as well as in the strategic decisions, is a key issue in robot software development. In recent years, machine learning techniques have been successfully used to find optimal parameters for typical robotic functionalities. However, one major drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters using policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2009.11.030,Journal,Expert Systems with Applications,scopus,2010-05-01,sciencedirect,Intelligent omni-directional vision-based mobile robot fuzzy systems design and implementation,https://api.elsevier.com/content/abstract/scopus_id/73249122254,"An evolutional particle swarm optimization (PSO)-learning algorithm is proposed to automatically generate fuzzy decision rules. Due to the development of the fuzzy rule-based system, it actually regulates the omni-directional vision-based mobile robot for obstacle avoidance and desired target approximation as soon as possible. In the proposed image processing algorithm, an image direct transformation method is applied to convert the omni-directional scene into panoramic normal-view. Thus, the objects positions of obstacle and target are detected by the proposed color image segmentation. Human knowledge-based fuzzy systems demonstrate their well adaptability for nonlinear and time-variant features of the mobile robot to actually approach the desired location whatever it is surrounded in a known or unknown environment. In software simulations, the omni-directional mobile robot can move toward desired targets from different initial positions and various block sizes. In hardware implementations, the fuzzy control system embedded in actual mobile robot platform is used to real-time manipulate the omni-directional wheels through the motor drivers by the captured image positions of the obstacle and target. The selected fuzzy rules are efficient to control the direction and speed of omni-directional wheels to achieve the desired targets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2009.09.009,Journal,Robotics and Autonomous Systems,scopus,2010-02-28,sciencedirect,Bridging the gap between feature- and grid-based SLAM,https://api.elsevier.com/content/abstract/scopus_id/75149183985,"One important design decision for the development of autonomously navigating mobile robots is the choice of the representation of the environment. This includes the question of which type of features should be used, or whether a dense representation such as occupancy grid maps is more appropriate. In this paper, we present an approach which performs SLAM using multiple representations of the environment simultaneously. It uses reinforcement to learn when to switch to an alternative representation method depending on the current observation. This allows the robot to update its pose and map estimate based on the representation that models the surrounding of the robot in the best way. The approach has been implemented on a real robot and evaluated in scenarios, in which a robot has to navigate in- and outdoors and therefore switches between a landmark-based representation and a dense grid map. In practical experiments, we demonstrate that our approach allows a robot to robustly map environments which cannot be adequately modeled by either of the individual representations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2010.02.131,Journal,Expert Systems with Applications,scopus,2010-01-01,sciencedirect,Online tuning gain scheduling MIMO neural PID control of the 2-axes pneumatic artificial muscle (PAM) robot arm,https://api.elsevier.com/content/abstract/scopus_id/80053611092,This paper presents a detailed study to investigate the possibility of applying the online tuning gain scheduling MIMO neural dynamic DNN-PID control architecture to a nonlinear 2-axes pneumatic artificial muscle (PAM) robot arm so as to improve its joint angle position output performance. The proposed controller was implemented as a subsystem to control the real-time 2-axes PAM robot-arm system so as to control precisely the joint angle position of the 2-axes PAM robot arm when subjected to system internal interactions and load variations. The results of the experiment have demonstrated the feasibility and benefits of the novel proposed control approach in comparison with the traditional PID control strategy. The proposed gain scheduling neural MIMO DNN-PID control scheme forced both joint angle outputs of 2-axes PAM robot arm to track those of the reference simultaneously under changes of the load and system coupled internal interactions. The performance of this novel proposed controller was found to be outperforming in comparison with conventional PID. These results can be applied to control other highly nonlinear systems.,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2010.04.001,Journal,Robotics and Autonomous Systems,scopus,2010-01-01,sciencedirect,Visual servoing of redundant manipulator with Jacobian matrix estimation using self-organizing map,https://api.elsevier.com/content/abstract/scopus_id/80052724345,"Vision based redundant manipulator control with a neural network based learning strategy is discussed in this paper. The manipulator is visually controlled with stereo vision in an eye-to-hand configuration. A novel Kohonen’s self-organizing map (KSOM) based visual servoing scheme has been proposed for a redundant manipulator with 7 degrees of freedom (DOF). The inverse kinematic relationship of the manipulator is learned using a Kohonen’s self-organizing map. This learned map is shown to be an approximate estimate of the inverse Jacobian, which can then be used in conjunction with the proportional controller to achieve closed loop servoing in real-time. It is shown through Lyapunov stability analysis that the proposed learning based servoing scheme ensures global stability. A generalized weight update law is proposed for KSOM based inverse kinematic control, to resolve the redundancy during the learning phase. Unlike the existing visual servoing schemes, the proposed KSOM based scheme eliminates the computation of the pseudo-inverse of the Jacobian matrix in real-time. This makes the proposed algorithm computationally more efficient. The proposed scheme has been implemented on a 7 DOF PowerCube™ robot manipulator with visual feedback from two cameras.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jfranklin.2009.10.019,Journal,Journal of the Franklin Institute,scopus,2010-01-01,sciencedirect,Decentralized neural identification and control for uncertain nonlinear systems: Application to planar robot,https://api.elsevier.com/content/abstract/scopus_id/79251594751,"This paper presents a discrete-time decentralized neural identification and control for large-scale uncertain nonlinear systems, which is developed using recurrent high order neural networks (RHONN); the neural network learning algorithm uses an extended Kalman filter (EKF). The discrete-time control law proposed is based on block control and sliding mode techniques. The control algorithm is first simulated, and then implemented in real time for a two degree of freedom (DOF) planar robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.medengphy.2009.08.002,Journal,Medical Engineering and Physics,scopus,2009-12-01,sciencedirect,Real-time model based electrical powered wheelchair control,https://api.elsevier.com/content/abstract/scopus_id/70449517241,"The purpose of this study was to evaluate the effects of three different control methods on driving speed variation and wheel slip of an electric-powered wheelchair (EPW). A kinematic model as well as 3D dynamic model was developed to control the velocity and traction of the wheelchair. A smart wheelchair platform was designed and built with a computerized controller and encoders to record wheel speeds and to detect the slip. A model based, a proportional-integral-derivative (PID) and an open-loop controller were applied with the EPW driving on four different surfaces at three specified speeds. The speed errors, variation, rise time, settling time and slip coefficient were calculated and compared for a speed step-response input. Experimental results showed that model based control performed best on all surfaces across the speeds.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.hal.2009.04.006,Journal,Harmful Algae,scopus,2009-09-01,sciencedirect,"Remote, subsurface detection of the algal toxin domoic acid onboard the Environmental Sample Processor: Assay development and field trials",https://api.elsevier.com/content/abstract/scopus_id/69249228534,"The ability to detect harmful algal bloom (HAB) species and their toxins in real- or near real-time is a critical need for researchers studying HAB/toxin dynamics, as well as for coastal resource managers charged with monitoring bloom populations in order to mitigate their wide ranging impacts. The Environmental Sample Processor (ESP), a robotic electromechanical/fluidic system, was developed for the autonomous, subsurface application of molecular diagnostic tests and has successfully detected several HAB species using DNA probe arrays during field deployments. Since toxin production and thus the potential for public health and ecosystem effects varies considerably in natural phytoplankton populations, the concurrent detection of HAB species and their toxins onboard the ESP is essential. We describe herein the development of methods for extracting the algal toxin domoic acid (DA) from Pseudo-nitzschia cells (extraction efficiency >90%) and testing of samples using a competitive ELISA onboard the ESP. The assay detection limit is in the low ng/mL range (in extract), which corresponds to low ng/L levels of DA in seawater for a 0.5L sample volume acquired by the ESP. We also report the first in situ detection of both a HAB organism (i.e., Pseudo-nitzschia) and its toxin, domoic acid, via the sequential (within 2–3h) conduct of species- and toxin-specific assays during ESP deployments in Monterey Bay, CA, USA. Efforts are now underway to further refine the assay and conduct additional calibration exercises with the aim of obtaining more reliable, accurate estimates of bloom toxicity and thus their potential impacts.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0074-7742(09)86008-X,Book Series,International Review of Neurobiology,scopus,2009-07-16,sciencedirect,Chapter 8 Neurofeedback and Brain-Computer Interface. Clinical Applications,https://api.elsevier.com/content/abstract/scopus_id/67650248609,"Most of the research devoted to BMI development consists of methodological studies comparing different online mathematical algorithms, ranging from simple linear discriminant analysis (LDA) (Dornhege et al., 2007) to nonlinear artificial neural networks (ANNs) or support vector machine (SVM) classification. Single cell spiking for the reconstruction of hand movements requires different statistical solutions than electroencephalography (EEG)‐rhythm classification for communication. In general, the algorithm for BMI applications is computationally simple and differences in classification accuracy between algorithms used for a particular purpose are small. Only a very limited number of clinical studies with neurological patients are available, most of them single case studies.
                  The clinical target populations for BMI‐treatment consist primarily of patients with amyotrophic lateral sclerosis (ALS) and severe CNS damage including spinal cord injuries and stroke resulting in substantial deficits in communication and motor function. However, an extensive body of literature started in the 1970s using neurofeedback training. Such training implemented to control various EEG‐measures provided solid evidence of positive effects in patients with otherwise pharmacologically intractable epilepsy, attention deficit disorder, and hyperactivity ADHD. More recently, the successful introduction and testing of real‐time fMRI and a NIRS‐BMI opened an exciting field of interest in patients with psychopathological conditions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2009.06.032,Journal,Neural Networks,scopus,2009-07-01,sciencedirect,Extending the Evolutionary Robotics approach to flying machines: An application to MAV teams,https://api.elsevier.com/content/abstract/scopus_id/68149170032,"The work presented in this article focuses on the use of embodied neural networks–developed through Evolutionary Robotics and Multi-Agent Systems methodologies–as autonomous distributed controllers for Micro-unmanned Aerial Vehicle (MAV) teams. The main aim of the research is to extend the range of domains that could be successfully tackled by the Evolutionary Robotics approach. The flying robots realm is an area that has not been yet thoroughly investigated by this discipline. This is due to the lack of an affordable and reliable robotic platform to use for carrying out experiments, and to the difficulty and the high computational load involved in experiments based upon a realistic software simulator for aircraft. We believe that the most recent improvements to the state of the art now permit the investigation of this domain. For demonstrating this point, two different evolutionary computer simulation models are presented in this article. The first model, which uses a simplified 2D test environment, has resulted in controllers evolved with the following capabilities: (1) navigation through unknown environments, (2) obstacle-avoidance, (3) tracking of a movable target, and (4) execution of cooperative and coordinated behaviors based on implicit communication strategies. In order to improve the robustness of these results and their potential use in real MAV teams, a more sophisticated 3D model is presented herein. The results obtained so far using the two models demonstrate the feasibility of the chosen approach for further research on the design of autonomous controllers for MAVs.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2009.06.043,Journal,Neural Networks,scopus,2009-07-01,sciencedirect,Neural networks with multiple general neuron models: A hybrid computational intelligence approach using Genetic Programming,https://api.elsevier.com/content/abstract/scopus_id/68149160210,"Classical neural networks are composed of neurons whose nature is determined by a certain function (the neuron model), usually pre-specified. In this paper, a type of neural network (NN-GP) is presented in which: (i) each neuron may have its own neuron model in the form of a general function, (ii) any layout (i.e network interconnection) is possible, and (iii) no bias nodes or weights are associated to the connections, neurons or layers. The general functions associated to a neuron are learned by searching a function space. They are not provided a priori, but are rather built as part of an Evolutionary Computation process based on Genetic Programming. The resulting network solutions are evaluated based on a fitness measure, which may, for example, be based on classification or regression errors. Two real-world examples are presented to illustrate the promising behaviour on classification problems via construction of a low-dimensional representation of a high-dimensional parameter space associated to the set of all network solutions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2008.06.028,Journal,Neurocomputing,scopus,2009-06-01,sciencedirect,Automated multi-label text categorization with VG-RAM weightless neural networks,https://api.elsevier.com/content/abstract/scopus_id/67349255290,"In automated multi-label text categorization, an automatic categorization system should output a label set, whose size is unknown a priori, for each document under analysis. Many machine learning techniques have been used for building such automatic text categorization systems. In this paper, we examine virtual generalizing random access memory weightless neural networks (VG-RAM WNN), an effective machine learning technique which offers simple implementation and fast training and test, as a tool for building automatic multi-label text categorization systems. We evaluated the performance of VG-RAM WNN on two real-world problems:, (i) categorization of free-text descriptions of economic activities and (ii) categorization of Web pages, and compared our results with that of the multi-label lazy learning approach (Multi-Label K-Nearest Neighbors, ML-KNN). Our experimental comparative analysis showed that, on average, VG-RAM WNN either outperforms ML-KNN or show similar categorization performance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2009.03.001,Journal,Engineering Applications of Artificial Intelligence,scopus,2009-06-01,sciencedirect,An implementing framework for holonic manufacturing control with multiple robot-vision stations,https://api.elsevier.com/content/abstract/scopus_id/67349215793,"The paper describes a holonic control architecture and implementing issues for agile job shop assembly with networked intelligent robots, based on the dynamic simulation of material processing and transportation. The holarchy was defined considering the PROSA reference architecture relative to which in-line vision-based quality control was added by help of feature-based descriptions of the material flow. Two solutions for production planning are proposed: a knowledge-based algorithm using production rules, and an OO resolved scheduling rate planner (RSRP) based on variable-timing simulation. Failure- and recovery-management are developed as generic scenarios embedding the CNP mechanism into production self-rescheduling. Aggregate Order Holon execution is realized by OPC-based PLC software integration and event-driven product transportation. The holonic control of multiple networked robot-vision stations also features tolerance to station computer- (IBM PC-type), station controller- (robot controller), quality control- (machine vision) and communication- (LAN) failure. Fault tolerance and high availability at shop-floor level are provided due to the multiple physical communication capabilities of the robot controllers, to their multiple-axis multitasking operating capability, and to hardware redundancy of single points of failure (SPOF). Implementing solutions and experiments are reported for a 6-station robot-vision assembly cell with twin-track closed-loop pallet transportation system and product-racking RD/WR devices. Future developments will consider manufacturing integration at enterprise level.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2009.01.013,Journal,Neural Networks,scopus,2009-03-01,sciencedirect,Robotic sound-source localisation architecture using cross-correlation and recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/61749088969,"In this paper we present a sound-source model for localising and tracking an acoustic source of interest along the azimuth plane in acoustically cluttered environments, for a mobile service robot. The model we present is a hybrid architecture using cross-correlation and recurrent neural networks to develop a robotic model accurate and robust enough to perform within an acoustically cluttered environment. This model has been developed with considerations of both processing power and physical robot size, allowing for this model to be deployed on to a wide variety of robotic systems where power consumption and size is a limitation. The development of the system we present has its inspiration taken from the central auditory system (CAS) of the mammalian brain. In this paper we describe experimental results of the proposed model including the experimental methodology for testing sound-source localisation systems. The results of the system are shown in both restricted test environments and in real-world conditions. This paper shows how a hybrid architecture using band pass filtering, cross-correlation and recurrent neural networks can be used to develop a robust, accurate and fast sound-source localisation model for a mobile robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2008.10.014,Journal,Robotics and Autonomous Systems,scopus,2009-02-28,sciencedirect,HRP-2W: A humanoid platform for research on support behavior in daily life environments,https://api.elsevier.com/content/abstract/scopus_id/58549110024,"We introduce a concept of a real-world-oriented humanoid robot that can support humans’ activities in daily life. In such environments, robots have to watch humans, understand their behavior, and support their daily life tasks. In particular, these robots must be capable of such real-world behavior as handling tableware and delivering daily commodities by hand. We developed a humanoid robot, HRP-2W, which has an upper body of HRP-2 [K. Kaneko, F. Kanehiro, S. Kajita, H. Hirukawa, T. Kawasaki, M. Hirata, K. Akachi, T. Isozumi, Humanoid Robot HRP-2, in: Proceedings of the 2004 IEEE International Conference on Robotics & Automation, 2004, pp. 1083–1090] and a wheel module instead of legs, as a research platform to fulfill this aim. We also developed basic software configuration in order to integrate our platform with other research groups. Through experiments, we demonstrated the feasibility of the humanoid robot platform and the potential of the software architecture.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2008.11.002,Journal,ISA Transactions,scopus,2009-01-01,sciencedirect,Adaptive user interfaces in complex supervisory tasks,https://api.elsevier.com/content/abstract/scopus_id/61549092162,"In this paper we propose a novel idea for adaptation of the user interface in complex supervisory tasks. Under the assumption that the user behavior is stationary and that the user has limited cognitive and motor abilities, we have shown that a combination of genetic algorithm for constrained optimization and probabilistic modeling of the user may evolve the adaptive interface to the level of personalization. The non-parametric statistics has been employed in order to evaluate the feasibility of the ranking approach. The method proposed is flexible and easy to use in various problem domains. We have tested the method with an automated user and a group of real users in an air traffic control environment. The automated user, implemented for initial tests, is built first under the same assumptions as a real user. In the second step, we have exploited the adaptive interface through a group of real users and collected subjective ratings using questionnaires. We have shown that the proposed method can effectively improve human–computer interaction and our approach is pragmatically a valid approach for the interface adaptation in complex environments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2008.06.040,Journal,Expert Systems with Applications,scopus,2009-01-01,sciencedirect,Motion planning in order to optimize the length and clearance applying a Hopfield neural network,https://api.elsevier.com/content/abstract/scopus_id/58749107169,"This paper deals with motion planning in plane for a mobile robot with two freedom degrees through some polygonal unmoved obstacles. Applying Minkowski sum, we can represent the robot as a point. Then, by using traditional approaches such as visibility graphs, simple and generalized Voronoi diagrams, decomposition methods, etc, it is possible to provide a graph covering obstacles, say roadmap. In order to find a real-time collision-free robot motion planning between two arbitrary source and target configurations through the roadmap, an adoptive Hopfield neural network is considered. Maximizing the clearance of path together with minimizing the length of path are pursued in a bi-objective framework. For treating with multiple objectives TOPSIS method, as a kind of goal programming techniques, is provided to find the efficient solutions. Because of capability of parallel computation through hardware implementation of neural networks, the presented approach is a reasonable technique in mobile robot navigation and traveler guidance systems. The advantages of the proposed system are confirmed by simulation experiments. This approach can be directly extended in unknown environment including time-varying conditions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2008.06.016,Journal,Neurocomputing,scopus,2009-01-01,sciencedirect,Architectures for functional imagination,https://api.elsevier.com/content/abstract/scopus_id/58149496092,"Imagination can be defined broadly as the manipulation of information that is not directly available to an agent's sensors. However, the topic of imagination raises representational, physiological, and phenomenological issues that cannot be tackled easily without using the body as a reference point. Within this framework, we define functional imagination as the mechanism that allows an embodied agent to simulate its own actions and their sensory consequences internally, and to extract behavioural benefits from doing so. In this paper, we present five necessary and sufficient requirements for the implementation of functional imagination, as well as a minimal architecture that meets all these criteria. We also present a taxonomy for categorising possible architectures according to their main attributes. Finally, we describe experiments with some simple architectures designed using these principles and implemented on simulated and real robots, including an extremely complex anthropomimetic humanoid.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2008.06.019,Journal,Neurocomputing,scopus,2009-01-01,sciencedirect,Discretized ISO-learning neural network for obstacle avoidance in reactive robot controllers,https://api.elsevier.com/content/abstract/scopus_id/58149470368,"Isotropic sequence order learning (ISO-learning) and its variations, input correlation only learning (ICO-learning) and ISO three-factor learning (ISO3-learning) are unsupervised neural algorithms to learn temporal differences. As robotic software operates mainly in discrete time domain, a discretization of ISO-learning is needed to apply classical conditioning to reactive robot controllers.
                  Discretization of ISO-learning is achieved by modifications to original rules: weights sign restriction, to adequate ISO-learning devices outputs to the usually predefined kinds of connections (excitatory/inhibitory) used in neural networks, and decay term in learning rate for weights stabilization. Discrete ISO-learning devices are included into neural networks used to learn simple obstacle avoidance in the reactive control of two real robots.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2008.10.003,Journal,Neural Networks,scopus,2008-12-01,sciencedirect,A visually guided collision warning system with a neuromorphic architecture,https://api.elsevier.com/content/abstract/scopus_id/56949095147,"We have designed a visually guided collision warning system with a neuromorphic architecture, employing an algorithm inspired by the visual nervous system of locusts. The system was implemented with mixed analog–digital integrated circuits consisting of an analog resistive network and field-programmable gate array (FPGA) circuits. The resistive network processes the interaction between the laterally spreading excitatory and inhibitory signals instantaneously, which is essential for real-time computation of collision avoidance with a low power consumption and a compact hardware. The system responded selectively to approaching objects of simulated movie images at close range. The system was, however, confronted with serious noise problems due to the vibratory ego-motion, when it was installed in a mobile miniature car. To overcome this problem, we developed the algorithm, which is also installable in FPGA circuits, in order for the system to respond robustly during the ego-motion.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2008.08.010,Journal,Robotics and Autonomous Systems,scopus,2008-11-30,sciencedirect,Logic-based robot control in highly dynamic domains,https://api.elsevier.com/content/abstract/scopus_id/53849128142,"In this paper, we present the robot programming and planning language Readylog, a Golog dialect, which was developed to support the decision making of robots acting in dynamic real-time domains, such as robotic soccer. The formal framework of Readylog, which is based on the situation calculus, features imperative control structures such as loops and procedures, allows for decision-theoretic planning, and accounts for a continuously changing world. We developed high-level controllers in Readylog for our soccer robots in RoboCup’s Middle-size league, but also for service robots and for autonomous agents in interactive computer games. For a successful deployment of Readylog on a real robot it is also important to account for the control problem as a whole, integrating the low-level control of the robot (such as localization, navigation, and object recognition) with the logic-based high-level control. In doing so, our approach can be seen as a step towards bridging the gap between the fields of robotics and knowledge representation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2008.04.002,Journal,Microprocessors and Microsystems,scopus,2008-10-01,sciencedirect,A tunable high-performance architecture for enhancement of stream video captured under non-uniform lighting conditions,https://api.elsevier.com/content/abstract/scopus_id/54549122634,"A novel architecture for performing hue-saturation-value (HSV) domain enhancement of digital color images captured under non-uniform lighting conditions is proposed in this paper for video streaming applications. The approach promotes log-domain computation to eliminate all multiplications, divisions and exponentiations utilizing the compact high-speed logarithmic estimation modules. An optimized quadrant symmetric architecture is incorporated into the design of homomorphic filter for the enhancement of intensity value. Efficient modules are also presented for conversion between RGB and HSV color spaces with tunable H and S components in HSV for more flexible color rendering. The design is able to bring out details hidden in shadow regions of the image and preserve the bright parts with adjustable vividness and color shift for improvement of visual quality while maintaining its consistency. It is capable of producing 187.86 million outputs per second (MOPs) on Xilinx’s Virtex II XC2V2000-4ff896 field programmable gate array (FPGA) at a clock frequency of 187.86MHz. It can process over 179.1 (1024×1024) frames per second, which is very suitable for high definition videos, and consumes approximately 70.7% and 76.8% less hardware resource with 127% and 280% performance boost when compared to the designs with machine learning algorithm in [M.Z. Zhang, M.J. Seow, V.K. Asari, A high performance architecture for color image enhancement using a machine learning approach, International Journal of Computational Intelligence Research – Special Issue on Advances in Neural Networks 2(1) (2006) 40–47], and with separated dynamic and contrast enhancements in [H.T. Ngo, M.Z. Zhang, L. Tao, V.K. Asari, Design of a high performance architecture for real-time enhancement of video stream captured in extremely low lighting environment, International Journal of Embedded Systems: Special Issue on Media and Stream Processing, in press], respectively. This approach also provide 83.4 times performance gain with more consistent fidelity in the results compared to some DSP based implementations (256×256 frame size) [G.D. Hines, Z. Rahman, D.J. Jobson, G.A. Woodell, DSP implementation of the retinex image enhancement algorithm, visual information processing XIII, in: Proceedings of the SPIE, vol. 5438, 2004, pp. 13–24; G.D. Hines, Z. Rahman, D.J. Jobson, G.A. Woodell, Single-scale retinex using digital signal processors, in: Proceedings of the Global Signal Processing Conference, September 2004, pp. 1–6] under the reflectance-illuminance category of image enhancement models.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2008.06.016,Journal,Neural Networks,scopus,2008-10-01,sciencedirect,The Emergent neural modeling system,https://api.elsevier.com/content/abstract/scopus_id/53249121490,"Emergent (http://grey.colorado.edu/emergent) is a powerful tool for the simulation of biologically plausible, complex neural systems that was released in August 2007. Inheriting decades of research and experience in network algorithms and modeling principles from its predecessors, PDP++ and PDP, Emergent has been redesigned as an efficient workspace for academic research and an engaging, easy-to-navigate environment for students. The system provides a modern and intuitive interface for programming and visualization centered around hierarchical, tree-based navigation and drag-and-drop reorganization. Emergent contains familiar, high-level simulation constructs such as Layers and Projections, a wide variety of algorithms, general-purpose data handling and analysis facilities and an integrated virtual environment for developing closed-loop cognitive agents. For students, the traditional role of a textbook has been enhanced by wikis embedded in every project that serve to explain, document, and help newcomers engage the interface and step through models using familiar hyperlinks. For advanced users, the software is easily extensible in all respects via runtime plugins, has a powerful shell with an integrated debugger, and a scripting language that is fully symmetric with the interface. Emergent strikes a balance between detailed, computationally expensive spiking neuron models and abstract, Bayesian or symbolic systems. This middle level of detail allows for the rapid development and successful execution of complex cognitive models while maintaining biological plausibility.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2007.09.016,Journal,Neural Networks,scopus,2008-06-01,sciencedirect,SOVEREIGN: An autonomous neural system for incrementally learning planned action sequences to navigate towards a rewarded goal,https://api.elsevier.com/content/abstract/scopus_id/44649089467,"How do reactive and planned behaviors interact in real time? How are sequences of such behaviors released at appropriate times during autonomous navigation to realize valued goals? Controllers for both animals and mobile robots, or animats, need reactive mechanisms for exploration, and learned plans to reach goal objects once an environment becomes familiar. The SOVEREIGN (Self-Organizing, Vision, Expectation, Recognition, Emotion, Intelligent, Goal-oriented Navigation) animat model embodies these capabilities, and is tested in a 3D virtual reality environment. SOVEREIGN includes several interacting subsystems which model complementary properties of cortical What and Where processing streams and which clarify similarities between mechanisms for navigation and arm movement control. As the animat explores an environment, visual inputs are processed by networks that are sensitive to visual form and motion in the What and Where streams, respectively. Position-invariant and size-invariant recognition categories are learned by real-time incremental learning in the What stream. Estimates of target position relative to the animat are computed in the Where stream, and can activate approach movements toward the target. Motion cues from animat locomotion can elicit head-orienting movements to bring a new target into view. Approach and orienting movements are alternately performed during animat navigation. Cumulative estimates of each movement are derived from interacting proprioceptive and visual cues. Movement sequences are stored within a motor working memory. Sequences of visual categories are stored in a sensory working memory. These working memories trigger learning of sensory and motor sequence categories, or plans, which together control planned movements. Predictively effective chunk combinations are selectively enhanced via reinforcement learning when the animat is rewarded. Selected planning chunks effect a gradual transition from variable reactive exploratory movements to efficient goal-oriented planned movement sequences. Volitional signals gate interactions between model subsystems and the release of overt behaviors. The model can control different motor sequences under different motivational states and learns more efficient sequences to rewarded goals as exploration proceeds.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2008.03.010,Journal,Neural Networks,scopus,2008-05-01,sciencedirect,Towards a general neural controller for quadrupedal locomotion,https://api.elsevier.com/content/abstract/scopus_id/44949146060,"Our study aims at the design and implementation of a general controller for quadruped locomotion, allowing the robot to use the whole range of quadrupedal gaits (i.e. from low speed walking to fast running). A general legged locomotion controller must integrate both posture control and rhythmic motion control and have the ability to shift continuously from one control method to the other according to locomotion speed. We are developing such a general quadrupedal locomotion controller by using a neural model involving a CPG (Central Pattern Generator) utilizing ground reaction force sensory feedback. We used a biologically faithful musculoskeletal model with a spine and hind legs, and computationally simulated stable stepping motion at various speeds using the neuro-mechanical system combining the neural controller and the musculoskeletal model. We compared the changes of the most important locomotion characteristics (stepping period, duty ratio and support length) according to speed in our simulations with the data on real cat walking. We found similar tendencies for all of them. In particular, the swing period was approximately constant while the stance period decreased with speed, resulting in a decreasing stepping period and duty ratio. Moreover, the support length increased with speed due to the posterior extreme position that shifted progressively caudally, while the anterior extreme position was approximately constant. This indicates that we succeeded in reproducing to some extent the motion of a cat from the kinematical point of view, even though we used a 2D bipedal model. We expect that such computational models will become essential tools for legged locomotion neuroscience in the future.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artint.2007.09.009,Journal,Artificial Intelligence,scopus,2008-04-01,sciencedirect,Teachable robots: Understanding human teaching behavior to build more effective robot learners,https://api.elsevier.com/content/abstract/scopus_id/38649092712,"While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a Reinforcement Learning agent: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback, possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. Given this, we made specific modifications to the simulated RL robot, and analyzed and evaluated its learning behavior in four follow-up experiments with human trainers. We report significant improvements on several learning measures. This work demonstrates the importance of understanding the human-teacher/robot-learner partnership in order to design algorithms that support how people want to teach and simultaneously improve the robot's learning behavior.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-008045374-3/50016-8,Book,Generalisation of Geographic Information,scopus,2007-12-01,sciencedirect,A Prototype Generalisation System Based on the Multi-Agent System Paradigm,https://api.elsevier.com/content/abstract/scopus_id/84884847160,"This chapter presents two pieces of research undertaken at the French National Geographic Institute's (Institut Geographique National, IGN) COGIT laboratory that used multi-agent systems (MAS) to automate the generalization process. These two complementary pieces of work were linked together to build AGIT, which is a generalization research platform based on MAS technology. The work reflects efforts to apply multi-agent systems to map generalization, a core activity within the COGIT laboratory. The concepts of agent and multi-agent systems stem from the field of artificial intelligence (AI). The agent paradigm is increasingly being used to solve complex problems in a broad set of domains, from robotic agents to software agents. Automation of the generalization process is one of the main research subjects of the COGIT laboratory. The automation of this process is a real challenge for a NMA that in the short term wishes to reduce costs and time taken to produce series mapping, and in the longer term wants to be able to deliver maps over the Internet, providing generalization on demand.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2007.01.003,Journal,Engineering Applications of Artificial Intelligence,scopus,2007-10-01,sciencedirect,Application of reinforcement learning in robot soccer,https://api.elsevier.com/content/abstract/scopus_id/34548663531,"The robot soccer game has been proposed as a benchmark problem for the artificial intelligence and robotic researches. Decision-making system is the most important part of the robot soccer system. As the environment is dynamic and complex, one of the reinforcement learning (RL) method named FNN-RL is employed in learning the decision-making strategy. The FNN-RL system consists of the fuzzy neural network (FNN) and RL. RL is used for structure identification and parameters tuning of FNN. On the other hand, the curse of dimensionality problem of RL can be solved by the function approximation characteristics of FNN. Furthermore, the residual algorithm is used to calculate the gradient of the FNN-RL method in order to guarantee the convergence and rapidity of learning. The complex decision-making task is divided into multiple learning subtasks that include dynamic role assignment, action selection, and action implementation. They constitute a hierarchical learning system. We apply the proposed FNN-RL method to the soccer agents who attempt to learn each subtask at the various layers. The effectiveness of the proposed method is demonstrated by the simulation and the real experiments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imavis.2006.08.003,Journal,Image and Vision Computing,scopus,2007-08-01,sciencedirect,Finger identification and hand posture recognition for human-robot interaction,https://api.elsevier.com/content/abstract/scopus_id/34248580490,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2006.09.004,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2007-07-01,sciencedirect,Neuro-fuzzy state modeling of flexible robotic arm employing dynamically varying cognitive and social component based PSO,https://api.elsevier.com/content/abstract/scopus_id/34249704095,The present paper proposes the development of a neuro-fuzzy state-space model for flexible robotic arm on the basis of real sensor data acquired. The training problem of the neuro-fuzzy architecture has been configured as a highly multidimensional stochastic global optimization problem and improved variants of particle swarm optimization (PSO) techniques have been successfully implemented for it. The effects of dynamically varying the “cognitive” and the “social” components of the improved PSOs on the training performance have been studied in detail. The practical utility of such a model development procedure is aptly demonstrated by employing the best trained model to design a stable fuzzy state controller and implementing it in real life for the same flexible robotic arm.,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2006.04.010,Journal,Robotics and Autonomous Systems,scopus,2006-10-31,sciencedirect,Using direct competition to select for competent controllers in evolutionary robotics,https://api.elsevier.com/content/abstract/scopus_id/33748457107,"Evolutionary robotics (ER) is a field of research that applies artificial evolution toward the automatic design and synthesis of intelligent robot controllers. The preceding decade saw numerous advances in evolutionary robotics hardware and software systems. However, the sophistication of resulting robot controllers has remained nearly static over this period of time. Here, we make the case that current methods of controller fitness evaluation are primary factors limiting the further development of ER. To address this, we define a form of fitness evaluation that relies on intra-population competition. In this research, complex neural networks were trained to control robots playing a competitive team game. To limit the amount of human bias or know-how injected into the evolving controllers, selection was based on whether controllers won or lost games. The robots relied on video sensing of their environment, and the neural networks required on the order of 150 inputs. This represents an order of magnitude increase in sensor complexity compared to other research in this field. Evolved controllers were tested extensively in real fully-autonomous robots and in simulation. Results and experiments are presented to characterize the training process and the acquisition of controller competency under different evolutionary conditions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2006.02.003,Journal,Mechatronics,scopus,2006-10-01,sciencedirect,Neural network based-time optimal sliding mode control for an autonomous underwater robot,https://api.elsevier.com/content/abstract/scopus_id/33746483312,"This paper presents a robot control system using sliding mode control (SMC) as a core controller. The SMC switches according to the Pontryagin’s time optimal control principle, in which the solution is obtained by using neural network approach. The control system is implemented on Chalawan, a six-degree-of-freedom autonomous underwater robot developed at Mechatronics Laboratory, AIT. The control system can be applied to underwater robots, which have similar kind of architecture. Performance of the proposed controller is compared with various classical SMCs and conventional linear control system. The comparison detail results such as controller performance and error phase portrait are presented and analyzed. Such comparisons ensure the implementation success and prove it as a real time-optimal controller. The results also show the controller’s effective capabilities in plant nonlinearity and parameters uncertainties.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2005.05.002,Journal,Information Sciences,scopus,2006-06-22,sciencedirect,Design and performance of an intelligent predictive controller for a six-degree-of-freedom robot using the Elman network,https://api.elsevier.com/content/abstract/scopus_id/33646496168,"The aim of this paper was to propose a recurrent neural network-based predictive controller for robotic manipulators. A neural network controller for a six-joint Stanford robotic manipulator was designed using the generalized predictive control (GPC) and the Elman network. The GPC algorithm, which is a class of digital control method, requires long computational time. This is a disadvantage in real-time robot control; therefore, the Elman network controller was designed to reduce processing time by avoiding the highly mathematical and computational complexity of the GPC. The main reason for choosing the Elman network, amongst several neural network algorithms, was that the presence of feedback loops have a profound impact on the learning capability of the network. The designed neural network controller was able to recover quickly because of its significant generalization capability, which allowed it to adapt very rapidly to changes in inputs. The performance of the controller was also shown graphically using simulation software, including the dynamics and kinematics of the robot model.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2005.04.003,Journal,Robotics and Autonomous Systems,scopus,2005-08-31,sciencedirect,Evolution of recurrent neural controllers using an extended parallel genetic algorithm,https://api.elsevier.com/content/abstract/scopus_id/22644434133,"Autonomous intelligent agents often must complete non-Markovian sequential tasks, which require complex recurrent neural controllers. In order to improve the convergence of evolution and reduce the computation time, this paper proposes application of an extended evolutionary algorithm. We implemented an extended multi-population genetic algorithm (EMPGA), where subpopulations apply different evolutionary strategies. In addition, subpopulations compete and cooperate among each other. Results show that EMPGA outperformed single population genetic algorithm (SPGA) by efficiently distributing the number of individuals among subpopulations as different strategies became successful during the course of evolution. In addition, the comparison with other multi-population GA shows that competition between subpopulations improved the quality of solution. The evolved neural controllers were also tested in the real hardware of Cyber Rodent robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2004.09.011,Journal,Information Sciences,scopus,2005-05-13,sciencedirect,On the design of intelligent robotic agents for assembly,https://api.elsevier.com/content/abstract/scopus_id/16344396133,"Robotic agents can greatly be benefited from the integration of perceptual learning in order to monitor and adapt to changing environments. To be effective in complex unstructured environments, robots have to perceive the environment and adapt accordingly. In this paper it is discussed a biology inspired approach based on the adaptive resonance theory (ART) and implemented on an KUKA KR15 industrial robot during real-world operations (e.g. assembly operations). The approach intends to embed naturally the skill learning capability during manufacturing operations (i.e., within a flexible manufacturing system).
                  The integration of machine vision and force sensing has been useful to demonstrate the usefulness of the cognitive architecture to acquire knowledge and to effectively use it to improve its behaviour. Practical results are presented, showing that the robot is able to recognise a given component and to carry out the assembly. Adaptability is validated by using different component geometry during assemblies and also through skill learning which is shown by the robot’s dexterity.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2004.09.018,Journal,Robotics and Autonomous Systems,scopus,2005-03-31,sciencedirect,The Psikharpax project: Towards building an artificial rat,https://api.elsevier.com/content/abstract/scopus_id/13944270338,"Drawing inspiration from biology, the Psikharpax project aims at endowing a robot with a sensory-motor equipment and a neural control architecture that will afford some of the capacities of autonomy and adaptation that are exhibited by real rats. The paper summarizes the current state of achievement of the project. It successively describes the robot's future sensors and actuators, and several biomimetic models of the anatomy and physiology of structures in the rat's brain, like the hippocampus and the basal ganglia, which have already been at work on various robots, and that make navigation and action selection possible. Preliminary results on the implementation of learning mechanisms in these structures are also presented. Finally, the article discusses the potential benefits that a biologically inspired approach affords to traditional autonomous robotics.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2004.09.010,Journal,Robotics and Autonomous Systems,scopus,2004-12-31,sciencedirect,A study of neural network based inverse kinematics solution for a three-joint robot,https://api.elsevier.com/content/abstract/scopus_id/10044270818,"A neural network based inverse kinematics solution of a robotic manipulator is presented in this paper. Inverse kinematics problem is generally more complex for robotic manipulators. Many traditional solutions such as geometric, iterative and algebraic are inadequate if the joint structure of the manipulator is more complex. In this study, a three-joint robotic manipulator simulation software, developed in our previous studies, is used. Firstly, we have generated many initial and final points in the work volume of the robotic manipulator by using cubic trajectory planning. Then, all of the angles according to the real-world coordinates (x, y, z) are recorded in a file named as training set of neural network. Lastly, we have used a designed neural network to solve the inverse kinematics problem. The designed neural network has given the correct angles according to the given (x, y, z) cartesian coordinates. The online working feature of neural network makes it very successful and popular in this solution.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2004.04.002,Journal,Microprocessors and Microsystems,scopus,2004-11-02,sciencedirect,Control of a mobile robot using generalized dynamic fuzzy neural networks,https://api.elsevier.com/content/abstract/scopus_id/4744339382,"This paper presents the design and implementation of a neural fuzzy controller suitable for real-time control of an autonomous mobile robot. The neural fuzzy controller is developed based on the Generalized Dynamic Fuzzy Neural Networks (GDFNN) learning algorithm of Wu et al. (IEEE Transactions on Fuzzy System 9 (4), 2001, 578–594). Not only the parameters of the controller can be optimized, but also the structure of the controller can be self-adaptive. Experimental results show that in comparison with a conventional fuzzy-logic-based controller, the proposed controller is superior in performance.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2004.03.006,Journal,Robotics and Autonomous Systems,scopus,2004-06-30,sciencedirect,Self-valuing learning and generalization with application in visually guided grasping of complex objects,https://api.elsevier.com/content/abstract/scopus_id/2942552836,"For programming by demonstration and for reinforcement learning, the learned skills need appropriate representations for generalization and possibilities for further improvements by the robot itself. We present a self-valuing learning technique which is capable of learning how to grasp unfamiliar objects and generalize the learned abilities. The learning system consists of two components which distinguish between local and global quality criteria for grasp points. The local criteria are not object-specific while the global criteria cover physical properties of each object. In this case we present a generalization method of the learning parameters based on a tree distance model for the medial axis transformations. The system is self-valuing, i.e. it rates its actions by evaluating sensory information and the usage of image processing techniques. This learning system has been implemented in a real robot assembly system equipped with hand-cameras and force/torque sensors. Both the theory and the experiments have shown it ability to grasp a wide range of objects and to apply pre-learned knowledge to new objects.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2003.11.002,Journal,Robotics and Autonomous Systems,scopus,2004-03-31,sciencedirect,Maze exploration behaviors using an integrated evolutionary robotics environment,https://api.elsevier.com/content/abstract/scopus_id/1442283130,"This paper presents results generated with a new evolutionary robotics (ER) simulation environment and its complementary real mobile robot colony research test-bed. Neural controllers producing mobile robot maze searching and exploration behaviors using binary tactile sensors as inputs were evolved in a simulated environment and subsequently transferred to and tested on real robots in a physical environment. There has been a considerable amount of proof-of-concept and demonstration research done in the field of ER control in recent years, most of which has focused on elementary behaviors such as object avoidance and homing. Artificial neural networks (ANN) are the most commonly used evolvable controller paradigm found in current ER literature. Much of the research reported to date has been restricted to the implementation of very simple behaviors using small ANN controllers. In order to move beyond the proof-of-concept stage our ER research was designed to train larger more complicated ANN controllers, and to implement those controllers on real robots quickly and efficiently. To achieve this a physical robot test-bed that includes a colony of eight real robots with advanced computing and communication abilities was designed and built. The real robot platform has been coupled to a simulation environment that facilitates the direct wireless transfer of evolved neural controllers from simulation to real robots (and vice versa). We believe that it is the simultaneous development of ER computing systems in both the simulated and the physical worlds that will produce advances in mobile robot colony research. Our simulation and training environment development focuses on the definition and training of our new class of ANNs, networks that include multiple hidden layers, and time-delayed and recurrent connections. Our physical mobile robot design focuses on maximizing computing and communications power while minimizing robot size, weight, and energy usage. The simulation and ANN-evolution environment was developed using MATLAB. To allow for efficient control software portability our physical evolutionary robots (EvBots) are equipped with a PC-104-based computer running a custom distribution of Linux and connected to the Internet via a wireless network connection. In addition to other high-level computing applications, the mobile robots run a condensed version of MATLAB, enabling ANN controllers evolved in simulation to be transferred directly onto physical robots without any alteration to the code. This is the first paper in a series to be published cataloging our results in this field.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artint.2003.05.001,Journal,Artificial Intelligence,scopus,2004-03-01,sciencedirect,An attempt to formalise a non-trivial benchmark problem in common sense reasoning,https://api.elsevier.com/content/abstract/scopus_id/1642566160,"Most logic-based AI research works at a meta-theoretical level, producing new logics and studying their properties. Little effort is made to show how these logics can be used to formalise object-level theories of common sense. In the spirit of Pat Hayes's Naive Physics Manifesto, the present paper supplies a formalisation of a non-trivial benchmark problem in common sense physical reasoning, namely how to crack an egg. The formalisation is based on the event calculus, a well-known formalism for reasoning about action. Along the way, a number of methodological issues are raised, such as the question of how the symbols deployed in the formalisation might be grounded through a robot's interaction with the world.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artint.2003.07.001,Journal,Artificial Intelligence,scopus,2004-03-01,sciencedirect,Logic-based subsumption architecture,https://api.elsevier.com/content/abstract/scopus_id/1642484539,"We describe a logic-based AI architecture based on Brooks' subsumption architecture. In this architecture, we axiomatize different layers of control in First-Order Logic (FOL) and use independent theorem provers to derive each layer's outputs given its inputs. We implement the subsumption of lower layers by higher layers using nonmonotonic reasoning principles. In particular, we use circumscription to make default assumptions in lower layers, and nonmonotonically retract those assumptions when higher layers draw new conclusions. We also give formal semantics to our approach. Finally, we describe layers designed for the task of robot control and a system that we have implemented that uses this architecture for the control of a Nomad 200 mobile robot.
                  Our system combines the virtues of using the represent-and-reason paradigm and the behavioral-decomposition paradigm. It allows multiple goals to be serviced simultaneously and reactively. It also allows high-level tasks and is tolerant to different changes and elaborations of its knowledge in runtime. Finally, it allows us to give more commonsense knowledge to robots. We report on several experiments that empirically show the feasibility of using fully expressive FOL theorem provers for robot control with our architecture and the benefits claimed above.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2003.11.006,Journal,Robotics and Autonomous Systems,scopus,2004-02-29,sciencedirect,A reinforcement learning with evolutionary state recruitment strategy for autonomous mobile robots control,https://api.elsevier.com/content/abstract/scopus_id/0742289960,"In recent robotics fields, much attention has been focused on utilizing reinforcement learning (RL) for designing robot controllers, since environments where the robots will be situated in should be unpredictable for human designers in advance. However there exist some difficulties. One of them is well known as ‘curse of dimensionality problem’. Thus, in order to adopt RL for complicated systems, not only ‘adaptability’ but also ‘computational efficiencies’ should be taken into account. The paper proposes an adaptive state recruitment strategy for NGnet-based actor-critic RL. The strategy enables the learning system to rearrange/divide its state space gradually according to the task complexity and the progress of learning. Some simulation results and real robot implementations show the validity of the method.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2003.07.001,Journal,Applied Soft Computing Journal,scopus,2004-02-01,sciencedirect,Recognizing environments from action sequences using self-organizing maps,https://api.elsevier.com/content/abstract/scopus_id/2442623476,"In this paper, we describe development of a mobile robot which does unsupervised learning for recognizing an environment from action sequences. We call this novel recognition approach action-based environment modeling (AEM). Most studies on recognizing an environment have tried to build precise geometric maps with high sensitive and global sensors. However such precise and global information may be hardly obtained in a real environment, and may be unnecessary to recognize an environment. Furthermore unsupervised-learning is necessary for recognition in an unknown environment without help of a teacher. Thus we attempt to build a mobile robot which does unsupervised-learning to recognize environments with low sensitive and local sensors. The mobile robot is behavior-based and does wall-following in enclosures (called rooms). Then the sequences of actions executed in each room are transformed into environment vectors for self-organizing maps. Learning without a teacher is done, and the robot becomes able to identify rooms. Moreover, we develop a method to identify environments independent of a start point using a partial sequence. We have fully implemented the system with a real mobile robot, and made experiments for evaluating the ability. As a result, we found out that the environment recognition was done well and our method was adaptive to noisy environments.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0957-4158(03)00004-7,Journal,Mechatronics,scopus,2003-10-01,sciencedirect,A new golf swing robot to simulate human skill - Accuracy improvement of swing motion by learning control,https://api.elsevier.com/content/abstract/scopus_id/0038348360,"A new golf swing robot to simulate human skill of motion control with one actuated joint and one passive joint has been developed by authors. Because of the special mechanism with non-holonomic constraint of the robot and the motion of high speed, it is difficult to realize an accurate swing motion by usual feedback control. To solve the problem, this paper describes a control method using mainly feedforward control based on an approximate inverse dynamics model (IDM) close to the real system. The approximate IDM is composed of a simple IDM and a compensation IDM represented by a neural network and is to be improved by learning in doing. By this method, most part of control input is shifted from feedback control to feedforward control and an accurate swing can be realized. The method is implemented to the prototype of golf swing robot, and experimental results of shadow swing before and after learning control show the effectiveness of the proposed learning control.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0531-5131(03)00353-4,Book Series,International Congress Series,scopus,2003-06-01,sciencedirect,The NASA Smart Probe Project for real-time multiple microsensor tissue recognition: Update,https://api.elsevier.com/content/abstract/scopus_id/12144250151,"The NASA Smart Probe combines information from multiple microsensors—using fuzzy logic and neural network software—to provide a unique tissue “signature” in real time. This report presents recent advances in the probe architecture itself plus clinical information gathered from women undergoing biopsy for suspected breast cancer by the NASA licensee, BioLuminate (Dublin, CA, USA). The multiparameter Smart Probe for breast cancer—1 mm in diameter—can clearly differentiate normal breast, benign lesions, and breast carcinoma. The sensors employed in the Smart Probe for breast cancer include electrical impedance and optical spectroscopy (OS) (both broadband or white light, and laser light (infrared and blue/fluorescence)). Data are acquired 100 times per second; a typical breast “biopsy” typically generates 500 MB of data. Potential applications of nanoelectrode arrays and the Smart Probe concept for deep brain recording and stimulation in neurosurgery are also noted.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S1474-6670(17)33456-0,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2003-01-01,sciencedirect,Neuromorphic processing of image relevance function for path planning and navigation,https://api.elsevier.com/content/abstract/scopus_id/85064434105,"This paper proposes the use of an image operator called image relevance function (IRF) for path planning of a mobile robot. Successive maxima of IRF fonn a skeleton of the path. The IRF function is formed by combining image components related to the contrast and the homogeneity of an image property map. The problemdependent property map of the image is defined based on an extended polynomial regression model within a region of interest. By applying gradient-based neuromorphic processing on the image property map, the relevance function method can be extended to the task of local navigation. An important practical advantage of the proposed methods is that they can be directly implemented and executed in real time on VLSI circuits. Copyright © 2003 IFAC.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S1474-6670(17)32540-5,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2003-01-01,sciencedirect,A real-time system for tracking and catching moving targets,https://api.elsevier.com/content/abstract/scopus_id/84979882249,"In this paper we describe the real-time issues related to the development of a control system for tracking and catching moving targets by vision. After describing the main hardware and software components of the system, we discuss a number of interesting scheduling problems that arise in these kind of control applications. A possible solution to these problems is also outlined and has been implemented on top the Shark operating system. used to develop the real-time application. The experimental results obtained on the system prototype show the effectiveness of our approach and encourage further research on the specific scheduling problems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0957-4158(03)00042-4,Journal,Mechatronics,scopus,2003-01-01,sciencedirect,Mechatronic design,https://api.elsevier.com/content/abstract/scopus_id/0041509193,"Mechatronic design is the integrated design of a mechanical system and its embedded control system. In order to make proper choices early in the design stage, tools are required that support modelling and simulation of physical systems––together with the controllers––with parameters that are directly related to the real-world system. Such software tools are becoming available now. Components in various physical domains (e.g. mechanical or electrical) can easily be selected from a library and combined into a ‘process’ that can be controlled by block-diagram-based (digital) controllers. A few examples will be discussed that show the use of such a tool in various stages of the design. The examples include a typical mechatronic system with a flexible transmission, a mobile robot, and an industrial linear motor with a neural-network-based learning feed-forward controller that compensates for cogging.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/s0141-9331(02)00069-8,Journal,Microprocessors and Microsystems,scopus,2002-12-20,sciencedirect,Real-time implementation of a dynamic fuzzy neural networks controller for a SCARA,https://api.elsevier.com/content/abstract/scopus_id/0037147579,"This paper presents the design, development and implementation of a Dynamic Fuzzy Neural Networks (D-FNNs) Controller suitable for real-time industrial applications. The unique feature of the D-FNNs controller is that it has dynamic self-organising structure, fast learning speed, good generalisation and flexibility in learning. The approach of rapid prototyping is employed to implement the D-FNNs controller with a view of controlling a Selectively Compliance Assembly Robot Arm (SCARA) in real time. Simulink, an iterative software for simulating dynamic systems, is used for modelling, simulation and analysis of the dynamic system. The D-FNNs controller was implemented through Real-Time Workshop (RTW). RTW generates C-codes from the Simulink block diagrams and in turn, the generated codes (object codes) are downloaded to the dSPACE DS1102 floating-point processor, together with the supporting files, for execution. The performance of the D-FNNs controller was found to be superior and it matches favourably with the simulation results.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(02)00232-4,Journal,Robotics and Autonomous Systems,scopus,2002-08-31,sciencedirect,Behavior generation for a mobile robot based on the adaptive fitness function,https://api.elsevier.com/content/abstract/scopus_id/0037206240,"We have to prepare the evaluation (fitness) function to evaluate the performance of the robot when we apply the machine learning techniques to the robot application. In many cases, the fitness function is composed of several aspects. Simple implementation to cope with the multiple fitness functions is a weighted summation. This paper presents an adaptive fitness function for the evolutionary computation to obtain the purposive behaviors through changing the weights for the fitness function. As an example task, a basic behavior in a simplified soccer game (shooting a ball into the opponent goal) is selected to show the validity of the adaptive fitness function. Simulation results and real experiments are shown, and a discussion is given.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(02)00165-3,Journal,Robotics and Autonomous Systems,scopus,2002-03-31,sciencedirect,Visual approach skill for a mobile robot using learning and fusion of simple skills,https://api.elsevier.com/content/abstract/scopus_id/0037204478,"This paper presents a reinforcement learning algorithm which allows a robot, with a single camera mounted on a pan tilt platform, to learn simple skills such as watch and orientation and to obtain the complex skill called approach combining the previously learned ones. The reinforcement signal the robot receives is a real continuous value so it is not necessary to estimate an expected reward. Skills are implemented with a generic structure which permits complex skill creation from sequencing, output addition and data flow of available simple skills.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.3182/20020721-6-es-1901.01303,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2002-01-01,sciencedirect,High-level control of autonomous robots using a behavior-based scheme and reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/84945581469,"This paper proposes a behavior-based scheme for high-level control of autonomous robots. Two main characteristics can be highlighted in the control scheme. Behavior coordination is done through a hybrid methodology, which takes in advantages of the robustness and modularity in competitive approaches, as well as optimized trajectories in cooperative ones. As a second feature, behavior state/action mapping is learnt by means of Reinforcement Learning (RL). A new continuous approach of the Q_learning algorithm, implemented with a multi-layer neural network, is used. The behavior-based scheme attempts to fulfill simple missions in which several behaviors/tasks compete for the vehicle's control. This paper is centered in the RL-based behaviors. In order to test the feasibility of the proposed Neural-Q_learning scheme, real experiments with the underwater robot ODIN in a target following behavior were done. Results showed the convergence of the behavior into an optimal state/action mapping. Discussion about the proposed approach is given, as well as an overall description of the high level control scheme.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0026-2714(01)00097-X,Journal,Microelectronics Reliability,scopus,2001-12-01,sciencedirect,The Hi-NOON neural simulator and its applications,https://api.elsevier.com/content/abstract/scopus_id/0035576219,"This paper describes the Hi-noon (hierarchical network of object-oriented neurons) neural simulator, originally conceived as a general-purpose, computationally efficient, object-oriented software system for the simulation of small systems of biological neurons, as an aid to the study of links between neurophysiology and behaviour in lower animals. As such, the artificial neurons employed were spiking in nature; to effect an appropriate compromise between computational complexity and biological realism, modelling was at the transmembrane potential level of abstraction. Further, since real neural systems incorporate different types of neurons specialised to somewhat different functions, the software was written to accommodate a non-homogeneous population of neurons. The computational efficiency of Hi-noon makes it eminently suitable for situated system studies (biological robotics, animats) where real-time operation is a pre-requisite. The flexibility which was a central design goal of Hi-noon means that the system is also capable of modelling interconnections of non-spiking artificial neurons with continuous or piecewise linear activation functions. The efficacy of the simulator is illustrated with respect to some recent applications to situated systems studies. We also consider prospects for integrating Hi-noon with a conventional circuit simulator in the future.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(01)00031-8,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-10-01,sciencedirect,Reinforcement learning control of nonlinear multi-link system,https://api.elsevier.com/content/abstract/scopus_id/0035493967,"In this paper, the effects of basic parameters in reinforcement learning control such as eligibility, action and critic network constrained weights, system nonlinearities, gradient information, state-space partitioning, variance of exploration are studied in detail. It is attempted to increase feasibility for practical applications, implementation, learning efficiency, and enhance performance. Also, a novel adaptive grid algorithm is proposed to overcome the difficulty in partitioning the input space to achieve better performance. Reinforcement learning is applied for control of a nonlinear one and two-link robots. This problem dictates that the learning is performed on-line, based on a binary or real-valued reinforcement signal from a critic network, without knowing the system model or nonlinearity.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(01)00113-0,Journal,Robotics and Autonomous Systems,scopus,2001-07-31,sciencedirect,Acquisition of stand-up behavior by a real robot using hierarchical reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/0035979437,"In this paper, we propose a hierarchical reinforcement learning architecture that realizes practical learning speed in real hardware control tasks. In order to enable learning in a practical number of trials, we introduce a low-dimensional representation of the state of the robot for higher-level planning. The upper level learns a discrete sequence of sub-goals in a low-dimensional state space for achieving the main goal of the task. The lower-level modules learn local trajectories in the original high-dimensional state space to achieve the sub-goal specified by the upper level.
                  We applied the hierarchical architecture to a three-link, two-joint robot for the task of learning to stand up by trial and error. The upper-level learning was implemented by Q-learning, while the lower-level learning was implemented by a continuous actor–critic method. The robot successfully learned to stand up within 750 trials in simulation and then in an additional 170 trials using real hardware. The effects of the setting of the search steps in the upper level and the use of a supplementary reward for achieving sub-goals are also tested in simulation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0954-1810(01)00003-6,Journal,Artificial Intelligence in Engineering,scopus,2001-07-01,sciencedirect,A low-cost Internet-based telerobotic system for access to remote laboratories,https://api.elsevier.com/content/abstract/scopus_id/0035385318,"This paper presents an account of the design of a low-cost Internet-based teleoperation system implemented on China's Internet. Using a multimedia-rich human-computer interface, combining predictive displays and graphical overlays, a series of simple tasks were performed within a simulated space environment scenario. Internet clients anywhere can monitor the robotic workspace, talk with technicians, and control the Arm/Hand integrated system with 15DOF located in lab to perform tasks (such as grasping a vessel, pouring a liquid, and peg-in-hole assembling, etc.). Our main contributions are to establish a foundation for teleoperated science and engineering research, and we have addressed some issues involving the time-delay associated with the Internet. We also developed several key software adaptation technologies and products used for Internet-Based teleoperation, compatible with the BH-III dexterous hand, BH1 6-DOF mechanical arm and five-finger 11-DOF data glove, constructed in our laboratory. This system has been successfully tested and applied in remote robotic education (Virtual Laboratories) system via China's Internet using our Master/Slave architecture, which combines mixed modes of remote monitor/manipulate and local autonomous control.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0925-2312(01)00500-8,Journal,Neurocomputing,scopus,2001-06-01,sciencedirect,A biologically inspired visual system for an autonomous robot,https://api.elsevier.com/content/abstract/scopus_id/17544395043,"We have implemented an artificial visual system that takes advantage of known properties of biological systems to achieve segmentation and recognition of simple images. The use of biologically plausible mechanisms makes the system inherit a series of features that are present in biological systems, such as flexibility, robustness and adaptability. The implementation of the model on an autonomous robot has proved its reliability and robustness in real environments and shows the relevance of this kind of approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(01)00010-0,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-06-01,sciencedirect,Opportunistic planning for a fleet of transportation robots,https://api.elsevier.com/content/abstract/scopus_id/0035366212,"The Dynamic Transportation-Planning Problem (DTPP) embodies a class of real-world applications that involve the reactive routing and scheduling of a fleet of vehicles in response to dynamically changing transportation demands. Examples include mobile robots in a warehouse, taxis in an urban road network, or aeroplanes for medical evacuation. In contrast with the Vehicle Routing Problem, for which a plethora of techniques is available, few approaches exist that permit the efficient deployment of a large number of vehicles in a changing environment. This paper highlights the characteristic features of the problem, reviews possible approaches and existing techniques, and proposes a heuristic solution to the DTPP using a Blackboard-based approach. The resulting application is an intelligent transportation planning system (ITPS) for a fleet of automated robot taxis, based on the generic assumption-based truth maintained Blackboard shell (GATMBS) and comprising traffic simulation models as well as various monitoring and problem-solving strategies for assignment and routing. The Blackboard architecture supports the dynamic alteration of planned routes in response to changes in traffic conditions and passenger requests. A prototype of the ITPS has been validated in simulation using a small fleet of robot taxis with randomly generated road networks, background traffic load, and passenger requests.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0020-0255(01)00081-0,Journal,Information Sciences,scopus,2001-04-01,sciencedirect,Considerations in the application of evolution to the generation of robot controllers,https://api.elsevier.com/content/abstract/scopus_id/0035307250,"This paper is concerned with different aspects of the use of evolution for the successful generation of real robot Artificial Neural Network (ANN) controllers. Several parameters of an evolutionary/genetic algorithm (GA) and the way they influence the evolution of ANN behavioral controllers for real robots have been contemplated. These parameters include the way the initial populations are distributed, how the individuals are evaluated, the implementation of race schemes, etc. A batch of experiments on the evolution of three types of behaviors with different population sizes have been carried out in order to ascertain their effect on the evolution of the controllers and their validity in real implementations. The results provide a guide to the design of evolutionary algorithms for generating ANN based robot controllers, especially when, due to computational constraints, the populations to be used are small with respect to the complexity of the problem to be solved. The problem of transferring the controllers evolved in simulated environments to the real systems operating in real environments are also considered and we present results of this transference to reality with a robot which has few and extremely noisy sensors.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0097-8493(01)00151-0,Journal,Computers and Graphics (Pergamon),scopus,2001-01-01,sciencedirect,An artificial life approach for the animation of cognitive characters,https://api.elsevier.com/content/abstract/scopus_id/0035578037,"This paper addresses the problem of cognitive character animation. We propose the use of finite state machines for the behavioral control of characters. Our approach rests on the idea that the cognitive character arises from the evolutionary computation embedded in the artificial life simulation, which in our case is implemented by the finite state machine. We present some of the results of the WOXBOT/ARENA research project. This project to build virtual worlds is aimed at the graphic simulation of an arena, where small mobile robots can perform requested tasks while behaving according to their own motivation and reasoning. Each robot is an intelligent agent that perceives the virtual environment through a simulated vision system and reacts by moving away from or approaching the object it sees. The conception and specification of the robots and environment are being done very carefully to create an open distributed object architecture that could serve as a test-bed freely available and ready to use for testing theories in some computational areas such as evolutionary computation, artificial life, pattern recognition, artificial intelligence, cognitive neurosciences and distributed objects architectures. Furthermore, it is a first step towards building a cognitive animated character.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(01)00004-5,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-01-01,sciencedirect,Parallel and diagonal parking in nonholonomic autonomous vehicles,https://api.elsevier.com/content/abstract/scopus_id/0035435172,"This paper considers the problem of parallel and diagonal parking in wheeled vehicles. A method to plan in real-time a set of collision-free manoeuvres is presented. Artificial intelligent techniques, namely fuzzy logic, play an important role in the practical application of the method. Thus, a fuzzy system is used to select the most suitable manoeuvre from the solution set according with the environment, dealing with optimality, path tracking performance and collision avoidance trade-off. This technique has been implemented in a fuzzy behaviour-based control architecture combining planning and reactivity. The efficiency of the proposed method is demonstrated using the nonholonomic mobile robot ROMEO-3R designed and built at the University of Seville.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0020-0255(01)00149-9,Journal,Information Sciences,scopus,2001-01-01,sciencedirect,Learning fuzzy classifier systems for multi-agent coordination,https://api.elsevier.com/content/abstract/scopus_id/0035426729,"We present ELF, a learning fuzzy classifier system (LFCS), and its application to the field of Learning Autonomous Agents. In particular, we will show how this kind of Reinforcement Learning systems can be successfully applied to learn both behaviors and their coordination for Autonomous Agents. We will discuss the importance of knowledge representation approach based on fuzzy sets to reduce the search space without losing the required precision. Moreover, we will show how we have applied ELF to learn the distributed coordination among agents which can exchange information with each other. The experimental validation has been done on software agents interacting in a real-time task.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(00)00070-1,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-01-01,sciencedirect,"Perception network for the team of indoor mobile robots: Concept, architecture, implementation",https://api.elsevier.com/content/abstract/scopus_id/0035311549,"The concept of perception network with application to the distributed perception processes taking place among mobile robots operating on the shared shop-floor is discussed. Its relationship with the distributed environment modeling is pointed out. The concept of geometrical database is combined with multiple classes of maps generated with particular physical sensors, in order to obtain the world model. The logical and functional structure of the perception network has been proposed to reflect the semantics of the transportation system consisting of the team of indoor mobile robots.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(00)00047-6,Journal,Engineering Applications of Artificial Intelligence,scopus,2001-01-01,sciencedirect,Genetic adaptive control for an inverted wedge: Experiments and comparative analyses,https://api.elsevier.com/content/abstract/scopus_id/0035254088,"The inverted wedge is a planar robot with two degrees of freedom and a single control input (i.e., it is “underactuated”). The goal is to develop a digital controller that can balance the wedge in the inverted position by shifting a weight on the top of the wedge. Because it is underactuated and has complicated nonlinear dynamics, the inverted wedge is a good testbed for the development of nonconventional advanced control techniques and comparative analysis between control methods. We begin with the development of a nonlinear state feedback controller and direct and adaptive fuzzy controllers, that we will later use as a baseline comparison to show what type of performance is possible for this testbed. Control routines based on the GA have been found to apply to several practical applications in simulation and off-line optimization. Here, we will show that a GA can be used on-line in real-time to produce a particularly effective adaptive control method and this is the main contribution of this work. Computational and real-time implementation issues will be discussed and the genetic adaptive strategy will be compared with the state feedback and fuzzy control methods.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(00)00026-9,Journal,Engineering Applications of Artificial Intelligence,scopus,2000-08-01,sciencedirect,A novel neuro-estimator and it's application to parameter estimation in a remotely piloted vehicle,https://api.elsevier.com/content/abstract/scopus_id/0343005882,"The paper presents a novel neuro-computing approach to the problem of state estimation by means of a hybrid combination of a Hopfield neural network and a feedforward multilayer neural net capable to solve certain optimization problems. This neuro-estimator is very appropriate for the real-time implementation of nonlinear state estimators, especially when the modeling of uncertainty is considered in the problem. The proposed estimator is applied to estimate the aerodynamic parameters of a remotely piloted vehicle. Simulation results show the effectiveness of the proposed method.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(99)00070-6,Journal,Robotics and Autonomous Systems,scopus,2000-01-31,sciencedirect,Visual homing problem: An example of robotics/biology cross fertilization,https://api.elsevier.com/content/abstract/scopus_id/0033906523,"In this paper, we describe how a mobile robot under simple visual control can retrieve a particular goal location in an open environment. Our model neither needs a precise map nor to learn all the possible positions in the environment. The system is a neural architecture inspired by neurobiological analysis of how visual patterns named landmarks are recognized. The robot merges these visual informations and their azimuth to build a plastic representation of its location. This representation is used to learn the best movement to reach the goal. A simple and fast on-line learning of a few places located near the goal allows this goal to be reached from anywhere in its neighborhood. The system uses only a very rough representation of the robot environment and presents very high generalization capabilities. We describe an efficient implementation of autonomous and motivated navigation tested on our robot in real indoor environments. We show the limitations of the model and its possible extensions.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0888-613X(00)00056-6,Journal,International Journal of Approximate Reasoning,scopus,2000-01-01,sciencedirect,"Fuzzy behaviors for mobile robot navigation: Design, coordination and fusion",https://api.elsevier.com/content/abstract/scopus_id/0343290240,"The implementation of complex behavior generation for artificial systems can be overcome by decomposing the global tasks into simpler, well-specified behaviors which are easier to design and can be tuned independently of each other. Robot behavior can be implemented as a set of fuzzy rules which mimic expert knowledge in specific tasks in order to model expert knowledge. These behaviors are included in the lowest level of a hybrid deliberative–reactive architecture which is aimed at an efficient integration of planning and reactive control. In this work, we briefly present the architecture and attention is focused on the design, coordination and fusion of the elementary behaviors. The design is based on regulatory control using fuzzy logic control and the coordination is defined by fuzzy metarules which define the context of applicability for each behavior. Regarding action fusion, two combination methods for fusing the preferences from each behavior are used in the experiments. In order to validate the system, several measures are also proposed, and thus the performance of the architecture and combination/arbitration algorithms have been demonstrated in both the simulated and the real world. The robot achieves every control objective and the trajectory is smooth in spite of the interaction between several behaviors, unexpected obstacles and the presence of noisy data. When the results of the experimentation from both methods are taken into account, the influence of the combination method appears to be of prime importance when attempting to achieve the best trade-off among the preferences of every behavior.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0957-4158(99)00058-6,Journal,Mechatronics,scopus,2000-01-01,sciencedirect,Analysis and real-time implementation of a radial-basis-function neural-network compensator for high-performance robot manipulators,https://api.elsevier.com/content/abstract/scopus_id/0034135293,"System performance of robot manipulators with nonadaptive controllers might degrade significantly in the presence of structured or unstructured uncertainties. In order to improve the system performance, a novel radial-basis-function (RBF) neural-network (NN) compensator is proposed. With the RBF NN compensator introduced, the system errors and the NN weights with large dispersion in the initial NN weights are guaranteed to be bounded in the Lyapunov sense. The NN weights of the RBF NN compensator are adaptively tuned. Several software-based controllers, including the computed-torque control (CTC) and a few RBF NN schemes, are implemented in an industrial manipulator in real time. Experimental results are obtained to demonstrate the relative effectiveness of the proposed controllers in improving the tracking performance of the robot manipulators associated with structured or unstructured uncertainties.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0094-114X(98)00091-3,Journal,Mechanism and Machine Theory,scopus,2000-01-01,sciencedirect,Dynamic optimization of redundant manipulators in worst case using recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/0033733372,"The aim of this paper is to find a comprehensive dynamic performance index (CDPI) for evaluating dynamic merit, and to develop a procedure for the optimization of dynamic performance for redundant manipulators in the worst case. CDPI stands for the maximum normalized joint driving torque and it can be minimized by linear programming. To obtain the minimum CDPI solution, a recurrent neural-network-based computational scheme is proposed for real time implementation. Robot configurations reached using the proposed planning algorithm can obtain the minimum joint driving torques. Numerical simulations have been carried out which illustrate good performance capability from the viewpoint of torque optimization.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(99)00055-X,Journal,Robotics and Autonomous Systems,scopus,1999-12-31,sciencedirect,On robots and flies: modeling the visual orientation behavior of flies,https://api.elsevier.com/content/abstract/scopus_id/0033352703,"Although artificial and biological systems face similar sensorimotor control problems, until today only a few attempts have been made to implement specific biological control structures on robots. Nevertheless, the process of designing the sensorimotor control of a robot can contribute to our understanding of these mechanisms and can provide the basis of a critical evaluation of existing biological models. Flies have developed a specialized visuomotor control for tasks such as course stabilization, fixation and approach towards stationary objects, tracking of moving objects and landing, which are based on the analysis of visual motion information. Theoretical and experimental results suggest that in flies the visuomotor control for course stabilization as well as fixation and approach towards stationary objects may be implemented at least partially by one common sensory circuit. We present agents with a visuomotor controller that regulates the two behaviors of course stabilization and object fixation. To test this controller under real world conditions, we implemented it on a miniature robot. We have been able to show that in addition to course stabilization and object fixation, the robot also approaches stationary objects.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0969-806X(98)00275-8,Journal,Radiation Physics and Chemistry,scopus,1999-01-01,sciencedirect,NorTRACK(TM) product tracking system - Development and implementation,https://api.elsevier.com/content/abstract/scopus_id/0344178164,"This paper presents the experience gained by developers and users with implementation and operation of NorTRACKTM, a real-time computerized product tracking system. A Programmable Logic Controller (PLC) collects and transfers data in real time to NorTRACK’s OracleTM database on a Windows NTTM server network. After extensive development and Beta testing at MDS Nordion’s Canadian Irradiation Centre in Montreal, Canada, NorTRACK was installed in January 1997 with a new irradiation facility in Ethicon Endo-Surgery Inc.’s Albuquerque plant in the United States. NorTRACK communicates with the irradiator control and safety system, the plant's central manufacturing database, an innovative pallet staging and tote loading robot, and an automated dosimetry reading system. This integrated system allows the sterilization facility to monitor the irradiator operation and the flow of many products, through varied processing modes, continuously and reliably. As a result of operating with NorTRACK, both MDS Nordion’s CIC facility and the Endo-Surgery manufacturing site, are beginning to realize unique benefits in their respective operations. MDS Nordion is also initiating several future product enhancements and additional productivity modules. This paper describes the NorTRACK system, the various stages of the development project and Beta tests, and the experience of the users to date in their operations.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0273-1177(99)00318-X,Journal,Advances in Space Research,scopus,1999-01-01,sciencedirect,Development of autonomous control in a closed microbial bioreactor,https://api.elsevier.com/content/abstract/scopus_id/0033374124,"Space-based life support systems which include ecological components will rely on sophisticated hardware and software to monitor and control key system parameters. Autonomous closed artificial ecosystems are useful for research in numerous fields. We are developing a bioreactor designed to study both microbe-environment interactions and autonomous control systems. Currently we are investigating N-cycling and N-mass balance in closed microbial systems. The design features of the system involve real-time monitoring of physical parameters (e.g. temperature, light), growth solution composition (e.g. pH, NOx, CO2), cell density and the status of important hardware components. Control of key system parameters is achieved by incorporation of artificial intelligence software tools that permit autonomous decision-making by the instrument. These developments provide a valuable research tool for terrestrial microbial ecology, as well as a testbed for implementation of artificial intelligence concepts. Autonomous instrumentation will be necessary for robust operation of space-based life support systems, and for use on robotic spacecraft. Sample data acquired from the system, important features of software components, and potential applications for terrestrial and space research will be presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0004-3702(99)00025-9,Journal,Artificial Intelligence,scopus,1999-01-01,sciencedirect,"Task decomposition, dynamic role assignment, and low-bandwidth communication for real-time strategic teamwork",https://api.elsevier.com/content/abstract/scopus_id/0033149662,"Multi-agent domains consisting of teams of agents that need to collaborate in an adversarial environment offer challenging research opportunities. In this article, we introduce periodic team synchronization (PTS) domains as time-critical environments in which agents act autonomously with low communication, but in which they can periodically synchronize in a full-communication setting. The two main contributions of this article are a flexible team agent structure and a method for inter-agent communication. First, the team agent structure allows agents to capture and reason about team agreements. We achieve collaboration between agents through the introduction of formations. A formation decomposes the task space defining a set of roles. Homogeneous agents can flexibly switch roles within formations, and agents can change formations dynamically, according to pre-defined triggers to be evaluated at run-time. This flexibility increases the performance of the overall team. Our teamwork structure further includes pre-planning for frequently occurring situations. Second, the communication method is designed for use during the low-communication periods in PTS domains. It overcomes the obstacles to inter-agent communication in multi-agent environments with unreliable, single-channel, high-cost, low-bandwidth communication. We fully implemented both the flexible teamwork structure and the communication method in the domain of simulated robotic soccer, and conducted controlled empirical experiments to verify their effectiveness. In addition, our simulator team made it to the semi-finals of the RoboCup-97 competition, in which 29 teams participated. It achieved a total score of 67–9 over six different games, and successfully demonstrated its flexible teamwork structure and inter-agent communication.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(98)00054-2,Journal,Robotics and Autonomous Systems,scopus,1998-11-30,sciencedirect,Q-learning of complex behaviors on a six-legged walking machine,https://api.elsevier.com/content/abstract/scopus_id/0032208351,"We present work on a six-legged walking machine that uses a hierarchical version of [C.J.C.H. Watkins, Learning with delayed rewards, Ph.D. Thesis, Psychology Department, Cambridge University, 1989] Q-learning (HQL) to learn both: the elementary swing and stance movements of individual legs as well as the overall coordination scheme to perform forward movements. The architecture consists of a hierarchy of local controllers implemented in layers. The lowest layer consists of control modules performing elementary actions, like moving a leg up, down, left or right to achieve the elementary swing and stance motions for individual legs. The next level consists of controllers that learn to perform more complex tasks like forward movement by using the previously learned, lower level modules. The work is related to similar, although simulation based, work [L.J. Lin, Reinforcement learning for robots using neural networks, Ph.D. Thesis, Carnegie Mellon University, 1993] on hierarchical reinforcement-learning and [S.P. Singh, learning to solve Markovian decision problems, Ph.D. Thesis, Department of Computer Science at the University of Massachusetts, 1994] on compositional Q-learning. We report on the HQL architecture as well as on its implementation on the walking machine Sir Arthur. Results from experiments carried out on the real robot are reported to show the applicability of the HQL approach to real world robot problems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(98)00005-0,Journal,Robotics and Autonomous Systems,scopus,1998-10-31,sciencedirect,A robust landmark-based system for vehicle location using low-bandwidth vision,https://api.elsevier.com/content/abstract/scopus_id/0032180335,"This paper presents novel computer algorithms, a system architecture, and the prototype implementation of a vision-based automatic vehicle location system. The objective of the vehicle location system is to keep track of the vehicle location for a human driver, and perhaps to provide the driver with real-time audio directions to his destination. The techniques developed here are equally applicable to autonomous robot navigation. The prototype system uses odometer readings and a skeleton map to perform dead reckoning, and uses low-bandwidth visual information and neural networks to recognize places for correcting cumulative dead reckoning errors. The visual information is also used to detect turns, for dead reckoning at intersections. The system is self-contained in the sense that it requires no infrastructure outside the vehicle, such as external beacons installed on roadways or satellites used by Global Positioning Systems (GPS). The system maintains a large number of location hypotheses and searches for a large number of landmarks stored in a database in real time. Hence the system is robustly able to recover the vehicle location after being lost for various reasons. The system has been tested, with success, in both day and night time, in all four seasons, and on roads in New York City, a regional highway, and on suburban streets.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0952-1976(97)00076-6,Journal,Engineering Applications of Artificial Intelligence,scopus,1998-04-01,sciencedirect,Sensing the third dimension in stereo vision systems: A cellular neural networks approach,https://api.elsevier.com/content/abstract/scopus_id/0032041455,"In this paper the use of the cellular neural network (CNN) paradigm is investigated for the vision-based real-time guidance of robots. This paradigm is employed in recovering information on the tridimensional structure of the environment, through the resolution of the static and the lateral motion stereo vision problems. The proposed approaches exploit the spontaneous internal energy decrease of the CNN, coding the problem in terms of an optimisation task. Results of computer simulations on some test cases for the two different issues are provided. The performance of a hardware implementation of these networks for the tasks presented is outlined.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0893-6080(98)00048-3,Journal,Neural Networks,scopus,1998-01-01,sciencedirect,Neural control of rhythmic arm movements,https://api.elsevier.com/content/abstract/scopus_id/0032191803,"In this paper we present an approach to robot arm control based on exploiting the dynamical properties of a simple neural network oscillator circuit coupled to the joints of an arm. The entrainment and input/output properties of the oscillators are used to perform a variety of tasks with the same architecture, without any modeling of the arm or its environment. The approach is implemented on two real robot arms, and has been used to tune into the resonant frequency of pendulums, perform multi-joint coordinated motion by turning cranks, and exploit the dynamics of a `Slinky' toy to coordinate the motion of two arms. By exploiting the coupling between the physical arm and the neural oscillator, a range of complex behaviors can be achieved with a very simple system.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0951-5240(98)00013-5,Journal,Computer Integrated Manufacturing Systems,scopus,1998-01-01,sciencedirect,Neural networks implementations to control real-time manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/0032180310,"The main objective of advanced manufacturing control techniques is to provide efficient and accurate tools in order to control machines and manufacturing systems in real-time operations. Recent developments and implementations of expert systems and neural networks support this objective. This research explores the use of neural networks to control several manufacturing systems in real-time operations: robot manipulators, tool changes, conveyor systems and machine faults diagnosis. The main barrier to wide implementation of neural networks is the huge computation resources (times and capacities) required to train a network. This research represents the use of a multi-layer architecture of networks (input layer, several hidden layers and an output layer) to define single-valued inter-relationships between system participants and to avoid the need for long training processes. The use of neural networks to control the above-mentioned systems was evaluated from the following parameters: the architectures, network training methods, efficiencies and accuracies of networks to perform the task of control. Several conclusions related to neural network implementations to manufacturing systems were produced: (1) the multi-layer architecture fits the complexity of manufacturing systems; (2) neural networks are efficient to control real-time operations of machines; (3) machines which were controlled by neural networks performed accurate results; and (4) the use of several hidden layers can replace the need for long training processes and saves on computation resources.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0967-0661(97)10058-2,Journal,Control Engineering Practice,scopus,1998-01-01,sciencedirect,Reinforcement learning and its application to force control of an industrial robot,https://api.elsevier.com/content/abstract/scopus_id/0031982354,"This paper presents a learning control design, together with an experimental study for implementing it on an industrial robot working in constrained environments. A new reinforcement learning scheme is proposed, to enable performance optimization in industrial robots. Using this scheme, the learning process is split into generalized and specialized learning phases, increasing the convergence speed and aiding practical implementation. Initial computer simulations were carried out for force tracking control of a two-link robot arm. The results confirmed that even without calculating the inverse kinematics or possessing the relevant environmental information, operating rules for simultaneously controlling the force and velocity of the robot arm can be achieved via repetitive exploration. Furthermore, practical experiments were carried out on an ABB IRB-2000 industrial robot to demonstrate the developed reinforcement-learning scheme for real-world applications. Experimental results verify that the proposed learning algorithm can cope with variations in the contact environment, and achieve performance improvements.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1006/ijhc.1997.0163,Journal,International Journal of Human Computer Studies,scopus,1998-01-01,sciencedirect,Adaptive agent tracking in real-world multiagent domains: A preliminary report,https://api.elsevier.com/content/abstract/scopus_id/0031701158,"Intelligent interaction in multi-agent domains frequently requires an agent to track other agents' mental states: their current goals, beliefs and intentions. Accuracy in thisagent-trackingtask is critically dependent on the accuracy of the tracker's (tracking agent's) model of the trackee (tracked agent). Unfortunately, in real-world situations, model imperfections arise due to the tracker's resource and information constraints, as well as due to trackees' dynamic behavior modification. While such model imperfections are unavoidable, a tracker must nonetheless attempt to be adaptive in its agent tracking. This article identifies key issues in adaptive agent tracking and presents an approach called DEFT. At its core, DEFT is based on discrimination-based learning. The main idea is to identify the deficiency of a model based on tracking failures, and revise the model by using features that are critical in discriminating successful and failed tracking episodes. Because in real-world situations the set of candidate discriminating features is very large, DEFT relies on knowledge-based focusing to limit the discrimination to those features that it determines were relevant in successful tracking episodes—with an autonomous explanation capability as a major source of this knowledge. This article reports on experiments with an implementation of key aspects of DEFT in a complex synthetic air-to-air combat domain.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/s0957-4174(98)00037-2,Journal,Expert Systems with Applications,scopus,1998-01-01,sciencedirect,The VirBot: A virtual reality robot driven with multimodal commands,https://api.elsevier.com/content/abstract/scopus_id/0008315285,"In this paper we show how symbolic Artificial Intelligence (AI) techniques can be used to develop intelligent Virtual Reality (VR) environments. We have developed an expert system architecture for building intelligent agents that respond to voice and gesture commands in virtual environments. To demonstrate the utility of this we present a simple application that allows a user to drive a virtual robot (the VirBot) around a virtual environment with multimodal commands. This software agent is able to accept spoken commands from the user, interpret them using natural language understanding and interact with and modify the virtual environment. Command recognition is further improved by the use of contextual information which reduces recognition error rates by 31%. Context is encoded using scripts, making it easy to compose inferences about events for which there is incomplete or fuzzy information.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(97)00034-1,Journal,Robotics and Autonomous Systems,scopus,1997-11-20,sciencedirect,Synthesis of indoor maps in presence of uncertainty,https://api.elsevier.com/content/abstract/scopus_id/0031272601,"A robotic system is presented, which is able to autonomously explore unengineered indoor environments, thereby synthesising maps suitable for planning and navigation purposes. Map recovery takes place through interaction between the robot and the world, in which either sensing and acting are affected by uncertainty. Kalman filtering is applied to maintain position best estimates, which are then fused with data coming from the observation of landmarks.
                  The proposed method has been implemented on a robot equipped with ultrasonic range finders, and tested in a fairly simple, real environment.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(96)00067-X,Journal,Robotics and Autonomous Systems,scopus,1997-01-01,sciencedirect,Evolutionary robotics: The Sussex approach,https://api.elsevier.com/content/abstract/scopus_id/0031153174,"We give an overview of evolutionary robotics research at Sussex over the last five years. We explain and justify our distinctive approaches to (artificial) evolution, and to the nature of robot control systems that are evolved. Results are presented from research with evolved controllers for autonomous mobile robots, simulated robots, co-evolved animats, real robots with software controllers, and a real robot with a controller directly evolved in hardware.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0951-5240(97)00004-9,Journal,Computer Integrated Manufacturing Systems,scopus,1997-01-01,sciencedirect,Task management in a multi-robot environment,https://api.elsevier.com/content/abstract/scopus_id/0031141084,"Contemporary computer technology allows robotic cells to communicate and cooperate. However, this expanded functionality requires more intelligence and better management of the cooperating robots.
                  This paper presents a software methodology to accommodate real time constraints imposed by cooperating robots, or any other task related constraint. This methodology is general and is capable of handling a large variety of exceptions such as task failures, sensor interruptions, and equipment failures. The methodology presented treats exceptions as tasks with special features; hence, the methodology expands into task management in a general robotic cell.
                  The methodology can accommodate failures independent of any hardware. In addition to the obvious functional benefits, this approach also allows easier development of robotic tasks, and improved portability of tasks among systems.
                  The methodology is demonstrated using an example with two cooperating robots.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/s0952-1976(96)00084-x,Journal,Engineering Applications of Artificial Intelligence,scopus,1997-01-01,sciencedirect,Collision-free motion planning for redundant robots using neural-network processing,https://api.elsevier.com/content/abstract/scopus_id/0031124335,"A computationally efficient obstacle-avoidance algorithm for redundant robots is presented in this paper. The algorithm incorporates Tank-Hopfield networks and the J function in the framework of resolved motion rate control, which is well suited for real-time implementation. Robot-arm kinematic control is carried out by the TH network. The connection weights of the network can be directly obtained from the known matrices at each sampling time, and joint velocity commands are generated from the outputs of the network. The obstacle-avoidance task can be achieved by formulating the performance criterion J > J
                     
                        min
                      (J
                     
                        min
                      represents the minimal distance between the redundant robot and obstacles), and by using a null space to ensure that this criterion is satisfied. Several simulation cases for a four-link planar manipulator are given, to demonstrate how the proposed collision free trajectory planning scheme works.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/s0004-3702(96)00037-9,Journal,Artificial Intelligence,scopus,1997-01-01,sciencedirect,Continuous case-based reasoning,https://api.elsevier.com/content/abstract/scopus_id/0031072835,"Case-based reasoning systems have traditionally been used to perform high-level reasoning in problem domains that can be adequately described using discrete, symbolic representations. However, many real-world problem domains, such as autonomous robotic navigation, are better characterized using continuous representations. Such problem domains also require continuous performance, such as on-line sensorimotor interaction with the environment, and continuous adaptation and learning during the performance task. This article introduces a new method for continuous case-based reasoning, and discusses its application to the dynamic selection, modification, and acquisition of robot behaviors in an autonomous navigation system, SINS (self-improving navigation system). The computer program and the underlying method are systematically evaluated through statistical analysis of results from several empirical studies. The article concludes with a general discussion of case-based reasoning issues addressed by this research.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/s0004-3702(96)00031-8,Journal,Artificial Intelligence,scopus,1997-01-01,sciencedirect,Permissive planning: Extending classical planning to uncertain task domains,https://api.elsevier.com/content/abstract/scopus_id/0030712509,"Uncertainty, inherent in most real-world domains, can cause failure of apparently sound classical plans. On the other hand, reasoning with representations that explicitly reflect uncertainty can engender significant, even prohibitive, additional computational costs. This paper contributes a novel approach to planning in uncertain domains. The approach is an extension of classical planning. Machine learning is employed to adjust planner bias in response to execution failures. Thus, the classical planner is conditioned towards producing plans that tend to work when executed in the world.
                  The planner's representations are simple and crisp; uncertainty is represented and reasoned about only during learning. The user-supplied domain theory is left intact. The operator definitions and the planner's projection ability remain as the domain expert intended them. Some structuring of the planner's bias space is required. But with suitable structuring the approach scales well. The learning converges using no more than a polynomial number of examples. The system then probabilistically guarantees that either the plans produced will achieve their goal when executed or that adequate planning is not possible with the domain theory provided. An implemented robotic system is described.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0967-0661(96)00184-0,Journal,Control Engineering Practice,scopus,1996-12-01,sciencedirect,"Mobile robot navigation in a partially structured static environment, using neural predictive control",https://api.elsevier.com/content/abstract/scopus_id/0030380849,"This paper presents a way of implementing a model-based predictive controller (MBPC) for mobile robot navigation when unexpected static obstacles are present in the robot environment. The method uses a nonlinear model of mobile robot dynamics, and thus allows an accurate prediction of the future trajectories. An ultrasonic ranging system has been used for obstacle detection. A multilayer perceptron is used to implement the MBPC, allowing real-time implementation and also eliminating the need for high-level data sensor processing. The perceptron has been trained in a supervised manner to reproduce the MBPC behaviour. Experimental results obtained when applying the neural-network controller to a TRC Labmate mobile robot are given in the paper.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0921-8890(96)00036-X,Journal,Robotics and Autonomous Systems,scopus,1996-11-01,sciencedirect,Application of evolved locomotion controllers to a hexapod robot,https://api.elsevier.com/content/abstract/scopus_id/0030283980,"In previous work, we demonstrated that genetic algorithms could be used to evolve dynamical neural networks for controlling the locomotion of a simulated hexapod agent. We also demonstrated that these evolved controllers were robust to loss of sensory feedback and other peripheral variations. In this paper, we show that these locomotion controllers, evolved in simulation, are capable of directing the walking of a real six-legged robot, and that many of the desirable properties observed in simulation carry over directly to the real world. In addition, we demonstrate that these controllers are amenable to hardware implementation and can thus be easily embodied within the robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0924-0136(96)02460-0,Journal,Journal of Materials Processing Technology,scopus,1996-08-01,sciencedirect,An intelligent software system for a robotics assembly cell,https://api.elsevier.com/content/abstract/scopus_id/0030215956,"The research discussed in this paper is directed towards the development of an intelligent software system using a knowledge base and artificial intelligence approach for a flexible robotics assembly cell, which can automatically generate and verify a robot-level program based on sensory data with a CAD-based user interface. The system can perform various assembly tasks for different products on a single station without the aid of jigs and fixtures to present the parts. The developed system consists of several modules and subsystems including; a CAD-based user interface, a sensory system, a knowledge based system, a task planner module, a motion control module, and cell device controllers.
                  The system has two modes, a learning mode and an execution mode. The learning mode provides the facility to introduce component objects of each product to the system, and to automatically create a knowledge base for all the objects, which is based on both the data received from sensors in the workplace and from the CAD database. In the execution mode, the system can recognize any assembly part coming into the robot workspace, where recognition is based on selected component features, and can calculate the object's real position and orientation. Then, the motion planner modifies the object's assembly program, based on real position and orientation data. Finally, the system downloads motion commands via a robot interface into the robot controller, to perform the appropriate assembly operation.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0045-7906(95)00038-0,Journal,Computers and Electrical Engineering,scopus,1996-05-01,sciencedirect,Fuzzy interval control of mobile robots,https://api.elsevier.com/content/abstract/scopus_id/0030149210,"A new fuzzy logic control (FLC) methodology called the fuzzy interval control (FIC) is discussed in this paper. The FIC implements an interval-valued FLC (or type 2 FLC) without the need to evaluate the interval-valued fuzzy sets. The structure of the FIC consists of a conventional FLC (or type 1 FLC) operating in the normalized universe of discourse; a set of parameters called the sensitivity indices which determine the intervals of the membership functions in the normalized universe; a set of input and output fuzzy gains which control the mapping of the normalized universe to the real axis; and a performance optimizer which dynamically adjusts the values of the sensitivity indices and input and output fuzzy gains in the run time. The invariant properties of the interval mapping preserve the stability of the underlying FLC in the FIC. The significance of FIC methodology is threefold. First, the FIC represents an adaptive FLC whose input-output relation is no longer deterministic. The adaptability of the controller allows the underlying FLC to be extremely simple and fast. This characteristic enables the FIC to be implemented on low-cost embedded microcontrollers for cost-sensitive industrial applications. Second, the FIC is designed for the applications in which limited or uncertain expert's experience is available. Finally, the FIC provides a practical implementation of a type 2 FLC to real applications. To validate the FIC methodology, an autonomous navigation system consisting of a fuzzy logic implemented navigator and an FIC autopilot are designed and implemented on Motorola 68HC11 8-bit microcontrollers. This system has successfully navigated a miniature robot in an unknown maze without touching the walls.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0921-8890(96)00006-1,Journal,Robotics and Autonomous Systems,scopus,1996-01-01,sciencedirect,Robot assistants: Applications and evolution,https://api.elsevier.com/content/abstract/scopus_id/0030191801,"Service robots are machines designed to work not onlyfor human beings (like the industrial robot) butalso with human beings. In addition to challenging technical problems, the application of service robots in real-life situations requires to address intriguing issues concerning their interactions with humans.
                  We are investigating both types of problems with reference to three different case studies and real research projects: a mobile robot system primarily aimed at the assistance of patients in hospitals and institutions (the “URMAD” project); a mobile robot system for the assistance to the disabled and the elderly at home (the “MOVAID” project); and a wheelchair incorporating a robot arm (the “IMMEDIATE” project). The paper discusses the design of the three robotic systems as well as their practical implementation and preliminary experimental results.
                  Finally, the paper addresses recent results which could lead to the implementation of cybernetic prostheses, that is devices which would ultimately allow to achieve real intimate physical symbiosis between human beings and artificial robotic devices.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0921-8890(96)81008-6,Journal,Robotics and Autonomous Systems,scopus,1995-01-01,sciencedirect,Evolution of neural control structures: some experiments on mobile robots,https://api.elsevier.com/content/abstract/scopus_id/0029520701,"From perception to action and from action to perception, all elements of an autonomous agent are interdependent and need to be strongly coherent. The final behavior of the agent is the result of the global activity of this loop and every weakness or incoherence of a single element has strong consequences on the performances of the agent. We think that, for the purpose of building autonomous robots, all these elements need to be developed together in continuous interaction with the environment. We describe the implementation of a possible solution (artificial neural networks and genetic algorithms) on a real mobile robot through a set of three different experiments. We focus our attention on three different aspects of the control structure: perception, internal representation and action. In all the experiments these aspects are not considered as single processing elements, but as part of an agent. For every experiment, the advantages and disadvantages of this approach are presented and discussed. The results show that the combination of genetic algorithms and neural networks is a very interesting technique for the development of control structures in autonomous agents. The time necessary for evolution, on the other hand, is a very important limitation of the evolutionary approach.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0921-8890(95)00051-8,Journal,Robotics and Autonomous Systems,scopus,1995-01-01,sciencedirect,A view-based neurocomputational system for relational map-making and navigation in visual environments,https://api.elsevier.com/content/abstract/scopus_id/0029511739,"Artificial navigation systems stand to benefit greatly from learning maps of visual environments, but traditional map-making techniques are inadequate in several respects. This paper describes an adaptive, view-based, relational map-making system for navigating within a 3D environment defined by a spatially distributed set of visual landmarks. Inspired by an analogy to learning aspect graphs of 3D objects, the system comprises two neurocomputational architectures that emulate cognitive mapping in the rat hippocampus. The first architecture performs unsupervised place learning by combining the “What” with the “Where”, namely through conjunctions of landmark identity, pose, and egocentric gaze direction within a local, restricted sensory view of the environment. The second associatively learns action consequences by incorporating the “When”, namely through conjunctions of learned places and coarsely coded robot motions. Together, these networks form a map reminiscent of a partially observable Markov decision process, and consequently provide an ideal neural substrate for prediction, environment recognition, route planning, and exploration. Preliminary results from real-time implementations on a mobile robot called MAVIN (the Mobile Adaptive VIsual Navigator) demonstrate the potential for these capabilities.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0360-8352(95)00061-5,Journal,Computers and Industrial Engineering,scopus,1995-01-01,sciencedirect,An intelligent knowledge-based system for robotic cell design,https://api.elsevier.com/content/abstract/scopus_id/0029370562,"As research fields in AI accelerate and a greater number of experts are demanded by industry, Expert y tem play an important role in meeting the technological sophistication required in today's competitive world. Industries are demanding the assistance of human experts for solving complicated problems. However, there is a shortage of experts due to this demand. Expert Systems are rapidly becoming one of the major approaches to solve engineering and manufacturing problems. They have been implemented for several practical applications in many decision making problems. Expert Systems are helping major companies to diagnose processes in real time, schedule operations, maintain machinery and to design service and production facilities.
                  Robots are an integral part of today's manufacturing environment. New tasks are being defined for robots in order to meet the challenges of Flexible Manufacturing Systems. Along with this growth there is an increasing variety of robots to choose from. One of the major problems facing the potential robot user will be his/her choice of an optimum robot for a particular task. Various parameters should be considered and the user should choose an industrial robot whose characteristics satisfy the requirements of the intended task. This paper will present a solution to the problem of selecting an optimum robot by building a Knowledge-Based Expert System. It uses the knowledge base and the rules to determine an optimum robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0952-1976(95)00021-R,Journal,Engineering Applications of Artificial Intelligence,scopus,1995-01-01,sciencedirect,Flexible planning by integrating multilevel reasoning,https://api.elsevier.com/content/abstract/scopus_id/0029352695,"The successful application of a general-purpose planning system in real-world complex application domains depends on the extent to which the activities of plan formation, plan execution, monitoring and failure handling can be flexibly interleaved. This paper presents a multilevel reasoning system (called MRG) where low-level functionalities (e.g. navigation, vision and speech understanding) are flexibly combined with higher-level reasoning capabilities through a set of specialized subreasoners. At the top of the architecture there is a high-level reasoning system, implemented using a programming language based on the notion of tactics. MRG is currently used as the core of an intelligent robot, able to navigate within an unpredictable environment and to exchange information with human users.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0921-8890(94)00032-W,Journal,Robotics and Autonomous Systems,scopus,1995-01-01,sciencedirect,Neural networks for the control of a six-legged walking machine,https://api.elsevier.com/content/abstract/scopus_id/0029307420,In this paper a hierarchical control architecture for a six-legged walking machine is presented. The basic components of this architecture are neural networks which are taught in using examples of the control process. It is shown how the basic components “leg control” and “leg coordination” have been implemented by recurrent and feedforward networks respectively. The teaching process and the tests of the walking behaviour have mainly been done in a simulation system. First tests of the leg control on our real walking machine LAURON are also described.,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0952-1976(94)00049-S,Journal,Engineering Applications of Artificial Intelligence,scopus,1995-01-01,sciencedirect,Real-time navigation and obstacle avoidance based on grids method for fast mobile robots,https://api.elsevier.com/content/abstract/scopus_id/0029255414,"This paper describes the development and implementation of a real-time navigation and obstacle avoidance method based on grids on the THMR-2 mobile root. This method permits the detection of unknown obstacles and the avoidance of collisions, based on information received from ultrasonic sensors, while autonomously steering the mobile root towards the given target by a smooth and continuous motion. Experimental results are given in some typical environments. The strength of the method has been demonstrated.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0004-3702(94)00058-9,Journal,Artificial Intelligence,scopus,1995-01-01,sciencedirect,Exploiting patterns of interaction to achieve reactive behavior,https://api.elsevier.com/content/abstract/scopus_id/0029246725,"This paper introduces an approach that allows an agent to exploit inherent patterns of interaction in its environment, so-called dynamics, to achieve its objectives. The approach extends the standard treatment of planning and (re) action in which part of the input to the plan generation algorithm is a set of basic actions and perhaps some domain axioms. Real world actions are typically difficult to categorize consistently and are highly context dependent. The approach presented here takes as input a procedural model of the agent's environment and produces as output a set of action descriptions that capture how the agent can exploit the dynamics in the environment. An agent constructed with this approach can utilize context sensitive actions, “servo” style actions, and other intuitively efficient ways to manipulate its environment.
                  A process-algebra based representation, 
                        RS
                     , is introduced to model the environment and the agent's reactions. The paper demonstrates how to analyze an 
                        RS
                      environment model so as to automatically generate a set of potentially useful dynamics and convert these to action descriptions. The output action descriptions are designed to be input to an Interval Temporal Logic based planner. A series of examples of reaction construction drawn from the kitting robot domain is worked through, and the prototype implementation of the approach described.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0009-9120(95)00002-Q,Journal,Clinical Biochemistry,scopus,1995-01-01,sciencedirect,Use of artificial intelligence in analytical systems for the clinical laboratory,https://api.elsevier.com/content/abstract/scopus_id/0029093694,"Objective: To consider the role of software in system operation, control and automation, and attempts to define intelligence. Methods and Results: Artificial intelligence (AI) is characterized by its ability to deal with incomplete and imprecise information and to accumulate knowledge. Expert systems, building on standard computing techniques, depend heavily on the domain experts and knowledge engineers that have programmed them to represent the real world. Neural networks are intended to emulate the pattern-recognition and parallel processing capabilities of the human brain and are taught rather than programmed. The future may lie in a combination of the recognition ability of the neural network and the rationalization capability of the expert system. In the second part of this paper, examples are given of applications of AI in stand-alone systems for knowledge engineering and medical diagnosis and in embedded systems for failure detection, image analysis, user interfacing, natural language processing, robotics and machine learning, as related to clinical laboratories. Conclusion: AI constitutes a collective form of intellectual property, and that there is a need for better documentation, evaluation and regulation of the systems already being used widely in clinical laboratories.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0009-8981(94)90206-2,Journal,Clinica Chimica Acta,scopus,1994-12-16,sciencedirect,Use of artificial intelligence in analytical systems for the clinical laboratory,https://api.elsevier.com/content/abstract/scopus_id/0002895587,"The incorporation of information-processing technology into analytical systems in the form of standard computing software has recently been advanced by the introduction of artificial intelligence (AI) both as expert systems and as neural networks. This paper considers the role of software in system operation, control and automation and attempts to define intelligence. AI is characterized by its ability to deal with incomplete and imprecise information and to accumulate knowledge. Expert systems, building on standard computing techniques, depend heavily on the domain experts and knowledge engineers that have programmed them to represent the real world. Neural networks are intended to emulate the pattern-recognition and parallel-processing capabilities of the human brain and are taught rather than programmed. The future may lie in a combination of the recognition ability of the neural network and the rationalization capability of the expert system. In the second part of this paper, examples are given of applications of AI in stand-alone systems for knowledge engineering and medical diagnosis and in embedded systems for failure detection, image analysis, user interfacing, natural language processing, robotics and machine learning, as related to clinical laboratories. It is concluded that AI constitutes a collective form of intellectual property and that there is a need for better documentation, evaluation and regulation of the systems already being used widely in clinical laboratories.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S0166-4115(08)61283-2,Book Series,Advances in Psychology,scopus,1994-01-01,sciencedirect,Reinforcement learning for robotic reaching and grasping,https://api.elsevier.com/content/abstract/scopus_id/77956789090,"A reinforcement learning approach is used to train a neural controller to perform a robotic reaching task. Unlike supervised learning techniques, where the teacher must provide the correct sequence of motor actions, only an evaluation of the robot's performance is provided. From this limited information, the robot must discover the appropriate motor programs that best satisfy the teacher's evaluation criterion. This type of learning approach is important because in a real-world environment, the teacher is generally not able to describe the motor program that performs the desired motor skill. This chapter utilizes the language of schema theory [1] as a mechanism for describing functional decompositions of motor programs. A connection is made from schema descriptions to a neural-level implementation of the schemas. It is at this low level of processing that we define a reinforcement learning algorithm that acquires motor programs that satisfy the reinforcement policy defined by the teacher.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0950-7051(94)90024-8,Journal,Knowledge-Based Systems,scopus,1994-01-01,sciencedirect,"Multi-paradigm software environment for the real-time processing of sound, music and multimedia",https://api.elsevier.com/content/abstract/scopus_id/38149147114,"The paper introduces a system and a software architecture for the representation and real-time processing of sound, music, and multimedia based on artificial intelligence techniques. This system, called WinProcne/HARP, is able to represent objects in a two-fold formalism—symbolic and analogical—at different levels of abstraction, and to carry out plans according to the user's goals. It also provides both formal and informal analysis capabilities for extracting information. In WinProcne/HARP the user can build, update, browse, and merge various knowledge bases of sound, music, and multimedia material, as well as enter queries, start and manage real time performance, using a high-level graphical user interface. The system is currently used by researchers and composers in various experiments, including (a) advanced robotics projects, in which the system is used as a tool for interacting, cotrolling and simulating robot movements, and (b) theatrical automation, where the system is delegated to manage and integrate sound, music, and three-dimensional computer animations of humanoid figures. The paper explicitly refers to some applications in the music field.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0004-3702(94)90047-7,Journal,Artificial Intelligence,scopus,1994-01-01,sciencedirect,Robot shaping: developing autonomous agents through learning,https://api.elsevier.com/content/abstract/scopus_id/0028739953,"Learning plays a vital role in the development of autonomous agents. In this paper, we explore the use of reinforcement learning to “shape” a robot to perform a predefined target behavior. We connect both simulated and real robots to Alecsys, a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behaviors, we explore the effects on learning of different types of agent's architecture and training strategies. We show that the best results are achieved when both the agent's architecture and the training strategy match the structure of the behavior pattern to be learned. We report the results of a number of experiments carried out both in simulated and in real environments, and show that the results of simulations carry smoothly to physical robots. While most of our experiments deal with simple reactive behavior, in one of them we demonstrate the use of a simple and general memory mechanism. As a whole, our experimental activity demonstrates that classifier systems with genetic algorithms can be practically employed to develop autonomous agents.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0736-5845(95)00008-9,Journal,Robotics and Computer Integrated Manufacturing,scopus,1994-01-01,sciencedirect,Cooperative multi-agent system for an assembly robotics cell,https://api.elsevier.com/content/abstract/scopus_id/0028719992,"A multi-agent system architecture is described and justified for the sake of its application to an assembly robotics testbed. A blackboard-based agent using a GoalBlackboard/DataBlackboard facility for intra (not inter) agent communication and including knowledge about all the agent's community, is presented as well as its main functionality. Coordination of different agents dynamically playing the roles either of organizers or respondents may lead to the use of either negotiation or client/server protocols for cooperation. Also come cooperative strategies and involved knowledge have been studied, classified and implemented in the robotics testbed enabling a sophisticated agent behavior both in terms of cooperation and local control. A real testbed, whose agents are briefly presented here, working with real-time constraints, has already been implemented and tested in our laboratory.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0926-5805(94)90033-7,Journal,Automation in Construction,scopus,1994-01-01,sciencedirect,Path planning and sensing for an experimental masonry building robot,https://api.elsevier.com/content/abstract/scopus_id/0028425345,"An experimental robot cell is being used to investigate the enabling technology for a masonry tasking robot. A CAD/CAM facility has been devised by which wall designs are translated into the robot's “theoretical task”. However, this cannot be directly implemented without real-time adjustments derived from sensors. A further complication is that the form of a move influences the dynamic response of the robot structure. Rule-based intelligence has been applied to the solution of both these problems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0967-0661(93)91395-D,Journal,Control Engineering Practice,scopus,1993-01-01,sciencedirect,An experimental study of robotic modeling and control using a fuzzy neural network,https://api.elsevier.com/content/abstract/scopus_id/0027645075,"In this paper, a fuzzy neural network (FNN) is applied to modeling and control of a robot. Comparisons are made between the FNN and standard back propagation neural networks as well as a commercially available neural network software package for modeling the robot, and observations on the robustness of these networks are made. A number of experiments demonstrate that the FNN can learn faster and more accurately than the standard backpropagation and certain commercial neural networks for: 1) modeling and control of a real robot, 2) solving a benchmark encoder problem. The FNN will be used as a prototype dynamic model and a control component in the control system of a 7 degree of freedom robot.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0893-6080(93)90015-O,Journal,Neural Networks,scopus,1993-01-01,sciencedirect,The error-bounded descriptional complexity of approximation networks,https://api.elsevier.com/content/abstract/scopus_id/0027266365,"It is well known that artificial neural nets can be used as approximators of any continuous functions to any desired degree and therefore be used, e.g., in high-speed, real-time process control. Nevertheless, for a given application and a given network architecture, the nontrivial task remains to determine the necessary number of neurons and the necessary accuracy (number of bits) per weight for a satisfactory operation which are critical issues in VLSI and computer implementations of nontrivial tasks. In this paper the accuracy of the weights and the number of neurons are seen as general system parameters which determine the maximal approximation error by the absolute amount and the relative distribution of information contained in the network. We define as the “error-bounded network descriptional complexity” the minimal number of bits for a class of approximation networks which show a certain approximation error and achieve the conditions for this goal by the new principle of “optimal information distribution.” For two examples, a simple linear approximation of a nonlinear, quadratic function and a nonlinear approximation of the inverse kinematic transformation used in robot manipulator control, the principle of optimal information distribution gives the optimal number of neurons and the resolutions of the variables, i.e., the minimal amount of storage for the neural net.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0926-5805(92)90037-K,Journal,Automation in Construction,scopus,1992-01-01,sciencedirect,Expert robots for process environments,https://api.elsevier.com/content/abstract/scopus_id/44049119146,"The Robotics Technology Group at the Savannah River Laboratory has developed expert mobile robots and control strategies for process applications. An expert robot is an intelligent machine that senses its environment, responds to its environment, and can perform independent tasks as outlined by a knowledge-based control system that incorporates artificial intelligence techniques. A real-time expert system is employed, whereby robots are treated as dynamic process elements in the overall process environment. The system has been implemented using a functional, layered control architecture. Decision, analysis, and control tasks are shared between the mobile robot actually performing the task and supervisory computers that interact with process data. Investigated are the control architecture and the performance of the laboratory development system.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0066-4138(91)90025-7,Journal,Annual Review in Automatic Programming,scopus,1991-01-01,sciencedirect,Applications of intelligent telerobotic control,https://api.elsevier.com/content/abstract/scopus_id/44949283750,"The telerobotics laboratory at Lawrence Livermore National Laboratory is a facility for developing and testing new concepts in robotics controls. Research and development is being conducted in computer vision; adaptive control; software architectures for real-time, intelligent control; artificial neural networks; fuzzy logic controllers; telepresence; and path planning and collision avoidance.
                  The equipment in the telerobotics laboratory includes a six degree of freedom articulating robot arm with controller, gripper and force and torque sensor, a 3D CAD workstation with software to model the work cell environment and simulate the robot dynamics; a six degree of freedom forceball for operator input to the telerobotics controller and the robot simulation; and a computer with a real-time operating system. Soon to be added are a 3D viewing system and a force reflecting hand controller.
                  This paper describes one of the research and development efforts currently in progress on this program.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0921-8890(91)90013-B,Journal,Robotics and Autonomous Systems,scopus,1991-01-01,sciencedirect,A cost-sensitive machine learning method for the approach and recognize task,https://api.elsevier.com/content/abstract/scopus_id/0026258630,"Tan M. and Schlimer, J.C., A cost-sensitive machine learning method for the approach and recognize task, Robotics and Autonomous Systems, 8 (1991) 31–45.
                  The long-term goal of this reasearch is to build a robot which can survive in an unanticipated environment for a long time. Such a robot must learn which sensors to use, where to use them, and how to generate inexpensive and reliable effector procedures to accomplish its tasks. Current machine learning methods are inadequate because they ignore execution costs and are ill-prepared to handle prediction failures. This paper described the CSI, learning and control system that attempts to address this goal, CSL has been implemented in a real-world robot for the approach and recognize taks.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0736-5845(89)90116-6,Journal,Robotics and Computer Integrated Manufacturing,scopus,1989-01-01,sciencedirect,Programming and control of a two-hand assembly system,https://api.elsevier.com/content/abstract/scopus_id/0024906322,"This paper presents the implementation of an original cooperating system for precise assembly operations. The whole mechanical architecture consists of a conventional manipulator robot and a micro-manipulator setting in parallel. The micro-manipulator used is a manipulator-gripper in a left hand configuration. The mechanism of the manipulator-gripper was designed to achieve active or passive fine compliant motions. Some details of its technology are given. A real-time distributed computer system has been developed for coordinated-motion control. Programming assignments are explained. For complex assembly tasks, automatic fine motion strategies are obtained by a rule-based expert system.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0094-5765(89)90052-0,Journal,Acta Astronautica,scopus,1989-01-01,sciencedirect,"Telescience and microgravity. Impact on future facilities, ground segments and operations",https://api.elsevier.com/content/abstract/scopus_id/0024856605,"Scientific activities related to experimentation in long duration microgravity missions can only be accomplished by the implementation of the Telescience Concept.
                  Telescience is in fact the logical answer to the need of an intelligent interactive conduct of experiments, to the lack (or very little availability) of crew time on board of the Segments of the Columbus project and to the PIs demand for decentralized operations. Telescience could also be seen as the preparative phase for the ultimate, future exploitation of Microgravity by means of Expert Systems that will utilize AI and Robotics for routine operations (Data Factories, Space Productions and Commercial Enterprises).
                  The implications of Telescience on future Space Activities is reviewed with reference to the Principal Investigator Activities, Crew Members Roles and Facilities. The possibilities offered by newly designed Facilities to be operated in Telescience are pointed out with reference to the scientific objectives that would not be achieved otherwise.
                  Diagnostic facilities (mainly non invasive) that provide digital measurements to be inputted (in real time) into numerical codes for computation of field parameters are being considered. Ground Segment Structure, User Support Centers Organization and Test Bedding activities will be discussed as essential factors of the Telescience Scenario of the Multiuser, permanent platform Facilities for the Microgravity disciplines (Material, Fluid, Life and Engineering Science).",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0954-1810(88)90026-X,Journal,Artificial Intelligence in Engineering,scopus,1988-01-01,sciencedirect,Integrated planning and execution control for an autonomous mobile robot,https://api.elsevier.com/content/abstract/scopus_id/0023995447,"We present a distributed hierarchical planning and execution monitoring system and its implementation on an actual mobile robot. The planning system is a distributed hierarchical domain independent system called FPS for Flexible Planning System. It is a rule based plan generation system with planning specific and domain specific rules. A planning solution to the ‘Boxes and Wedge’ Problem is presented.
                  The Robot Control System (RCS) operates and monitors the robot in the real world. In order to allow real-time responses to asynchronous events (both internal and external), RCS consists of a rule-based decision kernel and a distributed set of sensor/effector monitors. RCS contains an execution model and may authorize local corrective actions, e.g., unexpected obstacle avoidance during execution of a trajectory. RCS also generates status and failure reports through which the PMs inform the different decision subsystems as to the robot's state and current capacities. The failure reports help the RCS and planners in correcting/replanning a plan that has aborted. An illustrative example of system behaviour is to be presented.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0031-3203(87)90023-9,Journal,Pattern Recognition,scopus,1987-01-01,sciencedirect,VLSI architectures for string matching and pattern matching,https://api.elsevier.com/content/abstract/scopus_id/0023207478,"In this paper, we discuss string-matching and dynamic time-warp pattern-matching. The string-matching problem arises in a number of applications such as in artificial intelligence, pattern recognition and information retrieval. The method of dynamic time-warping is a well-established technique for time alignment and comparison of speech and image patterns. It has found extensive application in speech recognition and related areas of pattern-matching.
                  We propose a VLSI architecture based on the space-time domain expansion approach which can compute the string distance and also give the matching index-pairs which correspond to the edit sequence. The time complexity is O(max(m, n)) by using m× n processing elements array, where m is the length of the input string and n is the length of the reference string. With a uniprocessor the matching process will have the time complexity O(m × n). If there are p reference strings, using the proposed architecture the string-matching problem can be solved in time O(max(m, n, p)). With a uniprocessor the time complexity will be O(m × n × p). We also propose a VLSI architecture for dynamic time-warping based on the space-time expansion method which can obtain high throughput by using extensive pipelining and parallelism. It can measure the dissimilarity between two patterns in time O(max(m, n, N)). If using a uniprocessor the time complexity will be O(m × n × N), where m and n are the numbers of feature vectors of the unknown input pattern and the reference template respectively, and N is the number of elements of the feature vector. If there are p reference templates, the time complexity will be O(max(m, n, N × p)), and if using a uniprocessor the time complexity will be O(m × n × p × N). The algorithm partition problems are discussed. Verifications of the proposed VLSI architectures are also given. The backtracking procedures are discussed in much detail and their hardware implementations are also given. The proposed architectures can be applied to many areas such as pattern recognition, information retrieval, image processing, speech processing, remote sensing, robotics, computer vision, artificial intelligence and office automata. They are useful to real-time information processing.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0020-0255(86)90017-4,Journal,Information Sciences,scopus,1986-01-01,sciencedirect,A VLSI implementation of a fuzzy-inference engine: Toward an expert system on a chip,https://api.elsevier.com/content/abstract/scopus_id/0022698054,"We present a VLSI implementation of an inference mechanism to cope with uncertainty and to perform approximate reasoning. The design is based on the “max-min operation” of fuzzy set theory for effective and real-time use. This inference mechanism can handle imprecise and uncertain knowledge; therefore, it can obtain human expert knowledge and simulate reasoning processes. An inference mechanism has been realized by using custom CMOS technology which emphasizes simplicity, extensibility, and efficiency. Timing simulation suggests that the inference engine can perform approximately 80,000 fuzzy logical inferences per second. A potential application of such inference engines is real-time decision making in the area of command and control and adaptive command generation of robotic systems.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/0165-9936(85)85023-8,Journal,Trends in Analytical Chemistry,scopus,1985-01-01,sciencedirect,Robots in flexible analysis systems,https://api.elsevier.com/content/abstract/scopus_id/0022012173,"In this article an attempt is made to place robots in the general context of automation. The changes that will have to take place to avoid the robot becoming a dedicated instrument are discussed. To obtain real flexible analysis systems both hardware and software will have to change. The robot periphery and the controllers will have to be standardised, and to become more user-friendly the software developments based on the techniques of artificial intelligence (AI) will have to be supported by appropriate tactile and visual sensors. Experience based on the automation of sample preparation in biomedical and pharmaceutical analysis with existing laboratory equipment is discussed in this perspective.",robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
