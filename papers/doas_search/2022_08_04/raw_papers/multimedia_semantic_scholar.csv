paperId,url,title,abstract,venue,year,externalIds.DOI,database,query_name,query_value
0bca80c452d4f2900a17acaa476c36e92df9a3af,https://www.semanticscholar.org/paper/0bca80c452d4f2900a17acaa476c36e92df9a3af,"DISSIMILAR: Towards fake news detection using information hiding, signal processing and machine learning","Digital media have changed the classical model of mass media that considers the transmitter of a message and a passive receiver, to a model where users of the digital media can appropriate the contents, recreate, and circulate them. In this context, online social media are a suitable circuit for the distribution of fake news and the spread of disinformation. Particularly, photo and video editing tools and recent advances in artificial intelligence allow non-professionals to easily counterfeit multimedia documents and create deep fakes. To avoid the spread of disinformation, some online social media deploy methods to filter fake content. Although this can be an effective method, its centralized approach gives an enormous power to the manager of these services. Considering the above, this paper outlines the main principles and research approach of the ongoing DISSIMILAR project, which is focused on the detection of fake news on social media platforms using information hiding techniques, in particular, digital watermarking, combined with machine learning approaches.",ARES,2021.0,10.1145/3465481.3470088,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
1d3539a8d94bd3ab78993d7cc584efc06ed0e460,https://www.semanticscholar.org/paper/1d3539a8d94bd3ab78993d7cc584efc06ed0e460,Synthetic Benchmarks for Scientific Research in Explainable Machine Learning,"As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",NeurIPS Datasets and Benchmarks,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
5d730d20cb53ecda86ced0a053b95dc07f9eb72e,https://www.semanticscholar.org/paper/5d730d20cb53ecda86ced0a053b95dc07f9eb72e,Veracity Assessment of Multimedia Facebook Posts for Infodemic Symptom Detection using Bi-modal Unsupervised Machine Learning Approach,"Abstract: Ascertaining the truthfulness and trustworthiness of information posted on social media has been challenging with the proliferation of unsubstantiated, misleading, and inciting news, with different intents by purveyors. Unlike the traditional media with some level of regulations, user-generated posts on social networks does not pass through censorships in order to establish the truism of news items hence the need to be cautious of posted information on the networks. The lingering issue of recent suspension of Twitter microblogging site by the Nigerian government and the consequent decision to regulate social network operations in the country similarly centers on the subject of social media dependability for legitimate social engagements by millions of savvy Nigerian users. Whereas existing models in literature have proposed state-of-the-arts, this study seeks to improve on obtainable studies with a bi-modal machine learning methodology that indicate symptoms of infodemic social media posts. Using a multimedia facebook corpus, an unsupervised natural language processor, Inception v3 model, coupled with a hierarchical clustering network, is deployed for the duo of image and text sentiment analytics. Experimental result uniquely identified infodemic tendencies in facebook text-corpus and efficiently differentiates image-corpus into respective clusters through the Euclidian distance metrics. The most infodemic post returned a -0.9719 compound score while the most positive post returns 0.9488. Veracity assessment of polarized opinions expressed in negative clusters reveals that provocative, derogatory, obnoxious, etc. indicate propensity for infodemic tendencies. Keywords: Fake news. Facebook. Social media. Sentiment Analysis. Infodemic",International Journal for Research in Applied Science and Engineering Technology,2021.0,10.22214/ijraset.2021.39406,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a0051e9e2e42f26077b35801c0f504a0eeb328dc,https://www.semanticscholar.org/paper/a0051e9e2e42f26077b35801c0f504a0eeb328dc,MADP-IIME: malware attack detection protocol in IoT-enabled industrial multimedia environment using machine learning approach,,,2021.0,10.1007/S00530-020-00743-9,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ed9b2c4d4ea93d86a6e1167c9e92cfa0a243c4bc,https://www.semanticscholar.org/paper/ed9b2c4d4ea93d86a6e1167c9e92cfa0a243c4bc,Challenges and Opportunities for Unikernels in Machine Learning Inference,"Machine Learning has become a value creator for many new and old businesses. However, efficient realworld machine learning deployments are still a challenge. Traditional Machine Learning deployments suffer from efficient resource utilization and achieving predictable latency. They cannot be treated in the same manner as other application server deployments. Unikernels are a method to specialize application deployment and performance to suit the needs of the application. Traditionally, building or porting applications to unikernels have been challenging. However, recent work has been into simplifying the development of unikernels. Real-world Unikernels as of now are only for specializing applications that run on the CPU. We survey machine learning practitioners and find out that the majority of machine learning practitioners are using the CPU for machine learning deployments, thus, creating an opportunity for unikernels to optimize the performance of these applications. We compare the architecture of two unikernels: nanos and Unikraft. We benchmarked scikit-learn, a popular machine library, inside a unikernel and found that it only offered a 1% advantage over a traditional deployment. However, our testing could not include more innovative systems like Unikraft due to their immaturity and inability to run machine learning libraries. We include a dependency analysis of three popular machine learning libraries Tensorflow Lite, PyTorch and ONNX, to help pave the way for building machine learning applications as Unikraft unikernels.","2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",2021.0,10.1109/icrito51393.2021.9596080,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
b14558c0b727af0ac9086f463b6030b9072dbe16,https://www.semanticscholar.org/paper/b14558c0b727af0ac9086f463b6030b9072dbe16,Methods for Automatic Machine-Learning Workflow Analysis,,ECML/PKDD,2021.0,10.1007/978-3-030-86517-7_4,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
56e63ffea11c875f7eee257798e18cd04e453b6c,https://www.semanticscholar.org/paper/56e63ffea11c875f7eee257798e18cd04e453b6c,Synthetic Benchmarks for Scientific Research in Explainable Machine Learning,"As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d87648a18c4b7f095baef04ca817cf0fa568e643,https://www.semanticscholar.org/paper/d87648a18c4b7f095baef04ca817cf0fa568e643,Assessment of Machine Learning-Based Audiovisual Quality Predictors,"Quality assessment of audiovisual (AV) signals is important from the perspective of system design, optimization, and management of a modern multimedia communication system. However, automatic prediction of AV quality via the use of computational models remains challenging. In this context, machine learning (ML) appears to be an attractive alternative to the traditional approaches. This is especially when such assessment needs to be made in no-reference (i.e., the original signal is unavailable) fashion. While development of ML-based quality predictors is desirable, we argue that proper assessment and validation of such predictors is also crucial before they can be deployed in practice. To this end, we raise some fundamental questions about the current approach of ML-based model development for AV quality assessment and signal processing for multimedia communication in general. We also identify specific limitations associated with the current validation strategy which have implications on analysis and comparison of ML-based quality predictors. These include a lack of consideration of: (a) data uncertainty, (b) domain knowledge, (c) explicit learning ability of the trained model, and (d) interpretability of the resultant model. Therefore, the primary goal of this article is to shed some light into mentioned factors. Our analysis and proposed recommendations are of particular importance in the light of significant interests in ML methods for multimedia signal processing (specifically in cases where human-labeled data is used), and a lack of discussion of mentioned issues in existing literature.",ACM Trans. Multim. Comput. Commun. Appl.,2021.0,10.1145/3430376,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
19552c33b6144ba9cf02b52310cfdccdc66b14f2,https://www.semanticscholar.org/paper/19552c33b6144ba9cf02b52310cfdccdc66b14f2,Empirical observation of negligible fairness-accuracy trade-offs in machine learning for public policy,,Nat. Mach. Intell.,2020.0,10.1038/s42256-021-00396-x,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
b14692c1e0658dd1d814c737171ce714b1588360,https://www.semanticscholar.org/paper/b14692c1e0658dd1d814c737171ce714b1588360,An Intelligent UAV Deployment Scheme for Load Balance in Small Cell Networks Using Machine Learning,"In wireless networks, network load can be highly unbalanced due to the mobility of user equipments (UEs). Unmanned Aerial Vehicles (UAVs) supported base station with the advantage of flexible deployment, ubiquitous wireless coverage and high speed data rate, is a promising approach to handle with the foregoing problem. However, how to achieve cost-effective UAV deployment in an autonomous and dynamic manner is a significant challenge. Facing this problem, we propose a novel UAV base station intelligent deployment scheme based on machine learning and evaluate its performance on a realworld dataset. First, we conduct data preprocessing to process, clean, and transform raw data into formatted data. Missing values are filled by Conditional Mean Imputation (CMI) method and outliers are corrected by pauta criterion. Then, we use hybrid approach which contains ARIMA model and XGBoost model. Linear predictions are carried out by ARIMA model and later nonlinear model XGBoost are applied on residue of ARIMA. Resultant prediction is obtained by adding linear and nonlinear prediction, hybrid model is estimated by Root Mean Square Error (RMSE) and R2 score. Finally, according to predicted results, UAV base stations can be deployed to cater for dynamically changing demands in the hotspot areas and achieve cost-effective deployment. Simulation results show that the propose scheme is superior to other benchmark schemes in load balancing.",2019 IEEE Wireless Communications and Networking Conference (WCNC),2019.0,10.1109/WCNC.2019.8885648,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d94808b3136a60218132744df149e414bdccfacf,https://www.semanticscholar.org/paper/d94808b3136a60218132744df149e414bdccfacf,Machine-Assisted Learning in Highly-Interdisciplinary Media Fields: A Multimedia Guide on Modern Art,"Art and technology have always been very tightly intertwined, presenting strong influences on each other. On the other hand, technological evolution led to today’s digital media landscape, elaborating mediated communication tools, thus providing new creative means of expression (i.e., new-media art). Rich-media interaction can expedite the whole process into an augmented schooling experience though art cannot be easily enclosed in classical teaching procedures. The current work focuses on the deployment of a modern-art web-guide, aiming at enhancing traditional approaches with machine-assisted blended-learning. In this perspective, “machine” has a two-folded goal: to offer highly-interdisciplinary multimedia services for both in-class demonstration and self-training support, and to crowdsource users’ feedback, as to train artificial intelligence systems on painting movements semantics. The paper presents the implementation of the “Istoriart” website through the main phases of Analysis, Design, Development, and Evaluation, while also answering typical questions regarding its impact on the targeted audience. Hence, elaborating on this constructive case study, initial hypotheses on the multidisciplinary usefulness, and contribution of the new digital services are put into test and verified.",Education Sciences,2019.0,10.3390/EDUCSCI9030198,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
2303bdc62a575f3825e691e7cb4d5c48f0baf2d6,https://www.semanticscholar.org/paper/2303bdc62a575f3825e691e7cb4d5c48f0baf2d6,Detección de anomalías de red mediante técnicas de machine learning,"In the current scenario [1] with an increase of traffic (due to the proliferation of the internet of things, the rise of the philosophy of always connected and the increase in multimedia services, cloud, videoconferencing and its associated traffic) along with the proliferation of attacks and new threats, there is a need for fast and adaptable defense models. There are different approaches when dealing with the study of network traffic, but the use of the aggregation approach, both in the capture as in the analysis, comes to partially solve the problems of the huge amounts of traffic that support day-to-day traffic of the organizations. The aggregation allows grouping the traffic, at any given time, in a sequence of packets that share certain values, getting this way reduce the volume of data to be processedwithout losing the relevant information. Despite the reduction in the volume of information, achieved through the use of flows, the use of Big Data techniques to analyze it is still necessary. The current boom in machine learning techniques, hereinafter ML, together with the growth, availability and simplicity of use of distributed computing, provide us with the necessary tools to undertake the tasks focused on the analysis of aggregate traffic. The main objective of this project is to compare and understand different ML techniques applied to the real-time detection of anomalous behaviors in a network’s traffic. In a transversal way we will focus on aspects such as the capture of flows or the implementation and deployment of a distributed solution as tools to provide our model with the expected characteristics of performance and scalability..",,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
26937db6917952a9c13bfe152eddd7defc08e695,https://www.semanticscholar.org/paper/26937db6917952a9c13bfe152eddd7defc08e695,Guest Editorial: Special Issue on Machine Learning Implementations,,J. Signal Process. Syst.,2019.0,10.1007/s11265-018-1432-1,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
216f468fbbf5a409c363626e697cab836fcd32a3,https://www.semanticscholar.org/paper/216f468fbbf5a409c363626e697cab836fcd32a3,Securing IP-Multimedia Subsystem (IMS) against Anomalous Message Exploits by Using Machine Learning Algorithms,"Modern communication infrastructure (IP Multimedia Subsystem (IMS) and Voice over IP (VoIP)) are vulnerable to zero day attacks and unknown threats. Anomalous SIP requests can be used to remotely launch malicious activity. Furthermore, anomalous messages are capable of crashing - sometimes with one message only - servers and end points. Recently, it is shown that a malicious SIP message ""INVITE of Death"" crash a server or gain unfettered access to it. In contrast, little research is done to protect IMS against such anomalous messages. In this paper, we propose an anomalous message detection framework that extracts novel syntactical features from SIP messages at the P-CSCF of an IMS. Our framework operates in four steps: (1) analyzes the byte-level distribution of SIP message, (2) extracts spatial features from IMS messages in form of byte transition probabilities, (3) uses well-known feature selection scheme to remove redundancy in the features set, and (4) uses standard machine learning algorithms to raise the final alarm. The benefit of our framework is that it is lightweight requiring less processing and memory resources and provides high detection accuracy. We have evaluated our system on a real-world IMS dataset consisting of more than 10, 000 benign and malicious SIP messages. The results of our experiments demonstrate that using machine learning algorithms, our framework achieves detection accuracy of more than 99%. Last but not least, its testing time is 152μ seconds per packet, as a result, it can be easily deployed on IMS core.",2011 Eighth International Conference on Information Technology: New Generations,2011.0,10.1109/ITNG.2011.102,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
5994ea254d8e60e9b240cf0c3824b3e5f40df85a,https://www.semanticscholar.org/paper/5994ea254d8e60e9b240cf0c3824b3e5f40df85a,Machine Learning for Indoor Localization Using Mobile Phone-Based Sensors,"In this paper we investigate the problem of localizing a mobile device based on readings from its embedded sensors utilizing machine learning methodologies. We consider a realworld environment, collect a large dataset of 3110 datapoints, and examine the performance of a substantial number of machine learning algorithms in localizing a mobile device. We have found algorithms that give a mean error as accurate as 0.76 meters, outperforming other indoor localization systems reported in the literature. We also propose a hybrid instance-based approach that results in a speed increase by a factor of ten with no loss of accuracy in a live deployment over standard instance-based methods, allowing for fast and accurate localization. Further, we determine how smaller datasets collected with less density affect accuracy of localization, important for use in real-world environments. Finally, we demonstrate that these approaches are appropriate for real-world deployment by evaluating their performance in an online, in-motion experiment.",ArXiv,2015.0,10.1109/CCNC.2016.7444919,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
fbbee5da12c0e0f15813254b9ffca18e339d3546,https://www.semanticscholar.org/paper/fbbee5da12c0e0f15813254b9ffca18e339d3546,10 - Machine learning for future intelligent air quality networks,"During the last few years, machine learning emerged as a very effective tool for data analysis and sematic value extraction from the large amount of data generated from deployed chemical multisensors devices. Many works have now highlighted the potential impact on multisensor device calibration, drift counteraction, data assimilation, optimal deployment of these classes of algorithms. Unlike 5 years ago, the huge amount of available data make possible to confirm this potential on realworld long-term deployments. This work analyze the literature produced by EuNetAir partners extracting the lessons cooperatively learnt about their impact and propose a novel architecture for future intelligent air quality networks based on the machine learning emerging paradigm.",,2016.0,10.5162/6EuNetAir2016/10,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
82bbb8932b2850074b2b658eaf46953e9735ba05,https://www.semanticscholar.org/paper/82bbb8932b2850074b2b658eaf46953e9735ba05,Modèles d’apprentissage automatique d’estimation dequalité perçue dans les communications en temps réel / Machine learning based perceived quality estimationmodels in realtime communications.,"L’objectif de notre travail est de developper des modeles d’apprentissage automatique qui predisent 
la qualite audiovisuelle percue. La prediction se fait a partir d’un ensemble de parametres 
correles derives d’un ensemble de donnees extraits de la cible. Afin d’atteindre cet objectif, nous 
avons tout d’abord developpe, avec VLC, un banc d’essai de la VsD (Video sur Demande) et avons 
genere un ensemble de donnees preliminaires de la qualite audiovisuelle. Le but etait d’etudier divers 
algorithmes d’apprentissage automatique. Ces premieres experimentations nous ont encourage a developper 
un banc d’essai plus robuste, base sur le framework multimedia GStreamer. Nous avons 
genere, avec ce nouveau banc d’essai, un ensemble de donnees de qualite audiovisuelle, propre a 
notre contexte. Ces donnees refletent les configurations contemporaines des communications interactives 
pour le taux d’image par seconde, la quantification video, les parametres de reduction du 
bruit et le taux de perte des paquets du reseau. Nous avons ensuite utilise cet ensemble de donnees 
afin de developper divers modeles, reposant soit sur l’information media (« parametriques »), soit 
sur les donnees reseau (« bitstream »), d’estimation de la qualite percue. Ces modeles sont bases 
sur les methodes des forets d’arbres decisionnels, des techniques dites de demarrage (« bootstrap 
»), de l’apprentissage profond et de la programmation genetique. 
Pour les modeles parametriques, les quatre methodes ont atteint une precision elevee en terme 
de correlation RMSE et de Pearson. Les modeles bases sur les forets d’arbres decisionnels et les 
techniques de bootstrap montrent un petit avantage par rapport a l’apprentissage profond quant 
a la precision qu’ils ont atteint. Les modeles bases sur la programmation genetique sont moins 
performants meme si leur precision est impressionnante. Nous avons egalement obtenu une precision 
elevee en utilisant les autres ensembles de donnees sur la qualite visuelle, accessibles au public. Les 
metriques de performance que nous avons calculees sont comparables aux modeles existants formes 
et testes sur ces ensembles de donnees. 
Pour les modeles bitstream, les methodes de forets d’arbres decisionnels ainsi que les techniques 
de bootstrap ont surpasse les modeles bases sur l’apprentissage profond et la programmation genetique 
ainsi que tous les modeles parametriques. Cependant, les modeles bitstream realises en 
programmation genetique et en apprentissage profond ont moins bien performe que les modeles parametriques 
a cause d’une augmentation significative du nombre de caracteristiques dans l’ensemble 
de donnees bitstream. Dans l’ensemble, nous concluons que le calcul de l’information bitstream merite 
l’effort fourni pour la generer. Ce calcul aide a construire des modeles plus precis mais demeure 
utile uniquement pour le deploiement de bons algorithmes. 
Sur la base de nos resultats, nous concluons que les algorithmes bases sur l’arbre de decision 
conviennent aux modeles parametriques ainsi qu’aux modeles bitstream. De plus, nous savons que 
l’extraction de donnees correlees supplementaires de l’ensemble de donnees nous aide a generer des 
modeles plus precis lorsque des algorithmes d’apprentissage automatique appropries sont deployes. L’ensemble des donnees, les outils et les codes d’apprentissage automatique qui ont ete developpes 
au cours de cette recherche sont gracieusement offerts a la communaute pour des fins de 
recherche et de developpement. Abstract This research has started with the initial objective to build machine learning based models 
that predict the perceived audiovisual quality directly from a set of correlated parameters that 
are extracted from a target quality dataset. To reach that goal, we have first created a VideoLAN 
Video-on-Demand based testbed and generated a preliminary audiovisual quality dataset that let 
us experiment with various machine learning algorithms. These early experiments encouraged us 
to create a more robust testbed based on the GStreamer multimedia framework. With this new 
testbed, we have generated the INRS audiovisual quality dataset that reflects contemporary realtime 
configurations for video frame rate, video quantization, noise reduction parameters and network 
packet loss rate. Then we have utilized this INRS dataset to build several machine learning based 
parametric and bitstream perceived quality estimation models based on Random Forests, Bagging, 
Deep Learning and Genetic Programming methods. 
For the parametric models, all four methods have achieved high accuracy in terms of RMSE and 
Pearson correlation with subjective ratings. Random Forests and Bagging based models show a small 
edge over Deep Learning with respect to the accuracy they have achieved. Genetic Programming 
based models fell behind even though their accuracy is impressive as well. We have also obtained 
high accuracy on other publicly available audiovisual quality datasets and the performance metrics 
we have computed are comparable to the existing models trained and tested on these datasets. 
For the bitstream models, both the Random Forests and Bagging based bitstream models have 
outperformed the Deep Learning and Genetic Programming based bitstream models as well as 
all of the parametric models. However, both the Genetic Programming and Deep Learning based 
bitstream models fell behind the parametric models due to a significant increase in the number of 
features in the bitstream dataset. Overall we conclude that computing the bitstream information 
is worth the effort and helps to build more accurate models. However, it is useful only for the 
deployment of the right algorithms. 
In light of our results, we conclude that the Decision Trees based algorithms are well suited 
to the parametric models as well as to the bitstream models. Moreover, we know that extracting 
additional correlated data from the dataset helps us to generate more accurate models when suitable 
machine learning algorithms are deployed. 
The dataset, tools and machine learning codes that have been generated during this research 
are publicly available for research and development purposes.",,2017.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
c6bde5c3b6b5bd9cc4c9de2be3a3c4ed48fe4e86,https://www.semanticscholar.org/paper/c6bde5c3b6b5bd9cc4c9de2be3a3c4ed48fe4e86,"Tambe , Developing the Science and Applications of Security Games : Machine Learning , Uncertainty and Preference Elicitation in Game Theory for Security","Having successfully founded the research area of security games, which has led to real-world applications in scheduling the deployment of limited resources (patrols, checkpoints, inspections, etc.), we now provide fundamental advances by incorporating machine learning to enhance realworld security applications, new models of opportunistic security games, robust methods for handling uncertainty, and novel techniques for preference elicitation techniques.",,2015.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
898dd32b2f53e9943915d62b2129a80d0173513c,https://www.semanticscholar.org/paper/898dd32b2f53e9943915d62b2129a80d0173513c,Machine Learning Paradigms for Modeling Spatial and Temporal Information in Multimedia Data Mining,"Multimedia data mining and knowledge discovery is a fast emerging interdisciplinary applied research area. There is tremendous potential for effective use of multimedia data mining (MDM) through intelligent analysis. Diverse application areas are increasingly relying on multimedia understanding systems. Advances in multimedia understanding are related directly to advances in signal processing, computer vision, machine learning, pattern recognition, multimedia databases, and smart sensors. The main mission of this special issue is to identify state-of-the-art machine learning paradigms that are particularly powerful and effective for modeling and combining temporal and spatial media cues such as audio, visual, and face information and for accomplishing tasks of multimedia data mining and knowledge discovery. These models should be able to bridge the gap between low-level audiovisual features which require signal processing and high-level semantics. A number of papers have been submitted to the special issue in the areas of imaging, artificial intelligence; and pattern recognition and five contributions have been selected covering state-of-the-art algorithms and advanced related topics. The first contribution by D. Xiang et al. "" Evaluation of data quality and drought monitoring capability of FY-3A MERSI data "" describes some basic parameters and major technical indicators of the FY-3A, and evaluates data quality and drought monitoring capability of the Medium-Resolution Imager (MERSI) onboard the FY-3A. The second contribution by A. Belatreche et al. "" Computing with biologically inspired neural oscillators: application to color image segmentation "" investigates the computing capabilities and potential applications of neural oscillators, a biologically inspired neural model, to gray scale and color image segmentation, an important task in image understanding and object recognition. The major contribution of this paper is the ability to use neural oscillators as a learning scheme for solving real world engineering problems. The third paper by A. Dargazany et al. entitled "" Multi-bandwidth Kernel-based object tracking "" explores new methods for object tracking using the mean shift (MS). A bandwidth-handling MS technique is deployed in which the tracker reach the global mode of the density function not requiring a specific staring point. It has been proven via experiments that the Gradual Multibandwidth Mean Shift tracking algorithm can converge faster than the conventional kernel-based object tracking (known as the mean shift). The fourth contribution by S. Alzu'bi et al. entitled "" 3D medical volume segmentation using hybrid multi-resolution statistical approaches "" studies new 3D volume segmentation using multiresolution statistical approaches based on discrete wavelet transform and …",Adv. Artif. Intell.,2010.0,10.1155/2010/312350,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
362edc0f31ca39ad58d473a3872715a04fe516ed,https://www.semanticscholar.org/paper/362edc0f31ca39ad58d473a3872715a04fe516ed,Fair Policy Learning,"Ensuring machine learning algorithms deployed in the real world do not result in unexpected unfairness or social implications is becoming increasingly important. However, there exists a clear gap in literature for a measure of fairness that can detect discrimination against multiple sensitive attributes while also handling continuous or discrete outcomes. In this thesis, we propose a fairness measure, Fair-COCCO, based on the conditional cross-covariance operator on reproducing kernel Hilbert Spaces. This novel method generalise to the majority of existing fairness notions and naturally extends to settings with continuous outcomes and multidimensional sensitive attributes. Additionally, we demonstrate how the proposed measure can be readily implemented in stochastic gradient optimisation for fair policy learning in supervised learning settings. Empirical evaluations of Fair-COCCO on synthetic and realworld experiments reveal favourable comparisons to state-of-the-art techniques in balancing predictive power and fairness. We also see much potential in applying machine learning to analyse fairness in observed behaviour, especially in complex and high-dimensional real-world environments. To that end, we propose the first known definition of fairness for sequences of decisions and showcase how Fair-COCCO can be applied to quantify fairness in these problems. Building off these definitions, we turn to learning fair policies in real-world conditions, where learning is constrained to be performed offline. We propose Fair-PoLe, a novel inverse reinforcement learning that operates completely offline and is computationally efficient and functionally expressive when compared to existing methods. We illustrate the potential for Fair-PoLe to learn policies that balance imitation of expert policies with fair outcomes on the challenging problem of sepsis treatment.",,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a44c9535f3ed8acc4977c07c843471f7be5d2ebc,https://www.semanticscholar.org/paper/a44c9535f3ed8acc4977c07c843471f7be5d2ebc,Visual Computing and Machine Learning Techniques for Digital Forensics,"It is impressive how fast science has improved day by day in so many different fields. In special, technology advances are shocking so many people bringing to their reality facts that previously were beyond their imagination. Inspired by methods earlier presented in scientific fiction shows, the computer science community has created a new research area named Digital Forensics, which aims at developing and deploying methods for fighting against digital crimes such as digital image forgery.This work presents some of the main concepts associated with Digital Forensics and, complementarily, presents some recent and powerful techniques relying on Computer Graphics, Image Processing, Computer Vision and Machine Learning concepts for detecting forgeries in photographs. Some topics addressed in this work include: source attribution, spoofing detection, pornography detection, multimedia phylogeny, and forgery detection. Finally, this work highlights the challenges and open problems in Digital Image Forensics to provide the readers with the myriad opportunities available for research.",RITA,2015.0,10.22456/2175-2745.49492,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6a36fceecd1cc1f617cba57bfa9cde0e34d284f4,https://www.semanticscholar.org/paper/6a36fceecd1cc1f617cba57bfa9cde0e34d284f4,Learning-Based Cooperative Content Caching Policy for Mobile Edge Computing,"To address the drastic increase of multimedia traffic dominated by streaming videos, mobile edge computing (MEC) can be exploited to accelerate the development of intelligent caching at mobile network edges to reduce redundant data transmissions and improve content delivery performance. Under the MEC architecture, content providers (CPs) can access MEC servers to deploy popular content items to improve users' quality of experience. Designing an efficient caching policy is crucial for CPs due to the content dynamics, unknown spatial-temporal traffic demands and limited storage capacity. The knowledge of users' preference is important for efficient caching, but is also often unavailable in advance. Machine learning can be used to learn the users' preference based on historical demand information and decide the content items to be cached at the MEC servers. In this paper, we propose a learning based cooperative content caching policy for the MEC architecture, when the users' preference is unknown and only the historical content demands can be observed. We model the cooperative content caching problem as a multi-agent multi-armed bandit problem and propose a multiagent reinforcement learning (MARL)-based algorithm to solve the problem. Simulation experiments are conducted based on the real dataset from MovieLens and the numerical results show that the proposed MARL-based caching policy can significantly improve content cache hit rate and reduce content downloading latency in comparison with other popular caching strategies.",ICC 2019 - 2019 IEEE International Conference on Communications (ICC),2019.0,10.1109/ICC.2019.8761121,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
925cb5c0af5c33dab15e30ce28dc7068c29a9378,https://www.semanticscholar.org/paper/925cb5c0af5c33dab15e30ce28dc7068c29a9378,Towards a Smooth E-Justice: Semantic Models and Machine Learning,,,2013.0,10.1007/978-3-642-34471-8_5,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
da58c67380e285455eb8c66fc237f429fe7abd6a,https://www.semanticscholar.org/paper/da58c67380e285455eb8c66fc237f429fe7abd6a,A smart network and compute-aware Orchestrator to enhance QoS on cloud-based multimedia services,"Rich-media applications deployed on cloud lead the use of the internet by people and organisations around the world. The advent of Software-Defined Networking (SDN), Networking Function Virtualisation (NFV), and Machine Learning (ML) techniques brings new possibilities to address carrier environment challenges, especially QoS. The literature does not show a smart and flexible solution that brings scalability with holistic management of network, compute, and application resources taking into account different approaches to enhance QoS. This paper presents the Orchestrator that manages agnostic network, compute, and applications resources hosted in the cloud. Through ML algorithms, our solution enhances QoS towards network resilience, bandwidth allocation based on real-time traffic, and end-to-end QoS mechanism to the event-driven scenario. The Orchestrator operation spans across different domains providing applications, virtual functions, and cloud resources management elastically. Our experimental evaluation in a large-scale testbed shows Orchestrator's capability to provide a smart jitter decrease using AI techniques.",Int. J. Grid Util. Comput.,2020.0,10.1504/ijguc.2020.10025642,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
458b8871e9e42daae302ca160ee7e3e878666c18,https://www.semanticscholar.org/paper/458b8871e9e42daae302ca160ee7e3e878666c18,Adversarial Learning Targeting Deep Neural Network Classification: A Comprehensive Review of Defenses Against Attacks,"With wide deployment of machine learning (ML)-based systems for a variety of applications including medical, military, automotive, genomic, multimedia, and social networking, there is great potential for damage from adversarial learning (AL) attacks. In this article, we provide a contemporary survey of AL, focused particularly on defenses against attacks on deep neural network classifiers. After introducing relevant terminology and the goals and range of possible knowledge of both attackers and defenders, we survey recent work on test-time evasion (TTE), data poisoning (DP), backdoor DP, and reverse engineering (RE) attacks and particularly defenses against the same. In so doing, we distinguish robust classification from anomaly detection (AD), unsupervised from supervised, and statistical hypothesis-based defenses from ones that do not have an explicit null (no attack) hypothesis. We also consider several scenarios for detecting backdoors. We provide a technical assessment for reviewed works, including identifying any issues/limitations, required hyperparameters, needed computational complexity, as well as the performance measures evaluated and the obtained quality. We then delve deeper, providing novel insights that challenge conventional AL wisdom and that target unresolved issues, including: robust classification versus AD as a defense strategy; the belief that attack success increases with attack strength, which ignores susceptibility to AD; small perturbations for TTE attacks: a fallacy or a requirement; validity of the universal assumption that a TTE attacker knows the ground-truth class for the example to be attacked; black, gray, or white-box attacks as the standard for defense evaluation; and susceptibility of query-based RE to an AD defense. We also discuss attacks on the privacy of training data. We then present benchmark comparisons of several defenses against TTE, RE, and backdoor DP attacks on images. The article concludes with a discussion of continuing research directions, including the supreme challenge of detecting attacks whose goal is not to alter classification decisions, but rather simply to embed, without detection, “fake news” or other false content.",Proceedings of the IEEE,2020.0,10.1109/JPROC.2020.2970615,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
4408ba95c877c3214b9aa3d269c073282b9b3787,https://www.semanticscholar.org/paper/4408ba95c877c3214b9aa3d269c073282b9b3787,Generative forms of multimedia content. (Opening keynote talk),"Multimedia analysis has recently made spectacular improvements in both quality and in sophistication. Over the last half-decade we have seen extreme progress in tasks like image and video tagging, object detection and activity recognition, generating descriptive captions and more. Some of these have been deployed and are in widespread use in our smartphones and on our social media platforms. We have also seen recent research work, including our own, on computing more abstract features of multimedia, such as person-counting from CCTV, computing visual salience, estimating aesthetics of images and videos, and computing video memorability. 
The common methodology used across most of these applications is of course machine learning, in all its forms, from convolutional neural networks to simple regression and support vector machines. Much of the research in our field is about wrestling with machine learning to optimise its performance in multimedia analysis tasks and this recent run of extreme progress does not look like ending anytime soon, though it will reach its high water mark. When it does reach the point at which it cannot get any better, what then ? 
Generative machine learning (ML) is a recent form of media analysis which turns the conventional approach on its head and its methodology is to train a model and then generate new data. Example applications of generative ML deoldify which colourises black and white images and video clips, and Generative Adversarial Networks (GANs) which can generate DNA sequences, 3D models of replacement teeth, impressionist paintings, and of course video clips, some known as deepfakes. Putting aside the more nefarious applications of deepfakes, what is the potential for generative forms of multimedia ? In the short to medium term we can speculate that it would include things like movie augmentation but it how far can it go and could it replicate human creativity ? 
In this talk I will introduce some of the recent forms of generative multimedia and discuss how far I believe we could go with this exciting new technology.",,2020.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
9e9fd4dc04906b87b934694bb34ed12135f22b33,https://www.semanticscholar.org/paper/9e9fd4dc04906b87b934694bb34ed12135f22b33,Supervised-learning-Based QoE Prediction of Video Streaming in Future Networks: A Tutorial with Comparative Study,"Quality of experience (QoE)-based service management remains key for successful provisioning of multimedia services in next-generation networks such as 5G/6G, which requires proper tools for quality monitoring, prediction, and resource management where machine learning (ML) can play a crucial role. In this article, we provide a tutorial on the development and deployment of the QoE measurement and prediction solutions for video streaming services based on supervised learning ML models. First, we provide a detailed pipeline for developing and deploying super-vised-learning-based video streaming QoE prediction models that covers several stages including data collection, feature engineering, model optimization and training, testing and prediction, and evaluation. Second, we discuss the deployment of the ML model for QoE prediction/measurement in 5G/6G networks using network-enabling technologies such as software-defined networking, network function virtualization, and multi-access edge computing by proposing reference architecture. Third, we present a comparative study of the state-of-the-art supervised learning ML models for QoE prediction of video streaming applications based on multiple performance metrics.",IEEE Communications Magazine,2021.0,10.1109/MCOM.001.2100109,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
1163baadb6edf2dff16f339d668db4789403f01b,https://www.semanticscholar.org/paper/1163baadb6edf2dff16f339d668db4789403f01b,"Multimedia Analysis Techniques for Flood Detection Using Images, Articles and Satellite Imagery","This paper presents the various algorithms that the CERTH-ITI team has implemented to tackle three tasks that relate to the problem of flood severity estimation, using satellite images and online media content. Deep Convolutional Neural Networks were deployed to classify articles as flood event-related based on their images, but also to detect flooding events in satellite sequences. Remote sensing indices play a key role in the machine learning approach to identify changes between satellite imagery, while visual and textual features were exploited to estimate whether an image shows people standing in flooded areas.",MediaEval,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0966363ea46368f297999b026c827f0f5ea7fcc9,https://www.semanticscholar.org/paper/0966363ea46368f297999b026c827f0f5ea7fcc9,Efficient Machine-Type Communication Using Multi-Metric Context-Awareness for Cars Used as Mobile Sensors in Upcoming 5G Networks,"Upcoming 5G-based communication networks will be confronted with huge increases in the amount of transmitted sensor data related to massive deployments of static and mobile Internet of Things (IoT) systems. Cars acting as mobile sensors will become important data sources for cloud-based applications like predictive maintenance and dynamic traffic forecast. Due to the limitation of available communication resources, it is expected that the grows in Machine-Type Communication (MTC) will cause severe interference with Human-to-human (H2H) communication. Consequently, more efficient transmission methods are highly required. In this paper, we present a probabilistic scheme for efficient transmission of vehicular sensor data which leverages favorable channel conditions and avoids transmissions when they are expected to be highly resource-consuming. Multiple variants of the proposed scheme are evaluated in comprehensive realworld experiments. Through machine learning based combination of multiple context metrics, the proposed scheme is able to achieve up to 164% higher average data rate values for sensor applications with soft deadline requirements compared to regular periodic transmission.",2018 IEEE 87th Vehicular Technology Conference (VTC Spring),2018.0,10.1109/VTCSpring.2018.8417753,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
79480dd37fed5bf6ec1590ea3e87a1bc075ea344,https://www.semanticscholar.org/paper/79480dd37fed5bf6ec1590ea3e87a1bc075ea344,Animation Rendering on Multimedia Fog Computing Platforms,"Modern distributed multimedia applications are resource-hungry, and they often leverage on-demand cloud services to reduce their expenses. Existing cloud services deploy many servers in a few data centers, which consume a lot of electricity to power up and cold down, and thus are expensive and environmentally unfriendly. In this paper, we present a multimedia fog computing platform that utilizes resources from public crowds, edge networks, and data centers to serve distributed multimedia applications at lower costs. We use animation rendering as a case study, and identify several challenges for optimizing it on our multimedia fog computing platform. Among these challenges, we focus on the problem of predicting the completion time of each rendering job. We propose an efficient algorithm based on state-of-the-art machine learning algorithms. We also fine-tune the algorithm using multi-fold cross-validation for higher prediction accuracy. With real datasets, we conduct trace-driven simulations to quantify the performance of our prediction algorithm and that of the whole platform. The simulation results show that our proposed algorithm outperforms a state-of the-art statistical model in several aspects: completed job ratio by 20%, makespan by 2 times, and normalized deviation by 30 times, on average. Moreover, the overall performance of the platform with our proposed algorithm is fairly close to that with an Oracle of the actual job completion time: a small factor of 1.48 in terms of makespan is observed.",2016 IEEE International Conference on Cloud Computing Technology and Science (CloudCom),2016.0,10.1109/CloudCom.2016.0060,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
aa96aafaa1d0998bbee5e792a64168bf7c151a64,https://www.semanticscholar.org/paper/aa96aafaa1d0998bbee5e792a64168bf7c151a64,Traffic classification for efficient load balancing in server cluster using deep learning technique,,J. Supercomput.,2021.0,10.1007/S11227-020-03613-3,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
e162394e5dfee4732e23d867ea1ece5c9ee73a2a,https://www.semanticscholar.org/paper/e162394e5dfee4732e23d867ea1ece5c9ee73a2a,Scenario-based cyber attack·defense education system on virtual machines integrated by web technologies for protection of multimedia contents in a network,,Multimedia Tools and Applications,2020.0,10.1007/s11042-019-08583-0,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0770d401afc19bc3cf69642cc68c783bd5e2959b,https://www.semanticscholar.org/paper/0770d401afc19bc3cf69642cc68c783bd5e2959b,Introduction to the Special Issue on Fine-grained Visual Computing,"Visual computing and processing methods have been long researched in the image processing and computer vision community. This special issue not only focuses on the theoretical challenge of related technical problems, but also pays special attention on the practical effectiveness in realworld applications. Specifically, with the emergence and popularity of smart phones and cameras, we have witnessed an unprecedented growth in the volume of images and videos. The visual big multimedia data is required and supposed to be automatically processed and analyzed. However, the unique and variant visual application scenarios, such as social media, auto driving, remote sensing, and so on, lead visual data inefficient to be handled and analyzed. When real-life visual applications meet image/video computing and processing, many interesting issues and challenges will be generated. Deep learning has achieved remarkable success in computer vision and natural language processing. This special issue aims to demonstrate how machine learning and deep learning algorithm models have contributed, and are contributing to the new mathematical formulations, models, architectures, datasets, and applications to tackle visual application problems related to the topic of fine-grained visual computing. The following articles in this special issue explore a variety of deep-based multimedia analyzing solutions. Most of the articles in this special issue address the problem of recognition and understanding. The article titled “Alignment Enhancement Network for Fine-grained Visual Categorization,” by Yutao Hu, Xuhui Liu, Baochang, Zhang, Jungong Han, and Xianbin Cao, proposes a novel Alignment Enhancement Network (AENet), including two-level alignments, Cross-Layer Alignment (CLA), and Cross-Image Alignment (CIA). The CLA module exploits the cross-layer relationship between low-level spatial information and high-level semantic information, which contributes to cross-layer feature aggregation to improve the capacity of feature representation for input images. The article “Urban Perception: Sensing Cities via a Deep Interactive Multi-task Learning Framework,” by Weili Guan, Zhaozheng Chen, Fuli Feng, Weifeng Liu, and Liqiang Nie, presents a Deep inteRActive Multi-task leArning scheme (DRAMA), which comparatively quantifies the perceptions of urban attributes by jointly integrating the pairwise comparisons, regional interactions, and urban attribute correlations within a unified deep scheme. In DRAMA, each urban attribute is treated as a task, whereby the task-sharing and the task-specific information is fully explored. The article “Chinese Image Captioning via Fuzzy Attention-based DenseNet-BiLSTM,” by Huimin Lu, Rui Yang, Zhenrong Deng, Yonglin Zhang, Guangwei Gao, and Rushi Lan, proposes a fuzzy attention-based DenseNet-BiLSTM Chinese image captioning method. In the proposed",,2021.0,10.1145/3447532,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
32acdd6bf696ca1fe5e916e8c5bf554cc6d07ecf,https://www.semanticscholar.org/paper/32acdd6bf696ca1fe5e916e8c5bf554cc6d07ecf,Automatic Grading Tool for Jupyter Notebooks in Artificial Intelligence Courses,"Jupyter notebooks provide an interactive programming environment that allows writing code, text, equations, and multimedia resources. They are widely used as a teaching support tool in computer science and engineering courses. However, manual grading programming assignments in Jupyter notebooks is a challenging task, thus using an automatic grader becomes a must. This paper presents UNCode notebook auto-grader, that offers summative and formative feedback instantaneously. It provides instructors with an easy-to-use grader generator within the platform, without having to deploy a new server. Additionally, we report the experience of employing this tool in two artificial intelligence courses: Introduction to Intelligent Systems and Machine Learning. Several programming activities were carried out using the proposed tool. Analysis of students’ interactions with the tool and the students’ perceptions are presented. Results showed that the tool was widely used to evaluate their tasks, as a large number of submissions were performed. Students expressed positive opinions mostly, giving feedback about the auto-grader, highlighting the usefulness of the immediate feedback and the grading code, among other aspects that helped them to solve the activities. Results remarked on the importance of providing clear grading code and formative feedback to help the students to identify errors and correct them.",Sustainability,2021.0,10.3390/su132112050,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a2e74639174ea3db6cec4663bb8195b7dc248b5a,https://www.semanticscholar.org/paper/a2e74639174ea3db6cec4663bb8195b7dc248b5a,SINGA-Easy: An Easy-to-Use Framework for MultiModal Analysis,"Deep learning has achieved great success in a wide spectrum of multimedia applications such as image classification, natural language processing and multimodal data analysis. Recent years have seen the development of many deep learning frameworks that provide a high-level programming interface for users to design models, conduct training and deploy inference. However, it remains challenging to build an efficient end-to-end multimedia application with most existing frameworks. Specifically, in terms of usability, it is demanding for non-experts to implement deep learning models, obtain the right settings for the entire machine learning pipeline, manage models and datasets, and exploit external data sources all together. Further, in terms of adaptability, elastic computation solutions are much needed as the actual serving workload fluctuates constantly, and scaling the hardware resources to handle the fluctuating workload is typically infeasible. To address these challenges, we introduce SINGA-Easy, a new deep learning framework that provides distributed hyper-parameter tuning at the training stage, dynamic computational cost control at the inference stage, and intuitive user interactions with multimedia contents facilitated by model explanation. Our experiments on the training and deployment of multi-modality data analysis applications show that the framework is both usable and adaptable to dynamic inference loads. We implement SINGA-Easy on top of Apache SINGA and demonstrate our system with the entire machine learning life cycle.",ACM Multimedia,2021.0,10.1145/1122445.1122456,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d89af9d977839ce13728b2d9c697aed3830cd747,https://www.semanticscholar.org/paper/d89af9d977839ce13728b2d9c697aed3830cd747,"Human oriented solutions for intelligent analysis, multimedia and communication systems","In recent years many user-oriented and personalized computing technologies have been developed, in which users are immersed in a virtual world and surrounded by processing units. Such computing technologies require distributed signals to be collected, and perform intelligent analysis with data fusion depending on user preferences and the surrounding environment. In such human-oriented analysis, it is also necessary to consider different user preferences and even behavioral factors, that influence the final computing results. Development of user-oriented computing approaches are especially apparent in virtual reality and interactive technologies, multimedia, and decision-making systems, as well as user-oriented security protocols. Such human-oriented protocols allow the intelligent analysis of a great amount of information, perform analytics processes, extract meaning and manage systems in a secure manner. These subjects, as well as a number of others, such as personalized protocols for data analysis and security, computing approaches based on behavioral or perceptual factors, and bio-inspired technologies for knowledge extraction, will form the topics of this Special Issue on “Human oriented solutions for intelligent analysis, multimedia and communication systems” in the journal Concurrency and Computation: Practice and Experience. For this Special Issue eleven articles of particular interest were selected, which present the most interesting research activities and results within the subject matter of this special issue. The article “Towards human oriented solutions for deep semantic data analysis” by Ogiela and Snasel,1 presents novel solutions for efficient semantic analysis of data on the basis of cognitive reasoning and an assessment of marketing preferences registered in the course of the human perception process. Obtaining information from data on the basis of its interpreted meaning, with a view to determine individual preferences, makes it possible to designate the set of features on whose occurrence (or absence) attention is focused and those features whose occurrence has an impact on ‘interest’ within a given piece of information, product, service, and so forth. The approach presented is based on application of cognitive resonance processes implemented in cognitive information systems. The article entitled “A method to generate context information sets from analysis results with a unified abstraction model based on an extension of data enrichment scheme” by Park et al.2 presents studies on a method for processing analysis modules that can enrich result datasets with context information based on a data abstraction model. Data abstraction provides not only capabilities for context-aware systems and users to inspect the context at four levels from raw datasets to situational relationships, but also supports unified context levels for each entity that can be deployed at any location where systems deal with context to provide dedicated services. The article “Customer-oriented sales modeling strategy in a big data environment” by Chen et al.3 presents a new idea for a data mining technology application in business services. Different factors are analyzed, which may affect the profit of shopping malls in a big data environment and the most critical factors are found by data mining technology. This allows different sales promotion strategies to be provided for merchants to facilitate the expansion of sales. In management, small profits and quick returns is a popular sales strategy used by many shopping malls to increase turnover. The article “An online cognitive authentication and trust evaluation application programming interface for cognitive security gateway based on distributed massive Internet of Things network” by Chen et al.4 presents a new online cognitive authentication and trust evaluation API for CSG based on distributed massive IoT network. An online identity generation API is proposed, together with the modified EPC Class 1 Gen2 tag translator which is used to create both provider’s as well as client’s online identities. The article entitled “Dealing with Noise in Crowdsourced GPS Human Trajectory Logging Data” by Adhinugraha et al.5 presents new solutions for classifying the noise that might be found from public GPS traces. More than 5300 trajectories that started in the state of Victoria, Australia, were considered, and noise was classified into four types: spike noise, point noise, track noise, and logical noise. The authors tested the behavior of noise when processed with convex hull-based non-map-matching preprocessing methods to reduce spikes, followed by granularity reduction to reduce point density. In the article “An Effective Architecture of Digital Twin System to Support Human Decision Making and AI-Driven Autonomy” by Mostafa et al.6 a data analytic maturity model is presented, which consists of four phases with ordered activities. It shows that any data analytic project needs to be gradually developed from foundations to powerful AI algorithms. The effort and time spent on a routine will create an exponential increase in business value. The digital twin starts in phase two which immediately follows the event that the big data infrastructure is established. It is started by shallowly replicating the characteristics, features and states of its physical twin, and then dives deeper to copy its behaviors, which is achieved by AI technologies, typically machine learning models.",Concurr. Comput. Pract. Exp.,2021.0,10.1002/cpe.6532,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
14b28fd9690d3f21516649f978d5b7711ae57673,https://www.semanticscholar.org/paper/14b28fd9690d3f21516649f978d5b7711ae57673,Semantics and Machine Learning: A New Generation of Court Management Systems,,IC3K,2010.0,10.1007/978-3-642-29764-9_26,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
114aa720872462b0ca1b97bfdec0ebd56c36fd0a,https://www.semanticscholar.org/paper/114aa720872462b0ca1b97bfdec0ebd56c36fd0a,Towards Understanding and Mitigating Social Biases in Language Models,"Warning: this paper contains model outputs that may be offensive or upsetting. As machine learning methods are deployed in realworld settings such as healthcare, legal systems, and social science, it is crucial to recognize how they shape social biases and stereotypes in these sensitive decision-making processes. Among such real-world deployments are large-scale pretrained language models (LMs) that can be potentially dangerous in manifesting undesirable representational biases harmful biases resulting from stereotyping that propagate negative generalizations involving gender, race, religion, and other social constructs. As a step towards improving the fairness of LMs, we carefully define several sources of representational biases before proposing new benchmarks and metrics to measure them. With these tools, we propose steps towards mitigating social biases during text generation. Our empirical results and human evaluation demonstrate effectiveness in mitigating bias while retaining crucial contextual information for highfidelity text generation, thereby pushing forward the performance-fairness Pareto frontier.",ICML,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0e3f259d26734e30b465af1c63b13258064f11b1,https://www.semanticscholar.org/paper/0e3f259d26734e30b465af1c63b13258064f11b1,Java Deep Learning Projects,"Build and deploy powerful neural network models using the latest Java deep learning librariesAbout This BookUnderstand DL with Java by implementing real-world projectsMaster implementations of various ANN models and build your own DL systemsDevelop applications using NLP, image classification, RL, and GPU processingWho This Book Is ForIf you are a data scientist, machine learning professional, or deep learning practitioner keen to expand your knowledge by delving into the practical aspects of deep learning with Java, then this book is what you need! Get ready to build advanced deep learning models to carry out complex numerical computations. Some basic understanding of machine learning concepts and a working knowledge of Java are required.What You Will LearnMaster deep learning and neural network architecturesBuild real-life applications covering image classification, object detection, online trading, transfer learning, and multimedia analytics using DL4J and open-source APIsTrain ML agents to learn from data using deep reinforcement learningUse factorization machines for advanced movie recommendationsTrain DL models on distributed GPUs for faster deep learning with Spark and DL4JEase your learning experience through 69 FAQsIn DetailJava is one of the most widely used programming languages. With the rise of deep learning, it has become a popular choice of tool among data scientists and machine learning experts.Java Deep Learning Projects starts with an overview of deep learning concepts and then delves into advanced projects. You will see how to build several projects using different deep neural network architectures such as multilayer perceptrons, Deep Belief Networks, CNN, LSTM, and Factorization Machines.You will get acquainted with popular deep and machine learning libraries for Java such as Deeplearning4j, Spark ML, and RankSys and you'll be able to use their features to build and deploy projects on distributed computing environments.You will then explore advanced domains such as transfer learning and deep reinforcement learning using the Java ecosystem, covering various real-world domains such as healthcare, NLP, image classification, and multimedia analytics with an easy-to-follow approach. Expert reviews and tips will follow every project to give you insights and hacks.By the end of this book, you will have stepped up your expertise when it comes to deep learning in Java, taking it beyond theory and be able to build your own advanced deep learning systems.Style and approachA unique, learn-as-you-do approach, as the reader builds on his understanding of deep learning with Java progressively with each project. This book is designed in such a way that implementing each project will empower you with a unique skill set, and enable you to implement the next project more confidently.",,2018.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ee9e36c0abe8fd1c48aa73d1f83bcbb22fe3670b,https://www.semanticscholar.org/paper/ee9e36c0abe8fd1c48aa73d1f83bcbb22fe3670b,Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale,"The ever-growing demand and complexity of machine learning are putting pressure on hyper-parameter tuning systems: while the evaluation cost of models continues to increase, the scalability of state-of-the-arts starts to become a crucial bottleneck. In this paper, inspired by our experience when deploying hyper-parameter tuning in a real-world application in production and the limitations of existing systems, we propose Hyper-Tune, an efficient and robust distributed hyper-parameter tuning framework. Compared with existing systems, Hyper-Tune highlights multiple system optimizations, including (1) automatic resource allocation, (2) asynchronous scheduling, and (3) multi-fidelity optimizer. We conduct extensive evaluations on benchmark datasets and a large-scale realworld dataset in production. Empirically, with the aid of these optimizations, Hyper-Tune outperforms competitive hyper-parameter tuning systems on a wide range of scenarios, including XGBoost, CNN, RNN, and some architectural hyper-parameters for neural networks. Compared with the state-of-the-art BOHB and A-BOHB, Hyper-Tune achieves up to 11.2× and 5.1× speedups, respectively. PVLDB Reference Format: Yang Li, Yu Shen, Huaijun Jiang, Wentao Zhang, Jixiang Li, Ji Liu, Ce Zhang, and Bin Cui. Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale. PVLDB, 14(1): XXX-XXX, 2020. doi:XX.XX/XXX.XX PVLDB Availability Tag: The source code of this research paper has been made publicly available at https://github.com/PKU-DAIR/HyperTune.",Proc. VLDB Endow.,2022.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
dba3478cb46874a97e301deb0f20f7692c1f1ae9,https://www.semanticscholar.org/paper/dba3478cb46874a97e301deb0f20f7692c1f1ae9,PenDer: Incorporating Shape Constraints via Penalized Derivatives,"When deploying machine learning models in the real-world, system designers may wish that models exhibit certain shape behavior, i.e., model outputs follow a particular shape with respect to input features. Trends such as monotonicity, convexity, diminishing or accelerating returns are some of the desired shapes. Presence of these shapes makes the model more interpretable for the system designers, and adequately fair for the customers. We notice that many such common shapes are related to derivatives, and propose a new approach, PenDer (Penalizing Derivatives), which incorporates these shape constraints by penalizing the derivatives. We further present an Augmented Lagrangian Method (ALM) to learn the joint unconstrained objective function. Experiments on three realworld datasets illustrate that even though both PenDer and state-of-the-art Lattice models achieve similar conformance to shape, PenDer captures better sensitivity of prediction with respect to intended features. We also demonstrate that PenDer achieves better test performance than Lattice while enforcing more desirable shape behavior.",AAAI,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d3ac65b10af091759863b8e2c488036bf52a2ce6,https://www.semanticscholar.org/paper/d3ac65b10af091759863b8e2c488036bf52a2ce6,DAG Card is the new Model Card,"With the progressive commoditization of modeling capabilities, data-centric AI recognizes that what happens before and after training becomes crucial for realworld deployments. Following the intuition behind Model Cards, we propose DAG Cards as a form of documentation encompassing the tenets of a data-centric point of view. We argue that Machine Learning pipelines (rather than models) are the most appropriate level of documentation for many practical use cases, and we share with the community an open implementation to generate cards from code.",ArXiv,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
f02f6e666aef6b0675cc4a189f9962b716c17487,https://www.semanticscholar.org/paper/f02f6e666aef6b0675cc4a189f9962b716c17487,FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled Data,"Supervised machine learning classifiers have been widely used for attack detection, but their training requires abundant high-quality labels. Unfortunately, high-quality labels are difficult to obtain in practice due to the high cost of data labeling and the constant evolution of attackers. Without such labels, it is challenging to train and deploy targeted countermeasures. In this paper, we propose FARE, a clustering method to enable fine-grained attack categorization under low-quality labels. We focus on two common issues in data labels: 1) missing labels for certain attack classes or families; and 2) only having coarsegrained labels available for different attack types. The core idea of FARE is to take full advantage of the limited labels while using the underlying data distribution to consolidate the lowquality labels. We design an ensemble model to fuse the results of multiple unsupervised learning algorithms with the given labels to mitigate the negative impact of missing classes and coarsegrained labels. We then train an input transformation network to map the input data into a low-dimensional latent space for fine-grained clustering. Using two security datasets (Android malware and network intrusion traces), we show that FARE significantly outperforms the state-of-the-art (semi-)supervised learning methods in clustering quality/correctness. Further, we perform an initial deployment of FARE by working with a large e-commerce service to detect fraudulent accounts. With realworld A/B tests and manual investigation, we demonstrate the effectiveness of FARE to catch previously-unseen frauds.",NDSS,2021.0,10.14722/NDSS.2021.24403,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
e016b50627d81c1e6d4510dfc1b59657535b018e,https://www.semanticscholar.org/paper/e016b50627d81c1e6d4510dfc1b59657535b018e,IEEE Access Special Section: Digital Forensics Through Multimedia Source Inference,"With the prevalence of low-cost imaging devices (smartphones, tablets, camcorders, digital cameras, scanners, wearable, and IoT devices), images and videos have become the main modalities of information being exchanged in every walk of life. The ever-increasing convenience of image acquisition has facilitated instant distribution and sharing of multimedia on digital social platforms. In the meantime, powerful multimedia editing tools allow even unskilled people to easily manipulate digital content for malicious or criminal purposes. In all cases wheremultimedia serves as critical evidence, forensic technologies that help to determine the origin, the authenticity of multimedia sources, and the integrity of multimedia content become essential to forensic investigators. Imaging devices and post-acquisition processing software leave unique ‘‘fingerprints’’ in multimedia content. This allows many challenging problems faced by the multimedia forensics community to be addressed through source inference. Source inference is the task of linking digital content to the source device or platform (e.g., social media such as Facebook) responsible for its creation. It can facilitate applications such as identification and verification of source device and platform, common source inference, content integrity verification, and source-oriented image clustering. It also allows the establishment of digital evidence or the history of multimedia processing steps applied to the content, starting from the acquisition procedure and up to tracking the spread. The recent adoption of multimedia source inference techniques in the law enforcement sector (e.g., U.K. Sussex Police, Guildford Crown Court, and INTERPOL) in realworld criminal cases and child sexual exploitation databases has manifested the significant value of multimedia source inference in the fight against crime. This Special Section in IEEE ACCESS aims to collect a diverse and complementary set of articles that demonstrate new developments and applications in digital forensics through multimedia source inference. The Call for Papers received a positive response from the scientific community, and nine articles were accepted for inclusion in the Special Section after a thorough review process by at least two independent referees. The nine accepted articles range from camera and smartphone identification, including the proposal of new databases for video identification, to emerging challenges in multimedia forensics. In the article ‘‘Camera identification based on domain knowledge-driven deep multi-task learning,’’ by Ding et al., the authors describe a domain knowledge-driven method for camera identification, composed of one preprocessing module consisting of a sequential multiscale high-pass filter to achieve a residual image, feature extractor, and a hierarchical multitask learning procedure. The classification phase is made through a Convolutional Neural Network (CNN) that can distinguish among camera brands, models, and devices. The article ‘‘A deep and scalable unsupervised machine learning system for cyber-attack detection in large-scale smart grids,’’ by Karimipour et al., presents an anomaly detection method able to differentiate an actual fault from a cyber-attack in a smart grid. The proposed method applies feature extraction utilizing symbolic dynamic filtering. The article ‘‘FD-GAN: Face de-morphing generative adversarial network for restoring accomplice’s facial image,’’ by Peng et al., studies a face de-morphing generative adversarial network (FD-GAN) to restore a facial image. A face morphing detector is devised employing the symmetric dual network architecture. The article ‘‘Estimation of primary quantization steps in double-compressed JPEG images using a statistical model of discrete cosine transform,’’ by Thai and Cogranne, discusses the estimation of the first compression parameter of double compression in JPEG images to help reveal the software used to create an image or the camera that acquired it. In detail, the article proposes an accurate method for estimating the possible value for the quantization of primary DCT coefficients with respect to the secondary quantization step. The article ‘‘The video authentication and camera identification database: A new database for video forensics,’’ by Hosler et al., introduces a video authentication and camera identification database (videoACID) with a large collection of videos. The videoACID database contains more than 12 000 videos from 46 physical devices representing 36 unique camera models.",IEEE Access,2020.0,10.1109/access.2020.3036772,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
8d18aa4b23b4f9124b9eb46427eeb9929a63fa05,https://www.semanticscholar.org/paper/8d18aa4b23b4f9124b9eb46427eeb9929a63fa05,IEEE Access Special Section Editorial: Mobile Multimedia for Healthcare,"With the availability of easy access to the Internet, and the proliferation of various mobile devices, people can get access to mobile multimedia ubiquitously in order to have a desktop experience. Mobile multimedia refers to different types of multimedia content (e.g., text, images, audios, and videos), which are accessed via heterogeneous mobile devices, such as mobile phones, portable devices, and smartphones. Mobile multimedia services and applications have tremendous potential in the healthcare sector. Currently, as the healthcare sector is increasingly dependent on mobile multimedia services and applications, many challenges remain unsolved for the successful deployment of mobile multimedia services in order to have a balance between power-limited mobile devices and resource hungry medical multimedia content. This Special Section aims to theme innovative research achievements in the field of related techniques, applications, services, and systems for mobile multimedia healthcare. The articles in this Special Section bring together academic and industrial researchers to identify and discuss technical challenges and recent results related to mobile multimedia for healthcare. As an application area, mobile multimedia is one of the most active and successful fields of use in the domain of the healthcare industry. The Special Section focuses on particular aspects of mobile multimedia for healthcare, such as comprehensive data sensing, assistive sensory media, and sharing mobile-healthcare big data. After a rigorous review process, we accepted the following articles to form the Special Section. In the article titled, ‘‘DEEP-SEE FACE: A mobile face recognition system dedicated to visually impaired people,’’ by Mocanu et al., the authors introduce a novel assistive device designed to improve cognition, interaction, and communication of visually impaired (VI) people in social encounters. The proposed approach jointly exploits computer vision algorithms and deep convolutional neural networks in order to detect, track, and recognize, in real time, various people’s existence in video streams. The major contribution of the article concerns a global, fixed-size face representation that takes into account various video frames while remaining independent of the length of the image sequence. For this purpose, the authors introduce an effective weight adaptation scheme that can determine the relevance assigned to each face instance, depending on the frame degree of motion/ camera blur, scale variation, and compression artifacts. The experimental results carried out on a large-scale data set validate the proposed methodology with an average accuracy and recognition rates superior to 92%.When tested in real-life indoor/outdoor scenarios, the proposed framework proves to be effective and easy to use, allowing the VI people to access visual information during social events. In the article, ‘‘Voice disorder identification by using machine learning techniques,’’ by Verde et al., the authors introduce an exhaustive comparison between the most used machine learning algorithms existing in the literature. The aim of this study is to identify the techniques capable of discriminating between pathological and healthy voices with more accuracy. This is fundamental to realizing a valid and precise mobile health system and a promising solution for people who desire the detection, monitoring, and treatment of their health conditions anywhere and at any time. All analyses are performed on a dataset of voices selected from the freely available Saarbrucken Voice Database. They show that the best accuracy in voice disease detection is achieved by the support vector machine algorithm or the decision tree one, depending on the features evaluated by using opportune feature selection methods. The article ‘‘Performance analysis of personal cloud storage services for mobile multimedia health record management,’’ by Akter et al., focuses on performance analysis of personal cloud storage services for mobile multimedia personal health record (PHR) management. In particular, the authors investigated using qualitative and quantitative analyses of the strengths and weaknesses of personal cloud storage services for PHR management scenarios. The qualitative analysis includes chunking, bundling, deduplication, delta-encoding, and data compression features. The quantitative analysis includes control data overhead, application data exchanged, and impact of data size on number of packets, as well as transmission rate, synchronization initialization time, and protocol overhead. Experimental results on various benchmark cloud storage datasets showed satisfactory outcomes. Wearable technology and personal health devices (PHDs) play a critical role in shaping the future of healthcare. The International Organization for Standardization (ISO) realized the role of personal health systems and proposed the 11 073 family of standards. To this end, the article ‘‘ISO/IEEE 11 073 personal health device (X73-PHD) standards",IEEE Access,2020.0,10.1109/access.2020.3017119,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
9145d36f4892771990d014bc151c45664dcbaf2e,https://www.semanticscholar.org/paper/9145d36f4892771990d014bc151c45664dcbaf2e,Image Similarity Search in Large Databases Using a Fast Machine Learning Approach,,New Directions in Intelligent Interactive Multimedia,2008.0,10.1007/978-3-540-68127-4_9,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3352eb2b731571ca9ba85e671a214b2e2467d8d9,https://www.semanticscholar.org/paper/3352eb2b731571ca9ba85e671a214b2e2467d8d9,Online and Scalable Model Selection with Multi-Armed Bandits,"Many online applications running on live traffic are powered by machine learning models, for which training, validation, and hyperparameter tuning are conducted on historical data. However, it is common for models demonstrating strong performance in offline analysis to yield poorer performance when deployed online. This problem is a consequence of the difficulty of training on historical data in non-stationary environments. Moreover, the machine learning metrics used for model selection may not sufficiently correlate with real-world business metrics used to determine the success of the applications being tested. These problems are particularly prominent in the Real-Time Bidding (RTB) domain, in which ML models power bidding strategies, and a change in models will likely affect performance of the advertising campaigns. In this work, we present Automatic Model Selector (AMS), a system for scalable online selection of RTB bidding strategies based on realworld performance metrics. AMS employs Multi-Armed Bandits (MAB) to near-simultaneously run and evaluate multiple models against live traffic, allocating the most traffic to the bestperforming models while decreasing traffic to those with poorer online performance, thereby minimizing the impact of inferior models on overall campaign performance. The reliance on offline data is avoided, instead making model selections on a case-by-case basis according to actionable business goals. AMS allows new models to be safely introduced into live campaigns as soon as they are developed, minimizing the risk to overall performance. In livetraffic tests on multiple ad campaigns, the AMS system proved highly effective at improving ad campaign performance.",ArXiv,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0f5dc98f4ad051b7e49aa31cfc8fae5c2b532a1e,https://www.semanticscholar.org/paper/0f5dc98f4ad051b7e49aa31cfc8fae5c2b532a1e,Using system context information to complement weakly labeled data,"Real-world datasets collected with sensor networks often contain incomplete and uncertain labels as well as artefacts arising from the system environment. Complete and reliable labeling is often infeasible for large-scale and long-term sensor network deployments due to the labor and time overhead, limited availability of experts and missing ground truth. In addition, if the machine learning method used for analysis is sensitive to certain features of a deployment, labeling and learning needs to be repeated for every new deployment. To address these challenges, we propose to make use of system context information formalized in an information graph and embed it in the learning process via contrastive learning. Based on realworld data we show that this approach leads to an increased accuracy in case of weakly labeled data and leads to an increased robustness and transferability of the classifier to new sensor locations.",ArXiv,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
34c59ec266e2f1798918d765c2a2519a2b8d03d2,https://www.semanticscholar.org/paper/34c59ec266e2f1798918d765c2a2519a2b8d03d2,ReLink: Complete-Link Industrial Record Linkage Over Hybrid Feature Spaces,"Record Linkage (ReL) is the task of identifying records from a pair of databases referring to the same realworld entity. This has many applications in organisations of all sizes where related data often exist in silos leading to inefficiency in data engineering and analytics applications as well as ineffectiveness of business applications (e.g., unable to personalise marketing campaigns).State-of-the-art (SOTA) machine learning and deep learning based ReL techniques use adaptive similarity measures and learn their relative contributions based on labeled data. However, we report here that they do not work with similar efficacy on industrial data owing to its fundamental differences such as magnitude of schema heterogeneity, need for leveraging structure of the data, lack of training data etc. Through our proposed system ‘ReLink’, we carefully mitigate these challenges and demonstrate that it not only significantly outperforms SOTA baselines on industrial datasets but also on majority of research benchmarks. ReLink introduces the notion of complete-linkage over attributes as well as uses hybrid feature spaces on lexical and semantic similarity measures using pre-trained models such as BERT. Going beyond empirical demonstration, we provide insights and prescriptive guidance on choice of ReL techniques in industrial settings from our observations and lessons learnt from the experience of transferring and deploying for real use-cases in a large financial services organization.",2021 IEEE 37th International Conference on Data Engineering (ICDE),2021.0,10.1109/ICDE51399.2021.00293,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
4d8e7c7f09ed151ee1e9fd37a4638e528432526e,https://www.semanticscholar.org/paper/4d8e7c7f09ed151ee1e9fd37a4638e528432526e,Adaptive and Blended Learning _ the Panacea for the Challenges of E-Learning,"In spite of increased use of information and communication technologies in many areas, E-learning is not widely used in Higher Education as it is still considered as an inferior way of education and also due to the fact it carries its own barriers. In this article the advantages as well as the disadvantages of Elearning are listed. Then the solutions such as Blended Learning and Adaptive Learning embedded with Gamification, Group Dynamics and Graphic Organizers and Multimedia packages to solve the impediments are dealt with, in detail. The population of the study included the teaching staff and undergraduate students of An Nabhanya College of Science and Arts. About 60 Questionnaires are distributed amongst them. Questionnaires are designed consisting three parts. The first part deals with the number of courses where e-learning is implemented and the second part lists the benefits availed by the teachers and students by E-Learning. The third part enlists the problems faced by the students and the instructors during E-Learning. The study indicates that there is a poor milieu as far as educational environment is concerned due to the boredom of e-learning, there is also the lack of proper resources, PCs, Wi-Fi’s and study materials and also, procrastination, lack of motivation, lack of serious Assignments. Moreover, there is also a dearth of well trained and experienced Instructors and technical staff in the campus. Thereby this paper insists that concentration is to be bestowed on Blended Learning and adaptive E-learning as tools to overcome the disadvantages. Also this article suggests that the teaching staff should be provided with many professional Development Sessions and Workshops in ELearning, Blended -Learning Adaptive E-Learning. It also suggests that there can be availability of a technical staff for each programme in the colleges. Key Terms: E-Learning Challenges, Blended Learning , Adaptive Learning, Professional Development Sessions, Provision of Technical Assistants. 1. Background of the study Both globalization and the innovations in information and communication technology brought in a seachange in learning. One of the such born e-children, e-learning, the new changing face of learning, is learning eased by electronic technology with the objective of better the learners’ knowledge, skills and productive capabilities. It comprises of an extensive array of digitalization approaches, components and delivery methods in education through internet. Distance education, online instruction, e-learning, online training, asynchronous/synchronous learning, distant education, and web-based education programs are some of the most popular terms recently being used in instructional and technological contexts (Moore, Dickson-Deane & Galyen, 2011)20. E-learning is utilized by all walks of people. This paper presents a brief overview the concept of e-learning, the history of e-learning, the benefits of e-learning, unfortunately there are many a drawback to eLearning which makes the education community ponder on the question of ‘To be E or Not to be E’. Fortunately, adaptive e-learning and blended Learning can help to overcome the disadvantages of e-learning. The current research study will certainly play an important role in providing valuable insights about the attitudes of students and the staff at An Nabhanya College of Science and Arts Girls’ College towards elearning activities. The research study will therefore suggest the deployment of instructors and staff who are professionally well trained in Blended Learning and adaptive learning. © 2020 JETIR May 2020, Volume 7, Issue 5 www.jetir.org (ISSN-2349-5162) JETIR2005241 Journal of Emerging Technologies and Innovative Research (JETIR) www.jetir.org 708 2. E-learning 2.1 What is E-learning Millions and millions of millennials have already knocked at the Gateways of E-Learning, as it has become the ‘summum bonum’ of educational setting. It is internet-enabled or web-based (LaRose et al, 1998)16 learning. There are live instructions where specialized instructors can remain in their own places and deliver lessons to students in different locations. Video content delivery can be viewed and reviewed whenever students need. The e-learning concept means all the computer based educational tools or systems will allow the learners to receive their lessons anytime and anywhere. The transition from the usage of just the CD-ROM to the delivery of e-learning lessons [2] that bridges the geographical gap and conducts online virtual classes and that leads the students roam in a new landscape and lets them actively participate [1] is beyond one’s imagination. 2.2 The History of E-learning The term “e-learning” came into existence in 1999, though words used to describe e-learning such as “online learning” and “virtual learning” were in existence earlier in the 19th century [1]. Isaac Pitman taught his pupils shorthand via correspondence in the 1840s paving the road to e-learning. Then, in 1954, BF Skinner invented the “teaching machine” a big achievement to help the schools to administer programmed instruction to their students. In 1960, the first computer-based training program was introduced to the world. This computer-based training program (CBT) was also termed as Programmed Logic for Automated Teaching Operations (PLATO). It was originally designed for students attending the University of Illinois.[1] In the second half of the 20th century, e-learning tools and delivery methods have become very much in vogue. Then, the advent of Virtual learning began and thrived. 2.3 E Learning in KSA The e-learning milieu in KSA is a shining like a star embedded sky as every University tries to board the e-learning bandwagon. The Custodian of the Two Holy Mosques King Abdullah launching the first phase of the university and higher education city projects on an iPad in a ceremony in the first week of May,2012 speaks volumes of the nation’s interest and efforts in promoting e learning. The ministry of Higher education in the kingdom has already set up a National centre that caters for both E learning and distance learning. In 2007, KSA established a new university, the Knowledge International University (KIU), dedicated to the use of e-learning resources. The MOHE has set up a repository for e-learning material to help universities adopt e-learning and e-books for engineering, medical, computer science and humanities courses, these are either planned or available and academics are able to receive training. [Al-Kahtani SA. 2001]3 2.4 Benefits of E-Learning It is an All in One Learning by linking the various resources in several varying formats at the same time. It promotes active and independent learning. Liberty is at one’s Door as no dependence on anyone for anything and at one’s own pace. E-Learning can be done on laptops, tablets and phone. It eradicates boundaries of place and time. (Holmes and Gardner, 2006)13. The Good News is the teachers no longer worry about the class room management. E Learning is available at minimum cost. 2.5 Barriers to E-learning: All-time favourite is still face-to face learning. Lack of self-discipline is the biggest threat to e-learning. Though gadget-friendly people are gratified with e-learning immensely, there are many with GadgetPhobia. E-Learning is not feasible to all courses for instance, science courses. There will be cheating and plagiarism. There is also a dearth of resources like technologies and infrastructure for the communication, security, personal relations and motivation. © 2020 JETIR May 2020, Volume 7, Issue 5 www.jetir.org (ISSN-2349-5162) JETIR2005241 Journal of Emerging Technologies and Innovative Research (JETIR) www.jetir.org 709 According to Judahil et al (2007)15, it demands a variety of skills in Information and Communication Technology (ICT). The most noticeable condemnation of e-Learning is poor ICT infrastructure. Most importantly, the void of vital personal interactions between learners and instructors, and also among colearners (Young, 1997;Burdman, 1998)36 is the biggest criticism on eLearning. 3. Advanced E Learning Methods 3.1 Blended Learning Blended Learning and Adaptive Learning embedded with Gamification, Group Dynamics and Graphic Organizers and Multimedia packages to solve the impediments of e learning. Blended learning, a mix of direct face-to-face interactions and technology-mediated interactions between students, teachers and learning resources. The adoption of blended education is increasingly seen in higher education institutions, and researchers expect that blended learning will become the new ""traditional model"" (Ross & Gage, 2006)28 or the ""new norm"" in the introduction of higher education courses (Norberg, 2011)24 According to Stacey & Gerbic [2007]30 learning experience and performance improve when traditional course delivery is paired with online learning. A study by Marriot, Marriot, and Selwyn [2004]18 showed learners expressing their preference for face-to-face due to its facilitation of social interaction and communication skills acquired from classroom environment. Blackboard network platform Developed by Blackboard Company (the United States), a curriculumoriented digital teaching platform can display teaching contents and implement the comprehensive strategy of teaching activities conducive to represent the teaching contents efficiently and improve the use of teaching resources. [14 &36] An Example for Blended Learning Structure In class: Students select an historical event to research, such as., Indo –China War, Kargil War, Indian Independence, World War I, World War II. Students brainstorm what they know about each of the events. Outside of class: Students access one of the interactive sites and complete a graphic organizer. In class: Students collaborate to create a timeline of Indian history (on poster board or chart paper posted around the classroom). 3.2 Addressing Potential Impediments to Lear",,2020.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
7d6e9e6e39c70b947296cb4c17aacf4452fc5b29,https://www.semanticscholar.org/paper/7d6e9e6e39c70b947296cb4c17aacf4452fc5b29,Exploring the Use of Synthetic Gradients for Distributed Deep Learning across Cloud and Edge Resources,"With the explosive growth of data, largely contributed by the rapidly and widely deployed smart devices on the edge, we need to rethink the training paradigm for learning on such realworld data. The conventional cloud-only approach can hardly keep up with the computational demand from these deep learning tasks; and the traditional back propagation based training method also makes it difficult to scale out the training. Fortunately, the continuous advancement in System on Chip (SoC) hardware is transforming edge devices into capable computing platforms, and can potentially be exploited to address these challenges. These observations have motivated this paper’s study on the use of synthetic gradients for distributed training cross cloud and edge devices. We employ synthetic gradients into various neural network models to comprehensively evaluate its feasibility in terms of accuracy and convergence speed. We distribute the training of the various layers of a model using synthetic gradients, and evaluate its effectiveness on the edge by using resource-limited containers to emulate edge devices. The evaluation result shows that the synthetic gradient approach can achieve comparable accuracy compared to the conventional back propagation, for an eight-layer model with both fully-connected and convolutional layers. For a more complex model (VGG16), the training suffers from some accuracy degradation (up to 15%). But it achieves 11% improvement in training speed when the layers of a model are decoupled and trained on separate resource-limited containers, compared to the training of the whole model using the conventional method on the physical machine.",HotEdge,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
9164a133d88876596bd994dc6530f2750a96a2f2,https://www.semanticscholar.org/paper/9164a133d88876596bd994dc6530f2750a96a2f2,Catch-up TV forecasting: enabling next-generation over-the-top multimedia TV services,,Multimedia Tools and Applications,2018.0,10.1007/s11042-017-5043-9,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0fc5cd83fcc493a764b6b8ab8496a40f46d130d8,https://www.semanticscholar.org/paper/0fc5cd83fcc493a764b6b8ab8496a40f46d130d8,DIME: Fine-grained Interpretations of Multimodal Models via Disentangled Local Explanations,"The ability for a human to understand an Artificial Intelligence (AI) model's decision-making process is critical in enabling stakeholders to visualize model behavior, perform model debugging, promote trust in AI models, and assist in collaborative human-AI decision-making. As a result, the research fields of interpretable and explainable AI have gained traction within AI communities as well as interdisciplinary scientists seeking to apply AI in their subject areas. In this paper, we focus on advancing the state-of-the-art in interpreting multimodal models - a class of machine learning methods that tackle core challenges in representing and capturing interactions between heterogeneous data sources such as images, text, audio, and time-series data. Multimodal models have proliferated numerous real-world applications across healthcare, robotics, multimedia, affective computing, and human-computer interaction. By performing model disentanglement into unimodal contributions (UC) and multimodal interactions (MI), our proposed approach, DIME, enables accurate and fine-grained analysis of multimodal models while maintaining generality across arbitrary modalities, model architectures, and tasks. Through a comprehensive suite of experiments on both synthetic and real-world multimodal tasks, we show that DIME generates accurate disentangled explanations, helps users of multimodal models gain a deeper understanding of model behavior, and presents a step towards debugging and improving these models for real-world deployment.",AIES,2022.0,10.48550/arXiv.2203.02013,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
5871821e9216016a075acb999ca3b798209b0c49,https://www.semanticscholar.org/paper/5871821e9216016a075acb999ca3b798209b0c49,Video representation and suspicious event detection using semantic technologies,"Due to the widespread deployment of Surveillance Systems and IoT applications, the amount of surveillance data is massively on the rise. Storing and analyzing video surveillance data is a significant challenge, requiring video interpretation and event detection along with related context. Low-level features from multimedia content are extracted and represented in symbolic form. These features include shape, texture, and color information of the multimedia content. In this work, a methodology is proposed, which extracts the salient features and properties using machine learning techniques typical of the surveillance domain, and represents the information using a domain ontology tailored explicitly for the detection of certain activities. An ontology is developed to include concepts and properties which may be applicable in the domain of surveillance and its applications. Extracted features are represented as Linked Data using an ontology. The proposed approach is validated with actual implementation and is thus evaluated by recognizing suspicious activity in an open parking space. The suspicious activity detection is formalized through inference rules and SPARQL queries. Eventually, Semantic Web Technology has proven to be a remarkable toolchain to interpret videos, thus opening novel possibilities for video scene representation, and detection of complex events, without any human involvement. As per the best of our knowledge about the literature of this domain, we claim that there is no existing method that can represent frame-level information of a video in structured representation and perform event detection, reducing storage and enhancing semantically-aided retrieval of video data. A video dataset of six different, and unusual, suspicious activities has also been built, which can be useful to solve problems related to activity recognition in other smart parking scenarios.",Semantic Web,2021.0,10.3233/sw-200393,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ce6efaeed43056b7483246635d7fd0f7bf96ddeb,https://www.semanticscholar.org/paper/ce6efaeed43056b7483246635d7fd0f7bf96ddeb,SDN Based Content-Centric QoS-Guaranteed for Wireless Multimedia Sensor Networks,,INISCOM,2017.0,10.1007/978-3-319-74176-5_4,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
f3a4b1e6ee23465786c60b891e1eafb6b71b0dcb,https://www.semanticscholar.org/paper/f3a4b1e6ee23465786c60b891e1eafb6b71b0dcb,EasyDeep: An IoT Friendly Robust Detection Method for GAN Generated Deepfake Images in Social Media,,IFIPIoT,2021.0,10.1007/978-3-030-96466-5_14,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
17e3d02953834fd5524691422795b99d8e874cf2,https://www.semanticscholar.org/paper/17e3d02953834fd5524691422795b99d8e874cf2,"Energy-Efficient Ultra-Dense 5G Networks: Recent Advances, Taxonomy and Future Research Directions","The global surge of connected devices and multimedia services necessitates increased capacity and coverage of communication networks. One approach to address the unprecedented rise in capacity and coverage requirement is deploying several small cells to create ultra-dense networks. This, however, exacerbates problems with energy consumption and network management due to the density and unplanned nature of the deployment. This review discusses various approaches to solving energy efficiency problems in ultra-dense networks, ranging from deployment to optimisation. Based on the review, we propose a taxonomy, summarise key findings, and discuss operational and implementation details of past research contributions. In particular, we focus on popular approaches such as machine learning, game theory, stochastic and heuristic techniques in the ultra-dense network from an energy perspective due to their promise in addressing the issue in future networks. Furthermore, we identify several challenges for improving energy efficiency in an ultra-dense network. Finally, future research directions are outlined for improving energy efficiency in ultra-dense networks in 5G and beyond 5G networks.",IEEE Access,2021.0,10.1109/access.2021.3123577,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3eb80ab0e130c72e2c7670836fd596a35c4e4579,https://www.semanticscholar.org/paper/3eb80ab0e130c72e2c7670836fd596a35c4e4579,Energy Conservation in Multimedia Big Data Computing and the Internet of Things—A Challenge,,Intelligent Systems Reference Library,2019.0,10.1007/978-981-13-8759-3_2,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
9cd93137427957a0ce5b071965d78b946e6f5088,https://www.semanticscholar.org/paper/9cd93137427957a0ce5b071965d78b946e6f5088,"Call for Papers: Science teaching, learning, and assessment with 21st century, cutting-edge digital ecologies","The science education community has embraced the deployment of contemporaneous technological tools and platforms in the service of improving science teaching, learning, and assessment. Technology use in science education has ranged—among many other things—from computer-assisted instruction in the 1970s, to using microcomputer-based laboratories and first-generation simulations and micro-worlds in the 1980s and throughout the 1990s. The 1990s also witnessed the deployment of interactive videodiscs, multimedia, hypermedia, and other digital resources as cognitive tools in science classrooms (Songer, 2007), which was followed by efforts to harness the power of the Internet to, for instance, share data in support of multisite student-driven inquiry projects, among many other applications (Abd-El-Khalick, 2001). The last two decades featured the expanded and integrated use of learning-specific software applications, interactive visualizations, modeling tools, and immersive e-learning environments in science teaching and learning (Krajcik & Mun, 2014). The last decade or so has witnessed rapid and groundbreaking advancements in technologies and digital platforms, as well as their application to teaching and learning. These include advances that made high-powered computing and powerful applications in serious gaming, and virtual and augmented reality more accessible to mainstream users. Similar advances have been evident in big data curation, data mining and data analytics, natural language processing, as well as next-generation machine learning and the application of artificial intelligence (AI) to the real-time and adaptive assessment of learning. The coordination through powerful computing and AI of tangible, immersive, intelligent, and multiuser technologies and digital media systems (coordinating, for instance, learner interactions with interactive wall displays, intelligent interfaces, multitouch tables, motion sensors, etc.) now allow the creation of digital ecologies that provide learners with highly engaging and authentic interactive science learning experiences. Simultaneously, these technologies and interfaces enable the collection of massive data about the choices, behaviors, and cognition of an individual learner or groups of learners (keyboard strokes, mouse clicks, eye tracking, body movement, etc.) that allow for real-time feedback both to learners and their teachers, as well as the delivery of adaptive and personalized learning experiences (ILSDI, 2014). These digital technologies and ecologies have the potential to transform science teaching and learning, as well as deliver on the promise of more personalized science education experiences in service of promoting scientific literacy for all (NGSS Lead States, 2013) including, but not limited to, historically underrepresented populations in science, culturally, ethnically, and linguistically diverse students, as well as learners in underprivileged and underserved communities in the United States and around the globe. The aims of this Special Issue of JRST is to provide a platform for reporting on empirical research that examines the use and impact of 21st century cutting-edge technologies, technological platforms, technological activity, and digital ecologies on science teaching, learning, and assessment. We also Received: 20 December 2018 Accepted: 20 December 2018",Journal of Research in Science Teaching,2019.0,10.1002/TEA.21529,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3751af1e39575120bc5c31724f173db51f0e1653,https://www.semanticscholar.org/paper/3751af1e39575120bc5c31724f173db51f0e1653,A Dilated Convolutional Neural Network as Feature Selector for Spatial Image Steganalysis – A Hybrid Classification Scheme,,,2020.0,10.1134/s1054661820030098,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
320e3a66dbc51a1331f65b5ac42b937a39d5e051,https://www.semanticscholar.org/paper/320e3a66dbc51a1331f65b5ac42b937a39d5e051,Physical Activity Recognition With Statistical-Deep Fusion Model Using Multiple Sensory Data for Smart Health,"Nowadays, enhancing the living standard with smart healthcare via the Internet of Things is one of the most critical goals of smart cities, in which artificial intelligence plays as the core technology. Many smart services, deployed according to wearable sensor-based physical activity recognition, have been able to early detect unhealthy daily behaviors and further medical risks. Numerous approaches have studied shallow handcrafted features coupled with traditional machine learning (ML) techniques, which find it difficult to model real-world activities. In this work, by revealing deep features from deep convolutional neural networks (DCNNs) in fusion with conventional handcrafted features, we learn an intermediate fusion framework of human activity recognition (HAR). According to transforming the raw signal value to pixel intensity value, segmentation data acquired from a multisensor system are encoded to an activity image for deep model learning. Formulated by several novel residual triple convolutional blocks, the proposed DCNN allows extracting multiscale spatiotemporal signal-level and sensor-level correlations simultaneously from the activity image. In the fusion model, the hybrid feature merged from the handcrafted and deep features is learned by a multiclass support vector machine (SVM) classifier. Based on several experiments of performance evaluation, our fusion approach for activity recognition has achieved the accuracy over 96.0% on three public benchmark data sets, including Daily and Sport Activities, Daily Life Activities, and RealWorld. Furthermore, the method outperforms several state-of-the-art HAR approaches and demonstrates the superiority of the proposed intermediate fusion model in multisensor systems.",IEEE Internet of Things Journal,2021.0,10.1109/JIOT.2020.3013272,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ba160d74ec4499fc3e1c054595db2b1ce5583820,https://www.semanticscholar.org/paper/ba160d74ec4499fc3e1c054595db2b1ce5583820,Efficient Approximate Adders for FPGA-Based Data-Paths,"Approximate computing represents a powerful technique to reduce energy consumption and computational delay in error-resilient applications, such as multimedia processing, machine learning, and many others. In these contexts, designing efficient digital data-paths is a crucial concern. For this reason, the addition operation has received a great deal of attention. However, most of the approximate adders proposed in the literature are oriented to Application Specific Integrated Circuits (ASICs), and their deployment on different devices, such as Field Programmable Gate Arrays (FPGAs), appears to be unfeasible (or at least ineffective). This paper presents a novel approximate addition technique thought to efficiently exploit the configurable resources available within an FPGA device. The proposed approximation strategy sums the k least significant bits two-by-two by using 4-input Look-up-Tables (LUTs), each performing a precise 2-bit addition with the zeroed carry-in. In comparison with several FPGA-based approximate adders in the existing literature, the novel adder achieves markedly improved error characteristics without compromising either the power consumption or the delay. As an example, when implemented within the Artix-7 xc7a100tcsg324-3 chip, the 32-bit adder designed as proposed here with k = 8 performs as fast as its competitors and reduces the Mean Error Distance (MED) by up to 72% over the state-of-the-art approximate adders, with an energy penalty of just 8% in the worst scenario. The integration of the new approximate adder within a more complex application, such as the 2D digital image filtering, has shown even better results. In such a case, the MED is reduced by up to 97% with respect to the FPGA-based counterparts proposed in the literature.",Electronics,2020.0,10.3390/ELECTRONICS9091529,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
89f116cc57a16c9da0c84e91472d949508f337c2,https://www.semanticscholar.org/paper/89f116cc57a16c9da0c84e91472d949508f337c2,MLModelCI: An Automatic Cloud Platform for Efficient MLaaS,"MLModelCI provides multimedia researchers and developers with a one-stop platform for efficient machine learning (ML) services. The system leverages DevOps techniques to optimize, test, and manage models. It also containerizes and deploys these optimized and validated models as cloud services (MLaaS). In its essence, MLModelCI serves as a housekeeper to help users publish models. The models are first automatically converted to optimized formats for production purpose and then profiled under different settings (e.g., batch size and hardware). The profiling information can be used as guidelines for balancing the trade-off between performance and cost of MLaaS. Finally, the system dockerizes the models for ease of deployment to cloud environments. A key feature of MLModelCI is the implementation of a controller, which allows elastic evaluation which only utilizes idle workers while maintaining online service quality. Our system bridges the gap between current ML training and serving systems and thus free developers from manual and tedious work often associated with service deployment. We release the platform as an open-source project on GitHub under Apache 2.0 license, with the aim that it will facilitate and streamline more large-scale ML applications and research projects.",ACM Multimedia,2020.0,10.1145/3394171.3414535,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
fbcd33389f71f288a27622beb4d8a366c964fd73,https://www.semanticscholar.org/paper/fbcd33389f71f288a27622beb4d8a366c964fd73,"Ghost calls from operational 4G call systems: IMS vulnerability, call DoS attack, and countermeasure","IMS (IP Multimedia Subsystem) is an essential framework for providing 4G/5G multimedia services. It has been deployed worldwide to support two call services: VoLTE (Voice over LTE) and VoWi-Fi (Voice over Wi-Fi). VoWi-Fi enables telephony calls over the Wi-Fi network to complement VoLTE. In this work, we uncover that the VoWi-Fi signaling session can be hijacked to maliciously manipulate the IMS call operation. An adversary can easily make ghost calls to launch a stealthy call DoS (Denial of Service) attack against specific cellular users. Only phone numbers, but not any malware or network information, are required from the victims. This sophisticated attack harnesses a design defect of the IMS call state machine, but not simply flooding or a crash trigger. To stealthily detect attackable phones at run time, we exploit a vulnerability of the 4G network infrastructure, call information leakage, which we explore using machine learning. We validate these vulnerabilities in operational 4G networks of 4 top-tier carriers across Asia and North America countries with 7 phone brands. Our result shows that the call DoS attack can prevent the victims from receiving incoming calls up to 99.0% time without user awareness. We finally propose and evaluate recommended solutions.",MobiCom,2020.0,10.1145/3372224.3380885,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
dfab95c0af007979c990a932fed2fa9b80d943c1,https://www.semanticscholar.org/paper/dfab95c0af007979c990a932fed2fa9b80d943c1,QoE-Aware Intelligent Handover Method for Intent-Based Software-Defined Wireless Network,"Intent-Based Networking (IBN) focuses on technologically independent, fast, and reliable interaction between network infrastructure management systems and users. This concept is being developed to automate and accelerate the deployment of the network lifecycle. Thus, IBN includes mechanisms for recognizing, understanding, and extending the intents that define the quality-of-service (QoS) requests. Therefore, this paper proposes an intent-based software-defined wireless network (IBSDWN) approach in which the controller intelligently decides when to initiate the handover of services. For this purpose, the controller selects the access point (AP) to which the client device should connect, based on the set quality of experience (QoE) requirements using an intent processing technique. A method for initiating handover in IBSDWN based on machine learning (ML) algorithms and an integral QoE criterion formed from real-time measurements of parameters: received signal strength indication (RSSI), throughput, packet loss, and delay is developed. Implementation of ML module in IBN architecture for monitoring system allowed to reduce the volume of signal traffic in communication channels between network equipment and controller. Also, the developed ML module made it possible to detect the degradation of QoE values and prevent situations when the user is not satisfied with the received QoS for adaptive prediction of the moment of network reconfiguration. On the basis of a simulation model, it is proved that the proposed solutions can improve the quality of experience of multimedia services to end-users.","2022 IEEE 16th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering (TCSET)",2022.0,10.1109/tcset55632.2022.9767075,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
cec77c96ade4949df6a9e3f52715ea977ce1427c,https://www.semanticscholar.org/paper/cec77c96ade4949df6a9e3f52715ea977ce1427c,Real-Time Classification of Multimedia Traffic Using FPGA,"Real-time classification of Internet traffic according to application types is vital for network management and surveillance. Identifying emerging applications based on well-known port numbers is no longer reliable. While deep packet inspection (DPI) solutions can be accurate, they require constant updates of signatures and become infeasible for encrypted payload especially in multimedia applications (e.g. Skype). Statistical approaches based on machine learning have thus been considered more promising and robust to encryption, privacy, protocol obfuscation, etc. However, the computation complexity of traffic classification using those statistical solutions is high, which prevents them being deployed in systems that need to manage Internet traffic in real time. This paper proposes a FPGA-based parallel architecture to accelerate the statistical identification of multimedia applications while maintaining high classification accuracy. Specifically, we base our design on the k-Nearest Neighbors (k-NN) algorithm which has been shown to be one of the most accurate machine learning algorithms for Internet traffic classification. To enable high-rate data streaming for real-time classification, we adopt the locality sensitive hashing (LSH) for approximate k-NN. The LSH scheme is carefully designed to achieve high accuracy while being efficient for implementation on FPGA. Processing components in the architecture are optimized to realize high throughput. Extensive experiments and FPGA implementation results show that our design can achieve high accuracy above 99% for classifying three main categories of multimedia applications from Internet traffic while sustaining 80 Gbps throughput for minimum size (40 bytes) packets.",2010 International Conference on Field Programmable Logic and Applications,2010.0,10.1109/FPL.2010.22,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
89a4d90808238ea941af8e24d920fb6fc1b6f97a,https://www.semanticscholar.org/paper/89a4d90808238ea941af8e24d920fb6fc1b6f97a,Construction of an Artificial Intelligence Writing Model for English Based on Fusion Neural Network Model,"This paper presents an in-depth study and analysis of the model of English writing using artificial intelligence algorithms of neural networks. Based on word vectors, the unsupervised disambiguation, and clustering of multimedia contexts extracted from massive online videos, the disambiguation accuracy reaches over 0.7, and the resulting small-scale multimedia context set can cover up to 90% of vocabulary learning tasks; user experiments show that the multimedia context learning system based on this method can improve the effectiveness and experience of ESL vocabulary learning, as well as the long-term word sense memory of learners. The results are 30% better. Based on the dependency grammatical relations and semantic metrics of collocations on a large-scale professional corpus, we established a collocation intention description and retrieval method in line with users' linguistic cognition and doubled the usage rate of collocation retrieval on the actual deployment system after half a year, becoming a user “sticky” ESL writing aid, and further defined style. Dictionaries only provide basic lexical definitions, and, even if supported by example sentences, they still cannot meet the needs of ESL authors in terms of expressive accuracy and richness. However, the current machine translation is based on the black box deep neural network construction, and its translation process is not understandable and interactive. Among the three algorithmic models constructed in this paper, the multitask learning model outperforms the conditional random field model and the LSTM-CRF model because the multitask learning model with auxiliary tasks solves the problem of sparse data to a certain extent, allowing the model to be trained more adequately in the case of uneven label distribution, and thus performs better than other models in the task of grammatical error detection.",Computational intelligence and neuroscience,2022.0,10.1155/2022/1779131,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
69f91edaf5abc963a9b9b121d1f8bc851333e133,https://www.semanticscholar.org/paper/69f91edaf5abc963a9b9b121d1f8bc851333e133,Active Learning in the Era of Big Data,"Active learning methods automatically adapt data collection by selecting the most informative samples in order to accelerate machine learning. Because of this, real-world testing and comparing active learning algorithms requires collecting new datasets (adaptively), rather than simply applying algorithms to benchmark datasets, as is the norm in (passive) machine learning research. To facilitate the development, testing and deployment of active learning for real applications, we have built an open-source software system for large-scale active learning research and experimentation. The system, called NEXT, provides a unique platform for realworld, reproducible active learning research. This paper details the challenges of building the system and demonstrates its capabilities with several experiments. The results show how experimentation can help expose strengths and weaknesses of active learning algorithms, in sometimes unexpected and enlightening ways.",,2015.0,10.2172/1225849,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6af4abe9f3360b2817db4a655e1d3486754ba6b0,https://www.semanticscholar.org/paper/6af4abe9f3360b2817db4a655e1d3486754ba6b0,Large-scale learning for media understanding,,EURASIP J. Image Video Process.,2015.0,10.1186/S13640-015-0080-7,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
59da04a47e98fbbd5fcf43d573392d54abd5ed05,https://www.semanticscholar.org/paper/59da04a47e98fbbd5fcf43d573392d54abd5ed05,InfoNames : An Information-Based Naming Scheme for Multimedia Content,"RESEARCH INTERESTS Data management and its intersection with machine learning (an area popularly known as advanced analytics or data science), especially devising data managementinspired abstractions, systems, frameworks, and algorithms to make the end-to-end process of building and using machine learning algorithms for data analytics easier (improving the productivity of data scientists and developers) and faster (improving runtime performance and introducing accuracy trade-offs). My work spans the whole gamut of building systems, algorithm design, theoretical analysis, empirical analysis, and working with practitioners to deploy my research.",,2010.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
aa9d3c045e6197dad29907df9ed2787d4ca7dc3e,https://www.semanticscholar.org/paper/aa9d3c045e6197dad29907df9ed2787d4ca7dc3e,Location and Mobility-Aware Routing for Improving Multimedia Streaming Performance in MANETs,,Wirel. Pers. Commun.,2016.0,10.1007/s11277-015-3012-z,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
c59dc28f30409531bae0cd0b99969070ecd3ed01,https://www.semanticscholar.org/paper/c59dc28f30409531bae0cd0b99969070ecd3ed01,The Application of English Teaching Based on Cloud Network with Virtual Machine Technology,"The research and practice of virtual machine technology in English teaching is in its infancy, research involving the production and use of the teaching courseware, the use of existing educational software, and the use of computer networks classrooms, the campus network, the Internet and distance learning utility. These research and practice indicates the trend of the future development of foreign language teaching. This article focuses on the discusses of the popularity of cloud computing and virtual machine instruction, by introducing the technology of VMware virtualization to solve problems encountered in the process of teaching cloud computing, fully demonstrated the widely use of virtualization technology and its irreplaceable role . Introduction The development of information technology and computer applications has had a tremendous impact on foreign language teaching. Multimedia technology can be used to design a new process of teaching and interactive, personalized training methods , which tightly integrated English teachers’ teaching process and students learning process, and prompting the English teachers to generate new ideas in teaching, promoting the teaching process of fundamental change, prompting the students to change the traditional passive learning style [1,2]. This paper aims to present their views on the problems encountered in the promotion process and teaching process, through traditional and relatively mature virtualization technology to solve problems encountered in teaching ""cloud computing"" [3]. In fact, this is also a kind of cloud computing solutions, more specifically, an application of virtualization technology, a combination of virtualization technology and teaching application of cloud computing, a platform to promote cloud computing with VMware technology built. Advantage of virtual machine Convenient and safe use of a computer through the virtual machine to install more than one operating system to learn; portability of software test platform migration process; develop cross-platform system software for cross-platform testing. For example, mission-critical Windows and Linux-based [4,5] application development, virtual machines can take advantage of cross-platform development. The use of virtual machines in a computer at the same time enables multiple clients connected into a network, completely realistic simulated environment for testing or learning. Noting that virtualization is the logical representation of resource. Cloud computing introduction Although very young, cloud computing has become a broader application of technology, and various cloud emerging in the IT sector, some analysts believe that cloud computing represents a change in the way of enterprise computing. Expected that over the next five years, many giant manufacturers around the world, such as IBM, Dell, and Hewlett-Packard will transfer its own product line to cloud computing. With more and more enterprises turning to cloud computing, the traditional CPU chip chase higher performance, the pursuit of more large-scale supercomputers tirelessly to improve the performance of a single system industry development model will be slowly 2nd International Conference on Management Science and Industrial Engineering (MSIE 2013) © 2013. The authors Published by Atlantis Press 627 replacing. Cloud computing course, have great vitality and represent the future direction of development of the IT industry, on behalf of the people’s target in the IT industry, but this is also need to spread cloud computing in teaching which not only needs to implement a solid theoretical foundation for students, but also requires a combination of practice and more experimental, and a deep understanding of cloud computing. PM-LB algorithm for virtual machine deployment based on the performance of vector The study of deployment algorithm should fully considering the cloud computing’s multi-user and multi-service environment, the reason is that the system is based on a virtual machine hosted business whose dependence is different for different resources, mainly dependent on the performance of the virtual machine as a user preference for performance and making resource allocation is given adequate resources to reserve space, the side of the user is designed to obtain a better user experience, admittedly. When dealing with the virtual machine deployment, we need first to effectively monitor the performance of the virtual machines. For that the virtual machine hardware resources generally consist primarily of CPU performance, memory utilization, network connectivity and configuration state of the virtual machine on the host operating status, etc. Standardization of performance characteristics herein by reference Virtual Machine Manager 2008 technical report performance evaluation criteria for the physical servers , the four basic performance of the CPU, memory, substitution, and a hard disk , for example, per 10min to extract the average value of the condition of use , according to resource characteristics calculated under treatment:",,2013.0,10.2991/MSIE-13.2013.138,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
47f586d1c679d2a82807a140789c01c8c814f484,https://www.semanticscholar.org/paper/47f586d1c679d2a82807a140789c01c8c814f484,Anomaly Detection and Diagnosis for Container-Based Microservices with Performance Monitoring,,ICA3PP,2018.0,10.1007/978-3-030-05063-4_42,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
10bbc5556fe6b79b18bb986af5e601b7ac7ab114,https://www.semanticscholar.org/paper/10bbc5556fe6b79b18bb986af5e601b7ac7ab114,LTF: A Label Transformation Framework for Correcting Target Shift,"Distribution shift is a major obstacle to the deployment of current deep learning models on realworld problems. Let Y be the target (label) and X the predictors (features). We focus on one type of distribution shift, target shift, where the marginal distribution of the target variable PY changes but the conditional distribution PX|Y does not. Existing methods estimate the density ratio between the sourceand target-domain label distributions by density matching. However, these methods are either computationally infeasible for large-scale data or restricted to shift correction for discrete labels. In this paper, we propose an end-to-end Label Transformation Framework (LTF) for correcting target shift, which implicitly models the shift of PY and the conditional distribution PX|Y using neural networks. Thanks to the flexibility of deep networks, our framework can handle continuous, discrete, and even multidimensional labels in a unified way and is scalable to large data. Moreover, for high dimensional X , such as images, we find that the redundant information in X severely degrades the estimation accuracy. To remedy this issue, we propose to match the distribution implied by our generative model and the target-domain distribution in a low-dimensional feature space that discards information irrelevant to Y . Both theoretical and empirical studies demonstrate the superiority of our method over previous approaches. UBTECH Sydney AI Centre, School of Computer Science, Faculty of Engineering, The University of Sydney, Darlington, NSW 2008, Australia School of Mathematics and Statistics, The University of Melbourne Department of Philosophy, Carnegie Mellon University. Correspondence to: Jiaxian Guo <jguo5934@uni.sydney.edu.au>. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).",,2020.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ccb23f6e8a16883dc88132cf197a451b79f03778,https://www.semanticscholar.org/paper/ccb23f6e8a16883dc88132cf197a451b79f03778,Accelerator of Stacked Convolutional Independent Subspace Analysis for Deep Learning-Based Action Recognition,"Action recognition has been a research challenge in multimedia computing and machine vision. Recent advances in deep learning combined with stacked convolutional Independent Subspace Analysis (ISA) has achieved a better performance superior to all previously published results on several public available data sets. Unfortunately, one major issue in large-scale deployment of this new deep learning-based approach is the unacceptable latency of training with high-dimension data. In this paper, we propose a new hardware accelerator that can reduce the training time substantially for deep learning-based action recognition. Specifically, our proposed approach focuses on accelerating the convolutional stacked ISA algorithm, the core components of the deep learning-based action recognition algorithms. We design parallel pipelines, data parallelisms and look-up table to speed up the algorithm. With an embedded heterogeneous platform consisting of a general purpose processor and a FPGA, we are able to achieve up to 10X speedup for stacked ISA training compared to a software-only implementation.",2014 IEEE 22nd Annual International Symposium on Field-Programmable Custom Computing Machines,2014.0,10.1109/FCCM.2014.37,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6bdb186ec4726e00a8051119636d4df3b94043b5,https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5,Caffe: Convolutional Architecture for Fast Feature Embedding,"Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",ACM Multimedia,2014.0,10.1145/2647868.2654889,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6a2a534a9d01b76ecb5caba20032022a904cb50d,https://www.semanticscholar.org/paper/6a2a534a9d01b76ecb5caba20032022a904cb50d,COSMIC Semantic Segmentation Framework,"Deep space missions such as the Mars Reconnaissance Orbiter collect more data than can be sent back to Earth due to limited communications bandwidth. Machine learning algorithms can be deployed on board orbiters to prioritize the downlink of scientifically interesting images, such as those including fresh impact craters, recurring slope lineae, or dust devils. However, basic machine learning research is necessary to boost realworld performance, and numerous possible convolutional neural network architectures must be evaluated in terms of accuracy and compute requirements. A framework is designed to reduce redundant development, to standardize the algorithm testing process, and to allow developers to focus on the implementation details of novel machine learning algorithms. Three convolutional neural network implementations are included with the framework, pending use in future research. 1Content-based Onboard Summarization to Monitor Infrequent Change 2CL #18-465",,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ccf73e5ab695e9cf2c62f2b6cbef679ef888892a,https://www.semanticscholar.org/paper/ccf73e5ab695e9cf2c62f2b6cbef679ef888892a,DRAFT On Machine Perception of Sound Ph,"One of the desiderata in machine intelligence is that computers must be able to comprehend sounds as humans do. They must know about various sounds, associate them with physical objects, entities or events, be able to recognize and categorize them, know or discover relationships between them, etc. Successful solutions to these tasks is critical to and can have immediate effect on a variety of applications including content based indexing and retrieval of multimedia data on web which has grown exponentially in past few years. Automated machine understanding of sounds in specific forms such as speech, language and music has become fairly advanced, and has successfully been deployed into systems which are now part of daily life. However, the same cannot be said about natural occurring sounds in our environment. The problem is exacerbated by the sheer vastness of number of sound types, the diversity and variability of sound types, the variations in their structure, and even their interpretation. This dissertation aims to expand the scale and scope of machine hearing capabilities by addressing challenges in recognition of sound events, cataloging large number of potential word phrases that identify sounds and using them to categorize and learn relationships for sounds and by finding ways to efficiently evaluate trained models on large scale. On the sound event recognition front we address the major hindrance of lack of labeled data by describing ways to effectively use the vast amount of data on web. We describe methods for audio event detection which uses only weak labels in the learning process, combines weakly supervised learning with fully supervised learning to leverage labeled data in both forms and finally semi-supervised learning approaches which exploits the vast amount of available unlabeled data on web. Further, we describe methods to automatically mine sound related knowledge and relationships from vast amount of information stored in textual data. The third part once again addresses labeling challenges but now during evaluation phase. Evaluation of trained models on large scale once again requires data labeling. We describe ways to precisely estimate the performance of a trained model under restricted labeling budget. In this proposal we describe the completed works in the above directions. Empirical evaluation shows the effectiveness of the proposed methods. For each component framework described, we discuss expected research directions for successful completion of this dissertation. November 20, 2016 DRAFT",,2016.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a6c7b3c141f6c604e08fee902fa268665b8a4221,https://www.semanticscholar.org/paper/a6c7b3c141f6c604e08fee902fa268665b8a4221,Simple linear classifiers via discrete optimization: learning certifiably optimal scoring systems for decision-making and risk assessment,"Scoring systems are linear classification models that let users make quick predictions by adding, subtracting, and multiplying a few small numbers. These models are widely used in applications where humans have traditionally made decisions because they are easy to understand and validate. In spite of extensive deployment, many scoring systems are still built using ad hoc approaches that combine statistical techniques, heuristics, and expert judgement. Such approaches impose steep trade-offs with performance, making it difficult for practitioners to build scoring systems that will be used and accepted. In this dissertation, we present two new machine learning methods to learn scoring systems from data: Supersparse Linear Integer Models (SLIM) for decision-making applications; and Risk-calibrated Supersparse Linear Integer Models (RiskSLIM) for risk assessment applications. Both SLIM and RiskSLIM solve discrete optimization problems to learn scoring systems that are fully optimized for feature selection, small integer coefficients, and operational constraints. We formulate these problems as integer programming problems and develop specialized algorithms to recover certifiably optimal solutions with an integer programming solver. We illustrate the benefits of this approach by building scoring systems for realworld problems such as recidivism prediction, sleep apnea screening, ICU seizure prediction, and adult ADHD diagnosis. Our results show that a discrete optimization approach can learn simple models that perform well in comparison to the state-ofthe-art, but that are far easier to customize, understand, and validate. Thesis Supervisor: Cynthia Rudin Title: Associate Professor of Computer Science Duke University",,2017.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
01f3d1379049d2b1c5142dcc7ae2a7c8b79daa29,https://www.semanticscholar.org/paper/01f3d1379049d2b1c5142dcc7ae2a7c8b79daa29,Joint-based multi-task sparse learning for human action recognition,"Human action recognition from videos is a challenging computer vision task and it has wide applications, such as human robot/machine interaction, interactive entertainment, multimedia information retrieval, and surveillance. In this paper, we present a novel human action recognition method based on human joint position available video sequences. We use the joint-based covariance matrix over time as a discriminative descriptor for each human joint. Meanwhile, to encode the temporal information of the moving joints, multiple covariance matrices are deployed over sub-sequences that are different in temporal granularity. After that, we input the descriptor into multi-task sparse learning framework to obtain a more compact and discriminative action representation. The proposed method is evaluated on the sub-J-HMDB dataset. Experimental results show that the proposed method achieves a good performance and is superior to some state-of-the-art approaches.",ICIMCS '15,2015.0,10.1145/2808492.2808535,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
037942f8c07198db1e7f9afbb1a4580d66c3349a,https://www.semanticscholar.org/paper/037942f8c07198db1e7f9afbb1a4580d66c3349a,Introduction to the Special Section on Distance Metric Learning in Intelligent Systems,"Distance metric learning is an important machine-learning technique and has played a critical role in various tasks of real-world intelligent systems. Typically, any task that requires dissimilarity/similarity measures has to assume some forms of distance metrics or distance functions, either explicitly or implicitly. For example, Euclidean distance is widely used in many real-world applications, such as face recognition and automated image annotation. Many studies have shown that the choice of distance metrics could greatly affect the performance of tasks, making distance metric learning an important research topic. A large number of algorithms have been proposed and studied for distance metric learning. Numerous applications have been found for distance metric learning, including pattern recognition, natural language processing, computer vision, computer graphics, multimedia retrieval, web search and mining, bioinformatics, etc. For example, distance metric learning has been applied to boost the quality of data clustering, improve the accuracy of object recognition, and enhance the performance of image/video retrieval. Despite the extensive efforts, there are a number of important issues that need to be further explored and investigated when applying distance metric learning in real-world applications. This special Section presents high-quality articles that aim to advance the state-ofthe-art research on distance metric learning, with the focus on solving important and practical issues in deploying distance metric learning to intelligent systems in various domains. The selection of articles explore and develop practical distance metric learning techniques as a key component technology of an overall, perhaps large-scale, real-world intelligent system. The special Section not only addresses novel methodology and theory, but also emphasizes the innovative applications of distance metric learning techniques in real-world intelligent systems. In particular, this special Section received a total of 9 submissions, about half of which were invited from carefully selected papers accepted by top conferences. The editors managed the rigorous review tasks from this pool of good quality submissions, which involved 26 reviewers. Finally, three articles are accepted in this special Section. In the first article entitled “Multiview Metric Learning with Global Consistency and Local Smoothness”, Zhai et al. address a multiview metric learning problem where the same object could have different observations from multiview observation spaces. To handle the unique challenges arising from multiviewed data, the authors present a new distance-metric learning method in a semi-supervised learning setting that takes into account both global consistency and local smoothness. The basic idea is to reveal the shared latent feature space of the multiview observations by embodying global consistency constraints and preserving local geometric structures. An empirical evaluation on face alignment shows promising performance of the proposed method. In the second article entitled “Transfer Metric Learning with Semi-Supervised Extension”, Zhang and Yeung address a practical challenge of distance metric learning due to the insufficiency of labeled data. They propose a transfer learning technique that improves the learning of distance metric of a target task by exploiting the labeled data from the other tasks. A convex optimization formulation is presented to model the relationships among tasks in the form of a task covariance matrix. They further extend the proposed transfer metric learning to the semi-supervised learning setup in order to effectively explore the unlabeled data. The effectiveness of this method was validated on several applications.",TIST,2012.0,10.1145/2168752.2168766,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
eb0c64244dcf238a2cbf479ab2fdc9047fc80bc5,https://www.semanticscholar.org/paper/eb0c64244dcf238a2cbf479ab2fdc9047fc80bc5,Deep Hashing Network for Efficient Similarity Retrieval,"
 
 Due to the storage and retrieval efficiency, hashing has been widely deployed to approximate nearest neighbor search for large-scale multimedia retrieval. Supervised hashing, which improves the quality of hash coding by exploiting the semantic similarity on data pairs, has received increasing attention recently. For most existing supervised hashing methods for image retrieval, an image is first represented as a vector of hand-crafted or machine-learned features, followed by another separate quantization step that generates binary codes. However, suboptimal hash coding may be produced, because the quantization error is not statistically minimized and the feature representation is not optimally compatible with the binary coding. In this paper, we propose a novel Deep Hashing Network (DHN) architecture for supervised hashing, in which we jointly learn good image representation tailored to hash coding and formally control the quantization error. The DHN model constitutes four key components: (1) a sub-network with multiple convolution-pooling layers to capture image representations; (2) a fully-connected hashing layer to generate compact binary hash codes; (3) a pairwise cross-entropy loss layer for similarity-preserving learning; and (4) a pairwise quantization loss for controlling hashing quality. Extensive experiments on standard image retrieval datasets show the proposed DHN model yields substantial boosts over latest state-of-the-art hashing methods.
 
",AAAI,2016.0,10.1609/aaai.v30i1.10235,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
5901e5d1b4fad2a770d18043a390bb0ae6783a55,https://www.semanticscholar.org/paper/5901e5d1b4fad2a770d18043a390bb0ae6783a55,A Review on 6G Wireless Communication Systems: Localization and Sensing,"The demand for multimedia data services has grown up rapidly over the years. Fifth generation (5G) wireless communication which has been deployed in a lot of countries will not be able to meet up with users demand based on the estimated mobile traffic volume of users in the next few years. Therefore, the sixth generation (6G) communication has been proposed to address the constraints/limitations of 5G communication. 6G systems will operate in the millimeter wave (mmWave) and terahertz region which has larger bandwidth and offers higher data rate than 5G systems. 6G has a lot of opportunities like high-definition imaging, frequency spectroscopy, accurate localization and sensing, which is the main focus of this work. There are a lot of opportunities for sensing at higher frequencies because of fine resolution in all physical dimensions (range, Doppler and angle). Moreover, localization and sensing in 6G is made possible by the key enablers technologies which are: the use of new radio band for communication, intelligent beam-space incorporation of intelligent surfaces, artificial intelligence and machine learning methods. In the new proposed 6G system, it is necessary for localization, sensing and communication to coexist, sharing the same time-frequency-spatial resources. In other to enable sharing, cooperation, coexistence and co-design, various mechanisms and approaches are needed in 6G communication systems.",2021 1st International Conference on Multidisciplinary Engineering and Applied Science (ICMEAS),2021.0,10.1109/ICMEAS52683.2021.9692415,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
b2ebc8c0664d5df2e388b9be9ad2d479e8c34832,https://www.semanticscholar.org/paper/b2ebc8c0664d5df2e388b9be9ad2d479e8c34832,Simplifying Programming for Non-technical Students: A Hermeneutic Approach,,Künstliche Intell.,2022.0,10.1007/s13218-021-00748-0,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
2ff58257d18a2cfc43417df163c3222e0e2943f2,https://www.semanticscholar.org/paper/2ff58257d18a2cfc43417df163c3222e0e2943f2,IMS2020 Microwave Week Workshops,": This workshop showcases intelligent mixed-signal, RF/mm-wave, and microwave photonics systems that exploit machine learning and AI techniques in three focused application areas: advanced wireless communication, sensing, and computation. With an emphasis on wireless communication, the workshop explores machine-learning and AI techniques for RF signal conditioning, dynamic wireless-spectrum collaboration, wireless PA linearization, and massive MIMO– mm-wave phased-array beamforming. With a focus on sensing and imaging applications, the workshop presents machine-learning–based radar signal-processing techniques for autonomous navigation and their implementation in integrated frequency-modulated continuous-wave radar systems. Regarding computation, the workshop combines mixed-signal, RF/mm-wave, and microwave-photonics circuit techniques to accelerate energy-efficient, multidimensional signal processing for machine-learning and AI algorithms. In addition, the workshop discusses several applications of photonic deep-learning hardware accelerators in wireless communication, such as RF fingerprinting. Abstract: Advances in mm-wave CMOS technology have resulted in fully integrated mm-wave radar sensors that offer a cost-effective and robust solution to automotive safety, provide accurate industrial sensing, and enable gesture recognition. This workshop features technical experts from academia and industry who present the state of the art in mm-wave CMOS technology, such as all-digital architectures, higher carrier frequencies, advanced signal processing, and machine learning. These technologies promise to improve the achievable accuracy and push performance levels further. The speakers will also share their view of the Abstract: Coherent detection, where the optical carrier’s phase information provides higher signal-to-noise ratios, has ever-increasing momentum. Today, coherent communication dominates long-haul networks operating with data rates beyond 400 Gb/s per wavelength. Thanks to advancements in digital signal processing that leverage ultralow-power implementations in deep submicron technologies (for instance, 7 nm), the cost and power of coherent transponders are becoming competitive for short-reach networks (inter- and intra-data centers). Reducing the cost and enhancing the overall performance of such networks is only achievable through highly integrated solutions that encompass complex digital signal-processing algorithms, state-of-the-art transimpedance amplifiers and modulator drivers, and integrated silicon photonics. Codesign and co-optimization become the key factors in further scaling the power and performance of coherent transponders. They will be the focus of this workshop and addressed by several speakers from different backgrounds. Abstract: Quantum computing has spurred intense research to develop electronics to control quantum devices operating at cryogenic temperatures. Several applications beyond quantum computing require cryogenic electronics to be compatible with very low ambient temperatures or outperform their room-temperature counterparts. This workshop presents an overview of cryogenic electronics, from applications to device operation, focusing on ICs. Applications that must operate at cryogenic temperatures, such as quantum computing (first talk) and particle physics (second talk), will be presented to highlight requirements, current limitations, and future perspectives. The operation of silicon-germanium (SiGe) (third talk) and CMOS (fourth talk) at cryogenic temperatures will be discussed, and four examples of ICs that employ SiGe, bulk CMOS, and fully depleted silicon-on-insulator (SOI) CMOS and target low-noise Abstract: Low-noise amplifiers (LNAs), PAs, switches, and phase shifters can be integrated into one silicon RF front-end (RFFE) IC for mm-wave 5G, and multichannel integration is likely; however, the cost, robustness, and manufacturability advantages of the all-silicon RFFE IC approach are not clear compared to hybrid III-V/ silicon alternatives. mm-Wave 5G broadband PA power efficiency is considerably lower than for 4G equipment. Gallium-nitride (GaN)/ gallium-arsenide (GaAs) III-V–based PAs have a higher output power than silicon-based PAs and good efficiency, but the cost of hybrid-integration approaches rapidly increases with complexity, as will be covered in this workshop. mm-Wave PA linearity versus power-added efficiency at power backoff is always a design tradeoff, and novel RF linearization techniques are required to improve 5G mm-wave PAs. All-silicon solutions with superstrates for antennas will be investigated, and we will discuss the PA antenna and package codesign for 5G MIMO PAs. Design: Basics Abstract: This workshop by phased-array experts in academia and industry provides an in-depth learning experience and walks attendees through different aspects of mm-wave phased-array transceiver design. It covers the following topics: 1) silicon-based mm-wave phased-array basics; 2) phase- and gain-control circuits; 3) package, antenna, and module codesign and calibration; 4) phased-array measurements on-chip and over the air; 5) phased-array applications in commercial and defense systems; and 6) current 5G New Radio phased-array systems and limitations and an outlook Abstract: 5G communication in sub-6-GHz frequencies offers enhanced data rates, capacity, and flexibility but faces challenges, such as energy efficiency, linearity, integration, and scalability. To increase battery life, optimizing PA efficiency is of the utmost importance. This workshop investigates digitally intensive transmit architectures and predistortion techniques that enhance the efficiency of the transmitters and PAs used in these next-generation wireless systems. Experts from industry and academia will share their latest research on linearization techniques to build highly efficient linear PAs in various technologies, employing topologies such as Doherty, out-phasing, and polar. Circuit topologies and digital signal-processing algorithms for the predistortion of these PAs will also be covered. Abstract: 5G will be key to meeting an order-of-magnitude increase in the data-traffic demand on mobile networks. 5G massive MIMO technology will deliver high data rates to many users, helping to increase capacity. It will support real-time multimedia services and reduce energy consumption by targeting signals to individual users through digital beamforming. Element-level digital beamforming that supports emerging multibeam communications and directional sensing at the mm-wave frequency range will expand the use of mm-wave phased arrays and make them broadly applicable across U.S. Department of Defense systems. This workshop presents state-of-the-art radio circuits and systems exploiting MIMO and digital beamforming at sub-6-GHz and mm-wave bands for civilian 5G New Radio and defense applications. Abstract: Indoor positioning and localization will be critical to the next-generation Internet of Things (IoT). The technology obtains the location of a device or user in an indoor environment, which is a key function enabling various IoT applications, such as smart buildings, distance-bounded security, smart industrial applications, and so forth. In this workshop, several popular smartphone-based wireless technologies for locating people and objects will be discussed. Bluetooth Low Energy (BLE), ultrawideband (UWB), and WiFi are three popular standards-compliant localization approaches. BLE is the most widely adopted smartphone-based wireless protocol, so BLE-based localization has an advantage in densely deployed infrastructure. UWB is an emerging wireless-localization technology that is used in advanced smartphones (for example, the iPhone 11). The new UWB protocol, IEEE 802.15.4z, can provide centimeter-level accuracy thanks to its wide spectrum. Finally, WiFi, as a wireless technology deployed in most buildings, will play an important role in accurate positioning with the upcoming IEEE 802.11az protocol. Abstract: This vertically oriented workshop provides technical know-how, from the satellite to the device, by bringing together commercial and defense leaders in space hardware. It reviews satellite orbits and the demands on antenna systems and also provides a detailed overview of CubeSats and the drive for small-form-factor, high-reliability electronics, followed by a comprehensive examination of the market and challenges for satellite-communication terminals. The workshop covers RFICs for space in CMOS and III-V technology, including a special discussion of advanced, very-low-power CMOS for deep-space sensors. A technical review of radiation types and their effects on CMOS and the techniques to successfully design in space using a radiation-hard library or next-generation radiation-hard process on advanced bulk CMOS is offered. This is a great place for new and experienced engineers to learn about the adventure of space. Abstract: PAs do not fulfill all the requirements of linearity, energy efficiency, and bandwidth necessary for New Radio and mm-wave 5G operation and future communications, particularly in user equipment. New techniques are required to design ultrahigh-linearity PAs and yield improved linearization, efficiency enhancements, and bandwidth-extension methods to dramatically improve performance. All aspects of New Radio and mm-wave PA design become more challenging when equipment is placed in arrays with non-negligible element-to-element coupling. This workshop explores PA designs in the mm-wave spectrum as well as linearization techniques (digital predistortion, outphasing, envelope tracking, and so forth) and efficiency enhancements (load and supply modulation and so on) in user equipment and base stations. Abstract: In emerging 5G cellular communication and other mm-wave systems, the generation, distribution, and synchronization of local-oscillator (LO) signals remain a challenge. This ",IEEE Microwave Magazine,2020.0,10.1109/mmm.2020.2971397,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
fc8e777975e6744cab5f149cf4d46ff4ce6d2118,https://www.semanticscholar.org/paper/fc8e777975e6744cab5f149cf4d46ff4ce6d2118,The Metamorphosis (of RAM3S),"The real-time analysis of Big Data streams is a terrific resource for transforming data into value. For this, Big Data technologies for smart processing of massive data streams are available, but the facilities they offer are often too raw to be effectively exploited by analysts. RAM3S (Real-time Analysis of Massive MultiMedia Streams) is a framework that acts as a middleware software layer between multimedia stream analysis techniques and Big Data streaming platforms, so as to facilitate the implementation of the former on top of the latter. RAM3S has been proven helpful in simplifying the deployment of non-parallel techniques to streaming platforms, such as Apache Storm or Apache Flink. In this paper, we show how RAM3S has been updated to incorporate novel stream processing platforms, such as Apache Samza, and to be able to communicate with different message brokers, such as Apache Kafka. Abstracting from the message broker also provides us with the ability to pipeline several RAM3S instances that can, therefore, perform different processing tasks. This represents a richer model for stream analysis with respect to the one already available in the original RAM3S version. The generality of this new RAM3S version is demonstrated through experiments conducted on three different multimedia applications, proving that RAM3S is a formidable asset for enabling efficient and effective Data Mining and Machine Learning on multimedia data streams.",Applied Sciences,2021.0,10.3390/app112411584,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
bdf7d11a90fad58a5803a0aaf0c2e7cd5d87ad39,https://www.semanticscholar.org/paper/bdf7d11a90fad58a5803a0aaf0c2e7cd5d87ad39,A Deep Neural Network-Based Multi-Label Classifier for SLA Violation Prediction in a Latency Sensitive NFV Application,"Recent advancements in the domain of Network Function Virtualization (NFV), and rollout of next-generation networks have necessitated the requirement for the upkeep of latency-critical application architectures in future networks and communications. While Cloud service providers recognize the evolving mission-critical requirements in latency sensitive verticals such as autonomous driving, multimedia, gaming, telecommunications, and virtual reality, there is a wide gap to bridge the Quality of Service (QoS) constraints for the end-user experience. Most latency-critical services are over-provisioned on all fronts to offer reliability, which is inefficient towards scalability in the long run. To address this, we propose a strategy to model frequent violations on the application level as a multi-output target to enable more complex decision-making in the management of virtualised communication networks. In this work, we utilize data from a real-world deployment to configure and draft a realistic set of Service Level Objectives (SLOs) for a voice based NFV application, and develop a deep neural network based multi-label classification methodology to identify and predict multiple categories of SLO breaches associated with an application state. With this, we aim to gain granular SLA and SLO violation insights, enabling us to study and mitigate their impact and inform precision in drafting proactive scaling policies. We further compare the performance against a set of multi-label compatible machine learning classifiers, and address class imbalance in a multi-label setup. We perform a comprehensive evaluation to assess the performance on example-based, label-based and ranking-based measures, and demonstrate the suitability of deep learning in such a use-case.",IEEE Open Journal of the Communications Society,2021.0,10.1109/ojcoms.2021.3122844,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
4ba2880b228996ce93de17e87fbc0adfd1843fd6,https://www.semanticscholar.org/paper/4ba2880b228996ce93de17e87fbc0adfd1843fd6,HEAP: A Heterogeneous Approximate Floating-Point Multiplier for Error Tolerant Applications,"Floating point arithmetic is one of the most commonly used units in nowadays computing systems and is deployed for a wide range of domains and applications. While floating point operators offer high precision calculations, a plethora of applications such as multimedia processing and machine learning tolerate errors and computation imprecision. In a context of limited power budget embedded systems, saving resources and energy with an acceptable precision loss is a challenging design task. Approximate computing is an emerging systems design paradigm that offers promising balance between accuracy on the one hand and power consumption and resource utilization on the other hand. While state of the art approximate techniques offer a wide design space at the operator level, few are the works that consider exploring different techniques to build a heterogeneous comprehensive approximate design. In this paper, we propose HEAP: a heterogeneous approximate floating point multiplier. Based on a design space exploration process, we present an approximation at the transistor level that reduces energy consumption of up to 68%. Experimental study on a set of machine learning applications shows promising results with comparable accuracy to exact multiplier based systems.",RSP,2019.0,10.1145/3339985.3358495,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
51ca4adbcbef0dc12087c774df403caaeed4f237,https://www.semanticscholar.org/paper/51ca4adbcbef0dc12087c774df403caaeed4f237,Towards Black-Box Anomaly Detection in Virtual Network Functions,"The maturity of hardware virtualization has motivated communication service providers to apply this paradigm to network services. Virtual Network Functions (VNFs) come from this motivation and refer to any virtual execution environment configured to provide a given network service. VNFs constitute a new paradigm and related dependability evaluation mechanisms are still not thoroughly defined. In this paper we propose a preliminary evaluation of an anomaly detection approach applied to VNFs. Our approach uses a supervised machine learning algorithm. It notably relies on data provided by the underlying hypervisor of the VMs hosting the VNF, making it a black-box approach. Such an approach is actually well suited for infrastructure or telecommunication service providers willing to deploy tools that are easily configurable while reducing deployment costs. We validate our approach with the case study of the vIMS (IP Multimedia Subsystem) implemented by the Clearwater project.",2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshop (DSN-W),2016.0,10.1109/DSN-W.2016.17,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
5cb3baa1c13caf1d0a58da42639e4730bffd9579,https://www.semanticscholar.org/paper/5cb3baa1c13caf1d0a58da42639e4730bffd9579,Building a Sextbot : botrotica,"In this paper, I reflect on the the development and deployment botrotica—a situated, site-specific art installation and coding machine learning experiment for public interaction. The system, botrotica is a sextbot—a chat bot that is inspired by the explicit messages that we send to each other. This sextbot is an exploration in sexting developed for futuresmut, the 10th annual Smut Cabaret at Nextfest 2017, an emerging artist festival in Edmonton, Alberta, Canada. This project serves is case study on the incorporation of machine learning technology in interactive multimedia art installations. 1 How did we get here? The Internet enables us to explore our identities and develop ourselves through social communication. New technologies continue to change the way we interact with one another. How do we share ourselves publicly and privately? Who do we share ourselves with and what exactly are we sharing? We create ourselves by how we interact with each other, and as Marshall McLuhan would say, “the medium is the message [9]”. Modern artists often remind us of how these systems developed to connect us can drive us apart, transforming social media into antisocial forces [3]. Thoughts, ideas, pictures, sounds, and videos can be exchanged publicly and privately with passion partners. Sexting— the portmanteau of sex and texting added to the Merriam-Webster’s Collegiate Dictionary in August 2012—is the sending of sexually explicit messages or images by cell phone. The popularization of this technology has led to the emergence of a field of psycho-social research. Rather than increasing intimacy in these types of relationships, sexting may act as a buffer for physical intimacy and may be associated with risky behaviour in teens and young adults [1, 7]. Sexting has also been linked to sexual objectification [2]. This artistic installation uses botrotica to challenge questions of sexual communication, objectification, instigation, and artificial companionship. This work is inspired by the work of Sherry Turkle in “Alone Together” [10], and software: My Virtual Boyfriend [6] and SELF [5]. 2 What is botrotica? botrotica is a disembodied site-specific installation. It is situated abstractly behind a phone number. Willing and consensual participants only need access to a mobile phone for interaction. This interactive cyber-installation piece was turned-on for the duration of the futuresmut cabaret evening event. When participants texted the number they engaged the sextbot in a back-and-forth interaction which included rule-based preset dialog and short utterances generated from a deep neural network model trained on a large collection of online erotica. In addition to conversational dialogue, several action hooks into machine learning (ML) systems could be triggered to classify objects, faces, details, emotions, and not-safe-for-work (NSFW) predictions in images. This multimodal interaction was designed for ongoing engagement over the course of a cabaret evening. The system is designed to respond in a way that a late-night human sexter might. It has a slightly coy and dirty persona, asks for photos, and, if requested of, sends photos of web-scraped, human 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. curated, sexy robots. If the user sent an image to the bot, then it would attempt to classify the objects in the image and send back the resulting predictions. This notion of ‘self-objectification’ has been re-interpreted, under the lens of post-feminist media culture, not as oppressive but as constituting a prime site of sexual liberation, value and pleasure [4]. botrotica would also classify potentially NSFW content with a likelihood probability. This probability was reinterpreted as a rating of the image, and images would be scored according to this rating. Images that scored higher would be then ranked on a leader board. The implied scoring metric was that the most NSFW image would be at the top of the leader board. For example, in response to an image (excluded), botrotica rather astutely responded: “73.42% explicit nudity. 37.27% graphic male nudity. I see a beautiful face. I am 70.0% sure. You look CONFUSED and a little bit CALM. I would guess you are somewhere between 35 and 52. Looks like a 2 dressed up as a 8. . . I see people, person, human, tattoo. . . ” During the evening, physical advertising was employed to attract users. Business cards scattered around the venue were embossed with the phone number and the words. . . helloworld–an homage to the traditional computer program used to introduce novices to a new language or toolset. A stack of cards sat on a lonely table, behind which sat a single flower and a TV/VCR combination playing looped 1980’s advertisements for adult phone lines with this phone number dubbed over top (See Fig. 1. There was a pre-recorded message for those who called the associated number which prompted the human to leave a voice message and then send an SMS for a faster response. botrotica is a micro-service backend and Twilio-backed voice and text interface frontend. Written in Python (Flask), then Dockerized, it runs on an Amazon p2.xlarge EC2 server and hooks via HTTP requests to Amazon ML Rekognition image analysis API. A trained Tensorflow character-level recurrent neural network (RNN) model ran on the server, performing live inference upon receiving HTTP requests. The model used a 3 layer, 512 unit long-short term memory (LSTM) architecture. The model is trained on a large collection of erotic fiction scraped from the internet. The system also included several curated response lists. A set of 200 of the sexiest sexts curated by a domain expert, and additional pre-defined lists included 10 requests each for ‘dreams’, ‘secrets’, ‘pictures’, as these are some of the most common themes in sexting. Lines from these sources were queried by an information retrieval model based on n-gram similarity. Due to the sensitive nature of the data, it was deleted immediately following deployment with no post-processing. The goal of the system was not systematic comparison of interactions engagement metrics, but rather it served as an art installation designed to challenge the users. The system had respectable popularity and interaction over the 5.5 hour event handling 847 messages (731 SMS + 136 MMS), most interactions were longer than 4 turns. There were 64 minutes of recorded voice messages from 144 voice calls to the number. Interactions varied from innocent banter to exchanging explicit images and dirty talk, between human and agent. 3 Eroticism in the age of AI botrotica serves as an interesting window into the world of sext messaging—only a small piece of possible erotic interaction with artificial intelligence. It illuminated how popular simple chat interactions can be if prepared, produced, developed, and deployed appropriately and in interesting ways. This project inspires many future research directions, including photo scavenger hunts, collaborative photo classification and interactive live-streaming. Future interactions might involve rooms full of interlocutors (some human, some not) in collective communication by embracing an online chatroom dynamic. What we share online changes as new technology is introduced. How and what we share on one social channel is different from how we share on another. We often build channels through which we communicate with scripted, humorous, pseudoembodiments in video games and online chatbots. Perhaps these ‘pretend’ channels are not ‘obscene’ or as chatbot pioneer Weizenbaum believed [11]. This installation addresses the obscenity through transparency, and by granting explicit agency the user, hence making it not obscene. By openly communicating about ourselves, we become the media and the message. The content and the way we share information differs if it is a human or machine listening; virtual humans immediately offer two appealing features: anonymity and rapport [8]. How we share our lusts, thoughts, fears, desires, emotions, judgments, interests, hopes, dreams and memories makes us who we are. Hopefully, art-project-cum-coding-experiments like this continue to challenge our own identities and how we present ourselves online.",,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
bfb0dff0ab9a66693e7ef6c972a5d5465f05e030,https://www.semanticscholar.org/paper/bfb0dff0ab9a66693e7ef6c972a5d5465f05e030,""" Face to Face "" Project Summary an Interactive Language Learning Model on the Internet","Computing technology has been brought to bear on many aspects of the second language learning process. Computer programs have been built that help students with pronunciation, vocabulary, grammar, reading, and writing. However most of these programs lack very robust facilities for interactive learning. They do not support practice in using this knowledge in the communication process. Even though the communicative approach has been dominant in language teaching for two decades, there is no interactive multimedia learning tool available right now that helps students effectively learn the four major communicative skills, namely, speaking, listening, reading, and writing. Such software has not been developed, we believe, because the needed collaboration of expertise in machine-learning and language instruction has not developed. We propose a computer software system supporting instruction in Mandarin which incorporates techniques from machine learning and computational linguistics, as well as language pedagogy. Its purpose will be to mimic situations a learner might face if placed in a Mandarin-speaking environment with a communication problem to solve, such as buying vegetables or obtaining directions. It will richly model the target language environment and hence simulate those experiences that are known to be most important in making progress in second language learning, namely, the ability to interact flexibly with an informationally rich environment. Although the proposed web-based program is directed most immediately to teaching Mandarin and will initially be correlated to a specific popular language Mandarin text that is used by 212 colleges and universities in the US., the techniques from the traditions in artificial intelligence, machine learning and computational linguistics that is uses are generic and can be brought to bear on the second language learning of any language. Indeed, the modular approach to be followed in this project, which separates formal representation of knowledge, semantics, pragmatics and syntax, entail that many components can be deployed the languages other than Mandarin without modification. Since we intend to publish our results in a vigorous way to the communities outside Computer Scie nce, we hope that have a broad general influence on second language learning. 1. Introduction We propose a theoretical and technological framework for designing and developing an interactive language learning model based on current language learning theories [DOB96], existing technology and established techniques in Artificial Intelligence and Machine Learning. More particularly, we propose to augment an existing prototype, Face-to-Face, a computer aided instruction software system supporting instruction in Mandarin for adult learners …",,,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6e05fd932172d0e590d1906724de6db6c81efa4e,https://www.semanticscholar.org/paper/6e05fd932172d0e590d1906724de6db6c81efa4e,Open Source Remote Triggered Laboratory for Web based Manufacturing-A Case Study of 2D Plotter,"The recent advances in information and telecommunication technologies based on multimedia and global network will lead to innovations in the field of engineering especially in the machinery and mechanical engineering. The need for systems or machines, which can be accessed via internet and these technological advancements have resulted in the evolution of web-based manufacturing, which can be accessed through the remote environment. The appearance of ‘Remote laboratory’ reflects the development of e-learning. Access to e-learning resources is becoming easy via the internet and electronic media, which increases its flexibility in time, location and content. Once published on the internet, anyone on the web with the proper authentication can access and control the experiments. Remote laboratories will usually consist of a group of measuring instruments, encoders, and actuators connected to the internet through appropriate network equipment. Remote laboratories will allow students to access the set of experiments without any time and location restrictions. This paper focuses on the remotely operated open source laboratory for a student through web based manufacturing by taking 2D Sketcher as a case study. A student can deploy the codes on the web by which the machine will be accessed and live feed of the machine can be viewed by the students on their location.","2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",2020.0,10.1109/ICECA49313.2020.9297410,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,https://www.semanticscholar.org/paper/8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,Multi Uav Cooperative Surveillance With Spatio Temporal,"Deep Learning for Unmanned SystemsMultiple Heterogeneous Unmanned Aerial VehiclesAdvanced Mobile RoboticsSafe Robot Navigation Among Moving and Steady ObstaclesComputer Safety, Reliability, and SecurityAdvances in Swarm IntelligenceHolonic and Multi-Agent Systems for ManufacturingAdvances in Artificial Intelligence and Applied Cognitive ComputingUnmanned Aircraft SystemsIntelligent Computing Theories and ApplicationAutonomous Airborne Wireless NetworksAd Hoc NetworksEnabling Blockchain Technology for Secure Networking and CommunicationsUAV Sensors for Environmental MonitoringUnmanned Aerial Vehicles: Breakthroughs in Research and PracticeComputational Collective IntelligenceTime-Critical Cooperative Control of Autonomous Air VehiclesAdvances in Cooperative Control and OptimizationCooperative Robots and Sensor Networks 2015Artificial Intelligence and SecurityPRICAI 2016: Trends in Artificial IntelligenceClosing the Gap Between Research and Field Applications for Multi-UAV Cooperative MissionsMulti-rotor Platform Based UAV SystemsProceedings of the Future Technologies Conference (FTC) 2020, Volume 1Unmanned Aerial SystemsAdvanced Distributed Consensus for Multiagent SystemsCooperative Control of MultiAgent SystemsMulti-UAV Planning and Task AllocationMobile Internet SecurityCooperative Control of Multiple Unmanned Aerial Vehicles with Application to Forest Fire Detection and FightingMulti UAV Systems with Motion and Communication ConstraintsIntelligent Autonomy of UAVsIntelligent and Fuzzy Techniques in Big Data Analytics and Decision MakingIntelligent Autonomy of UAVsUAV Cooperative Decision and ControlCooperative Localization and NavigationAdvances in Guidance, Navigation and ControlMachine Learning and Intelligent CommunicationsUnmanned Aerial VehiclesThe Cognitive Approach in Cloud Computing and Internet of Things Technologies for Surveillance Tracking Systems Ad hoc networks, which include a variety of autonomous networks for specific purposes, promise a broad range of civilian, commercial, and military applications. These networks were originally envisioned as collections of autonomous mobile or stationary nodes that dynamically auto-configure themselves into a wireless network without relying on any existing network infrastructure or centralized administration. With the significant advances in the last decade, the concept of ad hoc networks now covers an even broader scope, referring to the many types of autonomous wireless networks designed and deployed for a specific task or function, such as wireless sensor networks, vehicular networks, home networks, and so on. In contrast to the traditional wireless networking paradigm, such networks are all characterized by sporadic connections, highly error-prone communications, distributed autonomous operation, and fragile multi-hop relay paths. The new wireless networking paradigm necessitates reexamination of many established concepts and protocols, and calls for developing a new understanding of fundamental problems such as interference, mobility, connectivity, capacity, and security, among others. While it is essential to advance theoretical research on fundamental and practical research on efficient policies, algorithms and protocols, it is also critical to develop useful applications, experimental prototypes, and real-world deployments to achieve an immediate impact on society for the success of this wireless networking paradigm.A comprehensive review of the state of the art in the control of multi-agent systems theory and applications The superiority of multi-agent systems over single agents for the control of unmanned air, water and ground vehicles has been clearly demonstrated in a wide range of application areas. Their large-scale spatial distribution, robustness, high scalability and low cost enable multi-agent systems to achieve tasks that could not successfully be performed by even the most sophisticated single agent systems. Cooperative Control of Multi-Agent Systems: Theory and Applications provides a wide-ranging review of the latest developments in the cooperative control of multi-agent systems theory and applications. The applications described are mainly in the areas of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Throughout, the authors link basic theory to multi-agent cooperative control practice — illustrated within the context of highly-realistic scenarios of high-level missions — without losing site of the mathematical background needed to provide performance guarantees under general working conditions. Many of the problems and solutions considered involve combinations of both types of vehicles. Topics explored include target assignment, target tracking, consensus, stochastic game theory-based framework, event-triggered control, topology design and identification, coordination under uncertainty and coverage control. Establishes a bridge between fundamental cooperative control theory and specific problems of interest in a wide range of applications areas Includes example applications from the fields of space exploration, radiation shielding, site clearance, tracking/classification, surveillance, search-and-rescue and more Features detailed presentations of specific algorithms and application frameworks with relevant commercial and military applications Provides a comprehensive look at the latest developments in this rapidly evolving field, while offering informed speculation on future directions for collective control systems The use of multi-agent system technologies in both everyday commercial use and national defense is certain to increase tremendously in the years ahead, making this book a valuable resource for researchers, engineers, and applied mathematicians working in systems and controls, as well as advanced undergraduates and graduate students interested in those areas.Time-Critical Cooperative Control of Autonomous Air Vehicles presents, in an easy-to-read style, the latest research conducted in the industry, while also introducing a set of novel ideas that illuminate a new approach to problem-solving. The book is virtually self-contained, giving the reader a complete, integrated presentation of the different concepts, mathematical tools, and control solutions needed to tackle and solve a number of problems concerning time-critical cooperative control of UAVs. By including case studies of fixed-wing and multirotor UAVs, the book effectively broadens the scope of application of the methodologies developed. This theoretical presentation is complemented with the results of flight tests with real UAVs, and is an ideal reference for researchers and practitioners from academia, research labs, commercial companies, government workers, and those in the international aerospace industry. Addresses important topics related to time-critical cooperative control of UAVs Describes solutions to the problems rooted in solid dynamical systems theory Applies the solutions developed to fixed-wing and multirotor UAVs Includes the results of field tests with both classes of UAVsThis book provides the state-of-the-art intelligent methods and techniques for solving realworld problems along with a vision of the future research. The fifth 2020 Future Technologies Conference was organized virtually and received a total of 590 submissions from academic pioneering researchers, scientists, industrial engineers, and students from all over the world. The submitted papers covered a wide range of important topics including but not limited to computing, electronics, artificial intelligence, robotics, security and communications and their applications to the real world. After a double-blind peer review process, 210 submissions (including 6 poster papers) have been selected to be included in these proceedings. One of the meaningful and valuable dimensions of this conference is the way it brings together a large group of technology geniuses in one venue to not only present breakthrough research in future technologies, but also to promote discussions and debate of relevant issues, challenges, opportunities and research findings. The authors hope that readers find the book interesting, exciting and inspiringAdvanced Distributed Consensus for Multiagent Systems contributes to the further development of advanced distributed consensus methods for different classes of multiagent methods. The book expands the field of coordinated multiagent dynamic systems, including discussions on swarms, multi-vehicle and swarm robotics. In addition, it addresses advanced distributed methods for the important topic of multiagent systems, with a goal of providing a high-level treatment of consensus to different versions while preserving systematic analysis of the material and providing an accounting to math development in a unified way. This book is suitable for graduate courses in electrical, mechanical and computer science departments. Consensus control in multiagent systems is becoming increasingly popular among researchers due to its applicability in analyzing and designing coordination behaviors among agents in multiagent frameworks. Multiagent systems have been a fascinating subject amongst researchers as their practical applications span multiple fields ranging from robotics, control theory, systems biology, evolutionary biology, power systems, social and political systems to mention a few. Gathers together the theoretical preliminaries and fundamental issues related to multiagent systems and controls Provides coherent results on adopting a multiagent framework for critically examining problems in smart microgrid systems Presents advanced analysis of multiagent systems under cyberphysical attacks and develops resilient control strategies to guarantee safe operationComplete with online files and updates, this cutting-edge text looks at the next generation of unmanned flying machines. Aerial robots can be considered as an evolution of the Unmanned Aerial Vehicl",,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0e4301537519a6f57d3ae03264f0c8c23ecf5577,https://www.semanticscholar.org/paper/0e4301537519a6f57d3ae03264f0c8c23ecf5577,The Application of Rich Media Technology in Digital Learning Terminal,"At present, digital learning terminal has larger impact on people's lives and students learning, and is likely to become more mature in a short period of time in the future. New digital terminal is built on the basis of reading. It is a dedicated terminal which is interactive, relevance, openness and has rich media features. It can help students to start meaningful learning. [1] Through the application and analysis of rich media and rich Internet and compared with multimedia technology features and digital terminal learning research, rich media and rich Internet technology can explore the terminals of digital learning, create a new type of digital learning environment, and further help and improve students' learning enthusiasm and initiative. In people's life and learning, electronic products such as smart phones and tablet computers are widely used as terminal equipment. Gradually mobile reading and extensive electronic reading form becomes an important part in people's lives. E-books, with the fast development of electronic technology, get new developments. Digital textbooks, as special electronic books in education teaching, earn widespread interest and attention. Departments of Education put forward the corresponding requirements for digital education informatization in 2013, which includes: fully launch second generation People's Education Press digital textbooks, realize the development of digital products, and ensure to introduce scientific applicability product in the autumn of 2013. Deputy Minister of Departments of Education in our country put forward that we should insist on innovation and driving mechanism, fully implement the application in teaching and fully realize normalization and extensive application in Anhui province education information research. Modern teaching reform needs to rely on the innovation of digital teaching technology to truly achieve teaching wisdom and ascend the quality of teaching. It has become the inevitable development trend to apply digital teaching facilities in education and teaching, especially in elementary education class. [2] Although people make digital textbooks as the focus of the study, currently people have no unified understanding of digital teaching material, and issues such as the content design and application of digital textbook are still in the preliminary study stage. I. RICH MEDIA TECHNOLOGY APPLICATION A. The characteristics of rich media technology Rich media mainly refers to the use of digital interactive media category. The technology is able to be downloaded and embedded in web pages. Rich media is to watch or offline use in Real player of Real Network and QuickTim of Apple. Driving is the most obvious characteristic of the technology and driving mechanism maintaining time is longer and can realize the indirect corresponding to the user operation. After the analysis of state information technology data in University of Washington, it is known that rich media is not a very detailed form of Internet media and it refers to animation, sound, Flash, text and programming language embedded into JAVE. Rich media has the features: digital, interactive, free deployment in a web page, alone download, offline download, and can realize one-time download. But the number of using times is more common and it has a dynamic driving mechanism. It can fully realize user's synchronous operation and can realize cross-platform operation. It can support lightweight widgets. One of the most significant is UI show, a deeper level of user interaction, corresponding to dynamic drive and integrates with convenient deployment, 2nd International Conference on Advances in Mechanical Engineering and Industrial Informatics (AMEII 2016) © 2016. The authors Published by Atlantis Press 1267 desktop applications and network. [3] B. Rich Internet applications Rich Internet application is one of Web application types, which has multiple desktop application characteristics, browses on the plug-in and achieves a distributed system virtual machine, etc. Rich Internet application belongs to a new type of rich media network application technology. This technology can realize network terminal applications, and it has high similarity with C/S architecture, so it is more convenient in desktop application deployment and able to actualize network application client program. Rich Internet is regarded as a lightweight user operation interface. Because of this, it can be more adapted to low performance interrupt, and can better realize interface enhancement than using HTML. The reaction is more flexible and it has the characteristics of visualization and interaction. Rich Internet can provide interactive interface for message identification and format organization, and provide users with common interface. For example, it can be applied in WEB2.0 environment implementation, web page drag-and-drop, and in the process of refreshing Forms and offline operation etc. Standing on the point of technical features, rich Internet engine can provide the technical support for timely response to the system, data exchange and rich user graphic interface. Rich Internet can allow SVG usage or other technologies graphics building, and can offer according data changes for whole activities animation. Its strength is in that data can be cached in the Client, and can be back and forth between the servers based on HTML at a faster corresponding speed. In mobile terminal equipment, the system can be designed as offline mode for a short period of time and implement sustainability. To jump out of the browser's limit, the interface can realize richer and more beautiful. Strongly ascend interface interaction ability and it is also a kind of network application. It has faster changes and deployment capabilities, and a strong dynamics in ActionScript script modification. The goal of rich Internet is mainly to fully apply WEB in terminal desktop, fully fuse desktop and WEB, apply WEB, and integrate browser and WEB. The relevant scholars believe that the further development of rich Internet fully displays the coming of desktop rich Internet era. II. RICH MEDIA TECHNOLOGY APPLICATION IN DIGITAL LEARNING TERMINAL A. Current digital terminal application At present, digital terminal products applications in learning in the market are mainly electronic reading products like E-book, mobile terminals installed electronic course ware learning process, etc., and students dedicated electronic textbooks and electronic schoolbag, etc. There is a wide variety with different characteristics. In the continuous development of learning concept, many products have to meet the digital learning needs. E-book is an electronic reading terminal and the main focus is content show in the pursuit of a more lifelike paper effect, and fully provides learning resources. For example, Amazon's kindleDX can fully realize the effect of newspaper and try to establish a multifaceted digital publishing content. At present, all kinds of digital learning products constantly appear but they are mostly in the form of e-books, and still stay on the basis of E-link technology or mainly use Flash technology to produce a good electronic course ware. [4] General electronic textbooks are only the digital implementation of textbook content and did not achieve a real shift of digital textbooks. Electronic course ware mainly takes learning theory as instruction, learning objectives as design aim, and fully reflects some strategies in learning and detailed teaching content. Electronic classes perform the corresponding user operations and further control the user's behavior for some feedback and control. Electronic course ware content is stable and will not implement corresponding adjustment by reader's feedback. All of the content is developed and designed ahead of schedule, so learning course ware resources have certain characteristics, such as closeness and reservation, no relevance and openness. This causes the difficulties of learning process and time cannot achieve consistent with the difference in learner's ability, and both cannot undertake adaptability adjustment. B. Rich media technology application in digital learning terminal 1. Silverlight and Air technology At present, there are two companies in the world make rich media technology research and",,2016.0,10.2991/AMEII-16.2016.238,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
aa30901b02e9923851d507e1f2726bcf9ef1b068,https://www.semanticscholar.org/paper/aa30901b02e9923851d507e1f2726bcf9ef1b068,OccuSpace: Towards a Robust Occupancy Prediction System for Activity Based Workplace,"Workplace occupancy detection is becoming increasingly important in large Activity Based Work (ABW) environments as it helps building and office management understand the utilisation and potential benefits of shared workplace. However, existing sensor-based technologies detect workstation occupancy in indoor spaces require extensive installation of hardware and maintenance incurring ongoing costs. Moreover, accuracy can depend on the specific seating styles of workers since the sensors are usually placed under the table or overhead. In this research, we provide a robust system called OccuSpace to predict occupancy of different atomic zones in large ABW environments. Unlike fixed sensors, OccuSpace uses statistical features engineered from Received Signal Strength Indicator (RSSI) of Bluetooth card beacons carried by workers while they are within the ABW environment. These features are used to train state-of-the-art machine learning algorithms for prediction task. We setup the experiment by deploying our system in a realworld open office environment. The experimental results show that OccuSpace is able to achieve a high accuracy for workplace occupancy prediction.",2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),2019.0,10.1109/PERCOMW.2019.8730762,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d6bfe8a73d1c8096d5736143c7086ee36caf5ee0,https://www.semanticscholar.org/paper/d6bfe8a73d1c8096d5736143c7086ee36caf5ee0,Scalable Prediction of Service-Level Events in Datacenter Infrastructure Using Deep Neural Networks,"The complexity of cloud datacenter scenarios poses new challenges in infrastructure management processes such as the impracticality of collecting specific service level events from inside the datacenter infrastructure, and the scalability issues that can appear during event monitoring when thousands of virtual machines have to be polled at a granularity of seconds. Therefore, it would be desirable to provide mechanisms for obtaining these types of events without incurring in the previously described problems. To this end, we propose a generic and scalable method based on the application of deep neural network architectures for predicting service level events using only a reduced number of generic datacenter infrastructure statistics that can be monitored in a scalable way. We demonstrate in a controlled scenario of a real datacenter and using only three variables from a physical machine that it is possible to predict events in real-time and with decent accuracy, without needing to deploy any meter in the end-user equipment. Specifically, we demonstrate this over two service-level events: i) the so-called Noisy Neighbors effect, a harmful situation that appears in physical machines due to the interferences created by the interaction of virtual machines running on them; and ii) the jitter values of a multimedia call running in a virtual machine. We set up a testbed in a real datacenter deploying physical and virtual machines, running a large amount of different experiments for 1000 hours and collecting samples at a 10 seconds granularity in a dataset of 260,000 records. Two different scenarios, in which training and testing data sets contain significant statistical differences, are deployed to demonstrate a better generalization ability of deep models in changing scenarios when compared with traditional Machine Learning techniques. A set of different deep architectures are proposed for both use cases and approximately 4,000 deep models were trained and tested. In both use cases, the best deep models show a good performance when predicting service level events, even if the inputs do not exactly follow the statistical patterns of the data used during training.",IEEE Access,2019.0,10.1109/ACCESS.2019.2956182,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
f6e3bcd3ceb4e7a98832b908449623f77fe654ce,https://www.semanticscholar.org/paper/f6e3bcd3ceb4e7a98832b908449623f77fe654ce,Multimodal Analysis of Image Search Intent: Intent Recognition in Image Search from User Behavior and Visual Content,"Users search for multimedia content with different underlying motivations or intentions. Study of user search intentions is an emerging topic in information retrieval since understanding why a user is searching for a content is crucial for satisfying the user's need. In this paper, we aimed at automatically recognizing a user's intent for image search in the early stage of a search session. We designed seven different search scenarios under the intent conditions of finding items, re-finding items and entertainment. We collected facial expressions, physiological responses, eye gaze and implicit user interactions from 51 participants who performed seven different search tasks on a custom-built image retrieval platform. We analyzed the users' spontaneous and explicit reactions under different intent conditions. Finally, we trained machine learning models to predict users' search intentions from the visual content of the visited images, the user interactions and the spontaneous responses. After fusing the visual and user interaction features, our system achieved the F-1 score of 0.722 for classifying three classes in a user-independent cross-validation. We found that eye gaze and implicit user interactions, including mouse movements and keystrokes are the most informative features. Given that the most promising results are obtained by modalities that can be captured unobtrusively and online, the results demonstrate the feasibility of deploying such methods for improving multimedia retrieval platforms.",ICMR,2017.0,10.1145/3078971.3078995,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
89a3ce54bb1343cf72e0d24c993caa70d3b2a41b,https://www.semanticscholar.org/paper/89a3ce54bb1343cf72e0d24c993caa70d3b2a41b,The Pathway Active Learning Environment: An interactive web-based tool for physics education,"The work described here represents an effort to design, construct, and test an interactive online multimedia learning environment that can provide physics instruction to students in their homes. The system was designed with one-on-one human tutoring in mind as the mode of instruction. The system uses an original combination of a video-based tutor that incorporates natural language processing video-centered lessons and additional illustrative multimedia. Our Synthetic Interview (SI) tutor provides pre-recorded video answers from expert physics instructors in response to students’ typed natural language questions. Our lessons cover Newton’s laws and provide a context for the tutoring interaction to occur, connect physics ideas to real-world behavior of mechanical systems, and allow for quantitative testing of physics. Additional multimedia can be used to supplement the SI tutors’ explanations and illustrate the physics of interest. The system is targeted at students of algebra-based and concept-based physics at the college and high school level. The system logs queries to the SI tutor, responses to lesson questions and several other interactions with the system, tagging those interactions with a username and timestamp. We have provided several groups of students with access to our system under several different conditions ranging from the controlled conditions of our interview facility to the naturalistic conditions of use at home. In total nearly two-hundred students have accessed the system. To gain insight into the ways students might use the system and understand the utility of its various components we analyzed qualitative interview data collected with 22 algebra-based physics students who worked with our system in our interview facility. We also performed a descriptive analysis of data from the system’s log of user interactions. Finally we explored the use of machine learning to explore the possibility of using automated assessment to augment the interactive capabilities of the system as well as to identify productive and unproductive use patterns. This work establishes a proof-of-concept level demonstration of the feasibility of deploying this type of system. The impact of this work and the possibility of future research efforts are discussed in the context of Internet technologies that are changing rapidly. THE PATHWAY ACTIVE LEARNING ENVIRONMENT: AN INTERACTIVE WEB-BASED TOOL FOR PHYSICS EDUCATION",,2012.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
37c2ac5bd9350226b6e8f2e938af9755493e7af4,https://www.semanticscholar.org/paper/37c2ac5bd9350226b6e8f2e938af9755493e7af4,ChunkDetection Model Training ChunkDetection Feature Extraction QoE Prediction Models Feature Extraction Measure Accuracy Training Evaluation Requet Video Labeling Video Labeling Video Labeling Data Acquisition Trace Collection Trace Collection Packet Traces Packet Traces QoE Metrics QoE,"As video traffic dominates the Internet, it is important for operators to detect video Quality of Experience (QoE) in order to ensure adequate support for video traffic. With wide deployment of endto-end encryption, traditional deep packet inspection based traffic monitoring approaches are becoming ineffective. This poses a challenge for network operators to monitor user QoE and improve upon their experience. To resolve this issue, we develop and present a system for REal-time QUality of experience metric detection for Encrypted Traffic, Requet. Requet uses a detection algorithm we develop to identify video and audio chunks from the IP headers of encrypted traffic. Features extracted from the chunk statistics are used as input to a Machine Learning (ML) algorithm to predict QoE metrics, specifically, buffer warning (low buffer, high buffer), video state (buffer increase, buffer decay, steady, stall), and video resolution. We collect a large YouTube dataset consisting of diverse video assets delivered over various WiFi network conditions to evaluate the performance. We compare Requet with a baseline system based on previous work and show that Requet outperforms the baseline system in accuracy of predicting buffer low warning, video state, and video resolution by 1.12×, 1.53×, and 3.14×, respectively. CCS CONCEPTS • Information systems→Multimedia streaming; •Networks → Network performance analysis; • Computing methodologies → Classification and regression trees;",,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a812368fe1d4a186322bf72a6d07e1cf60067234,https://www.semanticscholar.org/paper/a812368fe1d4a186322bf72a6d07e1cf60067234,Gaussian processes for modeling of facial expressions,"Automated analysis of facial expressions has been gaining significant attention over the past years. This stems from the fact that it constitutes the primal step toward developing some of the next-generation computer technologies that can make an impact in many domains, ranging from medical imaging and health assessment to marketing and education. No matter the target application, the need to deploy systems under demanding, realworld conditions that can generalize well across the population is urgent. Hence, careful consideration of numerous factors has to be taken prior to designing such a system. The work presented in this thesis focuses on tackling two important problems in automated analysis of facial expressions: (i) view-invariant facial expression analysis; (ii) modeling of the structural patterns in the face, in terms of well coordinated facial muscle movements. Driven by the necessity for efficient and accurate inference mechanisms we explore machine learning techniques based on the probabilistic framework of Gaussian processes (GPs). Our ultimate goal is to design powerful models that can efficiently handle imagery with spontaneously displayed facial expressions, and explain in detail the complex configurations behind the human face in real-world situations. To effectively decouple the head pose and expression in the presence of large outof-plane head rotations we introduce a manifold learning approach based on multi-view learning strategies. Contrary to the majority of existing methods that typically treat the numerous poses as individual problems, in this model we first learn a discriminative manifold shared by multiple views of a facial expression. Subsequently, we perform facial expression classification in the expression manifold. Hence, the pose normalization problem is solved by aligning the facial expressions from different poses in a common latent space. We demonstrate that the recovered manifold can efficiently generalize to various poses and expressions even from a small amount of training data, while also being largely robust to corrupted image features due to illumination variations. State-of-the-art performance is achieved in the task of facial expression classification of basic emotions. The methods that we propose for learning the structure in the configuration of the muscle movements represent some of the first attempts in the field of analysis and intensity estimation of facial expressions. In these models, we extend our multi-view approach to exploit relationships not only in the input features but also in the multi-output labels. The structure of the outputs is imposed into the recovered manifold either from heuristically defined hard constraints, or in an auto-encoded manner, where the structure is learned automatically from the input data. The resulting models are proven to be robust to data with imbalanced expression categories, due to our proposed Bayesian learning of the target manifold. We also propose a novel regression approach based on product of GP experts where we take into account people’s individual expressiveness in order to adapt the learned models on each subject. We demonstrate the superior performance of our proposed models on the task of facial expression recognition and intensity estimation.",,2016.0,10.25560/44106,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
45e3d48f8ac4ff05a2db2cbff411958b94129b2f,https://www.semanticscholar.org/paper/45e3d48f8ac4ff05a2db2cbff411958b94129b2f,Handbook of Approximation Algorithms and Metaheuristics,"PREFACE BASIC METHODOLOGIES Introduction, Overview, and Notation Basic Methodologies and Applications Restriction Methods Greedy Methods Recursive Greedy Methods Linear Programming LP Rounding and Extensions On Analyzing Semidefinite Programming Relaxations of Complex Quadratic Optimization Problems Polynomial-Time Approximation Schemes Rounding, Interval Partitioning, and Separation Asymptotic Polynomial-Time Approximation Schemes Randomized Approximation Techniques Distributed Approximation Algorithms via LP-Duality and Randomization Empirical Analysis of Randomized Algorithms Reductions that Preserve Approximability Differential Ratio Approximation Hardness of Approximation LOCAL SEARCH, NEURAL NETWORKS, AND METAHEURISTICS Local Search Stochastic Local Search Very Large-Scale Neighborhood Search: Theory, Algorithms, and Applications Reactive Search: Machine Learning for Memory-Based Heuristics Neural Networks Principles of Tabu Search Evolutionary Computation Simulated Annealing Ant Colony Optimization Memetic Algorithms MULTIOBJECTIVE OPTIMIZATION, SENSITIVITY ANALYSIS, AND STABILITY Approximation in Multiobjective Problems Stochastic Local Search Algorithms for Multiobjective Combinatorial Optimization: A Review Sensitivity Analysis in Combinatorial Optimization Stability of Approximation TRADITIONAL APPLICATIONS Performance Guarantees for One-Dimensional Bin Packing Variants of Classical One-Dimensional Bin Packing Variable, Sized Bin Packing and Bin Covering Multidimensional Packing Problems Practical Algorithms for Two-Dimensional Packing A Generic Primal-Dual Approximation Algorithm for an Interval Packing and Stabbing Problem Approximation Algorithms for Facility Dispersion Greedy Algorithms for Metric Facility Location Problems Prize-Collecting Traveling Salesman and Related Problems A Development and Deployment Framework for Distributed Branch and Bound Approximations for Steiner Minimum Trees Practical Approximations of Steiner Trees in Uniform Orientation Metrics Approximation Algorithms for Imprecise Computation Tasks with 0/1 Constraint Scheduling Malleable Tasks Vehicle Scheduling Problems in Graphs Approximation Algorithms and Heuristics for Classical Planning Generalized Assignment Problem Probabilistic Greedy Heuristics for Satisfiability Problems COMPUTATIONAL GEOMETRY AND GRAPH APPLICATIONS Approximation Algorithms for Some Optimal 2D and 3D Triangulations Approximation Schemes for Minimum-Cost k-Connectivity Problems in Geometric Graphs Dilation and Detours in Geometric Networks The Well-Separated Pair Decomposition and its Applications Minimum-Edge Length Rectangular Partitions Partitioning Finite d-Dimensional Integer Grids with Applications Maximum Planar Subgraph Edge-Disjoint Paths and Unsplittable Flow Approximating Minimum-Cost Connectivity Problems Optimum Communication Spanning Trees Approximation Algorithms for Multilevel Graph Partitioning Hypergraph Partitioning and Clustering Finding Most Vital Edges in a Graph Stochastic Local Search Algorithms for the Graph Coloring Problem On Solving the Maximum Disjoint Paths Problem with Ant Colony Optimization LARGE-SCALE AND EMERGING APPLICATIONS Cost-Efficient Multicast Routing in Ad Hoc and Sensor Networks Approximation Algorithm for Clustering in Ad Hoc Networks Topology Control Problems for Wireless Ad Hoc Networks Geometrical Spanner for Wireless Ad Hoc Networks Multicast Topology Inference and its Applications Multicast Congestion in Ring Networks QoS Multimedia Multicast Routing Overlay Networks for Peer-to-Peer Networks Scheduling Data Broadcasts on Wireless Channels: Exact Solutions and Heuristics Combinatorial and Algorithmic Issues for Microarray Analysis Approximation Algorithms for the Primer Selection, Planted Motif Search, and Related Problems Dynamic and Fractional Programming-Based Approximation Algorithms for Sequence Alignment with Constraints Approximation Algorithms for the Selection of Robust Tag SNPs Sphere Packing and Medical Applications Large-Scale Global Placement Multicommodity Flow Algorithms for Buffered Global Routing Algorithmic Game Theory and Scheduling Approximate Economic Equilibrium Algorithms Approximation Algorithms and Algorithm Mechanism Design Histograms, Wavelets, Streams, and Approximation Digital Reputation for Virtual Communities Color Quantization INDEX",Comput. J.,2010.0,10.1093/comjnl/bxp121,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
e9c058077bdbde58f3bd6e3413e248aca100c169,https://www.semanticscholar.org/paper/e9c058077bdbde58f3bd6e3413e248aca100c169,Multimedia information technology and the annotation of video,"The state of the art in multimedia information technology has not progressed to the point where a single solution is available to meet all reasonable needs of documentalists and users of video archives. In general, we do not have an optimistic view of the usability of new technology in this domain, but digitization and digital power can be expected to cause a small revolution in the area of video archiving. The volume of data leads to two views of the future: on the pessimistic side, overload of data will cause lack of annotation capacity, and on the optimistic side, there will be enough data from which to learn selected concepts that can be deployed to support automatic annotation. At the threshold of this interesting era, we make an attempt to describe the state of the art in technology. We sample the progress in text, sound, and image processing, as well as in machine learning.",,2006.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
f9784db8ff805439f0a6b6e15aeaf892dba47ca0,https://www.semanticscholar.org/paper/f9784db8ff805439f0a6b6e15aeaf892dba47ca0,"Comparing the Performance of Emotion-Recognition Implementations in OpenCV, Cognitive Services, and Google Vision APIs","Emotions represent feelings about people in several situations. Various machine learning algorithms have been developed for emotion detection in a multimedia element, such as an image or a video. These techniques can be measured by comparing their accuracy with a given dataset in order to determine which algorithm can be selected among others. This paper deals with the comparison of three implementations of emotion recognition in faces, each implemented with specific technology. OpenCV is an open-source library of functions and packages mostly used for computer-vision analysis and applications. Cognitive services, as well as Google Cloud AI, are sets of APIs which provide machine learning and artificial intelligence algorithms to develop smart applications capable of integrate computer-vision, speech, knowledge, and language processing features. Three Android mobile applications were developed in order to test the performance between an OpenCV algorithm for emotion recognition, an implementation of Emotion cognitive service, and a Google Cloud Vision deployment for emotion-detection in faces. For this research, one thousand tests were carried out per experiment. Our findings show that the OpenCV implementation got the best performance, which can be improved by increasing the sample size per emotion during the training step.",,2017.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
9437726d525bebd68a8b0f17bd7cea479808d761,https://www.semanticscholar.org/paper/9437726d525bebd68a8b0f17bd7cea479808d761,A Novel Framework for Road Transportation Systems Using Cloud Computing,"Highly populated cities around the world are facing problems of better traffic management. Technologically advanced cities deploy agent based multiple multimedia sensor based networks to collect and analyse traffic data to provide better solutions for management and prediction of road conditions. However, the collected data reaches a high volume and became very difficult to manage. Moreover, the predictive analysis also demands a high computational power to run the predictive analysis algorithms. The data collections methods include automatic and manual collections of large amount of data and then the analysis is often done in legacy system or manually. Cloud providers are deploying large-scale data centres across the globe to meet Cloud customers’ compute, storage and network resource demands, and better efficiency, scalability and performance of the hosted applications. The outcomes of this research also considers the most effective cloud based storage for traffic data with the knowledge of most popular cloud based storage service providers. The accumulation of the data is also followed by a predictive system for road traffic data analysis. Hence, in this work we also explore the use of standard machine learning techniques to identify the most suitable technique with performance consideration.","International journal of simulation: systems, science & technology",2018.0,10.5013/ijssst.a.19.04.19,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
cdebf1de7b2ccb852b203708f9dc2e584a2abb0c,https://www.semanticscholar.org/paper/cdebf1de7b2ccb852b203708f9dc2e584a2abb0c,Comparing Human-Robot Proxemics between Virtual Reality and the Real World,"Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of Human-Robot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other. Comparing Human-Robot Proxemics between Virtual Reality and the Real World Rui Li KTH Royal Institute of Technology Stockholm, Sweden Rui3@kth.se ABSTRACT Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other.Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other. INTRODUCTION Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI) [1][2][3][4]. VR has been used to test teleoperation and collect demonstration data to train machine learning algorithms, which showcased the effectiveness of learning visuomotor skills using data collected by consumer-grade devices [1]. VR teleoperation systems were proposed to crowdsource robotic demonstrations at scale [2]. A VR simulation framework was also proposed to replace the physical robot, as VR can enable high level abstraction in embodiment and multimodal interaction [3]. VR has also been used as a rapid prototyping tool to design in-vehicle interactions and interfaces for self-driving cars, which showed the evocation to genuine responses from test participants [4]. Compared to other HRI experiment methods, VR as an emerging interactive media provides unique advantages. VR HRI has the potential of having higher immersion and fidelity than picture based HRI, video-based HRI and simulated HRI. In situations where the perception of the robot is challenging, compared to on-screen viewing, VR display showed significant improvement on collaborative tasks [5]. When comparing VR HRI to the physical, realworld interaction (Live HRI), there is a trade-off between the two. VR experiences still cannot replace physical experiences due to system limitation, and limited interaction modalities etc. [6]. For example, system limitations such as limited field of view and low display resolution could reduce immersion and presence of the VR experience, resulting in different behaviors from Live experiments. Limited interaction modalities, such as the absence of touch, means that the participant could not feel the robot or even go through the robot, which could potentially break the entire interaction. Figure 1: Photograph of the Live experiment setting However, with the help of the distribution of consumer-grade VR devices and online crowdsourcing platforms, VR HRI has the potential to gain massive data for training robotic behavior and studying HRI related issues. Data collection through VR can also reduce noise and improve the data quality [1], which help to ease data processing and algorithm training. Furthermore, VR HRI experiments can test concepts and interactions without physical robots, making it more resource efficient and less expensive than Live HRI. Less hardware also means that the experiment will be less cumbersome to set up, easier to be reproduced and to ensure experiment quality. In this study, HRI Proxemics (the preferred personal space between a human and a robot) was compared to give a better justification and more basic understanding of the relationship between Live and VR. Proxemics preferences rely on lower level intuition [7], therefore, reflect the differences in the perceptions between Live and VR better. Compared to other HRI subject such as conversational (audio) or gaze behavior (visual), which are more modality dependent, proxemics can give a comprehensive understanding of the human responses. In addition, variations of modalities in VR can greatly influence human perception. For example, a higher visual familiarity of the physical environment in VR can decrease the effect of distance distortion [8]. Auditory inputs play another important role in VR, the addition of spatial sound can increase the sense of presence in VR and provide sound localization [9]. Thus, this work also compares VR settings with variance in modalities to evaluate the impacts of visual familiarity and spatial sound on VR HRI experiments. A 2 x 3 mixed design experiment was conducted to evaluate the differences between Live and VR HRI, as well as the influence of visual familiarity and spatial sound in VR. For the Live HRI, the pepper robot from Softbank Robotics was used (Figure 1). In the VR HRI, a 3D model of the same robot was used. To measure visual familiarity, the VR scene was created in Blender based on a 3D scan of the physical lab. The spatial sound was created by enabling the movement of the physical robot, due to the difficulties of engineering spatial sound. The interaction was implemented in Unity. As an objective measurement for proxemics preference, the minimum comfort distance (MCD) was measured. In addition, for the psychological perception of the experience, the feeling of presence was measured with the SUS questionnaire. For the perception of the robot, two relevant factors, competence and discomfort was measured with the ROSAS questionnaire.",,2018.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
59e10d1d4cd454635914cfd0ac5160a318fd0473,https://www.semanticscholar.org/paper/59e10d1d4cd454635914cfd0ac5160a318fd0473,UB09 Session 9,"In the domain of Wireless Sensor Networks (WSN), providing an effective security solution to protect the motes and their communications is challenging. Due to the hard constraints on performance, storage and energy consumption, normal network-security related techniques cannot be applied. Focusing on the ""Intrusion Detection"" problem, we propose a realworld application of our WSN Intrusion Detection System (WIDS). WIDS exploits the Weak Process Models to classify potential security issues in the WSN and to notify the operators when an attack tentative is detected. In this demonstration, we show how our IDS works, how it detects some basic attacks and how the IDS can evolve to fullfil the needs of secure WSN deployments. Download Paper (PDF) UB09.2 RESCUE: EDA TOOLSET FOR INTERDEPENDENT ASPECTS OF RELIABILITY, SECURITY AND QUALITY IN NANOELECTRONIC SYSTEMS DESIGN Authors: Cemil Cem Gürsoy1, Guilherme Cardoso Medeiros2, Junchao Chen3, Nevin George4, Josie Esteban Rodriguez Condia5, Thomas Lange6, Aleksa Damljanovic5, Raphael Segabinazzi Ferreira4, Aneesh Balakrishnan6, Xinhui Anna Lai1, Shayesteh Masoumian7, Dmytro Petryk3, Troya Cagil Koylu2, Felipe Augusto da Silva8, Ahmet Cagri Bagbaba8 and Maksim Jenihhin1 1Tallinn University of Technology, EE; 2Delft University of Technology, NL; 3IHP, DE; 4BTU Cottbus-Senftenberg, DE; 5Politecnico di Torino, IT; 6IROC Technologies, FR; 7Intrinsic ID B.V., NL; 8Cadence Design Systems GmbH, DE Abstract The demonstrator will introduce an EDA toolset developed by a team of PhD students in the H2020-MSCA-ITN RESCUE project. The recent trends for the computing systems include machine intelligence in the era of IoT, complex safety-critical applications, extreme miniaturization of technologies and intensive interaction with the physical world. These trends set tough requirements on mutually dependent extra-functional design aspects. RESCUE is focused on the key challenges for reliability (functional safety, ageing, soft errors), security (tamper-resistance, PUF technology, intelligent security) and quality (novel fault models, functional test, FMEA/FMECA, verification/debug) and related EDA methodologies. The objective of the interdisciplinary cross-sectoral team from Tallinn UT, TU Delft, BTU Cottbus, POLITO, IHP, IROC, Intrinsic-ID, Cadence and Bosch is to develop in collaboration a holistic EDA toolset for modelling, assessment and enhancement of these extra-functional design aspects. Download Paper (PDF)The demonstrator will introduce an EDA toolset developed by a team of PhD students in the H2020-MSCA-ITN RESCUE project. The recent trends for the computing systems include machine intelligence in the era of IoT, complex safety-critical applications, extreme miniaturization of technologies and intensive interaction with the physical world. These trends set tough requirements on mutually dependent extra-functional design aspects. RESCUE is focused on the key challenges for reliability (functional safety, ageing, soft errors), security (tamper-resistance, PUF technology, intelligent security) and quality (novel fault models, functional test, FMEA/FMECA, verification/debug) and related EDA methodologies. The objective of the interdisciplinary cross-sectoral team from Tallinn UT, TU Delft, BTU Cottbus, POLITO, IHP, IROC, Intrinsic-ID, Cadence and Bosch is to develop in collaboration a holistic EDA toolset for modelling, assessment and enhancement of these extra-functional design aspects. Download Paper (PDF) UB09.3 ASAM: AUTOMATIC SYNTHESIS OF ALGORITHMS ON MULTI CHIP/FPGA WITH COMMUNICATION CONSTRAINTS Authors: Amir Masoud Gharehbaghi, Tomohiro Maruoka, Yukio Miyasaka, Akihiro Goda, Amir Masoud Gharehbaghi and Masahiro Fujita, The University of Tokyo, JP Abstract Mapping of large systems/computations on multiple chips/multiple cores needs sophisticated compilation methods. In this demonstration, we present our compiler tools for multi-chip and multi-core systems that considers communication architecture and the related constraints for optimal mapping. Specifically, we demonstrate compilation methods for multi-chip connected with ring topology, and multi-core connected with mesh topology, assuming fine-grained reconfigurable cores, as well as generalization techniques for large problems size as convolutional neural networks. We will demonstrate our mappings methods starting from data-flow graphs (DFGs) and equations, specifically with applications to convolutional neural networks (CNNs) for convolution layers as well as fully connected layers. Download Paper (PDF) UB09.4 HEPSYCODE-MC: ELECTRONIC SYSTEM-LEVEL METHODOLOGY FOR HW/SW CO-DESIGN OF MIXED-CRITICALITY EMBEDDED SYSTEMS Authors: Luigi Pomante1, Vittoriano Muttillo1, Marco Santic1 and Emilio Incerto2 1Università degli Studi dell'Aquila DEWS, IT; 2IMT Lucca, IT Abstract Heterogeneous parallel architectures have been recently exploited for a wide range of embedded application domains. Embedded systems based on such kind of architectures can include different processor cores, memories, dedicated ICs and a set of connections among them. Moreover, especially in automotive and aerospace application domains, they are even more subjected to mixed-criticality constraints. So, this demo addresses the problem of the ESL HW/SW co-design of mixed-criticality embedded systems that exploit hypervisor (HPV) technologies. In particular, it shows an enhanced CSP/SystemC-based design space exploration step, in the context of an existing HW/SW co-design flow that, given the system specification is able to (semi)automatically propose to the designer: a custom heterogeneous parallel HPV-based architecture; an HW/SW partitioning of the application; a mapping of the partitioned entities onto the proposed architecture. Download Paper (PDF)Heterogeneous parallel architectures have been recently exploited for a wide range of embedded application domains. Embedded systems based on such kind of architectures can include different processor cores, memories, dedicated ICs and a set of connections among them. Moreover, especially in automotive and aerospace application domains, they are even more subjected to mixed-criticality constraints. So, this demo addresses the problem of the ESL HW/SW co-design of mixed-criticality embedded systems that exploit hypervisor (HPV) technologies. In particular, it shows an enhanced CSP/SystemC-based design space exploration step, in the context of an existing HW/SW co-design flow that, given the system specification is able to (semi)automatically propose to the designer: a custom heterogeneous parallel HPV-based architecture; an HW/SW partitioning of the application; a mapping of the partitioned entities onto the proposed architecture. Download Paper (PDF) UB09.5 CS: CRAZYSQUARE Authors: Federica Caruso1, Federica Caruso1, Tania Di Mascio1, Alessandro D'Errico1, Marco Pennese2, Luigi Pomante1, Claudia Rinaldi1 and Marco Santic1 1University of L'Aquila, IT; 2Ministry of Education, IT Abstract CrazySquare (CS) is an adaptive learning system, developed as a serious game for music education, specifically indicated for young teenager approaching music for the first time. CS is based on recent educative directions which consist of using a more direct approach to sound instead of the musical notation alone. It has been inspired by a paper-based procedure that is currently used in an Italian middle school. CS represents a support for such teachers who prefer involving their students in a playful dimension of learning rhythmic notation and pitch, and, at the same time, teaching playing a musical instrument. To reach such goals in a cost-effective way, CS fully exploits all the recent advances in the EDA domain. In fact, it is based on a framework composed of mobile applications that will be integrated with augmented reality HW/SW tools to provide virtual/augmented musical instruments. The proposed demo will show the main features of the current CS framework implementation. Download Paper (PDF)CrazySquare (CS) is an adaptive learning system, developed as a serious game for music education, specifically indicated for young teenager approaching music for the first time. CS is based on recent educative directions which consist of using a more direct approach to sound instead of the musical notation alone. It has been inspired by a paper-based procedure that is currently used in an Italian middle school. CS represents a support for such teachers who prefer involving their students in a playful dimension of learning rhythmic notation and pitch, and, at the same time, teaching playing a musical instrument. To reach such goals in a cost-effective way, CS fully exploits all the recent advances in the EDA domain. In fact, it is based on a framework composed of mobile applications that will be integrated with augmented reality HW/SW tools to provide virtual/augmented musical instruments. The proposed demo will show the main features of the current CS framework implementation. Download Paper (PDF) UB09.6 LABSMILING: A SAAS FRAMEWORK, COMPOSED OF A NUMBER OF REMOTELY ACCESSIBLE TESTBEDS AND RELATED SW TOOLS, FOR ANALYSIS, DESIGN AND MANAGEMENT OF LOW DATA-RATE WIRELESS PERSONAL AREA NETWORKS BASED ON IEEE 802.15.4 Authors: Carlo Centofanti, Luigi Pomante, Marco Santic and Walter Tiberti, University of L'Aquila, IT Abstract Low data-rate wireless personal area networks (LR-WPANs) are constantly increasing their presence in the fields of IoT, wearable, home automation, health monitoring. The development, deployment and testing of SW based on IEEE 802.15.4 standard (and derivations, e.g. 15.4e), require the exploitation of a testbed as the network grows in complexity and heterogeneity. This demo shows LabSmiling: a SaaS framework which connects testbeds deployed in a real-world-environment and the related SW tools that make available a meaningful (but still scalable) number of physical devices (sensor nodes) to developers. It provides a comforta",,2019.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d91b1b996678425418321d9de5b251778eb506d7,https://www.semanticscholar.org/paper/d91b1b996678425418321d9de5b251778eb506d7,Knowledge engineering with semantic web technologies for decision support systems based on psychological models of expertise,"Machines that provide decision support have traditionally used either a representation of human expertise or used mathematical algorithms. Each approach has its own limitations. This study helps to combine both types of decision support system for a single system. However, the focus is on how the machines can formalise and manipulate the human representation of expertise rather than on data processing or machine learning algorithms. It will be based on a system that represents human expertise in a psychological format. The particular decision support system for testing the approach is based on a psychological model of classification that is called the Galatean model of classification. The simple classification problems only require one XML structure to represent each class and the objects to be assigned to it. However, when the classification system is implemented as a decision support system within more complex realworld domains, there may be many variations of the class specification for different types of object to be assigned to the class in different circumstances and by different types of user making the classification decision. All these XML structures will be related to each other in formal ways, based on the original class specification, but managing their relationships and evolution becomes very difficult when the specifications for the XML variants are text-based documents. For dealing with these complexities a knowledge representation needs to be in a format that can be easily understood by human users as well as supporting ongoing knowledge engineering, including evolution and consistency of knowledge. The aim is to explore how semantic web technologies can be employed to help the knowledge engineering process for decision support systems based on human expertise, but deployed in complex domains with variable circumstances. The research evaluated OWL as a suitable vehicle for representing psychological expertise. The task was to see how well it can provide a machine formalism for the knowledge without losing its psychological validity or transparency: that is, the ability of end users to understand the knowledge representation intuitively despite its OWL format. The OWL Galatea model is designed in this study to help in automatic knowledge maintenance, reducing the replication of knowledge with variant uncertainties and support in knowledge engineering processes. The OWL-based approaches used in this model also aid in the adaptive knowledge management. An adaptive assessment questionnaire is an example of it, which is dynamically derived using the users age as the seed for creating the alternative questionnaires. The credibility of the OWL Galatea model is tested by applying it on two extremely different assessment domains (i.e. GRiST and ADVANCE). The conclusions are that OWLbased specifications provide the complementary structures for managing complex knowledge based on human expertise without impeding the end users’ understanding of the knowledgebase. The generic classification model is applicable to many domains and the accompanying OWL specification facilitates its implementations.",,2016.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
f2b4d4cba21fbaafdd4c2775d6d046268bda7289,https://www.semanticscholar.org/paper/f2b4d4cba21fbaafdd4c2775d6d046268bda7289,Intelligent Video QoE Prediction Model for Errorprone Networks,"Objective: Quantifying the quality of video transmitted over diversified networks is becoming critical in the frontiers of digital video Communication. The exponential growth of video-driven applications in wireless domain have created plethora of research issues to be explored in real time. Estimation of video quality in wireless environment requires the conception of better framework and methodologies to improve users’ Quality of Experience (QoE).This paper depicts a novel QoE prediction model that uses machine learning algorithms in predicting video quality over an error prone environment with better prediction accuracy. Methods: The work deploys Pseudo Subjective Quality Assessment (PSQA) method that involves a hybrid technique in assessing the multimedia quality using WEKA machine learning workbench. Findings: The proposed model provides a comparative study of well-known Artificial Intelligence (AI) techniques in predicting the perceived quality of multimedia and the efficiency is analyzed using performance indicators such as Root Mean Squared Error, Correlation Coefficient and Mean Absolute Error. The results of the proposed method underline the effective and inherent advantage in using machine learning methods for video quality prediction. Application: The evaluation results exemplify the importance of applying machine learning paradigms in broad areas of visual quality assessment. The output of various error measures and error variation analysis of the model shows the superiority of Multilayer perceptron based AI technique over other methods.",,2015.0,10.17485/IJST/2015/V8I16/65562,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3af91b1be29551c1cf19866f47e7035b7e139343,https://www.semanticscholar.org/paper/3af91b1be29551c1cf19866f47e7035b7e139343,Objective Image Quality Assessment: Facing The Real-World Challenges,"There has been a growing interest in recent years in the development of objective image quality assessment (IQA) models, whose roles are not only to monitor image quality degradations and benchmark image processing systems, but also to optimize various image and video processing algorithms and systems. While the past achievement is worth celebrating, a number of major challenges remain when we apply existing IQA models in realworld applications. These include obvious ones such as the challenges to largely reduce the complexity of existing IQA algorithms and to make them easy-to-use and easy-to-understand. There are also challenges regarding the applicability of existing IQA models in many real-world problems where image quality needs to be evaluated and compared across dimensionality, across viewing environment, and across the form of representations − specific examples include quality assessment for image resizing, color-togray image conversion, multi-exposure image fusion, image retargeting, and high dynamic range image tone mapping. Here we will first elaborate these challenges, and then concentrate on a specific one, namely the generalization challenge, which we believe is a more fundamental issue in the development, validation and application of IQA models. Specifically, the challenge is about the generalization capability of existing IQA models, which achieve superior quality prediction performance in lab testing environment using a limited number of subject-rated test images, but the performance may not extend to the real-world where we are working with images of a much greater diversity in terms of content and complexity. We will discuss some principle ideas and related work that might help us meet the challenges in the future. Introduction Over the past decades, a growing number of researchers and engineers in the image processing community have started to realize the importance of image/video quality assessment (IQA/VQA) [40, 29, 4]. This is not surprising because no matter what image/video processing problems we are working on, the same issues repeatedly come up − How should we evaluate the images generated from our algorithms/systems? How do we know our algorithm/system is creating an improvement between the input and output images, and by how much? How can we know one algorithm/system performs better than another, and by how much? What should be the quality criterion for which the design of our algorithms/systems should be optimized? Since the human eyes are the ultimate receivers in most image processing applications, human subjective visual testing would be a reliable solution. However, with the exponential increase of the volume of image/video data being generated daily, it becomes impossible to address these quality issues in a timely manner by subjective visual testing, which is slow, cumbersome and expensive. Instead, only trusted objective IQA models may potentially meet these needs. In academia, objective IQA has been a hot research topic, especially in the past 15 years [35, 4, 29]. First, the commonly used numerical disotrtion/quality measures in the past − the mean squared error (MSE) and the peak signal-to-noise ratio (PSNR) − have been shown to correlate poorly with perceived image quality [28, 30]. Second, a large number of perceptually more meaningful IQA models have been proposed, including full-reference (where a perfect quality reference image is available when evaluating a distorted image) [35, 4, 29], no-reference (where the reference image is not accessible) [34, 24, 31], and reduced-reference (where only partial information about the reference image is available) models [39, 36, 31, 29]. Third, several design principles have been discovered and repeatedly demonstrated to be useful in the design and improvement of IQA models. These include psychophysical and physiological visibility models [35, 4], the structural similarity (SSIM) approaches [28, 32, 33, 20, 49], the natural scene statistics (NSS) and information theoretic approaches [36, 39, 21, 31], the visual saliency based approaches [50], and the machine learning based approaches [6]. Fourth, a number of subject-rated image quality databases have been created and made publicly available [22, 7, 8, 17, 16, 47]. They provide a common benchmark platform for the evaluation and comparison of IQA models, among which several algorithms have achieved high correlations with the subjective mean opinion scores (MOSs) of the test images [23, 38, 33, 49]. In the video delivery industry, perceptual objective IQA methods such as the SSIM algorithm have been incorporated into many practical hardware and software systems to monitor image/video quality degradations and to test/compare image/video encoders and transcoders [27, 25, 26]. The wide use of SSIM has resulted in a Primetime Engineering Emmy Award given by the Academy of Television Arts and Sciences [1]. The remarkable development and successful deployment of modern IQA methods are definitely worth celebrating. Nevertheless, this does not necessarily mean that the existing IQA models have already met the real-world challenges. Otherwise, they should have made a much stronger impact and become a gamechanging factor in the industry. Using the video delivery industry as an example, even now most practitioners are still equating bitrate with quality in the practical design of video delivery architectures. However, using the same bitrate to encode different video content could result in dramatically different visual quality. Clearly, the perceptual quality of the video itself, which is presumably the ultimate evaluation criterion of the whole video delivery system, has not been placed at the driver’s seat. While it is understandable that quality degradation is inevitable at many stages in the video delivery chain due to practical constraints, the real concern here is that there is no existing protocol to monitor and control such quality degradation. As a result, various tricks have been used to manipulate the video content and network resources are allocated in suboptimal ways, leaving the creative intent of the content producers unprotected. While it is certain that the industry needs to be better informed about the great potentials of making the best use of IQA/VQA models, we believe that an equally important aspect that slows down the process is that the existing IQA/VQA models still do not meet many real-world challenges. In the following sections, we will elaborate some of these challenges and then focus on a specific one, namely the generalization challenge. We wish our discussions on some fundamental ideas could provide some useful insights for the future development of IQA models that may meet these real-world challenges. The Real-World Challenges Here we make a list of real-world challenges, many of which are described in more details through examples of practical scenarios. 1. It is highly desirable to reduce the complexity of the IQA/VQA algorithms so that they can be computed in realtime or in an even faster speed. This is especially useful in time-sensitive applications such as live broadcasting and videoconferencing. Many existing models are far from meeting this challenge. 2. It is essential to make the IQA/VQA scores easy-to-use and easy-to-understand. For example, the raw SSIM score does not have an explicit perceptual meaning, making it difficult to determine what level of SSIM index can warrant an excellent video quality and how much improvement in the SSIM index is sufficient to create visible quality improvement. Mapping the raw scores into a perceptually linear domain that is easily linked to human expressions about image quality is desirable. 3. The same video stream shown on different display devices could result in very different perceptual quality. For example, a strongly compressed video that exhibits very annoying artifacts on a large TV could appear to have fine quality when viewed on the screen of a smartphone. The quality may also change significantly when the video is watched on the same TV but at two different viewing distances, one at the default distance and the other at a very close distance. However, existing IQA/VQA models give the same score based on the video stream only, completely ignorant of the viewing device and viewing condition. 4. In a video-on-demand application, a high-quality highresolution (e.g., 4K) source video may be encoded into multiple video streams of different resolutions (e.g., 1080p, 720p, 360p, 240p, etc.) and different bit rates, aiming for satisfying a variety of user needs. In order to measure the quality of the encoded videos, most existing VQA models cannot be computed because the source (reference) and test videos have different spatial resolutions. 5. An image or video may need to be displayed on a screen that has a spatial resolution higher than that of the image resolution. As a result, spatial interpolation is performed. Again, most existing VQA models are not applicable because the reference and test images have different spatial resolutions. 6. An image or video of imperfect quality (e.g., being compressed at an earlier stage) is received and then transcoded to multiple images or videos with different bitrates and resolutions. Most existing IQA/VQA models are not applicable not only because they do not allow for cross-resolution quality assessment, but also because they assume the original reference image/video to have perfect quality, which is not the case here. How to carry out “degraded reference” IQA/VQA is a major challenge. 7. A high dynamic range (HDR) image (e.g., the pixels are in 10 or more bit depths) is tone mapped to a standard dynamic range (SDR) image (8 bits per pixel) in order to be visualized on an SDR display. There is certainly information loss that we would like to capture. However, most existing IQA models do not apply because they cannot compare images/videos with different dynamic ranges.",IQSP,2016.0,10.2352/ISSN.2470-1173.2016.13.IQSP-205,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3f3f00fc84c5ea2f6fba2dea24d139dfcc2278bb,https://www.semanticscholar.org/paper/3f3f00fc84c5ea2f6fba2dea24d139dfcc2278bb,Visual Model Interpretation for Epidemiological Cohort Studies,"Epidemiological cohort studies investigate the cause and development of diseases in human populations. Conventional analyses are challenged by recently increasing study sizes, which is why the incorporation of machine learning gains popularity. State-of-the-art classifiers are however often hard to interpret – an important requirement in medical applications. This thesis addresses the gap between predictive power and interpretability in the context of cohort study analysis. Main contribution is the development of an interactive visual interface for the interpretation and comparison of probabilistic classifiers. It supports the analysis of important features at both global and individual level, computation of partial dependence, and iterative construction of meaningful feature groups. To analyse the longitudinal influence of features, the user can modify the feature set by removing a feature or replacing its value by a previous examination record. The developed visual interface is evaluated in two case studies in order to test its effectiveness for the generation and validation of research hypotheses. The case studies include a realworld epidemiological cohort study and synthetic data. The results indicate the interface’s usefulness for epidemiological research, but also reveal necessary further work for the deployment into a productive environment.",,2018.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
14a43c3c9d44410c2f1fd438f7d6a7d9b7c28d43,https://www.semanticscholar.org/paper/14a43c3c9d44410c2f1fd438f7d6a7d9b7c28d43,Intellimedia Systems: Research and Applications at the Intersection of Multimedia and Artificial Intelligence,,PRICAI,2002.0,10.1007/3-540-45683-X_4,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
229fc8a087adad290460117ba621b3cf5d4ed9c3,https://www.semanticscholar.org/paper/229fc8a087adad290460117ba621b3cf5d4ed9c3,Audio computing in the wild: frameworks for big data and small computers,"This talk introduces some machine learning algorithms that are designed to process as much data as needed while spending the least possible amount of resources, such as time, energy, and memory. Examples of those applications, but not limited to, can be a large-scale multimedia information retrieval system where both queries and the database items are noisy signals; collaborative audio enhancement from hundreds of user-created Youtube clips of a music concert; an event detection system running in a small device that has to process various sensor signals in real time; a lightweight custom chipset for speech enhancement on handheld devices; instant music analysis engine running on smartphone apps. In all those applications, efficient machine learning algorithms are supposed to achieve not only a good performance, but also a great resourceefficiency. To meet these contradicting requirements at the same time, I have developed various matrix factorization algorithms (or topic models): a topic model that takes sparse landmark representations as input, a latent component sharing technique to analyze a set of crowdsourced audio recordings, and a hashing-based speed-up technique for faster sparse coding in topic modeling. Finally, to describe an extremely optimized deep learning deployment system, Bitwise Neural Networks (BNN) will be also discussed. In BNNs, all the inputs, outputs, and operations are defined with Boolean algebra (e.g. in BNNs a multiplication between floating-points is reduced down to a single XNOR gate for the two binary inputs). Some preliminary results on the MNIST dataset and speech denoising demonstrate that a straightforward extension of backpropagation can successfully train BNNs whose performance is comparable while necessitating vastly fewer computational resources. Biography: Minje Kim is a PhD candidate in the Department of Computer Science at the University of Illinois at Urbana-Champaign. Before joining UIUC, he worked as a researcher in ETRI, a national lab in Korea, from 2006 to 2011. He received his Bachelor’s and Master’s degrees in the Division of Information and Computer Engineering at Ajou University (with honor) and in the Department of Computer Science and Engineering at POSTECH (Summa Cum Laude) in 2004 and 2006, respectively. During his PhD study, he interned at Creative Technologies Lab in Adobe Research four times from 2012 to 2015. His research focuses on developing machine learning algorithms applied to audio processing, stressing out the computational efficiency in the resource-constrained environments or in the applications involving large unorganized datasets. He received Richard T. Cheng Endowed Fellowship from UIUC in 2011. Google and Starkey grants also honored his ICASSP papers as the outstanding student papers in 2013 and 2014, respectively. Audio Computing in the Wild: Frameworks for Big Data and Small Computers",,2016.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
069206bc035f8bddc754f53aea235e84180e1268,https://www.semanticscholar.org/paper/069206bc035f8bddc754f53aea235e84180e1268,On the inefficacy of Euclidean classifiers for detecting self-similar Session Initiation Protocol (SIP) messages,"The Session Initiation Protocol (SIP) is an important multimedia session establishment protocol used on the Internet. Due to the nature and deployment realities of the protocol (ASCII message representation, most deployments over UDP, limited use of message encryption), it becomes relatively easy to attack the protocol at the message level. To mitigate this, self-learning systems have been proposed to counteract new threats. However the efficacy of existing machine learning algorithms must be studied on varied data sets before they can be successfully used. Existing literature indicates that Euclidean distance based classifiers work well to detect anomalous messages. Our work suggests that such classifiers do not produce adequate results for well-crafted malicious messages that differ very slightly from normal messages. To demonstrate this, we gather SIP traffic and minimally perturb it using 13 generic transforms to create malicious SIP messages. We use the Levenshtein distance, L, as a measure of similarity between normal and malicious SIP messages. We subject our dataset — consisting of malicious and normal SIP messages — to Euclidean distance-based classifiers as well as four standard classifiers. Our results show vast differences for Euclidean distance-based classifiers on our dataset than reported in current literature. We further see that the standard classifiers are better able to classify an anomalous message when L is small.",12th IFIP/IEEE International Symposium on Integrated Network Management (IM 2011) and Workshops,2011.0,10.1109/INM.2011.5990708,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
e2a330edc8693516e330e479e9e485c4de5010e5,https://www.semanticscholar.org/paper/e2a330edc8693516e330e479e9e485c4de5010e5,La révolution de l'assurance par la donnée : défis scientifiques de l'extraction à la gestion de connaissances,"Marcin Detyniecki is senior R&D officer at the Data Innovation Lab recently created by AXA. Additionally, he is professor at the Polish Academy of Science (IBS PAN) and associate researcher at the computer science laboratory LIP6 of the University Pierre and Marie Curie (UPMC). Currently, his research focuses on the emerging challenge popularly named big data. In the past, he has worked on the usage of new media, with challenges ranging from multimedia information retrieval to image understanding. Several of the developed applications have not only been deployed in the market, but they have also been singled out in international competitions such as TrecVid, ImageClef, MediaEval. This applicative success is the results of a dialogue with more theoretical works on topics such as new challenges in approximate reasoning, information aggregation and fusion, and machine learning from a computational intelligence perspective. Marcin Detyniecki studied mathematics, physics and computer science at the University Pierre and Marie Curie (UPMC) in Paris. In 2000 he obtained his Ph.D. in Artificial Intelligence from the same university. Between 2001 and 2014, he was a research scientist of the French National Center for Scientific Research (CNRS). He has has been researcher at the University of California at Berkeley and at Carnegie Mellon University (CMU). He has been visiting researcher at the University of Florence and at British Telecom Research labs. Today he is member of the research and academic council of UPMC University, member of the executive board of laboratory SMART, elected member of the LIP6 laboratory council, and member of the editorial board of the International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJFUKS). He also funded and animated until 2014 the UPMC – Sorbonne Universités Computer Science Colloquium. Dr. Detyniecki has over 90 publications in journals and conference proceedings, including 6 keynotes.",EGC,2016.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
aad3d226fac7747a9ccce2044e4ea1c070103a6f,https://www.semanticscholar.org/paper/aad3d226fac7747a9ccce2044e4ea1c070103a6f,Speech/Music Classification using wavelet based Feature Extraction Techniques,"Audio classification serves as the fundamental step towards the rapid growth in audio data volume. Due to the increasing size of the multimedia sources speech and music classification is one of the most important issues for multimedia information retrieval. In this work a speech/music discrimination system is developed which utilizes the Discrete Wavelet Transform (DWT) as the acoustic feature. Multi resolution analysis is the most significant statistical way to extract the features from the input signal and in this study, a method is deployed to model the extracted wavelet feature. Support Vector Machines (SVM) are based on the principle of structural risk minimization. SVM is applied to classify audio into their classes namely speech and music, by learning from training data. Then the proposed method extends the application of Gaussian Mixture Models (GMM) to estimate the probability density function using maximum likelihood decision methods. The system shows significant results with an accuracy of 94.5%.",J. Comput. Sci.,2014.0,10.3844/jcssp.2014.34.44,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
8f2a47cd8a04aa7985d36c1106b01f35290be30f,https://www.semanticscholar.org/paper/8f2a47cd8a04aa7985d36c1106b01f35290be30f,Development of 80- and 100- Mile Work Day Cycles Representative of Commercial Pickup and Delivery Operation,"When developing and designing new technology for integrated vehicle systems deployment, standard cycles have long existed for chassis dynamometer testing and tuning of the powertrain. However, to this day with recent developments and advancements in plug-in hybrid and battery electric vehicle technology, no true “work day” cycles exist with which to tune and measure energy storage control and thermal management systems. To address these issues and in support of development of a range-extended pickup and delivery Class 6 commercial vehicle, researchers at the National Renewable Energy Laboratory in collaboration with Cummins analyzed 78,000 days of operational data captured from more than 260 vehicles operating across the United States to characterize the typical daily performance requirements associated with Class 6 commercial pickup and delivery operation. In total, over 2.5 million miles of realworld vehicle operation were condensed into a pair of duty cycles, an 80-mile cycle and a 100-mile cycle representative of the daily operation of U.S. class 3-6 commercial pickup and delivery trucks. Using novel machine learning clustering methods combined with mileage-based weighting, these composite representative cycles correspond to 90th and 95th percentiles for daily vehicle miles traveled by the vehicles observed. In addition to including vehicle speed vs time drive cycles, in an effort to better represent the environmental factors encountered by pickup and delivery vehicles operating across the United States, a nationally representative grade profile and key status information were also appended to the speed vs. time profiles to produce a “work day” cycle that captures the effects of vehicle dynamics, geography, and driver behavior which can be used for future design, development, and validation of technology. Introduction Under DOE-FOA-0001349 FY15 Award for Mediumand Heavy-Duty Vehicle Powertrain Electrification, Cummins and PACCAR jointly proposed the development of a range-extending plug-in hybrid electric Class 6 pickup and delivery truck. The goal of this project is to demonstrate an electrified vehicle that would deliver a minimum of 50% reduction in fuel consumption across a range of representative drive cycles. In addition to achieving the 50% fuel reduction target, the vehicle also needs to demonstrate as good or better drivability and performance while still meeting emissions requirements when compared to existing conventionally fueled baseline vehicles. Most existing duty cycles used to test conventional internal combustion powered vehicles are of a limited time duration. For example, the Hybrid Truck Utility Forum Class 6 Pickup and Delivery cycle is slightly more than one hour. When testing a system using only fuel as its energy source, this is acceptable; a onehour duty cycle can be used to represent the vehicle operation for the entire work day (e.g., fuel consumption in the middle of the day is very similar to fuel consumption at the end of the day). However, with plug-in electric vehicles, the system (battery characteristics and thermal management systems) may operate differently throughout the work day (especially near the end of the day). For example, the available battery energy may be completely spent prior to the completion of the route. A short duty cycle cannot simply be extrapolated. Evaluating the vehicle over the entire work day also provides the ability to interject appropriate stops that are typical of the Class 6-7 pickup and delivery application. These stops can range from several minutes to much longer and can have significant thermal effect on the vehicle and powertrain systems. These stops may also have a large impact on overall duty cycle mileage (and other duty cycle characteristics such as average speed) as the stops may account for roughly half of the work day. As part of the research and development team, the National Renewable Energy Laboratory (NREL) was been NREL/CP-5400-70943. Posted with permission. Presented at WCX 18: SAE World Congress Experience, 10-12 April 2018, Detroit, Michigan.",,2018.0,10.4271/2018-01-1192,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d65eb2f3356018c78d910d7864448a3dda658e17,https://www.semanticscholar.org/paper/d65eb2f3356018c78d910d7864448a3dda658e17,Classification-Based System For Cross-Layer Optimized Wireless Video Transmission,"Joint optimization strategies across various layers of the protocol stack have recently been proposed for improving the performance of real-time video transmission over wireless networks. In this paper, we propose a new, low complexity system for determining the optimal cross-layer strategies for wireless multimedia transmission based on classification and machine learning techniques. We first determine offline the optimal cross-layer strategy for various video sequences and channel conditions (training data). Subsequently, we extract relevant and easy to compute content features, encoder-specific parameters, and channel resources from the training data, and train a statistical classifier based on these optimal results. At run-time, we predict using the classifier the optimal cross-layer compression and transmission strategy using these simple, on-the-fly computed features. Hence, we consider the complex problem of finding the optimal cross-layer strategy during the training phase only, and rely at transmission-time on low-complexity classification techniques. We illustrate the proposed classification-based system by performing MAC-application layer optimizations for video transmission over 802.11a wireless LANs. Specifically, we predict the optimal MAC retry limits for the various video packets and compare our results against both optimal and conventionally used ad-hoc cross-layer solutions. Our results indicate that considerable improvements can be obtained through the proposed cross-layer techniques relying on classification as opposed to optimized ad-hoc solutions. The improvements are especially important at high packet-loss rates (5% and higher), where deploying a judicious mixture of strategies at the various layers becomes essential. Furthermore, our proposed classification-based system can be easily modified to include other layers from the OSI stack during the cross-layer optimization",IEEE Transactions on Multimedia,2006.0,10.1109/TMM.2006.879827,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0f9a0660e8768fa48e7daa864830e61e5a5bff45,https://www.semanticscholar.org/paper/0f9a0660e8768fa48e7daa864830e61e5a5bff45,IMPACT OF ONLINE STREAM CLUSTERING IN BANDWIDTH- CONSTRAINED MOBILE VIDEO ENVIRONMENT,"Mobile Video Streaming is becoming increasingly popular in today’s Multimedia community. Various adaptive streaming techniques have been proposed by multimedia researchers to dynamically vary the video quality according to the available bandwidth. However, the deployment of best video adaptation techniques in real time is highly challenging due to critical QoE (Quality of Experience) requirements in wireless multimedia streaming. Resource constrained wireless multimedia networks demands better perception on the behavior of critical factors such as bandwidth in varying geographic milieu. In this paper, Machine Learning based online stream clustering is adopted to study the bandwidth impact in a streaming environment using 3G wireless video dataset. Massive Online Analysis (MOA) software framework is used to infer the results using algorithms such as CluStream and DenStream. The experimental result shows the effect of stream clustering based on unsupervised study.The measures such as Sum Square Error (SSQ) and Silhouette coefficient are deployed to perform cluster analysis. The results demonstrate the efficiency of CluStream with K means algorithm over density based streaming algorithm. The proposed framework justifies the scope of context aware computing applications in the broader areas of wireless multimedia.",,2015.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
2684e6514f4e7bf7c5c3792d55aff76a646fde13,https://www.semanticscholar.org/paper/2684e6514f4e7bf7c5c3792d55aff76a646fde13,SCHOOL AS A ( MULTIMEDIA SIMULATION ) GAME : THE USE OF OBJECT TOOLS FOR DESIGNING MULTIMEDIA APPLICATIONS FOR BIOMEDICAL TEACHING,"Nowadays, Comenius’s old motto – “schola ludus” (“school as play”) has found a modern use in interactive educational programs using simulation games. Educational applications using simulation games, available through the web, represent a new educational aid, very effi cient from the didactic point of view in explaining complex pathophysiological processes. However, the process of creating them is not very easy – it requires multidisciplinary team cooperation and the use of suitable object-oriented development tools.The development of multimedia simulation games is a combination of research and development work. The research work consists in formalizing physiological reality by designing mathematical models, while development work is the very creation of multimedia simulators, which make use of the mathematical models designed. Creative interconnection of the various professions and various object-oriented tools and applications is the key to success. A scenario of good quality, created by an experienced pedagogue, still remains the foundation of the e-learning program. The creation of animated images is the responsibility of artists who create interactive animation in Adobe Flash or in Microsoft Expression Blend environment. The artists use the Animtester software tool developed by us, to create and test animations to be subsequently controlled by the simulation model. The core of the simulators is the simulation model, created in the environments of special development tools designated to create simulation models (we have used Simulink from Mathworks). Now, we use a very effi cient object-oriented environment, which utilizes the Modelica simulation language. We are working on the Modelica language compiler to compile into the .NET component form, which, together with the differential equations solver implemented on the .NET platform as well, shall serve as the “data layer” of the simulator with the implemented model. The user interface is connected with the simulation model using the data binding concept, which provides the intelligent automatic propagation of values between the layers, thus data transfer. We use hierarchical state automatons to design the inner application logic (the automatons make it possible to remember the relevant model context and the user interface context). We have also developed a visual environment (Statecharts editor), which allows creating the graphic design of the automatons, generating a code, and debugging them. The resulting simulator is a web application for the Silverlight platform, which makes it possible to distribute the simulator as a web application running directly in the internet browser (even on computers with various operating systems – it is only necessary that the relevant plugin is installed in the browser). 1. Schola ludus in modern form Educational multimedia programs with simulation components are not just a modern replacement for traditional textbooks. They are an entirely new teaching aid that allows vivid examination of the studied problem by means of educational simulation games. The internet as a distribution medium can make these new teaching aids easily available worldwide. A combination of the internet, a multimedia environment serving as an audio and visual user interface, with simulative models allows clarifi cation of the dynamic relations between studied terms to students connected to the magical internet network with the help of an educational simulation game. The integration of multimedia educational games into teaching brings about entirely new pedagogical opportunities, in particular when explaining complex interrelations and actively exercising practical skills and checking theoretical knowledge. In a simulation game, it is possible to test the behaviour of a simulated object without risk – e.g. try to land a virtual aircraft or, with medical simulators, treat a virtual patient or test the behaviour of physiological subsystems. An old Chinese proverb says: “That which I hear, I shall forget; that which I see, I shall remember; that which I do, I understand”. This old Chinese piece of wisdom is proved by modern teaching methods, sometimes called “learn by doing”, where simulation games play a major role. In addition, simulation games introduce an element of experience and a bit of playful enjoyment into teaching. This is the modern fi eld of application of John Amos Comenius’s old credo “Schola Ludus” (school as play) (Comenius, 1656] which was promoted by this European pedagogue as early as the 17th century (Fig. 1). Teaching with the help of simulation games available on the internet is common in physics or chemistry; the utilization of simulation games and simulators in biomedicine is rarer, which is probably due to the complexity of the necessary simulation models. Nonetheless, there are a number of educational applications with simulation games for medicine available on the internet. Many educational simulators of individual physiological subsystems can be found on the Web. For instance, there is ECGsim (http://www.ecgsim.org/download.html), a simulator that allows examining the generation and propagation of the electric potential in the ventricles and studying the origination mechanism of the ventricular QRS complex for various pathologies from heart blocks to ischaemias and infarctions (Oostendorp, 2004). Pressure circulation curves in the ventricles with various heart pathologies (valve defects, left or right heart failures) can be observed on a heart simulator from Columbia University (http://www.columbia.edu/itc/hs/medical/heartsim) (Burkhoff and Dickstein, 2002, Kelsey et al., 2002); simulators of anaesthesia machines from the University of Florida allow giving anaesthesia to a virtual patient (http://vam.anest.ufl .edu/) and monitoring related physiological responses, etc. (however, the more complex simulators require paid access). Figure 1: The combination of the internet and interactive graphics with simulation models in educational programs allows students to get “hands-on” experience with the studied problem in virtual reality. This is the modern fi eld of application for Comenius’s old credo – “School as play”. 2. Complex models for integrative physiology and education Pathophysiology teaching and the study of the pathogenesis of various pathological states can make good use of complex simulators including models of not only individual physiological subsystems but also their interconnection into a more comprehensive whole. The creation of such models was pioneered by Prof. Guyton, who used a mathematical model to describe the physiological regulations of the circulatory system and its broader physiological relations and links with the other subsystems in the body – the kidneys, volumetric and electrolyte balance control, oxygen transfer, nerve and endocrine control, etc. – in the Annual Review of Physiology in 1972 (Guyton et al., 1972). Guyton’s model, which we described in detail in the previous chapter of this book, was the fi rst extensive mathematical description of the physiological functions of interconnected body subsystems and launched the fi eld of physiological research that is sometimes described as integrative physiology today. The model was not of purely theoretical importance – Guyton soon realized the great signifi cance of models used as specifi c teaching aids. Guyton and his disciples continued developing the model. In 1982, Guyton’s colleague Thomas Coleman created the “Human” model intended mainly for educational purposes. The model allowed simulating a number of pathological states (cardiac and renal failure, haemorrhagic shock, etc.) and the effect of certain therapeutic interventions (infusion therapy, the effect of some medicines, blood transfusion, artifi cial pulmonary ventilation, dialysis, etc.) (Coleman and Randal, 1983). Meyers et al. (2008) have recently made Coleman’s original model available on the Web by implementing it in Java. In 2005, Coleman et al. published a large educational simulator, Quantitative Circulatory Physiology (QCP) which they made freely accessible on the Web (http://physiology.umc.edu/themodelingworkshop/) to support its use as a medical teaching aid (Abram et al., 2007), see Fig. 2. Figure 2: The environment of the Quantitative Human Physiology educational simulator. The simulator offers monitoring of hundreds of variables, but is diffi cult to control and requires study of the extensive simulator structure as well as good knowledge of which processes need to be monitored during simulations of certain pathological states. This was further expanded into the Quantitative Human Physiology educational simulator including more than 4,000 variables, which is probably the largest model of physiological regulations available today (Coleman et al, 2008, Hester et al. 2008) We have also been engaged in the development of complex educational models for medical training and previously created the “Golem” educational simulator, which was based on a complex model of integrated physiological controls (Kofránek et al, 2001). Our “Golem” simulator focused primarily on teaching complex disorders of the inner environment (Kofránek et al., 2005). 3. Simple is better However, experience with the deployment of complex models in teaching has shown that large, complicated models have a signifi cant disadvantage from the didactic point of view in that they are diffi cult to control. The large numbers of input variables and wide range of possibilities in monitoring output variables require that the user have a deeper understanding of the actual structure of the simulation model and know which processes need to be monitored during simulations of certain pathological states. Otherwise the complex, sophisticated model will seem just a “complicated and hard to understand technical toy” to users (similarly to when you place them in front of a complex airliner simulator with no previous theoretical tra",,2009.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
aeb54c3ac5b8cf2ca4bcdea391811f8f596568df,https://www.semanticscholar.org/paper/aeb54c3ac5b8cf2ca4bcdea391811f8f596568df,Scalable Wall-Socket Multimedia Grid Computing,"Multimedia data is rapidly gaining importance along with recent deployment of publicly accessible digital tele vision archives, and surveillance cameras in public locations. In a few years, analyzing the content of multimedia data will be a problem of phenomenal proportions, as digital video may produce high data rates, and multimedia archives steadily run into Petabytes of storage space. Consequently, for urgent problems in multimedia content analy sis, Grid computing is rapidly becoming indispensable. For the last decade, theasyand efficient use of distributed resources (ultimately at a world-wide scale) has been the foremost visionary aim (or ’promise’) of the field of Grid computing. Today, with the advent of easy-to-use programming models and run-time systems, as developed by this proposal’s team members, Grids indeed are maturing towards a viable commodity for non-experts in highperformance computing. Moreover, our current results indicate that, particularly with the increasing deployment o f high-speed optical networks, efficient world-wide execution of massively communicating distributed applications is achievable. In other words, realization of the ’promise of the Grid’ is now finally within reach. This proposal aims to realize easy, efficient, and scalable distributed supercomputing for the multimedia domain. It does so by integrating several solutions that are designed t o remove the intrinsic difficulties of large-scale employmen t of Grids. Specifically, we aim to develop an application in which a digital camera (potentially as part of a robot system) is capable of real-time ’recognition’ of objects from a set of learned objects, while being connected to a largescale Grid system comprising of cluster computers located in Europe, and potentially even world-wide. Apart from the appealing nature of a demonstration including visual infor mation (i.e., the camera data) and speech (i.e., the real-ti me reaction of the system), we aim to show true Wall-Socket Grid Computing— meaning that the application is being compiled and started on a local desktop machine, with Grid resources being employed entirely transparently. 1 Application domain and technologies This is a time of transition in which information is more and more composed of multimedia items , i.e. a combination of pictorial, textual, and auditory data. The computer ized access to the content of such information is generally recognized as a tremendous challenge [6]. This is because the automatic deduction of semantics from multimedia data requires sophisticated techniques for data structuring, t ransformation, analysis, classification, and learning. In part icular, due to the nature of the data, the challenge is to discove r and interpret tiny fractions of useful information in a whir lwind of meaningless noise. Given the increasing storage and connectivity of multimedia data, automatic multimedia content analysis (MMCA) is becoming an ever more important research area. Multimedia content analysis considers all aspects of the automated extraction of new knowledge from multimedia data streams and archives. This proposal concentrates on image and video, as these contain the bulk of all data. Research in this area has made a giant leap forward with the introduction of machine learned multimedia analysis, yiel ding automatic categorization by visual object types, such a s human faces, cars, interviews, etcetera [7]. Fundamental MMCA research questions include: • Can we automatically find genres in images from a statistical evaluation of large image sets? • Can we learn to find objects in images and video streams from partially annotated image sets? Scientifically, these questions deal with the philosophica l foundations of cognition and the naming of things. Practically, solutions are urgently needed given the increasin g volume of multimedia data. 1.1 Color-based object recognition The path to finding computerized MMCA solutions that can compete with the visual capabilities of the human brain is littered with many fundamental problems. One such problem — which is the focus of this proposal — is that of",,2008.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
00725201a37656dfee3b3e77027f27fdb326f2dc,https://www.semanticscholar.org/paper/00725201a37656dfee3b3e77027f27fdb326f2dc,Evaluation of classifiers: Practical considerations for security applications,"In recent years several tools based on statistical methods and machine learning have been incorporated in security related tasks involving classification, such as intrusion detection systems (IDSs), fraud detection, spam filters, biometrics and multimedia forensics. Measuring the security performance of these classifiers is an essential part for facilitating decision making, determining the viability of the product, or for comparing multiple classifiers. There are however relevant considerations for security related problems that are sometimes ignored by traditional evaluation schemes. In this paper we identify two pervasive problems in securityrelated applications. The first problem is the usually large class imbalance between normal events and attack events. This problem has been addressed by evaluating classifiers based on cost-sensitive metrics and with the introduction of Bayesian Receiver Operating Characteristic (B-ROC) curves. The second problem to consider is the fact that the classifier or learning rule will be deployed in an adversarial environment. This implies that good performance on average might not be a good performance measure, but rather we look for good performance under the worst type of adversarial attacks. In order to address this notion more precisely we provide a framework to model an adversary and define security notions based on evaluation metrics.",AAAI 2006,2006.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6dcc62c6b120995982f2c8b98b95a2e246bbcf69,https://www.semanticscholar.org/paper/6dcc62c6b120995982f2c8b98b95a2e246bbcf69,SUPPORT SELF-DIRECTED LEARNING OF INDUSTRIAL TECHNOLOGY : AN EXAMPLE FROM MICROTECHNOLOGY,"Most technological education relies on “cookbook”-oriented practice that provides students with a technical question, the procedure to address the question, the expected results of the experiment, and even an interpretation of those results. The purpose is to get familiar with the existing technologies. However, technologies are currently undergoing dynamic developments. The fundamental pedagogical approaches of technological education must change from “technologypracticing,” into “enhancing students’ problem solving ability,“ through practical activities. Selfdirected learning is to encourage students to learn inductively with the help of teaching systems. This method gives students more freedom to come up with a question to investigate, devise an experimental procedure, and decide how to interpret the results. Effective, or successful, self-directed learning depends on information gathering, information monitor students’ processing and other cognitive activities, and in the way they react to information. Thus, an e-learning system is developed to provide learning content with multimedia to the students, offer good support in asynchronous communication and information gathering. Further, virtual technology is applied to virtually represent the concept of frontal learning. The capability of the developed virtual environments is to offer experiential learning, simulation-based learning, and guided exploratory learning. Finally, a wireless sensor network was deployed in the laboratory to collect real-time information of students’ activities and machine operation conditions. The impact of the proposed methodology on student learning outcomes was examined. Generally, the proposed methodology is beneficial to the technological education.",,,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
cce600d54ef32b3f6312b9166da097e0f9eded8a,https://www.semanticscholar.org/paper/cce600d54ef32b3f6312b9166da097e0f9eded8a,Designing a Visual Analytics System for Industry-Scale Deep Neural Network Models,"The complexity of industry-scale deep learning models and datasets pose unique design, visualization, and system challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have designed, developed, and deployed ACTIVIS, a visual analytics system for interpreting industry-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both instanceand subset-level. ACTIVIS has been deployed on Facebook’s machine learning platform. This article is a summary for the VAST’17 paper (TVCG track) ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models [2]. 1 DESIGNING FOR INDUSTRY-SCALE MODELS Despite the increasing interest in developing visualization tools for deep learning interpretation [5–7], the complexity of large-scale models and datasets used in industry pose unique design challenges that are inadequately addressed by existing work. For example, while most existing visualization tools target image datasets, deep learning tasks in industry often involve different types of data, including text and numerical data. Furthermore, in designing tools for realworld deployment, it is a high priority that the tools be flexible and scalable, adapting to the wide variety of models and datasets used. These observations motivate us to design and develop ACTIVIS [2], a visual analytics system for deep neural network models, now deployed on Facebook’s machine learning platform. Since the ACTIVIS project started in April 2016, we have conducted participatory design sessions with over 15 Facebook engineers, researchers, and data scientists across multiple teams to learn about their visual analytics needs. We identified six key design challenges — for data, model, and analytics — that have not been adequately addressed by existing deep learning visualization tools. The challenges include the need to support: (1) diverse input data sources, (2) high data volume, (3) complex model architecture, (4) a great variety of models, (5) diverse subset definitions for analytics, and (6) both instanceand subset-level analyses. These challenges shape the main design goals of ACTIVIS. 2 ACTIVIS CONTRIBUTIONS ACTIVIS’s main contributions include: • A novel visual representation that unifies instanceand subsetlevel inspections of neuron activation, facilitating comparison of activation patterns for multiple instances. *e-mail: kahng@gatech.edu †e-mail: mortimer@fb.com ‡e-mail: adityakalro@fb.com §e-mail: polo@gatech.edu • An interface that tightly integrates an overview of graph-structured complex models and local inspection of neuron activations, allowing users to explore the model at different levels of abstraction. • A deployed system scaling to large datasets and models. • Case studies with Facebook engineers and data scientists that highlight how ACTIVIS helps them with their work. ACTIVIS’s multiple coordinated views help users get a high-level overview of the model from which the user can drill down to perform localized inspection of activations. ACTIVIS visualizes how neurons are activated by user-specified instances or instance subsets, to help users understand how a model derives its predictions. The subsets can be flexibly defined using data attributes, features, or output results, enabling model inspection from multiple angles. While many existing deep learning visualization tools support instancelevel exploration [6, 7], ACTIVIS is the first tool that simultaneously supports instanceand subset-level exploration. Both exploration strategies are common and effective, and they offer complementary analytics benefits. Instance-based analysis instructs how individual instances contribute to a model’s accuracy, but it is tedious to inspect many instances one by one. Subset-based analysis leverages input features or instance subsets to help reveal relationships between data attributes and machine learning algorithms’ outputs [3]. It is especially beneficial when dealing with huge datasets in industry, which may consist of millions or billions of data points. By exploring instance subsets and enabling their comparison with individual instances, users can learn how them models respond to many different slices of the data. We refer our readers to the longer version of our ACTIVIS [2] VAST’17 paper published in IEEE Transactions on Visualization and Computer Graphics.",,2017.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
03400cf04472dcb7d26064041b12eb5fd84d2963,https://www.semanticscholar.org/paper/03400cf04472dcb7d26064041b12eb5fd84d2963,Marginalised Stacked Denoising Autoencoders for Robust Representation of Real-Time Multi-View Action Recognition,"Multi-view action recognition has gained a great interest in video surveillance, human computer interaction, and multimedia retrieval, where multiple cameras of different types are deployed to provide a complementary field of views. Fusion of multiple camera views evidently leads to more robust decisions on both tracking multiple targets and analysing complex human activities, especially where there are occlusions. In this paper, we incorporate the marginalised stacked denoising autoencoders (mSDA) algorithm to further improve the bag of words (BoWs) representation in terms of robustness and usefulness for multi-view action recognition. The resulting representations are fed into three simple fusion strategies as well as a multiple kernel learning algorithm at the classification stage. Based on the internal evaluation, the codebook size of BoWs and the number of layers of mSDA may not significantly affect recognition performance. According to results on three multi-view benchmark datasets, the proposed framework improves recognition performance across all three datasets and outputs record recognition performance, beating the state-of-art algorithms in the literature. It is also capable of performing real-time action recognition at a frame rate ranging from 33 to 45, which could be further improved by using more powerful machines in future applications.",Sensors,2015.0,10.3390/s150717209,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
45dc2fedaf830f59d05113f958b45b65f5360ffc,https://www.semanticscholar.org/paper/45dc2fedaf830f59d05113f958b45b65f5360ffc,"Introduction to the Special Issue on Representation, Analysis, and Recognition of 3D Humans","Modeling, processing, recognizing, searching, and retrieving 3D human data (shapes, gestures, interactions) is a well-established research area in Multimedia. In the last decade, there has been a tremendous increase in opportunities for using 3D human data in medicine, security, and human computer interaction, largely driven by the development of effective devices and algorithms for recovering 3D data (e.g., Microsoft Kinect, Intel RealSense, Google Project Tango, and Apple Prime-Sense). Such rich information opens the way to new modes of experiential computing, interactive environments, as well as new multimedia content. This special issue is of interest to an interdisciplinary target audience as well interdisciplinary teams of contributors spanning: applied math, multimedia experiential computing, computational science and engineering, and application domain experts. Several fundamental research problems within the scope include: Representations for 3D static and dynamic human data Representations for non-rigid 3D objects (face, body) Temporal modeling of 3D face/body sequences Machine learning techniques for 3D human representations Computationally efficient strategies for resource constrained deployments Fusing multiple cues: shape, color, texture, motion etc. This special issue aims to bring together researchers interested in defining new and innovative solutions that advance the way 3D human data are used in multimedia computing, communications and applications such as human behavior understanding from 3D sensors, animation and entertainment, sports analytics, natural interaction, virtual and augmented reality. Application areas of interest include, but are not limited to:",ACM Trans. Multim. Comput. Commun. Appl.,2018.0,10.1145/3181709,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
42213008928a6190641f8bbe2f6c75637b47ad78,https://www.semanticscholar.org/paper/42213008928a6190641f8bbe2f6c75637b47ad78,Technology to the Rescue: A Software-Based Approach to Tackle Extreme Speech,,,2018.0,10.1007/978-3-319-60116-8_5,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
1bd64a7541e8d34f0d7782f0e786b2ffd78e55b7,https://www.semanticscholar.org/paper/1bd64a7541e8d34f0d7782f0e786b2ffd78e55b7,Interacting in various application domains,"eLearning and Education.- Arab Children's Reading Preference for Different Online Fonts.- Adaptation Decisions and Profiles Exchange among Open Learning Management Systems Based on Agent Negotiations and Machine Learning Techniques.- Accessing e-Learning Systems via Screen Reader: An Example.- Using Tablet PCs and Pen-Based Technologies to Support Engineering Education.- Optimal Affective Conditions for Subconscious Learning in a 3D Intelligent Tutoring System.- Computer-Based Learning to Improve Breast Cancer Detection Skills.- Virtual Classroom and Communicability: Empathy and Interaction for All.- Communicability for Virtual Learning: Evaluation.- Attention and Motivation in Hypermedia Systems.- A Web-Based, Interactive Annotation Editor for the eCampus Development Environment for SCORM Compliant E-Learning Modules.- An Innovative Way of Understanding Learning Processes: Eye Tracking.- A Set of Rules and Strategies for UNSAM Virtual Campus.- HCI Professional Involvement in k-12 Education: On Target or Missing the Mark?.- A Language Learning System Utilizing RFID Technology for Total Physical Response Activities.- Promoting Metacognition in Immersive Cultural Learning Environments.- The Application of the Flexilevel Approach for the Assessment of Computer Science Undergraduates.- Development of Ubiquitous On-Demand Study Support Environment for Nursing Students.- The Effects of Prior Knowledge on the Use of Adaptive Hypermedia Learning Systems.- Supporting Learners in Adaptive Learning Environments through the Enhancement of the Student Model.- The Concept of IMPRESSION: An Interactive Instruction System and Its Practice for Real-Time Distance Lessons between U.S. and Japan.- Improving Children's Writing Ability.- From Paper to Module - An Integrated Environment for Generating SCORM Compliant Moodle Courses Out of Text and Multimedia Elements.- Development of a Simulator of Abacus: Ancient Analog Calculator on a Mobile Phone as a Teaching Material.- A Proposal for a Framework for an e-Alumni Program Using SNS.- Supporting End-User Development of Personalized Mobile Learning Tools.- Didactic Models as Design Representations.- Interactive Learning Panels.- WebELS: A Content-Centered E-Learning Platform for Postgraduate Education in Engineering.- A Pen-Based Teaching System for Children and Its Usability Evaluation.- Development of a Visualised Sound Simulation Environment: An e-Approach to a Constructivist Way of Learning.- Games and Entertainment.- Causal Links of Presence.- Games Design Principles for Improving Social Web Applications.- A Multiple-Level 3D-LEGO Game in Augmented Reality for Improving Spatial Ability.- An Online Survey System on Computer Game Enjoyment and Personality.- Playability Testing of Web-Based Sport Games with Older Children and Teenagers.- Exploring the Elements and Design Criteria of Massively-Multiplayer Online Role-Playing Game (MMORPG) Interfaces.- Healthcare Game Design: Behavioral Modeling of Serious Gaming Design for Children with Chronic Diseases.- Analyzing Human Behaviors in an Interactive Art Installation.- The Effects of Quest Types and Gaming Motivations on Players' Knowledge Acquisitions in an Online Role-Playing Game Environment.- Self-movement Feeling Generation in Sports Watching with Screen Movement via Pan-Tilt Steerable Projector.- Design of Interactive Emotional Sound Edutainment System.- Understanding Online Game Addiction: Connection between Presence and Flow.- The Experience of Presence in 3D Web Environment: An Analysis of Korean Second Life.- Influence of Real-World Ten-Pin Bowling Experience on Performance during First-Time Nintendo Wii Bowling Practice.- Emotionally Adapted Games - An Example of a First Person Shooter.- DiamondTheater: A System for Reproducing Theater and Supporting Creative Activities.- Work, Collaboration and Business.- New Health Information Systems (HIS) Quality-in-Use Model Based on the GQM Approach and HCI Principles.- An Information Visualization Approach to Hospital Shifts Scheduling.- Designed to Fit: Challenges of Interaction Design for Clothes Fitting Room Technologies.- Usability for Poll Workers: A Voting System Usability Test Protocol.- CAD and Communicability: A System That Improves the Human-Computer Interaction.- A Novel Visualization Tool for Evaluating Medication Side-Effects in Multi-drug Regimens.- Design of a Web Intervention to Change Youth Smoking Habits.- Smart Makeup Mirror: Computer-Augmented Mirror to Aid Makeup Application.- Studying Reactive, Risky, Complex, Long-Spanning, and Collaborative Work: The Case of IT Service Delivery.- Human Computer Interaction in Virtual Standardized Patient Systems.- Towards Standardized Pen-Based Annotation of Breast Cancer Findings.- ImproV: A System for Improvisational Construction of Video Processing Flow.- E-Assessment: A Suitable Alternative for Measuring Competences?.- Green Advocate in E-Commerce.- Gesture-Based Sharing of Documents in Face-to-Face Meetings.- Developing, Deploying and Assessing Usage of a Movie Archive System among Students of Film Studies.- Using Activity Descriptions to Generate User Interfaces for ERP Software.- Developing a Nomenclature for EMR Errors.- Mapping for Multi-source Visualization: Scientific Information Retrieval Service (SIRS).- Client-Side Visualization of Internet Forums for Information Retrieval.- Social-Technical Tools for Collaborative Sensemaking and Sketching.- Developing Some User Interfaces of TV under Enormous Channels Environment.- Electronic Glassboard - Conception and Implementation of an Interactive Tele-presence Application.- A New Automatic Teller Machine (ATM) Proposal through the Analysis of ATMs of Three Banks.- Advanced Applications.- Designing Usable Bio-information Architectures.- Run-Time Adaptation of a Universal User Interface for Ambient Intelligent Production Environments.- Heuristic Evaluation of Mission-Critical Software Using a Large Team.- Interface Development for Early Notification Warning System: Full Windshield Head-Up Display Case Study.- Reflections on the Interdisciplinary Collaborative Design of Mapping the Universe.- Distilling Support Opportunities to Improve Urban Search and Rescue Missions.- A New Approach to Design an Interactive System for Molecular Analysis.- The Differences of Aviation Human Factors between Individualism and Collectivism Culture.- Web-Based Training System for Improving Aviation Maintenance Performance.- Allocating Human-System Interfaces Functions by Levels of Automation in an Advanced Control Room.- Development of an Expert System as a User Interface for an RFID Application.- Developing a Validation Methodology for Educational Driving Simulators and a Case Study.- Developing a Usable Mobile Flight Case Learning System in Air Traffic Control Miscommunications.",,2009.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ea89d5ab69627a9361a340d43866cc0950a50fa1,https://www.semanticscholar.org/paper/ea89d5ab69627a9361a340d43866cc0950a50fa1,Distributed Learning Algorithms for Sensor Networks,"Wireless sensor networks have received significant attention in the last decade owing to their widespread use not only in monitoring the physical world but also in surveillance. The energy and communication constraints of sensor nodes, coupled with distributed processing of sensed signals, lead to challenges in developing effective methods to perform desired inference tasks such as object detection or classification. Further, the lack of well-calibrated sensors is a major obstacle for the rapid deployment of sensor networks. This dissertation develops gossip-based learning algorithms for distributed signal processing in sensor networks. In gossip-based algorithms, sensor nodes share information with local neighbors to converge upon common knowledge about the sensed environment. Gossip-based methods allow for manageable communication among energy-constrained nodes and also accommodate changing network communication topologies. We consider three related problems and develop gossip-based processing solutions. We first consider the problem of joint signature estimation and node calibration using distributed measurements over a large-scale sensor network. We develop a new Distributed Signature Learning and Node Calibration algorithm, called D-SLANC, which estimates the signature of a commonly-sensed source signal and simultaneously estimates calibration parameters local to each sensor node. The approach we take is ii to model the sensor network as a connected graph and make use of the gossip-based distributed consensus to update the estimates at each iteration of the algorithm. We prove convergence of the algorithm to the centralized data pooling solution. We also compare its performance with the Cramér-Rao bound (CRB), and study the scaling performance of both the CRB and the D-SLANC algorithm. Secondly, we develop a gossip-based algorithm for distributed `1-optimization in a large-scale sensor network setting. Specifically, we consider sensor nodes which can measure only a part of the entire measurement vector. We formulate the `1optimization problem as quadratic optimization and develop a distributed, gossipbased algorithm using the projected-gradient approach. We analyze the performance of the proposed algorithm using synthetic data and compare it with a standard `1 solver. Third, we consider the problem of distributed classifier learning in a large-scale sensor network setting. We adopt a machine learning approach to the problem and develop a distributed, gossip-based algorithm that learns the optimal (large-margin) hyperplane separating the two classes, using the projected-gradient approach. We illustrate the performance of the proposed algorithm using both synthetic and realworld datasets.",,2010.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6f070c05dbd342d3906ee2fbdd2c3529ed558851,https://www.semanticscholar.org/paper/6f070c05dbd342d3906ee2fbdd2c3529ed558851,Designing and evaluating techniques to mitigate misinformation spread on microblogging web services,"Online social media is a powerful platform for dissemination of information during important realworld events. Beyond the challenges of volume, variety and velocity of content generated on online social media, veracity poses a much greater challenge for effective utilization of this content by citizens, organizations, and authorities. Veracity of information refers to the trustworthiness / credibility / accuracy / completeness of the content. Over last few years social media has also been used to disseminate misinformation in the form of rumors, hoaxes, fake images, and videos. We aim to address this challenge of veracity or trustworthiness of content posted on social media. The spread of such untrustworthy content online has caused the loss of money, infrastructure and threat to human lives in the offline world. We focus our work on Twitter, which is one of the most popular microblogging web service today. We provide an in-depth analysis of misinformation spread on Twitter during real-world events. We propose and evaluate automated techniques to mitigate misinformation spread in real-time. The main contributions of this work are: (i) we analyzed how true versus false content is propagated through the Twitter network, with the purpose of assessing the reliability of Twitter as an information source during real-world events; (ii) we showed the effectiveness of automated techniques to detect misinformation on Twitter using a combination of content, meta-data, network, user profile and temporal features; (iii) we developed and deployed a novel framework for providing indication of trustworthiness / credibility of tweets posted during events. We evaluated the effectiveness of this real-time system with a live deployment used by real Twitter users. First, we analyzed Twitter data for 25+ global events from 2011-2014 for the spread of fake images, rumors, and untrustworthy content. Some of the prominent events analyzed by us are: Mumbai blasts (2011), England Riots (2011), Hurricane Sandy (2012), Boston Marathon Blasts (2013), Polar Vortex (2014). We identified tens of thousands of tweets containing fake images, rumors, fake websites, and by malicious user profiles for these events. We performed an in-depth characterization study of how this false versus the true data is introduced and disseminated in the Twitter network. Second, we showed how features of meta-data, network, event and temporat from user-generated content can be used effectively to detect misinformation and predict its propagation during realworld events. Third, we proposed and evaluated an automated methodology for assessing credibility of information in tweets using supervised machine learning and relevance feedback approach. We developed and deployed a real-time version in TweetCred, a system that assigns a credibility score to tweets. TweetCred, available as a browser plug-in, has been installed and used by 1,808 real Twitter users. During ten months of its deployment, the credibility score for about 12 million tweets was computed, allowing us to evaluate TweetCred in terms of accuracy, performance, effectiveness and usability. The system TweetCred built as part of this thesis work is used effectively by emergency responders, firefighters, journalists and general users to obtain credible content from Twitter. This thesis work has shown that measuring credibility of the Twitter content is possible using semi-automated techniques, and the results can be valuable to the real-world users. The insights obtained from this research and deployment provide a basis for building more sophisticated technology to tackle similar problems on different social media.",,2015.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3df4dbc3c7bfd09e74cce9491c4604f14126cd1b,https://www.semanticscholar.org/paper/3df4dbc3c7bfd09e74cce9491c4604f14126cd1b,"Interactions and Networks in the Context of Flexible Learning RESOURCES , ACTIVITIES , INTERACTIONS AND NETWORKS IN THE CONTEXT OF FLEXIBLE LEARNING","As part of flexible learning strategies, the ability to deliver courses over the Internet is growing at a rapid rate as the number of users, schools and tertiary institutions who are online increases proportionally to the sale of multimedia computers and modems. The cost of building these courses is both expensive and time consuming. At present the ability to deliver high quality sound and vision on the web is increasing and the demand for more authentic, engaging and dynamic learning environments is growing. Unfortunately, most users are limited in their access to the Internet, and the cost and time spent online waiting for a sound or video to download is both very distracting and frustrating. It breaks up the flow of concentration and the thread of learning. A strategy to consider in the design and deployment of on-line learning environments is to locate high quality resources and learning activities onto a CD-ROM and provide a link between them so the user has a seamless experience. The CD-ROM then acts as an active learning environment with a storehouse of information (resources) contained on it, which the user can navigate through to build knowledge. This can be done by using a number of key features such as Graphical Navigation landscapes, Iconic Metaphors, Intelligent Software Learning Agents, Vignettes, Keywords, and Glossaries all containing various types of media such as, video, sound, text and graphics, plus On-line web links to key external resources. At present standard CD-ROM’s can hold up to 650 Mb of information and multiple platform capability. By developing high quality resources and learning activities independently of the learning objectives, and storing them on a CD-ROM the user is able to access information rapidly and efficiently on their own local machine or via links to the Intranet/Internet network. The development of a CD-ROM with no preset learning objectives gives the activities and resources a long-range shelf life. Akin to an information bank (analogous to a library) this storehouse of information could be available to a broad section of disciplines and is only limited by the number of learning objectives and performance outcomes that can be developed by the educator. The key to the flexibility for this mode of learning is the use of the web as a delivery platform for the course. Learning objectives, key activities, evaluation and feedback can now be run online. This provides maximum learning flexibility so that the course can be changed each time with a new set of learning objectives and questions, or it could be incorporated into other courses or disciplines. This paper will present examples of how this can be implemented into a teaching and learning strategy using projects and CD-ROM’s that are part of these flexible learning environments.",,1998.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
d1e3e0e6c0b1a4b51d4891b226ce31c5013dc6cb,https://www.semanticscholar.org/paper/d1e3e0e6c0b1a4b51d4891b226ce31c5013dc6cb,A cognitive accountability mechanism for penalizing misbehaving ECN‐based TCP stacks,"The introduction of high‐bandwidth demanding services such as multimedia services has resulted in important changes on how services in the Internet are accessed and what quality‐of‐experience requirements (i.e. limited amount of packet loss, fairness between connections) are expected to ensure a smooth service delivery. In the current congestion control mechanisms, misbehaving Transmission Control Protocol (TCP) stacks can easily achieve an unfair advantage over the other connections by not responding to Explicit Congestion Notification (ECN) warnings, sent by the active queue management (AQM) system when congestion in the network is imminent. In this article, we present an accountability mechanism that holds connections accountable for their actions through the detection and penalization of misbehaving TCP stacks with the goal of restoring the fairness in the network. The mechanism is specifically targeted at deployment in multimedia access networks as these environments are most prone to fairness issues due to misbehaving TCP stacks (i.e. long‐lived connections and a moderate connection pool size). We argue that a cognitive approach is best suited to cope with the dynamicity of the environment and therefore present a cognitive detection algorithm that combines machine learning algorithms to classify connections into well‐behaving and misbehaving profiles. This is in turn used by a differentiated AQM mechanism that provides a different treatment for the well‐behaving and misbehaving profiles. The performance of the cognitive accountability mechanism has been characterized both in terms of the accuracy of the cognitive detection algorithm and the overall impact of the mechanism on network fairness. Copyright © 2012 John Wiley & Sons, Ltd.",Int. J. Netw. Manag.,2012.0,10.1002/nem.1806,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
4867a63e5edd7ee10f28067d6dd5b07d69321de7,https://www.semanticscholar.org/paper/4867a63e5edd7ee10f28067d6dd5b07d69321de7,Thesis Title: A Framework for Improving the Performance of Signature-based Network Intrusion Detection Systems,"Network Intrusion detection systems (NIDSs) have been widely deployed in different network environments (e.g., banks, schools) to defend against a variety of network attacks (e.g., Trojans, worms). Generally, a network intrusion detection system can be classified into two categories: signature-based NIDS and anomaly-based NIDS. In realworld applications, the signature-based NIDS is more prevalent than the anomaly-based detection as the false alarm rate of the former is much lower than the latter. However, we identify three major issues that can greatly affect the performance of a signature-based NIDS. Expensive signature matching. The traditional signature matching in a signature-based NIDS is too expensive that the computing burden is at least linear to the size of an incoming string. Therefore, the operational burden of a signature-based NIDS could be significantly increased in a large-scale network environment. Overhead network packets. In a large-scale network environment, a signature-based NIDS usually has to drop lots of network packets since the number of incoming packets exceeds its maximum processing capability. Massive false alarms. Although the false alarm rate of a signature-based NIDS is much smaller than that of an anomaly-based NIDS. The number of false alarms generated by a signature-based NIDS can still increase the difficulty in analyzing true alarms and adversely affect the analysis results. To mitigate the above issues, in this thesis, we propose several approaches in improving the performance of a signature-based NIDS such as Snort in the following three aspects: Signature matching improvement.We design an exclusive signature matching scheme to help perform a more efficient signature matching with the purpose of enhancing the performance of signature matching in a heavy traffic environment. Network packet filtration and reduction. To mitigate this issue, we advocate the method of constructing a packet filter such as blacklist-based packet filter, list-based packet filter and trust-based packet filter to help filter out target network packets for a signature-based NIDS such as Snort in terms of IP reputation. This packet filter can be deployed in front of a signature-based NIDS and reduce its workload in an intensive traffic network. False alarm reduction. To resolve this issue, we design several false alarm filters such as machine-learning based false alarm filters, alarm filters using knowledge-based alert verification and context-based alarm filters to help reduce false alarms (or non-critical alarms) that are generated by a signature-based NIDS. A Framework. In addition, we further propose a framework by combining the above work to overall improve the performance of a signature-based NIDS such as Snort. As a case study of the framework, we implement an enhanced filter mechanism (shortly EFM) that consists of three major components: a context-aware blacklist-based packet filter, an exclusive signature matching component and a KNN-based false alarm filter. In particular, the component of context-aware blacklist-based packet filter is responsible for filtering out network packets in terms of IP reputation. The exclusive signature matching component is implemented in the context-aware blacklist-based packet filter and aims to speed up the signature matching. At last, the component of KNN-based false alarm filter is responsible for filtering out false alarms which are produced by the context-aware blacklist-based packet filter and the NIDS. In the evaluation, the experimental results demonstrate that our framework is promising and by deploying with the EFM, the performance of a signature-based NIDS such as Snort can be improved in the aspects of network packet filtration, signature matching improvement and false alarm reduction.",,2013.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
6a8711d3b59ee507ed05bc6bef75720681007924,https://www.semanticscholar.org/paper/6a8711d3b59ee507ed05bc6bef75720681007924,TeekoTeacher : A Tool for Learning Good Teeko Strategies,"Teeko is a two-player zero-sum game with perfect information. The game tree complexity and the estimated state space complexity place it roughly in the same class with games such as Connect-4, Awari and Othello. This paper presents an educational tool (‘TeekoTeacher’) capable of teaching good Teeko strategies to human players. TeekoTeacher uses a database of moves created by another application (‘TeekoPlayer’, a Teeko playing program.) TeekoTeacher is an interactive GUI-driven and convenient web based (Java applet) tool that allows human players to play against themselves and to learn proposed moves. The paper also discusses the relevance of the tools and methods used to address other issues of E-Learning. Introduction Distance learning is an educational paradigm in which the instructor and students are geographically remote from each other. E-learning (also called ‘online learning’) is a distance learning technique that uses the Internet as the medium for delivering the course materials and teacher-student interaction. Benefits of E-learning (NIIT, 2003) include flexibility, convenience, accessibility, inexpensive worldwide distribution, travel cost/time savings, and ease of updating course materials. Issues relating to E-learning include the bandwidth limitations of the communication channel, and the resources (including time and money) invested in research, development, deployment, and maintenance of the tools. In a typical E-learning scenario, students would use their computers to connect to the content providers (online classrooms.) In addition to standard text content, these online classrooms usually utilize various multimedia tools to enhance the overall learning experience. The tools are divided (ClassesUSA, 2003) into: synchronous (require teacher’s real-time participation and interaction; examples: chat rooms, interactive TV and audio/video conferencing) and asynchronous (don’t require teacher’s real-time participation; examples: email, message boards, audio/video streams and interactive computer games.) Elearning implementations usually contain both types of tools. One example of an asynchronous e-learning tool is an interactive computer game. In general, in addition to the previously mentioned benefits, games provide an entertaining interaction during which the learning material is delivered implicitly. Strategic games are of special interest to E-learning applications because, by their nature, they don’t require big bandwidth and short network latency. Another interesting and important aspect of strategic games is that good strategies can be learned both from the game experts and during autonomous play. The general idea behind this paper follows from the previous paragraph: first, use machine learning to learn and then use E-learning to deliver the learned content. In this case, the content is a set of good game strategies. We present this ‘learning cycle’ using a simple strategic game Teeko. First, we present the game and its rules. Then, we describe a program TeekoPlayer that plays the game and learns how to play better. Finally, we present an interactive tool TeekoTeacher that takes advantage of the knowledge generated by TeekoPlayer and teach humans the learned good strategies extracted from that knowledge. About Teeko The game Teeko was invented in the middle of the 20 century and the game gained some popularity during the 1950’s (Scarne, 1955.) Scarne stated that the game is as playable as some older and more established board games like Checkers, Chess and Go. He was predicting a very bright future for the game and, according to him, some very popular celebrities already played it (Humphrey Bogart and Marilyn Monroe among others.) The game was also somewhat popular in the beginning of the Internet era because it was quite convenient to play it over the emerging email system. Using the terminology from Game Theory, Teeko can be classified as a two-player zero-sum deterministic sudden-death strategic game with perfect information and perfect memory. The rules of socalled ‘standard’ Teeko are relatively simple. The game is played on a 5×5 chess-like board. Each player has four equal pieces. The first four moves define the opening phase and usually no one wins at this point (although some trivial wins are theoretically possible.) During this phase, each player alternatively puts one piece on an unoccupied field on the board. The pieces are then to be moved only to unoccupied adjacent fields. The goal of the game is to make a four in a row, column, diagonal or 2×2 square. It’s easy to calculate that the total number of winning positions is 44. At the end of 1998, Teeko has been solved using a brute force method (Steele, 1998.) The solution was ‘a draw.’ This means that both players can guarantee not losing the game. The solving algorithm required about 200 MB of RAM and about 32 hours of computing time on a machine with a 300MHz Sun UltraSPARC CPU. Learning Teeko: TeekoPlayer Computer Program The first encounter with Teeko the authors had, was during creation of the ‘TeekoPlayer’ program (Despotovi , 2001.) The high-level research goal was to revisit an important artificial intelligence debate known as ‘search versus knowledge.’ Namely, we wanted to try to apply a combination of heuristic, searching and learning (with the emphasis on learning) to an algorithmic game theory problem and, in particular, to a specific game. We found Teeko to be an excellent test case for our experiments and applications of the theoretical results. TeekoPlayer was developed and used to examine the performance of the proposed learning algorithm. TeekoPlayer is a C program capable of playing, and learning to play better, the game of Teeko. The main features of TeekoPlayer are: • Plays the game of Teeko • Can play as the first or the second player • Has a ‘show/hide thinking’ option • Has the ability to learn in order to improve its game • Has on/off switches for heuristics, searching and learning modules • Has ‘self-play’ (the ability to play against itself) • Has ‘batch-play’ (the ability to play and record games without human intervention) • Keeps track of all games and makes convenient statistical data The main knowledge representation problems solved by TeekoPlayer are: • Storing and retrieving game positions • Storing and manipulating data generated by the learning algorithm • Generating all legal moves from a given position TeekoPlayer uses internal and external knowledge representation for game positions. Internally, TeekoPlayer handles all positions as 5×5 matrices. Externally, they are represented as chunks of a flat file (the ‘long-term memory.’) This file consists of one or more ‘memory elements’ each describing a position together with the number of games won and lost in which that position was a part of the strategy employed (we will refer to these numbers as winning and losing attributes of the position.) The fundamental idea was that TeekoPlayer should learn by adjusting these attributes during the course of many games. The game-playing engine consists of three main parts: • Heuristics module • Searching module • Learning module Heuristics module proposes heuristic moves such as ‘make four in a row’ or ‘make threatening three in a row.’ During the opening phase, only heuristic moves are used. They were obtained by formalizing the moves of human experts. Later, during the game, the heuristics module will be consulted for each position and, if it’s possible, this module will respond with a quick and efficient move. Searching module implements a simple one-move (ply and reply) look-ahead minimax algorithm. This algorithm examines the next two positions. Learning module implements the learning algorithm. The learning module uses ideas based on reinforcement learning (Sutton and Barto, 2000) and it takes advantage of the experience accumulated during the number of games played. This technique is also known as experience based learning (Jong and Schultz, 1988.) The learning algorithm is based on the following three concepts: • Storing. During the game, the learning module will be saving all visited positions into the short-term memory file. • Updating. After the game is finished, the learning algorithm will change the long-term memory according to the outcome of the game. If the game was a draw, no action will be taken. Otherwise, a lookup for each recorded position in the short-term memory file will be conducted in the long-term memory file. If the position cannot be found, it will be appended to the long-term memory file. Then, if the outcome of the game was won for the first player, the winning attribute will be increased by one; otherwise the losing attribute will be increased by one. • Recalling. Takes place during the game and its role is to recommend the position with the highest winning score reachable within one move from the current position. The final move is always decided by comparing the moves recommended by the heuristic module, the search module, and the learning module (if all of them are enabled.) If the learning module had a move to recommend, that move would be played. In this manner, we emphasize the impact of the learning algorithm to the overall style of play. In the general case, the learning module would not always have a move to recommend (or, it might have been simply disabled.) If this happens, TeekoPlayer will compare moves recommended by the heuristic and search modules (if enabled) and play the better one (in terms of the evaluation function used for the minimax search.) If there is no heuristic move to compare to, TeekoPlayer will play the move generated by the search module. The move selection process described above was very practical since all three modules could be independently turned on and off and provide a nice sandbox for conducting various ‘search vs. learning’ or ‘heuristics vs. search’ and other experiments. Picture 1: TeekoPlayer’s interactive and batch mode In the",,2007.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ee1c13885c18ec3b2e53df53f9da3e494739c06b,https://www.semanticscholar.org/paper/ee1c13885c18ec3b2e53df53f9da3e494739c06b,Preface,"Resource management has been a perpetual theme in wireless network design, deployment, and operations. In today’s wireless systems, data demands continue to grow with a diverse range of applications from bandwidth-hungry multimedia streaming, delay-sensitive instant messaging, and online gaming to bulk data transfer. The ever-increasing needs for high-speed ubiquitous network access by mobile users are further aggravated by emerging machine-to-machine communication for home and industrial automation, wide-area sensing and monitoring, autonomous vehicles, etc. Delivery of these rich sets of applications is fundamentally limited by resource scarcity in wireless networks that manifests at various levels. For instance, spectrum scarcity has emerged as a primary problem when trying to launch new wireless services. Vendors and operators are increasingly looking into millimeter radio bands for 5G cellular standard though the spectrum was previously considered unsuitable for wider area applications. Interferences among wireless transceivers in close proximity continue to pose challenges to the delivery of reliable and timely services. Mobile devices are inherently power-constrained, demanding efficient communication schemes and protocols. Many resource management solutions in wireless networks operate on the assumption that the decision makers have the complete knowledge of system states and parameters (e.g., channel states, network topology, and user density). When such information is unavailable or incomplete, probing or learning has to be conducted prior to the making of resource management decisions. As an example, in orthogonal frequency-division multiplexing (OFDM) systems, pilot signals are transmitted either along a dedicated set of subcarriers or a specific period across all subcarriers for channel estimation. This allows the adaption of subsequent transmissions to current channel conditions. Sequential learning, in contrast, is a paradigm where learning and decision-making are performed concurrently. The framework is applicable in a variety of scenarios where the utility of resource management resources follows single-parametrized independent and identically distributions, Markovian or unknown adversarial processes. It is a powerful tool in wireless resource management. Sequential learning and decision-making have been",Transactions. Medico-Chirurgical Society of Edinburgh,,10.1515/9781501736599-002,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0419ba0310ac083bdb277238c5800a059ccd142c,https://www.semanticscholar.org/paper/0419ba0310ac083bdb277238c5800a059ccd142c,The introduction of laptops in the teaching of mathematics and science in English under the Teaching and Learning of Science and Mathematics in English Programme ( Pengajaran dan,"The introduction of laptops in the teaching of mathematics and science in English under the Teaching and Learning of Science and Mathematics in English Programme (Pengajaran dan Pembelajaran Sains dan Matematik dalam Bahasa Inggeris, PPSMI) has been implemented by the Ministry of Education since 2003. The preliminary observations found that teachers are not fully utilising these facilities in their teaching. A survey was conducted to study the barriers preventing the integration and adoption of information and communication technology (ICT) in teaching mathematics. Six major barriers were identified: lack of time in the school schedule for projects involving ICT, insufficient teacher training opportunities for ICT projects, inadequate technical support for these projects, lack of knowledge about ways to integrate ICT to enhance the curriculum, difficulty in integrating and using different ICT tools in a single lesson and unavailability of resources at home for the students to access the necessary educational materials. To overcome some of these barriers, this paper proposes an e-portal for teaching mathematics. The e-portal consists of two modules: a resource repository and a lesson planner. The resource repository is a collection of mathematical tools, a question bank and other resources in digital form that can be used for teaching and learning mathematics. The lesson planner is a user friendly tool that can integrate resources from the repository for lesson planning. INTRODUCTION During the 2003 budget speech, the then Prime Minister of Malaysia, YAB Dato Seri Dr. Mahathir Mohamad, announced that the government had decided to implement the teaching of science and mathematics using the English language as the medium of instruction in school. The government allocated about 5 billion Ringgit from 2002 to 2008 for the above project. This allocation was to be used for teacher training, providing launching grants for schools as well as for educational aids which would include ICT equipment. In order to implement the project smoothly, the sum of 978.7 million Ringgit was spent in the year 2003 to purchase notebook computers, LCD projectors and other related equipment (Mahathir, 2002). Ittigson & Zewe (2003) cited that technology is essential in teaching and learning mathematics. ICT improves the way mathematics should be taught and enhances student understanding of basic concepts. Many researchers have carried out studies to evaluate the benefits of using ICT in mathematics. Becta (2003) summarised the key benefits – ICT promotes greater collaboration among students and encourages communication and the sharing of knowledge. ICT gives rapid and accurate feedbacks to students and this contributes towards positive motivation. It also allows them to focus on strategies and interpretations of answers rather than spend time on tedious computational calculations. ICT also supports constructivist pedagogy, wherein students use technology to explore and reach an understanding of mathematical concepts. This approach promotes higher order thinking and better problem solving strategies which are in line with the recommendations forwarded by the National Council of Teachers of Mathematics (NCTM); students would then use technology to concentrate on problem-solving processes rather than on calculations related to the problems (Ittigson & Zewe, 2003). MOJIT A Study on the Use of ICT in Mathematics Teaching 44 For a successful integration of ICT into the mathematics curriculum, it is essential to have knowledge of the existing software that is used by mathematics teachers. A survey carried out by Forgasz & Prince (2002) found that 61% of the respondents (teachers) used spreadsheets, 45% used word processing and 30% used Internet browsers. In the same survey, it was found that 19% used Geometer’s sketchpads, 19% used CD-ROMs that accompanied mathematics textbooks, 18% used Graphmatica, 14% used Maths Blaster and 8% used other mathematics-specific software. Knowledge of the use of software on the part of the teachers is not the only criterion for integrating ICT into mathematics lessons; a sound pedagogical knowledge on how to integrate it is another critical success factor. In a separate study, Jones (2004) found that seven barriers existed while integrating ICT into lessons. These barriers were (i) lack of confidence among teachers during integration (21.2% responses), (ii) lack of access to resources (20.8%), (iii) lack of time for the integration (16.4%), (iv) lack of effective training (15.0%), (v) facing technical problems while the software is in use (13.3%), (vi) lack of personal access during lesson preparation (4.9%) and (vii) the age of the teachers (1.8%). An analysis of the preventive maintenance record in one of the rural secondary schools revealed that the use of ICT equipment was too low, despite a large sum of public funds being used for the purchase. It was found that although nine LCD projectors were procured by the school, only six were available at the time of inspection. The total number of operation hours recorded by the machines was 174 hours for a period of two years. On average, each projector was then only used for about 29 hours in the two year duration which is considered to be very low (MHS, 2005). The main objective of this study was to help mathematics teachers in the integration of ICT into their teaching. The study aimed at identifying the most common ICT applications used by these teachers and how ICT was used in the class. It also aimed at understanding how the Internet was used by teachers, analysed their training needs and further assessed the level of ICT usage in instructional programmes. The barriers faced by teachers during the integration of ICT into mathematics lessons and their perception of the usefulness of an e-portal were also investigated. METHODOLOGY This research deployed a survey method to investigate the use of ICT and the barriers of integrating ICT into the teaching of mathematics. The survey was carried out during a mathematics in-service course conducted by the State Education Department. Before the commencement of the survey, the respondents were given a briefing on the purpose of the survey. A total of 111 responses was received and they were analysed using the SPSS statistical package. A questionnaire was adapted from the Teacher Technology Survey by the American Institute for Research (AIR, 1998). The questionnaire was divided into seven areas, i.e., (A) the teacher’s profile, (B) how teachers use ICT, (C) professional development activities, (D) the teacher’s ICT experience, (E) the level of use in ICT, (F) the barriers faced by teachers and (G) the proposed solution. RESULTS AND DISCUSSION ICT applications in general In general, a total of 71.1% of the respondents used computers on a regular basis. Table 1 depicts the percentage of usage by teachers in the various ICT applications: word processing packages (71.1%), spreadsheets (51.2%), Internet activity (44.1%), search engines (44.1%), presentation software (36.9%), drill and practice (24.3%), hypermedia/multimedia (22.5%), databases (21.6%), graphical applications (19.8%), simulation programmes (17.1%), desktop publishing (12.6%), Flash presentations (11.7%) and Java applets (6.3%). These percentages show that the computer literacy rate among secondary school mathematics teachers has been high. MOJIT A Study on the Use of ICT in Mathematics Teaching 45 Table 1: Common ICT Applications by Teachers Application Daily (%) Weekly (%) Monthly (%) 1 or 2 times a year (%) Never (%) NA (%) NR (%) Computers in general 25.2 22.5 23.4 17.1 2.7 3.6 5.4 Word processing packages 21.6 27.0 22.5 9.9 5.4 3.6 9.9 Spreadsheets 9.8 22.5 18.9 22.5 11.7 3.6 10.8 Databases 2.7 5.4 13.5 18.0 30.6 11.7 18.0 Graphical applications 1.8 6.3 11.7 20.7 27.9 9.9 21.6 Presentation software 2.7 12.6 21.6 28.8 18.9 6.3 9.0 Desktop publishing 1.8 3.6 7.2 18.9 38.7 8.1 21.6 Any Internet activity 12.6 13.5 18.0 20.7 18.9 5.4 10.8 Search engines for Internet 12.6 14.4 17.1 20.7 18.0 6.3 10.8 Hypermedia / Multimedia 3.6 8.1 10.8 18.9 32.4 8.1 18.0 Simulation programmes 0.9 3.6 12.6 12.6 38.7 10.8 20.7 Drill / Practice tutorials 1.8 6.3 16.2 16.2 34.2 9.0 16.2 Java applets 1.8 0.0 4.5 9.9 50.5 17.1 16.2 Flash presentations 1.8 0.9 9.0 17.1 45.0 12.6 13.5 NA – Not Available NR – No Response ICT applications in class 49.5% of the respondents used courseware in the class, 40.5% used ICT as presentation tools , 8.1% used ICT as a graphical visualising tool, 6.3% used ICT as an online demonstration tool and 3.6% used it for other purposes in class. About 29.7% of the respondents did not use ICT in the classroom. Table 2 shows the percentage distribution of ICT uses in the class Table 2: ICT Uses in the Class Application Using presentation tools Using courseware Using graphical visualising tools Online demos Others None Response (%) 40.5 49.5 8.1 6.3 3.6 29.7 Uses of Internet The Internet was used for various purposes. 68.5% respondents used it for browsing, 44.1% used the e-mail facility, 10.8% used chat rooms, 9.9% used IRC, 7.2% used it in discussion forums and 1.8% for other purposes. 17.1% respondents did not use the Internet. Table 3 depicts the details. Table 3: Use of Internet by Teachers Activity Browsing e-mail IRC Discussion forums Chat rooms Others None Response (%) 68.5 44.1 9.9 7.2 10.8 1.8 17.1 Professional development and training needs A total of 42.3% respondents indicated that they had received ICT training during 2002-2004. 71.2% of the respondents demonstrated that they had found the training to be generally useful while 64.9% said that they had not received training on how to integrate ICT into mathematics teaching. According to 33.3% of the respondents, mathematics teachers require training on how to integrate ICT into their teaching while 59.5% of them stated that they needed a combination of various types of training. Table 4 depicts the",,2005.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
88ea92d8b618525ff2a7815c08f0fc2c68d8daa2,https://www.semanticscholar.org/paper/88ea92d8b618525ff2a7815c08f0fc2c68d8daa2,Human Activity Inference via physical sensing in support of Industrial Equipment Maintenance,"The paper describes an active research project at Intel’s High Volume Manufacturing (HVM) facility located at Leixlip, Co. Kildare, Ireland. The project explores the practical aspects of deploying RFID transponders, subtle sensing platforms and machine learning based inferencing in a harsh, realworld environment. The key features of the sensing platform, the data collection process and the translation of data into information using visualization and inferencing techniques are described.",,2006.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
569e9bd1d140c2032aa4a713b5ca4a0870643673,https://www.semanticscholar.org/paper/569e9bd1d140c2032aa4a713b5ca4a0870643673,Analysis and Protection of SIP based Services,"Multimedia communications over IP are booming as they offer higher flexibility and more features than traditional voice and video services. 
IP telephony known as Voice over IP (VoIP) is one of the commercially most important emerging trends in multimedia communications over IP. Due to the flexibility and descriptive power, the Session Initiation Protocol (SIP) is becoming the root of many sessions-based applications such as VoIP and media streaming that are used by a growing number of users and organizations. The increase of the availability and use of such applications calls for careful attention to the possibility of transferring malformed, incorrect, or malicious SIP messages as they can cause problems ranging from relatively innocuous disturbances to full blown attacks and frauds. Given this scenario, a deep knowledge of the normal behavior of the network and users is essential to problem diagnosis and security protection of IP Telephony. Moreover, analysis tools taking into account service semantics and troubleshooting VoIP systems based on SIP are of paramount importance for network administrators. However, efficient design and deployment of robust and high performance security controlling systems remain a high challenge, in particular due to the open architecture of the Internet, heterogeneous environment and real time communication constraint. This thesis deals with the analysis and protection of services based on the SIP protocol with a special focus on SIP based VoIP applications. The first part of the work is dedicated to the conformance and security analysis of SIP based VoIP services. 
 
To this end, our first endeavor is to define a formal conceptual model of VoIP threat domain with the aim to exchange a common vocabulary about the security related information of the domain. We have introduced an ontology defined as “VoIP-Onto"" that provides a formal representation of a comprehensive taxonomy of VoIP attacks followed by specific security recommendations and guidelines for protecting the underlying infrastructure from these attacks. The use of “VoIP-Onto"" is not only limited to as a general vocabulary and extensible dictionary for sharing domain knowledge about VoIP security, but also can be employed in a real environment for testing or intrusion detection purposes. 
We have also concentrated on designing synthetic traffic generators considering the difficulties and challenges of collecting real-world VoIP traffic for the purpose of testing monitoring and security controlling tools. To this end, we have introduced “VoIPTG"", a generic synthetic traffic generator, that provides flexibility and efficiency in generation of large amount of synthetic VoIP traffic by imitating the realistic behavior profiles for users and attackers. We have also implemented “SIP-Msg-Gen"", a SIP fuzzer, capable to generate both the well-formed and fuzzed SIP messages with ease. 
Then, we focus on designing an on-line filter able to examine the stream 
of incoming SIP messages and classifies them as “good"" or “bad"" depending on whether their structure and content are deemed acceptable or not. Because of the different structure, contents and timing of the SIP “bad"" messages, their filtering is best carried out by a multistage classifier consisting of deterministic lexical analyzer and supervised machine learning classifiers. The performance and efficiency of our proposed multi-stage filtering system is tested with a large set of SIP based VoIP traffic including both the real and synthetic traces. The experimental result of the filtering system is very promising with high accuracy providing fast attack detection. 
Next, the focus is shifted on the understanding and modeling the social interaction patterns of users of the VoIP domain. The notion of “social 
networks"" is applied in the context of SIP based VoIP network, where “social networks"" of VoIP users are built based on their telephone records. 
Then, Social Network Analysis (SNA) techniques are applied on these “social networks"" of VoIP users to explore their social behavioral patterns. 
A prototype of filtering system for SIP based VoIP services is also implemented to demonstrate that the knowledge about the social behavior of the VoIP users is helpful in problem diagnosis, intruders detection, and security protection. The filtering system is trained with the normal behavioral patterns of the users. The machine, thus trained, is capable of identifying “malicious"" users.",,2014.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
957c92cdf94093030f161f80ed094844ab58eba5,https://www.semanticscholar.org/paper/957c92cdf94093030f161f80ed094844ab58eba5,End-to-end single-rate multicast congestion detection using support vector machines,"IP multicast is an efficient mechanism for simultaneously transmitting bulk data to multiple receivers. Many applications can benefit from multicast, such as audio and videoconferencing, multi-player games, multimedia broadcasting, distance education, and data replication. For either technical or policy reasons, IP multicast still has not yet been deployed in today’s Internet. Congestion is one of the most important issues impeding the development and deployment of IP multicast and multicast applications. Many congestion control schemes have been proposed to tackle multicast congestion problem. However, few of the schemes focus on using machine learning to detect multicast congestion in advance. Machine learning has already been successfully applied in a number of areas without much background information, and gives useful results. Because we tackle the multicast congestion problem with the end-to-end assumptions, we cannot obtain opportune and accurate congestion information directly from inside the network. Therefore, machine learning is particularly appropriate due to the absence of congestion information and the unpredictable variance of network congestion. To detect end-to-end multicast congestion, we propose an end-to-end multicast congestion detection scheme using support vector machines. Support vector machines are able to detect incipient congestion with great accuracy in an end-to-end multicast network after training by using structural information about the multicast network. To verify the performance of our scheme, we ran several ns-2 simulations and statistical experiments. Our simulations have shown that support vector machine is an appropriate mechanism for decision making in proactive multicast congestion detection.",,2008.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
4ea8230a6aaaea45049152643bed3baaa6d5818a,https://www.semanticscholar.org/paper/4ea8230a6aaaea45049152643bed3baaa6d5818a,EvoRecSys: Evolutionary Framework for Health and Wellbeing Recommender Systems. User Modeling and User-Adapted Interaction.,"In recent years, recommender systems have been employed in domains like e-commerce, tourism, and multimedia streaming, where personalising users’ experience based on their interactions is a fundamental aspect to consider. Recent recommender system developments have also focused on well-being, yet existing solutions have been entirely designed considering one single well-being aspect in isolation, such as a healthy diet or an active lifestyle. This research introduces EvoRecSys, a novel recommendation framework that proposes evolutionary algorithms as the main recommendation engine, thereby modelling the problem of generating personalised well-being recommendations as a multi-objective optimisation problem. EvoRecSys captures the interrelation between multiple aspects of well-being by constructing conﬁgurable recommendations in the form of bundled items with dynamic properties. The preferences and a predeﬁned well-being goal by the user are jointly considered. By instantiating the framework into an implemented model, we illustrate the use of a genetic algorithm as the recommendation engine. Finally, this implementation has been deployed as a Web application in order to conduct a users’ study. when a user is going to an exercise routine based on their previous behaviour and thus prevent it. The proposed model uses a machine learning algorithm as the core of the recommendation process. The previous user behaviour is used as a training vector which has 34 features including covered distance, workout duration, and rest time. Once the algorithm is trained, it is able to predict if a user is going to abandon the routine. If so, a recommendation for encouraging the user to continue the routine is triggered. Otherwise, the system predicts the user will not abandon the routine. The study tested 4 classiﬁcation algorithms: (i) random forest, (ii) AdaBoost, (iii) extra trees, and (iv) multi-layer perceptron; where random forest obtained the best performance. Data used for the analysis were taken from the u4ﬁt platform. ence modelling and aggregation, and AI for Sustainable Development Goals. Dr. Palomares’s research results have been published in top journals and conference proceedings, including IEEE TRANSACTIONS ON FUZZY SYSTEMS; IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS: SYSTEMS; European Journal of Operational Research; Applied Soft Computing; International Journal of Intelligent Systems; Information Fusion, Knowledge-Based Systems; Applied Intelligence; Renewable & Sustainable Energy Reviews, amongst others.",,,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
76e5d249aab8bb581365122ddfcb06ca959b105b,https://www.semanticscholar.org/paper/76e5d249aab8bb581365122ddfcb06ca959b105b,SURVEY ON HETEROGENEOUS NETWORK TRAFFIC ANALYSIS WITH SUPERVISED AND UNSUPERVISED DATA MINING TECHNIQUES,"Network Traffic Analysis (NTA) in heterogeneous networks is one of the emerging research areas receiving substantial attention from both the research community and traffic analyzers. Many tasks in NTA can be naturally cast in a supervised and unsupervised learning model. Many supervised classification models and unsupervised clustering learning models in data mining have been proposed for heterogeneous network. Due to the importance of network traffic analysis in data mining research with the rapid development of new models, To provide a comprehensive review on supervised classification and unsupervised clustering model on heterogeneous type of network in this paper and systematically give a summarization of the state-of-the-art techniques for network traffic analysis. It addresses the problem of network management such as traffic load, quality of service, and trend analysis. This survey covers real time supervised classification and unsupervised clustering algorithms and analyze techniques for heterogeneous networks. It provides taxonomy of the different supervised classification algorithms and unsupervised clustering algorithms and evaluates the various performance metrics that are significantly used for the purpose of comparison. A detailed review is provided covering fuzzy relational clustering algorithm, classification learning algorithms, global voting algorithm and hybrid algorithms. The survey evolve certain open issues, key research challenges for network traffic analysis using supervised classification and unsupervised clustering model in heterogeneous networks, and likely to provide productive research directions. Key Words--Supervised and Unsupervised Mining, Traffic Data Analysis, Heterogeneous Network D.Jayachitra et al, International Journal of Computer Science and Mobile Computing, Vol.3 Issue.7, July2014, pg. 47-59 © 2014, IJCSMC All Rights Reserved 48 I. STATE OF ART The growing population of the aged and the disable is leading to expansion of autonomous service systems. In data mining the data appear in limitless stream for classification of data stream. The problem of data stream classification, where the data enter in an unreal unlimited stream and the probability to evaluate each record is briefed. The problem is solved with the existence of stream classification algorithm. Sparse coding as demonstrated in [14] which fundamentally challenged to find an embedding for the data by assigning feature values based on subspace cluster membership. A direct application of sparse coding resulted in a collapse of knowledge relocate to sparse coding, by incorporating distribution distance approximate for the embedded data. Bayesian learning and expectation-maximization (EM) techniques were developed under the proposed generative model as shown in [17] for recognizing new training data for learning new unseen sites. Previously unseen attributes combined with their semantic labels were also exposed through another EMbased on the generative model. Segmentation algorithm is applied on this signal that automatically estimates the number of partitions and the partition borders as presented here [2] fails in holding each subtrajectory of the sampling set by different subtrajectories of the MOD (cluster), under the minimization of objective. Space-efficient algorithms maintain duplicate-insensitive order sketches so that rank-based queries are roughly processed with relative rank error that guarantees in the presence of data duplicates. Besides the space efficiency, the algorithm is time-efficient and highly accurate in [9]. Moreover, one scan algorithm is practical to the heavy hitter problem using distinct elements when compared to the existing fault-tolerant distributed communication techniques. For the discovery of a significant arrangement of data generated by human behavior, a clustering technique capable of detecting outliers is often employed. To be specific, Possibilistic c-Means (PCM), Fuzzy Possibilistic c-Means (FPCM) and Possibilistic Fuzzy c-Means (PFCM) are robust against outliers. However, they suffer from the local optimum problem and need to find a suitable means of combining and adjusting several free parameters to achieve optimal performance. Anomaly detection aims to recognize a minute group of instances which deviate remarkably from the accessible data. A well-known definition of outlier is that given an observation which deviates so much from other observations, as to arouse the uncertainties behavior generated by different mechanism, it gives the universal idea of an outlier and encourages many anomaly detection methods. Detecting anomalous insiders in collaborative information systems as shown in [1] intend to analyze the impact of such information in the future. The goal of the current work was to determine the basic information in the access logs and Meta information for the subjects in anomaly detection. On line alert aggregation based on a active, probabilistic model in [18] essentially are regarded as a data stream version of a maximum likelihood approach for the estimation of the model parameters. An online oversampling principal component analysis (OSPCA) illustrated in [8] aims in detecting the occurrence of outliers from a great amount of information via online update procedure. Fuzzy-state Q-learning (FSQL) process is incorporated, which is capable of learning human behavior patterns in a non-supervised manner and predicting subsequent human actions. In the latter case, interaction between certain users as shown in [7] often affects their choice of actions, and thus the situation of action learning is quite complicated. Error terms augment the standard sum of squared error computational experiments as shown in [16] that the modified learning method helps to extract fewer rules without increasing individual rule complexity and without decreasing classification accuracy. Ontology-based fuzzy video semantic content model uses spatial/temporal relations in event and conception definitions supply a wide domain pertinent rule construction average. D.Jayachitra et al, International Journal of Computer Science and Mobile Computing, Vol.3 Issue.7, July2014, pg. 47-59 © 2014, IJCSMC All Rights Reserved 49 Fuzzy video semantic content as shown in [10] allows the user to construct ontology for a given domain. In addition to domain ontology additional rule definitions are used to lower spatial relation computation cost and to identify some complex situations more effectively. Fascinatingly, the idea of fuzzy partitioning based on relational data is not novel, and can be traced. The purity of a cluster is defined as the fraction of the cluster size that the largest class of objects assigned to that cluster in [3] fails to extend these ideas to the development of a hierarchical fuzzy relational clustering algorithm. To derive a novel method for measuring similarity between the data objects in sparse and high dimensional field as shown in [15], same principle can be made use of. But alternative forms are defined for the relative similarity and do not use average but have other methods to combine the relative similarities according to the different viewpoints. More specially, show that hubness, i.e., the tendency of high-dimensional data to enclose points that frequently occur in k-nearest neighbor lists of other points in [20]. The hubness was successfully exploited in clustering. The cluster-adaptive distance bound based on separating hyper plane boundaries of Voronoi clusters in [5] enables well-organized spatial filtering, with a comparatively small preprocessing storage space overhead and is applicable to euclidean and Mahalanobis similarity measures. The large organizations will not retrieve and process petabytes of data, for various purposes such as data mining and decision support. Thus, there exist numerous applications that access large multimedia databases, which fail in efficient support. Fast smallest amount spanning tree-inspired clustering algorithm uses an efficient implementation of the cut and the rotation property of the minimum spanning trees. The rich properties of the MST algorithms fails in adapting MST inspired clustering algorithm [12] to more general and larger data sets, primarily when the whole data set cannot fit into the main memory. MAximal Resemblance Data Labeling (MARDL) allocate each unlabeled data point into the matching suitable cluster based on the narrative categorical clustering representative. To detect the drifting concepts at different sliding windows, DCD contrast the cluster distributions in the middle of the last clustering consequence and the temporal current clustering result [11]. However, since only an inadequate amount of labeled data are available in the above real world applications, how to establish anomaly of unseen data (or events) draws attention from the researchers in data mining and machine learning communities. Deploying the semantics embedded in web services request and present semantic web services, but the sharing of knowledge is not addressed [4]. Multivariate Reconstructed Phase Space (MRPS) for recognizing multivariate temporal patterns as shown in [13] is characterized by identifying the anomalies or events in a dynamic data system. Supervised model is based on training a data sample from data source with accurate clustering. Network traffic clustering is an important and challenging problem. The objective is to conclude the applications that produce a certain group of packets, such as video, peer-to-peer, gaming, email etc. However approach is no longer effective as there are now many different kinds of network applications, some of which deliberately change their behavior in order not to be detected. Another complexity is that due to isolation requirements and computational problem, it is envisage that classification algorithms are allowed to use only partial information present in the network data and avoid deep packet ",,2014.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a4cd21b048c77785add1a4dbb9a56ca456c6638d,https://www.semanticscholar.org/paper/a4cd21b048c77785add1a4dbb9a56ca456c6638d,Keynote: Compilers in the Manycore Era,,HiPEAC,2008.0,10.1007/978-3-540-92990-1_2,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
be43803704936febcf16f70cfa177223cb94ebc6,https://www.semanticscholar.org/paper/be43803704936febcf16f70cfa177223cb94ebc6,"New Trends in Applied Artificial Intelligence, 20th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2007, Kyoto, Japan, June 26-29, 2007, Proceedings",,IEA/AIE,2007.0,10.1007/978-3-540-73325-6,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
17e42ec161af3e4281649649f3562d5f45cb1e4b,https://www.semanticscholar.org/paper/17e42ec161af3e4281649649f3562d5f45cb1e4b,Theoretical advances and applications of intelligent paradigms,"What is an “intelligent paradigm”? While it is difficult to provide an exact definition for this term, the interests in intelligent paradigms research generally focus on designing and developing of computerized machines or systems that exhibit the capabilities of learning from experience, adapting to the surrounding environment, as well as understanding and controlling ones thinking or reasoning process. These are some crucial characteristics of intelligent paradigms so that they can be deployed as usable and useful tools to assist humans in daily activities. Indeed, recent research and development in intelligent paradigms has opened up the way for a number of theoretical advances and successful applications of intelligent techniques and approaches in various domains. Diverse intelligent paradigms are available in the literature, encompassing, to name a few, artificial neural networks, evolutionary algorithms, multiagent systems, artificial immune systems, swarm intelligence, knowledge-based systems, case-based reasoning, as well as hybrid intelligent systems in which these paradigms are contained. Applications of intelligent paradigms also span across various fields, covering, to name a few, information processing, decision making, control and robotics, industrial and medical diagnosis, data mining, e-learning and e-commerce, knowledge management, as well as virtual reality and multimedia. In this special issue, a total of eight articles are collected to showcase a small fraction of some recent advances in theory and application of intelligent paradigms. These articles present research into various intelligent paradigms, with their effectiveness in tackling different real-world problems demonstrated and discussed. A brief outline of each article is as follows. A powered wheelchair is an effective vehicle to help elderly or handicapped people move around the ordinary areas. Song et al. design of an electromyogram (EMG) pattern classifier that is robust against muscular fatigue effects for powered wheelchair control. It is discovered that variations of feature values owing to the effect of muscular fatigue are consistent for sustained duration. This finding leads to a new fatigue compensation method, and the fuzzy Min-Max neural network is employed as a robust EMG-based pattern classifier through the adaptation process of its hyperboxes. The proposed approach demonstrates improved performance for continuous control of powered wheelchair. Path planning is a fundamental problem in mobile robotics. The work by Chakraborty et al. addresses the issue of multi-robot path planning by using parallel differential evolution algorithms. Both centralized and distributed realizations for multi-robot path planning are studied, and the performances of the methods are compared with respect to a few pre-defined yardsticks. Most industrial plants are complex, nonlinear, time varying with time delay, and difficult to control. A fuzzy logic-based system is suitable for their control as it combines measurements, experts’ knowledge and op-",J. Intell. Fuzzy Syst.,2009.0,10.3233/IFS-2009-0410,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
cdb6b5919cb42b4e6c1ccff3da0df867fde8ac70,https://www.semanticscholar.org/paper/cdb6b5919cb42b4e6c1ccff3da0df867fde8ac70,NATURAL LANGUAGE PROCESSING IN VIRTUAL REALITY TRAINING ENVIRONMENTS,"Technological advances in areas such as transportation, communications, and science are rapidly changing our world--the rate of change will only increase in the 21st century. Innovations in training will be needed to meet these new requirements. Not only must soldiers and workers become proficient in using these new technologies, but shrinking manpower requires more crosstraining, self-paced training, and distance learning. Two key technologies that can help reduce the burden on instructors and increase the efficiency and independence of trainees are virtual reality simulators and natural language processing. This paper focuses on the design of a virtual reality trainer that uses a spoken natural language interface with the trainee. RTI has developed the Advanced Maintenance Assistant and Trainer (AMAT) with ACT II funding for the Army Combat Service Support (CSS) Battlelab. AMAT integrates spoken language processing, virtual reality, multimedia and instructional technologies to train and assist the turret mechanic in diagnosing and maintenance on the M1A1 Abrams Tank in a hands-busy, eyes-busy environment. AMAT is a technology concept demonstration and an extension to RTI’s Virtual Maintenance Trainer (VMAT) which was developed for training National Guard organizational mechanics. VMAT is currently deployed in a number of National Guard training facilities. The AMAT project demonstrates the integration of spoken human-machine dialogue with visual virtual reality in implementing intelligent assistant and training systems. To accomplish this goal, RTI researchers have implemented the following features: • Speech recognition on a Pentium-based PC, • Error correcting parsers that can correctly handle utterances that are outside of the grammar, • Dynamic natural language grammars that change as the situation context changes, • Spoken message interpretation that can resolve pronoun usage and incomplete sentences, • Spoken message reliability processing that allows AMAT to compute the likelihood that it properly understood the trainee (This score can be used to ask for repeats or confirmations.), • Goal-driven dialogue behavior so that the computer is directing the conversation to satisfy either the user-defined or computer-defined objectives, • Voice-activated movement in the virtual environment, and • Voice synthesis on a Pentium-based PC.",,1998.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
ed61b8ae828a23b669783672e62c0c2f6f9110e8,https://www.semanticscholar.org/paper/ed61b8ae828a23b669783672e62c0c2f6f9110e8,Conference preview: IUI 2001,"IUI 2001 is the annual meeting of the intelligent interfaces community and serves as the principal international forum for reporting outstanding research and development on intelligent user interfaces. Talks during the conference will be given by an international group of researchers and practitioners. Intelligent user interfaces (IUI) are human-machine interfaces that aim to improve the efficiency, effectiveness, and naturalness of human-machine interaction by representing, reasoning, and acting on models of the user, 60 i n t e r a c t i o n s. .. j a n u a r y + f e b r u a r y 2 0 0 1 demonstrations, and introduces intelligent user interfaces using the following outline: ✱ Multimedia input analysis ✱ Multimedia output generation ✱ Interaction Management, including user and discourse ✱ Models and adaptation ✱ Agent-based interaction This tutorial will give participants an active understanding of the issues that arise in the design of systems that adapt to their users— ranging from personalized e-commerce sites to context-aware alerting systems. Features of the tutorial: ✱ Learn about the potential benefits and limitations of many forms of user adaptation ✱ Discuss specific examples of deployed user-adaptive ✱ Systems and current research prototypes ✱ Actively deal with the central issues that arise in the design of such systems by addressing them in the context of a typical design task The presentation will consist of lectures that refer to concrete system examples within a unifying conceptual framework, interleaved with brief discussions of an example design problem. 3. Programming by Demonstration: Intelligent Interfaces for Teaching New Beahvior to a Machine Henry Lieberman Media Lab, MIT Programming by Example (also called Programming by Demonstration) is a powerful new technology that lets end-users create programs by recording actions in the user interface rather than by typing statements in a programming language. This tutorial will present this technology, which shows how intelligent user interfaces can dramatically improve the process of software development and make it accessible to users who do not have prior experience with programming. It will also include in-class design exercises, such as "" Wizard of Oz "" and "" Short-Order Programming "" exercises to give attendees hands-on experience with the technology. Animated pedagogical agents are emerging as an important way of enhancing the effectiveness of interactive learning environments, and providing intelligent help to other interactive applications. Nonverbal communication is an important part of face-to-face …",INTR,2001.0,10.1145/356978.356983,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
1da33462ceadefc9bf54c5488c7dfb089bfda953,https://www.semanticscholar.org/paper/1da33462ceadefc9bf54c5488c7dfb089bfda953,Extreme Makeover Computer Edition: Computer Refurbishers Are Equipping Cash-Strapped Schools with Used Hardware Made Good as New-Or Even Better,"IT'S THE GOLDEN RULE of economizing: Those who can, buy; those who can't, refurbish. What's common practice with living rooms and automobile interiors has proven to be good enough for computers. In the effort to acquire enough multimedia-capable, network-ready computers to provide meaningful technology access for all students, districts are turning to authorized refurbishers to equip their schools. Refurbishers take the guesswork out of deploying used computers in schools. They screen donated equipment, select computers and peripherals that meet appropriate technical requirements, and put the equipment through a meticulous process to ensure that it arrives in schools ready to be plugged into the network. Demand for refurbished systems is strong and growing. Roughly 13,800 schools and nonprofit organizations representing 11.5 million students are currently registered with the federal government to receive refurbished computers. The participating schools have an average ratio of nine students to one computer; they would need nearly 1 million more computers just to achieve a ratio of five students for every one computer. Nearly all districts must deal with a shortage of computers, but the dearth can be especially acute in urban and rural areas. With relatively low funding per pupil, such districts are most likely to serve students who don't have home access to technology. Of the 11.5 million students who receive refurbished computers, 35 percent are from low income families. The most recent data show that access to Internet-connected instructional computers still lags significantly in schools with mostly low-income or minority student populations. The Right Tool for the Right Job' The School District of Philadelphia (PA) recently became the first large district to issue a formal request for proposals to supply refurbished computers on a systemwide basis. District officials see refurbished computers as an integral part of their strategy to deploy a technology-based curriculum and support for instruction. In September 2005, the district awarded a contract to Computers for Schools (CFS; ww.pcsforschools.org), a nonprofit organization with operations in Philadelphia and Chicago, to provide 3,000 refurbished units over three years. According to Willie Cade, president and CEO of CFS, the contract will supply Philadelphia schools with reliable hardware for about one-third the cost of new equipment, without sacrificing any of the functionality schools need for most applications. The computers offer excellent price/performance value for common educational uses such as word processing, Internet research, and most educational software. In fact, CFS has a partnership with Scientific Learning (www.scilearn.com), a maker of reading-instruction software, to provide computers to schools using the company's Fast ForWord products. ""In other words,"" Cade says, ""refurbished computers provide Philadelphia with the right tool for the right job."" CFS underscores the reliability of its refurbished equipment by providing a three-year warranty at no additional cost. Over the last five years, the nonprofit has placed 35,000 computers in schools and homes of low-income families. By keeping detailed records of service issues, CFS has found that, within the first year, just 8.75 percent of its computers and monitors need repairs. According to the August 2005 issue of PC Magazine, the comparable repair rate for new equipment is 12 percent. In addition to providing dependable equipment at more affordable prices, computer refurbishers can help schools minimize the cost of supporting their rebuilt machines. When a school places an order, CFS fills the order with computers that are all the same make and model, and with monitors that are the same size and resolution. They also ship additional units, 5 percent of the total order, to serve as a ""pre-shipped warranty"" pool so that any service issues that do arise can be addressed onsite as quickly and efficiently as possible. …",,2006.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
398f5123e333cf2c22c312b95b1f0684a9cdbe39,https://www.semanticscholar.org/paper/398f5123e333cf2c22c312b95b1f0684a9cdbe39,TECHNOLOGY: Looking Ahead,"IN THE NEARLY 90 columns that I have written to date, only two have looked into the future: February 1996 and June 2000. Since it has been nearly three years since I last did so, I decided to dust off my crystal ball and gaze once again into the future. In June 2000 I made 11 predictions. I was dead wrong on the prediction that people would hire personal technology trainers, and I radically overestimated how quickly distance learning would grow. People have hired personal chefs and personal fitness trainers, but the personal technology trainers I envisioned haven't caught on. I was also wrong about how quickly a second version of the Internet would develop. Internet2 has not grown and flourished as rapidly as I had predicted. The other eight predictions were more or less correct, and several truly hit the nail on the head. I predicted in 2000 that computer interfaces would change radically and that more graphics and multimedia would begin to appear in what used to be simply text. Technically, the main user interfaces in Windows, Microsoft Office, and Mac OS haven't changed much. But what has changed is that more people are spending more time staring at Web browsers and e-mail interfaces. This is especially true for people who use AOL and custom-designed corporate or institutional websites or portals. Big players, such as Microsoft, Apple, and AOL, know they must not lose the so-called browser wars because life online has become a ""battle for eyeballs."" To remain a player, Apple recently released a beta version of its new browser called Safari. Benchmark tests show that Safari is roughly three times faster at drawing screens and interpreting Javascript than Microsoft's Internet Explorer. Other developments and trends relating to the Web prompt me to offer two new predictions about the Web. Web services software will quickly begin to replace traditional application and client-server software. Web services technology involves the deployment of a multitiered architecture with such tiers as a data tier, an application tier, a Web tier, a presentation tier, and a display tier. Each tier consists of one or many servers doing a specialized task. The user's Web interface is all that is needed to do things like send and receive e-mail, write reports, and query databases. The presentation tier is interesting because it is simply a server whose sole function is to format its output so it can be displayed on PCs, Personal Digital Assistants (PDAs), tablets, and phones. Perhaps the simplest example of Web services software is Microsoft's Webaccess, which can be used instead of its Outlook application. Even moderate-sized school districts are beginning to make the move to Web services. One of the major advantages to a Web services approach is that you do not have to install dozens of applications on every user's machine. For more information on Web services, browse the NetworkWorld site at www.nwfusion.com. Here's my second Web prediction. Weblog popularity and use in education, business, and the home will increase rapidly. Weblogs or blogs are online, self-published newsletters, discussions, news summaries, family albums, personal diaries, and so on. Various Internet sites offer software and storage so that nontechnically minded people can create a personal website or blog. Rather than make the owners/users learn to design a website using software like Dreamweaver, blog sites have templates that a neophyte can simply use to add text, images, and links. For more on the weblogs, visit www.lights.com/weblogs/index.html. You might also check out one of the oldest and largest blogs, http://slashdot.org. Notice the similarity between this trend and the Web services trend above: the servers and the networks are becoming the computer. I made a ""media everywhere"" prediction in 2000 that was certainly on target. Witness Apple's iLife software suite that integrates iPhoto, iTunes, iMovie, and iDVD. …",,2003.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
7e1a583c1f9fe3440d9218f7190dbcc0f3425779,https://www.semanticscholar.org/paper/7e1a583c1f9fe3440d9218f7190dbcc0f3425779,"Advanced information systems engineering : 14th International Conference, CAiSE 2002, Toronto, Canada, May 27-31, 2002 : proceedings","Invited Presentations.- The Grand Challenge in Information Technology and the Illusion of Validity.- Metadata and Cooperative Knowledge Management.- Ontology-Driven Conceptual Modeling.- Metadata and Cooperative Knowledge Management.- Web Component: A Substrate for Web Service Reuse and Composition.- Developing Web Applications.- Designing Web-Based Systems in Social Context: A Goal and Scenario Based Approach.- A State Machine Based Approach for a Process Driven Development of Web-Applications.- Knowledge Management.- Supporting Dimension Updates in an OLAP Server.- The COMET Metamodel for Temporal Data Warehouses.- Exploring RDF for Expertise Matching within an Organizational Memory.- Deployment Issues.- Describing and Communicating Software Architecture in Practice: Observations on Stakeholders and Rationale.- The Individual Deployment of Systems Development Methodologies.- Supporting the Deployment of Object-Oriented Frameworks.- Semantics of Information.- A Conceptual Modeling Approach to Semantic Document Retrieval.- Multidimensional Semistructured Data: Representing Context-Dependent Information on the Web.- The Role of Semantic Relevance in Dynamic User Community Management and the Formulation of Recommendations.- System Qualities.- Can We Ever Build Survivable Systems from COTS Components?.- Towards a Data Model for Quality Management Web Services: An Ontology of Measurement for Enterprise Modeling.- A Modelling Approach to the Realisation of Modular Information Spaces.- Integration Issues.- Data Integration under Integrity Constraints.- Babel: An XML-Based Application Integration Framework.- Integrating and Rapid-Prototyping UML Structural and Behavioural Diagrams Using Rewriting Logic.- Analysis and Adaptation.- Verification of Payment Protocols via MultiAgent Model Checking.- SNet: A Modeling and Simulation Environment for Agent Networks Based on i* and ConGolog.- Usage-Centric Adaptation of Dynamic E-Catalogs.- Retrieval and Performance.- Reengineering of Database Applications to EJB Based Architecture.- Efficient Similarity Search for Time Series Data Based on the Minimum Distance.- A High-Performance Data Structure for Mobile Information Systems.- Requirements Issues.- External Requirements Validation for Component-Based Systems.- Using Business Rules in Extreme Requirements.- Evaluating CM3: Problem Management.- Schema Matching and Evolution.- Database Schema Matching Using Machine Learning with Feature Selection.- Evolving Partitions in Conceptual Schemas in the UML.- Schema Evolution in Heterogeneous Database Architectures, A Schema Transformation Approach.- Workflows.- Serviceflow Beyond Workflow? Concepts and Architectures for Supporting Inter-Organizational Service Processes.- Design for Change: Evolving Workflow Specifications in ULTRAflow.- An Alternative Way to Analyze Workflow Graphs.- Semantics and Logical Representations.- Auditing Interval-Based Inference.- A Logical Foundation for XML.- Providing the Semantic Layer for WIS Design.- Understanding and Using Methods.- Towards a Framework for Comparing Process Modelling Languages.- Generic Models for Engineering Methods of Diverse Domains.- Role of Model Transformation in Method Engineering.- Modeling Objects and Relationships.- A Generic Role Model for Dynamic Objects.- Understanding Redundancy in UML Models for Object-Oriented Analysis.- Representation of Generic Relationship Types in Conceptual Modeling.- Short Papers.- Building Spatio-Temporal Presentations Warehouses from Heterogeneous Multimedia Web Servers.- A Practical Agent-Based Method to Extract Semantic Information from the Web.- Process Inheritance.- Addressing Performance Requirements Using a Goal and Scenario-Oriented Approach.- Querying Data with Multiple Temporal Dimensions.- Query Explorativeness for Integrated Search in Heterogeneous Data Sources.- Using Nested Tables for Representing and Querying Semistructured Web Data.- Defining and Validating Measures for Conceptual Data Model Quality.- An Architecture for Building Multi-device Thin-Client Web User Interfaces.- A Framework for Tool-Independent Modeling of Data Acquisition Processes for Data Warehousing.- Managing Complexity of Designing Routing Protocols Using a Middleware Approach.- Deferred Incremental Refresh of XML Materialized Views.- Requirements for Hypermedia Development Methods: A Survey of Outstanding Methods.- An Approach for Synergically Carrying out Intensional and Extensional Integration of Data Sources Having Different Formats.- DSQL - An SQL for Structured Documents Extended Abstract.- A Comparative Study of Ontology Languages and Tools.- Life Cycle Based Approach for Knowledge Management: A Knowledge Organization Case Study.- Parallel Query Processing Algorithms for Semi-structured Data.- Domain-Specific Instance Models in UML.- Extended Faceted Ontologies.- On the Logical Modeling of ETL Processes.- Intelligent Agent Supported Flexible Workflow Monitoring System.- A Meeting Scheduling System Based on Open Constraint Programming.",,2002.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
c67c89b6c7ea70effbd5f2ebe9ef2f5c7aa927d2,https://www.semanticscholar.org/paper/c67c89b6c7ea70effbd5f2ebe9ef2f5c7aa927d2,"Advances in Information Systems: Second International Conference, ADVIS 2002, Izmir, Turkey, October 23-25, 2002. Proceedings","Databases and Data Warehouses.- Preserving Aggregation in an Object-Relational DBMS.- Database Compression Using an Offline Dictionary Method.- Representation of Temporal Unawareness.- Scalable and Dynamic Grouping of Continual Queries.- Uncertainty in Spatiotemporal Databases.- Integrity Constraint Enforcement by Means of Trigger Templates.- Current, Legacy, and Invalid Tuples in Conditionally Evolving Databases.- Magic Sets Method with Fuzzy Logic.- Information Retrieval.- Information Retrieval Effectiveness of Turkish Search Engines.- Comparing Linear Discriminant Analysis and Support Vector Machines.- Cross-Language Information Retrieval Using Multiple Resources and Combinations for Query Expansion.- Extracting Shape Features in JPEG-2000 Compressed Images.- Comparison of Normalization Techniques for Metasearch.- On the Cryptographic Patterns and Frequencies in Turkish Language.- Automatic Stemming for Indexing of an Agglutinative Language.- Pattern Acquisition for Chinese Named Entity Recognition: A Supervised Learning Approach.- Information Systems.- The Information System for Creating and Maintaining the Electronic Archive of Documents.- KiMPA: A Kinematics-Based Method for Polygon Approximation.- The Implementation of a Robotic Replanning Framework.- A 300 MB Turkish Corpus and Word Analysis.- Adaptation of a Neighbor Selection Markov Chain for Prefetching Tiled Web GIS Data.- Web Based Automation Software for Calculating Production Costs in Apparel Industry.- Multi-agent Technologies and Systems.- Knowledge Representation in the Agent-Based Travel Support System.- Intelligent Agents in Virtual Worlds.- Characterizing Web Service Substitutivity with Combined Deductive and Inductive Engines.- Modular-Fuzzy Cooperation Algorithm for Multi-agent Systems.- Minimax Fuzzy Q-Learning in Cooperative Multi-agent Systems.- A Component-Based, Reconfigurable Mobile Agent System for Context-Aware Computing.- A FIPA-Compliant Agent Framework with an Extra Layer for Ontology Dependent Reusable Behaviour.- Evolutionary Algorithms.- Vibrational Genetic Algorithm (Vga) for Solving Continuous Covering Location Problems.- Minimal Addition-Subtraction Chains Using Genetic Algorithms.- Preserving Diversity through Diploidy and Meiosis for Improved Genetic Algorithm Performance in Dynamic Environments.- Ant Systems: Another Alternative for Optimization Problems?.- System Programming.- Augmenting Object Persistency Paradigm for Faster Server Development.- Power Conscious Disk Scheduling for Multimedia Data Retrieval.- Task Scheduling with Conflicting Objectives.- A Fast Access Scheme to Meet Delay Requirement for Wireless Access Network.- New Information Technologies in Education.- Dokuz Eylul University-Distance Education Utilities Model.- Problem-Based Learning as an Example of Active Learning and Student Engagement.- Use of PBL Method in Teaching IT to Students from a Faculty of Education: A Case Study.- Interval Matrix Vector Calculator-The iMVC 1.0.- Distributed and Parallel Data Processing.- Efficient Code Deployment for Heterogeneous Distributed Data Sources.- Efficient Parallel Modular Exponentiation Algorithm.- Interprocedural Transformations for Extracting Maximum Parallelism.- On Methods' Materialization in Object-Relational Data Warehouse.",,2002.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a132844518e757c8c34d356c8f1f05a724d0aeab,https://www.semanticscholar.org/paper/a132844518e757c8c34d356c8f1f05a724d0aeab,Wideband Beamforming www.modernh.com for to for,"Real-time Narrowband and Wideband Beamforming Techniques Fully-digital RF ArraysApplication of Frequency Invariant Constraints Wideband BeamformingLow-cost Smart AntennasGeolocation of RF SignalsUltra-Wideband, Short-Pulse Electromagnetics 5Statistical Signal Processing in EngineeringMIMO Antennas Wireless CommunicationAdaptive Array SystemsWireless Communication SystemsUltra Wideband Wireless CommunicationVLSIConvex Optimization in Signal Processing and CommunicationsSignal Processing Algorithms for Communication and Radar SystemsAn Analysis of Wideband Beamforming Techniques and Hardware Requirements for Analog and Digital Radar ArchitecturesUltra-Wideband Antennas and PropagationPervasive Mobile and Ambient Wireless CommunicationsIssues in Electronic Circuits, Devices, and Materials: 2013 EditionAdvances in Neural Networks - ISNN 2005Academic Press Library in Signal ProcessingUWB Communication SystemsCooperative and Cognitive Satellite SystemsAll-Optical Signal ProcessingRobust Adaptive BeamformingNeural information processing [electronic resource]Multiple Access CommunicationsUltra Wideband Signals and Systems in Communication EngineeringAdvanced Wireless CommunicationsTrue-Time-Delay Beamforming für ultrabreitbandige Systeme hoher LeistungIssues in Electronic Circuits, Devices, and Materials: 2012 EditionSimplified Robust Adaptive Detection and Beamforming for Wireless CommunicationsImaging: Sensors and TechnologiesWideband Direction of Arrival Estimation and Wideband Beamforming for Smart Antenna SystemsAdvances in Acoustic Emission TechnologyWideband BeamformingSound Visualization and ManipulationDistributed Sensor NetworksCognitive Radio Communication and NetworkingAdvanced Antenna Systems for 5G Network DeploymentsSound Capture for Human / Machine InterfacesMicrowave and Millimeter Wave Circuits and Systems multi-path signals. Key Features: Unique book focusing on wideband beamforming Discusses a hot topic coinciding with the increasing bandwidth in wireless communications and the development of UWB technology Addresses the general concept of beamforming including fixed beamformers and adaptive beamformers Covers advanced topics including sub-band adaptive beamforming, frequency invariant beamforming, blind wideband beamforming, beamforming without temporal processing, and beamforming for multi-path signals Includes various design examples and corresponding complexity analyses This book provides a reference for engineers and researchers in wireless communications and signal processing fields. Postgraduate students studying signal processing will also find this book of interest.This practically-oriented, all-inclusive guide covers all the major enabling techniques for current and next-generation cellular communications and wireless networking systems. Technologies covered include CDMA, OFDM, UWB, turbo and LDPC coding, smart antennas, wireless ad hoc and sensor networks, MIMO, and cognitive radios, providing readers with everything they need to master wireless systems design in a single volume. Uniquely, a detailed introduction to the properties, design, and selection of RF subsystems and antennas is provided, giving readers a clear overview of the whole wireless system. It is also the first textbook to include a complete introduction to speech coders and video coders used in wireless systems. Richly illustrated with over 400 figures, and with a unique emphasis on practical and state-of-the-art techniques in system design, rather than on the mathematical foundations, this book is ideal for graduate students and researchers in wireless communications, as well as for wireless and telecom engineers.This volume collects the papers from the 2013 World Conference on Acoustic Emission in Shanghai. The latest research and applications of Acoustic Emission (AE) are explored, with particular emphasis on detecting and processing of AE signals, development of AE instrument and testing standards, AE of materials, engineering structures and systems, including the processing of collected data and analytical techniques as well as experimental case studies.This book presents an alternative and simplified approaches for the robust adaptive detection and beamforming in wireless communications. It adopts several systems models including DS/CDMA, OFDM/MIMO with antenna array, and general antenna arrays beamforming model. It presents and analyzes recently developed detection and beamforming algorithms with an emphasis on robustness. In addition, simplified and efficient robust adaptive detection and beamforming techniques are presented and compared with exiting Spectrum Sensing: Basic Techniques; Cooperative Sensing Wideband Transmission Orthogonal Frequency Division Multiplexing Multiple Input Multiple Output for Cognitive Radio; Convex Optimization for Cognitive Radio; Cognitive Core (I): Algorithms for Reasoning and Learning; Cognitive Core (II): Game Theory; Cognitive Radio Network IEEE The First Cognitive Radio Wireless Regional Area Network Standard, and Testbeds.This and of research ultra-wideband radar systems; ultra-wideband and transient antennas; pulsed power generation and propagation; ultra-wideband polarimetry; ultra-wideband and transient metrology; detection and identification studies; RF interactions and chaotic effects; Multiple (UWB) the transmission sequence, the combining s cheme and ML decision rule for two-branch transmit diversity scheme with one and M receivers. Ultra Wide Band Radio, UWB multiple access in Gaussian channels, the UWB channel, UWB system with M-ary modulation, M-ary PPM UWB multiple access, coded UWB schemes, multi-user detection in UWB radio, UWB with space time processing and beam forming for UWB radio. Adaptive Beamforming the and work ofleading researchers investigating various approaches in onecomprehensive uncertainty set of thearray steering vector. their the standard Capon beamformers with a spherical orellipsoidal uncertainty set of the array steering Diagonal loading for finite sample size beamforming * Mean-squared error beamforming for signal estimation * Constant modulus beamforming * Robust wideband beamforming using a steered adaptive beamformerto adapt the weight vector within a generalized sidelobe cancellerformulation Adaptive Beamforming up-to-date reference for engineers, researchers, and inthis rapidly expanding field.ULTRA including part of massive MIMO to provide the important aspects of emerging technology. Aimed at researchers, professionals and graduate students in electrical engineering, electromagnetics, communications and signal processing including antenna theory and design, smart antennas, communication systems, this book: Investigates real time MIMO antenna designs for WLAN/WiMAX/LTE applications. Covers effects of ECC, MEG, TARC, and equivalent circuit. Addresses the coupling and diversity aspects of antenna design problem for MIMO systems. Focus on the MIMO antenna designs for the real time applications. Exclusive chapter on 5G Massive MIMO along with case studies throughout the book.Geolocation of RF Signals—Principles and Simulations offers an overview of the best practices and innovative techniques in the art and science of geolocation over the last twenty years. It covers all research and development aspects including theoretical analysis, RF signals, geolocation techniques, key block diagrams, and practical principle simulation examples in the frequency band from 100 MHz to 18 GHz or even 60 GHz. Starting with RF signals, the book progressively examines various signal bands – such as VLF, LF, MF, HF, VHF, UHF, L, S, C, X, Ku, and, K and the corresponding geolocation requirements per band and per application – to achieve required performance objectives of up to 0o precision. Part II follows a step-by-step approach of RF geolocation techniques and concludes with notes on state-of-the-art geolocation designs as well as advanced features found in signal generator instruments. Drawing upon years of practical experience and using numerous examples and illustrative applications, Ilir Progri provides a comprehensive introduction to Geolocation of RF Signals, and includes hands-on real world labs and applications using MATLAB in the areas of: RF signals specifications, RF geolocation distributed wireless communications networks and RF geolocation. Geolocation of RF Signals—Principles and Simulations will be of interest to government agency program managers industry professionals and engineers, academic researchers, faculty and graduate students who are interested in or currently designing, developing and deploying innovative geolocation of RF Signal systems.Advanced Antenna Systems for 5G Network Deployments: Bridging the Gap between Theory and Practice provides a comprehensive understanding of the field of advanced antenna systems (AAS) and how they can be deployed in 5G networks. The book gives a thorough understanding of the basic technology components, the state-of-the-art multi-antenna solutions, what support 3GPP has standardized together with the reasoning, AAS performance in real networks, and how AAS can be used to enhance network deployments. Explains how AAS features impact network performance and how AAS can be effectively used in a 5G network, based on either NR and/or LTE Shows what AAS configurations and features to use in different network deployment scenarios, focusing on mobile broadband, but also including fixed wireless access Presents the latest developments in multi-antenna technologies, including Beamforming, MIMO and cell shaping, along with the potential of different technologies in a commercial network context Provides a deep understanding of the differences between mid-band and mm-Wave solutionsWith a continuously increasing desire for natural and comfortable human/machine interaction, the acoustic interface of any terminal for multimedia or telecommunication services is challenged to allow seamless and hands-free audio commun",,2022.0,10.1002/9780470661178,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
74dafa7cfbf285da489e6fd3ac793d533114861c,https://www.semanticscholar.org/paper/74dafa7cfbf285da489e6fd3ac793d533114861c,Ieee Papers On Wireless Network Of Security,"802.11 Wireless Networks: The Definitive GuideWireless Personal Area NetworksLow-rate Wireless Personal Area NetworksAdvances in Wireless Sensors and Sensor NetworksWireless and Mobile Communications ICWMC, 2008 4th International Conference onWireless Networks and Security6gWireless BlockchainDevelopments in Wireless Network Prototyping, Design, and Deployment: Future GenerationsWireless Communications and ApplicationsNext Generation Wireless Terahertz Communication NetworksWireless Device-to-Device Communications and NetworksZigBee Wireless Networks and TransceiversWireless Communication StandardsIEEE 802.11 HandbookWireless NetworkingCooperative Communications for Improved Wireless Network Transmission: Framework for Virtual Antenna Array ApplicationsFundamentals of Public Safety Networks and Critical Communications SystemsIEEE 802 Wireless SystemsWireless Communications and Networking for Unmanned Aerial VehiclesWireless Network Security2021 IEEE 22nd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)Compressive Sensing for Wireless NetworksAlgorithms and Protocols for Wireless Sensor NetworksWireless Sensor Networks6G Mobile Wireless NetworksQuality, Reliability, Security and Robustness in Heterogeneous NetworksNext Generation Wireless Network Security and PrivacyWirelessMANInformation Networking. Towards Ubiquitous Networking and ServicesApplications of Machine Learning in Wireless CommunicationsWireless Network Traffic and Quality of Service Support: Trends and StandardsHierarchical Topology Control for Wireless NetworksProtocols and Architectures for Wireless Sensor NetworksWireless Network PricingIndustrial Wireless Sensor NetworksAutonomous Airborne Wireless NetworksLow-rate Wireless Personal Area NetworksThe WiFi Networking Book2019 Third International Conference on I SMAC (IoT in Social, Mobile, Analytics and Cloud) (I SMAC)",,2022.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
e9db360184bd05e81e22e4863c552047ffca4754,https://www.semanticscholar.org/paper/e9db360184bd05e81e22e4863c552047ffca4754,Multi Uav Cooperative Surveillance With Spatio Temporal Ebooks File,"Covering the design, development, operation and mission profiles of unmanned aircraft systems, this single, comprehensive volume forms a complete, stand-alone reference on the topic. The volume integrates with the online Wiley Encyclopedia of Aerospace Engineering, providing many new and updated articles for existing subscribers to that work. Time-Critical Cooperative Control of Autonomous Air Vehicles presents, in an easy-to-read style, the latest research conducted in the industry, while also introducing a set of novel ideas that illuminate a new approach to problem-solving. The book is virtually self-contained, giving the reader a complete, integrated presentation of the different concepts, mathematical tools, and control solutions needed to tackle and solve a number of problems concerning time-critical cooperative control of UAVs. By including case studies of fixed-wing and multirotor UAVs, the book effectively broadens the scope of application of the methodologies developed. This theoretical presentation is complemented with the results of flight tests with real UAVs, and is an ideal reference for researchers and practitioners from academia, research labs, commercial companies, government workers, and those in the international aerospace industry. Addresses important topics related to time-critical cooperative control of UAVs Describes solutions to the problems rooted in solid dynamical systems theory Applies the solutions developed to fixed-wing and multirotor UAVs Includes the results of field tests with both classes of UAVs Across the globe, the past several years have seen a tremendous increase in the role of cooperative autonomous systems. The field of cooperative control and optimization has established itself as a part of many different scientific disciplines. The contents of this hugely important volume, which adds much to the debate on the subject, are culled from papers presented at the Seventh Annual International Conference on Cooperative Control and Optimization, held in Gainesville, Florida, in January 2007. First used in military applications, unmanned aerial vehicles are becoming an integral aspect of modern society and are expanding into the commercial, scientific, recreational, agricultural, and surveillance sectors. With the increasing use of these drones by government officials, business professionals, and civilians, more research is needed to understand their complexity both in design and function. Unmanned Aerial Vehicles: Breakthroughs in Research and Practice is a critical source of academic knowledge on the design, construction, and maintenance of drones, as well as their applications across all aspects of society. Highlighting a range of pertinent topics such as intelligent systems, artificial intelligence, and situation awareness, this publication is an ideal reference source for military consultants, military personnel, business professionals, operation managers, surveillance companies, agriculturalists, policymakers, government officials, law enforcement, IT professionals, academicians, researchers, and graduate-level students. Discover what lies beyond the bleeding-edge of autonomous airborne networks with this authoritative new resource Autonomous Airborne Wireless Networks delivers an insightful exploration of recent advances in the theory and practice of using airborne wireless networks to provide emergency communications, coverage and capacity expansion, information dissemination, and more. The distinguished engineers and editors have selected resources that cover the fundamentals of airborne networks, including channel models, recent regulation developments, self-organized networking, AI-enabled flying networks, and notable applications in a variety of industries. The book evaluates advances in the cutting-edge of unmanned aerial vehicle wireless network technology while offering readers new ideas on how airborne wireless networks can support various applications expected of future networks. The rapidly developing field is examined from a fresh perspective, one not just concerned with ideas of control, trajectory optimization, and navigation. Autonomous Airborne Wireless Networks considers several potential use cases for the technology and demonstrates how it can be integrated with concepts from selforganized network technology and artificial intelligence to deliver results in those cases. Readers will also enjoy: A thorough discussion of distributed drone base station positioning for emergency cellular networks using reinforcement learning (AI-enabled trajectory optimization) An exploration of unmanned aerial vehicle-to-wearables (UAV2W) indoor radio propagation channel measurements and modelling An up-to-date treatment of energy minimization in UAV trajectory design for delay tolerant emergency communication Examinations of cache-enabled UAVs, 3D MIMO for airborne networks, and airborne networks for Internet of Things communications Perfect for telecom engineers and industry professionals working on identifying practical and efficient concepts tailored to overcome challenges facing unmanned aerial vehicles providing wireless communications, Autonomous Airborne Wireless Networks also has a place on the bookshelves of stakeholders, regulators, and research agencies working on the latest developments in UAV communications. ""The ability to fly multiple unmanned aerial vehicles (UAVs) in collaboration has the potential to expand the scope of feasible UAV missions and could become the backbone of future UAV missions. However, despite having garnered significant research interest, there is no indication that systems supporting collaborative operation of multiple UAVs are close to achieving field deployment. The challenge of successfully deploying a quality system is inherently complex, and systems engineering offers an approach to handle the complexities. Effective application of systems engineering requires both knowledge breadth and depth. This thesis presents the results of a consolidation of information intended to support the conduct of systems engineering activities; and describes an experiment to ascertain the sensitivities of some key operational parameters, e.g., acquisition, pointing, and tracking. The experiment was conducted using Automatic Dependent Surveillance Broadcast (ADS-B) and visual tracking equipment employing state-of-the-art technology to understand the operating challenges and requirements of using this equipment to provide situational awareness for a UAV pilot""--Abstract. This book compiles some of the latest research in cooperation between robots and sensor networks. Structured in twelve chapters, this book addresses fundamental, theoretical, implementation and experimentation issues. The chapters are organized into four parts namely multi-robots systems, data fusion and localization, security and dependability, and mobility. This two volume set constitutes the refereed post-conference proceedings of the Second International Conference on Machine Learning and Intelligent Communications, MLICOM 2017, held in Weihai, China, in August 2017. The 143 revised full papers were carefully selected from 225 submissions. The papers are organized thematically in machine learning, intelligent positioning and navigation, intelligent multimedia processing and security, intelligent wireless mobile network and security, cognitive radio and intelligent networking, intelligent internet of things, intelligent satellite communications and networking, intelligent remote sensing, visual computing and three-dimensional modeling, green communication and intelligent networking, intelligent ad-hoc and sensor networks, intelligent resource allocation in wireless and cloud networks, intelligent signal processing in wireless and optical communications, intelligent radar signal processing, intelligent cooperative communications and networking. A comprehensive review of the state of the art in the control of multi-agent systems theory and applications The superiority of multi-agent systems over single agents for the control of unmanned air, water and ground vehicles has been clearly demonstrated in a wide range of application areas. Their large-scale spatial distribution, robustness, high scalability and low cost enable multi-agent systems to achieve tasks that could not successfully be performed by even the most sophisticated single agent systems. Cooperative Control of Multi-Agent Systems: Theory and Applications provides a wide-ranging review of the latest developments in the cooperative control of multi-agent systems theory and applications. The applications described are mainly in the areas of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Throughout, the authors link basic",,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
586d40cc9f8a88e469bf67d8ac29ce1706e212aa,https://www.semanticscholar.org/paper/586d40cc9f8a88e469bf67d8ac29ce1706e212aa,Automatic Speaker Recognition System Pdf Read,"This book constitutes the thoroughly refereed post-conference proceedings of the Second International Symposium on Intelligent Informatics (ISI 2013) held in Mysore, India during August 23-24, 2013. The 47 revised papers presented were carefully reviewed and selected from 126 initial submissions. The papers are organized in topical sections on pattern recognition, signal and image processing; data mining, clustering and intelligent information systems; multi agent systems; and computer networks and distributed systems. The book is directed to the researchers and scientists engaged in various fields of intelligent informatics. The conference will consist of various topics relating to power systems, robotics, mechatronics and pattern recognition Automatic Speech and Speaker RecognitionAdvanced TopicsSpringer Science & Business Media This book presents an overview of speaker recognition technologies with an emphasis on dealing with robustness issues. Firstly, the book gives an overview of speaker recognition, such as the basic system framework, categories under different criteria, performance evaluation and its development history. Secondly, with regard to robustness issues, the book presents three categories, including environment-related issues, speaker-related issues and application-oriented issues. For each category, the book describes the current hot topics, existing technologies, and potential research focuses in the future. The book is a useful reference book and self-learning guide for early researchers working in the field of robust speech recognition. Speech Recognition has a long history of being one of the difficult problems in Artificial Intelligence and Computer Science. As one goes from problem solving tasks such as puzzles and chess to perceptual tasks such as speech and vision, the problem characteristics change dramatically: knowledge poor to knowledge rich; low data rates to high data rates; slow response time (minutes to hours) to instantaneous response time. These characteristics taken together increase the computational complexity of the problem by several orders of magnitude. Further, speech provides a challenging task domain which embodies many of the requirements of intelligent behavior: operate in real time; exploit vast amounts of knowledge, tolerate errorful, unexpected unknown input; use symbols and abstractions; communicate in natural language and learn from the environment. Voice input to computers offers a number of advantages. It provides a natural, fast, hands free, eyes free, location free input medium. However, there are many as yet unsolved problems that prevent routine use of speech as an input device by non-experts. These include cost, real time response, speaker independence, robustness to variations such as noise, microphone, speech rate and loudness, and the ability to handle non-grammatical speech. Satisfactory solutions to each of these problems can be expected within the next decade. Recognition of unrestricted spontaneous continuous speech appears unsolvable at present. However, by the addition of simple constraints, such as clarification dialog to resolve ambiguity, we believe it will be possible to develop systems capable of accepting very large vocabulary continuous speechdictation. rd It is a pleasure and an honour both to organize ICB 2009, the 3 IAPR/IEEE Intertional Conference on Biometrics. This will be held 2–5 June in Alghero, Italy, hosted by the Computer Vision Laboratory, University of Sassari. The conference series is the premier forum for presenting research in biometrics and its allied technologies: the generation of new ideas, new approaches, new techniques and new evaluations. The ICB series originated in 2006 from joining two highly reputed conferences: Audio and Video Based Personal Authentication (AVBPA) and the International Conference on Biometric Authentication (ICBA). Previous conferences were held in Hong Kong and in Korea. This is the first time the ICB conference has been held in Europe, and by Programme Committee, arrangements and by the quality of the papers, ICB 2009 will continue to maintain the high standards set by its predecessors. In total we received around 250 papers for review. Of these, 36 were selected for oral presentation and 93 for poster presentation. These papers are accompanied by the invited speakers: Heinrich H. Bülthoff (Max Planck Institute for Biological Cybernetics, Tübgen, Germany) on “What Can Machine Vision Learn from Human Perception?”, daoki Furui (Department of Computer Science, Tokyo Institute of Technology) on “40 Years of Progress in Automatic Speaker Recognition Technology” and Jean-Christophe Fondeur (SAGEM Security and Morpho, USA) on “Large Scale Deployment of Biomrics and Border Control”. Automatic speech recognition and speaker recognition have a lot of applications in personal identification, access control and in the new manmachine-interface paradigm. The existing applications in voice-activated embedded systems solve the problem of recognition of the spoken words only or the problem of recognition of a speaker through the words uttered only. The goal of this project, therefore, is the development of a robust algorithm for both speech recognition and speaker verification. An example of a target application of this work is speech dialing of mobile phones with a speaker verification front-end in order to effect access control. In view of the memory and computational constraints of embedded systems, the dynamic time warping algorithm is used. This project only considers isolated spoken digits. The developed algorithm is coded in C language and can be ported to firmware for Arabic numeral digit recognition with a speaker verification front end for an embedded system like mobile phones. The system produced a FAR of 13.33% and a FRR of 24.3% for a total of 70 true claims and 30 false claims. It also had a word accuracy of 96.7%. The three volume set LNCS 7062, LNCS 7063, and LNCS 7064 constitutes the proceedings of the 18th International Conference on Neural Information Processing, ICONIP 2011, held in Shanghai, China, in November 2011. The 262 regular session papers presented were carefully reviewed and selected from numerous submissions. The papers of part I are organized in topical sections on perception, emotion and development, bioinformatics, biologically inspired vision and recognition, bio-medical data analysis, brain signal processing, brain-computer interfaces, brain-like systems, brain-realistic models for learning, memory and embodied cognition, Clifford algebraic neural networks, combining multiple learners, computational advances in bioinformatics, and computational-intelligent human computer interaction. The second volume is structured in topical sections on cybersecurity and data mining workshop, data mining and knowledge doscovery, evolutionary design and optimisation, graphical models, humanoriginated data analysis and implementation, information retrieval, integrating multiple nature-inspired approaches, Kernel methods and support vector machines, and learning and memory. The third volume contains all the contributions connected with multi-agent systems, natural language processing and intelligent Web information processing, neural encoding and decoding, neural network models, neuromorphic hardware and implementations, object recognition, visual perception modelling, and advances in computational intelligence methods based pattern recognition. The Defense Communications Division of ITT (ITTDCD) has developed an automatic speaker recognition (ASR) system that meets the functional requirements defined in NRL's Statement of Work. This report is organized as follows. Chapter 2 is a short history of the development of the ASR system, both the algorithm and the implementation. Chapter 3 describes the methodology of the system testing, while Chapter 4 summarizes the test results. In Chapter 5, we discuss some further testing that was performed using the GFM test material. Conclusions derived from the contract work are given Chapter 6. Speech recognition. (JES). This book is a collection research papers and articles from the 2nd International Conference on Communications and CyberPhysical Engineering (ICCCE – 2019), held in Pune, India in Feb 2019. Discussing the latest developments in voice and data communication engineering, cyber-physical systems, network science, communication software, imageand multimedia",,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
8881dadf57a7515039c978bf3755c336fbb417af,https://www.semanticscholar.org/paper/8881dadf57a7515039c978bf3755c336fbb417af,Customer Relationship Management Customer Satisfaction Ebooks Download,"This book introduces a fuzzy classification approach, which combines relational databases with fuzzy logic for more effective and powerful customer relationship management (CRM). It shows the benefits of a fuzzy classification in contrast to the traditional sharp evaluation of customers for the acquisition, retention and recovery of customers in online shops. The book starts with a presentation of the basic concepts, fuzzy set theory and the combination of relational databases and fuzzy classification. In its second part, it focuses on the customer perspective, detailing the central concepts of CRM, its theoretical constructs and aspects of analytical, operational and collaborative CRM. It juxtaposes fuzzy and sharp customer classes and shows the implications for customer positioning, mass customization, personalization, customer assessment and controlling. Finally, the book presents the application and implementation of the concepts in online shops. A detailed case study presents the application and a separate chapter introduces the fuzzy Classification Query Language (fCQL) toolkit for implementing these concepts. In its appendix the book lists the fuzzy set operators and the query language’s grammar. This work offers a state-of-the art survey of information systems research on electronic customer relationship management (eCRM). It provides important new frameworks derived from current cases and applications in this emerging field. Each chapter takes a collaborative approach to eCRM that goes beyond the analytical and operational perspectives most often taken by researchers in the field. Chapters also stress integration with other enterprise information systems. The book is organized in four parts: Part I presents an overview of the role of CRM and eCRM in marketing and supply chain management; Part II focuses on the organizational success factors behind eCRM implementation; Part III presents cases of eCRM performance enhancement; and Part IV addresses eCRM issues in business-to-consumer commerce. Continuous improvements in digitized practices have created opportunities for businesses to develop more streamlined processes. This not only leads to higher success in day-today production, but it increases the overall success of businesses. Enterprise Information Systems and the Digitalization of Business Functions is a key resource on the latest advances and research for a digital agenda in the business world. Highlighting multidisciplinary studies on data modeling, information systems, and customer relationship management, this publication is an ideal reference source for professionals, researchers, managers, consultants, and university students interested in emerging developments for business process management. Research Paper (postgraduate) from the year 2019 in the subject Business economics Customer Relationship Management, CRM, grade: 1.5, Kwame Nkrumah University of Science and Technology, language: English, abstract: Customer Relationship Management (CRM) practices are business strategies designed to reduce costs and increase profitability by solidifying customer loyalty. With intense competition among insurance companies in Ghana, this study sought to assess Customer Relationship Management practices and Customer Retention in NSIA Insurance. The study was conducted to identify critical factors necessary for customer retention in carrying out customer relationship management practices in the selected insurance company and to develop effective customer relationship management practices to manage customer retention for sustainability within the insurance industry using NSIA Insurance as a case study. Well structured questionnaires and face-to-face interview were the methods adopted for the investigation of the study. A sample size of 40 respondents was considered, they were made up of customers and the staff who are fully involved in customer relationship management of the insurance company. Data collected from the completed questionnaires and the interviews were grouped into frequency tables and expressed in percentages. The researcher relied on the SPSS in interpreting the collected data. The study shows that even though NSIA insurance has policies on customer relationship management practices, these policies are not carried out fully to accomplish the ultimate goal of customer retention. The study recommends that for the insurance company to command an adequate number of loyal customers, NSIA Insurance should consistently improve on its quality of service to address the preference of the customers and consider the five service quality constructs of reliability, assurance, tangibility, empathy and responsiveness. The two-volume set CCIS 143 and CCIS 144 constitutes the refereed proceedings of the International Conference on Electronic Commerce, Web Application, and Communication, ECWAC 2011, held in Guangzhou, China, in April 2011. The 148 revised full papers presented in both volumes were carefully reviewed and selected from a large number of submissions. Providing a forum for engineers, scientists, researchers in electronic commerce, Web application, and communication fields, the conference will put special focus also on aspects such as e-business, e-learning, and e-security, intelligent information applications, database and system security, image and video signal processing, pattern recognition, information science, industrial automation, process control, user/machine systems, security, integrity, and protection, as well as mobile and multimedia communications. Customer Relationship Management, Fourth Edition, is a much-anticipated update of a bestselling textbook, including substantial revisions to bring its coverage up to date with the very latest in CRM practice. The book introduces the concept of CRM, explains its benefits, how and why it can be used, the technologies that are deployed, and how to implement it, providing you with a guide to every aspect of CRM in your business or your studies. Both theoretically sound and managerially relevant, the book draws on academic and independent research from a wide range of disciplines including IS, HR, project management, finance, strategy and more. Buttle and Maklan, clearly and without jargon, explain how CRM can be used throughout the customer life cycle stages of customer acquisition, retention and development. The book is illustrated liberally with screenshots from CRM software applications and case illustrations of CRM in practice. New to this Edition: Updated instructor support materials online Full colour interior Brand",,2021.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
0878f21553a04ae10ed1a3e55ddf4091e6238df2,https://www.semanticscholar.org/paper/0878f21553a04ae10ed1a3e55ddf4091e6238df2,ICIN 2020 Program,"For nearly fifty years, beginning with Kleinrock's pioneering work on using queueing theory to model packet flows in communication networks, network modeling has adopted the individual packet as primary level of granularity for network modeling and analysis. With the advent of terabit-switching capabilities, information-centric networking, and data centers with complex workloads and hundreds of thousands of components, the time would seem ripe to raise the level of abstraction beyond the packet. In this talk, we identify higher-level modeling abstractions are already proving useful as well as new needed abstractions. But also we identify cases where packet-level models are still crucial in providing important insights. Wednesday, February 26 10:00 11:00 K2: Keynote 2 Softwarization and IoT evolution Lefteris Mamatas (University of Macedonia, Greece) Room: La Grande Scène Chair: Alex Galis (University College London (UCL), United Kingdom (Great Britain)) Abstract: The Internet of Things (IoT), a main enabler for Industry 4.0, is considered as a system connecting myriads of people, things and services. IoT enables new large-scale applications with diverse constraints (e.g., limited resource availability or mobility) and requirements (e.g., ultra low delays). A main challenge is the evolution beyond large networks of sensing devices to multiple cooperating network deployments that implement context-sensitive communication and cloud processing strategies, through the seamless adoption of Softwarization technologies. The talk includes the following aspects: (i) a motivation of the above vision with two novel use-cases on smart-city and maritime contexts; (ii) a discussion on the evolutionary and clean-slate approaches to the IoT Softwarization; (iii) the missing elements and open issues in Software-Defined IoT and Edge Cloud technologies; and (iv) insights from our practical experience in relevant implementations and real experiments. The Internet of Things (IoT), a main enabler for Industry 4.0, is considered as a system connecting myriads of people, things and services. IoT enables new large-scale applications with diverse constraints (e.g., limited resource availability or mobility) and requirements (e.g., ultra low delays). A main challenge is the evolution beyond large networks of sensing devices to multiple cooperating network deployments that implement context-sensitive communication and cloud processing strategies, through the seamless adoption of Softwarization technologies. The talk includes the following aspects: (i) a motivation of the above vision with two novel use-cases on smart-city and maritime contexts; (ii) a discussion on the evolutionary and clean-slate approaches to the IoT Softwarization; (iii) the missing elements and open issues in Software-Defined IoT and Edge Cloud technologies; and (iv) insights from our practical experience in relevant implementations and real experiments. Wednesday, February 26 11:30 12:30 TS3: Network Slicing Room: La Grande Scène Chair: Prosper Chemouil (Orange Labs (retired), France) TS3.1 A Lightweight Policy-aware Broker for Multi-domain Network Slice Composition Xuan-Thuy Dang (Technische Universität Berlin & DAI Labor, Germany); Fikret Sivrikaya (GT-ARC gGmbH & Technische Universität Berlin, Germany) TS3.2 Enhancing the performance of 5G slicing operations via multi-tier orchestration Miquel Puig Mena (i2cat Foundation, Spain); Apostolos Papageorgiou, Leonardo Ochoa-Aday and Muhammad Shuaib Siddiqui (Fundació i2CAT, Internet i Innovació Digital a Catalunya, Spain); Gabriele Baldoni (ADLINK Technology, France) TS3.3 An Efficient Online Heuristic for Mobile Network Slice Embedding Katja Ludwig (University of Augsburg, Germany); Andrea Fendt (Nokia Bell Labs & University of Augsburg, Germany); Bernhard Bauer (University of Augsburg, Germany) Wednesday, February 26 12:30 13:00 DPS: Demo/Poster ""Elevator Pitch"" Session Room: La Grande Scène Chair: Prosper Chemouil (Orange Labs (retired), France) DPS.1 A QUIC-based proxy architecture for an efficient hybrid backhaul transport Michele Luglio and Mattia Quadrini (University of Rome Tor Vergata Dip. Ing. Elettronica, Italy); Cesare Roseti and Francesco Zampognaro (University of Rome Tor Vergata, Italy); Simon Pietro Romano (University of Napoli Federico II, Italy) DPS.2 A Blockchain-based Brokerage Platform for Fog Computing Resource Federation Marco Savi, Daniele Santoro, Katarzyna Di Meo and Daniele Pizzolli (Fondazione Bruno Kessler, Italy); Miguel Pincheira (OpenIoT Research Area, FBK CREATE-NET & University of Trento, Italy); Raffaele Giaffreda (FBK CREATE-NET, Italy); Silvio Cretti (Fondazione Bruno Kessler, Italy); Seung-woo Kum (Korea Electronics Technology Institute, Korea (South)); Domenico Siracusa (Fondazione Bruno Kessler, Italy) DPS.3 Optimized Network Slicing Proof-of-Concept with Interactive Gaming Use Case José J Alves Esteves, Jr. (Orange Labs & Sorbonne Université, France); Amina Boubendir and Fabrice M. Guillemin (Orange Labs, France); Pierre Sens (Université de Paris 6, France) DPS.4 A Deployable Containerized 5G Core Solution for Time Critical Communication in Smart Grid Van Giang Nguyen, Karl-Johan Grinnemo, Javid Taheri and Anna Brunstrom (Karlstad University, Sweden) DPS.5 FogGuru: a Fog Computing platform based on Apache Flink Davaadorj Battulga (University of Rennes 1 & U-Hopper, Italy); Daniele Miorandi (U-Hopper, Italy); Cedric Tedeschi (University of Rennes I / INRIA, France) DPS.6 5G Experimentation Framework: Architecture Specifications, Design and Deployment Louiza Yala (Orange Labs, France); Sihem Cherrared (University of Rennes 1 & Orange Labs and INRIA, France); Grzegorz Panek (Orange Polska, Poland); Sofiane Imadali and Ayoub Bousselmi (Orange Labs, France) DPS.7 A New Service Management Framework for Vehicular Networks Jose Ramirez, Onyekachukwu Augustine Ezenwigbo, Gayathri Karthick and Ramona Trestian (Middlesex University, United Kingdom (Great Britain)); Glenford E Mapp (MIddlesex University & Cantego Limited, United Kingdom (Great Britain)) DPS.8 Creating trust in automation in intent-based mobile network management Ville Vartiainen (Aalto University, Finland); Dmitry Petrov and Vilho Räisänen (Nokia Bell Labs, Finland) DPS.9 Interoperable and discrete eHealth Data Exchange between Hospital and Patient Andreea Ancuta Corici, Olaf Rode, Ben Kraufmann, Andreas Billig, Jörg Caumanns and Markus Deglmann (Fraunhofer FOKUS, Germany); Viktoria Walter, Janina Rexin and Gunther Nolte (Vivantes Netzwerk für Gesundheit GmbH, Germany) Wednesday, February 26 14:00 15:00 K3: Keynote 3 Network Operations and AI Rafia Inam (Ericsson, Sweden) Room: La Grande Scène Chair: Diego Lopez (Telefonica I+D, Spain) Abstract: The Fifth Generation Mobile Networks (5G) are seen as a key enabler for diverse-natured industry verticals (such as automotive, manufacturing, mining, utility, health, etc.) by providing a platform to support heterogeneous sets of network quality requirements. The presentation will discuss how Artificial Intelligence and automation can support Telecom industry to manage the increased complexity, scalability, and diversity in its use cases. The work presents different aspects of the network operations of the future, done in an automated, proactive, and intent-driven fashion using different AI techniques. The Fifth Generation Mobile Networks (5G) are seen as a key enabler for diverse-natured industry verticals (such as automotive, manufacturing, mining, utility, health, etc.) by providing a platform to support heterogeneous sets of network quality requirements. The presentation will discuss how Artificial Intelligence and automation can support Telecom industry to manage the increased complexity, scalability, and diversity in its use cases. The work presents different aspects of the network operations of the future, done in an automated, proactive, and intent-driven fashion using different AI techniques. Wednesday, February 26 15:00 16:10 TS4: Improving Service Performance Room: La Grande Scène Chair: Amina Boubendir (Orange Labs, France) TS4.1 Multimedia Service Management with Virtualized Cache Migration Reza Shokri Kalan (Ege UniversityTurkey, Turkey); Muge Sayit (Ege University, Turkey); Stuart Clayman (University College London (UCL), United Kingdom (Great Britain)) TS4.2 Proposal of Profile and Event Sharing by Agent Communication Masafumi Katoh (Fujitsu Labotatories Ltd., Japan); Tomonori Kubota and Eiji Yoshida (Fujitsu Laboratories, Japan); Yuji Kojima (Fujitsu Limited, Japan); Yuuichi Yamagishi (FUJITSU LIMITED, Japan) TS4.3 Double Mask: An Efficient Rule Encoding for Software Defined Networking Ahmad Abboud (University of Lorraine, France); Abdelkader Lahmadi (INRIA Nancy Grand Est, France); Michael Rusinowitch (INRIA Nancy-Grand Est, France); Miguel Couceiro (University of Lorraine, France); Adel Bouhoula (Higher School of Communication of Tunis & University of Carthage, Tunisia); Mondher Ayadi (Numeryx, France) Wednesday, February 26 16:35 18:00 TS5: Network Security Room: La Grande Scène Chair: Ved P. Kafle (National Institute of Information and Communications Technology, Japan) TS5.1 Neural network based anomaly detection for SCADA systems Lenhard Reuter (AIT Austrian Institute of Technology, Austria); Oliver Jung (AIT Austrian Institute of Technology GmbH, Austria); Julian Magin (AIT Austrian Institute of Technology, Austria) TS5.2 DDoS Detection System Using Feature Selection and Machine Learning Algorithms in a Distributed System Amjad Alsirhani (Dalhousie University, Faculty of Computer Science & Canada, Canada); Geetanshu Grover and Srinivas Sampalli (Dalhousie University, Canada); Peter Bodorik (Dalhousie University, Faculty of Computer Science, Canada) TS5.3 Configuration of the Detection Function in a Distributed IDS Using Game Theory Clement Weill (Institut Polytechnique de Paris & CEA LIST, France); Alexis Olivereau (CEA, LIST, France); Djamal Zeghlache (Insti","2020 23rd Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)",2020.0,10.1109/icin48450.2020.9059372,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
54787e19899972f47f154f5c63254144e20edee8,https://www.semanticscholar.org/paper/54787e19899972f47f154f5c63254144e20edee8,Human-Computer Interaction,,Encyclopedia of Database Systems,1993.0,10.1007/978-0-387-39940-9_192,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a5d85748055ff954e38c4c1f24138d614d4323fa,https://www.semanticscholar.org/paper/a5d85748055ff954e38c4c1f24138d614d4323fa,SmartDashCam: Automatic Live Calibration for DashCams,"Dashboard camera installations are becoming increasingly common due to various Advanced Driver Assistance Systems (ADAS) based services provided by them. Though deployed primarily for crash recordings, calibrating these cameras can allow them to measure real-world distances, which can enable a broad spectrum of ADAS applications such as lane-detection, safe driving distance estimation, collision prediction, and collision prevention Today, dashboard camera calibration is a tedious manual process that requires a trained professional who needs to use a known pattern (e.g., chessboard-like) at a calibrated distance. In this paper, we propose SmartDash-Cam, a system for automatic and live calibration of dashboard cameras which always ensures highly accurate calibration values. Smart-DashCam leverages collecting images of a large number of vehicles appearing in front of the camera and using their coarse geometric shapes to derive the calibration parameters. In sharp contrast to the manual process we are proposing the use of a large amount of data and machine learning techniques to arrive at calibration accuracies that are comparable to the manual process. SmartDashCam implemented using commodity dashboard cameras estimates realworld distances with mean errors of 5.7 % which closely rivals the 4.1% mean error obtained from traditional manual calibration using known patterns.",2019 18th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN),2019.0,10.1145/3302506.3310397,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
68ab393451f124597b46cce4a68ec29fb392fc7d,https://www.semanticscholar.org/paper/68ab393451f124597b46cce4a68ec29fb392fc7d,"Service-Oriented Computing - ICSOC 2007, Fifth International Conference, Vienna, Austria, September 17-20, 2007, Proceedings",,ICSOC,2007.0,10.1007/978-3-540-74974-5,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
45cbdace972359f0ae71b35b3714a6f4ec4a1816,https://www.semanticscholar.org/paper/45cbdace972359f0ae71b35b3714a6f4ec4a1816,IEEE INFOCOM 2020 Workshops: IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS) - Program,"In the past decade, applications of Internet of Things (IoT) such as Smart Home, Smart Cities, Smart Healthcare etc. have been deployed where the devices in our surroundings are interconnected to provide better services and comfort to humans. More recently, we witness the emerging applications in industrial internet, supply chains and other areas where the scale of the systems, the number of devices and data being generated continuously increases. It will be at very high cost to send all the data to a centralized server, as done in cloud computing, for processing and decision-making. Therefore, recent trend is to move the computation tasks from centralized cloud to edge devices which are closer to data sources. In this talk, I will describe Edge, an infrastructure for collaborative edge computing, where the intelligence and decision-making are pushed to the edge of and within the network closer to the sources of data, EdgeMesh lets the edge devices share the data and collaborate on the computation tasks. It also facilitates higher scalability and reliability with flexible and dynamic system reconfiguration. Short Bio: Dr. Cao is currently a Chair Professor of Department of Computing at The Hong Kong Polytechnic University, Hong Kong. He is also the director of the Internet and Mobile Computing Lab in the department and the director of University's Research Facility in Big Data Analytics. His research interests include parallel and distributed computing, wireless sensing and networks, pervasive and mobile computing, and big data and cloud computing. He has co-authored 5 books, co-edited 9 books, and published over 600 papers in major international journals and conference proceedings. He received Best Paper Awards from conferences including IEEE DSAA 2017, IEEE SMARTCOMP 2016, IEEE ISPA 2013, IEEE WCNC 2011, etc. Dr. Cao served the Chair of the Technical Committee on Distributed Processing of IEEE Computer Society from 2012 to 2014, a member of IEEE Fellows Evaluation Committee of the Computer Society and the Reliability Society, a member of IEEE Computer Society Education Awards Selection Committee, a member of IEEE Communications Society Awards Committee, and a member of Steering Committee of IEEE Transactions on Mobile Computing. He has also served as chairs and members of organizing and technical committees of many international conferences, and as associate editor and member of the editorial boards of many international journals. Dr. Cao is a fellow of IEEE and ACM distinguished member. In 2017, he received the Overseas Outstanding Contribution Award from China Computer Federation. Sunday, April 28 10:30 11:45 Mobile Edge Computing Room: Forum E Chair: Xu Chen (Sun Yat-sen University, P.R. China) Economics of Investment and Use of Shared Network Infrastructures Iordanis Koutsopoulos (Athens University of Economics and Business, Greece); Angeliki Anastopoulou (Athens University of Economics and Business & Center for Research and Technology Hellas, Greece); Merkourios Karaliopoulos (Athens University of Economics and Business, Greece) PayFlow: Micropayments for Bandwidth Reservations in Software Defined Networks David Chen, Zhiyue Zhang, Ambrish Krishnan and Bhaskar Krishnamachari (University of Southern California, USA) DeepMarket: An Edge Computing Marketplace with Distributed TensorFlow Execution Capability Susham Yerabolu, Soyoung Kim, Samuel Gomena, Xuanzhe Li, Rohan Patel, Shraddha Bhise and Ehsan Aryafar (Portland State University, USA) Sunday, April 28 10:30 11:30 Session 1: Cloud Applications Room: Scene D Chair: Qichao Xu (Shanghai University, P.R. China) Session 1.1 Credible and Economic Multimedia Service Optimization in Cloud Network Tengfei Cao, Changqiao Xu and Han Xiao (Beijing University of Posts and Telecommunications, P.R. China); Lujie Zhong (Capital Normal University, P.R. China) Session 1.2 Reinforcing the Edge: Autonomous Energy Management for Mobile Device Clouds Venkatraman Balasubramanian (Arizona State University, USA); Faisal Zaman (University of Ottawa, Canada); Moayad Aloqaily (Gnowit Inc., Canada); Saed Alrabaee (United Arab Emirates University, United Arab Emirates); Maria Gorlatova (Duke University, USA); Martin Reisslein (Arizona State University, USA) Session 1.3 Context-Aware Service Chaining Framework for Over-the-Top Applications in 5G Networks Chang Ge, David Lake, Ning Wang, Yogaratnam Rahulan and Rahim Tafazolli (University of Surrey, United Kingdom (Great Britain)) Sunday, April 28 11:30 12:30 Session 2: Cloud System Room: Scene D Chair: David Lake (University of Surrey, United Kingdom (Great Britain)) Session 2.1 Design and Evaluation of a Software Defined Passive Optical Intra-Rack Network in Data Centers Yueping Cai, Sen Luo, Li Zhou, Zongchen Yao and Tianchi Li (Chongqing University, P.R. China) Session 2.2 Point Estimator Log Tracker for Cloud Monitoring Tariq Daradkeh and Anjali Agarwal (Concordia University, Canada); Nishith Goel (Cistel, Canada); Andrew J. Kozlowski (Cistech Ltd., Canada) Session 2.3 Cyberspace Surveying and Mapping: Hierarchical Model and Resource Formalization Rui Xu (Cyberspace Security Key Laboratory of Sichuan Province & China Electronic Technology Cyber Security Co., Ltd, P.R. China); Zhiyong Zhang and ZhiHong Rao (China Electronic Technology Cyber Security Co., Ltd & Cyberspace Security Key Laboratory of Sichuan Province, P.R. China); Jianfeng Chen (China Electronic Technology Cyber Security Co. Ltd, P.R. China); Ming LI (China Electronic Technology Cyber Security Co., Ltd, P.R. China); Fang Liu (China Electronic Technology Cyber Security Co., Ltd & Cyberspace Security Key Laboratory of Sichuan Province, P.R. China); Shengli Pan (China University of Geosciences (Wuhan), P.R. China) Sunday, April 28 13:30 14:30 Session 3: Cloud Security Room: Scene D Chair: Zhi Zhou (Sun Yat-sen University, P.R. China) Session 3.1 Policy-based Bigdata Security and QoS Framework for SDN/IoT: An Analytic Approach Keshav Sood (Deakin University, Melbourne Australia, Australia); Shiva Raj Pokhrel (Deakin University & Nepal Telecom, Australia); Shui Yu (University of Technology Sydney, Australia); Mohammad Reza Nosouhi (University of Technology Sydney & CSIRO' Data61, Australia) Session 3.2 Intrusion Detection in Autonomous Vehicular Networks: A Trust Assessment and Q-learning Approach Rui Xing and Zhou Su (Shanghai University, P.R. China); Yuntao Wang (Xi'an Jiaotong University, P.R. China) Session 3.3 Early Online Classification of Encrypted Traffic Streams using Multi-fractal Features Erik Areström and Niklas Carlsson (Linköping University, Sweden) Sunday, April 28 14:30 15:30 Keynote Session 2: Automated Management of Softwarized and Virtualized Network Functions Xiaoming Fu Room: Scene D Chair: Zhi Zhou (Sun Yat-sen University, P.R. China) Abstract: Online management of large-scale cloud and virtualized resources poses many challenges and opportunities. As emerging network appliances, such as firewalls, loadbalancing, QoS and DPI, are more and more implemented as software-defined functions and converging on the cloudized and virtualized network infrastructure, the management of such functions becomes more and more critical. I will introduce some of our recent work towards efficient management of NFV-based service chaining, placement of data and virtual machines (VMs), as well as scheduling of NFV resources. Online management of large-scale cloud and virtualized resources poses many challenges and opportunities. As emerging network appliances, such as firewalls, loadbalancing, QoS and DPI, are more and more implemented as software-defined functions and converging on the cloudized and virtualized network infrastructure, the management of such functions becomes more and more critical. I will introduce some of our recent work towards efficient management of NFV-based service chaining, placement of data and virtual machines (VMs), as well as scheduling of NFV resources. Short Bio: Prof. Xiaoming Fu received his Ph.D. from Tsinghua University, Beijing, China in 2000. He was then a research staff at the Technical University Berlin until joining University of Göttingen as an assistant professor in 2002, where he has been a professor in computer science and heading the Computer Networks Group since 2007, and the founding director of Sino-German Institute of Social Computing since 2015. Prof. Fu's research interests lie in networked systems and applications, including cloud computing, mobile computing, big data and social networks. He has actively participated in national and international projects, including as coordinator of EU FP7 GreenICN, CleanSky and MobileCloud projects as well as H2020 ICN2020 project. He has also served on the program or organization committees of several conferences such as ACM SIGCOMM, CoNEXT, MOBICOM, ICN, IEEE INFOCOM, ICNP and ICDCS. He is a Fellow the IET and the Academia Europaea, an IEEE senior member and Distinguished Lecturer, and has served as secretary (2008-2010) and vice chair (2010-2012) of IEEE Communications Society Technical Committee on Computer Communications (TCCC), as well as as chair (2011-2013) of the Internet Technical Committee (ITC), the joint committee of IEEEE Communications Society and the Internet Society. Sunday, April 28 16:00 18:00 S4: Age of Information in Wireless Networks Room: Scene C Chair: Bo Ji (Temple University, USA) Maintaining Information Freshness under Jamming Andrey Garnaev (WINLAB, Rutgers University, USA); Wuyang Zhang, Jing Zhong and Roy Yates (Rutgers University, USA) Fundamental Bounds on the Age of Information in General Multi-Hop Interference Networks Shahab Farazi (Worcester Polytechnic Institute, USA); Andrew G. Klein (Western Washington University, USA); Donald R. Brown, III (Worcester Polytechnic Institute, USA) Minimizing The Age of Information: NOMA or OMA? Ali Maatouk (CentraleSupélec, France); Mohamad Assaad (CentraleSupelec, France); Anthony Ephremides (University of Marylan",IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),2019.0,10.1109/infcomw.2019.8845227,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
972b20f1a231cb991f43b5a8dc99b8892c6a3db9,https://www.semanticscholar.org/paper/972b20f1a231cb991f43b5a8dc99b8892c6a3db9,Stress Detection for Keystroke Dynamics,"Background. Stress can profoundly affect human behavior. Critical-infrastructure operators (e.g., at nuclear power plants) may make more errors when overstressed; malicious insiders may experience stress while engaging in rogue behavior; and chronic stress has deleterious effects on mental and physical health. If stress could be detected unobtrusively, without requiring special equipment, remedies to these situations could be undertaken. In this study a common computer keyboard and everyday typing are the primary instruments for detecting stress. Aim. The goal of this dissertation is to detect stress via keystroke dynamics – the analysis of a user’s typing rhythms – and to detect the changes to those rhythms concomitant with stress. Additionally, we pinpoint markers for stress (e.g., a 10% increase in typing speed), analogous to the antigens used as markers for blood type. We seek markers that are universal across all typists, as well as markers that apply only to groups or clusters of typists, or even only to individual typists. Data. Five types of data were collected from 116 subjects: (1) demographic data, which can reveal factors (e.g., gender) that influence subjects’ reactions to stress; (2) psychological data, which capture a subject’s general susceptibility to stress and anxiety, as well as his/her current stress state; (3) physiological data (e.g., heart-rate variability and blood pressure) that permit an objective and independent assessment of a subject’s stress level; (4) self-report data, consisting of subjective self-reports regarding the subject’s stress, anxiety, and workload levels; and (5) typing data from subjects, in both neutral and stressed states, measured in terms of keystroke timings – hold and latency times – and typographical errors. Differences in typing rhythms between neutral and stressed states were examined to seek specific markers for stress. Method. An ABA, single-subject design was used, in which subjects act as their own controls. Each subject provided 80 typing samples in each of three conditions: (A) baseline/neutral, (B) induced stress, and (A) post-stress return/recovery-to-baseline. Physiological measures were analyzed to ascertain the subject’s stress level when providing each sample. Typing data were analyzed, using a variety of statistical and machine learning techniques, to elucidate markers of stress. Clustering techniques (e.g., K-means) were also employed to detect groups of users whose responses to stress are similar. Results. Our stressor paradigm was effective for all 116 subjects, as confirmed through analysis of physiological and self-report data. We were able to identify markers for stress within each subject; i.e., we can discriminate between neutral and stressed typing when examining any subject individually. However, despite our best attempts, and the use of state-of-the-art machine learning techniques, we were not able to identify universal markers for stress, across subjects, nor were we able to identify clusters of subjects whose stress responses were similar. Subjects’ stress responses, in typing data, appear to be highly individualized. Consequently, effective deployment in a realworld environment may require an approach similar to that taken in personalized medicine.",,2018.0,10.1184/R1/6723227.V3,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
7bab1583623e8446b6dce1fbf30eef487aca2e64,https://www.semanticscholar.org/paper/7bab1583623e8446b6dce1fbf30eef487aca2e64,A computational approach to the art of visual storytelling,"For millennia, humanity as been using images to tell stories. In modern society, these visual narratives take the center stage in many different contexts, from illustrated children’s books to news media and comic books. They leverage the power of compounding various images in sequence to present compelling and informative narratives, in an immediate and impactful manner. In order to create them, many criteria are taken into account, from the quality of the individual images to how they synergize with one another. With the rise of the Internet, visual content with which to create these visual storylines is now in abundance. In areas such as news media, where visual storylines are regularly used to depict news stories, this has both advantages and disadvantages. Although content might be available online to create a visual storyline, filtering the massive amounts of existing images for high quality, relevant ones is a hard and time consuming task. Furthermore, combining these images into visually and semantically cohesive narratives is a highly skillful process and one that takes time. As a first step to help solve this problem, this thesis brings state of the art computational methodologies to the age old tradition of creating visual storylines. Leveraging these methodologies, we define a three part architecture to help with the creation of visual storylines in the context of news media, using social media content. To ensure the quality of the storylines from a human perception point of view, we deploy methods for filtering and raking images according to news quality standards, we resort to multimedia retrieval techniques to find relevant content and we propose a machine learning based approach to organize visual content into cohesive and appealing visual narratives.",,2018.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,https://www.semanticscholar.org/paper/4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,Implementing Operational Analytics using Big Data Technologies to Detect and Predict Sensor Anomalies,"Operational analytics when combined with Big Data technologies and predictive techniques have been shown to be valuable in detecting mission critical sensor anomalies that might be missed by conventional analytical techniques. Our approach helps analysts and leaders make informed and rapid decisions by analyzing large volumes of complex data in near real-time and presenting it in a manner that facilitates decision making. It provides cost savings by being able to alert and predict when sensor degradations pass a critical threshold and impact mission operations. Operational analytics, which uses Big Data tools and technologies, can process very large data sets containing a variety of data types to uncover hidden patterns, unknown correlations, and other relevant information. When combined with predictive techniques, it provides a mechanism to monitor and visualize these data sets and provide insight into degradations encountered in large sensor systems such as the space surveillance network. In this study, data from a notional sensor is simulated and we use big data technologies, predictive algorithms and operational analytics to process the data and predict sensor degradations. This study uses data products that would commonly be analyzed at a site. This study builds on a big data architecture that has previously been proven valuable in detecting anomalies. This paper outlines our methodology of implementing an operational analytic solution through data discovery, learning and training of data modeling and predictive techniques, and deployment. Through this methodology, we implement a functional architecture focused on exploring available big data sets and determine practical analytic, visualization, and predictive technologies. APPROACH This study developed an operational analytics implementation that uses Big Data technologies and machine learning algorithms to determine and predict sensor anomalies. A previous study [1] showed that Big Data Analytics can uncover anomalies that may be missed through conventional analyses. This study enhances that effort and shows a methodology to implement operational analytics that can be applied toward common solutions for data analysis. Our operational analytics implementation relies on continuous learning from historical data to analyze data in the stream of real-time operations. In the previous study, where data was identified that can be used to uncover anomalies, this implementation extends that approach and now identifies trends and correlations that reveal anomalies that can be missed by traditional analytic techniques with limited datasets. This study adopted a three-step methodology to implementing operational analytics – Discovery, Modeling and Operations as shown in Fig. 1. Copyright © 2016 Advanced Maui Optical and Space Surveillance Technologies Conference (AMOS) – www.amostech.com Fig. 1. Operational Implementation Approach Fig. 1 shows the three steps to implement operational analytics and the continuous feedback between learning and operational deployment. The following sections will elaborate on the methodology employed as applied to a realworld problem of analyzing large datasets such as would be encountered at an operational site.",,2016.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
3e075a29a3d768a91816ab193ea8f31b1ff635ee,https://www.semanticscholar.org/paper/3e075a29a3d768a91816ab193ea8f31b1ff635ee,"Distributed computing and networking : 15th International Conference, ICDCN 2014, Coimbatore, India, January 4-7, 2014 : proceedings","Fast Rendezvous on a Cycle by Agents with Different Speeds.- Iterative Byzantine Vector Consensus in Incomplete Graphs.- Mutual Exclusion Algorithms in the Shared Queue Model.- On the Signaling Problem.- Optimization of Execution Time under Power Consumption Constraints in a Heterogeneous Parallel System with GPUs and CPUs.- Multicore Parallelization of the PTAS Dynamic Program for the Bin-Packing Problem.- Energy Accounting and Control with SLURM Resource and Job Management System.- Asynchronous Reconfiguration for Paxos State Machines.- A Causal Checkpointing Algorithm for Mobile Computing Environments.- Gathering and Exclusive Searching on Rings under Minimal Assumptions.- Online Algorithms to Generate Slices for Regular Temporal Logic Predicates.- HiperTM: High Performance, Fault-Tolerant Transactional Memory.- Non-interference and Local Correctness in Transactional Memory.- A TimeStamp Based Multi-version STM Algorithm.- Optimized OR-Sets without Ordering Constraints.- Quorums Quicken Queries: Efficient Asynchronous Secure Multiparty Computation.- Conscious and Unconscious Counting on Anonymous Dynamic Networks.- On Probabilistic Snap-Stabilization.- Backward-Compatible Cooperation of Heterogeneous P2P Systems.- Towards a Peer-to-Peer Bandwidth Marketplace.- A Fault Tolerant Parallel Computing Scheme of Scalar Multiplication for Wireless Sensor Networks.- Conflict Resolution in Heterogeneous Co-allied MANET: A Formal Approach.- Batch Method for Efficient Resource Sharing in Real-Time Multi-GPU Systems.- Impairment-Aware Dynamic Routing and Wavelength Assignment in Translucent Optical WDM Networks.- Mobility Aware Charge Scheduling of Electric Vehicles for Imbalance Reduction in Smart Grid.- Effective Scheduling to Tame Wireless Multi-Hop Forwarding.- Dynamic Gateway Selection for Load Balancing in LTE Networks.- Exploiting Scalable Video Coding for Content Aware Downlink Video Delivery over LTE.- Stochastic Model for Cognitive Radio Networks under Jamming Attacks and Honeypot-Based Prevention.- InterCloud RAIDer: A Do-It-Yourself Multi-cloud Private Data Backup System.- Improved Heterogeneous Human Walk Mobility Model with Hub and Gateway Identification.- FlowMaster: Early Eviction of Dead Flow on SDN Switches.- A Simple Lightweight Encryption Scheme for Wireless Sensor Networks.- Analyzing the Network Connectivity Probability of a Linear VANET in Nakagami Fading Channels.- Max-Min-Path Energy-Efficient Routing Algorithm - A Novel Approach to Enhance Network Lifetime of MANETs.- Towards a New Internetworking Architecture: A New Deployment Approach for Information Centric Networks.- Energy-Efficient Multimedia Communication for Cognitive Radio Networks.- Stabilizing Dining with Failure Locality 1.- Machine Learning in a Policy Driven Grid Environment.- Not So Synchronous RPC: RPC with Silent Synchrony Switch for Avoiding Repeated Marshalling of Data.",,2014.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
7d4fb2af1232d49f60ff194d2da46846cf729323,https://www.semanticscholar.org/paper/7d4fb2af1232d49f60ff194d2da46846cf729323,International symposium on distributed computing and artificial intelligence 2008 (DCAI 2008),,,2008.0,10.1007/978-3-540-85863-8,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
aecb51cdeb26b104fed164f67081bedb08003429,https://www.semanticscholar.org/paper/aecb51cdeb26b104fed164f67081bedb08003429,Ambient Networks : toward a Future Internet embracing the Wireless World,"The mobile phone is becoming a trusted personal device with fundamental new capabilities. New form factors of mobile device and their user interfaces require new concepts for transformable mechanics. Integration of electronics and user interface functions into structural components will be necessary. Modular architecture will enable use of optimal technology for any particular functionality and optimization of power consumption. Nanomaterials, new manufacturing solutions and energy sources together with increased memory and computing capacity will enhance the capabilities of mobile devices. Nanotechnologies will also enable embedding of intelligence into human everyday environments and body area networks. We have presented a concept device called the Morph that illustrates use and bene_ts of nanotechnologies in real life applications. 1. Transformation of mobile communication During the following ten years mobile communication and the Internet will converge into a global information platform. Mobile phones have already become an enabling platform for digital services and applications. Mobile phones are powerful multimedia computers with wide range of functionality, e.g., imaging, navigation, music, content management, browsing, email, and time management. Increasingly they will have advanced multi-access communication, information processing, multimedia, mass storage and multimodal user interface capabilities. In the continuation these trusted personal devices will also have new capabilities: Interacting with local environment via embed-ded short range radios, sensors, cameras, and audio functionality; Functioning both as servers for global and local internet services and as clients for global internet services; Serving as gateways that connect local information and global internet based services; Carrying the digital identity of the user and enabling easy-to-use secure communication and controlled privacy in future smart spaces; Sensing local context and the behaviour of its user. Context awareness, including location, is the fundamental underlying capability of the future mobile devices. These context sensitive devices will open wide range of solutions for Internet services and mobile communication. Sensors, positioning and powerful signal processing embedded in mobile devices make it possible to detect, observe and follow different events and patterns in user's behavior and surrounding environments with precise location. Mobile device becomes a cognitive user interface that is continuously connected to the local environment and to the Internet Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES services. Context awareness has also profound inuence on the development of future communication and computing solutions by enabling intelligent allocation and sharing of resources. Form factors and user interface concepts of mobile multimedia computers will vary according to the usage scenario. The tendency towards smaller and thinner structures as well as towards reliable transformable mechanics will continue. The desire to have curved, flexible, compliant, stretchable structures and more freedom for industrial design sets demanding requirements for displays, keyboard, antennas, batteries, electromagnetic shielding and electronics integration technologies. A possibility to integrate electronics and user interface functions into structural components, such as covers, will be necessary. Modular device architecture of mobile multimedia computers will consist of several functional subsystems that are connected together via very high speed asynchronous serial interfaces [5, 6]. The modular approach enables the use of optimal technology for any particular functionality, optimization of power consumption, and the modular development of device technologies and software. The same modular architecture can be extended from one device to a distributed system of devices that shares the same key content, e.g., a remote mass storage, display or a printer. Nanoscience means capabilities to image, measure and manipulate physical and chemical processes at molecular level. These capabilities convert into nanotechnologies that are based on physical and chemical phenomena that emerge at nanoscale. Thus nanotechnologies are not just a continuation of the miniaturization roadmap but offer new capabilities to create solutions for health care, information technologies, materials and manufacturing. These pervasive capabilities will affect mobile communication [2]. Nanotechnologies for sensing, computing, radios, displays, structural and surface materials will enable creative design of future mobile devices and services. Mobile communication and the Internet are converging: wireless communication will nd optimal solutions based on both regulated mobile communication (3GPP track) and unregulated local access (IEEE track) solutions. Flexible and efficient local access will support sensing, computing and actuation in mobile devices that are continuously onnected to the Internet services. Implementation of sensors and multi-modal user interface features together with energy efficient local connectivity will enable new mobile services and new paradigms of communication, e.g., ad hoc social networking. Context awareness and machine learning will create the user experience seamless connectivity and information access but require powerful embedded computing solutions. Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES 2. Sensing and signal processing Sensors can already be found as key features of various battery powered, handheld devices. Especially, location, motion and gesture recognition are new pervasive elements of applications, user interfaces and services. One of the enablers of this rapid development has been microelectromechanical systems (MEMS) based on micromachining of silicon (see a review in [4]). The need for low cost, reliable sensors for automotive applications initiated the mass manufacture of silicon MEMS sensors. The requirements of consumer electronics, especially of sport gadgets, mobile phones and game controllers, have driven further the miniaturization of MEMS devices. Today MEMS and CMOS technologies provide a solid basis for large scale deployment of sensor applications. The opportunity to connect locally measured information to Internet services and to incorporate this local information into structured global information might be even more significant. Example of benefits include real time tracking of the spread of a disease or epidemic or interpretation of changes in traffic patterns on roads through a combination of local sensors and the Internet. The Internet is becoming a massive store of heterogeneous data and linked information. Extremely efficient search and data mining technologies are creating a dynamic and real time map of the physical world with its various economical and social networks. Nanotechnologies may not revolutionize sensor technologies and applications. Existing sensor technologies based on MEMS and CMOS platforms have not yet fully met their potential to provide sensor applications and networks that improve the human everyday environment. However, nanotechnologies, i.e., different nanoscale building blocks and fabrication processes, will affect the development of sensors, their signal processing and actuators. Nanotechnologies will extend the applications of sensors to new potential fields, such as smart spaces, body area networks, remote health care, and pervasive environmental monitoring (see a review in [7, 8]). Many nanoscale sensors are related to chemical and biochemical sensing where nanoscale transducers create a possibility to derive more detailed information on observed phenomena. Nanotechnologies offer a new possibility to create nanoscale transducers, memory and computing elements and to merge these elements together to form an intelligent sensor system. The same technology, e.g., silicon or ZnO nanowires or carbon nanotubes, can be used to create various functional elements for these systems. Several possible architectures, e.g., coupled resonator arrays, nanowire crossbars, plasmonics, and spiking neuron networks can be used for both sensing and signal processing. Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES 3. Morph Nanotechnologies in future mobile devices Transformation of the device can essentially happen in many levels: transformation of graphical user interface, mechanical configuration, available applications and services. The Morph device [1] is transformable in many different ways. The user interface of the device can adapt to the context of the user in terms of functionality but also its appearance. Transformability can be used to enable the ease of use of the device, applications and services. The Morph device is transformable in its form and conformation. The Morph is a cognitive user interface, capable of sensing both the user and the environment, making decisions based on this information, adapting to the context and give feedback to the user. The Morph learns about its user and becomes a trusted personal companion. The last forty years of development in electronics have targeted to ever increasing integration of functionality, i.e., very large scale integration. There is no doubt that this development will continue to build even more efficient solutions for sensing, computing and communication. However, interfaces of future devices with the physical world and their users require new type of intelligent and energy efficient sensors and actuators that can benefit of development of low cost electronics manufacturing and functional materials. Printed electronics creates capabilities to integrate functio",,2010.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
8ae4034b50c050d7654c921f4040c982a50b9875,https://www.semanticscholar.org/paper/8ae4034b50c050d7654c921f4040c982a50b9875,Beginning Java ME Platform,,,2008.0,10.1007/978-1-4302-1062-7,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
1b98e364526f0aea3dd50bb5f2c4dad787ef83b3,https://www.semanticscholar.org/paper/1b98e364526f0aea3dd50bb5f2c4dad787ef83b3,"Advances in Web-Age Information Management, 6th International Conference, WAIM 2005, Hangzhou, China, October 11-13, 2005, Proceedings",,WAIM,2005.0,10.1007/11563952,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
cc6f9c7e3008bb8e22fde3dee6d07eb2979d9036,https://www.semanticscholar.org/paper/cc6f9c7e3008bb8e22fde3dee6d07eb2979d9036,"Advanced Parallel Programming Technologies, 5th International Workshop, APPT 2003, Xiamen, China, September 17-19, 2003, Proceedings",,APPT,2003.0,10.1007/b13582,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
a407364d8d1c6cd44bffb2fa7918b4733c246a64,https://www.semanticscholar.org/paper/a407364d8d1c6cd44bffb2fa7918b4733c246a64,"Digital libraries : people, knowledge, and technology : 5th International Conference on Asian Digital Libraries, ICADL 2002, Singapore, December 11-14, 2002 : proceedings","Keynote and Invited Papers.- Challenges in Building Digital Libraries for the 21st Century.- Building Digital Libraries Made Easy: Toward Open Digital Libraries.- Dublin Core: Process and Principles.- From Digital Library to Digital Government: A Case Study in Crime Data Mapping and Mining.- Progress on Educational Digital Libraries: Current Developments in the National Science Foundation's (NSF) National Science, Technology, Engineering, and Mathematics Education Digital Library (NSDL) Program.- Examples of Practical Digital Libraries: Collections Built Internationally Using Greenstone.- Data Mining Technologies for Digital Libraries and Web Information Systems.- Papers.- Chinese Text Summarization Using a Trainable Summarizer and Latent Semantic Analysis.- A Linear Text Classification Algorithm Based on Category Relevance Factors.- A Hierarchical Framework for Multi-document Summarization of Dissertation Abstracts.- Generality of Texts.- The Effiectiveness of a Graph-Based Algorithm for Stemming.- Searching Digital Music Libraries.- The NUS Digital Media Gallery - A Dynamic Architecture for Audio, Image, Clipart, and Video Repository Accessible via the Campus Learning Management System and idtvukcan the Digital Library.- A Schema Language for MPEG-7.- Bitmap-Based Indexing for Multi-dimensional Multimedia XML Documents.- What People Do When They Look for Music: Implications for Design of a Music Digital Library.- Distributing Relevance Feedback in Content Based Image Retrieval Systems.- Multistrategy Learning of Rules for Automated Classification of Cultural Heritage Material.- VideoCube: A Novel Tool for Video Mining and Classification.- Developing Tsinghua University Architecture Digital Library for Chinese Architecture Study and University Education.- Retrieving News Stories from a News Integration Archive.- A Data Mining Approach to New Library Book Recommendations.- Grouping Web Pages about Persons and Organizations for Information Extraction.- Personalized Services for Digital Library.- Automatic References: Active Support for Scientists in Digital Libraries.- Organizing and Maintaining Dynamic Digital Collections.- Navigation, Organization, and Retrieval in Personal Digital Libraries of Email.- A Work Environment for a Digital Library of Historical Resources.- A Personalized Collaborative Digital Library Environment.- Virtual Tutor: A System for Deploying Digital Libraries in Classrooms.- Resource Annotation Framework in a Georeferenced and Geospatial Digital Library.- Building Policy, Building Community: An Example from the US National Science, Technology, Engineering, and Mathematics Education Library (NSDL).- Building a Digital Library from the Ground Up: An Examination of Emergent Information Resources in the Machine Learning Community.- Subscription Clubs for E-journals: Indian Initiatives.- A Multilingual Multi-script Database of Indian Theses: Implementation of Unicode at Vidyanidhi.- A Workbench for Acquiring Semantic Information and Constructing Dictionary for Compound Noun Analysis.- Building Parallel Corpora by Automatic Title Alignment.- Offline Isolated Handwritten Thai OCR Using Island-Based Projection with N-Gram Models and Hidden Markov Models.- A Cache-Based Distributed Terabyte Text Retrieval System in CADAL.- Rural Digital Library: Connecting Rural Communities in Nepal.- Collection Development for the Digital Age: The Case of Malaysia.- Digital Divide: How Can Digital Libraries Bridge the Gap?.- Digital Libraries in Academia: Challenges and Changes.- Building Digital Libraries for Children: Reviewing Information Literacy of Students and Teachers.- The Use and Functionality of the Environmental Data Registry: An Evaluation of User Feedback.- Adding Semantics to 3D Digital Libraries.- INEXP: Information Exchange Protocol for Interoperability.- Study on Data Placement and Access Path Selection in an FC-SAN Virtual Storage Environment.- Building an OAI-Based Union Catalog for the National Digital Archives Program in Taiwan.- Intergenerational Partnerships in the Design of a Digital Library of Geography Examination Resources.- Pie Charts for Visualizing Query Term Frequency in Search Results.- Information Therapy in Digital Libraries.- Evaluation of Task Based Digital Work Environment.- A Framework for Flexible Information Presentation in Digital Collections.- Electronic Journal of the University of Malaya (EJUM): An Attempt to Provide a Truly Electronic Environment.- Patenting the Processes for Content-Based Retrieval in Digital Libraries.- Secure Content Distribution for Digital Libraries.- A Strategic Level for Scientific Digital Libraries.- Bridging the Gap between Information Resource Design and Enterprise Content Management.- A Digital Content Management Model for Making Profits in Digital Content Sites.- Posters.- The Idea of a Digital Library: Issues of Today.- US-Korea Collaboration on Digital Libraries: An Overview and Generalization for Pacific Rim Collaboration.- ETDs at HKU: A Spearhead for Digital Library Growth.- MiMedicalLibrary: A Digital Health Library for Michigan.- Reference Services in a Digital Library of Historical Artifacts.- An Integrative User-Centered Purchase Request Service in the Age of Digital Library Development.- Vitalising Library and Information Science Education: A Challenge in the Digital Information Environment.- Developing a Dialogue Library System.- WebClipper: A Personal/Community Link Library Builder Based on Web Link Management Technique.- Hiding a Logo Watermark in an Image for Its Copyright Protection.- Searching Video Segments through Transcript, Metadata, and SVG Objects.- Similar Sub-trajectory Retrieval Based on k-Warping Distance Algorithm for Moving Objects in Video Databases.- A Keyword Spotting System of Korean Document Images.- An Efficient Strategy for Adding Bulky Data into B+-Tree Indices in Information Retrieval Systems.",,2002.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
2c598f5071937d27a517595d36b9def9bb3de629,https://www.semanticscholar.org/paper/2c598f5071937d27a517595d36b9def9bb3de629,Professional Visual C++ Activex Intranet Programming,"From the Publisher: 
Long Live the Information Superhighway! 
Wait a minute! I heard some loud heckling from the back row. 
""I thought this is a 'Microsoft ActiveX' technical programming book?!"" 
It is. 
The point is, there are two ways you can show a technology: either in dry, boring isolation, talking about the nuances without reference to the problems the technology is supposed to solve, or as we've attempted to do, applying the technology to a real-world situation. We've chosen to show you ActiveX programming by applying this technology to a large growth area, intranets. As you'll soon see, the ActiveX family of technologies is a very broad family covering the gamut of Internet-intranet, client-server and distributing computing solutions. It has to be this way, since ActiveX represents Microsoft's entire investment into the Internet-intranet (and object based distributed computing) race. Within this book, ActiveX will be used as a vehicle to explore many of the concepts and techniques involved in intranet construction. In many cases, the concepts and approaches explored are generally applicable to your practice whether it's Microsoft-, UNIX-, or even Netscape-centric. What's Covered in this Book Just before the technical reader, fluent with Visual C++, decides to return this book to the bookstore for a refund, I must say that this is by no means a 'lame theoretical treatise'. We turn on the power-throttle, and shine our high beams on the core ActiveX technologies once we've reached Chapter 2. In fact, a discussion of what intranets are about has been relegated to Appendix A, simply because you don't actually need to know about them to gain an understanding of ActiveX. From there we dive into the depths of the Microsoft's Component Object Model (COM) which is fundamental to all of Microsoft's ActiveX technology. Covering the basics, we'll be taking a view that reduces this complex topic to simple programming practices that we're fully familiar with. From there, we examine the concept of COM aggregation and show how it further enhances code reuse and provides a powerful mechanism for COM. In Chapter 3, we take our understanding of COM and put it into practice by writing an ActiveX control from scratch, using just raw C++. Here, we'll become intimate with the complete anatomy of a simple ActiveX control. When we move on to more powerful libraries and code generation wizards, this basic understanding will enable us to adapt and troubleshoot more effectively. In this chapter, we encounter many essential COM interfaces through actual hands-on programming; we'll also get acquainted with some indispensable COM programming tools such as the MIDL compiler and the Object Viewer utility. To handle some more complex problems without coding forever, we'll take a look at programming libraries to simplify the COM object programming task (ActiveX controls, to be precise). We'll explore how to code powerful, yet super efficient and tiny COM objects using the ActiveX Template Library (ATL) 2.1, and we will spend some time explaining many of the new COM interfaces, and show how ATL makes everything simple. Also in this chapter, we'll be learning about the threading models supported by COM objects and the different types of COM servers that can be created. Using ATL to create ActiveX controls is the focus of Chapter 4. Chapters 2, 3 and 4 give us enough background into understanding what ActiveX provides for the intranet development environment. We'll understand how ActiveX controls can be fundamental building blocks (actually software components) in both client- and server-based programming. We'll make excursions into the ActiveX controls (OCX ) specifications in Chapter 5, covering the differences between the OLE Control specification (for Visual controls) and the new OC96 specification (for ActiveX controls). We'll actually be designing an Events Calendar control. This control will display currently active events (for the month) from different company departments for easy and straightforward access. The distributed 'live update' nature of this control eliminates the need for consolidating events information in a centralized database. In Chapters 6 and 7 we put our design into code. Using Visual C++ 5.0 and MFC 4.21, we'll be building the actual Events Calendar intranet control. The control class and custom wizard provided by MFC greatly simplify much of the development. We'll also be building two additional 'back-end' ActiveX controls using ATL 2.1 to do data processing for the Visual Calendar control. Finally, we will test the controls and show that the Calendar control is a bona fide ActiveX control that can be hosted within containers such as Visual Basic 5.0, Internet Explorer 3.0, and FrontPage 97. In Chapter 8, we shift into the highest gear and attempt to put the Calendar control through its paces by using DCOM to run the front-end and back-end ActiveX controls across three separate machines. Along the way, we'll learn a lot about DCOM and how it enables true distributed computing. We'll also be examining the difficult problem of ActiveX control code installation and revision control, and see how the Internet Explorer 3.0 provides us with a ready-made solution to the problem. As part of the installation solution, we'll develop a small program to download controls from remote sites. After the intensive programming in Chapter 8, we shift our focus to a hot intranet issue in Chapter 9: security. We'll examine the topic by drawing a parallel to the Windows NT security model which is fundamental to all other security mechanisms built upon it. We'll learn about the various security, authentication and encryption APIs and COM interfaces available to intranet application developers. Special attention will be paid to DCOM related security issues and how arbitrary distributed objects may be prevented or allowed to execute on certain machines. We conclude our coverage in Chapter 10 by casting aside our overly enthusiastic attitude and examine some real and hard-to-tackle ActiveX and intranet deployment issues, suggesting potential solutions wherever they are available. We'll cover a lot of ground in the following pages. I hope your journey into the exciting world of ActiveX will be as pleasant, productive, and profitable for you as it has been for us. What You Need to Use This Book To use this book you need Visual C++ 5.0, and the latest version of Microsoft's best-selling C++ compiler. This version is 32-bit only, so you'll need to install it on Windows 95, Windows NT 3.51 or NT 4, which means a 486 CPU or better and a minimum 16Mb of memory. For Visual C++, you'll need quite a lot of hard disk space - a typical installation is 170 Mbytes. You can do a minimal installation which takes up around 40 Mbytes, but this will mean longer compile times as the CD-Rom will be utilized more often. Some of the later chapters require you to have access to a network and a second computer to test the code correctly. You'll also need to have DCOM for Windows 95 (information on obtaining this is given in Chapter 8) or Windows NT 4.0. |AUTHORBIO: Bitten by the microcomputer bug since 1978, Sing has grown up with the microprocessor age. His first personal computer was a $99 do-it-yourself Netronics COSMIC ELF computer with 256 bytes of memory, mail ordered from the back pages of Popular Electronics magazine. Currently, Sing is an active author, consultant, and entrepreneur. He has written for popular technical journals and is the creator of the ""Internet Global Phone"", one of the very first Internet phones available. His wide-ranging consulting expertise spans Internet and Intranet systems design, distributed architectures, digital convergence, embedded systems, real-time technologies, and cross platform software design. Recently, he has completed an assignment with Nortel Multimedia Labs working in Computer Telephony Integration, and Advanced Callcenter Management products. Sing is a founder of microWonders, an emerging company specializing in products to fulfill the ubiquitous ""computing anywhere"" vision. Other titles by this author: ATL Programmer's Resource Kit Professional COM Applications with ATL Professional IE4 Programming Visual C++ 4 Master Class|AUTHORBIO: Panos Economopoulos has been the architect, designer and leader for implementations of a number of complex and successful distributed computer systems. Currently, he is Manager of Research and Development at Telesis North. Here, he designed the OnAir series of mobile client-server products that provide efficient and robust remote access to BackOffice servers over a variety of satellite and other wireless networks. He has extensive experience as a consultant to the Industry and has developed, and taught, a variety of courses both at University undergrad level and for mature developers. He's also carried out advanced research at the University of Toronto - results of which have been published in several research journals. Other titles by this author ATL Programmer's Resource Kit, Professional COM Applications with ATL|",,1997.0,,semantic_scholar,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
