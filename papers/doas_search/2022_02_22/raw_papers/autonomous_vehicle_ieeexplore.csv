doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database
10.1109/CCNC49033.2022.9700725,Mitigating Location-based Attacks Using Predication Models in Vehicular Ad-Hoc Networks,IEEE,Conferences,"The modern world is constantly in a state of technological revolution. Everyday new technological ideas, inventions, and threats emerge. With modern computer software and hardware advancements, we have the emergence of the Internet of Things (IoT). In conjunction, modern car companies have a push from public demand for a fully-autonomous car. To accomplish autonomy, small, and secure Vehicular Ad-Hoc Networks (VANETs) it is necessary to ensure that the systems that rely on connected vehicle data is reliable and accurate. In the event there is a malicious actor manipulating the data through replica and injection attacks or there is a hardware failure yielding inaccurate location information, it is necessary to explore efficient methods for predicting connected vehicles locations such that these systems, which rely on accurate information are not impacted. This study analyzes multiple clustering and prediction models to discover how effectively a multi-layered machine learning approach is able to meet the real-time requirement of future generation smart cities.",https://ieeexplore.ieee.org/document/9700725/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700636,Balancing Latency and Accuracy on Deep Video Analytics at the Edge,IEEE,Conferences,"Real-time deep video analytic at the edge is an enabling technology for emerging applications, such as vulnerable road user detection for autonomous driving, which requires highly accurate results of model inference within a low latency. In this paper, we investigate the accuracy-latency trade-off in the design and implementation of real-time deep video analytic at the edge. Without loss of generality, we select the widely used YOLO-based object detection and WebRTC-based video streaming for case study. Here, the latency consists of both networking latency caused by video streaming and the processing latency for video encoding/decoding and model inference. We conduct extensive measurements to figure out how the dynamically changing settings of video streaming affect the achieved latency, the quality of video, and further the accuracy of model inference. Based on the findings, we propose a mechanism for adapting video streaming settings (i.e. bitrate, resolution) online to optimize the accuracy of video analytic within latency constraints. The mechanism has proved, through a simulated setup, to be efficient in searching the optimal settings.",https://ieeexplore.ieee.org/document/9700636/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/ICCECE54139.2022.9712792,Design of Deep Learning Based Autonomous Driving Control Algorithm,IEEE,Conferences,"In recent years, with the continuous development of the field of artificial intelligence, autonomous driving technology has gained widespread attention. In order to meet the purpose of changing driving behavior and completing driving tasks in real time without human intervention. In this paper, we study the design and implementation process of end-to-end autonomous driving algorithms based on computer vision and deep learning, and explain the elements of algorithm design from a theoretical perspective. The method of continuous steering angle prediction for autonomous driving based on convolutional neural network is proposed, as well as the method of network pre-training and overfitting prevention to improve the training effect and generalization ability. The difference with the traditional end-to-end control methods is that the traditional methods study the problem abstractly as a classification problem, describing the motion in terms of direction with a coarser granularity. The method proposed in this paper treats it as a regression problem, describing the motion in terms of steering angles, which provides a more accurate description of the motion and is more adaptive.",https://ieeexplore.ieee.org/document/9712792/,2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE),14-16 Jan. 2022,ieeexplore
10.1109/WACV51458.2022.00206,Plugging Self-Supervised Monocular Depth into Unsupervised Domain Adaptation for Semantic Segmentation,IEEE,Conferences,"Although recent semantic segmentation methods have made remarkable progress, they still rely on large amounts of annotated training data, which are often infeasible to collect in the autonomous driving scenario. Previous works usually tackle this issue with Unsupervised Domain Adaptation (UDA), which entails training a network on synthetic images and applying the model to real ones while minimizing the discrepancy between the two domains. Yet, these techniques do not consider additional information that may be obtained from other tasks. Differently, we propose to exploit self-supervised monocular depth estimation to improve UDA for semantic segmentation. On one hand, we deploy depth to realize a plug-in component which can inject complementary geometric cues into any existing UDA method. We further rely on depth to generate a large and varied set of samples to Self-Train the final model. Our whole proposal allows for achieving state-of-the-art performance (58.8 mIoU) in the GTA5 â†’ CS benchmark. Code is available at https://github.com/CVLAB-Unibo/d4-dbst.",https://ieeexplore.ieee.org/document/9707096/,2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),3-8 Jan. 2022,ieeexplore
10.1109/JAS.2021.1003907,Domain-Invariant Similarity Activation Map Contrastive Learning for Retrieval-Based Long-Term Visual Localization,IEEE,Journals,"Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the contrastive learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.",https://ieeexplore.ieee.org/document/9358457/,IEEE/CAA Journal of Automatica Sinica,February 2022,ieeexplore
