id,type,doi,publisher,database,url,domain,publication_date,title,abstract
1,experiments,10.1109/lra.2021.3116700,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9555228/,multimedia,1/1/2022 0:00,sim2real learning of obstacle avoidance for robotic manipulators in uncertain environments,"Obstacle avoidance for robotic manipulators can be challenging when they operate in unstructured environments. This problem is probed with the sim-to-real (sim2real) deep reinforcement learning, such that a moving policy of the robotic arm is learnt in a simulator and then adapted to the real world. However, the problem of sim2real adaptation is notoriously difficult. To this end, this work proposes (1) a unified representation of obstacles and targets to capture the underlying dynamics of the environment while allowing generalization to unseen goals and (2) a flexible end-to-end model combining the unified representation with the deep reinforcement learning control module that can be trained by interacting with the environment. Such a representation is agnostic to the shape and appearance of the underlying objects, which simplifies and unifies the scene representation in both simulated and real worlds. We implement this idea with a vision-based actor-critic framework by devising a bounding box predictor module. The predictor estimates the 3D bounding boxes of obstacles and targets from the RGB-D input. The features extracted by the predictor are fed into the policy network, and all the modules are jointly trained. This makes the policy learn object-aware scene representation, which leads to a data-efficient learning of the obstacle avoidance policy. Our experiments in simulated environment and the real-world show that the end-to-end model of the unified representation achieves better sim2real adaption and scene generalization than state-of-the-art techniques."
2,architecture,10.1109/tifs.2021.3131026,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9627681/,science,1/1/2000 0:00,poligraph: intrusion-tolerant and distributed fake news detection system,"We present Poligraph, an intrusion-tolerant and decentralized fake news detection system. Poligraph aims to address architectural, system, technical, and social challenges of building a practical, long-term fake news detection platform. We first conduct a case study for fake news detection at authors’ institute, showing that machine learning-based reviews are less accurate but timely, while human reviews, in particular, experts reviews, are more accurate but time-consuming. This justifies the need for combining both approaches. At the core of Poligraph is two-layer consensus allowing seamlessly combining machine learning techniques and human expert determination. We construct the two-layer consensus using Byzantine fault-tolerant (BFT) and asynchronous threshold common coin protocols. We prove the correctness of our system in terms of conventional definitions of security in distributed systems (agreement, total order, and liveness) as well as new review validity (capturing the accuracy of news reviews). We also provide theoretical foundations on parameter selection for our system. We implement Poligraph and evaluate its performance on Amazon EC2 using a variety of news from online publications and social media. We demonstrate Poligraph achieves throughput of more than 5,000 transactions per second and latency as low as 0.05 second. The throughput of Poligraph is only marginally (<inline-formula> <tex-math notation=""LaTeX"">${4\%}$ </tex-math></inline-formula>–<inline-formula> <tex-math notation=""LaTeX"">${7\%}$ </tex-math></inline-formula>) slower than that of an unreplicated, single-server implementation. In addition, we conduct a real-world case study for the review of fake and real news among both experts and non-experts, which validates the practicality of our approach."
3,architecture,http://arxiv.org/abs/2201.07312v1,arxiv,arxiv,http://arxiv.org/abs/2201.07312v1,multimedia,1/18/2022 0:00,model-driven cluster resource management for ai workloads in edge clouds,"Since emerging edge applications such as Internet of Things (IoT) analytics
and augmented reality have tight latency constraints, hardware AI accelerators
have been recently proposed to speed up deep neural network (DNN) inference run
by these applications. Resource-constrained edge servers and accelerators tend
to be multiplexed across multiple IoT applications, introducing the potential
for performance interference between latency-sensitive workloads. In this
paper, we design analytic models to capture the performance of DNN inference
workloads on shared edge accelerators, such as GPU and edgeTPU, under different
multiplexing and concurrency behaviors. After validating our models using
extensive experiments, we use them to design various cluster resource
management algorithms to intelligently manage multiple applications on edge
accelerators while respecting their latency constraints. We implement a
prototype of our system in Kubernetes and show that our system can host 2.3X
more DNN applications in heterogeneous multi-tenant edge clusters with no
latency violations when compared to traditional knapsack hosting algorithms."
4,experiments,10.1109/lra.2022.3143289,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9682507/,robotics,4/1/2022 0:00,visuotactile 6d pose estimation of an in-hand object using vision and tactile sensor data,"Knowledge of the 6D pose of an object can benefit in-hand object manipulation. Existing 6D pose estimation methods use vision data. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot’s grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this letter, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot’s hand.The main challenges of this research include 1) lack of standard representation for tactile sensor data, 2) fusion of sensor data from heterogeneous sources—vision and tactile, and 3) a need for large training datasets. To address these challenges, first, we propose use of point clouds to represent object surfaces that are in contact with the tactile sensor. Second, we present a network architecture based on pixel-wise dense fusion to fuse vision and tactile data to estimate the 6D pose of an object. Third, we extend NVIDIA’s Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and the corresponding tactile point clouds for 11 objects from the YCB Object and Model Set in Unreal Engine 4. We present results of simulated experiments suggesting that using tactile data in addition to vision data improves the 6D pose estimate of an in-hand object. We also present qualitative results of experiments in which we deploy our network on real physical robots showing successful transfer of a network trained on synthetic data to a real system."
5,experiments,http://arxiv.org/abs/2201.05753v1,arxiv,arxiv,http://arxiv.org/abs/2201.05753v1,robotics,1/15/2022 0:00,"parameter identification and motion control for articulated rigid body
  robots using differentiable position-based dynamics","Simulation modeling of robots, objects, and environments is the backbone for
all model-based control and learning. It is leveraged broadly across dynamic
programming and model-predictive control, as well as data generation for
imitation, transfer, and reinforcement learning. In addition to fidelity, key
features of models in these control and learning contexts are speed, stability,
and native differentiability. However, many popular simulation platforms for
robotics today lack at least one of the features above. More recently,
position-based dynamics (PBD) has become a very popular simulation tool for
modeling complex scenes of rigid and non-rigid object interactions, due to its
speed and stability, and is starting to gain significant interest in robotics
for its potential use in model-based control and learning. Thus, in this paper,
we present a mathematical formulation for coupling position-based dynamics
(PBD) simulation and optimal robot design, model-based motion control and
system identification. Our framework breaks down PBD definitions and
derivations for various types of joint-based articulated rigid bodies. We
present a back-propagation method with automatic differentiation, which can
integrate both positional and angular geometric constraints. Our framework can
critically provide the native gradient information and perform gradient-based
optimization tasks. We also propose articulated joint model representations and
simulation workflow for our differentiable framework. We demonstrate the
capability of the framework in efficient optimal robot design, accurate
trajectory torque estimation and supporting spring stiffness estimation, where
we achieve minor errors. We also implement impedance control in real robots to
demonstrate the potential of our differentiable framework in human-in-the-loop
applications."
6,architecture,http://arxiv.org/abs/2201.09550v1,arxiv,arxiv,http://arxiv.org/abs/2201.09550v1,multimedia,1/24/2022 0:00,crowd tracking and monitoring middleware via map-reduce,"This paper presents the design, implementation, and operation of a novel
distributed fault-tolerant middleware. It uses interconnected WSNs that
implement the Map-Reduce paradigm, consisting of several low-cost and low-power
mini-computers (Raspberry Pi). Specifically, we explain the steps for the
development of a novice, fault-tolerant Map-Reduce algorithm which achieves
high system availability, focusing on network connectivity. Finally, we
showcase the use of the proposed system based on simulated data for crowd
monitoring in a real case scenario, i.e., a historical building in Greece (M.
Hatzidakis' residence).The technical novelty of this article lies in presenting
a viable low-cost and low-power solution for crowd sensing without using
complex and resource-intensive AI structures or image and video recognition
techniques."
