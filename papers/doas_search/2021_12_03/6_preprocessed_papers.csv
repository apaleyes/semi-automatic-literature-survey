paperId,url,title,abstract,venue,year
1c8fad213b92997e6f92e16e919be031986eb9c7,https://www.semanticscholar.org/paper/1c8fad213b92997e6f92e16e919be031986eb9c7,Sliding mode heading control for AUV based on continuous hybrid model-free and model-based reinforcement learning,,Applied Ocean Research,2022
1cbebbaa1747460e72d0a44e3af2f8b469a99757,https://www.semanticscholar.org/paper/1cbebbaa1747460e72d0a44e3af2f8b469a99757,The adaptive sliding mode control using improved genetic algorithm tuning PID controller for the planetary rover,"The purpose of this paper is to resolve the problem of the dynamic response performance of the driving control system for a six-wheeled planetary rover. An adaptive sliding mode controller based on an improved genetic algorithm (IGA) to tune PID sliding surface parameters was used in the driving control system of the planetary rover.,First, the mathematical model of planetary rover driving control is established. Second, according to sliding mode variable structure control, an equivalent controller and a disturbance controller are constructed to solve the problem of a multi-disturbance nonlinear driving control system of planetary rovers and an IGA is used to tune PID parameters.,Simulation results show that the proposed control algorithm improves the accuracy of the driving control system and optimizes the smoothness of rover motion control.,The controller based on the IGA to tune PID sliding surface parameters has good self-adaptability and real-time controllability for the control object which is difficult to present a precise mathematical model.,The advanced control method is adopted to solve the uncertainty and external interference of planetary rovers in a complex environment. The mathematical model of the six-wheeled rover is established as the control object and the uncertainty and external disturbance of the model are considered. The controller based on IGA has good adaptability and real-time performance and the control algorithm can be used to drive robots in complex environments.",,2021
52c5dc4f6fcfa6f15077972d47cbc784a1446672,https://www.semanticscholar.org/paper/52c5dc4f6fcfa6f15077972d47cbc784a1446672,A Self-adaptive SAC-PID Control Approach based on Reinforcement Learning for Mobile Robots,"Present Address College of Information Engineering, Zhejiang University of Technology, Hangzhou, Zhejiang, China Abstract Proportional-integral-derivative (PID) control is the most widely used in industrial control, robot control and other fields. However, traditional PID control is not competent when the system cannot be accurately modeled and the operating environment is variable in real time. To tackle these problems, we propose a self-adaptivemodel-free SAC-PID control approach based on reinforcement learning for automatic control of mobile robots. A new hierarchical structure is developed, which includes the upper controller based on soft actor-critic (SAC), one of the most competitive continuous control algorithms, and the lower controller based on incremental PID controller. Soft actor-critic receives the dynamic information of the mobile robot as input, and simultaneously outputs the optimal parameters of incremental PID controllers to compensate for the error between the path and the mobile robot in real time. In addition, the combination of 24-neighborhood method and polynomial fitting is developed to improve the adaptability of SAC-PID control method to complex environments. The effectiveness of the SAC-PID control method is verified with several different difficulty paths both on Gazebo and real mecanum mobile robot. Futhermore, compared with fuzzy PID control, the SAC-PID method has merits of strong robustness, generalization and real-time performance.",International Journal of Robust and Nonlinear Control,2021
bc950b2e4a5c8611afb493bbc9cf6c92c8b87f86,https://www.semanticscholar.org/paper/bc950b2e4a5c8611afb493bbc9cf6c92c8b87f86,Multi-robot exploration in task allocation problem,"Task allocation is an important problem in multi-robot system which can be defined with different setup for different application, i.e. coverage, surveillance and mining mission in static or dynamic scenarios. Our focus in this paper is exploring environment to accomplish tasks distributed over the environment by minimizing overall cost of the system. This problem is defined as a NP-Hard problem, thus will be more challenging in larger environments containing many robots and tasks. To solve multi-robot task allocation in very large environment we propose a new deployment-based framework. Our proposal divided the problem into two sub-problems: region partitioning and routing problem. This decomposition eases considering our problem specification in multi-robot system which are not easily considerable in other approaches, i.e distribution of the tasks or robots’ initial position. Load balancing is done globally by deploying robots in a proper location of the environment and assigning sub-regions among them. Sub-regions contains set of points, where the goal is visiting all the points individually by one of the robots. On the other hand, after deploying the robots, routing techniques can be simply applied to find shortest and safest paths for every robots. To search for solutions in this NP-hard problem, two methods are built on a tailor-made multi-objective scheme of Genetic Algorithm (GA) with a different setup and search operators, and a reinforcement learning approach. Simulation results testify the performance of our methods in comparison to existing ones.",,2021
c0e4fe2f6945cbe3e3cf99c9ba93ef8144fc548c,https://www.semanticscholar.org/paper/c0e4fe2f6945cbe3e3cf99c9ba93ef8144fc548c,A Self-adaptive LSAC-PID Approach based on Lyapunov Reward Shaping for Mobile Robots,"To solve the coupling problem of control loops and the adaptive parameter tuning problem in the multi-input multi-output (MIMO) PID control system, a self-adaptive LSAC-PID algorithm is proposed based on deep reinforcement learning (RL) and Lyapunovbased reward shaping in this paper. For complex and unknown mobile robot control environment, an RL-based MIMO PID hybrid control strategy is firstly presented. According to the dynamic information and environmental feedback of the mobile robot, the RL agent can output the optimal MIMO PID parameters in real time, without knowing mathematical model and decoupling multiple control loops. Then, to improve the convergence speed of RL and the stability of mobile robots, a Lyapunov-based reward shaping soft actor-critic (LSAC) algorithm is proposed based on Lyapunov theory and potential-based reward shaping method. The convergence and optimality of the algorithm are proved in terms of the policy evaluation and improvement step of soft policy iteration. In addition, for line-following robots, the region growing method is improved to adapt to the influence of forks and environmental interference. Through comparison, test and cross-validation, the simulation and real-environment experimental results all show good performance of the proposed LSAC-PID tuning algorithm.",ArXiv,2021
d325aa9305ec92a75511dff3c5b2cdcc8b6c3953,https://www.semanticscholar.org/paper/d325aa9305ec92a75511dff3c5b2cdcc8b6c3953,Deep Reinforcement Learning with Shallow Controllers: An Experimental Application to PID Tuning,"Deep reinforcement learning (RL) is an optimization-driven framework for producing control strategies for general dynamical systems without explicit reliance on process models. Good results have been reported in simulation. Here we demonstrate the challenges in implementing a state of the art deep RL algorithm on a real physical system. Aspects include the interplay between software and existing hardware; experiment design and sample efficiency; training subject to input constraints; and interpretability of the algorithm and control law. At the core of our approach is the use of a PID controller as the trainable RL policy. In addition to its simplicity, this approach has several appealing features: No additional hardware needs to be added to the control system, since a PID controller can easily be implemented through a standard programmable logic controller; the control law can easily be initialized in a “safe” region of the parameter space; and the final product—a well-tuned PID controller—has a form that practitioners can reason about and deploy with confidence.",ArXiv,2021
e0642272d01afd867c090c7beddd37218616fcfd,https://www.semanticscholar.org/paper/e0642272d01afd867c090c7beddd37218616fcfd,Reinforcement learning in robotic applications: a comprehensive survey,"In recent trends, artificial intelligence (AI) is used for the creation of complex automated control systems. Still, researchers are trying to make a completely autonomous system that resembles human beings. Researchers working in AI think that there is a strong connection present between the learning pattern of human and AI. They have analyzed that machine learning (ML) algorithms can effectively make self-learning systems. ML algorithms are a sub-field of AI in which reinforcement learning (RL) is the only available methodology that resembles the learning mechanism of the human brain. Therefore, RL must take a key role in the creation of autonomous robotic systems. In recent years, RL has been applied on many platforms of the robotic systems like an air-based, under-water, land-based, etc., and got a lot of success in solving complex tasks. In this paper, a brief overview of the application of reinforcement algorithms in robotic science is presented. This survey offered a comprehensive review based on segments as (1) development of RL (2) types of RL algorithm like; Actor-Critic, DeepRL, multi-agent RL and Human-centered algorithm (3) various applications of RL in robotics based on their usage platforms such as land-based, water-based and air-based, (4) RL algorithms/mechanism used in robotic applications. Finally, an open discussion is provided that potentially raises a range of future research directions in robotics. The objective of this survey is to present a guidance point for future research in a more meaningful direction.",,2021
f3ec88fe7378977d33520989f481559d865b8939,https://www.semanticscholar.org/paper/f3ec88fe7378977d33520989f481559d865b8939,Proximal Policy Optimization for Tracking Control Exploiting Future Reference Information,"In recent years, reinforcement learning (RL) has gained increasing attention in control engineering. Especially, policy gradient methods are widely used. In this work, we improve the tracking performance of proximal policy optimization (PPO) for arbitrary reference signals by incorporating information about future reference values. Two variants of extending the argument of the actor and the critic taking future reference values into account are presented. In the first variant, global future reference values are added to the argument. For the second variant, a novel kind of residual space with future reference values applicable to model-free reinforcement learning is introduced. Our approach is evaluated against a PI controller on a simple drive train model. We expect our method to generalize to arbitrary references better than previous approaches, pointing towards the applicability of RL to control real systems.",ArXiv,2021
211535e93ccaed8c3ff116d451dd1e888752780e,https://www.semanticscholar.org/paper/211535e93ccaed8c3ff116d451dd1e888752780e,An adaptive deep reinforcement learning approach for MIMO PID control of mobile robots.,"Intelligent control systems are being developed for the control of plants with complex dynamics. However, the simplicity of the PID (proportional-integrative-derivative) controller makes it still widely used in industrial applications and robotics. This paper proposes an intelligent control system based on a deep reinforcement learning approach for self-adaptive multiple PID controllers for mobile robots. The proposed hybrid control strategy uses an actor-critic structure and it only receives low-level dynamic information as input and simultaneously estimates the multiple parameters or gains of the PID controllers. The proposed approach was tested in several simulated environments and in a real time robotic platform showing the feasibility of the approach for the low-level control of mobile robots. From the simulation and experimental results, our proposed approach demonstrated that it can be of aid by providing with behavior that can compensate or even adapt to changes in the uncertain environments providing a model free unsupervised solution. Also, a comparative study against other adaptive methods for multiple PIDs tuning is presented, showing a successful performance of the approach.",ISA transactions,2020
2fc629622efb2827aa65888ea21dde65bd7a07da,https://www.semanticscholar.org/paper/2fc629622efb2827aa65888ea21dde65bd7a07da,A reinforcement learning control approach for underwater manipulation under position and torque constraints,"In marine operations underwater manipulators play a primordial role. However, due to uncertainties in the dynamic model and disturbances caused by the environment, low-level control methods require great capabilities to adapt to change. Furthermore, under position and torque constraints the requirements for the control system are greatly increased. Reinforcement learning is a data driven control technique that can learn complex control policies without the need of a model. The learning capabilities of these type of agents allow for great adaptability to changes in the operative conditions. In this article we present a novel reinforcement learning low-level controller for the position control of an underwater manipulator under torque and position constraints. The reinforcement learning agent is based on an actor-critic architecture using sensor readings as state information. Simulation results using the Reach Alpha 5 underwater manipulator show the advantages of the proposed control strategy.",Global Oceans 2020: Singapore – U.S. Gulf Coast,2020
42bb6615fa08381a726e62eddb7c66bad9d50abe,https://www.semanticscholar.org/paper/42bb6615fa08381a726e62eddb7c66bad9d50abe,Reinforcement Q-learning PID Controller for a Restaurant Mobile Robot with Double Line-Sensors,"The wheeled mobile robots have been widely applied in daily applications for its simplicity, robustness, stability and low-cost of manufacturing. Typically, PID controller is implemented to drive a mobile robot. However, the performance of the robot is greatly depended on the PID control parameters are tuned and the robustness of the mechanical system. Since the analog controllers were replaced by digital controller, PID control parameters could be automatically tuned to adapt the variation of the system parameters and operating condition. In this manuscript, a mathematical model is developed for a line following mobile robotic system which is used as a restaurant serving robot. The serving robot is controlled by an adaptive PID controller using Q-learning algorithm. The simulation and experimental results are compared to verify the advantage of the adaptive PID controller over classical PID controller.",ICMLSC,2020
635680904e5eb1602df20528aad745e4d64b7017,https://www.semanticscholar.org/paper/635680904e5eb1602df20528aad745e4d64b7017,Reinforcement Learning based Design of Linear Fixed Structure Controllers,"Reinforcement learning has been successfully applied to the problem of tuning PID controllers in several applications. The existing methods often utilize function approximation, such as neural networks, to update the controller parameters at each time-step of the underlying process. In this work, we present a simple finite-difference approach, based on random search, to tuning linear fixed-structure controllers. For clarity and simplicity, we focus on PID controllers. Our algorithm operates on the entire closed-loop step response of the system and iteratively improves the PID gains towards a desired closed-loop response. This allows for embedding stability requirements into the reward function without any modeling procedures.",IFAC-PapersOnLine,2020
87a5b7ae9d3b56d168c26cf166ad0bf851f4002f,https://www.semanticscholar.org/paper/87a5b7ae9d3b56d168c26cf166ad0bf851f4002f,Adaptive neural network control of nonlinear systems with unknown dynamics,"Abstract In this study, an adaptive neural network control approach is proposed to achieve accurate and robust control of nonlinear systems with unknown dynamics, wherein the neural network is innovatively used to learn the inverse problem of system dynamics with guaranteed convergence. This study focuses on the following three contributions. First, the considered system is transformed into a multi-integrator system using an input-output linearization technique, and an extended state observation technique is used to identify the transformed states. Second, an iterative control learning algorithm is proposed to achieve the neural network training, and stability analysis is given to prove that the network’s predictions converge to ideal control inputs with guaranteed convergence. Third, an adaptive neural network controller is developed by combining the trained network and a proportional-integral controller, and the long-standing challenge of model-based methods for control determination of unknown dynamics is resolved. Simulation results of a virtual control mission and an aerospace altitude tracking mission are provided to substantiate the effectiveness of the proposed techniques and illustrate the adaptability and robustness of the proposed controller.",,2020
8fb4849ce9c3983c1a9a3711ad621989694a484c,https://www.semanticscholar.org/paper/8fb4849ce9c3983c1a9a3711ad621989694a484c,A STUDY OF REINFORCEMENT LEARNING APPLICATIONS & ITS ALGORITHMS,"Machine Learning is an indispensable part of Artificial Intelligence. It is the investigation of projects that makes computer to express like humans. Machine learning has come into existence as an important innovation with its adequate number of uses. Reinforcement Learning is one of the major application of Machine Learning that enables machines and software agents to work explicitly and also resolve the conduct within a definite situation to maximize its performance. Due to the aspect of self-improving, web based learning and less programming effort Reinforcement Learning becomes an intelligent agent’s in core technologies. With the advancement of more robust and efficient algorithms, there is still a requirement for more work to be done. Thus the main aim of this study is to provide the review of Reinforcement Learning and its applications by utilizing various algorithms from Machine learning perspective.",,2020
981624c2dcd0cf04467aef7970d4363905193ec0,https://www.semanticscholar.org/paper/981624c2dcd0cf04467aef7970d4363905193ec0,Research on Improved Intelligent Control Processes Based on Three Kinds of Artificial Intelligence,"Autotuning and online tuning of control parameters in control processes (OTP) are widely used in practice, such as in chemical production and industrial control processes. Better performance (such as dynamic speed and steady-state error) and less repeated manual-tuning workloads in bad environments for engineers are expected. The main works are as follows: Firstly, a change ratio for expert system and fuzzy-reasoning-based OTP methods is proposed. Secondly, a wavelet neural-network-based OTP method is proposed. Thirdly, comparative simulations are implemented in order to verify the performance. Finally, the stability of the proposed methods is analyzed based on the theory of stability. Results and effects are as follows: Firstly, the proposed control parameters of online tuning methods of artificial-intelligence-based classical control (AI-CC) systems had better performance, such as faster speed and smaller error. Secondly, stability was verified theoretically, so the proposed method could be applied with a guarantee. Thirdly, a lot of repeated and unsafe manual-based tuning work for engineers can be replaced by AI-CC systems. Finally, an upgrade solution AI-CC, with low cost, is provided for a large number of existing classical control systems.",Processes,2020
b3804444c46df2f5cf097167bfc518714af36b63,https://www.semanticscholar.org/paper/b3804444c46df2f5cf097167bfc518714af36b63,An Improved DDPG and Its Application Based on the Double-Layer BP Neural Network,"This paper focused on three application problems of the traditional Deep Deterministic Policy Gradient(DDPG) algorithm. That is, the agent exploration is insufficient, the neural network performance is unsatisfied, the agent output fluctuates greatly. In terms of agent exploration strategy, network training algorithm and overall algorithm implementation, an improved DDPG method based on double-layer BP neural network is proposed. This method introduces fuzzy algorithm and BFGS algorithm based on Armijo-Goldstein criterion, improves the exploration efficiency, learning efficiency and convergence of BP neural network, increases the number of layers of BP neural network to improve the fitting ability of the network, and adopts periodic update to ensure the stable operation of the algorithm. The experimental results show that the deep learning network based on the improved DDPG algorithm has greatly improved the performance compared with the traditional method after multiple rounds of self-learning under variable working conditions. This study lays a theoretical and experimental foundation for the extended application of deep learning algorithm.",IEEE Access,2020
b828a2c8e85169d6d85eef89b8a30c48bea90ee1,https://www.semanticscholar.org/paper/b828a2c8e85169d6d85eef89b8a30c48bea90ee1,Reinforcement Learning: Recent Threads,"​Abstract ​ —Reinforcement learning is a method of  training algorithms using reward and punishment  feedback. Reinforcement learning agents will  interact with their environment to extract  information. It is using a trial and error  mechanism to learn from its experiences. The goal  of reinforcement learning is getting a model that  can maximize the total aggregate reward. Its  policy is similar to supervised learning. When  comparing, both reinforcement learning and  supervised learning uses the mapping between  input and output as a policy method. This paper  contains detailed comparisons and discussion of  six reinforcement algorithms, their exploration  and exploitation strategy, their weakness and  strengths. Background on reinforcement learning  models and its recent trends, advantages and  future opportunities of reinforcement learning are  presented in the paper. This paper is keen to  discuss the state-of-the-art applications and  achievements of reinforcement learning in various  domains.  ​Index Terms​ —Reinforcement learning, trends,  review, challenges, model-free, Q-learning, DDPG,  SARSA, Inverse Reinforcement Learning, Actor  critic model.  I.INTRODUCTION  Reinforcement learning (RL) is a multidisciplinary  machine learning technique. It is a hot research topic  in the artificial intelligence domain. The last decade  witnessed research and applicational level success in  reinforcement learning. The concept and research in  reinforcement learning started during 1980 and have  its origin rooted back into statistics, game theory,  control theory and animal psychology. Reinforcement  learning is a goal-oriented method with the ability to  interact with the environment and learn from it. A  reinforcement learning agent is designed to learn from its environment using a trial and error  mechanism. An RL agent in a dynamic environment  is capable of extracting information from the current  state and to take appropriate action. The  reinforcement learning model is designed to choose  the best-fit action to maximize the reward and deliver  maximum utility. More appropriate actions will be  selected based on the reward function value and  undesirable actions will be silenced using punishment  feedback. Starting from single-agent reinforcement  learning detailed research is carrying out on  multi-agent and swarm intelligence topics. Genetic  algorithms and hybrid approaches are now trying to  break the barrier of human cognitive ability to  achieve superhuman perfection. The ability of  reinforcement learning to extract and manipulate the  raw pixels data made it an integral part of computer  vision and digital game environments. An RL agent learns the best policy using the  exploration of the environment. Reinforcement  learning models are used to solve complex  computational problems by setting a reward  mechanism and control policies. It chooses a best-fit  policy to maximize the reward. The concept of  reinforcement learning is inspired and adapted from  the natural learning process of the animals, especially  the learning and action behaviour of human beings. In  reinforcement learning, data will generate based on  environment exploration. The agent will only be  informed about the starting state, and the behaviour  will be modelled based on the reward and  punishments. The reward feedback in the form of a  scalar objective function is a performance measure ​of  each step. Reinforcement learning is closely related to  optimal control theory. RL and optimal control theory  are used to find an optimal control policy to optimize  the objective function. The ability of RL agents in  decision making under the uncertainty maid is special  among other machine learning techniques. No  information regarding what move to make is provided  to the RL agent. The agent must decide the best  activity to boost long-term rewards and execute it.  The selected action will change the current  environment state into the next adjacent state.  Different RL algorithms developed during the last  two decades are improvised a lot and achieved good  results in complex real-world applications. The  International Journal of Engineering Research & Technology (IJERT)",,2020
ccf4d07af16ea3c99484c62c0c85bd2507651bf1,https://www.semanticscholar.org/paper/ccf4d07af16ea3c99484c62c0c85bd2507651bf1,Optimising PID Control with Residual Policy Reinforcement Learning,"Suspension control systems in cars are a vital component in modern vehicles tasked with enhancing ride comfort for passengers. However, these systems rely on system controllers to dictate the damping rate. Commonly PID controllers are used for this purpose, but these controllers have a number of drawbacks such as their linearity and inability to adapt. On the other hand, many of these weaknesses are the strengths of Reinforcement Learning (RL) techniques. In this research, a novel approach is taken to combine both PID controllers and RL through a technique known as Residual Policy Reinforcement Learning (RPRL). This approach is evaluated on a quarter car suspension system model in a variety of common scenarios and is shown to improve the suspension control of a car, enhance the performance of a PID-controller, and adapt to environmental changes. However, it is also shown that the algorithm’s performance is highly reliant on the performance of the base policy, i.e., initially selected PID parameters.",AICS,2020
d226e9729b40d5c69a6ae7af56d22001dbecdfbf,https://www.semanticscholar.org/paper/d226e9729b40d5c69a6ae7af56d22001dbecdfbf,Adaptive Single Neuron Anti-Windup PID Controller Based on the Extended Kalman Filter Algorithm,"In this paper, an adaptive single neuron Proportional–Integral–Derivative (PID) controller based on the extended Kalman filter (EKF) training algorithm is proposed. The use of EKF training allows online training with faster learning and convergence speeds than backpropagation training method. Moreover, the propose adaptive PID approach includes a back-calculation anti-windup scheme to deal with windup effects, which is a common problem in PID controllers. The performance of the proposed approach is shown by presenting both simulation and experimental tests, giving results that are comparable to similar and more complex implementations. Tests are performed for a four wheeled omnidirectional mobile robot. Tests show the superiority of the proposed adaptive PID controller over the conventional PID and other adaptive neural PID approaches. Experimental tests are performed on a KUKA® Youbot® omnidirectional platform.",,2020
d7b37e645bb7450fe88c537e88ca4b4c05504ce3,https://www.semanticscholar.org/paper/d7b37e645bb7450fe88c537e88ca4b4c05504ce3,Adaptive neuro-fuzzy PID controller based on twin delayed deep deterministic policy gradient algorithm,"Abstract This paper presents an adaptive neuro-fuzzy PID controller based on twin delayed deep deterministic policy gradient (TD3) algorithm for nonlinear systems. In this approach, the observation of the environment is embedded with information of a multiple input single output (MISO) fuzzy inference system (FIS) and have a specially defined fuzzy PID controller in neural network (NN) formation acting as the actor in the TD3 algorithm, which achieves automatic tuning of gains of fuzzy PID controller. From the control perspective, the controller combines the merits of both FIS and PID controller and utilizes reinforcement learning algorithm for optimizing parameters. From the reinforcement learning point of view, embedding the prior knowledge into the fuzzy PID controller incorporated in the actor network helps reduce the learning difficulty in the training process. The proposed method was tested on the cart-pole system in simulation environment with comparison of a linear PID controller, which demonstrates the robustness and generalization of the proposed approach.",Neurocomputing,2020
f1e118216f8ef4d15f251eadda7287608143193e,https://www.semanticscholar.org/paper/f1e118216f8ef4d15f251eadda7287608143193e,NARX Prediction-Based Parameters Online Tuning Method of Intelligent PID System,"Control parameters of classical control system are expected to be online tuned and optimized by intelligent methods, in order to improve performance and help engineers reduce a lot of repetitive work in dangerous and harmful working environments. Main ideas and works of this paper are as follows:Firstly, change ratio based expert PID control method (EA-PID) is proposed to expand range of control parameters. Expert rule table (ERT) of expert PID control method (E-PID) is replaced by change ratio table (CRT) of EA-PID. Adjusted parameters of EA-PID are the results of multiplying change ratios in current adjusting cycle and control parameters in previous adjusting cycle. Secondly, NARX prediction-based NARX-E-PID and NARX-EA-PID are proposed. The NARX neural network is designed as a time series predictor to predict the output of the control system, then control parameters are adjusted according to the predicted output. Thirdly, comparative simulations of all the above methods are implemented to verify the improved effects. Finally, theoretical analysis is provided to ensure the stability of control systems. Effect are as follows: Firstly, comparative simulations verify that the improved methods have faster control speed, smaller steady-state error, less overshoot, and better ability of anti-interference. Secondly, theoretical analysis shows that the unstable control systems with adjusted parameters can be changed into a stable system by stability judgment in each adjusting cycle.",IEEE Access,2020
f807922458471796e363a7f6511d82950aad180a,https://www.semanticscholar.org/paper/f807922458471796e363a7f6511d82950aad180a,Uma Abordagem de Aprendizado online para o Seguimento de Trajetórias usando Robôs não Holonômicos,"This study investigates a Reinforcement Learning (RL) method to derivate control laws of a non-holonimic robot considering the coupling and nonlinearity of the system. The controller is on-line derivated from the interaction between the agent and an unknown environment through a Q-learning based approach. This approach aims to find the best action that maximizes the rewards along attempts to follow a trajectory. Performed experiments might show that the learned controllers were able of efficiently following diverse trajectories considering different speed variations of the robot translation and rotation as well as maximizing the reward amount over iteractions for two distinct learning process configurations. Resumo: Este artigo investiga a aplicação de um método de Aprendizado por Reforço (RL) para derivar as leis de controle de robôs não holonômico, considerando o acoplamento e a não linearidade do sistema. Os controladores são derivados on-line através da interação entre o agente real e o ambiente desconhecido, usando uma abordagem baseada no algoritmo Q-Learning, que visa descobrir qual a melhor ação a ser tomada pelo agente, de modo a maximizar as recompensas recebidas em cada tentativa de execução do seguimento da trajetória desejada. Resultados experimentais mostraram que os controladores aprendidos são capazes de realizar o seguimento de diferentes trajetórias, de forma eficiente, levando em conta a variação das velocidades de translação e de rotação do robô e a maximização do valor das recompensas ao longo das iterações, conforme apresentado nos estudos de caso.",,2020
020e4193cca69c790f3fd43341795572257eed90,https://www.semanticscholar.org/paper/020e4193cca69c790f3fd43341795572257eed90,Performance Analysis of Deep Q Networks and Advantage Actor Critic Algorithms in Designing Reinforcement Learning-based Self-tuning PID Controllers,"Use of Reinforcement Learning (RL) in designing adaptive self-tuning PID controllers is a relatively new horizon of research with Q-learning and its variants being the predominant algorithms found in the literature. However, the possibility of using an interesting alternative algorithm i.e. Advantage Actor Critic (A2C) in the above context is relatively unexplored. In the present study, Deep Q Networks (DQN) and A2C approaches have been employed to design self-tuning PID controllers. Comparative performance analysis of both the controllers was undertaken in a simulation environment on a servo position control system, with various static and dynamic control objectives, keeping a conventional PID controller as a baseline. A2C based Adaptive PID Controller(A2CAPID) is more promising in trajectory tracking problems whereas DQN based Adaptive PID Controller(DQNAPID) is rather suitable for systems with relatively large plant parameter variations.",2019 IEEE Bombay Section Signature Conference (IBSSC),2019
24f9cec3c63d0a37a709bbccdf55c55a7770614d,https://www.semanticscholar.org/paper/24f9cec3c63d0a37a709bbccdf55c55a7770614d,Double Q-PID algorithm for mobile robot control,"Abstract Many expert systems have been developed for self-adaptive PID controllers of mobile robots. However, the high computational requirements of the expert systems layers, developed for the tuning of the PID controllers, still require previous expert knowledge and high efficiency in algorithmic and software execution for real-time applications. To address these problems, in this paper we propose an expert agent-based system, based on a reinforcement learning agent, for self-adapting multiple low-level PID controllers in mobile robots. For the formulation of the artificial expert agent, we develop an incremental model-free algorithm version of the double Q -Learning algorithm for fast on-line adaptation of multiple low-level PID controllers. Fast learning and high on-line adaptability of the artificial expert agent is achieved by means of a proposed incremental active-learning exploration-exploitation procedure, for a non-uniform state space exploration, along with an experience replay mechanism for multiple value functions updates in the double Q -learning algorithm. A comprehensive comparative simulation study and experiments in a real mobile robot demonstrate the high performance of the proposed algorithm for a real-time simultaneous tuning of multiple adaptive low-level PID controllers of mobile robots in real world conditions.",Expert Syst. Appl.,2019
2666ebdb6f6b9566e2bebab3bef5c01796f2c23e,https://www.semanticscholar.org/paper/2666ebdb6f6b9566e2bebab3bef5c01796f2c23e,Dynamic Linear Predictive Optimization of Flexible Robot Profiling MFA Model,"As the airbag of a flexible robot is affected by external environmental factors during the profiling process, there are many uncertainties in the process of deformation of the airbag. For this reason, the general nonlinear control strategy cannot obtain an accurate data model. In this paper, a flexible robot profiling MFA (Model-Free Adaptive) model based on adaptive predictive dynamic linear optimization is proposed. Firstly, the real-time thickness of the airbag is obtained through edge detection by using the image processing algorithm. Secondly, the airbag aerodynamic model is constructed by visual servo control strategy. Then, a nonlinear control system based on model-free adaptive control is established. Thirdly, the weighting factor is used to limit the variation range of the input quantity, and the deviation of the actual value and the expected value is corrected by the adaptive prediction mechanism. Finally, the servo control the airbag is completed. The experimental results show that the improved model proposed in this paper solves the overshoot phenomenon of the standard control model with less control error and higher robustness.",J. Sensors,2019
6e61f825069bc1da7863aaed45ece4e55b516fb8,https://www.semanticscholar.org/paper/6e61f825069bc1da7863aaed45ece4e55b516fb8,Trajectory Tracking Control for Mobile Robots Using Reinforcement Learning and PID,"In this paper, a novel algorithm of trajectory tracking control for mobile robots using the reinforcement learning and PID is proposed. The Q-learning and PID are adopted for tracking the desired trajectory of the mobile robot. The proposed method can reduce the computational complexity of reward function for Q-learning and improve the tracking accuracy of mobile robot. The effectiveness of the proposed algorithm is demonstrated via simulation tests.","Iranian Journal of Science and Technology, Transactions of Electrical Engineering",2020
8660967a947a6c705d35df9c0a8383b7166355db,https://www.semanticscholar.org/paper/8660967a947a6c705d35df9c0a8383b7166355db,Ictiobot-40 a low cost AUV platform for acoustic imaging surveying,"Autonomous Underwater Vehicles (AUVs) are suitable platforms for a wide type of applications in the oceanic environment. These applications are developed in various fields such as scientific surveying, off-shore industry and defense. The employment of AUVs requires less human support and reduces operation costs. Due to the changing marine environment these vehicles must deal with uncertain and hostile conditions to perform its tasks. In the marine robotics matter, the INTELYMEC group has developed in 2012 an AUV prototype called Ictiobot, a low cost experimental platform for multipurpose missions. In this paper an upgrade of the original prototype is presented, the Ictiobot-40, conceived to perform acoustic imaging surveying missions of up to two hours and maximum depths of 40 meters. The new software and hardware architectures and mechanical structure improvements, are detailed. In addition to these technical details, initial experimental results of the AUV performance in quiet waters will be discussed. Also, the new approaches for systems under development are presented.",OCEANS 2019 - Marseille,2019
8ab6c626bf074b501da30d656432afaefdfa5a45,https://www.semanticscholar.org/paper/8ab6c626bf074b501da30d656432afaefdfa5a45,Solving the optimal path planning of a mobile robot using improved Q-learning,"Abstract Q-learning, a type of reinforcement learning, has gained increasing popularity in autonomous mobile robot path planning recently, due to its self-learning ability without requiring a priori model of the environment. Yet, despite such advantage, Q-learning exhibits slow convergence to the optimal solution. In order to address this limitation, the concept of partially guided Q-learning is introduced wherein, the flower pollination algorithm (FPA) is utilized to improve the initialization of Q-learning. Experimental evaluation of the proposed improved Q-learning under the challenging environment with a different layout of obstacles shows that the convergence of Q-learning can be accelerated when Q-values are initialized appropriately using the FPA. Additionally, the effectiveness of the proposed algorithm is validated in a real-world experiment using a three-wheeled mobile robot.",Robotics Auton. Syst.,2019
c0379693aae06b4f8aa6f3b80429f9831cbb6233,https://www.semanticscholar.org/paper/c0379693aae06b4f8aa6f3b80429f9831cbb6233,Meta-heuristic algorithms for the control tuning of omnidirectional mobile robots,"ABSTRACT The growth in usage of efficient mobile robots in engineering has motivated the search for new alternatives to improve the control tuning task. In this article, Cartesian space proportional–derivative control tuning for omnidirectional mobile robots is established under an offline dynamic optimization approach wherein the minimization of the tracking error and energy consumption are considered simultaneously, providing efficient performance in real tests. A statistical study of the performance of twelve different meta-heuristic algorithms and one gradient technique indicates that using the fittest solution in the meta-heuristic optimization process through generations allows finding more suitable controller parameters. Also, real tests with each of the best control gains obtained using algorithms are realized as a laboratory prototype. Analysis of laboratory tests indicate that, statistically, of comparisons with the best control gains exhibit different performance functions in spite of having only slightly different control gains.",Engineering Optimization,2020
c90be74c07dde44a77f1b04b0656cfbc1ffc6391,https://www.semanticscholar.org/paper/c90be74c07dde44a77f1b04b0656cfbc1ffc6391,Neuroevolution with CMA-ES for Real-time Gain Tuning of a Car-like Robot Controller,"This paper proposes a method for dynamically varying the gains of a mobile robot controller that takes into account, not only errors to the reference trajectory but also the uncertainty in the localisation. To do this, the covariance matrix of a state observer is used to indicate the precision of the perception. CMA-ES, an evolutionary algorithm is used to train a neural network that is capable of adapting the robot’s behaviour in real-time. Using a car-like vehicle model in simulation. Promising results show significant trajectory following performances improvements thanks to control gains fluctuations by using this new method. Simulations demonstrate the capability of the system to control the robot in complex environments, in which classical static controllers could not guarantee a stable behaviour.",ICINCO,2019
d8b5801c638432c0f08eb7aeacec6277598b59be,https://www.semanticscholar.org/paper/d8b5801c638432c0f08eb7aeacec6277598b59be,Path Planning for Unmanned Vehicles Based on Value Function Approximation Algorithm,"This paper deals with the path planning problem for unmanned vehicles based on reinforcement learning. Considering the unmanned vehicles’ dynamic model, the neural network is used to approximate the value function. Besides, in order to make it more suitable for practical applications and speed up the learning process, the recursive least squares algorithm is used to eliminate the inverse operation. Then some experiments are implemented to verify the effectiveness of the proposed improved value function approximation algorithm. It is proved to have improved the generalization performance of reinforcement learning in continuous space.",2019 IEEE 15th International Conference on Control and Automation (ICCA),2019
d8f8aa4a1fe134531deda3cdc1d6214ddc580ea7,https://www.semanticscholar.org/paper/d8f8aa4a1fe134531deda3cdc1d6214ddc580ea7,Multi-objective Optimization Based Self Tuning Robot Manipulator Controller,"The multi-joint robot manipulator has nonlinear and strong coupling characteristics. It’s motion planning can be obtained by multi-objective optimization control with minimum torque motion and position deviation. In this paper, NSGA-II and preference information based RV-NSGA-II multi-objective optimization algorithm are used to optimize the control of two link manipulator joints respectively. On the basis of the Kinetic model of two-link manipulator, the proportional, integral and differential coefficients of the PID controller can be online adjusted by the multi-objective optimization algorithm for the desired motion planning path, so that the motion of two link manipulator can be controlled. The optimization results show that the self-tuning PID controller of NSGA-II can effectively control the joints according to the established target, especially the proposed preference information based RV-NSGA-II multi-objective algorithm has less deviation on joint position control.",2019 Chinese Control And Decision Conference (CCDC),2019
deca168c83c47b81b07636ba1b17473fc3344639,https://www.semanticscholar.org/paper/deca168c83c47b81b07636ba1b17473fc3344639,System Modelling and Development of Accurate Feeding Control System for Forest Harvester Operation,"In order to improve the efficiency of harvesters, the control system of the feed roller precision feeding has been developed and tested (we develop and test a kind of feeding roller control system which can precisely feed). This control system is based on PID control algorithm to research the automatic precision feeding control system of the harvesters. Based on the combination of the accurate automatic feeding requirement with the control process, this paper studied the application of incremental PID control algorithm aiming at automatic precise feeding control. In the experiment, an improved multi-segment adaptive PID control algorithm was proposed based on the feeding results which analyzed with different P, I and D parameters. The experimental results showed that the improved PID control algorithm can achieve automatic and accurate feeding, and its deviation is within the accepted range. This method is well-adapted which can effectively improve the operation efficiency of harvesters. But in following tasks, it is necessary to make further optimization about the characteristics of different tree species and diameter, length etc.",Proceeding of the 24th International Conference on Industrial Engineering and Engineering Management 2018,2019
fb2df65189174d5cd96923520c63f5abcf0acd4b,https://www.semanticscholar.org/paper/fb2df65189174d5cd96923520c63f5abcf0acd4b,Vehículos de guiado autónomo (AGV) en aplicaciones industriales: una revisión,"Se presenta una revisión del estado del arte de vehículos de guiado autónomo (AGV por sus siglas en inglés: Automated Guided Vehicle) para el transporte de objetos y materia prima en aplicaciones industriales. La revisión de literatura hace énfasis en varios aspectos como la identificación del lugar, aplicación en diferentes entornos, control del vehículo y descripción de los sistemas de software usados para la programación de los robots móviles, de acuerdo a los requisitos o necesidades a resolver. Adicionalmente, se hace un análisis, con base a las referencias citadas, del aporte que hace este tipo de tecnologías no solo a la industria, sino también a otros tipos de modelo de negocio, como lo son el área de la salud, los sistemas de transporte urbano, entre otros.",Revista Politécnica,2019
fe66eec24a4f245fbd227edeb3e0222491213b72,https://www.semanticscholar.org/paper/fe66eec24a4f245fbd227edeb3e0222491213b72,PID Tuning with Neural Networks,"In this work we will report our initial investigation of how a neural network architecture could become an efficient tool to model Proportional-Integral-Derivative controller (PID controller). It is well known that neural networks are excellent function approximators, we will then be investigating if a recursive neural networks could be suitable to model and tune PID controllers thus could assist in determining the controller’s proportional, integral, and the derivative gains. A preliminary evaluation is reported.",ACIIDS,2019
01dd890d1f453c87daf76456f0dd099465012134,https://www.semanticscholar.org/paper/01dd890d1f453c87daf76456f0dd099465012134,An adaptive deep Q-learning strategy for handwritten digit recognition,"Handwritten digits recognition is a challenging problem in recent years. Although many deep learning-based classification algorithms are studied for handwritten digits recognition, the recognition accuracy and running time still need to be further improved. In this paper, an adaptive deep Q-learning strategy is proposed to improve accuracy and shorten running time for handwritten digit recognition. The adaptive deep Q-learning strategy combines the feature-extracting capability of deep learning and the decision-making of reinforcement learning to form an adaptive Q-learning deep belief network (Q-ADBN). First, Q-ADBN extracts the features of original images using an adaptive deep auto-encoder (ADAE), and the extracted features are considered as the current states of Q-learning algorithm. Second, Q-ADBN receives Q-function (reward signal) during recognition of the current states, and the final handwritten digits recognition is implemented by maximizing the Q-function using Q-learning algorithm. Finally, experimental results from the well-known MNIST dataset show that the proposed Q-ADBN has a superiority to other similar methods in terms of accuracy and running time.",Neural Networks,2018
23eedfdb04ec6cdfe6bc6064d5d2c29076c37e23,https://www.semanticscholar.org/paper/23eedfdb04ec6cdfe6bc6064d5d2c29076c37e23,Analysis on Improving the Response Time with PIDSARSA-RAL in ClowdFlows Mining Platform,This paper provides an improved parallel data processing in Big Data mining using ClowdFlows platform. The big data processing involves an improvement in Proportional Integral Derivative (PID) controller using Reinforcement Adaptive Learning (RAL). The Reinforcement Adaptive Learning involves the use of Actor-critic State–action–reward–state–action (SARSA) learning that suits well the stream mining module of ClowdFlows platform. The study concentrates on batch mode processing in Big Data mining model with the use of proposed PID-SARSA-RAL. The experimental evaluation with the conventional ClowdFlows platform proved the effectiveness of the proposed method over continuous parallel workflow execution.,EAI Endorsed Trans. Energy Web,2018
24fbe4b4c11ce465c66c8bc070bc18f62f6082f3,https://www.semanticscholar.org/paper/24fbe4b4c11ce465c66c8bc070bc18f62f6082f3,Pareto-Based Multi-objective Optimization for Fractional Order $$\hbox {PI}^{\lambda }$$PIλ Speed Control of Induction Motor by Using Elman Neural Network,"This paper presents Pareto-based multi-objective optimization for speed control of induction motor with fractional order proportional integral ($$\hbox {FOPI}^{\lambda }$$FOPIλ) controller. The aim of this study is to find optimum values of tuning parameters of $$\hbox {FOPI}^{\lambda }$$FOPIλ by using Elman neural network (ENN) and Pareto-based multi-objective optimization. In this context, proportional gain $$K_{\mathrm{p}}$$Kp, integral gain $$K_{\mathrm{i}}$$Ki and the order of fractional integral $$\lambda $$λ are selected as tuning parameters while settling time $${T}_{\mathrm{s}}$$Ts and overshoot $${M}_{\mathrm{o}}$$Mo are chosen as objective functions. Firstly, experiments have been carried out to obtain training and test data. Then, ENN has been trained to construct mathematical model which is necessary for multi-objective optimization. In the next step, accuracy and reliability of ENN model are tested by using test data taken from experimental set-up. Finally, Pareto-based multi-objective optimization method has been used to find the optimum values of tuning parameters that minimize both $${T}_{\mathrm{s}}$$Ts and $${M}_{\mathrm{o}}$$Mo values. The different three conditions of the Pareto solution set are applied to the experimental set-up to verify the effectiveness of the proposed method. Results show that ENN is well modelled for induction motor and Pareto solution is an effective method to find optimal values of controller coefficients according to desired $${T}_{\mathrm{s}}$$Ts and $${M}_{\mathrm{o}}$$Mo values.",Arabian Journal for Science and Engineering,2018
4c698279fdde21a4951a4cda6534ef8f0e114cc6,https://www.semanticscholar.org/paper/4c698279fdde21a4951a4cda6534ef8f0e114cc6,Adaptive PID controller based onQ-learning algorithm,"An adaptive proportional–integral–derivative (PID) controller based on Q-learning algorithm is proposed to balance the cart–pole system in simulation environment. This controller was trained using Q-learning algorithm and implemented the learned Q-tables to change the gains of linear PID controllers according to the state of the system during the control process. The adaptive PID controller based on Q-learning algorithm was trained from a set of fixed initial positions and was able to balance the system starting from a series of initial positions that are different from the ones used in the training session, which achieved equivalent or even better performances in comparison with the conventional PID controller and the controller only uses Q-learning algorithm. This indicates the advantage of the adaptive PID controller based on Q-learning algorithm both in the generality of balancing the cart–pole system from a relatively wide range of initial positions and in the stabilisability of achieving smaller steady-state error.",CAAI Trans. Intell. Technol.,2018
aac079292803dbd24765ba6295d789c5422d53ca,https://www.semanticscholar.org/paper/aac079292803dbd24765ba6295d789c5422d53ca,The Control Design for Trajectory Tracking of Four-wheeled Mobile Robot using Model Predictive Control: A Preliminary Study,"The mobile robot is one of the Unmanned Vehicle that belongs to Unmanned Ground Vehicle (UGV) which has the ability to be remotely controlled. The advancement in navigation has enabled new opportunity to send the UGV to explore new area or disaster mitigation. The path is set with the help of digital imaging of a certain area, then the mobile robot is expected to follow the path. In this paper, we conduct a simulation of fourwheeled mobile robot trajectory tracking. We design a control for trajectory tracking using the Model Predictive Control approach. By simulating for some values of control and reference, the simulation shows that the control design for the trajectory tracking in four wheeled mobile robots need some improvement. Keywords—model predictive control, mobile robot, trajectory tracking",,2018
b5e4ca0a6e59d2ce361214313ccf97dc1b5d79d7,https://www.semanticscholar.org/paper/b5e4ca0a6e59d2ce361214313ccf97dc1b5d79d7,Reinforcement Learning for Quality of Experience Optimization in Tactical Networks,"The future tactical battlespace will require a variety of services that are deployed at the company or platoon level. Tactical radios provide the communications between these elements, which must operate in a disconnected intermittent, limited bandwidth environment. The projected computing and communications requirements are significantly greater than what tactical radios and their devices currently offer. Capacity is the result of a bottom-up approach, where routes and links are determined by the nodes locations. This leads to the situation where the capacity does not take the applications requirements into account. We propose a top-down approach that considers application requirement in the network and attempts to reconfigure the network to improve overall network performance through reinforcement learning techniques. The learning considers understanding of the quality of experience demands or requirements of the communications services in a network domain and learns optimizations of the Quality of Service in the network. We present validation of this approach to use of tactical node deployments in Switzerland.",MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM),2018
bdd930679751b87941102ffddc5d6f2a5649eca9,https://www.semanticscholar.org/paper/bdd930679751b87941102ffddc5d6f2a5649eca9,Temperature Control of Abnormal Condition Integrated with Fuzzy Improved ELMAN Network and Q Learning for Raw Meal Calcination Process,"Thus the pipe between preheater C5 and kiln rotary was blocked because the outlet temperature of preheater C5 is greater than the maximum value. To overcome above the problem, an abnormal condition controller integrated with fuzzy improved ELMAN network and Q learning has been proposed. The abnormal condition controller has been successfully applied to the actual industry process. Practical applications show that this abnormal condition controller has high potential in process control and can be applied to the other complex industries.",2018 37th Chinese Control Conference (CCC),2018
d14379c63128265439435b502550507c2b5e33f5,https://www.semanticscholar.org/paper/d14379c63128265439435b502550507c2b5e33f5,Intelligent tuning method of PID parameters based on iterative learning control for atomic force microscopy.,"Proportional-integral-derivative (PID) parameters play a vital role in the imaging process of an atomic force microscope (AFM). Traditional parameter tuning methods require a lot of manpower and it is difficult to set PID parameters in unattended working environments. In this manuscript, an intelligent tuning method of PID parameters based on iterative learning control is proposed to self-adjust PID parameters of the AFM according to the sample topography. This method gets enough information about the output signals of PID controller and tracking error, which will be used to calculate the proper PID parameters, by repeated line scanning until convergence before normal scanning to learn the topography. Subsequently, the appropriate PID parameters are obtained by fitting method and then applied to the normal scanning process. The feasibility of the method is demonstrated by the convergence analysis. Simulations and experimental results indicate that the proposed method can intelligently tune PID parameters of the AFM for imaging different topographies and thus achieve good tracking performance.",Micron,2018
ef09b86f6d449ba99adcc73944bd7a8797f0ce8f,https://www.semanticscholar.org/paper/ef09b86f6d449ba99adcc73944bd7a8797f0ce8f,Control Strategy of Speed Servo Systems Based on Deep Reinforcement Learning,"We developed a novel control strategy of speed servo systems based on deep reinforcement learning. The control parameters of speed servo systems are difficult to regulate for practical applications, and problems of moment disturbance and inertia mutation occur during the operation process. A class of reinforcement learning agents for speed servo systems is designed based on the deep deterministic policy gradient algorithm. The agents are trained by a significant number of system data. After learning completion, they can automatically adjust the control parameters of servo systems and compensate for current online. Consequently, a servo system can always maintain good control performance. Numerous experiments are conducted to verify the proposed control strategy. Results show that the proposed method can achieve proportional–integral–derivative automatic tuning and effectively overcome the effects of inertia mutation and torque disturbance.",Algorithms,2018
c70ab7cf9ac8ddb955a7389be67669c0923b3dbf,https://www.semanticscholar.org/paper/c70ab7cf9ac8ddb955a7389be67669c0923b3dbf,Design of STM32-based hub motor controller,"ABSTRACT. This paper aims to develop a new control architecture of wheeled mobile robot that supports the start-up and stop of robot driven by dual hub motors, the forward and reverse rotation of hub motors, and the coordinated control of two wheels in motion. Inspired by three-phase power supply, Hall signal detection, and square wave driving mode, the hub motor control system was made up of a power circuit, a three-phase full bridge inverter circuit, a Hall signal detection circuit, a peripheral circuit of STM32 single chip microcomputer, communication circuits, a current detection circuit, an over-current detection circuit, a key input circuit, and a printed circuit board (PCB). With the aid of Keil software, the following programs were developed for the hub motor control system, namely, the keypad detection program, the organic light-emitting diode (OLED) module driver, speed detection program, proportional–integral–derivative (PID) support program, motor startup program, motor commutation program, motor speed PID control program and motor stop program. This research successfully optimizes the vehicle control architecture and simplifies the control logic, allowing the vehicle controller to send simple instructions and achieve the basic motion control of the robot body.",,2017
db7e8db83b4cfbca92112838a1ffdc6f23ffdbe9,https://www.semanticscholar.org/paper/db7e8db83b4cfbca92112838a1ffdc6f23ffdbe9,An improved adaptive control method for active balancing control of rotor with time-delay,,IEICE Electron. Express,2017
c02a79126d92167de2e6afaa9451ca46c9a97d4c,https://www.semanticscholar.org/paper/c02a79126d92167de2e6afaa9451ca46c9a97d4c,DHT-based Communications Survey: Architectures and Use Cases,"Several distributed system paradigms utilize Distributed Hash Tables (DHTs) to realize structured peer-to-peer (P2P) overlays. DHT structures arise as the most commonly used organizations for peers that can efficiently perform crucial services such as data storage, replication, query resolution, and load balancing. With the advances in various distributed system technologies, novel and efficient solutions based on DHTs emerge and play critical roles in system design. DHT-based methods and communications have been proposed to address challenges such as scalability, availability, reliability and performance, by considering unique characteristics of these technologies. In this article, we propose a classification of the state-of-the-art DHT-based methods focusing on their system architecture, communication, routing and technological aspects across various system domains. To the best of our knowledge, there is no comprehensive survey on DHT-based applications from system architecture and communication perspectives that spans various domains of recent distributed system technologies. We investigate the recently emerged DHT-based solutions in the seven key domains of edge and fog computing, cloud computing, blockchain, the Internet of Things (IoT), Online Social Networks (OSNs), Mobile Ad Hoc Networks (MANETs), and Vehicular Ad Hoc Networks (VANETs). In contrast to the existing surveys, our study goes beyond the commonly known DHT methods such as storage, routing, and lookup, and identifies diverse DHT-based solutions including but not limited to aggregation, task scheduling, resource management and discovery, clustering and group management, federation, data dependency management, and data transmission. Furthermore, we identify open problems and discuss future research guidelines for",ArXiv,2021
cbe5e92fcd2b1d24d9845e1971578b63ab6496e4,https://www.semanticscholar.org/paper/cbe5e92fcd2b1d24d9845e1971578b63ab6496e4,Exploiting the Spam Correlations in Scalable Online Social Spam Detection,"The huge amount of social spam from large-scale social networks has been a common phenomenon in the contemporary world. The majority of former research focused on improving the efficiency of identifying social spam from a limited size of data in the algorithm side, however, few of them target on the data correlations among large-scale distributed social spam and utilize the benefits from the system side. In this paper, we propose a new scalable system, named SpamHunter, which can utilize the spam correlations from distributed data sources to enhance the performance of large-scale social spam detection. It identifies the correlated social spam from various distributed servers/sources through DHT-based hierarchical functional trees. These functional trees act as bridges among data servers/sources to aggregate, exchange, and communicate the updated and newly emerging social spam with each other. Furthermore, by processing the online social logs instantly, it allows online streaming data to be processed in a distributed manner, which reduces the online detection latency and avoids the inefficiency of outdated spam posts. Our experimental results with real-world social logs demonstrate that SpamHunter reaches 95% F1 score in the spam detection, achieves high efficiency in scaling to a large amount of data servers with low latency.",CLOUD,2019
d689e2f595932b1c026d43321918d4383523f5c0,https://www.semanticscholar.org/paper/d689e2f595932b1c026d43321918d4383523f5c0,"Systematic Construction, Execution, and Reproduction of Complex Performance Benchmarks","In this work, we present the next generation of the Elba toolkit available under a Beta release, showing how we have used it for experimental research in computer systems using RUBBoS, a well-known n-tier system benchmark, as example. In particular, we show how we have leveraged milliScope – Elba toolkit’s monitoring and instrumentation framework – to collect log data from benchmark executions at unprecedented fine-granularity, as well as how we have specified benchmark workflows with WED-Make – a declarative workflow language whose main characteristic is to facilitate the declaration of dependencies. We also show how to execute WED-Makefiles (i.e., workflow specifications written with WED-Make), and how we have successfully reproduced the experimental verification of the millibottleneck theory of performance bugs in multiple cloud environments and systems.",CLOUD,2019
e7e057faa0017496863b8649f90df46667929c3f,https://www.semanticscholar.org/paper/e7e057faa0017496863b8649f90df46667929c3f,"Cloud Computing – CLOUD 2019: 12th International Conference, Held as Part of the Services Conference Federation, SCF 2019, San Diego, CA, USA, June 25–30, 2019, Proceedings","In the existing positioning system based on bluetooth (BT), the interference of the positioning device signal, the slow processing speed of the positioning data and the large energy consumption of the positioning device affect the system positioning accuracy and service quality. In this paper, we propose an Ultra-Low power indoor localization system using mobile cloud computing. The mobile cloud server reduces the signal interference of the positioning device, improves the positioning accuracy and reduces the system energy consumption by controlling the working mode of the positioning device. A simultaneous localization and power adaptation scheme is developed. In the real experiment evaluation, our proposed system can localize the area of a terminal located within 3 m distance with 98% accuracy and average positioning error less then 1.55 m. Compare with other BLE system, 97% average energy consumption of our system is reduced.",Lecture Notes in Computer Science,2019
0623b3247bc72e8b75f7a5eb1cb1ba007b8d4ef9,https://www.semanticscholar.org/paper/0623b3247bc72e8b75f7a5eb1cb1ba007b8d4ef9,Open-Ended Learning of Reactive Knowledge in Cognitive Robotics Based on Neuroevolution,,HAIS,2021
a6a90351e17b4e53702094a7072642d79ff36d88,https://www.semanticscholar.org/paper/a6a90351e17b4e53702094a7072642d79ff36d88,Theory of Mind Improves Human’s Trust in an Iterative Human-Robot Game,"Trust is a critical issue in human–robot interactions as it is at the base of the establishment of solid relationships. Theory of Mind (ToM) is the cognitive skill that allows us to understand what others think and believe. Several studies in HRI and psychology suggest that trust and ToM are interdependent concepts since we trust another agent based on our representation of its actions, beliefs, and intentions. However, very few works take ToM of the robot into consideration while studying trust in HRI. In this paper, we aim to examine whether the perception of ToM abilities on a robotic agent influences human-robot trust over time in an iterative game scenario. To this end, participants played an Investment Game with a humanoid robot (Pepper) that was presented as having either low-level ToM or high-level ToM. During the game, the participants were asked to pick a sum of money to invest in the robot. The amount invested was used as the main measurement of human-robot trust. Our experimental results show that robots possessing a high-level of ToM abilities were trusted more than the robots presented with low-level ToM skills.",HAI,2021
ae70da10c0e414414133d678150527a642758faf,https://www.semanticscholar.org/paper/ae70da10c0e414414133d678150527a642758faf,Recent trends towards cognitive science: from robots to humanoids,,Cognitive Computing for Human-Robot Interaction,2021
d4c2c340b4bd4ac591822ab640897836350fe756,https://www.semanticscholar.org/paper/d4c2c340b4bd4ac591822ab640897836350fe756,A Local Active Learning Strategy by Cooperative Multi-Agent Systems,"In this paper, we place ourselves in the context learning approach and we aim to show that adaptive multiagent systems are a relevant solution to its enhancement with local active learning strategy. We use a local learning approach inspired by constructivism: context learning by adaptive multi-agent systems. We seek to introduce active learning requests as a mean of internally improving the learning process by detecting and resolving imprecisions between the learnt knowledge. We propose a strategy of local active learning for resolving learning inaccuracies. In this article, we evaluate the performance of local active learning. We show that the addition of active learning requests facilitated by self-observation accelerates and generalizes learning, intelligently selects learning data, and increases performance on prediction errors.",ICAART,2021
fb39d026177c1d8f1594af64e5bd758fc82caa41,https://www.semanticscholar.org/paper/fb39d026177c1d8f1594af64e5bd758fc82caa41,Autonomous cognition development with lifelong learning: A self-organizing and reflecting cognitive network,"Abstract Lifelong learning is still a great challenge for cognitive robots since the continuous streaming data they encounter is usually enormous and no-stationary. Traditional cognitive methods suffer from large storage and computation consumption in this situation. Therefore, we propose a self-organizing and reflecting cognitive network (SORCN) to realize robotic lifelong cognitive development through incremental learning and regular reflecting. The network integrates a self-organizing incremental neural network (SOINN) with a modified CFS clustering algorithm. SOINN develops concise object concepts to alleviate storage consumption. Moreover, we modify SOINN by an efficient competitive method based on reflection results to reduce the learning computation. The modified CFS clustering algorithm is designed for reflecting knowledge learned by SOINN periodically. It improves the traditional CFS as a three-step clustering method including clustering, merging and splitting. Specifically, an autonomous center selection strategy is employed for CFS to cater to online learning. Moreover, a series of cluster merging and splitting strategies are proposed to enable CFS to cluster data incrementally and improve its clustering effect. Additionally, the reflection results are utilized to adjust the topological structure of SOINN and guide the future learning. Experimental results demonstrate that SORCN can achieve better learning effectiveness and efficiency over several state-of-art algorithms.",Neurocomputing,2021
2b737826c8fa88baf6e089c638e175121ecea915,https://www.semanticscholar.org/paper/2b737826c8fa88baf6e089c638e175121ecea915,Continual Learning: Tackling Catastrophic Forgetting in Deep Neural Networks with Replay Processes,"Les humains apprennent toute leur vie. Ils accumulent des connaissances a partir d'une succession d'experiences d'apprentissage et en memorisent les aspects essentiels sans les oublier. Les reseaux de neurones artificiels ont des difficultes a apprendre dans de telles conditions. Ils ont en general besoin d'ensembles de donnees rigoureusement prepares pour pouvoir apprendre a resoudre des problemes comme de la classification ou de la regression. En particulier, lorsqu'ils apprennent sur des sequences d'ensembles de donnees, les nouvelles experiences leurs font oublier les anciennes. Ainsi, ils sont souvent incapables d'apprehender des scenarios reels tels ceux de robots autonomes apprenant en temps reel a s'adapter a de nouvelles situations et devant resoudre des problemes sans oublier leurs experiences passees.L'apprentissage continu est une branche de l'apprentissage automatique s'attaquant a ce type de scenarios. Les algorithmes continus sont crees pour apprendre des connaissances, les enrichir et les ameliorer au cours d'un curriculum d'experiences d'apprentissage.Dans cette these, nous proposons d'explorer l'apprentissage continu avec rejeu de donnees. Les methodes de rejeu de donnees rassemblent les methodes de repetitions et les methodes de rejeu par generation. Le rejeu par generation consiste a utiliser un reseau de neurones auxiliaire apprenant a generer les donnees actuelles. Ainsi plus tard le reseau auxiliaire pourra etre utilise pour regenerer des donnees du passe et les rememorer au modele principal. La repetition a le meme objectif, mais cette methode sauve simplement des images specifiques et les rejoue plus tard au modele principal pour eviter qu'il ne les oublie. Les methodes de rejeu permettent de trouver un compromis entre l'optimisation de l'objectif d'apprentissage actuel et ceux du passe. Elles permettent ainsi d'apprendre sans oublier sur des sequences de tâches.Nous montrons que ces methodes sont prometteuses pour l'apprentissage continu.En particulier, elles permettent la reevaluation des donnees du passe avec des nouvelles connaissances et de confronter des donnees issues de differentes experiences. Nous demontrons la capacite des methodes de rejeu a apprendre continuellement a travers des tâches d'apprentissage non-supervisees, supervisees et de renforcements.",ArXiv,2020
690c53ead57de755ab300a81ed1cd62766fb324c,https://www.semanticscholar.org/paper/690c53ead57de755ab300a81ed1cd62766fb324c,DREAM Architecture: a Developmental Approach to Open-Ended Learning in Robotics,"Robots are still limited to controlled conditions, that the robot designer knows with enough details to endow the robot with the appropriate models or behaviors. Learning algorithms add some flexibility with the ability to discover the appropriate behavior given either some demonstrations or a reward to guide its exploration with a reinforcement learning algorithm. Reinforcement learning algorithms rely on the definition of state and action spaces that define reachable behaviors. Their adaptation capability critically depends on the representations of these spaces: small and discrete spaces result in fast learning while large and continuous spaces are challenging and either require a long training period or prevent the robot from converging to an appropriate behavior. Beside the operational cycle of policy execution and the learning cycle, which works at a slower time scale to acquire new policies, we introduce the redescription cycle, a third cycle working at an even slower time scale to generate or adapt the required representations to the robot, its environment and the task. We introduce the challenges raised by this cycle and we present DREAM (Deferred Restructuring of Experience in Autonomous Machines), a developmental cognitive architecture to bootstrap this redescription process stage by stage, build new state representations with appropriate motivations, and transfer the acquired knowledge across domains or tasks or even across robots. We describe results obtained so far with this approach and end up with a discussion of the questions it raises in Neuroscience.",ArXiv,2020
7039f4de07cb29a0cf91b4e08f999a389782aa54,https://www.semanticscholar.org/paper/7039f4de07cb29a0cf91b4e08f999a389782aa54,When Would You Trust a Robot? A Study on Trust and Theory of Mind in Human-Robot Interactions,"Trust is a critical issue in human-robot interactions (HRI) as it is the core of human desire to accept and use a non-human agent. Theory of Mind (ToM) has been defined as the ability to understand the beliefs and intentions of others that may differ from one’s own. Evidences in psychology and HRI suggest that trust and ToM are interconnected and interdependent concepts, as the decision to trust another agent must depend on our own representation of this entity’s actions, beliefs and intentions. However, very few works take ToM of the robot into consideration while studying trust in HRI. In this paper, we investigated whether the exposure to the ToM abilities of a robot could affect humans’ trust towards the robot. To this end, participants played a Price Game with a humanoid robot (Pepper) that was presented having either low-level ToM or high-level ToM. Specifically, the participants were asked to accept the price evaluations on common objects presented by the robot. The willingness of the participants to change their own price judgement of the objects (i.e., accept the price the robot suggested) was used as the main measurement of the trust towards the robot. Our experimental results showed that robots possessing a high-level of ToM abilities were trusted more than the robots presented with low-level ToM skills.",2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),2020
7352df45bbe318dec1aa037149d8c2dcc5d9c7d3,https://www.semanticscholar.org/paper/7352df45bbe318dec1aa037149d8c2dcc5d9c7d3,"Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges","Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective changes through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge. Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier.",Inf. Fusion,2019
84cb878e08f4fe355e97063afeaa7664515c9c24,https://www.semanticscholar.org/paper/84cb878e08f4fe355e97063afeaa7664515c9c24,Learning over the Attentional Space with Mobile Robots,"The advancement of technology has brought many benefits to robotics. Today, it is possible to have robots equipped with many sensors that collect different kinds of information on the environment all time. However, this brings a disadvantage: the increase of information that is received and needs to be processed. This computation is too expensive for robots and is very difficult when it has to be performed online and involves a learning process. Attention is a mechanism that can help us address the most critical data at every moment and is fundamental to improve learning. This paper discusses the importance of attention in the learning process by evaluating the possibility of learning over the attentional space. For this purpose, we modeled in a cognitive architecture the essential cognitive functions necessary to learn and used bottom-up attention as input to a reinforcement learning algorithm. The results show that the robot can learn on attentional and sensorial spaces. By comparing various action schemes, we find the set of actions for successful learning.",2020 Joint IEEE 10th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),2020
0b246ce3952e489dc225da7ab73d114908b4275a,https://www.semanticscholar.org/paper/0b246ce3952e489dc225da7ab73d114908b4275a,Producing Parameterized Value Functions Through Modulation for Cognitive Developmental Robots,"Parameterizing value functions as a representation of robotic tasks in different domains allows for their generalization, and can provide a way to transfer knowledge to new situations. To this end, in this paper we propose a modulation based mechanism embedded within a cognitive architecture for robots. It makes use of the combined operation of the long-term memory and the motivational system in order to select candidate primitive value functions for transfer. These are then adapted to the new situation through the addition of modulatory ANNs to progressively conform new parameterized value functions able to address more complex situations in a developmental manner. The proposed method is tested in a Baxter robot, which must solve different tasks in a cooking setup.",ROBOT,2019
26223b6ed10fecffd3722625b30988de0d94a9ce,https://www.semanticscholar.org/paper/26223b6ed10fecffd3722625b30988de0d94a9ce,Bootstrapping Autonomous Skill Learning in the MDB Cognitive Architecture,"This paper is concerned with motivation in autonomous robots. In particular we focus on the basic structure that is necessary for bootstrapping the initial stages of multiple skill learning within the motivational engine of the MDB cognitive architecture. To this end, taking inspiration from a series of computational models of the use of motivations in infants, we propose an approach that leverages two types of cognitive motivations: exploratory and proficiency based. The latter modulated by the concept of interestingness. We postulate that these make up the minimum set of motivational components required to initiate the unrewarded learning of a skill toolbox that may later be used in order to achieve operational goals. The approach is illustrated through an experiment with a real robot that is learning skills in a real environment.",IWINAC,2019
3b217dfcc54d40fded9ae5b60a9ed119e3c9d00c,https://www.semanticscholar.org/paper/3b217dfcc54d40fded9ae5b60a9ed119e3c9d00c,"Understanding the Brain Function and Emotions: 8th International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2019, Almería, Spain, June 3–7, 2019, Proceedings, Part I","Transcranial direct current stimulation (tDCS) is a noninvasive technique for brain stimulation capable of modulating brain excitability. Although beneficial effects of tDCS have been shown, the underlying brain mechanisms have not been described. In the present study, we aim to investigate the effects of tDCS on EEG-based functional connectivity, through a partial directed coherence (PDC) analysis, which is a frequency-domain metric that provides information about directionality in the interaction between signals recorded at different channels. The tDCS montage used in our study, was focused on the lower limbs and it was composed of two anodes and one cathode. A single-blind study was carried out, where eight healthy subjects were randomly separated into two groups: sham and active tDCS. Results showed that, for the active tDCS group, the central EEG electrodes Cz, C3 and C4 turned out to be highly connected within alpha and beta frequency bands. On the contrary, the sham group presented a tendency to be more random at its functional connections.",Lecture Notes in Computer Science,2019
5b6220c4f7d20a43fa80821a69c7eb2524f03133,https://www.semanticscholar.org/paper/5b6220c4f7d20a43fa80821a69c7eb2524f03133,Perceptual Generalization and Context in a Network Memory Inspired Long-Term Memory for Artificial Cognition,"In the framework of open-ended learning cognitive architectures for robots, this paper deals with the design of a Long-Term Memory (LTM) structure that can accommodate the progressive acquisition of experience-based decision capabilities, or what different authors call ""automation"" of what is learnt, as a complementary system to more common prospective functions. The LTM proposed here provides for a relational storage of knowledge nuggets given the form of artificial neural networks (ANNs) that is representative of the contexts in which they are relevant in a configural associative structure. It also addresses the problem of continuous perceptual spaces and the task- and context-related generalization or categorization of perceptions in an autonomous manner within the embodied sensorimotor apparatus of the robot. These issues are analyzed and a solution is proposed through the introduction of two new types of knowledge nuggets: P-nodes representing perceptual classes and C-nodes representing contexts. The approach is studied and its performance evaluated through its implementation and application to a real robotic experiment.",Int. J. Neural Syst.,2019
bb1a579a318ca17aeda89d226df7372c2adb4931,https://www.semanticscholar.org/paper/bb1a579a318ca17aeda89d226df7372c2adb4931,Introducing separable utility regions in a motivational engine for cognitive developmental robotics,,Integr. Comput. Aided Eng.,2018
e27022e0e5dd6b15fa210c91316075b3460475ad,https://www.semanticscholar.org/paper/e27022e0e5dd6b15fa210c91316075b3460475ad,Simplifying the creation and management of utility models in continuous domains for cognitive robotics,"Abstract Establishing goal/sub-goal hierarchies in robotic motivational systems for open-ended learning situations and modelling this utility in a manner that is useful for robots is an open research problem, especially when the robots’ state-spaces are continuous and may present ambiguities. In these cases, directly obtaining value functions, and in particular, precise Artificial Neural Network based value functions, becomes very difficult. In this paper, this issue is addressed through a new type of coarse utility functions for the representation of motivation. The proposed approach can be used as an intermediate step in order to be able to produce more consistent data for the subsequent training of precise value functions when and where it becomes necessary. This type of coarse utility functions, called Separable Utility Regions (SUR), are based on the use of the variation of sensor values as clues to the position of goals in state space. Moreover, areas in the state-space must be established where there are correlations between the desired direction the system should follow in its state-space towards a goal, and the direction of variation of the values of a particular sensor. The main focus of this paper is on the process of creating sub-goal hierarchies that permit leading the system in a consistent manner towards goals, so that it can autonomously learn to achieve them whatever its starting state. To this end, an approach to sub-goal determination and chaining based on a recursive establishment of consolidated goal domains as new goals for new utility functions is described. The approach is tested on a real robotic system and the results are extensively analysed and discussed.",Neurocomputing,2019
31d1df842f56f0eb592886aac0a93ec93128a505,https://www.semanticscholar.org/paper/31d1df842f56f0eb592886aac0a93ec93128a505,CIT: Integrated cognitive computing and cognitive agent technologies based cognitive architecture for human-like functionality in artificial systems,"Abstract The paper proposes a novel cognitive architecture that combines cognitive computing and cognitive agent technologies for performing human-like functionality. The system architecture is known as CIT (Cognitive Information Technology). This design takes advantage of cognitive computing to handle Experiential Information (EI) using audio processing, computer vision, natural language processing, text mining, and data mining techniques. The CIT architecture includes human like cognitive agent functionality comprising attention, learning, memory, action selection, and action to handle human like individual and distributed knowledge bases to create rational decisions. The work shows CIT architecture practical implementation through “CIT framework” developed in C# and python language. For validating the system performance, the paper shows CIT based Object Recognition and Question Answering System. This framework is anticipated to advance the quality of artificial intelligent agent based decision-making using human like perception, comprehend and action skills, reducing real world business errors and assuring the correct, accurate, knowledgeable and well-timed human like decisions.",Biologically Inspired Cognitive Architectures,2018
76f958640687b379aec44e5293c5b40d1cc39ece,https://www.semanticscholar.org/paper/76f958640687b379aec44e5293c5b40d1cc39ece,Utility Model Re-description within a Motivational System for Cognitive Robotics,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2018
e9ac4a5244b67308bfb78900f509dfe014d8d077,https://www.semanticscholar.org/paper/e9ac4a5244b67308bfb78900f509dfe014d8d077,40 years of cognitive architectures: core cognitive abilities and practical applications,"In this paper we present a broad overview of the last 40 years of research on cognitive architectures. To date, the number of existing architectures has reached several hundred, but most of the existing surveys do not reflect this growth and instead focus on a handful of well-established architectures. In this survey we aim to provide a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 84 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning, reasoning and metareasoning. In order to assess the breadth of practical applications of cognitive architectures we present information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight the overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.",Artificial Intelligence Review,2018
f85df94fac23a4c4c6e6f06c735160366d441d74,https://www.semanticscholar.org/paper/f85df94fac23a4c4c6e6f06c735160366d441d74,A Redescriptive Approach to Autonomous Perceptual Classification in Robotic Cognitive Architectures,"This paper is concerned with the problem of perceptual classification in the framework of life-long learning developmental cognitive architectures. Perceptual classification is the process by which autonomous entities organize their, usually continuous, perceptual streams into classes of perceptions that are relevant to the different contexts in which they find themselves. In particular, here we describe an approach based on context related generalization or categorization of perceptions in an autonomous manner within embodied systems. This approach involves the introduction of a new type of knowledge nuggets, Pnodes, within the long term memory structure of a cognitive architecture. Taking inspiration from the hippocampus-cortex relationships in real brains, P-nodes are initially described by means of a set of representative perceptual points which are subsequently generalized in a cortex like neural representation. This approach is tested in a series of experiments on a real robot.",2018 International Joint Conference on Neural Networks (IJCNN),2018
08b34c563d3a4eddbc2ef145cd71965f6a2435b6,https://www.semanticscholar.org/paper/08b34c563d3a4eddbc2ef145cd71965f6a2435b6,MLECOG: Motivated Learning Embodied Cognitive Architecture,"This paper presents a new cognitive architecture and its major functional blocks. It describes how the new architecture is related to major trends in cognitive architectures that move toward greater autonomy, motivations, and the creation of goals. After a brief characterization of existing cognitive architectures, particularly those that share similarities with our own, the desired architectural requirements for embodied cognitive systems are spelled out. The proposed cognitive architecture is then presented on a functional level that describes how its functional blocks interact to self-organize and to refine their operations. Selected implementation issues are also discussed. Finally, simulation results of an implemented simplified version of the proposed system are discussed. The simulation results show that the current implementation of the motivated learning embodied cognitive architecture system is capable of maintaining itself in a dynamic environment.",IEEE Systems Journal,2017
2fe9337171fd9daea843ec2b8d344f67f3a38b32,https://www.semanticscholar.org/paper/2fe9337171fd9daea843ec2b8d344f67f3a38b32,Context nodes in the operation of a long term memory structure for an evolutionary cognitive architecture,"This paper describes the creation and use of context nodes, or Cnodes, as an integral part of the structure of a network based Long Term Memory that has been constructed within the Multilevel Darwinist Brain cognitive architecture. Context nodes are networks with multiplicative inputs that support the storage of context related information, that is, a Cnode relates the world the system is in, as well as the system's goal and current state, to the most adequate policy to operate in this context in terms of its previous experience. These structures provide a simple, yet very effective way of retrieving (or activating) long term memory or experience based information when part of a context is detected. A simple example of the operation of the Long Term Memory using Cnodes is presented and discussed.",GECCO,2017
4b5afb8669413f3aba13583f6943eb40685e13c6,https://www.semanticscholar.org/paper/4b5afb8669413f3aba13583f6943eb40685e13c6,Motivational Engine for Cognitive Robotics in Non-static Tasks,"This work proposes a new method to model the extrinsic motivation of a cognitive architecture based on the discovery of separable utility regions (SUR), which reduce the complexity of the standard value functions typically used. Those regions exhibit a correlation between the expected utility and the response of one sensor of the robot. Once they are discovered, the evaluation of the candidate states is only based on the changes of one sensor, which provides a strong independence from noise or dynamism in the utility models. A non-static variation of the classical collect-a-ball scenario was used to test the mechanism in order to generate and define the certainty maps associated to those SURs. Preliminary results show a good response of the technique and a clear improvement in performance when this is associated to a restructuring mechanism for the utility model, which, in this case, corresponds to the creation and chaining of sub-goals.",IWINAC,2017
bc65f99c5fc710d8f2a2ae3445af367f2eb98a60,https://www.semanticscholar.org/paper/bc65f99c5fc710d8f2a2ae3445af367f2eb98a60,Multilevel Darwinist Brain: Context Nodes in a Network Memory Inspired Long Term Memory,"The Multilevel Darwinist Brain (MDB) is a cognitive architecture aimed at providing autonomous and self-motivated life-long learning capabilities for robots. This paper deals with a new structure and implementation for the long term memory (LTM) in MDB based on Fuster’s concept of Network memory and on the introduction of a new type of node or cognit called Context Node (Cnode). The idea of Network memory as proposed here, provides a path to hierarchically and progressively relate LTM knowledge elements, allowing for a developmental approach to learning that permits very efficient experience based responses from the robot. We include a simple, albeit quite illustrative, example of the application of these ideas using a real Baxter robot.",IWINAC,2017
01c3016bd2af12dfe22a1e43d2a86b52894b12c4,https://www.semanticscholar.org/paper/01c3016bd2af12dfe22a1e43d2a86b52894b12c4,Considering Memory Networks in the LTM Structure of the Multilevel Darwinist Brain,"In this paper, we present an initial implementation of the concept of memory network within the long term memory (LTM) structure of the Multilevel Darwinist Brain (MDB). The purpose is to address the problem of determining what, out of all the knowledge stored in the LTM, is relevant for the current context that a robot finds itself in, without having to resort to complex and time consuming search processes. Additionally, this type of structure allows for a very elegant way of hierarchically relating previously learnt knowledge with solutions to new situations. A very simple example is presented in order to help to understand how the system operates and its possibilities.",GECCO,2016
0a83eb1b03ea4e03e6b6486d79cb9689049aafe3,https://www.semanticscholar.org/paper/0a83eb1b03ea4e03e6b6486d79cb9689049aafe3,MotivEn: Motivational engine with sub-goal identification for autonomous robots,"This paper presents an initial integrated approximation to the complete problem of robot motivation in continuous domains in terms of how to adaptively combine intrinsic and extrinsic motivations into an integrated motivational engine, called MotivEn. It allows an autonomous robot to find goals and decompose them into sub-goals that can be chained to facilitate achieving the final goal. MotivEn is based on an evolutionarily learnt value function in continuous domains where exploration and exploitation, as well as its decomposition into sub-value functions, is autonomously achieved.",2016 IEEE Congress on Evolutionary Computation (CEC),2016
8978ddd91076bf202c42822ce80ec648223f3e0a,https://www.semanticscholar.org/paper/8978ddd91076bf202c42822ce80ec648223f3e0a,Neuroevolutionary Motivational Engine for Autonomous Robots,In this paper we present a motivational engine based on neuroevolution that permits a robot to autonomously obtain the appropriate value functions for its interaction with an environment. This motivational engine permits the combination of exploratory and exploitative drives through a certainty based approach. It allows for the exploration of the state space in order to determine where rewards can be obtained and provides an evolutionary based mechanism for constructing the corresponding value functions. An example considering a real robot in a real environment that implies the construction of several value functions is analyzed.,GECCO,2016
93c49fbc932dba6257df768be58782d896a99136,https://www.semanticscholar.org/paper/93c49fbc932dba6257df768be58782d896a99136,Decision based Cognitive Learning using Strategic Game Theory,"Objective: To modernize a system that can bring its own decision independently. Methodology: In this paper, we are projecting a novel model of the cognitive learning process using similar to the human learning technique. Findings: We have proved here that the relationship between two individuals may change their judgment in the same surroundings. Many researchers and scientists are working together over than six decades to develop an intelligence system as a human. Decision making is not so elementary. Each and every decision depends upon prior knowledge and decisions. With a slight change in nature may change the decision from pros to cons, from good to bad. In such a dynamic environment, we need to develop some dynamic system that can change the decision accordingly to the environment. Game theory plays an important role to handle such dynamic decision making in this world. We make decisions and learn through the observations and experience and then store the observed or concluded results into our knowledge base. Learning makes us more powerful to produce a sound determination. Rule based systems define the relationship between a person to another, then that decision does efficiently and consequently to the kinship. Application: This paper introduces a new version of thinking capability of machine in dynamic nature using game theory. We trust that this paper will require a revolution in sound system design and clay sculpture.",,2016
a4a2f9e56b7b6d21f97f23782e3cb976296ad803,https://www.semanticscholar.org/paper/a4a2f9e56b7b6d21f97f23782e3cb976296ad803,A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications,"In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 84 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.",,2016
a909055620dff103a732c3c100a355580891cada,https://www.semanticscholar.org/paper/a909055620dff103a732c3c100a355580891cada,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",IEEE Transactions on Cognitive and Developmental Systems,2016
dcbbe1d306b7ef25c2e9c5a5ba1599d79d03909c,https://www.semanticscholar.org/paper/dcbbe1d306b7ef25c2e9c5a5ba1599d79d03909c,Motivational engine with autonomous sub-goal identification for the Multilevel Darwinist Brain,"Abstract This work proposes a motivational system for an autonomous robot that guides the fulfillment of its goals in a developmental manner, discovering sub-goals not only as a way to simplify goal achievement, but as a way to acquire knowledge in an incremental, modular and reusable fashion. This system has been called MotivEn (Motivational Engine) and we have carried out its initial integration within the Multilevel Darwinist Brain (MDB) cognitive architecture. We describe here the main elements of MotivEn and how they improve the current MDB operation. Moreover, we present in detail a specific implementation of MotivEn and the application results obtained in terms of sub-goal identification when applying it in a real robot experiment with the MDB.",BICA 2016,2016
ec6c8b7175073e60d532a9d8e643a4de283bd03d,https://www.semanticscholar.org/paper/ec6c8b7175073e60d532a9d8e643a4de283bd03d,Motivational Engine with Sub-goal Identification in Neuroevolution Based Cognitive Robotics,"A first approach towards a new motivational system for an autonomous robot that can learn chains of sub-goals leading to a final reward is proposed in this paper. The motivational system provides the motivation that guides the robot operation according to its knowledge of its sensorial space so that rewards are maximized during its lifetime. In order to do this, a motivational engine progressively and interactively creates an internal model of expected future reward (value function) for areas of the robot’s state space, through a neuroevolutionary process, over samples obtained in the sensorial (state space) traces followed by the robot whenever it obtained a reward. To improve this modelling process, a strategy is proposed to decompose the global value function leading to the reward or goal into several more local ones, thus discovering sub-goals that simplify the whole learning process and that can be reused in the future. The motivational engine is tested in a simulated experiment with very promising results.",HAIS,2016
f46102759c5a9adeb36b1656d8b675237b14bb47,https://www.semanticscholar.org/paper/f46102759c5a9adeb36b1656d8b675237b14bb47,Improving extrinsically motivated developmental robots through intrinsic motivations,"This paper presents the initial results obtained in the application of the MotivEn motivational system in developmental robotics. The key feature of MotivEn is that it uses extrinsic motivations as the primary drive to guide the robot development, including intrinsic motivations to improve learning. We analyze here, through an experiment with a simulated robot, that both types of motivations are required.",2016 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),2016
102f3f5f75401b1a70a6d3af4cf6f5df11ecb925,https://www.semanticscholar.org/paper/102f3f5f75401b1a70a6d3af4cf6f5df11ecb925,Introducing Synaptic Delays in the NEAT Algorithm to Improve Modelling in Cognitive Robotics,"This paper describes and tests an approach to improve the temporal processing capabilities of the neuroevolution of augmenting topologies (NEAT) algorithm. This algorithm is quite popular within the robotics community for the production of trained neural networks without having to determine a priori their size and topology. The main drawback of the traditional NEAT algorithm is that, even though it can implement recurrent synaptic connections, which allow it to perform some time related processing tasks, its capabilities are rather limited, especially when dealing with precise time dependent phenomena. NEAT’s ability to capture the underlying dynamics that correspond to complex time series still has a lot of room for improvement. To address this issue, the paper describes a new implementation of the NEAT algorithm that is able to generate artificial neural networks (ANNs) with trainable time delayed synapses in addition to its previous capacities. We show that this approach, called tao-NEAT improves the behavior of the neural networks obtained when dealing with complex time related processes. Several examples are presented, both dealing with the generation of ANNs that are able to produce complex theoretical signals such as chaotic signals or real data series, as in the case of the monthly number of international airline passengers or monthly $$\hbox {CO}_{2}$$CO2 concentrations. In these examples, t-NEAT clearly improves over the traditional NEAT algorithm in these tasks. A final example of the integration of this approach within a robot cognitive mechanism is also presented, showing the clear improvements it could provide in the modeling required for many cognitive processes.",Neural Processing Letters,2016
3cd2bc9cd10a705a8b319ebe477f54f8fd396709,https://www.semanticscholar.org/paper/3cd2bc9cd10a705a8b319ebe477f54f8fd396709,Autonomous Learning of Procedural Knowledge in an Evolutionary Cognitive Architecture for Robots,This paper describes a procedure to provide a way for the Multilevel Darwinist Brain evolutionary cognitive architecture to be able to learn and preserve procedural knowledge while operating on-line. This procedural knowledge is acquired in the form of ANNs that implement behaviors in the sense of traditional evolutionary robotics. The behaviors are produced in real time as the robot is interacting with the world. It is interesting to see in the results presented that this approach of learning procedural representations instead of exhaustively selecting the appropriate action every instant of time provides better generalization results and more efficient action sequences.,EvoApplications,2015
5b271b282727266006455d67e47bfd6101afaf01,https://www.semanticscholar.org/paper/5b271b282727266006455d67e47bfd6101afaf01,Anytime Bounded Rationality,"Dependable cyber-physical systems strive to deliver anticipative, multi-objective performance anytime, facing deluges of inputs with varying and limited resources. This is even more challenging for life-long learning rational agents as they also have to contend with the varying and growing know-how accumulated from experience. These issues are of crucial practical value, yet have been only marginally and unsatisfactorily addressed in AGI research. We present a value-driven computational model of anytime bounded rationality robust to variations of both resources and knowledge. It leverages continually learned knowledge to anticipate, revise and maintain concurrent courses of action spanning over arbitrary time scales for execution anytime necessary.",AGI,2015
d5d7f7fd931cd97e69317be55be8933bf7599b2f,https://www.semanticscholar.org/paper/d5d7f7fd931cd97e69317be55be8933bf7599b2f,Studying the Coupled Learning of Procedural and Declarative Knowledge in Cognitive Robotics,"Procedural and Declarative knowledge play a key role in cognitive architectures for robots. These types of architectures use the human brain as inspiration to design control structures that allow robots to be fully autonomous, in the sense that their development depends only on their own experience in the environment. The two main components that make up cognitive architectures are models prediction and action-selection structures decision. Models represent the declarative knowledge the robot acquires during its lifetime. On the other hand, action-selection structures represent the procedural knowledge, and its autonomous acquisition depends on the quality of the models that are being learned concurrently. The coupled learning of models and action-selection structures is a key aspect in robot development, and it has been rarely studied in the field. This work aims to start filling this gap by analyzing how these concurrent learning processes affect each other using an evolutionary-based cognitive architecture, the Multilevel Darwinist Brain, in a simulated robotic experiment",Living Machines,2015
df03b3fbfbba48e0f6ab6d0ed546eed68aab23de,https://www.semanticscholar.org/paper/df03b3fbfbba48e0f6ab6d0ed546eed68aab23de,Una aproximación evolutiva a la planificación en entornos HPC basada en la incorporación de criterios subjetivos,"En el contexto de un centro de supercomputacion, por muy elevados que sean los recursos, la demanda sera siempre superior. Por ello, los usuarios deben realizar solicitudes para la ejecucion de sus trabajos, que se ponen en espera hasta que el planificador del sistema decide pasarlos a ejecucion. Pero, por desconocimiento o temor a que los trabajos sean abortados, estas solicitudes son normalmente muy imprecisas, dificultando la labor del planificador. Ademas, los planificadores son dificiles de configurar y en todo momento asumen que una planificacion dada va a satisfacer de igual manera a todos los usuarios. En este trabajo se propone un sistema de planificacion que utiliza tecnicas de computacion evolutiva para permitir la definicion de politicas de planificacion de manera mas natural y estimar las necesidades reales de recursos para lograr planificaciones mas precisas. Adicionalmente, se considera el concepto de calidad de servicio percibida, posibilitando la incorporacion de criterios subjetivos en el proceso de planificacion para mantener un alto nivel de satisfaccion en el conjunto de usuarios y en el propio centro de supercomputacion. Finalmente, se modelan diversos aspectos de los propios recursos computacionales mejorando aun mas la precision en la planificacion, especialmente en sistemas heterogeneos.",,2015
ebc16c44551501763e620bb54e23377e18bf184a,https://www.semanticscholar.org/paper/ebc16c44551501763e620bb54e23377e18bf184a,"Evolutionary Robotics: What, Why, and Where to","Evolutionary robotics applies the selection, variation, and heredity principles of natural evolution to the design of robots with embodied intelligence. It can be considered as a subfield of robotics that aims to create more robust and adaptive robots. A pivotal feature of the evolutionary approach is that it considers the whole robot at once, and enables the exploitation of robot features in a holistic manner. Evolutionary robotics can also be seen as an innovative approach to the study of evolution based on a new kind of experimentalism. The use of robots as a substrate can help address questions that are difficult, if not impossible, to investigate through computer simulations or biological studies. In this paper we consider the main achievements of evolutionary robotics, focusing particularly on its contributions to both engineering and biology. We briefly elaborate on methodological issues, review some of the most interesting findings, and discuss important open issues and promising avenues for future work.",Front. Robot. AI,2015
16b046568ca0ac15f58762467780b3940458c745,https://www.semanticscholar.org/paper/16b046568ca0ac15f58762467780b3940458c745,Cognitive-mapping and contextual pyramid based Digital Elevation Model Registration and its effective storage using fractal based compression,"Image Registration implies mapping images having varying orientation, multi-modal or multi-temporal images to map to one coordinate system. Digital Elevation models (DEM) are images having terrain information embedded into them. DEM-to-DEM registration incorporate registration of DEMs having different orientation, may have been mapped at different times, or may have been processed using different resolutions. Though very important only a handful of methods for DEM registration exist, most of which are for DEM-to-topographical map or DEM-toRemote Sensed Image registration. Using cognitive mapping concepts for DEM registration, has evolved from this basic idea of using the mapping between the space to objects and defining their relationships to form the basic landmarks that need to be marked, stored and manipulated in and about the environment or other candidate environments, namely, in our case, the DEMs. The progressive two-level encapsulation of methods of geo-spatial cognition includes landmark knowledge and layout knowledge and can be useful for DEM registration. Space-based approach, that emphasizes on explicit extent of the environment under consideration, and object-based approach, that emphasizes on the relationships between objects in the local environment being the two paradigms of cognitive mapping can be methodically integrated in this three-architecture for DEM registration. Initially, P-model based segmentation is performed followed by landmark formation for contextual mapping that uses contextual pyramid formation. Apart from landmarks being used for registration key-point finding, Euclidean distance based deformation calculation has been used for transformation and change detection. Initially, P-model based segmentation is performed followed by landmark formation for contextual mapping that uses contextual pyramid formation. Landmarks have been categorized to belong to either being flat-plain areas without much variation in the land heights; peaks that can be found when there is gradual increase in height as compared to the flat areas; valleys, marked with gradual decrease in the height seen in DEM; and finally, ripple areas with very shallow crests and nadirs. For the final storage of coregistered DEMs, fractal based compression has been found to give good results in terms of space and computation requirements. In this paper, an attempt has been made to implement DEMDEM registration based on human spatial cognition method of recollection. This method may further be extended for DEM-totopographic map and DEM-to-remote sensed image registration. Experimental results further cement the fact that DEM registration may be effectively done using the proposed method.",ArXiv,2014
64f2e480e010368b1618bd31996397fd2287a404,https://www.semanticscholar.org/paper/64f2e480e010368b1618bd31996397fd2287a404,"NeuCube: A spiking neural network architecture for mapping, learning and understanding of spatio-temporal brain data","The brain functions as a spatio-temporal information processing machine. Spatio- and spectro-temporal brain data (STBD) are the most commonly collected data for measuring brain response to external stimuli. An enormous amount of such data has been already collected, including brain structural and functional data under different conditions, molecular and genetic data, in an attempt to make a progress in medicine, health, cognitive science, engineering, education, neuro-economics, Brain-Computer Interfaces (BCI), and games. Yet, there is no unifying computational framework to deal with all these types of data in order to better understand this data and the processes that generated it. Standard machine learning techniques only partially succeeded and they were not designed in the first instance to deal with such complex data. Therefore, there is a need for a new paradigm to deal with STBD. This paper reviews some methods of spiking neural networks (SNN) and argues that SNN are suitable for the creation of a unifying computational framework for learning and understanding of various STBD, such as EEG, fMRI, genetic, DTI, MEG, and NIRS, in their integration and interaction. One of the reasons is that SNN use the same computational principle that generates STBD, namely spiking information processing. This paper introduces a new SNN architecture, called NeuCube, for the creation of concrete models to map, learn and understand STBD. A NeuCube model is based on a 3D evolving SNN that is an approximate map of structural and functional areas of interest of the brain related to the modeling STBD. Gene information is included optionally in the form of gene regulatory networks (GRN) if this is relevant to the problem and the data. A NeuCube model learns from STBD and creates connections between clusters of neurons that manifest chains (trajectories) of neuronal activity. Once learning is applied, a NeuCube model can reproduce these trajectories, even if only part of the input STBD or the stimuli data is presented, thus acting as an associative memory. The NeuCube framework can be used not only to discover functional pathways from data, but also as a predictive system of brain activities, to predict and possibly, prevent certain events. Analysis of the internal structure of a model after training can reveal important spatio-temporal relationships 'hidden' in the data. NeuCube will allow the integration in one model of various brain data, information and knowledge, related to a single subject (personalized modeling) or to a population of subjects. The use of NeuCube for classification of STBD is illustrated in a case study problem of EEG data. NeuCube models result in a better accuracy of STBD classification than standard machine learning techniques. They are robust to noise (so typical in brain data) and facilitate a better interpretation of the results and understanding of the STBD and the brain conditions under which data was collected. Future directions for the use of SNN for STBD are discussed.",Neural Networks,2014
6f930c33cfe8253b623f8fd5a0376c6e09790abf,https://www.semanticscholar.org/paper/6f930c33cfe8253b623f8fd5a0376c6e09790abf,A brief overview of evolutionary developmental robotics,"Purpose – This article aims to provide a brief overview of the field now known as “evolutionary developmental robotics (evo-devo-robo)”, which is based on the concept and principles of evolutionary and development principles such as evolutionary developmental psychology, evolutionary developmental biology (evo-devo) and evolutionary cognitive neuroscience. Design/methodology/approach – Evo-devo-robo is a new field bringing together developmental robotics and evolutionary robotics to form a new research area. Basic concepts and the origins of the field are described, and then some basic principles of evo-devo-robo that have been developed so far are discussed. Findings – Finally, some misunderstand concepts and the most promising future research developments in this area are discussed. Originality/value – Basic concepts and the origins of the field are described, and then some basic principles of evo-devo-robo that have been developed so far are discussed. Finally, some misunderstood concepts and the most ...",Ind. Robot,2014
76ed20bdc61c68b2e0b5642142d953d598edcd8d,https://www.semanticscholar.org/paper/76ed20bdc61c68b2e0b5642142d953d598edcd8d,A Role for Sleep in Artificial Cognition through Deferred Restructuring of Experience in Autonomous Machines,"This paper is concerned with the exploration of the benefits that can be derived within a cognitive architecture for robots through the application of nature inspired sleep related cognitive restructuring processes. To this end, the concept of Deferred Restructuring of Experience in Autonomous Machines (DREAM) is postulated and applied in the context of the Multilevel Darwinist Brain architecture. This concept implies a series of consolidation, enhancement and internal imaging based exploration processes that can be applied over the experience, in terms of models and behavioral structures, a robot has acquired in its interaction with the world during its lifetime. The result is a re-representation of all of this experience so that the robot becomes more efficient and adaptive in its subsequent interactions with the world. A couple of simple proof of concept experiments demonstrate the capabilities of the approach.",SAB,2014
787119f913cfafff4285299e08ad486d8035f5b2,https://www.semanticscholar.org/paper/787119f913cfafff4285299e08ad486d8035f5b2,Brain-Like Robotics,"This chapter aims to provide an overview of what is happening in the field of brain like robotics, what the main issues are and how they are being addressed by different authors. It starts by introducing several concepts and theories on the evolution and operation of the brain and provides a basic biological and operational framework as background to contextualize the topic. Building on these foundations, the main body of the chapter is devoted to the different contributions within the robotics community that use brain-like models as a source of inspiration for controlling real robots. These contributions are addressed from two perspectives. On one hand the main cognitive architectures developed under a more or less strict brain-like point of view are presented, offering a brief description of each architecture as well as highlighting some of their main contributions. Then the point of view is changed and a more extensive review is provided of what is being done within three areas that we consider key for the future development of autonomous brain-like robotic creatures that can live and work in human environments interacting with other robots and human beings. These are: Memory, Attention and Emotions. This review is followed by a description of some of the current projects that are being carried out or have recently finished within this field as well as of some robotic platforms that are currently being used. The chapter is heavily referenced in the hope that this extensive compilation of papers and books from the different areas that are relevant within the field are useful for the reader to really appreciate its breadth and beauty.",,2014
899f23ef8c427af1643daa2c4efe8914b10e59a8,https://www.semanticscholar.org/paper/899f23ef8c427af1643daa2c4efe8914b10e59a8,Brain-like Information Processing for Spatio-Temporal Pattern Recognition,"Information processes in the brain, such as gene and protein expression, learning, memory, perception, cognition, consciousness are all spatio- and/or spectro temporal. Modelling such processes would require sophisticated information science methods and the best ones could be the brain-inspired ones, that use the same brain information processing principles. Spatio and spectro-temporal data (SSTD) are also the most common types of data collected in many domain areas, including engineering, bioinformatics, neuroinformatics, ecology, environment, medicine, economics, etc. However, there is lack of methods for the efficient analysis of such data and for spatio-temporal pattern recognition (STPR). The brain functions as a spatio-temporal information processing machine and deals extremely well with spatio-temporal data. Its organization and functions have been the inspiration for the development of new methods for SSTD analysis and STPR. Brain-inspired spiking neural networks (SNN) are considered the third generation of neural networks and are a promising paradigm for the creation of new intelligent ICT for SSTD. This new generation of computational models and systems is potentially capable of modeling complex information processes due to the ability to represent and integrate different information dimensions, such as time, space, frequency, and phase, and to deal with large volumes of data in an adaptive and self-organizing manner. This chapter reviews methods and systems of SNN for SSTD analysis and STPR, including single neuronal models, evolving spiking neural networks (eSNN), and computational neurogenetic models (CNGM). Software and hardware implementations and some pilot applications for audio-visual pattern recognition, EEG data-analysis, cognitive robotic systems, BCI, neurodegenerative diseases, and others are discussed.",,2014
8e6d596030e3b9e90b6e4ad590c265e473656726,https://www.semanticscholar.org/paper/8e6d596030e3b9e90b6e4ad590c265e473656726,Brain-Like Ro 57. Brain-Like Robotics,,,2014
a3b96938580fba52ee37b61968615a86b2e56950,https://www.semanticscholar.org/paper/a3b96938580fba52ee37b61968615a86b2e56950,An evolutionary cognitive architecture made of a bag of networks,"A cognitive architecture is presented for modelling some properties of sensorimotor learning in infants, namely the ability to accumulate adaptations and skills over multiple tasks in a manner which allows recombination and re-use of task specific competences. The control architecture invented consists of a population of compartments (units of neuroevolution) each containing networks capable of controlling a robot with many degrees of freedom. The nodes of the network undergo internal mutations, and the networks undergo stochastic structural modifications, constrained by a mutational and recombinational grammar. The nodes used consist of dynamical systems such as dynamic movement primitives, continuous time recurrent neural networks and high-level supervised and unsupervised learning algorithms. Edges in the network represent the passing of information from a sending node to a receiving node. The networks in a compartment operate in parallel and encode a space of possible subsumption-like architectures that are used to successfully evolve a variety of behaviours for a NAO H25 humanoid robot.",Evol. Intell.,2014
bd5b547f6845b095f192d392634b331300a99a28,https://www.semanticscholar.org/paper/bd5b547f6845b095f192d392634b331300a99a28,Dynamic learning in cognitive robotics through a procedural long term memory,"Brain-like robotic approaches aim to reproduce the complex processes occurring within the biological brains to achieve a higher level of autonomy. One of the key aspects of these approaches is dynamic learning, that is, how to provide the cognitive architectures that control de robot with adaptive learning capabilities. Several options have been considered in this line in the field of Cognitive Robotics, although the development of a proper memory system has provided the best practical results up to now. This work also follows this approach, seeking to show the advantages of using a Long-Term Memory (LTM) for optimizing the adaptive learning capabilities of a cognitive robot in dynamic environments. Specifically, a procedural LTM that stores basic models and behaviours is included in the evolutionary-based Multilevel Darwinist Brain (MDB) cognitive architecture. The LTM management system that has been developed to control when a model must be stored or replaced is presented here in detail. Moreover, a Short-Term Memory (STM) sub-system included in the MDB is also explained due to its strong relationship with the operation of the LTM. The LTM elements are tested in theoretical functions and in a simulated example using the AIBO robot in a dynamic context with successful adaptive learning results.",Evol. Syst.,2014
e80623141758d12fcb71318ed96051a5d591884f,https://www.semanticscholar.org/paper/e80623141758d12fcb71318ed96051a5d591884f,Augmenting the NEAT algorithm to improve its temporal processing capabilities,"This paper is concerned with the incorporation of new time processing capacities to the Neuroevolution of Augmenting Topologies (NEAT) algorithm. This algorithm is quite popular within the robotics community for the production of trained neural networks without having to determine a priori their size and topology. However, and even though the algorithm can address temporal processing issues through its capacity of establishing feedback synaptic connections, that is, through recurrences, there are still instances where more precise time processing may go beyond its limits. In order to address these cases, in this paper we describe a new implementation of the NEAT algorithm where trainable synaptic time delays are incorporated into its toolbox. This approach is shown to improve the behavior of neural networks obtained using NEAT in many instances. Here, we provide some of these results using a series of typical complex time processing tasks related to chaotic time series modeling and consider an example of the integration of this new approach within a robotic cognitive architecture.",2014 International Joint Conference on Neural Networks (IJCNN),2014
337878293b38b0db01f32a444b4dc072f0c6fbb8,https://www.semanticscholar.org/paper/337878293b38b0db01f32a444b4dc072f0c6fbb8,Dynamic evolving spiking neural networks for on-line spatio- and spectro-temporal pattern recognition.,"On-line learning and recognition of spatio- and spectro-temporal data (SSTD) is a very challenging task and an important one for the future development of autonomous machine learning systems with broad applications. Models based on spiking neural networks (SNN) have already proved their potential in capturing spatial and temporal data. One class of them, the evolving SNN (eSNN), uses a one-pass rank-order learning mechanism and a strategy to evolve a new spiking neuron and new connections to learn new patterns from incoming data. So far these networks have been mainly used for fast image and speech frame-based recognition. Alternative spike-time learning methods, such as Spike-Timing Dependent Plasticity (STDP) and its variant Spike Driven Synaptic Plasticity (SDSP), can also be used to learn spatio-temporal representations, but they usually require many iterations in an unsupervised or semi-supervised mode of learning. This paper introduces a new class of eSNN, dynamic eSNN, that utilise both rank-order learning and dynamic synapses to learn SSTD in a fast, on-line mode. The paper also introduces a new model called deSNN, that utilises order learning and SDSP spike-time learning in unsupervised, supervised, or semi-supervised modes. The SDSP learning is used to evolve dynamically the network changing connection weights that capture spatio-temporal spike data clusters both during training and during recall. The new deSNN model is first illustrated on simple examples and then applied on two case study applications: (1) moving object recognition using address-event representation (AER) with data collected using a silicon retina device; (2) EEG SSTD recognition for brain-computer interfaces. The deSNN models resulted in a superior performance in terms of accuracy and speed when compared with other SNN models that use either rank-order or STDP learning. The reason is that the deSNN makes use of both the information contained in the order of the first input spikes (which information is explicitly present in input data streams and would be crucial to consider in some tasks) and of the information contained in the timing of the following spikes that is learned by the dynamic synapses as a whole spatio-temporal pattern.",Neural networks : the official journal of the International Neural Network Society,2013
4da9703b7b467031d635f0f8f08364e97a71eb2f,https://www.semanticscholar.org/paper/4da9703b7b467031d635f0f8f08364e97a71eb2f,Design for a Darwinian Brain: Part 2. Cognitive Architecture,"The accumulation of adaptations in an open-ended manner during lifetime learning is a holy grail in reinforcement learning, intrinsic motivation, artificial curiosity, and developmental robotics. We present a design for a cognitive architecture that is capable of specifying an unlimited range of behaviors. We then give examples of how it can stochastically explore an interesting space of adjacent possible behaviors. There are two main novelties; the first is a proper definition of the fitness of self-generated games such that interesting games are expected to evolve. The second is a modular and evolvable behavior language that has systematicity, productivity, and compositionality, i.e. it is a physical symbol system. A part of the architecture has already been implemented on a humanoid robot.",Living Machines,2013
cc835394ac6c47263c57aa815f1c5b9ea9cd0261,https://www.semanticscholar.org/paper/cc835394ac6c47263c57aa815f1c5b9ea9cd0261,Natural and Artificial Computation in Engineering and Medical Applications,"The Vehicle Routing Problem with Time Windows relates to frequently occuring real world problems in logistics. Much work has been done on solving static routing problems but solving the dynamic variants has not been given an equal amount of attention, while these are even more relevant to most companies in logistics and transportation. In this work an Ant Colony Optimization algorithm for solving the Dynamic Vehicle Routing Problem with Time Windows is proposed. Customers and time windows are inserted during the working day and need to be integrated in partially committed solutions. Results are presented on a benchmark that generalizes Solomon’s classical benchmark with varying degrees of dynamicity and different variants, including pheromone preservation and the min-max ant system.",Lecture Notes in Computer Science,2013
ee8a4eaad5cb9f0227a7f6bf54a9b51b806d4a22,https://www.semanticscholar.org/paper/ee8a4eaad5cb9f0227a7f6bf54a9b51b806d4a22,Multiscale Dynamic Learning in Cognitive Robotics,"This paper is concerned with the dynamics of Cognitive Developmental Robotic architectures and how to produce structures that allow these types of architectures to deal with the different time scales a robot must cope with. The most important types of dynamics that occur in different time scales are defined and different mechanisms within a particular cognitive architecture, the Multilevel Darwinist Brain, are suggested to model each one of them. The paper also proposes a novel neuroevolutionary technique, called τ-NEAT, in order to capture processes based on precise temporal cues. This technique is analyzed when addressing dynamic environments in a real robotic test.",IWINAC,2013
0a89bfe9a3135167c3ea8d78a413617f6cb4a05f,https://www.semanticscholar.org/paper/0a89bfe9a3135167c3ea8d78a413617f6cb4a05f,Advances in Computational Intelligence,"In the not so distant future, we expect analytic models to become a commodity. We envision having access to a large number of data-driven models, obtained by a combination of crowdsourcing, crowdservicing, cloud-based evolutionary algorithms, outsourcing, in-house development, and legacy models. In this new context, the critical question will be model ensemble selection and fusion, rather than model generation. We address this issue by proposing customized model ensembles on demand, inspired by Lazy Learning. In our approach, referred to as Lazy Meta-Learning, for a given query we find the most relevant models from a DB of models, using their meta-information. After retrieving the relevant models, we select a subset of models with highly uncorrelated errors. With these models we create an ensemble and use their meta-information for dynamic bias compensation and relevance weighting. The output is a weighted interpolation or extrapolation of the outputs of the models ensemble. Furthermore, the confidence interval around the output is reduced as we increase the number of uncorrelated models in the ensemble. We have successfully tested this approach in a power plant management application.",Lecture Notes in Computer Science,2012
4c84650d11245f40b9ccb6e43c2e7c63cc9b6c3f,https://www.semanticscholar.org/paper/4c84650d11245f40b9ccb6e43c2e7c63cc9b6c3f,Evolving Spiking Neural Networks and Neurogenetic Systems for Spatio- and Spectro-Temporal Data Modelling and Pattern Recognition,"Spatio- and spectro-temporal data (SSTD) are the most common types of data collected in many domain areas, including engineering, bioinformatics, neuroinformatics, ecology, environment, medicine, economics, etc. However, there is lack of methods for the efficient analysis of such data and for spatio-temporal pattern recognition (STPR). The brain functions as a spatio-temporal information processing machine and deals extremely well with spatio-temporal data. Its organisation and functions have been the inspiration for the development of new methods for SSTD analysis and STPR. The brain-inspired spiking neural networks (SNN) are considered the third generation of neural networks and are a promising paradigm for the creation of new intelligent ICT for SSTD. This new generation of computational models and systems are potentially capable of modelling complex information processes due to their ability to represent and integrate different information dimensions, such as time, space, frequency, and phase, and to deal with large volumes of data in an adaptive and self-organising manner. The paper reviews methods and systems of SNN for SSTD analysis and STPR, including single neuronal models, evolving spiking neural networks (eSNN) and computational neuro-genetic models (CNGM). Software and hardware implementations and some pilot applications for audio-visual pattern recognition, EEG data analysis, cognitive robotic systems, BCI, neurodegenerative diseases, and others are discussed.",WCCI,2012
54ec0126ebb8951564ccaf22fe8681d329a8227c,https://www.semanticscholar.org/paper/54ec0126ebb8951564ccaf22fe8681d329a8227c,Evolving spiking neural networks for spatio-and spectro-temporal pattern recognition,"This paper provides a survey on the evolution of the evolving connectionist systems (ECOS) paradigm, from simple ECOS introduced in 1998 to evolving spiking neural networks (eSNN) and neurogenetic systems. It presents methods for their use for spatio-and spectro temporal pattern recognition. Future directions are highlighted.",2012 6th IEEE International Conference Intelligent Systems,2012
592a896a8ead457f876e1cdad7839f30369de13f,https://www.semanticscholar.org/paper/592a896a8ead457f876e1cdad7839f30369de13f,A procedural Long Term Memory for cognitive robotics,"This paper provides some insights into the advantages of using a Long-Term Memory (LTM) for optimizing the adaptive learning capabilities of a cognitive robot in dynamic environments. Specifically, a procedural LTM that stores basic models and behaviours is included in the evolutionary-based Multilevel Darwinist Brain (MDB) cognitive architecture. The memory system is based on learning error stability and instability to detect if a model is candidate to enter the LTM or to be recovered. A LTM replacement strategy has been developed that is based on context detection using functional comparison of the models' response. The LTM elements are tested in theoretical functions and in a simulated example using the AIBO robot in a dynamic context with successful adaptive learning results.",2012 IEEE Conference on Evolving and Adaptive Intelligent Systems,2012
c37fd95afd61609e14bd4e44ac211e2e8089c47f,https://www.semanticscholar.org/paper/c37fd95afd61609e14bd4e44ac211e2e8089c47f,NeuCube EvoSpike Architecture for Spatio-temporal Modelling and Pattern Recognition of Brain Signals,"The brain functions as a spatio-temporal information processing machine and deals extremely well with spatio-temporal data. Spatio- and spectro-temporal data (SSTD) are the most common data collected to measure brain signals and brain activities, along with the recently obtained gene and protein data. Yet, there are no computational models to integrate all these different types of data into a single model to help understand brain processes and for a better brain signal pattern recognition. The EU FP7 Marie Curie IIF EvoSpike project develops methods and tools for spatio and spectro temporal pattern recognition. This paper proposes a new evolving spiking model called NeuCube as part of the EvoSpike project, especially for modeling brain data. The NeuCube is 3D evolving Neurogenetic Brain Cube of spiking neurons that is an approximate map of structural and functional areas of interest of an animal or human brain. Optionally, gene information is included in the NeuCube in the form of gene regulatory networks that relate to spiking neuronal parameters of interest. Different types of brain SSTD can be used to train a NeuCube, including: EEG, fMRI, video-, image- and sound data, complex multimodal data. Potential applications are: EEG -, fMRI-, and multimodal brain data modeling and pattern recognition; Brain-Computer Interfaces; cognitive and emotional robots; neuro-prosthetics and neuro-rehabilitation; modeling brain diseases. Analysis of the internal structure of the model can trigger new hypotheses about spatio-temporal pathways in the brain.",ANNPR,2012
d0c737d406cc1993d22d0834534881e2cd08dd98,https://www.semanticscholar.org/paper/d0c737d406cc1993d22d0834534881e2cd08dd98,"Evolving , Probabilistic Spiking Neural Networks and Neurogenetic Systems for Spatio-and Spectro-Temporal Data Modelling and Pattern Recognition","Spatioand spectro-temporal data (SSTD) are the most common types of data collected in many domain areas, including engineering, bioinformatics, neuroinformatics, ecology, environment, medicine, economics, etc. However, there is lack of methods for the efficient analysis of such data and for spatiotemporal pattern recognition (STPR). The brain functions as a spatio-temporal information processing machine and deals extremely well with spatio-temporal data. Its organisation and functions have been the inspiration for the development of new methods for SSTD analysis and STPR. The brain-inspired spiking neural networks (SNN) are considered the third generation of neural networks and are a promising paradigm for the creation of new intelligent ICT for SSTD. This new generation of computational models and systems are potentially capable of modelling complex information processes due to their ability to represent and integrate different information dimensions, such as time, space, frequency, and phase, and to deal with large volumes of data in an adaptive and self-organising manner. The paper reviews methods and systems of SNN for SSTD analysis and STPR, including single neuronal models, evolving spiking neural networks (eSNN) and computational neuro-genetic models (CNGM). Software and hardware implementations and some pilot applications for audio-visual pattern recognition, EEG data analysis, cognitive robotic systems, BCI, neurodegenerative diseases, and others are discussed.",,2012
1df4a6e400124271feba0d28694974cea5cfa29c,https://www.semanticscholar.org/paper/1df4a6e400124271feba0d28694974cea5cfa29c,Evolving Probabilistic Spiking Neural Networks for Spatio-temporal Pattern Recognition: A Preliminary Study on Moving Object Recognition,"This paper proposes a novel architecture for continuous spatio-temporal data modeling and pattern recognition utilizing evolving probabilistic spiking neural network ‘reservoirs’ (epSNNr). The paper demonstrates on a simple experimental data for moving object recognition that: (1) The epSNNr approach is more accurate and flexible than using standard SNN; (2) The use of probabilistic neuronal models is superior in several aspects when compared with the traditional deterministic SNN models, including a better performance on noisy data.",ICONIP,2011
26a99c3ed5fc5856f2494c6ff69f2cf782a404c3,https://www.semanticscholar.org/paper/26a99c3ed5fc5856f2494c6ff69f2cf782a404c3,EEG Classification with BSA Spike Encoding Algorithm and Evolving Probabilistic Spiking Neural Network,"This study investigates the feasibility of Bens Spike Algorithm (BSA) to encode continuous EEG spatio-temporal data into input spike streams for a classification in a spiking neural network classifier. A novel evolving probabilistic spiking neural network reservoir (epSNNr) architecture is used for the purpose of learning and classifying the EEG signals after the BSA transformation. Experiments are conducted with EEG data measuring a cognitive state of a single individual under 4 different stimuli. A comparison is drawn between using traditional machine learning algorithms and using BSA plus epSNNr, when different probabilistic models of neurons are utilised. The comparison demonstrates that: (1) The BSA is a suitable transformation for EEG data into spike trains; (2) The performance of the epSNNr improves when a probabilistic model of a neuron is used, compared to the use of a deterministic LIF model of a neuron; (3) The classification accuracy of the EEG data in an epSNNr depends on the type of the probabilistic neuronal model used. The results suggest that an epSNNr can be optimised in terms of neuronal models used and parameters that would better match the noise and the dynamics of EEG data. Potential applications of the proposed method for BCI and medical studies are briefly discussed.",ICONIP,2011
6fdc3a95b3b10dab13c7c4166daf2d013691ca20,https://www.semanticscholar.org/paper/6fdc3a95b3b10dab13c7c4166daf2d013691ca20,A Multiple Context Brain for Experiments With Robot Consciousness,"The PURR-PUSS system (PP) is a versatile model of a human-like brain, designed to be implemented in parallel hardware and embodied in the head of a robot moving in the real world. The aim of the research with PP is to try out mechanisms for learning, intelligence and consciousness. Limitations of resources have dictated that the experiments with PP are made on a personal computer by simulating the brain and robot body in a microworld. The unique features of PP are multiple context and novelty-seeking. In this paper, a squash-pop microworld is described first, so that concrete examples can be given for a brief review of the PP system, followed by two new features called trail memory, to realize Baars' global workspace, and belief memory, to realize Rosenthal's higher order thoughts and Johnson-Laird's conscious reasoning. The extended system, PP*, is designed to give consciousness to the subconscious PP, but higher order thoughts and conscious reasoning prove to be elusive. A definition of a conscious robot provides a measure of progress.",IEEE Transactions on Autonomous Mental Development,2011
85180e4e393d6da898ce3979eaeed3abb2e2a138,https://www.semanticscholar.org/paper/85180e4e393d6da898ce3979eaeed3abb2e2a138,Adaptivity on the Robot Brain Architecture Level Using Reinforcement Learning,"The design and implementation of a robot brain often requires making decisions between different modules with similar functionality. Many implementations and components are easy to create or can be downloaded, but it is difficult to assess which combination of modules work well and which does not. This paper discusses a reinforcement learning mechanism where the robot is choosing between the different components using empirical feedback and optimization criteria. With the interval estimation algorithm the robot deselects poorly functioning modules and retains only the best ones. A discount factor ensures that the robot keeps adapting to new circumstances in the real world. This allows the robot to adapt itself continuously on the architecture level and also allows working with large development teams creating several different implementations with similar functionalities to give the robot biggest chance to solve a task. The architecture is tested in the RoboCup@Home setting and can handle failure situations.",RoboCup,2012
08af0a197132c60d3eab0ac0afd2c6c0ee0218d2,https://www.semanticscholar.org/paper/08af0a197132c60d3eab0ac0afd2c6c0ee0218d2,A Comprehensive Evaluation of Internet-of-Things Platforms,"Internet of things (IoT) has attracted researchers in recent years as it has a great potential to solve many emerging problems. An IoT platform is missioned to operate as a horizontal key element for serving various vertical IoT domains such as structure monitoring, smart agriculture, healthcare, miner safety monitoring, smart home, and healthcare. In this chapter, the authors propose a comprehensive analysis of IoT platforms to evaluate their capabilities. The selected metrics (features) to investigate the IoT platforms are “ability to serve different domains,” “ability to handle different data formats,” “ability to process unlimited size of data from various context,” “ability to convert unstructured data to structured data,” and “ability to produce complex reports.” These metrics are chosen by considering the reporting capabilities of various IoT platforms, big data concepts, and domain-related issues. The authors provide a detailed comparison derived from the metric analysis to show the advantages and drawbacks of IoT platforms.","Emerging Trends in IoT and Integration with Data Science, Cloud Computing, and Big Data Analytics",2022
97ca9902f2c832180b3c94b8b420932e55da89ab,https://www.semanticscholar.org/paper/97ca9902f2c832180b3c94b8b420932e55da89ab,IoT and Raspberry Pi application in the food industry: a systematic review,"The Industry 4.0 technologies are in ascension in the worldwide market, in Brazil still needs to be explored. It was made a Systematic Review to measure the application of IoT in the food industry. Some platforms were used to select works, applying the string “IoT AND Raspberry Pi AND Cheese”. It was possible to evidence the majority of IoT applications in the food industry, focus on the control of temperature, humidity, color, traceability of productive chain, and enlargement of sustainability in the food industry. The most difficulties faced in the conventional application of IoT are related to the high cost of proprietary arquitectures, qualified manpower and obstacles of data security implementation. There are alternatives that aim to reduce the costs of implementation, like the utilization of Raspberry Pi. The food industry presents potential application of technologies that aim for the quality of products, being an excellent opportunity.","Research, Society and Development",2022
f2028bdceffac01fd6e567c0dbb6fdcba185f8ab,https://www.semanticscholar.org/paper/f2028bdceffac01fd6e567c0dbb6fdcba185f8ab,Edge computing–Foundations and applications,,"AI, Edge and IoT-based Smart Agriculture",2022
fd9831a712a1b32aadfcb9eed65a3a23431f6549,https://www.semanticscholar.org/paper/fd9831a712a1b32aadfcb9eed65a3a23431f6549,A mesh network case study for digital audio signal processing in Smart Farm,,Internet of Things,2022
03c4a3cf167a043e43a41f93014a58b8f25e8306,https://www.semanticscholar.org/paper/03c4a3cf167a043e43a41f93014a58b8f25e8306,An IoT open source platform for photovoltaic plants supervision,,,2021
08c1cf776e592f1ae9afa099e674526142444f22,https://www.semanticscholar.org/paper/08c1cf776e592f1ae9afa099e674526142444f22,Blockchain technology for a sustainable agri-food supply chain,"PurposeThe present paper is aimed at 1) performing a systematic literature review (SLR) on applications in the perspective of sustainable agri-food supply chain (SC) of blockchain technology (BCT); 2) analyzing the selected literature, focusing on the advantages of the sustainable uses of the blockchain of the aforementioned SC and 3) presenting an outlook and research directions capable of addressing unresolved problems.Design/methodology/approachThe SLR was conducted using detailed criteria to identify academic articles. Moreover, specific keywords and databases were used. The time frame considered included the years 2010–2020.FindingsThe review analysis indicates that the use of BCT or BCT supported by ICT/IoT contributes to sustainability of agri-food production. However, this technology can lead to several challenges such as scalability, privacy leakage, high cost and connectivity problems.Research limitations/implicationsThe paper demonstrates that BCT can widely use agri-food supply chain due to its intrinsic characteristics. However, it is not excluded that the criteria chosen may not have identified important articles regarding BCT, the agri-food sector and sustainability.Originality/valueAlthough the body of academic literature published on this topic is expansive, the effect of BCT on the agri-food SC's sustainability aspects has not yet been adequately analyzed. Thus, the article is aimed at investigating how BCT is used in the SC. In particular, the article is intended to update information about BCT and its impact on sustainability.",,2021
10542bf911b137821192465188e8c5cea8367003,https://www.semanticscholar.org/paper/10542bf911b137821192465188e8c5cea8367003,Edge-Based Missing Data Imputation in Large-Scale Environments,"Smart cities leverage large amounts of data acquired in the urban environment in the context of decision support tools. These tools enable monitoring the environment to improve the quality of services offered to citizens. The increasing diffusion of personal Internet of things devices capable of sensing the physical environment allows for low-cost solutions to acquire a large amount of information within the urban environment. On the one hand, the use of mobile and intermittent sensors implies new scenarios of large-scale data analysis; on the other hand, it involves different challenges such as intermittent sensors and integrity of acquired data. To this effect, edge computing emerges as a methodology to distribute computation among different IoT devices to analyze data locally. We present here a new methodology for imputing environmental information during the acquisition step, due to missing or otherwise out of order sensors, by distributing the computation among a variety of fixed and mobile devices. Numerous experiments have been carried out on real data to confirm the validity of the proposed method.",Inf.,2021
13e35abae4e70dcbab11fbf87a63df996cb70feb,https://www.semanticscholar.org/paper/13e35abae4e70dcbab11fbf87a63df996cb70feb,Internet of Things for the Future of Smart Agriculture: A Comprehensive Survey of Emerging Technologies,"This paper presents a comprehensive review of emerging technologies for the internet of things (IoT)-based smart agriculture. We begin by summarizing the existing surveys and describing emergent technologies for the agricultural IoT, such as unmanned aerial vehicles, wireless technologies, open-source IoT platforms, software defined networking (SDN), network function virtualization (NFV) technologies, cloud/fog computing, and middleware platforms. We also provide a classification of IoT applications for smart agriculture into seven categories: including smart monitoring, smart water management, agrochemicals applications, disease management, smart harvesting, supply chain management, and smart agricultural practices. Moreover, we provide a taxonomy and a side-by-side comparison of the state-of-the-art methods toward supply chain management based on the blockchain technology for agricultural IoTs. Furthermore, we present real projects that use most of the aforementioned technologies, which demonstrate their great performance in the field of smart agriculture. Finally, we highlight open research challenges and discuss possible future research directions for agricultural IoTs.",IEEE/CAA Journal of Automatica Sinica,2021
1eae78872e03a93127696699662833bd342daec6,https://www.semanticscholar.org/paper/1eae78872e03a93127696699662833bd342daec6,Back to Nature With Fenceless Farms—Technology Opportunities to Reconnect People and Food,"The development and application of the fence was one of the earliest forms of agricultural technology in action. Managing the supply of animal protein required hunter gatherer communities to be able to domesticate and contain wild animals. Over the ages the fence has become ingrained in the very fabric of society and created a culture of control and ownership. Garett Hardin's article titled “The Tragedy of the Commons” suggested that shared land, typified by access to a fenceless common resource, was doomed to failure due to a human instinct for mistrust and exploitation. Perhaps the fence has created an ingrained societal cultural response. While natural ecosystems do have physical boundaries, these are based on natural environmental zones. Landscapes are more porous and resilience is built up through animal's being able to respond to dynamic changes. This paper explores the opportunity for remote monitoring technologies to create open fenceless landscapes and how this might be integrated into the growing need for humans to access animal protein.",Frontiers in Sustainable Food Systems,2021
2253d22c42ddf44a65074f98c9fd849978b55f00,https://www.semanticscholar.org/paper/2253d22c42ddf44a65074f98c9fd849978b55f00,"Internet of Things (IoT) and Sensors Technologies in Smart Agriculture: Applications, Opportunities, and Current Trends",,Building Climate Resilience in Agriculture,2021
2e651f48e5697b3802820c33e072a028b5d8db73,https://www.semanticscholar.org/paper/2e651f48e5697b3802820c33e072a028b5d8db73,Anomaly Detection of Operating Equipment in Livestock Farms Using Deep Learning Techniques,"In order to establish a smart farm, many kinds of equipment are built and operated inside and outside of a pig house. Thus, the environment for livestock (limited to pigs in this paper) in the barn is properly maintained for its growth conditions. However, due to poor environments such as closed pig houses, lack of stable power supply, inexperienced livestock management, and power outages, the failure of these environment equipment is high. Thus, there are difficulties in detecting its malfunctions during equipment operation. In this paper, based on deep learning, we provide a mechanism to quickly detect anomalies of multiple equipment (environmental sensors and controllers, etc.) in each pig house at the same time. In particular, environmental factors (temperature, humidity, CO2, ventilation, radiator temperature, external temperature, etc.) to be used for learning were extracted through the analysis of data accumulated for the generation of predictive models of each equipment. In addition, the optimal recurrent neural network (RNN) environment was derived by analyzing the characteristics of the learning RNN. In this way, the accuracy of the prediction model can be improved. In this paper, the real-time input data (only in the case of temperature) was intentionally induced above the threshold, and 93% of the abnormalities were detected to determine whether the equipment was abnormal.",Electronics,2021
42fababa415d7f33feca3e7074ba98d7e6b62022,https://www.semanticscholar.org/paper/42fababa415d7f33feca3e7074ba98d7e6b62022,A Review and State of Art of Internet of Things (IoT),"The Internet of Things (IoT) is basically like a system for connecting computer devices, mechanical and digital machines, objects, or individuals provided with the unique system (UIDs) and without transfer to transmit data over an ability human-to-human or computer-to-human relation. Another thing on the internet is that the items in the IoT are like a connected manner with humans and computers to which internet protocol addresses can be assigned and which can transfer data over the network or another man-made object. In this paper, we describe the utilization of IoT in the cloud, fog, IoT technologies with applications and security. Specifically, we provide IoT architecture for design and development with sensors in 6G. Finally, we discuss the current research, solutions, and present open issues of future research in IoT.",Archives of Computational Methods in Engineering,2021
4569fd73ae68a948e5b9c24a4e45b1022c4a68b5,https://www.semanticscholar.org/paper/4569fd73ae68a948e5b9c24a4e45b1022c4a68b5,Precision Livestock Farming Technologies: Novel Direction of Information Flow,"Precision livestock farming (PLF) is a digital management system that continuously measures the production, reproduction, health and welfare of animals and environmental impacts of the herd by using information and communication technologies (ICT) and controls all stages of the production process. In conventional livestock management, decisions are mostly based on the appraisal, judgment, and experience of the farmer, veterinarian, and workers. The increasing demand for production and the number of animals makes it difficult for humans to keep track of animals. It is clear that a person is not able to continuously watch the animals 24 hours a day to receive reliable audio-visual data for management. Recent technologies already changed the information flow from animal to human, which helps people to collect reliable information and transform it into an operational decision-making process (eg reproduction management or calving surveillance). Today, livestock farming must combine requirements for a transparent food supply chain, animal welfare, health, and ethics as a traceable-sustainable model by obtaining and processing reliable data using novel technologies. This review provides preliminary information on the advances in ICT for livestock management.",,2021
478f23ba883f448d7fef6157c89616f863a724dc,https://www.semanticscholar.org/paper/478f23ba883f448d7fef6157c89616f863a724dc,LoRaWAN: Application of Nonlinear Optimization to Base Stations Location,,"Communication, Smart Technologies and Innovation for Society",2021
543ac6f38a29670e032dac56632cb3c0e0b99d73,https://www.semanticscholar.org/paper/543ac6f38a29670e032dac56632cb3c0e0b99d73,A Survey on IoT Applications in Smart Cities,"The term Internet of Things was coined a decade ago, but every day a slight part of its burgeoning ecosystem becomes an element in our lives. Industrial devices, consumer products, utility items, automobiles, sensors, and different everyday components are being combined with web connectivity and powerful information analytic capabilities that promise to remodel the lifestyle of people. The connectivity of humans, objects, and machines with the Internet is increasing, which results in the emergence of smart cities that bridge the physical and virtual world. IoT applications in smart cities such as energy management, agriculture, industrialization, transport, environment, safety, utilities, health, communities, commerce, tourism, and entertainment bring immense value into our everyday lives. This chapter is the study of various IoT applications in smart cities based on the literature survey method. The rapid growth of IoT has opened up vast new opportunities for users to look beyond their conventional industrial horizons.",Immersive Technology in Smart Cities,2021
57fa207a774e9db432a581d95969dc9c259bd591,https://www.semanticscholar.org/paper/57fa207a774e9db432a581d95969dc9c259bd591,Hybrid precoder designs for decentralized parameter estimation in millimeter wave (mmWave) sensor networks with perfect and imperfect CSI,"Abstract This work conceives techniques for the design of linear hybrid precoders toward decentralized parameter estimation in a millimeter wave (mmWave) wireless sensor network (WSN). To achieve this objective, a novel system model is proposed for mmWave WSNs, wherein the sensors pre-process their observations using hybrid baseband and radio frequency (RF) precoders, prior to their transmission over a coherent multiple access channel (MAC) to the fusion center (FC). The pertinent combiner is constrained to satisfy the constant signal gain condition, thus ensuring a distortionless estimate at the FC without requiring any additional post-processing. The precoders are designed to achieve the minimum mean square error (MSE) of parameter estimation at the FC. Furthermore, robust precoder designs are also developed to mitigate the effects of imperfect channel state information (CSI) in a mmWave sensor network, which is inevitable due to practical effects such as limited pilot overhead, channel drift, quantization error, among others. Robust designs are presented considering both the probabilistic as well as bounded CSI uncertainty models, which makes the design framework comprehensive since it considers both average and worst case distortion minimization. The centralized MMSE lower bound is also derived to characterize the estimation performance of the proposed schemes. Simulation results are presented to demonstrate the performance of the proposed designs and also verify the analytical propositions.",Phys. Commun.,2021
5cad7c7671850bb389a0eb1b54b865929ef287ea,https://www.semanticscholar.org/paper/5cad7c7671850bb389a0eb1b54b865929ef287ea,"Smart Dairy Farming Overview: Innovation, Algorithms and Challenges",,Transactions on Computer Systems and Networks,2021
5cfea46946d44607953d648c92120e20178d5fd9,https://www.semanticscholar.org/paper/5cfea46946d44607953d648c92120e20178d5fd9,A Systematic Literature Review of Blockchain Technology for Smart Villages,"Graphic Abstract According to the United Nations, Sustainable Development Goals are framed for improving rural health, hunger, poverty issues, environmental conditions, and illiteracy globally. With the upcoming technology, there have been many advances in the lifestyle of people all around the world. Comparatively, more emphasis has been given to the development of urban areas than rural. The sustainable development of a country depends on the growth of its rural areas. Countless technological and theoretical models, projects, and frameworks have been proposed and implemented to help overcome sundry issues and challenges faced by rural people in quotidian life. New technological methods are deemed to be the future of livability, therefore; a technologically advanced solution for sustainable rural development is called for. Blockchain Technology is the next step for innovation and development and it has far many applications in sustainable rural development that are yet to be discovered. The objective of this paper is to explicitly review research conducted in rural development to fill the undone work in the future with better research ideas, to make rural areas a livable and advanced place while also maintaining their integrity leading to sustainable development. To conduct such a review, a systematic research methodology is applied following regulations in the conduction of standardized but explorative analysis. Within the timeline of 2010–2021, 112 papers are carefully selected to perform the systematic review. This review will provide a comprehensible as well as concise research compendium for all applications proposed, implemented, and possible in the future to realize the concept of smart villages for the development of rural areas using blockchain technology.",Archives of computational methods in engineering : state of the art reviews,2021
5f4634aa233231551b832729ac753fdfd0dd8f11,https://www.semanticscholar.org/paper/5f4634aa233231551b832729ac753fdfd0dd8f11,Agri-Food 4.0 and Innovations: Revamping the Supply Chain Operations,"Abstract The agri-food sector contributes significantly to economic and social advancements globally despite numerous challenges such as food safety and security, demand and supply gaps, product quality, traceability, etc. Digital technologies offer effective and sustainable ways to these challenges through reduced human interference and improved data-accuracy. Innovations led by digital transformations in the agri-food supply chains (AFSCs) are the main aim of ‘Agri-Food 4.0’. This brings significant transformations in the agri-food sector by reducing food wastage, real-time product monitoring, reducing scalability issues, etc. This paper presents a systematic review of the innovations in the agri-food for digital technologies such as internet-of-things, artificial intelligence, big data, RFID, robotics, block-chain technology, etc. The employment of these technologies from the ‘farm to fork’ along AFSC emphasizes a review of 159 articles solicited from different sources. This paper also highlights digitization in developing smart, sensible, and sustainable agri-food supply chain systems.",Production Engineering Archives,2021
6502e646b5be0db1f0b265a39052a0aa2071e4de,https://www.semanticscholar.org/paper/6502e646b5be0db1f0b265a39052a0aa2071e4de,Is blockchain able to enhance environmental sustainability? A systematic review and research agenda from the perspective of Sustainable Development Goals (SDGs),,Business Strategy and the Environment,2021
695ddb52912766fedda9327b074b56685610ac03,https://www.semanticscholar.org/paper/695ddb52912766fedda9327b074b56685610ac03,Internet of Things (IoT) for Smart Farming: A Systematic Review,"The world population growth is projected to increase in the coming years and it brings along challenges such as food insecurity and increasing demand for food as a result of production challenges. For these reasons, sustainable and innovative agriculture practices are given higher priority. Smart farming is one of the innovative practices which has seen a significant growth as a result of improved technology and it is a novel farm management method that uses technologies to optimize farming activities and increase productivity. Many reviews on application of IoTs for farming have been published which shows significant contributions in this area of research. In existing reviews, the focus is mainly on areas like Unmanned Aerial Vehicles (UAC) and network topologies, technologies and protocols. This work uses the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to make a systematic review of current state of IoTs for farming by identifying the state-of-the-art sensing, networking, communication and data management technologies commonly used to implement the solution. The work demonstrates the growing importance of IoTs in farm management and reveals a significant improvement in the way sensor data are",,2021
779a25b387c03615fc34ab2b4ca212122615afd1,https://www.semanticscholar.org/paper/779a25b387c03615fc34ab2b4ca212122615afd1,A Taxonomy of Food Supply Chain Problems from a Computational Intelligence Perspective,"In the last few years, the Internet of Things, and other enabling technologies, have been progressively used for digitizing Food Supply Chains (FSC). These and other digitalization-enabling technologies are generating a massive amount of data with enormous potential to manage supply chains more efficiently and sustainably. Nevertheless, the intricate patterns and complexity embedded in large volumes of data present a challenge for systematic human expert analysis. In such a data-driven context, Computational Intelligence (CI) has achieved significant momentum to analyze, mine, and extract the underlying data information, or solve complex optimization problems, striking a balance between productive efficiency and sustainability of food supply systems. Although some recent studies have sorted the CI literature in this field, they are mainly oriented towards a single family of CI methods (a group of methods that share common characteristics) and review their application in specific FSC stages. As such, there is a gap in identifying and classifying FSC problems from a broader perspective, encompassing the various families of CI methods that can be applied in different stages (from production to retailing) and identifying the problems that arise in these stages from a CI perspective. This paper presents a new and comprehensive taxonomy of FSC problems (associated with agriculture, fish farming, and livestock) from a CI approach; that is, it defines FSC problems (from production to retail) and categorizes them based on how they can be modeled from a CI point of view. Furthermore, we review the CI approaches that are more commonly used in each stage of the FSC and in their corresponding categories of problems. We also introduce a set of guidelines to help FSC researchers and practitioners to decide on suitable families of methods when addressing any particular problems they might encounter. Finally, based on the proposed taxonomy, we identify and discuss challenges and research opportunities that the community should explore to enhance the contributions that CI can bring to the digitization of the FSC.",Sensors,2021
7f2271d9d18928fbb166bd1478be467fdccd54dd,https://www.semanticscholar.org/paper/7f2271d9d18928fbb166bd1478be467fdccd54dd,"A Survey of Industrial Internet of Things Platforms for Establishing Centralized Data-Acquisition Middleware: Categorization, Experiment, and Challenges","The development of industrial Internet of Things (IIoT), big data, and artificial intelligence technologies is leading to a major change in the production system. The change is being propagated into the wave of transforming the existing system with a vertical structure into the corresponding horizontal platform or middleware. Accordingly, the way of acquiring IIoT data from an individual system is being altered to the way of being increasingly centralized through an integrated middleware of a scalable server or through a large platform. That said, middleware-based IIoT data acquisition must consider multiple factors, such as infrastructure (e.g., operation environment and network), protocol heterogeneity, interoperability (e.g., links with legacy systems), real-time, and security. This manuscript explains these five aspects in detail and provides a taxonomy of eighteen state-of-the-art IIoT data-acquisition middleware systems based on these aspects. To validate one of these aspects (network), we present our evaluation results at a real production site where IIoT data-acquisition loss rates are compared between wireless (long-term evolution) and wired networks. As a result, the wired communication can be more suitable for centralized IIoT data-acquisition middleware than wireless networks. Finally, we discuss several challenges in establishing the best IIoT data-acquisition middleware in a centralized way.",Sci. Program.,2021
a5091cc4bb36220146278146baf50a8be3401202,https://www.semanticscholar.org/paper/a5091cc4bb36220146278146baf50a8be3401202,A LoRa sensor network for monitoring pastured livestock location and activity1,"Abstract Precision technologies for confinement animal agricultural systems have increased rapidly over the past decade, though precision technology solutions for pastured livestock remain limited. There are a number of reasons for this limited expansion of technologies for pastured animals, including networking availability and reliability, power requirements, and expense, among others. The objective of this work was to demonstrate a rapidly deployable long-range radio (LoRa) based, low-cost sensor suite that can be used to track location and activity of pastured livestock. The sensor is comprised of an inexpensive Arduino-compatible microprocessor, a generic MPU-9250 motion sensor which contains a 3-axis accelerometer, 3-axis magnetometer, and a 3-axis gyroscope, a generic GPS receiver, and a RFM95W generic LoRa radio. The microprocessor can be programmed flexibly using the open source Arduino IDE software to adjust the frequency of sampling, the data packet to send, and what conditions are needed to operate. The LoRa radio transmits to a Dragino LoRa gateway which can also be flexibly programmed through the Arduino IDE software to send data to local storage or, in cases where a web or cellular connection is available, to cloud storage. The sensor was powered using a USB cord connected to a 3,350 mAh lithium-ion battery pack. The Dragino gateway was programmed to upload data to the ThingSpeak IoT application programming interface for data storage, handling, and visualization. Evaluations showed minimal benefit associated with reducing sampling frequency as a strategy to preserve battery life. Packet loss ranged from 40% to 60%. In a 3 d evaluation on pastured sheep, the sensor suite was able to report GPS locations, inertial sensor readings, and temperature. Preliminary demonstrations of our system are satisfactory to detect animal location based on GPS data in real-time. This system has clear utility as a lower-cost strategy to deploy flexible, useful precision technologies for pasture-based livestock species.",Translational animal science,2021
ab0ff858fa332e034e543cb3efff1755f88734e8,https://www.semanticscholar.org/paper/ab0ff858fa332e034e543cb3efff1755f88734e8,"A Scoping Review of Renewable Energy, Sustainability and the Environment","The article aims to identify the latest trends in research on renewable energy, sustainability and the environment. A total of 92,873 publications from 123 Scopus sources for 2020–2021 are compared using the scoping review method. The results show that the most cited works in this sample are those by authors from the Asian region. The research of these authors focuses on the security, efficiency and reliability of separate elements in energy systems. Besides, the paper considers the problems regarding COVID disease along with the renewable energy sources, perovskite and organic solar panels, nanostructured materials and high energy density. Finally, the paper analyses applications of computer science methods in research on renewable energy, sustainability and the environment. The findings evidently show that recent advancements in computer science methods were not extensively used in the discussed research domain and give a great room for novel strategies of prognosing, simulation and processes optimisation.",Energies,2021
bd8a0b88a8e8e8ed7939165b2c000a93065162ad,https://www.semanticscholar.org/paper/bd8a0b88a8e8e8ed7939165b2c000a93065162ad,The internet of things in the food supply chain: adoption challenges,"Purpose: The food supply chain (FSC) challenges coupled with global disruptions, such as the recent coronavirus disease 2019 (COVID-19) pandemic outbreak, exacerbate its vulnerability The Internet of things (IoT) is one of the disruptive technologies being adopted in food supply chain management (FSCM) This study aims to address the challenges of IoT adoption in the FSC by systematically analyzing the prior pertinent literature Design/methodology/approach: A structured literature review was used to collate a list of peer-reviewed and relevant publications A total of 72 out of 210 articles were selected for the final evaluation Findings: The literature review findings suggest five themes: technical, financial, social, operational, educational and governmental related challenges A total of 15 challenges were devised from the review related literature of IoT adoption The study concludes with future research recommendations for scholars and practical implications for practitioners Research limitations/implications: While this study focuses on the overall FSC, further research should address other domains in the FSC such as cold supply chain, agriculture and perishable food to gain a better contextual understanding of the specific case Originality/value: The topic of IoT adoption in the FSCM is still considered emerging Therefore, the present work contributes to the limited studies and documentation on the level of IoT implementation in the FSCM This study should help organizations to assimilate how to adopt and manage the IoT application by addressing the factors and challenges presented in this research © 2021, Emerald Publishing Limited",,2021
c0816523b939146e8cde966073a329b0e61275ee,https://www.semanticscholar.org/paper/c0816523b939146e8cde966073a329b0e61275ee,Cybernetics approaches in intelligent systems for crops disease detection with the aid of IoT,"Detection of crop diseases is imperative for agriculture to be sustainable. Automated crop disease detection is a major issue in the current agricultural industry due to its cluttered background. Internet of Things (IoT) has gained immense interest in the past decade, as it accumulates a high level of contextual information to identify crop diseases. This study paper presents a novel method based on Taylor‐Water Wave Optimization‐based Generative Adversarial Network (Taylor‐WWO‐based GAN) to identify diseases in the agricultural industry. In this method, the IoT nodes sense the plant leaves, and the sensed data are transmitted to the Base Station (BS) using Fractional Gravitational Gray Wolf Optimization. This technique selects the optimal path for data transmission. After performing IoT routing, crop diseases are recognized at the BS. For detecting crop disease, the input image acquired from the IoT routing phase is then forwarded to the next step, that is, preprocessing, to improve the quality of the image for further processing. Then, Segmentation Network (SegNet) is adapted to segment the images, and extraction of significant features is performed using the acquired segments. The extracted features are adapted by the GAN, which is trained by Taylor‐WWO. The proposed Taylor‐WWO is newly devised by integrating the Taylor series and WWO algorithms. The proposed Taylor‐WWO‐based GAN showed improved performance with a maximum accuracy of 91.6%, maximum sensitivity of 89.3%, and maximum specificity of 92.3% in comparison with existing methods.",Int. J. Intell. Syst.,2021
c4ae90cccde15951b903e97d594c5b5bf12f6b8e,https://www.semanticscholar.org/paper/c4ae90cccde15951b903e97d594c5b5bf12f6b8e,Research and Technology Trend Analysis by Big Data-Based Smart Livestock Technology: a Review,,Journal of Biosystems Engineering,2021
c6047f2403a431088295edd6a3e4342c1aef3c93,https://www.semanticscholar.org/paper/c6047f2403a431088295edd6a3e4342c1aef3c93,Impact of Internet of Things in Agriculture,,Proceedings of International Conference on Data Science and Applications,2021
c7984163d6377d3a4c5843f8f7d5e569a33cc6c8,https://www.semanticscholar.org/paper/c7984163d6377d3a4c5843f8f7d5e569a33cc6c8,Deep Q-Learning and Preference Based Multi-Agent System for Sustainable Agricultural Market,"Yearly population growth will lead to a significant increase in agricultural production in the coming years. Twenty-first century agricultural producers will be facing the challenge of achieving food security and efficiency. This must be achieved while ensuring sustainable agricultural systems and overcoming the problems posed by climate change, depletion of water resources, and the potential for increased erosion and loss of productivity due to extreme weather conditions. Those environmental consequences will directly affect the price setting process. In view of the price oscillations and the lack of transparent information for buyers, a multi-agent system (MAS) is presented in this article. It supports the making of decisions in the purchase of sustainable agricultural products. The proposed MAS consists of a system that supports decision-making when choosing a supplier on the basis of certain preference-based parameters aimed at measuring the sustainability of a supplier and a deep Q-learning agent for agricultural future market price forecast. Therefore, different agri-environmental indicators (AEIs) have been considered, as well as the use of edge computing technologies to reduce costs of data transfer to the cloud. The presented MAS combines price setting optimizations and user preferences in regards to accessing, filtering, and integrating information. The agents filter and fuse information relevant to a user according to supplier attributes and a dynamic environment. The results presented in this paper allow a user to choose the supplier that best suits their preferences as well as to gain insight on agricultural future markets price oscillations through a deep Q-learning agent.",Sensors,2021
cb0630bbe0f22662abae83a44cf26ef70814c4e7,https://www.semanticscholar.org/paper/cb0630bbe0f22662abae83a44cf26ef70814c4e7,Digital Livestock Farming,"Abstract As the global human population increases, livestock agriculture must adapt to provide more livestock products and with improved efficiency while also addressing concerns about animal welfare, environmental sustainability, and public health. The purpose of this paper is to critically review the current state of the art in digitalizing animal agriculture with Precision Livestock Farming (PLF) technologies, specifically biometric sensors, big data, and blockchain technology. Biometric sensors include either noninvasive or invasive sensors that monitor an individual animal’s health and behavior in real time, allowing farmers to integrate this data for population-level analyses. Real-time information from biometric sensors is processed and integrated using big data analytics systems that rely on statistical algorithms to sort through large, complex data sets to provide farmers with relevant trending patterns and decision-making tools. Sensors enabled blockchain technology affords secure and guaranteed traceability of animal products from farm to table, a key advantage in monitoring disease outbreaks and preventing related economic losses and food-related health pandemics. Thanks to PLF technologies, livestock agriculture has the potential to address the abovementioned pressing concerns by becoming more transparent and fostering increased consumer trust. However, new PLF technologies are still evolving and core component technologies (such as blockchain) are still in their infancy and insufficiently validated at scale. The next generation of PLF technologies calls for preventive and predictive analytics platforms that can sort through massive amounts of data while accounting for specific variables accurately and accessibly. Issues with data privacy, security, and integration need to be addressed before the deployment of multi-farm shared PLF solutions becomes commercially feasible.",,2021
decdee81c80445d6b83e835a4b641ef5edc6a7a8,https://www.semanticscholar.org/paper/decdee81c80445d6b83e835a4b641ef5edc6a7a8,The interplay between the Internet of things and supply chain management: challenges and opportunities based on a systematic literature review,"PurposeThis study aims to identify and analyze how Internet of things (IoT) technology affects supply chain management (SCM) performance.Design/methodology/approachA systematic literature review was conducted (using Scopus, JSTOR, Emerald, ProQuest, Science Direct and Web of Science) covering a 20-year timeframe (2000–2020). Out of 2,572 papers identified, 171 peer-reviewed papers from the most important journals were selected. Content analysis was used following the Global Supply Chain Forum (GSCF) SCM framework.FindingsRegarding the GSCF SCM framework processes, most IoT-based studies have addressed improving order fulfilment, manufacturing flow management and demand management processes. However, no studies addressing the Supplier relationship management process were identified, suggesting that IoT-based applications are perceived to add more value in downstream than upstream SCM processes. The importance of using enabling technologies to realize the potential of value generation of IoT was also revealed. Findings suggest new research avenues related to product development and commercialization process, the supplier relationship management process, the returns management process, servitization strategies, new SCM models and new business models.Research limitations/implicationsThe review encompasses only academic papers from journals considered the most relevant (retrieved from specific databases), using the impact factor as the quality criterion.Practical implicationsThe findings can help business managers better understand the potential of IoT technology, such as the main applications identified in the literature and their impacts on SCM processes. Their importance in enabling technologies to leverage SCM performance is identified and the emerging SCM models/business models that IoT deployment can enable are highlighted.Originality/valueThis study contributes to filling a gap in the literature using a systematic literature review of how IoT technology affects SCM performance through content analysis, using an SCM framework to clarify which SCM processes are affected. Academic articles from the most important journals from 2000 to 2020 are identified.",Benchmarking: An International Journal,2021
df474bc26a3b79976e1a8b5e1cafa7273c2434f6,https://www.semanticscholar.org/paper/df474bc26a3b79976e1a8b5e1cafa7273c2434f6,Introduction of IoT-Based Surrogate Parameters in the Ex-Post Countermeasure of Industrial Sectors in Integrated Permit Policy,"New approaches and techniques are required for environmental management in workplaces that emit pollutants. The best available techniques (BATs) that are suggested by the integrated environmental permit system (IEPS) play a pivotal role in providing state-of-the-art approaches and techniques to workplaces. For the workplaces that install facilities with the BATs, it is necessary to perform real-time monitoring to determine whether pollutant emission facilities and treatment facilities are operating normally and whether such facilities can maintain the optimal condition during the emission of pollutants. The environmental management measures used before the IEPS had limitations for workplaces that are subjected to integrated environmental management because they consider the entire workplace as a single pollution source by combining all media. In addition, only the emission concentrations and amounts of pollutants were monitored because only the points at which most pollutants are discharged, i.e., stacks for air pollutant emission facilities and final effluent outlets for water pollutant emission facilities, are monitored. These monitoring approaches in a variety of facilities involve considerable costs, and most of them (95% for stacks in workplaces under IEPS, Korea) cannot perform real-time observation even though some of them are capable of it (5% for stacks managed by Tele Monitoring System, TMS). In this study, the applicability of a wireless sensor monitoring network was examined as a new approach for environmental management in workplaces. Based on the sensor monitoring network, surrogate parameters that can indirectly monitor the critical operating factors of pollutant emission and prevention facilities were developed and then measured in real time to examine the status of these facilities. Surrogate parameters can be used instead of directly measuring pollutants as the former has high efficiency, such as cost reduction, and can provide reliable data on the emission characteristics of pollutants. The wireless network is based on an Internet of Things (IoT) platform under real-time conditions in the emission and production facilities in a workplace. This study suggested that a wireless network using the IoT platform improves the BAT assessment methodology to understand the efficiency of environmental pollution reduction and the economic contribution to the workplace.",Sustainability,2021
ec9da3b5c896b67a15af062f8bca850526f2e633,https://www.semanticscholar.org/paper/ec9da3b5c896b67a15af062f8bca850526f2e633,Machine Learning Applications for Precision Agriculture: A Comprehensive Review,"Agriculture plays a vital role in the economic growth of any country. With the increase of population, frequent changes in climatic conditions and limited resources, it becomes a challenging task to fulfil the food requirement of the present population. Precision agriculture also known as smart farming have emerged as an innovative tool to address current challenges in agricultural sustainability. The mechanism that drives this cutting edge technology is machine learning (ML). It gives the machine ability to learn without being explicitly programmed. ML together with IoT (Internet of Things) enabled farm machinery are key components of the next agriculture revolution. In this article, authors present a systematic review of ML applications in the field of agriculture. The areas that are focused are prediction of soil parameters such as organic carbon and moisture content, crop yield prediction, disease and weed detection in crops and species detection. ML with computer vision are reviewed for the classification of a different set of crop images in order to monitor the crop quality and yield assessment. This approach can be integrated for enhanced livestock production by predicting fertility patterns, diagnosing eating disorders, cattle behaviour based on ML models using data collected by collar sensors, etc. Intelligent irrigation which includes drip irrigation and intelligent harvesting techniques are also reviewed that reduces human labour to a great extent. This article demonstrates how knowledge-based agriculture can improve the sustainable productivity and quality of the product.",IEEE Access,2021
ee81f3a32d613afd6ad9656eb7417ef77f6c8066,https://www.semanticscholar.org/paper/ee81f3a32d613afd6ad9656eb7417ef77f6c8066,Nanostructured gas sensors in smart manufacturing,,,2021
f0374706c249edd43ac22c7f54561dd80bbfdd81,https://www.semanticscholar.org/paper/f0374706c249edd43ac22c7f54561dd80bbfdd81,An Edge-IoT Architecture and Regression Techniques Applied to an Agriculture Industry Scenario,,SSCT,2021
fa6232ca180845464ccf95008c90239cbf87ce20,https://www.semanticscholar.org/paper/fa6232ca180845464ccf95008c90239cbf87ce20,"A Systematic Survey on the Role of Cloud, Fog, and Edge Computing Combination in Smart Agriculture","Cloud Computing is a well-established paradigm for building service-centric systems. However, ultra-low latency, high bandwidth, security, and real-time analytics are limitations in Cloud Computing when analysing and providing results for a large amount of data. Fog and Edge Computing offer solutions to the limitations of Cloud Computing. The number of agricultural domain applications that use the combination of Cloud, Fog, and Edge is increasing in the last few decades. This article aims to provide a systematic literature review of current works that have been done in Cloud, Fog, and Edge Computing applications in the smart agriculture domain between 2015 and up-to-date. The key objective of this review is to identify all relevant research on new computing paradigms with smart agriculture and propose a new architecture model with the combinations of Cloud–Fog–Edge. Furthermore, it also analyses and examines the agricultural application domains, research approaches, and the application of used combinations. Moreover, this survey discusses the components used in the architecture models and briefly explores the communication protocols used to interact from one layer to another. Finally, the challenges of smart agriculture and future research directions are briefly pointed out in this article.",Sensors,2021
0b4a8cd5f76a7c79fea9fc0250a2c186356752c0,https://www.semanticscholar.org/paper/0b4a8cd5f76a7c79fea9fc0250a2c186356752c0,A study on the significance of smart IoT sensors and Data science in Digital agriculture,"Agriculture is the backbone of the Indian economy. Environmental parameters such as temperature, humidity, rainfall, and so on are rapidly changing unpredictably. Internet-of-Things(IoT) and a wide range of agriculture sensors play a vital role to support farmers in enhancing their agricultural production despite the unpredictable behavior of natural parameters. Internet-of-Things(IoT) has a significant role in many smart applications that influences human life and sensors are inevitable in these systems. A high-volume of real-time data is generated from IoT sensor nodes deployed in farms at a faster rate. If this massive amount of data collected by IoT sensors need to be meaningful, it must be processed efficiently. This paper analyzes different types of sensors and IoT platforms used in smart farming. This paper also discusses the significance of data science in the agriculture sector and the various data processing methods applied over sensor data gathered for agricultural applications.",2020 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA),2020
11dbb92e9374353311574b37cddc34d9b9bf38ca,https://www.semanticscholar.org/paper/11dbb92e9374353311574b37cddc34d9b9bf38ca,Deep Tech and Artificial Intelligence for Worker Safety in Robotic Manufacturing Environments,,DCAI,2020
1424a053d584325f7c5391528f61436111aa3ea0,https://www.semanticscholar.org/paper/1424a053d584325f7c5391528f61436111aa3ea0,Deep Reinforcement Learning for the management of Software-Defined Networks in Smart Farming,"The Internet of Things and the millions of devices that generate and collect data through sensors to send it to the Cloud are part of the life of users in many contexts, including smart farming and precision agriculture scenarios. This volume of data is stored and processed in the Cloud, with the purpose of obtaining knowledge and valuable information for organizations. Edge Computing has emerged to reduce the costs associated with transferring, processing and storing data from IoT environments in the Cloud. This paradigm allows data to be pre-processed at the edge of the network before they are sent to the Cloud, obtaining shorter response times and maintaining service even during communication breakdowns between the IoT and Cloud layers. Furthermore, there is a increasing trend to shared physical network resources among diverse user entities through Software-Defined Networks and Network Function Virtualization with the aim to reduce costs. In this sense, smart mechanisms are required to optimize virtual dataflows in the networks, as Deep Reinforcement Learning techniques. This paper proposes a Double Deep-Q Learning approach to manage virtual dataflows in SDN/NFV using an Edge-IoT architecture, formerly applied in smart farming and Industry 4.0 scenarios.",2020 International Conference on Omni-layer Intelligent Systems (COINS),2020
14c4e8f856f3e1273f93a4fad1e5fbdf20128eb9,https://www.semanticscholar.org/paper/14c4e8f856f3e1273f93a4fad1e5fbdf20128eb9,Livestock Welfare by Means of an Edge Computing and IoT Platform,,ISAmI,2020
1c9fe28f9a8e42a824ec045b99a918f828a773a1,https://www.semanticscholar.org/paper/1c9fe28f9a8e42a824ec045b99a918f828a773a1,Big Data Processing Architecture for Smart Farming,"Abstract In the era of Big data, data-driven farming is changing the agricultural businesses thanks to the use of modern technologies such as the Internet of Things (IoT) sensors, drones, and farm monitoring. IoT devices produce a massive amount of precious agri-data, which are collected and analyzed in real-time using innovative application tools. This combination of technology, known as “Smart farming”, helps various stakeholders in the agri-ecosystem to monitor crops in real-time, as well as maximize productivity and profitability in farm and business operations with the minimum efforts. Although many Smart farming solutions have been introduced, both from industry and academia, universal applicability of these approaches for other farms, unfortunately, is not feasible. Most of these solutions are based on a home-made non-standard Big data processing architecture. In this paper, we propose WALLeSMART, a cloud-based Smart farming management system, applied to the Wallonia region of Belgium. The framework introduces a general architecture to address the challenges of acquisition, processing, storing, and visualization of very large amounts of data, both in batch and real-time basis. An initial prototype has been developed and tested with various farms showing prominent results.",EUSPN/ICTH,2020
2387b27c1a9eaea8678a26f70881c695c6cec09d,https://www.semanticscholar.org/paper/2387b27c1a9eaea8678a26f70881c695c6cec09d,A Systematic Review of IoT Solutions for Smart Farming,"The world population growth is increasing the demand for food production. Furthermore, the reduction of the workforce in rural areas and the increase in production costs are challenges for food production nowadays. Smart farming is a farm management concept that may use Internet of Things (IoT) to overcome the current challenges of food production. This work uses the preferred reporting items for systematic reviews (PRISMA) methodology to systematically review the existing literature on smart farming with IoT. The review aims to identify the main devices, platforms, network protocols, processing data technologies and the applicability of smart farming with IoT to agriculture. The review shows an evolution in the way data is processed in recent years. Traditional approaches mostly used data in a reactive manner. In more recent approaches, however, new technological developments allowed the use of data to prevent crop problems and to improve the accuracy of crop diagnosis.",Sensors,2020
29f362817c1c7520611c685b84fb7d3559fc5da6,https://www.semanticscholar.org/paper/29f362817c1c7520611c685b84fb7d3559fc5da6,Increasing Profitability and Monitoring Environmental Performance: A Case Study in the Agri-Food Industry through an Edge-IoT Platform,"Globalization has led to a new paradigm where the traditional industries, such as agriculture, employ vanguard technologies to broaden its possibilities into what is known as smart farming and the agri-food industry 4.0. This industry needs to adapt to the current market through an efficient use of resources while being environmentally friendly. The most commonly used approaches for analyzing efficiency and sustainability on farms are production efficiency based analyses, such as Data Envelopment Analysis and Stochastic Frontier Analysis, since they allow to see how efficient the outputs are generated regardless of the units of measurement of the inputs. This work presents a real scenario for making farms more profitable and sustainable through the analysis of the Data Envelopment Analysis and the application of the Internet of Things and Edge Computing. What makes this model interesting is that it allows monitoring the ambient conditions with real-time data from the different sensors that have been installed on the farm, minimizing costs and gaining robustness in the transmission of the data to the cloud with Edge Computing, and then to have a complete overview in terms of monthly resource efficiency through the Data Envelopment Analysis. The results show that including the costs of edge and non-edge data transfer have an impact on the efficiency. This small-scale study set the basis for a future test with many farms simultaneously.",Sustainability,2020
30a648e4f1d5d85057b9cae1f5f5cc6211e82a0d,https://www.semanticscholar.org/paper/30a648e4f1d5d85057b9cae1f5f5cc6211e82a0d,Neural networks for Pest Detection in Precision Agriculture,"Apple is one of the most produced fruit crops in the world. Recent advances in Artificial Intelligence and the Internet of Things can reduce production costs and improve crop quality by providing prompt detection of dangerous parasites. This paper presents an effective solution to automate the detection of the Codling Moths. The system takes pictures of trapped insects in the orchard, analyzes them through a DNN algorithm, and sends alarms to the farmer in case of a positive detection. The system is fully autonomous and can operate unattended for the entire crop season. Detection reports are used for optimizing the treatment with chemicals only when threats are identified. The prototype is designed with an embedded platform powered by a small solar panel to achieve an energy-neutral balance.",2020 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor),2020
36bcc7b463b0cee2abe450fb882dfc7aa6365e7d,https://www.semanticscholar.org/paper/36bcc7b463b0cee2abe450fb882dfc7aa6365e7d,A Hybrid Approach Using Multistage Collaborative Calibration for Wireless Sensor Network Localization in 3D Environments,"Accurate localization is critical in the internet of things (IOT), especially for wireless sensor networks (WSNs). Location estimation can be affected by factors such as node density, topological diversity, and sensor coverage. As such, we propose a hybrid approach using multistage collaborative calibration for wireless sensor network localization, specifically in 3D environments. This technique integrates a Modified version of Light Gradient Boosting Model (MLGB), which is based on a regression scheme, a cooperative methodology, and a fine calibration model for collaborative fusion. These techniques were combined with quadrilateral shrunk centroid (QSC) and distance vector hop algorithms, using a multi-communication radius and an improved frog-leaping algorithm (DVMFL). In the first step, MLGB was used to correct for inhomogeneous localization estimation errors and RSSI data sparsity. As a result, the model is capable of adapting to high topological diversity (i.e., C-shape, H-shape, S-shape, and O-shape).Successive steps further improved prediction accuracy by using a screening cooperative anchor node strategy to increase node density and enhance the QSC-DVMFL fusion framework for fine position estimation. The proposed methodology was assessed in a series of validation, comparing it to other techniques. The results demonstrated a clear effectiveness and adaptability across a variety of factors that typically affect WSN localization.",IEEE Access,2020
3748d15d37647429bd4cb295400e8f7191bd3dc8,https://www.semanticscholar.org/paper/3748d15d37647429bd4cb295400e8f7191bd3dc8,Experimental evaluation of RSSI-based positioning system with low-cost LoRa devices,"Abstract Along the last years, we have witnessed the growing demand for services, applications, and systems that depend on the specific location of both people and a variety of things and gadgets. Currently, the Global Positioning System (GPS) offers good accuracy on-location services around the world. Nevertheless, it does not work efficiently on applications that require several small, cheap, and low power devices. Under such conditions, researchers prefer to work with low-cost wireless alternatives such as WiFi, Zigbee, LoRa, Sigfox, among others. The purpose of this work is twofold. Firstly we evaluate the time-measurement and radio frequency capabilities of Pycom LoRa hardware implementation, in order to develop a low-cost and GPS-independent positioning system. Then, with these results, we propose and evaluate a positioning system with LoRa technology and based on the received signal strength indicator. Extensive field test measurements in outdoor rural environments show that we can obtain position estimation errors lesser than around 7% of the maximum distance between anchor nodes.",Ad Hoc Networks,2020
4ab992d02623e17fde58895669e0486cc4eb40d9,https://www.semanticscholar.org/paper/4ab992d02623e17fde58895669e0486cc4eb40d9,Recent Developments of the Internet of Things in Agriculture: A Survey,"A rise in the population has immensely increased the pressure on the agriculture sector. With the advent of technology, this decade is witnessing a shift from conventional approaches to the most advanced ones. The Internet of Things (IoT) has transformed both the quality and quantity of the agriculture sector. Hybridization of species along with the real-time monitoring of the farms paved a way for resource optimization. Scientists, research institutions, academicians, and most nations across the globe are moving towards the practice and execution of collaborative projects to explore the horizon of this field for serving mankind. The tech industry is racing to provide more optimal solutions. Inclusion of IoT, along with cloud computing, big data analytics, and wireless sensor networks can provide sufficient scope to predict, process, and analyze the situations and improve the activities in the real-time scenario. The concept of heterogeneity and interoperability of the devices by providing flexible, scalable, and durable methods, models are also opening new domains in this field. Therefore, this paper contributes towards the recent IoT technologies in the agriculture sector, along with the development of hardware and software systems. The public and private sector projects and startup’s started all over the globe to provide smart and sustainable solutions in precision agriculture are also discussed. The current scenario, applications, research potential, limitations, and future aspects are briefly discussed. Based on the concepts of IoT a precision farming framework is also proposed in this article.",IEEE Access,2020
5da83f4ea1166cdeb55b914ec2765617951c2222,https://www.semanticscholar.org/paper/5da83f4ea1166cdeb55b914ec2765617951c2222,AgriTrust—A Trust Management Approach for Smart Agriculture in Cloud-based Internet of Agriculture Things,"Internet of Things (IoT) provides a diverse platform to automate things where smart agriculture is one of the most promising concepts in the field of Internet of Agriculture Things (IoAT). Due to the requirements of more processing power for computations and predictions, the concept of Cloud-based smart agriculture is proposed for autonomic systems. This is where digital innovation and technology helps to improve the quality of life in the area of urbanization expansion. For the integration of cloud in smart agriculture, the system is shown to have security and privacy challenges, and most significantly, the identification of malicious and compromised nodes along with a secure transmission of information between sensors, cloud, and base station (BS). The identification of malicious and compromised node among soil sensors communicating with the BS is a notable challenge in the BS to cloud communications. The trust management mechanism is proposed as one of the solutions providing a lightweight approach to identify these nodes. In this article, we have proposed a novel trust management mechanism to identify malicious and compromised nodes by utilizing trust parameters. The trust mechanism is an event-driven process that computes trust based on the pre-defined time interval and utilizes the previous trust degree to develop an absolute trust degree. The system also maintains the trust degree of a BS and cloud service providers using distinct approaches. We have also performed extensive simulations to evaluate the performance of the proposed mechanism against several potential attacks. In addition, this research helps to create friendlier environments and efficient agricultural productions for the migration of people to the cities.",Sensors,2020
5fd611c87695c88e39948cafa74174ae454751af,https://www.semanticscholar.org/paper/5fd611c87695c88e39948cafa74174ae454751af,"Blockchain Technology in the Food Industry: A Review of Potentials, Challenges and Future Research Directions","Blockchain technology has emerged as a promising technology with far-reaching implications for the food industry. The combination of immutability, enhanced visibility, transparency and data integrity provides numerous benefits that improve trust in extended food supply chains (FSCs). Blockchain can enhance traceability, enable more efficient recall and aids in risk reduction of counterfeits and other forms of illicit trade. Moreover, blockchain can enhance the integrity of credence claims such as sustainably sourced, organic or faith-based claims such as kosher or halal by integrating the authoritative source of the claim (e.g., the certification body or certification owner) into the blockchain to verify the claim integrity and reassure business customers and end consumers. Despite the promises and market hype, a comprehensive overview of the potential benefits and challenges of blockchain in FSCs is still missing. To bridge this knowledge gap, we present the findings from a systematic review and bibliometric analysis of sixty-one (61) journal articles and synthesize existing research. The main benefits of blockchain technology in FCSs are improved food traceability, enhanced collaboration, operational efficiencies and streamlined food trading processes. Potential challenges include technical, organizational and regulatory issues. We discuss the theoretical and practical implications of our research and present several ideas for future research.",,2020
9367f9620ee4884526f2c124c45ce85db8018fd2,https://www.semanticscholar.org/paper/9367f9620ee4884526f2c124c45ce85db8018fd2,Integrating fuzzy cognitive maps and multi-agent systems for sustainable agriculture,"In conventional agriculture, a wide variety of decisions are made with high uncertainty. Recommendations regarding pesticides, fertilizers, and irrigation water are made in a very generic manner and do not consider the intrafield variability of parameters that can affect crop yields. This has serious economic and environmental implications. The goal of precision agriculture is to improve agricultural sustainability and to optimize crop growth decisions by accounting for field variability and site-specific parameter values. The aim of the present work was to build an online smart platform based on innovative technologies such as multi-agent processing and fuzzy cognitive maps that improves decision-making by farming field-management nodes, which should ultimately save resources at the farm level while increasing the income from farming through the optimal use of both water and fertilizers and respecting the environment and the consumer. The platform helps farmers to access knowledge that can assist them in making the right decisions when implementing precision agriculture management actions (e.g., matching the application of nitrogen to crop demands, predicting key growth stages, and estimating the optimal duration of irrigation).",Euro-Mediterranean Journal for Environmental Integration,2020
9384f66c14463a7e8ebabc8e4d8c0559bb084702,https://www.semanticscholar.org/paper/9384f66c14463a7e8ebabc8e4d8c0559bb084702,Smart Farming: An Enhanced Pursuit of Sustainable Remote Livestock Tracking and Geofencing Using IoT and GPRS,"The farmers of agricultural farms manage and monitor different types of livestock The manual inspection and monitoring of livestock are tedious since the cattle do not stay at fixed locations Fencing many cattle requires a considerable cost and involves farmers’ physical intervention to keep an eye to stop them from crossing beyond the access points Visual tracking of livestock and fencing is a time-consuming and challenging job This research proposes a smart solution for livestock tracking and geofencing using state-of-the-art IoT technology The study creates a geographical safe zone for cattle based on IoT and GPRS, where the cattle are assigned dedicated IoT sensors The cattle can be easily remotely monitored and controlled without having any need for farmers to intervene for livestock management physically The smart system collects the data regarding the location, well-being, and health of the livestock This kind of livestock management may help prevent the spread of COVID-19, lower the farming costs, and enable remote monitoring",Wirel. Commun. Mob. Comput.,2020
9e5e92b58c759919aa0ab25f0c53f4b2e37bcf10,https://www.semanticscholar.org/paper/9e5e92b58c759919aa0ab25f0c53f4b2e37bcf10,Blockchain technology for cybersecurity applications in the food supply chain: A systematic literature review,"The food supply chain is a complex system responsible for the circulation of food products, and managing it requires IT infrastructures and technologies that are free of cyber-risk and that are used to connect, build and share information. Blockchain technology is a distributed ledger that can play an important role in providing data transparency, trust, immutability, integrity, and traceability to all food supply chain members. The purpose of this review is to depict a landscape of the scientific literature enriched by an author's keywords analysis to develop and test blockchain’s capabilities for cyber-risks prevention in international food supply chains. This paper combines a systematic literature review (SLR) process with the analysis of bibliographic networks. Papers from interdisciplinary areas published between 2016 and 2020 were selected to review the evolution of cyber-risks, cybersecurity solutions, and blockchain solutions used as a reference to identify, classify and specify requirements for a cyber secure distributed ledger. The findings show how blockchain technology needs other technologies, such as advanced ICT and Internet of Things (IoTs), for better food product traceability, safety, and transparency. It shows the multiple choices of blockchain architectures and their maturity level to interface with ICTs and IoTs. Based on the analysis of literature, research gaps, and future research directions are proposed in this paper regarding the applications of blockchain technology for managing cyber risks in the food supply chain. To the best of our knowledge, this paper provides an important contribution of literature with an SLNA entirely focused on the intersection between cyberrisks, blockchain and food supply chains that are continuously evolving, and shaping new supply chain models.",,2020
b24f97fbfbfee8a626768bcabf974c0aab3ccefc,https://www.semanticscholar.org/paper/b24f97fbfbfee8a626768bcabf974c0aab3ccefc,Data Augmentation Using Gaussian Mixture Model on CSV Files,"One of the biggest challenges in training supervised models is the lack of amount of labeled data for training the model and facing overfitting and underfitting problems. One of the solutions for solving this problem is data augmentation. There have been many developments in data augmentation of the image files, especially in medical image type datasets, by doing some changes on the original file such as Random cropping, Filliping, Rotating, and so on, in order to make a new sample file. Or use Deep Learning models to generate similar samples like Generative Adversarial Networks, Convolutional Neural Networks and so on. However, in numerical dataset, there have not been enough advances. In this paper, we are proposing to use the Gaussian Mixture Models (GMMs) to augment more data very similar to the original Numerical dataset. The results demonstrated that the Mean Absolute Error decreases meaning that the regression model became more accurate.",DCAI,2020
b77b7255887fc7836a164978ba96c6a7f7ed5ac8,https://www.semanticscholar.org/paper/b77b7255887fc7836a164978ba96c6a7f7ed5ac8,Analysis of factors affecting IoT-based smart hospital design,"Currently, rapidly developing digital technological innovations affect and change the integrated information management processes of all sectors. The high efficiency of these innovations has inevitably pushed the health sector into a digital transformation process to optimize the technologies and methodologies used to optimize healthcare management systems. In this transformation, the Internet of Things (IoT) technology plays an important role, which enables many devices to connect and work together. IoT allows systems to work together using sensors, connection methods, internet protocols, databases, cloud computing, and analytic as infrastructure. In this respect, it is necessary to establish the necessary technical infrastructure and a suitable environment for the development of smart hospitals. This study points out the optimization factors, challenges, available technologies, and opportunities, as well as the system architecture that come about by employing IoT technology in smart hospital environments. In order to do that, the required technical infrastructure is divided into five layers and the system infrastructure, constraints, and methods needed in each layer are specified, which also includes the smart hospital’s dimensions and extent of intelligent computing and real-time big data analytic. As a result of the study, the deficiencies that may arise in each layer for the smart hospital design model and the factors that should be taken into account to eliminate them are explained. It is expected to provide a road map to managers, system developers, and researchers interested in optimization of the design of the smart hospital system.",J. Cloud Comput.,2020
c95d778852b56d6270ee7af60457ad3731fb5cd8,https://www.semanticscholar.org/paper/c95d778852b56d6270ee7af60457ad3731fb5cd8,Secure monitoring in IoT-based services via fog orchestration,"Abstract Fog computing proposes moving computation, communication and storage from the cloud to the edge of the network, thus making it a perfect match for latency-sensitive IoT services such as sensor monitoring. Security is, however, a fundamental issue in fog-enabled services dealing with sensitive data, such as healthcare monitoring. Some authors circumvent security issues by assuming that IoT devices and fog nodes are fully trusted. Nevertheless, when IoT devices are geographically distributed and/or may be deployed in non-secure locations, and communications are done via WAN, the probability of attacks increases significantly. Security-enabling solutions rely on either trusted and centralized infrastructures (which go against the distributed and ubiquitous nature of fog-enabled IoT services) or expensive cryptography (which increases latency). In contrast, we propose decentralized and efficient security-enabling protocols for fog-based services that involve continuous monitoring of data. We have put special care in ensuring that the performance benefits brought by fog computing are not significantly hampered by the security mechanisms in use. For this, we rely on the recent concept of fog orchestration by which the network is self-tailored to the service to be delivered; in this way, we minimize the load of the network and its nodes during the monitoring. By means of a set of theoretical analyses and empirical results, we discuss the performance of our protocols and how they improve the current literature.",Future Gener. Comput. Syst.,2020
d3cbb4f9b0a02e60e4bb95f9f264851befd18f2a,https://www.semanticscholar.org/paper/d3cbb4f9b0a02e60e4bb95f9f264851befd18f2a,Review: Application and Prospective Discussion of Machine Learning for the Management of Dairy Farms,"Simple Summary Machine learning (ML) offers new approaches for analyzing data and is particularly interesting for large datasets. Dairy farmers implement a wide range of sensors, which create large amounts of data, in farming. Therefore, they offer an interesting area for data-driven research. In this review, we show how ML methods have already been used in the scientific literature and describe the potential that these may offer for the future. We found that ML methods were applied to predict data in a variety of areas in dairy farming such as milk yield or energy consumption; however, larger integrated datasets are required to improve the reliability of the algorithms developed. Abstract Dairy farmers use herd management systems, behavioral sensors, feeding lists, breeding schedules, and health records to document herd characteristics. Consequently, large amounts of dairy data are becoming available. However, a lack of data integration makes it difficult for farmers to analyze the data on their dairy farm, which indicates that these data are currently not being used to their full potential. Hence, multiple issues in dairy farming such as low longevity, poor performance, and health issues remain. We aimed to evaluate whether machine learning (ML) methods can solve some of these existing issues in dairy farming. This review summarizes peer-reviewed ML papers published in the dairy sector between 2015 and 2020. Ultimately, 97 papers from the subdomains of management, physiology, reproduction, behavior analysis, and feeding were considered in this review. The results confirm that ML algorithms have become common tools in most areas of dairy research, particularly to predict data. Despite the quantity of research available, most tested algorithms have not performed sufficiently for a reliable implementation in practice. This may be due to poor training data. The availability of data resources from multiple farms covering longer periods would be useful to improve prediction accuracies. In conclusion, ML is a promising tool in dairy research, which could be used to develop and improve decision support for farmers. As the cow is a multifactorial system, ML algorithms could analyze integrated data sources that describe and ultimately allow managing cows according to all relevant influencing factors. However, both the integration of multiple data sources and the obtainability of public data currently remain challenging.",Animals : an open access journal from MDPI,2020
d715b9534b58a109e5fc67602cf8810aa7c694dc,https://www.semanticscholar.org/paper/d715b9534b58a109e5fc67602cf8810aa7c694dc,Practical Classification and Evaluation of Optically Recorded Food Data by Using Various Big-Data Analysis Technologies,"An increasing shortening of product life cycles, as well as the trend towards highly individualized food products, force manufacturers to digitize their own production chains. Especially the collection, monitoring, and evaluation of food data will have a major impact in the future on how the manufacturers will satisfy constantly growing customer demands. For this purpose, an automated system for collecting and analyzing food data was set up to promote advanced production technologies in the food industry. Based on the technique of laser triangulation, various types of food were measured three-dimensionally and examined for their chromatic composition. The raw data can be divided into individual data groups using clustering technologies. Subsequent indexing of the data in a big data architecture set the ground for setting up real-time data visualizations. The cluster-based back-end system for data processing can also be used as an organization-wide communication network for more efficient monitoring of companies’ production data flows. The results not only describe the procedure for digitization of food data, they also provide deep insights into the practical application of big data analytics while helping especially small- and medium-sized enterprises to find a good introduction to this field of research.",Machines,2020
d71b82bba67c87b818ce27edfb228057a76c48ce,https://www.semanticscholar.org/paper/d71b82bba67c87b818ce27edfb228057a76c48ce,A Systematic Literature Review: Blockchain Based Solutions for IoT’s,"-In the modern era, Internet of things brought revolution in the everyday life activities by automation in everyday functions, modifying the approach of people to collaborate with one another or with the devices. Actually, the main feature of IoTs is direct device to device interrelationship. Their benefits range from little domestic devices to heavy industrial systems. Despite of numerous advantages of IoTs, their execution contains different issues mostly due to the severe substance of the functions by implement and because of their narrow computing abilities. Blockchain is the forthcoming annoying technology field that has achieved the attention of IoT sectors to tackle the problems by becoming encountered by themselves. In the article, the relevant issues in IoT field are pointed by us and then examined by the method how these issues can be resolved with the help of Blockchain features. Furthermore, we have also identified issues that appear while allocation of blockchain (BC) in Internet of things (IoTs). Keywords--Internet of Things(IoT); Blockchain",,2020
dfef5482df45e659741cbf974462deac32a59498,https://www.semanticscholar.org/paper/dfef5482df45e659741cbf974462deac32a59498,"Efficiency, profitability and productivity: Technological applications in the agricultural sector","47 María E. Pérez-Pons, Javier Parra-Dominguez, Marta Plaza, Pablo Chamoso and Ricardo S. Alonso Efficiency, profitability and productivity: Technological applications in the agricultural sector ADCAIJ: Advances in Distributed Computing and Artificial Intelligence Journal Regular Issue, Vol. 9 N. 4 (2020), 47-54 eISSN: 2255-2863 https://adcaij.usal.es Ediciones Universidad de Salamanca cc by-nc-nd Efficiency, profitability and productivity: Technological applications in the agricultural sector",,2020
e04f8902211bb9dd5b25b8a502b0d2fb35b58c60,https://www.semanticscholar.org/paper/e04f8902211bb9dd5b25b8a502b0d2fb35b58c60,Deep Reinforcement Learning for the Management of Software-Defined Networks and Network Function Virtualization in an Edge-IoT Architecture,"The Internet of Things (IoT) paradigm allows the interconnection of millions of sensor devices gathering information and forwarding to the Cloud, where data is stored and processed to infer knowledge and perform analysis and predictions. Cloud service providers charge users based on the computing and storage resources used in the Cloud. In this regard, Edge Computing can be used to reduce these costs. In Edge Computing scenarios, data is pre-processed and filtered in network edge before being sent to the Cloud, resulting in shorter response times and providing a certain service level even if the link between IoT devices and Cloud is interrupted. Moreover, there is a growing trend to share physical network resources and costs through Network Function Virtualization (NFV) architectures. In this sense, and related to NFV, Software-Defined Networks (SDNs) are used to reconfigure the network dynamically according to the necessities during time. For this purpose, Machine Learning mechanisms, such as Deep Reinforcement Learning techniques, can be employed to manage virtual data flows in networks. In this work, we propose the evolution of an existing Edge-IoT architecture to a new improved version in which SDN/NFV are used over the Edge-IoT capabilities. The proposed new architecture contemplates the use of Deep Reinforcement Learning techniques for the implementation of the SDN controller.",,2020
eb62cfb43002ac9eb4ccd0280b2937214169e6d8,https://www.semanticscholar.org/paper/eb62cfb43002ac9eb4ccd0280b2937214169e6d8,Low-Power Distributed AI and IoT for Measuring Lamb's Milk Ingestion and Predicting Meat Yield and Malnutrition Diseases,"On most sheep dairy farms, it is a common practice to separate lambs from mothers shortly after birth, being raised by artificial lactation, i.e., automatic lamb feeders. This work will build a low-power Distributed AI device combining IoT and Machine Learning aimed at measuring each lamb’s milk ingestion and predicting its future meat yield and possible malnutrition diseases. This device will consist of a Customized Low-Energy Computing (CLEC) that will identify each lamb through Bluetooth beacons, measure the amount of milk ingested by each lamb and offer researchers and farmers a prediction using ML models that will be executed in the device itself through Distributed AI techniques.",ISAmI,2020
f450a6b8e45e64d2026f0552d64ab37144ea8cc2,https://www.semanticscholar.org/paper/f450a6b8e45e64d2026f0552d64ab37144ea8cc2,Deep Symbolic Learning and Semantics for an Explainable and Ethical Artificial Intelligence,,ISAmI,2020
3cbf0de56365c34ab0f7f2a2c96b36b8ac5e9dd2,https://www.semanticscholar.org/paper/3cbf0de56365c34ab0f7f2a2c96b36b8ac5e9dd2,A Review on Edge Computing in Smart Energy by means of a Systematic Mapping Study,"Context: Smart Energy is a disruptive concept that has led to the emergence of new energy policies, technology projects, and business models. The development of those models is driven by world capitals, companies, and universities. Their purpose is to make the electric power system more efficient through distributed energy generation/storage, smart meter installation, or reduction of consumption/implementation costs. This work approaches Smart Energy as a paradigm that is concerned with systemic strategies involving the implementation of innovative technological developments in energy systems. However, many of the challenges encountered under this paradigm are yet to be overcome, such as the effective integration of solutions within Smart Energy systems. Edge Computing is included in this new technology group. Objective: To investigate developments that involve the use of Edge Computing and that provide solutions to Smart Energy problems. The research work will be developed using the methodology of systematic mapping of literature, following the guidelines established by Kitchenham and Petersen that facilitate the identification of studies published on the subject. Results: Inclusion and exclusion criteria have been applied to identify the relevant articles. We selected 80 papers that were classified according to the type of publication (journal, conferences, or book chapter), type of research (conceptual, experience, or validation), type of activity (implement, validate, analyze) and asset (architecture, framework, method, or models). Conclusion: A complete review has been conducted of the 80 articles that were closely related to the questions posed in this research. To reach the goal of building Edge Computing architectures for Smart Energy environments, several lines of research have been defined. In the future, such architectures will overcome current problems, becoming highly energy-efficient, cost-effective, and capacitated to process and respond in real-time.",,2019
d8ddba9f0f8334d6266643f28ff5cb1fc6c9bb58,https://www.semanticscholar.org/paper/d8ddba9f0f8334d6266643f28ff5cb1fc6c9bb58,Who goes there?: selecting a robot to reach a goal using social regret,"A common decision problem in multi-robot applications involves deciding on which robot, out of a group of N robots, should travel to a goal location, to carry out a task there. Trivially, this decision problem can be solved greedily, by selecting the robot with the shortest expected travel time. However, this ignores the inherent uncertainty in path traversal times; we may prefer a robot that is slower (but always takes the same time), over a robot that is expected to reach the goal faster, but on occasion takes a very long time to arrive. We make several contributions that address this challenge. First, we bring to bear economic decision-making theory, to distinguish between different selection policies, based on risk (risk averse, risk seeking, etc.). Second, we introduce social regret (the difference between the actual travel time by the selected robot, and the hypothetical time of other robots) to augment decision-making in practice. Then, we carry out experiments in simulation and with real robots, to demonstrate the usefulness of the selection procedures under real-world settings, and find that travel-time distributions have repeating characteristics.",AAMAS,2011
378546e425f04311ea1fa45b9e762aecb333a8d4,https://www.semanticscholar.org/paper/378546e425f04311ea1fa45b9e762aecb333a8d4,Kablosuz EKG Cihazı Tasarımı ve Sinyal İşleme Teknikleri Kullanılarak Özniteliklerin Değerlendirilmesine Yönelik Web Sitesi Tasarımı,,European Journal of Science and Technology,2021
336053001fc6ab6a17f69923f7be4a51abd80113,https://www.semanticscholar.org/paper/336053001fc6ab6a17f69923f7be4a51abd80113,An Overview on Analyzing Deep Learning and Transfer Learning Approaches for Health Monitoring,"With the rise and advancement of technology, early detection and involvement in health-associated monitoring through home control are growing with population aging. The expansion of healthy life expectations is progressively significant due to the speedy aging of the world population. The patient requires early and home-based treatment to detect and prevent disease on time and with less effort. Home-based health monitoring has been considered the need of a smart home. The services of health monitoring can facilitate the patient by collecting and analyzing the data of health for tackling diverse complex issues of health at a large scale. Health monitoring is a sustainable progression of clinical trials for ensuring that health is monitored according to the defined protocol and standard operating procedures. Various scenarios can be considered for monitoring health and are performed through experts of the field. Healthcare systems are having large-scale infrastructure of electronic devices, medical information systems, wearable and smart devices, medical records, and handheld devices. The growth in medical infrastructure, combined with the development of computational approaches in healthcare, has empowered practitioners and researchers to devise a novel solution in the innovative spectra. A detailed report of the existing literature in terms of deep learning and transfer learning is the dire need and facilitating of modern healthcare. To overcome these limitations, therefore, the proposed study presents a comprehensive review of the existing approaches, techniques, and methods associated with deep learning and transfer learning for health monitoring. This review will help researchers to formulate new ideas for facilitating healthcare based on the existing evidence.",Comput. Math. Methods Medicine,2021
142c714564bee8dc7e3318706d763eb3ab6d0974,https://www.semanticscholar.org/paper/142c714564bee8dc7e3318706d763eb3ab6d0974,Data Analytics Framework Based on Cloud Environment,,,2021
86c72c3033176b26d72931d27b074de3f0f4a42f,https://www.semanticscholar.org/paper/86c72c3033176b26d72931d27b074de3f0f4a42f,Optimal Solution for a Disaster Recovery (DR) site Across Multiple Cloud Service Providers,"Disaster Recovery (DR) is an essential trait for all enterprises to maintain Business Continuity and to survive if disaster happens. During the past decades, Cloud computing gained popularity for a DR site due to advantages like specialized management dealing with data, specialized & reliable devices with the advantage of economy of scale, optimum use of resources, and it can handle Big Data, Data Mining , Mobile Computing, Block chain, high performance computing tasks efficiently. Further enhancement in technology and benefits of cloud computing give birth to a new generation of cloud computing technology called Multi cloud computing. Both models Single-Cloud and Multi-Cloud environment provides DR sites and different geographical zones to deal with disaster, with a difference that Multi-cloud environment operates by different vendors and provides greater flexibility to users. For a DR site, the Single-Cloud paradigm poses risks for a DR site due to failure of single vendor services, monopoly, damage caused by human errors, fraudulent practices adopted by the vendor etc. Whereas Multi-Cloud environment, overcome this deficiency with better flexibility , control, cost advantage and decide which workloads are going to be run and where they should be run efficiently. Due to this Multi-cloud environment is preferred choice for Disaster Recovery (DR) site. The objective of this paper is to find out the optimal solution for the DR site.",,2021
be826414155b889fc283446e6509d85e4c5c6369,https://www.semanticscholar.org/paper/be826414155b889fc283446e6509d85e4c5c6369,Characteristic insights on industrial cyber security and popular defense mechanisms,"Due to the deep integration of information technology and operational technology, networked control systems are experiencing an increasing risk of international cyber attacks. In practice, industrial cyber security is a significant topic because current networked control systems are supporting various critical infrastructures to offer vital utility services. By comparing with traditional IT systems, this paper first analyzes the uncontrollable cyber threats and classified attack characteristics, and elaborates the intrinsic vulnerabilities in current networked control systems and novel security challenges in future Industrial Internet. After that, in order to overcome partial vulnerabilities, this paper presents a few representative security mechanisms which have been successfully applied in today's industrial control systems, and these mechanisms originally improve traditional IT defense technologies from the perspective of industrial availability. Finally, several popular security viewpoints, adequately covering the needs of industrial network structures and service characteristics, are proposed to combine with burgeoning industrial information technologies. We target to provide some helpful security guidelines for both academia and industry, and hope that our insights can further promote in-depth development of industrial cyber security.",China Communications,2021
e8f775d0363af350c5e094ab08932551da9c863d,https://www.semanticscholar.org/paper/e8f775d0363af350c5e094ab08932551da9c863d,A Survey Paper on Machine Learning Approaches to Intrusion Detection,"This electronic document is a “live” template and already defines the components of your paper [title, text, heads, etc.] in its style sheet. For any nation, government, or cities to compete favorably in today’s world, it must operate smart cities and e-government. As trendy as it may seem, it comes with its challenges, which is cyber-attacks. A lot of data is generated due to the communication of technologies involved and lots of data are produced from this interaction. Initial attacks aimed at cyber city were for destruction, this has changed dramatically into revenue generation and incentives. Cyber-attacks have become lucrative for criminals to attack financial institutions and cart away with billions of dollars, led to identity theft and many more cyber terror crimes. This puts an onus on government agencies to forestall the impact or this may eventually ground the economy. The dependence on cyber networked systems is impending and this has brought a rise in cyber threats, cyber criminals have become more inventive in their approach. This proposed dissertation discusses various security attacks classification and intrusion detection tools which can detect intrusion patterns and then forestall a break-in, thereby protecting the system from",,2021
fc7ecd5e40b9b4d264c3bc33bb810eadd3ecedb2,https://www.semanticscholar.org/paper/fc7ecd5e40b9b4d264c3bc33bb810eadd3ecedb2,"An Overview: Stochastic Gradient Descent Classifier, Linear Discriminant Analysis, Deep Learning and Naive Bayes Classifier Approaches to Network Intrusion Detection","The security of Network Systems is ravaged by attacks on Systems in a bid to gain unauthorized access into the network system. The aim of Network Intrusion Detection Systems is to detect anomaly patterns either while the attack is unfolding or after evidence that an intrusion occurred. The demand and crave for Internet usage have surged over the years and will continue to rise, which also puts gadgets that are connected to Networks at risk of attacks by Cyber Terrorist and hackers. This problem is not limited to individuals or Corporations alone but also E-Governments and Enterprises, despite billions of dollars allocated to Cyber Security, computer systems and networks do not give a 100 percent guarantee against Cyber-attacks. It is against this backdrop that we must establish Network Intrusion Detection Systems to reveal and counter Cyber-attacks on Networks and Computer Systems. Keywords—Component; formatting; style; styling; Cyber Security; machine learning, Netwrok Intrusion Detection.",,2021
0cbc40d71bf61416918278b155fc2a558c524545,https://www.semanticscholar.org/paper/0cbc40d71bf61416918278b155fc2a558c524545,SDN Based Computation Offloading for Industrial Internet of Things,"As a new type of highly collaborative and shared intelligent network between producers and production environments, Industrial Internet of Things (IIOT) has been taken an important part of the fourth industrial revolution. IIOT generates large amounts of sensory data which need to be processed rapidly. However, the cloud-based data processing method consumes a long time and huge network overhead, which further affects the quality of service. On the other hand, the emerging edge computing also cannot process data efficiently because of limited compute and network resource. In this paper, we propose a four-layer network architecture based on SDN for the industrial internet of things scenario. Through effective transmission and computation coupling, the processing response efficiency is improved. We present a three-level computation offloading method to realize the optimization of network delay and power consumption. Theory and experiments show that the method proposed in this paper can effectively reduce the computation power consumption and response time.","2020 16th International Conference on Mobility, Sensing and Networking (MSN)",2020
ace26b449eb99ce657d7de54734076fa31c62456,https://www.semanticscholar.org/paper/ace26b449eb99ce657d7de54734076fa31c62456,The architecture and key technologies for an industrial Internet with synergy between the cloud and clients,"The fourth industrial revolution has been unveiled with the rapid development of Internet of things (IoT), cloud computing, and big data. The industrial Internet, as a highly cooperative and intelligence-sharing global network that connects entities, human beings, and the environment in smart manufacturing, is the core of this revolution. However, most current research on the industrial Internet is restricted to IoT, cloud computing, or big data, respectively. The synergy between the cloud and clients is currently at a very primary stage of sensing, connection, and knowledge, lacking a cloud-client-integrative architecture and key technologies that could meet the evolving requirements of networked smart production, including more complex objects to be sensed, more diversification of entities to be connected, faster data processing, and more intelligent feedback control. This paper first surveys some important research directions with respect to this research field and summarizes the research status and challenges. On this basis, a novel cloud-client integrative industrial Internet architecture and solutions for related key technologies are proposed. Then, the proposed technologies are demonstrated for some specific applications in the field of intelligent manufacturing. Finally, the prospects for cloud-client-integrative industrial Internet research are discussed and concluded.",,2020
2a8553cbc62ef762813c53c0f4accd1e4f22e30f,https://www.semanticscholar.org/paper/2a8553cbc62ef762813c53c0f4accd1e4f22e30f,The Case for Dual-access File Systems over Object Storage,"Object storage has emerged as a low-cost and hyperscalable alternative to distributed file systems. However, interface incompatibilities and performance limitations often compel users to either transfer data between a file system and object storage or use inefficient file connectors over object stores. The result is growing storage sprawl, unacceptably low performance, and an increase in associated storage costs. One promising solution to this problem is providing dual access, the ability to transparently read and write the same data through both file system interfaces and object storage APIs. In this position paper we argue that there is a need for dual-access file systems over object storage, and examine some representative use cases which benefit from such systems. Based on our conversations with end users, we discuss features which we believe are essential or desirable in a dual-access object storage file system (OSFS). Further, we design and implement an early prototype of Agni1, an efficient dual-access OSFS which overcomes the shortcomings of existing approaches. Our preliminary experiments demonstrate that for some representative workloads Agni can improve performance by 20%–60% compared to either S3FS, a popular OSFS, or the prevalent approach of manually copying data between different storage systems.",HotStorage,2019
47cb4711fa3b6780193eba6ce55f1dd4afb723ab,https://www.semanticscholar.org/paper/47cb4711fa3b6780193eba6ce55f1dd4afb723ab,Agni: An Efficient Dual-access File System over Object Storage,"Object storage is a low-cost, scalable component of cloud ecosystems. However, interface incompatibilities and performance limitations inhibit its adoption for emerging cloud-based workloads. Users are compelled to either run their applications over expensive block storage-based file systems or use inefficient file connectors over object stores. Dual access, the ability to read and write the same data through file systems interfaces and object storage APIs, has promise to improve performance and eliminate storage sprawl. We design and implement Agni1, an efficient, distributed, dual-access object storage file system (OSFS), that uses standard object storage APIs and cloud microservices. Our system overcomes the performance shortcomings of existing approaches by implementing a multi-tier write aggregating data structure and by integrating with existing cloud-native services. Moreover, Agni provides distributed access and a coherent namespace. Our experiments demonstrate that for representative workloads Agni improves performance by 20%--60% when compared with existing approaches.",SoCC,2019
4ac172470351a334aa36b6659d68ac55799ea73f,https://www.semanticscholar.org/paper/4ac172470351a334aa36b6659d68ac55799ea73f,Edge Powered Industrial Control: Concept for Combining Cloud and Automation Technologies,"In the past, industrial control of field devices was comprised of self-contained systems in a dedicated network for exchanging control information between field devices and control hardware to accomplish process tasks. Nowadays, cloud computing enables a massive amount of computing resources and high availability, which opens up new potentials in the industrial sector. Until now, the integration of cloud solutions in industrial control was limited due to missing technologies connecting the Internet of Things with industrial requirements. Furthermore, based on existing paradigms there is a lack of appropriate architecture concepts for industrial control. This paper depicts a platform concept, which combines cloud computing and industrial control using edge devices realized for an automation cell.",2018 IEEE International Conference on Edge Computing (EDGE),2018
94318aee1139ffcfe39984cea2b8051fcddb6f9d,https://www.semanticscholar.org/paper/94318aee1139ffcfe39984cea2b8051fcddb6f9d,ProducTron: Towards Flexible Distributed and Networked Production,"With the evolution of cloud computing, internet of things and the application of new approaches from communication and information technologies in industrial production, possibilities for a networked production of different production technologies arise. Established approaches use manufacturing execution systems as local production coordination systems at workshop level without considering cross-site production or the integration of different stakeholders along the value chain of production. This paper presents an architectural concept, referred to as the ProducTron, for the digital integration of different manufacturing and common engineering modules for flexible distributed networked production as a possible basis for an Internet of Production.",2018 IEEE 22nd International Conference on Intelligent Engineering Systems (INES),2018
58d62b9b34922ac69f55ac3ce71bc02977712b15,https://www.semanticscholar.org/paper/58d62b9b34922ac69f55ac3ce71bc02977712b15,TEEMU MONONEN CLOUD COMPUTING IN A MACHINE AUTOMATION APPLICA- TION,"TEEMU MONONEN: Cloud computing in a machine automation application Tampere University of Technology Master of Science Thesis, 61 pages, 2 Appendix pages October 2017 Master’s Degree Programme in Automation Technology Major: Process Automation Examiners: Professor Jouni Mattila, professor Matti Vilkko",,2017
ed582c45eaf750844e20d897eea0a21869b5250f,https://www.semanticscholar.org/paper/ed582c45eaf750844e20d897eea0a21869b5250f,A low-cost cloud-extended sensor network for supervisory control,"The current automation supervisory control systems are situated in well-restricted areas and require investments in computing hardware and communication systems. In machine automation systems, any additional computing hardware can be cumbersome to install, making upgrades hard to apply. This paper presents a cloud-extended sensor network with supervisory control in a public cloud. The hardware and cloud resources used in the solution are low-cost, reducing the up-front costs compared to the use of high-end components. The system collects data from ST microprocessor (STM)-based sensor nodes that send inertial measurement data using user datagram protocol (UDP). The sensor itself is a Bosch BMI160, a cheap and small inertial measurement unit (IMU). The system is designed to be used in machine automation applications where the frequency of the sensory data produced is hundreds of hertz. The system is to provide low-latency data transfer to the cloud. In the cloud environment, data is collected by a computing service that can be programmed to perform algorithms on it. The system is tested in a setup consisting of five IMU sensors and an angle measurement unit attached to a hydraulically actuated flexible beam. The test setup aims to update a local control system's parameters based on a cloud algorithm and camera measurements of the beam tip position. The control results and communication latency are inspected. The main advantages of the proposed solution are the simple system architecture and cost savings with the use of low-cost sensors and cloud resources. The focus of this study is the functionality of such a system; intricate security issues are beyond the scope of this study.","2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)",2017
3ca4b4c0af085f15db533b80a50014b4fb0b65ff,https://www.semanticscholar.org/paper/3ca4b4c0af085f15db533b80a50014b4fb0b65ff,Robotic-Based Well-Being Monitoring and Coaching System for the Elderly in Their Daily Activities,"The increasingly ageing population and the tendency to live alone have led science and engineering researchers to search for health care solutions. In the COVID 19 pandemic, the elderly have been seriously affected in addition to suffering from isolation and its associated and psychological consequences. This paper provides an overview of the RobWell (Robotic-based Well-Being Monitoring and Coaching System for the Elderly in their Daily Activities) system. It is a system focused on the field of artificial intelligence for mood prediction and coaching. This paper presents a general overview of the initially proposed system as well as the preliminary results related to the home automation subsystem, autonomous robot navigation and mood estimation through machine learning prior to the final system integration, which will be discussed in future works. The main goal is to improve their mental well-being during their daily household activities. The system is composed of ambient intelligence with intelligent sensors, actuators and a robotic platform that interacts with the user. A test smart home system was set up in which the sensors, actuators and robotic platform were integrated and tested. For artificial intelligence applied to mood prediction, we used machine learning to classify several physiological signals into different moods. In robotics, it was concluded that the ROS autonomous navigation stack and its autodocking algorithm were not reliable enough for this task, while the robot’s autonomy was sufficient. Semantic navigation, artificial intelligence and computer vision alternatives are being sought.",Sensors,2021
4b2c19bd90efbb074be98c978afcb2ab2dcd9d48,https://www.semanticscholar.org/paper/4b2c19bd90efbb074be98c978afcb2ab2dcd9d48,Base Cube One: A location-addressable service-oriented smart environment framework,,J. Ambient Intell. Smart Environ.,2019
05754be85ae62c64bd963c8e4fcc6313842ffae7,https://www.semanticscholar.org/paper/05754be85ae62c64bd963c8e4fcc6313842ffae7,ROSmotic: A Scalable Smart Home for Blind People Controlled with an App,"In this paper we present ROSmotic, a system for building smart homes operated by a smartphone app. The app is accessible for people with visual disabilities, and controlled by touch or voice commands. We provide a scalable and open source hardware and software solution by incorporating microcontrollers, cameras, laptops, and lights. We show an easy way to connect an iOS app with Robotics Operating System (ROS). We incorporate other open source libraries, cloud services, and image processing frameworks. The whole system is made in Swift and Python. Finally, we deliver the diagrams (logical and electronic), software code, and materials for its easy replication.",,2017
0b7ae1046c68875634961a48e1c38dd34db9e8d6,https://www.semanticscholar.org/paper/0b7ae1046c68875634961a48e1c38dd34db9e8d6,SmartGreeting: A New Smart Home System Which Enables Context-Aware Services,"Home automation systems are expected to develop a new trend, as they embed new technologies and low-cost devices making them suitable for any budget. Nowadays, the researching efforts are dedicated to designing low-power and low-cost smart home systems that offer personalized services considering multiple scenarios that cover usual daily activities. The main goal of the paper is to analyse the digital output signal of passive infrared sensors used in a configuration of smart home entrance called SmartGreeting. The system can be used to enable personalized services in an entire smart home environment.",FABULOUS,2017
7965886a6e412c3216b018ca04e74e62cb101a1a,https://www.semanticscholar.org/paper/7965886a6e412c3216b018ca04e74e62cb101a1a,Plug and Play your Robot into your Smart Home: Illustration of a New Framework,"We present our team IHSEV, and our preliminary studies to tackle the question of interoperability of devices and robots for smart homes. We propose a framework enabling the seamless communication between smart home devices and robots. Our framework relies primarily on the xAAL protocol, which allows any device from any type to be plugged into a smart house network. We have recently extended xAAL to allow any ROS-compatible robot to be integrated into the smart house network. We illustrate the relevance of this framework in an implemented use case: assistance of an elderly person in the case of a fall (Fig. 1).",KI - Künstliche Intelligenz,2017
7e19b083ff8e3f5f963a1e06e90d0535ee66ded9,https://www.semanticscholar.org/paper/7e19b083ff8e3f5f963a1e06e90d0535ee66ded9,ROSmotic: A Scalable Smart Home for Blind People Controlled with an App,"In this paper we present ROSmotic, a system for building smart homes operated by a smartphone app. The app is accessible for people with visual disabilities, and controlled by touch or voice commands. We provide a scalable and open source hardware and software solution by incorporating microcontrollers, cameras, laptops, and lights. We show an easy way to connect an iOS app with Robotics Operating System (ROS). We incorporate other open source libraries, cloud services, and image processing frameworks. The whole system is made in Swift and Python. Finally, we deliver the diagrams (logical and electronic), software code, and materials for its easy replication.",2017 International Conference on Computational Science and Computational Intelligence (CSCI),2017
a5fdb910fe821aab3ef3b6119cbd6c20aa228872,https://www.semanticscholar.org/paper/a5fdb910fe821aab3ef3b6119cbd6c20aa228872,Simulating IoT Frameworks and Devices in the Smart Home,"The rapid growth of the Internet of Things (IoT) has led to a situation where individual manufacturers develop their own communication protocols and frameworks that are often incompatible with other systems. Part of this is due to the use of incompatible communication hardware, and part is due to the entrenched proprietary systems. This has created a heterogeneous communication landscape, where it is difficult for devices to coordinate their efforts. To remedy this, a number of IoT Frameworks have been proposed to provide a common interface between IoT devices. There are many approaches to common frameworks, each with their strengths and weaknesses, but there is no clear winner among them. This thesis presents a virtual network testbed for implementing smart home IoT Frameworks. It consists of a simulated home network made up of multiple Virtual Machines (VM), simulated smart home devices and an implementation of the OpenHAB framework to integrate the devices. Simulated devices are designed to be networkaccurate representations of actual devices, a LIFX smart lightbulb was developed and an existing Nest thermostat simulation was integrated. The demonstrated setup serves as a proof of concept for the idea of a home network testbed. Such a testbed could allow for the development of new IoT frameworks or the comparison of existing ones, and it could also serve as an education aid to illustrate how smart home IoT devices communicate with one another. Simulating IoT Frameworks and Devices in the smart home",,2017
beffbb5dad0ee0feb829a74471cb966022a6e84a,https://www.semanticscholar.org/paper/beffbb5dad0ee0feb829a74471cb966022a6e84a,The Assisted Living Project,,,2020
04c093777440b6ce378639e3d66e7afbcbbd87ee,https://www.semanticscholar.org/paper/04c093777440b6ce378639e3d66e7afbcbbd87ee,Variable Stiffness Mechanism for the Reduction of Cutting Forces in Robotic Deburring,"One of the main issues related to robotic deburring is that the tool can get damaged or stopped when the burr thickness exceeds a certain threshold. The aim of this work is to devise a mechanism that can reduce cutting forces automatically, in the event that the burr is too high, and is able to return to the baseline configuration when the burr thickness is acceptable again. On the one hand, in normal cutting conditions, the mechanism should have high stiffness to ensure high cutting precision. On the other hand, when the burr is too high the mechanism should exploit its compliance to reduce the cutting forces and, as a consequence, a second cutting cycle will be necessary to completely remove the burr. After the conceptual design of the mechanism and the specification of the desired stiffness curve, the main design parameters of the system are derived thanks to an optimization method. The effectiveness of the proposed mechanism is verified by means of dynamic simulations using selected test cases. A reduction up to 60% of the cutting forces is obtained, considering a steel burr up to 6 mm high.",,2021
332d9320506c0a418aff45366907b1d3e98cb67c,https://www.semanticscholar.org/paper/332d9320506c0a418aff45366907b1d3e98cb67c,Integration of Wireless Sensor Networks with the Smart City for Optimized Economic Management,,Wireless Personal Communications,2021
928f4600d204c1b9c143730f04e7aaf69bfcd34c,https://www.semanticscholar.org/paper/928f4600d204c1b9c143730f04e7aaf69bfcd34c,A fast robot path planning algorithm based on bidirectional associative learning,"Abstract Fast path planning in unknown environment is important to reduce the loss of human and material resources. To reduce planning time while obtaining a short path, this paper proposes a Bidirectional Associative Learning Algorithm (BALA). In the proposed algorithm, an episode is defined as a bidirectional movement between the start point and the target point. The planning process in the BALA is divided into three stages: early stage, medium stage and end stage. In the early stage, the attraction of the target point is adopted to instruct the robot to select action. This strategy not only helps the robot avoid blind search, but also provides the search scope that may contain the global shortest path for the subsequent episodes. In the medium stage, we propose an action selection strategy based on the experience guidance, where the experience obtained in the obverse and reverse movements is used alternately to improve the learning efficiency of the robot. In the end stage, a strong connectivity relationship between nodes is defined. Planning by this relationship, the length of the final planned path will be the shortest based on the experience the robot obtains. The comparison results with Q-Learning and its improved algorithm reveal that the BALA demonstrates desirable and stable performance in planning efficiency in any environment, and it can well balance the planning time and path length. Additionally, the practicability of the proposed algorithm is validated on Turtlebot3 burger robot.",Comput. Ind. Eng.,2021
acb75001a27047e249704fce1efaa6396d922f24,https://www.semanticscholar.org/paper/acb75001a27047e249704fce1efaa6396d922f24,Flying Through a Narrow Gap Using End-to-end Deep Reinforcement Learning Augmented with Curriculum Learning and Sim2Real,"Traversing through a tilted narrow gap is previously an intractable task for reinforcement learning mainly due to two challenges. First, searching feasible trajectories is not trivial because the goal behind the gap is difficult to reach. Second, the error tolerance after Sim2Real is low due to the relatively high speed in comparison to the gap's narrow dimensions. This problem is aggravated by the intractability of collecting real-world data due to the risk of collision damage. In this brief, we propose an end-to-end reinforcement learning framework that solves this task successfully by addressing both problems. To search for dynamically feasible flight trajectories, we use a curriculum learning to guide the agent toward the sparse reward behind the obstacle. To tackle the Sim2Real problem, we propose a Sim2Real framework that can transfer control commands to a real quadrotor without using real flight data. To the best of our knowledge, our brief is the first work that accomplishes successful gap traversing task purely using deep reinforcement learning.",IEEE transactions on neural networks and learning systems,2021
c3269b0f710a9838013228bb81179c1ad3382872,https://www.semanticscholar.org/paper/c3269b0f710a9838013228bb81179c1ad3382872,Deep deterministic policy gradient algorithm for crowd-evacuation path planning,"Abstract In existing evacuation methods, the large number of pedestrians and the complex environment will affect the efficiency of evacuation. Therefore, we propose a hierarchical evacuation method based on multi-agent deep reinforcement learning (MADRL) to solve the above problem. First, we use a two-level evacuation mechanism to guide evacuations, the crowd is divided into leaders and followers. Second, in the upper level, leaders perform path planning to guide the evacuation. To obtain the best evacuation path, we propose the efficient multi-agent deep deterministic policy gradient (E-MADDPG) algorithm for crowd-evacuation path planning. E-MADDPG algorithm combines learning curves to improve the fixed experience pool of MADDPG algorithm and uses high-priority experience playback strategy to improve the sampling strategy. The improvement increases the learning efficiency of the algorithm. Meanwhile we extract pedestrian motion trajectories from real motion videos to reduce the state space of algorithm. Third, in the bottom layer, followers use the relative velocity obstacle (RVO) algorithm to avoid collisions and follow leaders to evacuate. Finally, experimental results illustrate that the E-MADDPG algorithm can improve path planning efficiency, while the proposed method can improve the efficiency of crowd evacuation.",Comput. Ind. Eng.,2021
ef2fb679c9c8041bb995be50a117d560babecc1f,https://www.semanticscholar.org/paper/ef2fb679c9c8041bb995be50a117d560babecc1f,Time-Aware and Temperature-Aware Fire Evacuation Path Algorithm in IoT-Enabled Multi-Story Multi-Exit Buildings,"Temperature sensors with a communication capability can help monitor and report temperature values to a control station, which enables dynamic and real-time evacuation paths in fire emergencies. As compared to traditional approaches that identify a one-shot fire evacuation path, in this paper, we develop an intelligent algorithm that can identify time-aware and temperature-aware fire evacuation paths by considering temperature changes at different time slots in multi-story and multi-exit buildings. We first propose a method that can map three-dimensional multi-story multi-exit buildings into a two-dimensional graph. Then, a mathematical optimization model is proposed to capture this time-aware and temperature-aware evacuation path problem in multi-story multi-exit buildings. Six fire evacuation algorithms (BFS, SP, DBFS, TABFS, TASP and TADBFS) are proposed to identify the efficient evacuation path. The first three algorithms that do not address human temperature limit constraints can be used by rescue robots or firemen with fire-proof suits. The last three algorithms that address human temperature limit constraints can be used by evacuees in terms of total time slots and total temperature on the evacuation path. In the computational experiments, the open space building and the Taipei 101 Shopping Mall are all tested to verify the solution quality of these six algorithms. From the computational results, TABFS, TASP and TADBF identify almost the same evacuation path in open space building and the Taipei 101 Shopping Mall. BFS, SP DBFS can locate marginally better results in terms of evacuation time and total temperature on the evacuation path. When considering evacuating a group of evacuees, the computational time of the evacuation algorithm is very important in a time-limited evacuation process. Considering the extreme case of seven fires in eight emergency exits in the Taipei 101 Shopping Mall, the golden window for evacuation is 15 time slots. Only TABFS and TADBFS are applicable to evacuate 1200 people in the Taipei 101 Shopping Mall when one time slot is setting as one minute. The computational results show that the capacity limit for the Taipei 101 Shopping Mall is 800 people in the extreme case of seven fires. In this case, when the number of people in the building is less than 700, TADBFS should be adopted. When the number of people in the building is greater than 700, TABFS can evacuate more people than TADBFS. Besides identifying an efficient evacuation path, another significant contribution of this paper is to identify the best sensor density deployment at large buildings like the Taipei 101 Shopping Mall in considering the fire evacuation.",Sensors,2020
093972ac9b1968dc65a4949b2336d718a1141c66,https://www.semanticscholar.org/paper/093972ac9b1968dc65a4949b2336d718a1141c66,Deep Reinforcement Learning by Balancing Offline Monte Carlo and Online Temporal Difference Use Based on Environment Experiences,"Owing to the complexity involved in training an agent in a real-time environment, e.g., using the Internet of Things (IoT), reinforcement learning (RL) using a deep neural network, i.e., deep reinforcement learning (DRL) has been widely adopted on an online basis without prior knowledge and complicated reward functions. DRL can handle a symmetrical balance between bias and variance—this indicates that the RL agents are competently trained in real-world applications. The approach of the proposed model considers the combinations of basic RL algorithms with online and offline use based on the empirical balances of bias–variance. Therefore, we exploited the balance between the offline Monte Carlo (MC) technique and online temporal difference (TD) with on-policy (state-action–reward-state-action, Sarsa) and an off-policy (Q-learning) in terms of a DRL. The proposed balance of MC (offline) and TD (online) use, which is simple and applicable without a well-designed reward, is suitable for real-time online learning. We demonstrated that, for a simple control task, the balance between online and offline use without an on- and off-policy shows satisfactory results. However, in complex tasks, the results clearly indicate the effectiveness of the combined method in improving the convergence speed and performance in a deep Q-network.",Symmetry,2020
0d67fc59e69f44bed80a8afad1e5547dc98bab05,https://www.semanticscholar.org/paper/0d67fc59e69f44bed80a8afad1e5547dc98bab05,Deep reinforcement learning with a particle dynamics environment applied to emergency evacuation of a room with obstacles,"A very successful model for simulating emergency evacuation is the social-force model. At the heart of the model is the self-driven force that is applied to an agent and is directed towards the exit. However, it is not clear if the application of this force results in optimal evacuation, especially in complex environments with obstacles. Here, we develop a deep reinforcement learning algorithm in association with the social force model to train agents to find the fastest evacuation path. During training, we penalize every step of an agent in the room and give zero reward at the exit. We adopt the Dyna-Q learning approach. We first show that in the case of a room without obstacles the resulting self-driven force points directly towards the exit as in the social force model and that the median exit time intervals calculated using the two methods are not significantly different. Then, we investigate evacuation of a room with one obstacle and one exit. We show that our method produces similar results with the social force model when the obstacle is convex. However, in the case of concave obstacles, which sometimes can act as traps for agents governed purely by the social force model and prohibit complete room evacuation, our approach is clearly advantageous since it derives a policy that results in object avoidance and complete room evacuation without additional assumptions. We also study evacuation of a room with multiple exits. We show that agents are able to evacuate efficiently from the nearest exit through a shared network trained for a single agent. Finally, we test the robustness of the Dyna-Q learning approach in a complex environment with multiple exits and obstacles. Overall, we show that our model can efficiently simulate emergency evacuation in complex environments with multiple room exits and obstacles where it is difficult to obtain an intuitive rule for fast evacuation.",ArXiv,2020
1d2b00b522b51ab558d288d33bb234cdd7c8a4f3,https://www.semanticscholar.org/paper/1d2b00b522b51ab558d288d33bb234cdd7c8a4f3,Metis: Multi-Agent Based Crisis Simulation System,"With the advent of the computational technologies (Graphics Processing Units - GPUs) and Machine Learning, the research domain of crowd simulation for crisis management has flourished. Along with the new techniques and methodologies that have been proposed all those years, aiming to increase the realism of crowd simulation, several crisis simulation systems/tools have been developed, but most of them focus on special cases without providing users the ability to adapt them based on their needs. Towards these directions, in this paper, we introduce a novel multi-agent-based crisis simulation system for indoor cases. The main advantage of the system is its ease of use feature, focusing on non-expert users (users with little to no programming skills) that can exploit its capabilities a, adapt the entire environment based on their needs (Case studies) and set up building evacuation planning experiments with some of the most popular Reinforcement Learning algorithms. Simply put, the system's features focus on dynamic environment design and crisis management, interconnection with popular Reinforcement Learning libraries, agents with different characteristics (behaviors), fire propagation parameterization, realistic physics based on popular game engine, GPU-accelerated agents training and simulation end conditions. A case study exploiting a popular reinforcement learning algorithm, for training of the agents, presents the dynamics and the capabilities of the proposed systems and the paper is concluded with the highlights of the system and some future directions.",SETN Workshops,2020
57d2c1c4d43b98e703ab816539b7f094817e9d36,https://www.semanticscholar.org/paper/57d2c1c4d43b98e703ab816539b7f094817e9d36,Dynamic Topology Model of Q-Learning LEACH Using Disposable Sensors in Autonomous Things Environment,"Low-Energy Adaptive Clustering Hierarchy (LEACH) is a typical routing protocol that effectively reduces transmission energy consumption by forming a hierarchical structure between nodes. LEACH on Wireless Sensor Network (WSN) has been widely studied in the recent decade as one key technique for the Internet of Things (IoT). The main aims of the autonomous things, and one of advanced of IoT, is that it creates a flexible environment that enables movement and communication between objects anytime, anywhere, by saving computing power and utilizing efficient wireless communication capability. However, the existing LEACH method is only based on the model with a static topology, but a case for a disposable sensor is included in an autonomous thing’s environment. With the increase of interest in disposable sensors which constantly change their locations during the operation, dynamic topology changes should be considered in LEACH. This study suggests the probing model for randomly moving nodes, implementing a change in the position of a node depending on the environment, such as strong winds. In addition, as a method to quickly adapt to the change in node location and construct a new topology, we propose Q-learning LEACH based on Q-table reinforcement learning and Fuzzy-LEACH based on Fuzzifier method. Then, we compared the results of the dynamic and static topology model with existing LEACH on the aspects of energy loss, number of alive nodes, and throughput. By comparison, all types of LEACH showed sensitivity results on the dynamic location of each node, while Q-LEACH shows best performance of all.",Applied Sciences,2020
697bf703d5dd23d17274d55b6dc96af4cef0ea90,https://www.semanticscholar.org/paper/697bf703d5dd23d17274d55b6dc96af4cef0ea90,Crowd simulation for crisis management: the outcomes of the last decade,"The last few decades, crowd simulation for crisis management is highlighted as an important topic of interest for many scientific fields. As the continues evolution of computational resources increases, along with the capabilities of Artificial Intelligence, the demand for better and more realistic simulation has become more attractive and popular to scientists. Along those years, there have been published hundreds of research articles and have been created numerous different systems that aim to simulate crowd behaviors, crisis cases and emergency evacuation scenarios. For better outcomes, recent research has focused on the separation of the problem of crisis management, to multiple research sub-fields (categories), such as the navigation of the simulated pedestrians, their psychology, the group dynamics etc. There have been extended research works suggesting new methods and techniques for those categories of problems. In this paper, we propose three main research categories, each one consist of several sub-categories, relying on crowd simulation for crisis management aspects and we present the outcomes of the last decade, focusing mostly on works exploiting multi-agent technologies. We analyze a number of technologies, methodologies, techniques, tools and systems introduced throughout the last years. A comparative review and discussion of the proposed categories is presented towards the identification of the most efficient aspects of the proposed categories. A general framework, towards the future crowd simulation for crisis management is presented based on the most efficient to yield the most realistic outcomes of the last decades. The paper is concluded with some highlights and open questions for future directions.",ArXiv,2020
bfa4c82684d72c399b7d2c0fc2e340eb80e80487,https://www.semanticscholar.org/paper/bfa4c82684d72c399b7d2c0fc2e340eb80e80487,A Review of AI and AI Intelligence Assessment,"The design and application of AI systems have witnessed rapid development in various fields over a period of three scores, accompanied by researcher’s increasing interest in developing a more intelligent and humanoid AI system. Naturally, it becomes more essential to assess the intelligence of AI objectively and quantitatively, as related researches are still limited and the quantitative methods lack. In this paper, we first comprehensively review the current studies on AI systems, and conclude that these studies could be classified into two groups, i.e. the design as well as development of AI systems and the intelligence assessment of AI. Reviews finds the need and urgency for the quantitative intelligence assessment methods for AI. We also believe that a more efficient assessment method is to establish an index system to estimate and score the intelligence level of AI quantitatively.",2020 IEEE 4th Conference on Energy Internet and Energy System Integration (EI2),2020
cbc2813c8011edc36b4ed6bf18556f13a202076d,https://www.semanticscholar.org/paper/cbc2813c8011edc36b4ed6bf18556f13a202076d,Applications of artificial intelligence for disaster management,"Natural hazards have the potential to cause catastrophic damage and significant socioeconomic loss. The actual damage and loss observed in the recent decades has shown an increasing trend. As a result, disaster managers need to take a growing responsibility to proactively protect their communities by developing efficient management strategies. A number of research studies apply artificial intelligence (AI) techniques to process disaster-related data for supporting informed disaster management. This study provides an overview of current applications of AI in disaster management during its four phases: mitigation, preparedness, response, and recovery. It presents example applications of different AI techniques and their benefits for supporting disaster management at different phases, as well as some practical AI-based decision support tools. We find that the majority of AI applications focus on the disaster response phase. This study also identifies challenges to inspire the professional community to advance AI techniques for addressing them in future research.",Natural Hazards,2020
ebf2c63244c39b0df7862ecca771d5f5092b7c6f,https://www.semanticscholar.org/paper/ebf2c63244c39b0df7862ecca771d5f5092b7c6f,A Review of Deep Reinforcement Learning Algorithms and Comparative Results on Inverted Pendulum System,"The control of inverted pendulum problem that is one of the classical control problems is important for many areas from autonomous vehicles to robotic. This chapter presents the usage of the deep reinforcement learning algorithms to control the cart-pole balancing problem. The first part of the chapter reviews the theories of deep reinforcement learning methods such as Deep Q Networks (DQN), DQN with Prioritized Experience Replay (DQN+PER), Double DQN (DDQN), Double Dueling Deep-Q Network (D3QN), Reinforce, Asynchronous Advanced Actor Critic Asynchronous (A3C) and Synchronous Advantage Actor-Critic (A2C). Then, the cart-pole balancing problem in OpenAI Gym environment is considered to implement the deep reinforcement learning methods. Finally, the performance of all methods are comparatively given on the cart-pole balancing problem. The results are presented by tables and figures.",,2020
0a2a1f0248288b45fc6189a52faa55d834bd1a52,https://www.semanticscholar.org/paper/0a2a1f0248288b45fc6189a52faa55d834bd1a52,Effect machine learning techniques for analyzing and filtering spam Mails problems,"The increase in spam and unwanted emails and messages has increased dramatically over the few past years to overcome this problem the need to develop more reliable and more powerful anti-spam filters. Modern machine learning techniques are applied to identify and filter spam messages. The research provide a symbolic review of different automated, learning-based spam filtering methods. This test provides details of the key concepts in spam filtering, testing, productivity, and search directions. The first discussion behind the study detect the application of machine learning approaches to the spam filtering methods for leading Internet service providers, such as spam filters in Gmail, Yahoo and Outlook. In this paper we provide the experiments about the normal spam filtering process and different work of researchers in finding spam using efficient ML techniques. Our research compares strengths and faults in current machine learning methods and clear research issues in spam filtering. We recommend in-depth and in-depth learning as future technologies that can accurately address the threat of spam. The necessity of effective spam filters increases. In this research, we also applied an efficient spam filter approaches to spam emails and messages based on Machine learning techniques such as Neural networks to remove the unwanted messages or raw data. The Neural Network Filtering feature evaluates the likelihood of different words appearing in Legitimate and spam mails and classifies them according to these possibilities.",,2021
1d08c1bbcb45ee060f2e923810f434b19ea7e262,https://www.semanticscholar.org/paper/1d08c1bbcb45ee060f2e923810f434b19ea7e262,Formally Identifying COVID-19 Patients for Providing Medical Services using Drones,"The Internet of Things (IoT) is an emerging technology that allows connecting physical devices that are linked to the internet across the world to communicate and share information. Drones are flying objects without any human pilot. In many countries, drones are being used for the fast delivery of packages or products. Nowadays the whole world is fighting against the COVID-19 pandemic which is a viral disease that can be spread by the interaction of people. To fight against this pandemic, the drone's technology can be very effective to minimize the interaction of people. There exists little research work in this area because this virus has been introduced recently in 2019. In this paper, we have proposed an IoT-based model in which wearable sensors are used that will be able to identify COVID-19 patients by monitoring the temperature and respiratory system of the people. After confirmation of identification, the control room will send an alert message and sends medical kits to the residence of the patient through drones. The UML (Unified Modeling Language) is used for the representation and flow of the system. models of the proposed system is specified using Vienna Development Method-Specification language (VDM-SL). VDM-SL toolbox is used to ensure the correctness of the models.",2021 International Conference of Women in Data Science at Taif University (WiDSTaif ),2021
34dc11193cc801215bed0053788339a14cd86287,https://www.semanticscholar.org/paper/34dc11193cc801215bed0053788339a14cd86287,A Software Engineering Perspective on Engineering Machine Learning Systems: State of the Art and Challenges,"Context: Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems. Objective: The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems. Method: I performed a systematic literature review (SLR). I systematically selected a pool of 65 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies. Results: The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions. Conclusion: The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.",J. Syst. Softw.,2020
8e3d925d65bfc3f39c54db1c167c98e646b533bd,https://www.semanticscholar.org/paper/8e3d925d65bfc3f39c54db1c167c98e646b533bd,A Holistic Framework for AI Systems in Industrial Applications,"Although several promising use cases for artificial intelligence (AI) for manufacturing companies have been identified, these are not yet widely used. Existing literature covers a variety of frameworks, methods and processes related to AI systems. However, the application of AI systems in manufacturing companies lacks a uniform understanding of components and functionalities as well as a structured process that supports developers and project managers in planning, implementing, and optimizing AI systems. To close this gap, we develop a generic conceptual model of an AI system for the application in manufacturing systems and a four-phase model to guide developers and project managers through the realization of AI systems.",Lecture Notes in Information Systems and Organisation,2021
95d94b767b0bcd94dd5fd725892ecb3a2dfcccbe,https://www.semanticscholar.org/paper/95d94b767b0bcd94dd5fd725892ecb3a2dfcccbe,The Statistical Learning Methods In image processing and Facial Recognition,"The aim of this paper is to develop a new approach for The Statistical Learning Methods in image processing and Facial Recognition using the deep learning techniques in python. In the recent years there have been significant advances in face recognition by using deep neural networks. One of the potential next steps is to develop optimized 3D facial recognition. Shifting from 2D to 3D increases complexity of the problem by adding an- other dimension to data, making possible solutions more resource hungry. We will investigate different depth camera based facial recognition techniques and test their performance by deploying them on an embedded processor. We focus on applications for embedded systems and use a small low-resolution time of flight (ToF) camera with our system to keep overall system portable and compact. All faces images are then projected on the feature space (“face space”) to find the corresponding coordinators. The face space is composed of “Eigenfaces” or “Fisherfaces” which are actually eigenvectors found after doing a matrix composition - Eigen decomposition. At the heart of Eigenface method is the Principal Component Analysis (PCA) - one of the most popular unsupervised learning algorithms - while Fisherface is a better version of the previous one which makes use of both Principal Component Analysis and Linear Discrimination Analysis (LDA) to get more reliable results. The algorithms were realized by Python in Anaconda. Given initial images in the database, the program can detect and recognize the human faces in the provided pictures before saving them in the database to improve the calculation accuracy in the future. After evaluation, the recognition general results are exported on the screen with details included in the text files.",The 7th International Conference on Engineering & MIS 2021,2021
51aa8666612bc6280b843b6cf60fa567c457e1e4,https://www.semanticscholar.org/paper/51aa8666612bc6280b843b6cf60fa567c457e1e4,Corrections to “A Novel Software Engineering Approach Toward Using Machine Learning for Improving the Efficiency of Health Systems“,"In the above article <xref ref-type=""bibr"" rid=""ref1"">[1]</xref>, two sentence in Section III and Section IV contained errors.",IEEE Access,2020
52318400d8a1c0530670c3095c40eeef982410c4,https://www.semanticscholar.org/paper/52318400d8a1c0530670c3095c40eeef982410c4,Characterization of complex fluvio–deltaic deposits in Northeast China using multi-modal machine learning fusion,"Due to the lack of petroleum resources, stratigraphic reservoirs have become an important source of future discoveries. We describe a methodology for predicting reservoir sands from complex reservoir seismic data. Data analysis involves a bio-integrated framework called multi-modal machine learning fusion (MMMLF) based on neural networks. First, acoustic-related seismic attributes from post-stack seismic data were used to characterize the reservoirs. They enhanced the understanding of the structure and spatial distribution of petrophysical properties of lithostratigraphic reservoirs. The attributes were then classified as varied modal inputs into a central fusion engine for prediction. We applied the method to a dataset from Northeast China. Using seismic attributes and rock physics relationships as input data, MMMLF was performed to predict the spatial distribution of lithology in the Upper Guantao substrata. Despite the large scattering in the acoustic-related data properties, the proposed MMMLF methodology predicted the distribution of lithological properties through the gamma ray logs. Moreover, complex stratigraphic traps such as braided fluvial sandstones in the fluvio–deltaic deposits were delineated. These findings can have significant implications for future exploration and production in Northeast China and similar petroleum provinces around the world.",Scientific Reports,2020
2a36402451c4fcab33c9e7f59fc027167c070aa6,https://www.semanticscholar.org/paper/2a36402451c4fcab33c9e7f59fc027167c070aa6,Perfection Not Required? Human-AI Partnerships in Code Translation,"Generative models have become adept at producing artifacts such as images, videos, and prose at human-like levels of proficiency. New generative techniques, such as unsupervised neural machine translation (NMT), have recently been applied to the task of generating source code, translating it from one programming language to another. The artifacts produced in this way may contain imperfections, such as compilation or logical errors. We examine the extent to which software engineers would tolerate such imperfections and explore ways to aid the detection and correction of those errors. Using a design scenario approach, we interviewed 11 software engineers to understand their reactions to the use of an NMT model in the context of application modernization, focusing on the task of translating source code from one language to another. Our three-stage scenario sparked discussions about the utility and desirability of working with an imperfect AI system, how acceptance of that system’s outputs would be established, and future opportunities for generative AI in application modernization. Our study highlights how UI features such as confidence highlighting and alternate translations help software engineers work with and better understand generative NMT models.",IUI,2021
767b5e373facf6c1ddd30e0b45b3720beb83cb9c,https://www.semanticscholar.org/paper/767b5e373facf6c1ddd30e0b45b3720beb83cb9c,Generative Adversarial Networks–Enabled Human–Artificial Intelligence Collaborative Applications for Creative and Design Industries: A Systematic Review of Current Approaches and Trends,"The future of work and workplace is very much in flux. A vast amount has been written about artificial intelligence (AI) and its impact on work, with much of it focused on automation and its impact in terms of potential job losses. This review will address one area where AI is being added to creative and design practitioners’ toolbox to enhance their creativity, productivity, and design horizons. A designer’s primary purpose is to create, or generate, the most optimal artifact or prototype, given a set of constraints. We have seen AI encroaching into this space with the advent of generative networks and generative adversarial networks (GANs) in particular. This area has become one of the most active research fields in machine learning over the past number of years, and a number of these techniques, particularly those around plausible image generation, have garnered considerable media attention. We will look beyond automatic techniques and solutions and see how GANs are being incorporated into user pipelines for design practitioners. A systematic review of publications indexed on ScienceDirect, SpringerLink, Web of Science, Scopus, IEEExplore, and ACM DigitalLibrary was conducted from 2015 to 2020. Results are reported according to PRISMA statement. From 317 search results, 34 studies (including two snowball sampled) are reviewed, highlighting key trends in this area. The studies’ limitations are presented, particularly a lack of user studies and the prevalence of toy-examples or implementations that are unlikely to scale. Areas for future study are also identified.",Frontiers in Artificial Intelligence,2021
7f4d129454480cea7683c5ed610c128876b6e12f,https://www.semanticscholar.org/paper/7f4d129454480cea7683c5ed610c128876b6e12f,Technology enablers for the implementation of Industry 4.0 to traditional manufacturing sectors: A review,"The traditional manufacturing sectors (footwear, textiles and clothing, furniture and toys, among others) are based on small and medium enterprises with limited capacity on investing in modern production technologies. Although these sectors rely heavily on product customization and short manufacturing cycles, they are still not able to take full advantage of the fourth industrial revolution. Industry 4.0 surfaced to address the current challenges of shorter product life-cycles, highly customized products and stiff global competition. The new manufacturing paradigm supports the development of modular factory structures within a computerized Internet of Things environment. With Industry 4.0, rigid planning and production processes can be revolutionized. However, the computerization of manufacturing has a high degree of complexity and its implementation tends to be expensive, which goes against the reality of SMEs that power the traditional sectors. This paper reviews the main scientific-technological advances that have been developed in recent years in traditional sectors with the aim of facilitating the transition to the new industry standard.",Comput. Ind.,2021
bcf6f6e1d959a713347c8114f671cd0f46205a1e,https://www.semanticscholar.org/paper/bcf6f6e1d959a713347c8114f671cd0f46205a1e,fAshIon after fashion: A Report of AI in Fashion,"In this independent report fAshIon after fashion, we examine the development of fAshIon (artificial intelligence (AI) in fashion) and explore its potentiality to become a major disruptor of the fashion industry in the near future. To do this, we investigate AI technologies used in the fashion industry – through several lenses. We summarise fAshIon studies conducted over the past decade and categorise them into seven groups: Overview, Evaluation, Basic Tech, Selling, Styling, Design, and Buying. The datasets mentioned in fAshIon research have been consolidated on one GitHub page for ease of use1. We analyse the authors’ backgrounds and the geographic regions treated in these studies to determine the landscape of fAshIon research. The results of our analysis are presented with an aim to provide researchers with a holistic view of research in fAshIon. As part of our primary research, we also review a wide range of cases of applied fAshIon in the fashion industry and analyse their impact on the industry, markets and individuals. We also identify the challenges presented by fAshIon and suggest that these may form the basis for future research. We finally exhibit that many potential opportunities exist for the use of AI in fashion which can transform the fashion industry embedded with AI technologies and boost profits.",ArXiv,2021
1275fef18dd3ec48f15e3a7d24fc364c623f454a,https://www.semanticscholar.org/paper/1275fef18dd3ec48f15e3a7d24fc364c623f454a,Transfer Learning-enabled Action Recognition for Human-robot Collaborative Assembly,,Procedia CIRP,2021
24e1efd8d7360c01fe46d1b8a11bd17d3e8ae3b0,https://www.semanticscholar.org/paper/24e1efd8d7360c01fe46d1b8a11bd17d3e8ae3b0,Towards scalable and reusable predictive models for cyber twins in manufacturing systems,"Smart factories are intelligent, fully-connected and flexible systems that can continuously monitor and analyse data streams from interconnected systems to make decisions and dynamically adapt to new circumstances. The implementation of smart factories represents a leap forward compared to traditional automation. It is underpinned by the deployment of cyberphysical systems that, through the application of Artificial Intelligence, integrate predictive capabilities and foster rapid decision-making. Deep Learning (DL) is a key enabler for the development of smart factories. However, the implementation of DL in smart factories is hindered by its reliance on large amounts of data and extreme computational demand. To address this challenge, Transfer Learning (TL) has been proposed to promote the efficient training of models by enabling the reuse of previously trained models. In this paper, by means of a specific example in aluminium can manufacturing, an empirical study is presented, which demonstrates the potential of TL to achieve fast deployment of scalable and reusable predictive models for Cyber Manufacturing Systems. Through extensive experiments, the value of TL is demonstrated to achieve better generalisation and model performance, especially with limited datasets. This research provides a pragmatic approach towards predictive model building for cyber twins, paving the way towards the realisation of smart factories.",Journal of Intelligent Manufacturing,2021
75a8e87db58d76c19c476588c4774ac0ec4006d2,https://www.semanticscholar.org/paper/75a8e87db58d76c19c476588c4774ac0ec4006d2,A Time-Series Data Generation Method to Predict Remaining Useful Life,"Accurate predictions of remaining useful life (RUL) of equipment using machine learning (ML) or deep learning (DL) models that collect data until the equipment fails are crucial for maintenance scheduling. Because the data are unavailable until the equipment fails, collecting sufficient data to train a model without overfitting can be challenging. Here, we propose a method of generating time-series data for RUL models to resolve the problems posed by insufficient data. The proposed method converts every training time series into a sequence of alphabetical strings by symbolic aggregate approximation and identifies occurrence patterns in the converted sequences. The method then generates a new sequence and inversely transforms it to a new time series. Experiments with various RUL prediction datasets and ML/DL models verified that the proposed data-generation model can help avoid overfitting in RUL prediction model.",Processes,2021
761c741bec25b8455f738c02ead75a6de4e04475,https://www.semanticscholar.org/paper/761c741bec25b8455f738c02ead75a6de4e04475,Making costly manufacturing smart with transfer learning under limited data: A case study on composites autoclave processing,"Abstract The integration of advanced manufacturing processes with ground-breaking Artificial Intelligence methods continue to provide unprecedented opportunities towards modern cyber-physical manufacturing processes, known as smart manufacturing or Industry 4.0. However, the “smartness” level of such approaches closely depends on the degree to which the implemented predictive models can handle uncertainties and production data shifts in the factory over time. In the case of change in a manufacturing process configuration with no sufficient new data, conventional Machine Learning (ML) models often tend to perform poorly. In this article, a transfer learning (TL) framework is proposed to tackle the aforementioned issue in modeling smart manufacturing. Namely, the proposed TL framework is able to adapt to probable shifts in the production process design and deliver accurate predictions without the need to re-train the model. Armed with sequential unfreezing and early stopping methods, the model demonstrated the ability to avoid catastrophic forgetting in the presence of severely limited data. Through the exemplified industry-focused case study on autoclave composite processing, the model yielded a drastic (88%) improvement in the generalization accuracy compared to the conventional learning, while reducing the computational and temporal cost by 56%.",,2021
be3291e6a234be03e05110af00c1d57c552b7e75,https://www.semanticscholar.org/paper/be3291e6a234be03e05110af00c1d57c552b7e75,Compressing Biosignal for Diagnosing Chronic Diseases,"Electrocardiogram, electromyogram, electroencephalogram are the foremost required vital signs for diagnosing chronic diseases like sleep disorder, mood disorder, epilepsy etc., which demands long-term monitoring. A sensor based wearable system which is enabled with internet technology, supports the continuous recordings of these vital signs without troubling the patient’s daily activities. And the wearable hub is responsible for collecting the readings of bio signals from multiple micro-sensor nodes deployed around the body which creates the short range of communication and forward to the observer. These continuous monitoring increases the signal transmission cost and declines the battery life of wearables. So, the observed multiple bio signals can be compressed jointly than individually before sending, at an edge level. This paper proposes transfer learning based multimodal convolutional denoising autoencoder to perform multimodal compression and to reconstruct the data from its latent representation. Transfer learning helps the system to reuse the learned weights which may reconstruct the data with better quality score than by randomly initialized weights. The proposed work achieves compression ratio of 128 and it is proved that multimodal compression is better than unimodal compression in case of consuming multiple sensors. And the experimental result proves that the computation cost is low in multimodal compression than in unimodal compression.",Journal of Physics: Conference Series,2021
d3ce1f9ce96dc130bcd5f8e170455ed401079f68,https://www.semanticscholar.org/paper/d3ce1f9ce96dc130bcd5f8e170455ed401079f68,Internet of things-based automation design and organizational innovation of manufacturing enterprises,,Materials Today: Proceedings,2021
ea5eaf8834e9db6349d27520b00eae65ec5a284c,https://www.semanticscholar.org/paper/ea5eaf8834e9db6349d27520b00eae65ec5a284c,Image classification method on class imbalance datasets using multi-scale CNN and two-stage transfer learning,,Neural Comput. Appl.,2021
f5255357b82adb03c6c6729fc939bd1b82b22a02,https://www.semanticscholar.org/paper/f5255357b82adb03c6c6729fc939bd1b82b22a02,A weighted fuzzy C-means clustering method with density peak for anomaly detection in IoT-enabled manufacturing process,"Accurate anomaly detection is the premise of production process control and normal execution of production plan. The implementation of Internet of Things (IoT) provides data foundation and guarantee for real-time perception and detection of production state. Taking abundant IoT data as support, a density peak (DP)-weighted fuzzy C-means (WFCM) based clustering method is proposed to detect abnormal situations in production process. Firstly, a features correlation and redundancy measure method based on mutual information (MI) and conditional MI is proposed, unsupervised feature reduction is completed based on the principle of maximum correlation-minimum redundancy. Secondly, a DP-WFCM based clustering model is established to identify clusters with fewer samples to detect production anomalies. DP is used to obtain the initial clustering centers to solve the problem that FCM is sensitive to the initial centers and the clusters number needs to be determined manually in advance. MI-based similarities are introduced as weight coefficients to guide the clustering process, which improves convergence speed and clustering quality. Finally, a real case from an IoT enabled machining workshop is carried out to verify the accuracy and effectiveness of the proposed method in anomaly detection of manufacturing process.",J. Intell. Manuf.,2020
63b90ba84e6c881166085bf2e838a7fc84428904,https://www.semanticscholar.org/paper/63b90ba84e6c881166085bf2e838a7fc84428904,"Industrial Artificial Intelligence in Industry 4.0 - Systematic Review, Challenges and Outlook","The advent of the Industry 4.0 initiative has made it so that manufacturing environments are becoming more and more dynamic, connected but also inherently more complex, with additional inter-dependencies, uncertainties and large volumes of data being generated. Recent advances in Industrial Artificial Intelligence have showcased the potential of this technology to assist manufacturers in tackling the challenges associated with this digital transformation of Cyber-Physical Systems, through its data-driven predictive analytics and capacity to assist decision-making in highly complex, non-linear and often multistage environments. However, the industrial adoption of such solutions is still relatively low beyond the experimental pilot stage, as real environments provide unique and difficult challenges for which organizations are still unprepared. The aim of this paper is thus two-fold. First, a systematic review of current Industrial Artificial Intelligence literature is presented, focusing on its application in real manufacturing environments to identify the main enabling technologies and core design principles. Then, a set of key challenges and opportunities to be addressed by future research efforts are formulated along with a conceptual framework to bridge the gap between research in this field and the manufacturing industry, with the goal of promoting industrial adoption through a successful transition towards a digitized and data-driven company-wide culture. This paper is among the first to provide a clear definition and holistic view of Industrial Artificial Intelligence in the Industry 4.0 landscape, identifying and analysing its fundamental building blocks and ongoing trends. Its findings are expected to assist and empower researchers and manufacturers alike to better understand the requirements and steps necessary for a successful transition into Industry 4.0 supported by AI, as well as the challenges that may arise during this process.",IEEE Access,2020
6e45e67526554fcbc75efee6eed5f2dabcb79fa3,https://www.semanticscholar.org/paper/6e45e67526554fcbc75efee6eed5f2dabcb79fa3,The Spatio-Temporal Modeling and Integration of Manufacturing Big Data in Job Shop: An Ontology-Based Approach,"Manufacturing big data provide the factory with a tremendous opportunity for transforming the current manufacturing paradigm to smart manufacturing. However, the multi-source data modeling and integration problems are the existing gaps between the collected big data and the data-driven smart applications. With the large-scale deployment of Internet of things on the shop floor, it is essential to develop adequate data modeling and integration methods to manage and organize the generated manufacturing big data. In this study, the spatiotemporal modeling is firstly presented to organize the data in temporal, spatial and attributive dimensions respectively. Furthermore, the ontology-based big data integration approach is proposed to manage the multisource manufacturing data and ensure the data can be easily indexed and conveniently reused for different subsequent applications. Finally, the proposed data modeling and integration methods are implemented and verified through the developed manufacturing big data-driven analysis and decision-making system.",2020 IEEE 7th International Conference on Industrial Engineering and Applications (ICIEA),2020
b880729023d6f7457171a94d86c208ebb3fbd0ea,https://www.semanticscholar.org/paper/b880729023d6f7457171a94d86c208ebb3fbd0ea,Product Completion Time Prediction Using A Hybrid Approach Combining Deep Learning and System Model,"Abstract The prediction of product completion time is critical in real time production scheduling and control to achieve customer demand satisfaction. However, it is a challenging task due to the increasing complexity of production systems and greater diversity of products. The recent advancement in data-driven approach and machine learning algorithms have provided unprecedent opportunities to tackle such problems that otherwise very difficult to solve using conventional methods in the manufacturing industry. However, most existing studies on product completion time prediction adopt a purely data-driven approach while ignoring the prospect of integrating domain knowledge in their machine learning models. In this paper, we propose a hybrid approach to predicting product completion time by combining the strengths of both machine learning techniques and analytical system model. A mathematical model for multi-product serial production line is proposed to describe the real-time dynamics of the system. With this model, the strict lower bound of product completion time can be efficiently computed for given system status, where the lower bound represents the least possible product completion time when assuming no random downtime in the system. Instead of directly predicting the product completion time, a deep learning model is developed to only predict the distance between the lower bound and actual product completion time. Guided by properties of production system, we discover a recurrent sequence in the prediction problem by modeling each machine and product as recurrent units. The Long Short-Term Memory (LSTM) method, a prominent variant of recurrent neural network (RNN), is used to combine with the system model to predict the product completion time in a real-time fashion.",Journal of Manufacturing Systems,2020
dbda0e68e8244d971b59bbdd9820ff20783802d6,https://www.semanticscholar.org/paper/dbda0e68e8244d971b59bbdd9820ff20783802d6,A Parallel Gated Recurrent Units (P-GRUs) network for the shifting lateness bottleneck prediction in make-to-order production system,"Abstract In the make-to-order production system, the lateness bottleneck is the constraint of just-in-time management and orders on-time delivery. Since the dynamic nature of the manufacturing system, the bottleneck frequently shifts and influences the stability during the production runs. Therefore, predicting the bottleneck allows operators to foresee the future production status and to make proactive decision towards a balanced-line. Based on the large volumes of manufacturing data collected by Internet of Things (IoT), a novel Parallel gated recurrent units (P-GRUs) network with main inputs and auxiliary inputs are particularly developed for shifting bottleneck prediction. The designed P-GRUs can capture the temporal correlations of shifting bottlenecks and depict the production status simultaneously to make accurate bottleneck prediction. The P-GRUs model is applied in a large-scale production system to validate the performance and demonstrate the practical impacts. Finally, the experiment results from both real-world production as well as simulation environment show that the P-GRUs model yields better performance than benchmark models, including Autoregressive integrated moving average model (ARIMA), vanilla Recurrent nueral network (RNN), Deep neural network (DNN), and regular GRUs network.",Comput. Ind. Eng.,2020
f9dfc843edbc5bd625892f68a5af9674b4beb925,https://www.semanticscholar.org/paper/f9dfc843edbc5bd625892f68a5af9674b4beb925,Transfer Learning for Smart Manufacturing: A Stepwise Survey,"Abstract Nowadays, industrial companies embrace the cutting-edge artificial intelligence (AI) techniques to achieve smart manufacturing over the entire organization. However, effective data collection and annotation still remain as a big challenge in many manufacturing scenarios. Transfer learning, serving as a breakthrough of learning sharing knowledge and extracting latent features from scarce data, has attracted much attention. Transfer learning in literature mainly focuses on the definitions and mechanisms of interpretation while lacking a systematic implementation scheme for manufacturing. To fulfill this gap and facilitate industrial resource use efficiency, this paper attempts to systematize strategies of transfer learning in today’s smart manufacturing in a step-by-step manner. Twenty representative transfer learning works are investigated from the perspectives of manufacturing activities along the engineering product lifecycle. Meanwhile, the potential availability of industrial dataset is also briefly introduced. It is hoped this research can provide a clear guide for both academics and industrial practitioners to design appropriate learning approaches according to their own industrial scenarios.",,2020
b5a8b326bce1c0f147bb116c75f9397714b10b77,https://www.semanticscholar.org/paper/b5a8b326bce1c0f147bb116c75f9397714b10b77,A Study on Kicking Motion Strategy for a Legged Robot,"For generating a translational motion of a robot in a horizontal plane or under microgravity, it is possible to utilize an impact force between the end-effector and a surface such as a wall and the ground. In this paper, we consider a legged robot consisting of four links that pushes a certain surface to obtain a translational momentum in a horizontal plane. The motion that maximizes the momentum is searched for, under the condition that the torque consumption during it is the same, by numerical optimization. The optimization results indicate that the motion with an impact force that is caused by hitting the surface is advantageous in increasing the translational momentum. ",International Journal of Mechanical Engineering and Robotics Research,2022
55566461ceb1f1617ac6479cdee9636c463e682b,https://www.semanticscholar.org/paper/55566461ceb1f1617ac6479cdee9636c463e682b,Real-time Optimal Landing Control of the MIT Mini Cheetah,"Quadrupedal landing is a complex process involving large impacts, elaborate contact transitions, and is a crucial recovery behavior observed in many biological animals. This work presents a real-time, optimal landing controller that is free of pre-specified contact schedules. The controller determines optimal touchdown postures and reaction force profiles and is able to recover from a variety of falling configurations. The quadrupedal platform used, the MIT Mini Cheetah, recovered safely from drops of up to 8 m in simulation, as well as from a range of orientations and planar velocities. The controller is also tested on hardware, successfully recovering from drops of up to 2 m.",ArXiv,2021
9ee028d0a0f1f7300dacbafa00af7a9e01d95cd0,https://www.semanticscholar.org/paper/9ee028d0a0f1f7300dacbafa00af7a9e01d95cd0,"Mini Cheetah, the Falling Cat: A Case Study in Machine Learning and Trajectory Optimization for Robot Acrobatics","Seemingly in defiance of basic physics, cats consistently land on their feet after falling. In this paper, we design a controller that lands the Mini Cheetah quadruped robot on its feet as well. Specifically, we explore how trajectory optimization and machine learning can work together to enable highly dynamic bioinspired behaviors. We find that a reflex approach, in which a neural network learns entire state trajectories, outperforms a policy approach, in which a neural network learns a mapping from states to control inputs. We validate our proposed controller in both simulation and hardware experiments, and are able to land the robot on its feet from falls with initial pitch angles between -90 and 90 degrees.",ArXiv,2021
e33bb564849617935bfb54ae3393a325c449c4ae,https://www.semanticscholar.org/paper/e33bb564849617935bfb54ae3393a325c449c4ae,Vision-based Navigation for a Small-scale Quadruped Robot Pegasus-Mini,"Quadruped locomotion is currently a vibrant research area, which has reached a level of maturity and performance that enables some of the most advanced real-world applications with autonomous quadruped robots both in academia and industry. Blind robust quadruped locomotion has been pushed forward in control and technology aspects within recent decades. However, in the complicated environment, the capability including terrain perception and path planning is still required. Visual perception is an indispensable ability in legged locomotion for such a demand. This study explores a vision-based navigation method for a small-scale quadruped robot Pegasus-Mini, aiming to propose a method that enables efficient and reliable navigation for the small-scale quadruped locomotion. The visionbased navigation method proposed in this study is applicable in such a small-scale quadruped robot platform in which the computation resources and space are limited. The semantic segmentation based on a CNN model is adopted for the realtime path segmentation in the outdoor environment. The desired traverse trajectory is generated through real-time updating the middle line, which is calculated from the edge position of the segmented path in the images. To enhance the stability of the path planning directly based on the semantic segmentation method, a trajectory compensation method is supplemented considering the temporal information to revise the untrustworthy planned path. Experiments of semantic segmentation and navigation in a garden scene are demonstrated to verify the effectiveness of the proposed method.",,2021
ccf0e751e359d23898a675edfadf934886945bec,https://www.semanticscholar.org/paper/ccf0e751e359d23898a675edfadf934886945bec,Asset management and maintenance programming for power distribution systems: A review,,,2021
de4aed1e821a9cf5527f3f2b1796a86b7f785860,https://www.semanticscholar.org/paper/de4aed1e821a9cf5527f3f2b1796a86b7f785860,"Evaluation of in-service power transformer health condition for Inspection, Repair, and Replacement (IRR) maintenance planning in electric utilities",,Int. J. Syst. Assur. Eng. Manag.,2021
e716a1d60fc26fedd5d86ec1ed8f02d4fdd1fe81,https://www.semanticscholar.org/paper/e716a1d60fc26fedd5d86ec1ed8f02d4fdd1fe81,Artificial intelligence techniques for enabling Big Data services in distribution networks: A review,"Abstract Artificial intelligence techniques lead to data-driven energy services in distribution power systems by extracting value from the data generated by the deployed metering and sensing devices. This paper performs a holistic analysis of artificial intelligence applications to distribution networks, ranging from operation, monitoring and maintenance to planning. The potential artificial intelligence techniques for power system applications and needed data sources are identified and classified. The following data-driven services for distribution networks are analyzed: topology estimation, observability, fraud detection, predictive maintenance, non-technical losses detection, forecasting, energy management systems, aggregated flexibility services and trading. A review of the artificial intelligence methods implemented in each of these services is conducted. Their interdependencies are mapped, proving that multiple services can be offered as a single clustered service to different stakeholders. Furthermore, the dependencies between the AI techniques with each energy service are identified. In recent years there has been a significant rise of deep learning applications for time series prediction tasks. Another finding is that unsupervised learning methods are mainly being applied to customer segmentation, buildings efficiency clustering and consumption profile grouping for non-technical losses detection. Reinforcement learning is being widely applied to energy management systems design, although more testing in real environments is needed. Distribution network sensorization should be enhanced and increased in order to obtain larger amounts of valuable data, enabling better service outcomes. Finally, the future opportunities and challenges for applying artificial intelligence in distribution grids are discussed.",,2021
bba504b1133c912b65790b2530e94aede55ec722,https://www.semanticscholar.org/paper/bba504b1133c912b65790b2530e94aede55ec722,Assets management on electrical grid using Faster-RCNN,"Electrical utility companies around the world are keeping track of all equipment on their distribution grid, because it will help them improve the management and the quality of the services they offer to their customers. Asset management of the electric grid is usually conducted manually, which is expensive, time consuming and the results obtained are often not accurate. In this article an automated asset management system for electricity, transport infrastructures is proposed, it is based on images taken by drones and analysed by Faster Region proposal Convolutional Neural Networks (Faster-RCNN) to generate the inventory. The designs of CNN are inspired from the human brain structures, they have been applied to many fields such as object recognition and crowed counting with promising results that are proven to be better than human observer. In order to evaluate the proposed asset management approach, a sample of images was randomly selected from a given dataset, the inventory results generated by the CNN based model are accurate, faster and cheaper than the previous approach based on human observers and helicopters.",Annals of Operations Research,2020
e0bb70dc52a5b01ce8b23e03f09cdf47e19c337d,https://www.semanticscholar.org/paper/e0bb70dc52a5b01ce8b23e03f09cdf47e19c337d,Data acquisition system for on-line temperature monitoring in power transformers,"Abstract This paper presents an original data acquisition and transmission system designed and optimized for on-line temperature monitoring systems in electric power transformers – system is called SPOTEL. The main purpose of this work is to evaluate a cost effective system that is based on open source components and modular hardware layout, supporting the highest reliability and data safety and security requirements, allowing it applications under demanding industrial conditions. A detailed description of the proposed system design is presented, including hardware and software implementations. Finally, its exemplary on-site implementation and simple reliability analysis have been presented. As a result, SPOTEL confirmed its reliability and functionality regarding the on-line temperature monitoring, typically not met in other similar solutions, and it is now being implemented in several hundreds of transformers of the selected population.",,2020
e9420cfe97dec30c88f1b353b7201c6199fa6a12,https://www.semanticscholar.org/paper/e9420cfe97dec30c88f1b353b7201c6199fa6a12,Maintenance Planning of Electric Distribution Systems—A Review,"Electric distribution systems have the objective of supplying electricity with quality and reliability to the final consumers. In order to meet both criteria, efficient maintenance programs have a vital importance mainly due to the actual increase in the requirements for distribution service quality and in technologies related to electrical networks. In this sense, the number of options and criteria for developing effective programs makes the related decision-making process a complex task. This paper presents a comprehensive review on maintenance planning in electrical distribution systems covering different criteria such as economic and reliability. More specifically, this work summarizes contributions up to now through a holistic framework that comprises the premises of predictive, preventive and corrective maintenance. The work is organized by relevant aspects of researches in the field, as criteria, probability functions, constraints and methods that have been applied, within a comprehensive classification.",,2020
2da09fe870aa87cfd349ba8aedca161c6a61c0db,https://www.semanticscholar.org/paper/2da09fe870aa87cfd349ba8aedca161c6a61c0db,Power transformer reliability assessment based on tap changer dynamic resistance and motor current measurements,"Information about the remaining power transformer life and the condition of its components is the most important role of asset management. One of the main causes of transformer failure is on load tap changer. In this paper, consideration of the power transformer reliability with regard to the state of the on load tap changer, based on the dynamic resistance measurement and tap changer motor current will be given",2019 18th International Symposium INFOTEH-JAHORINA (INFOTEH),2019
3029a28b148eafd360a88f98c19793ec7868198a,https://www.semanticscholar.org/paper/3029a28b148eafd360a88f98c19793ec7868198a,Adaptive Power Transformer Lifetime Predictions Through Machine Learning and Uncertainty Modeling in Nuclear Power Plants,"The remaining useful life (RUL) of transformer insulation paper is largely determined by the winding hot-spot temperature (HST). Frequently the HST is not directly monitored and it is inferred from other measurements. However, measurement errors affect prediction models and if uncertain variables are not taken into account this can lead to incorrect maintenance decisions. Additionally, existing analytic models for HST calculation are not always accurate because they cannot generalize the properties of transformers operating in different contexts. In this context, this paper presents a novel transformer condition assessment approach integrating uncertainty modeling, data-driven forecasting models, and model-based experimental models to increase the prediction accuracy and handle uncertainty. The proposed approach quantifies the effect of measurement errors on transformer RUL predictions and confirms that temperature and load measurement errors affect the RUL estimation. Forecasting results show that the extreme gradient boosting (XGB) algorithm best captures the nonlinearities of the thermal model and improves the prediction accuracy among a number of forecasting approaches. Accordingly, the XGB model is integrated with experimental models in a particle filtering framework to improve thermal modeling and RUL prediction tasks. Models are tested and validated using a real dataset from a power transformer operating in a nuclear power plant.",IEEE Transactions on Industrial Electronics,2019
3393d0ae980041c0585df86d12e637ec0d4a73c3,https://www.semanticscholar.org/paper/3393d0ae980041c0585df86d12e637ec0d4a73c3,Modeling of the Winding Hot-Spot Temperature in Power Transformers: Case Study of the Low-Loaded Fleet,"A proposal of the dynamic thermal rating (DTR) applied and optimized for low-loaded power transformers equipped with on-line hot-spot (HS) measuring systems is presented in the paper. The proposed method concerns the particular population of mid-voltage (MV) to high-voltage (HV) transformers, a case study of the population of over 1500 units with low average load is analyzed. Three representative real-life working units are selected for the method evaluation and verification. Temperatures used for analysis were measured continuously within two years with 1 h steps. Data from 2016 are used to train selected models based on various machine learning (ML) algorithms. Data from 2017 are used to verify the trained models and to validate the method. Accuracy analysis of all applied ML algorithms is discussed and compared to the conventional thermal model. As a result, the best accuracy of the prediction of HS temperatures is yielded by a generalized linear model (GLM) with mean prediction error below 0.71% for winding HS. The proposed method may be implemented as a part of the technical assessment decision support systems and freely adopted for other electrical power apparatus after relevant data are provided for the learning process and as predictors for trained models.",Energies,2019
64c3b0286ca4238b9bd52cb2a46c7c9740e097ef,https://www.semanticscholar.org/paper/64c3b0286ca4238b9bd52cb2a46c7c9740e097ef,An Internet of Things (IoT) based Monitoring System for Oil-immersed Transformers,"While the electricity power industry in the world continues to grow, it also becomes more traceable and smart with the developing technology. Naturally, the integration of these technologies into the electrical power systems brings with an additional cost. Most of the time producers and consumers struggle under the pressure of these additional costs and try new products that will reduce the cost. In this sense, competitive products in the market must be advantageous in terms of cost. In this study, an original IoT based transformer monitoring system has been developed by using open source software, modular and low cost components as an alternative to studies in literature. Arduino Mega 2560 microcontroller has been used as the main component in the system. The system can acquire data from a wide variety of sensors using internal and external transducers. And this data can be saved to the cloud system synchronously with the memory card on the monitoring system. The developed monitoring system has been utilized free and reliable platforms such as the ThingSpeak web interface and PushingBox Notification application. The all test process of the developed monitoring system has been carried out in the laboratory environment.",Balkan Journal of Electrical and Computer Engineering,2019
957b78c6111dc6d39797e90855dfa111fd7b8243,https://www.semanticscholar.org/paper/957b78c6111dc6d39797e90855dfa111fd7b8243,Transformer Fleet Optimal Maintenance with Risk Considerations,This paper aims at proposing an optimization model for high voltage transformers’ maintenance scheduling to minimize operational cost and risk. The focus of the paper is on the transformer fleet ma...,Electric Power Components and Systems,2019
06b935bd72567db5b0580078ffb7f4b08baca870,https://www.semanticscholar.org/paper/06b935bd72567db5b0580078ffb7f4b08baca870,Distribution asset management through coordinated microgrid scheduling,"Distribution Asset Management is an important task performed by utility companies to prolong the lifetime of the critical distribution assets and to accordingly ensure grid reliability by preventing unplanned outages. This study focuses on microgrid applications for distribution asset management as a viable and less expensive alternative to traditional utility practices in this area. A microgrid is as an emerging distribution technology that encompasses a variety of distribution technologies including distributed generation, demand response, and energy storage. Moreover, the substation transformer, as the most critical component in a distribution grid, is selected as the component of the choice for asset management studies. The resulting model is a microgrid-based distribution transformer asset management model in which microgrid exchanged power with the utility grid is reshaped in such a way that the distribution transformer lifetime is maximised. Numerical simulations on a test utility-owned microgrid demonstrate the effectiveness of the proposed model to reshape the loading of the distribution transformer at the point of interconnection in order to increase its lifetime.",IET Smart Grid,2018
253b68dbf3125a4fb71ff7b73f430f9aab2a00f4,https://www.semanticscholar.org/paper/253b68dbf3125a4fb71ff7b73f430f9aab2a00f4,Statistics based method for partial discharge identification in oil paper insulation systems,"Abstract An original partial discharge generated in oil insulation identification methodology based on simultaneously conducted measurements using electrical method, ultra high frequency method and acoustic emission method is presented in the paper. Three different partial discharge model sources as well as measuring instruments commonly applied for partial discharge detection in electrical power transformers are yielded within a laboratory research. Total of 45 scenarios, including proposed spark gap configurations, selected supply voltage levels and UHF frequencies are analyzed during measurements series. Furthermore, form among total of 93 descriptors assigned for every applied partial discharge model source configuration there are 24 proposed as potentially useful for partial discharge identification applications with their 95% confidence bounds. Attempt of discriminative descriptors selection for partial discharge source analysis in on-site transformer applications as well as a proposal of unique descriptors according to every selected spark gap configuration that could be potentially useful for partial discharge identification purposes are the main purpose of the presented paper. The proposed methodology verification on a real life transformer with particular consideration of the selected descriptors potential utility in the fields of partial discharge detection and identification in electrical power industry applications confirmed a proposed methodology usefulness.",Electric Power Systems Research,2018
255202a431aac44255f34e76c67f29127139dde6,https://www.semanticscholar.org/paper/255202a431aac44255f34e76c67f29127139dde6,Data Fusion and Machine Learning Integration for Transformer Loss of Life Estimation,"Rapid growth of machine learning methodologies and their applications offer new opportunity for improved transformer asset management. Accordingly, power system operators are currently looking for data-driven methods to make better-informed decisions in terms of network management. In this paper, machine learning and data fusion techniques are integrated to estimate transformer loss of life. Using IEEE Std. C57.91-2011, a data synthesis process is proposed based on hourly transformer loading and ambient temperature values. This synthesized data is employed to estimate transformer loss of life by using Adaptive Network-Based Fuzzy Inference System (ANFIS) and Radial Basis Function (RBF) network, which are further fused together with the objective of improving the estimation accuracy. Among various data fusion techniques, Ordered Weighted Averaging (OWA) and sequential Kalman filter are selected to fuse the output results of the estimated ANFIS and RBF. Simulation results demonstrate the merit and the effectiveness of the proposed method.",2018 IEEE/PES Transmission and Distribution Conference and Exposition (T&D),2017
2863a426f65964b0da390fe260c739eec466b027,https://www.semanticscholar.org/paper/2863a426f65964b0da390fe260c739eec466b027,"MEDOW - Multi-terminal DC Grid for Offshore Wind, Final report","MEDOW Multi-terminal DC Grid for Offshore Wind, Final report A DC grid based on multi-terminal voltage-source converter is a newly emerging technology, which is particularly suitable for the connection of offshore wind farms. Multi-terminal DC grids will be the key technology for the European offshore ‘Super Grid’. In the project, DC power flow, DC relaying protection, steady state operation, dynamic stability, fault-ride through capability, and impacts of DC grids on the operation of AC grids and power market were studied. Systematic comparison of DC grid topologies and stability control strategies was carried out, and DC grids for offshore wind power transmission and onshore AC grid interconnection were investigated. Operation and control were evaluated using various simulation platforms and experimental test rigs. The outcomes of the project are expected to contribute to integrating offshore wind power into the onshore AC grids in European countries and for the European Super Grid.",,2018
3e41f4416e151d5a22a089e56e13c8f5ebcfdd9b,https://www.semanticscholar.org/paper/3e41f4416e151d5a22a089e56e13c8f5ebcfdd9b,New analytical method for estimating mean life of electric power equipment based on complete and right-censored failure data,"Abstract Analysis based on application of two-parametric Weibull distribution is commonly used to characterize power equipment life distributions in the presence of censored data. Numerous studies have focused on enhancing the accuracy of statistical parameter estimation. However, there is still no straightforward and rigorous analytical method of estimation of the Weibull parameters and the mean life. In this work, a new method for mean life evaluation of power system equipment, based on the two-parameter Weibull distribution, is presented for complete and right-censored failure data. Classical maximum likelihood estimation (MLE) is employed for determination of distribution parameters. However, an estimator based on asymptotic expansions is proposed, overpassing the disadvantages of MLE-based methods that employ numerical or graphical techniques. High accuracy of the proposed method with respect to other estimators is also shown by analyzing two right-censored lifetime data sets with different sample sizes for three types of power equipment. The efficiency and accuracy of the proposed analytical method find their strengths in the analytically obtained closed-form expressions for the distribution parameters.",,2018
6e2ddca7e885e13c4338ce6da1a4bef719bd904e,https://www.semanticscholar.org/paper/6e2ddca7e885e13c4338ce6da1a4bef719bd904e,An Extended Parametric Analysis of Transformer Maintenance Plan Using Markov State Diagram,"Deregulation and competitive nature of electric power industry have forced the utilities to optimize the operation and the maintenance cycles of their assets to extend their life time and to minimize the total costs. This paper is an extension of a recent study and aims to increase the improvements in the reliability parameters and totallifecycle of the power transformers of Turkish National Power Transmission System. This extension covers the possible failure rate decreases as a result of decrease test rates. Once the consideration of the parametric analysis is described, the effect of the failure rate changes on the reliability indices is determined as a result of the maintenance improvement in addition to test to operation and failure to operation rates determined previous study. Also, the sensitivity analysis is performed.",2018 IEEE International Conference on Probabilistic Methods Applied to Power Systems (PMAPS),2018
82322a23655446fe36169db1622802b845f7db89,https://www.semanticscholar.org/paper/82322a23655446fe36169db1622802b845f7db89,Effect of Pre-Determined Maintenance Repair Rates on the Health Index State Distribution and Performance Condition Curve Based on the Markov Prediction Model for Sustainable Transformers Asset Management Strategies,"This paper presents an investigation of the condition state distribution and performance condition curve of the transformer population under different pre-determined maintenance repair rates based on the Markov Prediction Model (MPM). In total, 3195 oil samples from 373 transformers with an age between one and 25 years were tested. The previously computed Health Index (HI) prediction model of the transformer population based on MPM utilizing the nonlinear minimization technique was employed in this study. The transition probabilities for each of the states were updated based on 10%, 20% and 30% pre-determined maintenance repair rates for the sensitivity study. Next, the HI state distribution and performance condition curve were analyzed based on the Markov chain algorithm. Based on the case study, it is found that the pre-determined maintenance repair rates can affect the HI state distribution and improve the performance condition curve. The 30% pre-determined maintenance repair rate gives the highest impact, especially for the transformer population at state 4 (poor). Overall, the average percentage of change for all HI state distributions is 16.48%. A clear improvement of HI state distribution is found at state 4 (poor) where the highest percentage can be up to 63.25%.",Sustainability,2018
cbe7091dd0e845e84cf1aab091129baffcdab4c3,https://www.semanticscholar.org/paper/cbe7091dd0e845e84cf1aab091129baffcdab4c3,Individual Failure Rate Modelling and Exploratory Failure Data Analysis for Power System Components,A set of vital societal functions such as health and safety are necessary for today's society to function and to secure the life of its individuals. Infrastructure is required to provide and mainta ...,,2018
e58aefbd22f9b389b5b4b421aa4426ffbc88dd96,https://www.semanticscholar.org/paper/e58aefbd22f9b389b5b4b421aa4426ffbc88dd96,Asset Management Strategies for Power Electronic Converters in Transmission Networks: Application to Hvdc and FACTS Devices,"The urgency for an increased capacity boost bounded by enhanced reliability and sustainability through operating cost reduction has become the major objective of electric utilities worldwide. Power electronics have contributed to this goal for decades by providing additional flexibility and controllability to the power systems. Among power electronic based assets, high-voltage dc (HVdc) transmission systems and flexible ac transmission systems (FACTS) controllers have played a substantial role on sustainable grid infrastructure. Recent advancements in power semiconductor devices, in particular in voltage source converter based technology, have facilitated the widespread application of HVdc systems and FACTS devices in transmission networks. Converters with larger power ratings and higher number of switches have been increasingly deployed for bulk power transfer and large scale renewable integration—increasing the need of managing power converter assets optimally and in an efficient way. To this end, this paper reviews the state-of-the-art of asset management strategies in the power industry and indicates the research challenges associated with the management of high power converter assets. Emphasis is made on the following aspects: condition monitoring, maintenance policies, and ageing and failure mechanisms. Within this context, the use of a physics-of-failure based assessment for the life-cycle management of power converter assets is introduced and discussed.",IEEE Access,2018
0f230bb30749c3ee7605610e3a176030a0a39344,https://www.semanticscholar.org/paper/0f230bb30749c3ee7605610e3a176030a0a39344,Determining Optimal Inspection Intervals in Maintenance Considering Equipment Aging Failures,"This paper presents an integrated inspection and failure model of equipment for asset management. The model combines both repairable and aging failure modes with maintenance activities. Based on this model, an optimization approach for determining equipment inspection interval is proposed. The proposed approach can optimize the inspection interval by minimizing the total cost including maintenance, failure loss, repair, replacement, and patrol costs. The proposed method is applied to a mixed set of equipment consisting of breakers and transformers in two regions. The results indicate that the optimal inspection interval for each region can be effectively obtained using the proposed method. Equipment aging failures have significant impacts on the optimal inspection interval. The optimal inspection interval gradually becomes shorter over years due to the equipment aging process. The optimal inspection interval is different for different regions depending on the equipment aging status and other factors in each region. Therefore, it is recommended to have a region-specific inspection strategy for each area.",IEEE Transactions on Power Systems,2017
20191e99d26c0db3568909e2f9dd941c38709e40,https://www.semanticscholar.org/paper/20191e99d26c0db3568909e2f9dd941c38709e40,From condition monitoring to maintenance management in electric power system generation with focus on wind turbines,"espanolDebido al creciente numero de sensores instalados en subconjuntos de componentes industriales, la cantidad de datos recogidos esta aumentando rapidamente. Estos datos contienen informacion en areas como la operacion del sistema y la evolucion del estado de salud de los componentes. Por tanto, extraer el conocimiento de los datos puede conllevar mejoras significativas en las areas mencionadas. Esta tesis proporciona un camino para alcanzar tal objetivo. Se comienza analizando los datos en el nivel del subconjunto de los componentes y se crean cuatro marcos para el analisis de la operacion y mantenimiento (OM tidigare, nuvarande och framtida horisonter pa komponentniva. Dessa modeller mojliggor forbattring av drift, underhallsplanering, kostnadsminskning, effektivitet och prestanda for industrikomponenterna. Darefter utvarderar avhandlingen om sadana modeller kan kopplas till systemnivaanalys och hur ett sadant samband kan ge ytterligare forbattringar for systemoperatorer. Slutligen studeras forebyggande underhall for planerat underhall for elgenerering i elkraftsystemet. Detta gors med avseende pa nya metoder med tillgang till information fran elmarknaden och detaljerad information om komponenters tillstand i underhallsmodeller. Speciellt undersoks underhallsplanering genom spelteori i avreglerade elkraftsystem, for en havsbaserad vindkraftpark (OWF) och ett isolerat mikrogrid (MG). Resultaten visar forbattringar i att sanka kostnaden och oka vinsten for marknadsaktorer och systemoperatorer samt tillgangsagarna. Dessutom ger modellerna aven en inblick i hur direkt integration av insamla operationsdata formodeller pa komponentniva kan hjalpa till att forbattra driften och hanteringen av underhallet for systemet. Met de toename van het aantal geinstalleerde sensoren op subassemblage van industriele componenten neemt de hoeveelheid verzamelde gegevens snel toe. Deze gegevens bevatten informatie over de werking van het systeem en de ontwikkeling van de gezondheid van de componenten. Door deze gegevens om te zetten in kennis, kunnen daarom aanzienlijke verbeteringen op de hiervoor genoemde gebieden tewerkstellingen. Dit proefschrift biedt een weg voor het bereiken van een dergelijk doel. Het begint met het analyseren van de data op het subassemblage niveau van de componenten en creeert vier kaders voor de analyse van de bediening en het onderhoud (O&M) voor de voorbije, huidige en toekomstige tijdshorizon op het componentniveau. Deze kaders maken verbeteringen op het gebied van onderhoudsplanning, kostenreductie, efficientie en prestatie van de industriele componenten mogelijk. Vervolgens wordt in dit proefschrift beoordeeld of dergelijke modellen gekoppeld kunnen worden aan een systeemniveauanalyse en hoe het maken van een dergelijke link extra verbeteringen kan bieden voor netbeheerders. Ten slotte wordt het doen van preventief onderhoud (PM) in de onderhoudsplanning van generatoren (GMS) in het elektriciteitsnet beoordeeld en aangepast. Recente ontwikkelingen, zoals de aansluiting op de elektriciteitsmarkt en de gedetailleerde implementatie van gezondheidsindicatoren in de onderhoudsmodellen zijn in het preventieve onderhoud geimplementeerd. Met name wordt de onderhoudsplanning aan de hand van speltheorie in een gedereguleerde elektriciteitsmarkt, voor een windpark op zee (OWF) en een microgrid in eiland bedrijf (MG) onderzocht. De resultaten tonen een kostenbesparing en een verhoging van de winst aan voor handelspartijen, netbeheerders en de eigenaars van de generatoren. Bovendien geven de modellen ook inzicht in hoe de directe integratie van de verzamelde operationele data via de ontwikkelde componentmodellen kan bijdragen aan het verbeteren van de uitvoer en het beheer van het onderhoud.",,2018
2fa4fa4b67db6aff76bad312bea91bbeb3af05ed,https://www.semanticscholar.org/paper/2fa4fa4b67db6aff76bad312bea91bbeb3af05ed,Machine learning applications in estimating transformer loss of life,"Transformer life assessment and failure diagnostics have always been important problems for electric utility companies/Ambient temperature and load profile are the main factors which affect aging of the transforiner insulation, and consequently, the transformer lifetime. The IEEE Std. C57.91-1995 provides a model for calculating the transformer loss of life based on ambient temperature and transformer's loading. In this paper, this standard is used to develop a data-driven static model for hourly estimation of the transformer loss of life. Among various machine learning methods for developing this static model, the Adaptive Network-Based Fuzzy Inference System (ANFIS) is selected. Numerical simulations demonstrate the effectiveness and the accuracy of the proposed ANFIS method compared with other relevant machine learning based methods to solve this problem.",2017 IEEE Power & Energy Society General Meeting,2017
663c742c3a15ec4271709e97bbb85c1e69d7d5f0,https://www.semanticscholar.org/paper/663c742c3a15ec4271709e97bbb85c1e69d7d5f0,Assessing degradation of power transformer solid insulation considering thermal stress and moisture variation,"Abstract This paper presents a novel method for estimating the degradation of solid insulation in power transformers, considering thermal ageing and paper moisture dynamics. Current ageing models are based on both, experimental evidence and theoretical developments; considering that all models are approximation to reality, loss of life estimation could be found in a large range depending on the evidence considered; this amplitude could lead inaccurate results to make adequate decisions in an asset-management context. These differences in results can be explained because the models consider only nominal operative temperatures ranges overlooking low and high temperatures degradation process and the influence of variations in paper moisture content. Considering the above, this document proposes a holistic methodology for solid insulation ageing assessing based on all thermal degradation process (oxidation, hydrolysis and pyrolysis) and the influence of dynamics on paper moisture. Paper moisture is estimated using as input external variables such as: load, ambient temperature, transformer technical data and measurements regarding oil moisture, in order to consider uncertain in oil moisture growing Arithmetic-Brownian-Motion algorithms are presented. The proposed methodology was tested for four power transformers, for which load and ambient temperature hourly profiles are available over a period of almost nine years. In order to compare different degradation rates, three alternatives to model the chemical environment in which cellulose is aged, are analysed. Results are presented, and conclusions are finally detailed.",,2017
71cc0c9949dd352bc8098c02b0a988fbb57e3371,https://www.semanticscholar.org/paper/71cc0c9949dd352bc8098c02b0a988fbb57e3371,Leveraging sensory data in estimating transformer lifetime,"Transformer lifetime assessments plays a vital role in reliable operation of power systems. In this paper, leveraging sensory data, an approach in estimating transformer lifetime is presented. The winding hottest-spot temperature, which is the pivotal driver that impacts transformer aging, is measured hourly via a temperature sensor, then transformer loss of life is calculated based on the IEEE Std. C57.91-2011. A Cumulative Moving Average (CMA) model is subsequently applied to the data stream of the transformer loss of life to provide hourly estimates until convergence. Numerical examples demonstrate the effectiveness of the proposed approach for the transformer lifetime estimation, and explores its efficiency and practical merits.",2017 North American Power Symposium (NAPS),2017
c6cfab44246fd1a0edcb943c36bb2a73e1000f3c,https://www.semanticscholar.org/paper/c6cfab44246fd1a0edcb943c36bb2a73e1000f3c,RCAM based maintenance plan of the power transformers using k-means clustering algorithm,"RCAM based maintenance planning of power transmission grid aims to optimize the planned outage of the assets that maximizes the system reliability without additional cost increases. A recent RCAM based transformer maintenance procedure is extended to the system level and a revised maintenance plan is proposed to achieve better reliability indices, total costs and longer life cycles. k-means clustering algorithm is used for criticality assessment and classification of the transformers with respect to two criticality criteria. The proposed classification is applied to the power transformers of Turkish National Power Transmission System and the results are discussed in terms of accuracy and the applicability.",2017 19th International Conference on Intelligent System Application to Power Systems (ISAP),2017
db36dd1868e5b9d31dec8a23f2b551a37ad5c32d,https://www.semanticscholar.org/paper/db36dd1868e5b9d31dec8a23f2b551a37ad5c32d,Wind turbine prognostics and maintenance management based on a hybrid approach of neural networks and a proportional hazards model,"This paper proposes an approach for stress condition monitoring and maintenance assessment in wind turbines (WTs) through large amounts of collected data from the supervisory control and data acquisition (SCADA) system. The objectives of the proposed approach are to provide a stress condition model for health monitoring, to assess the WT’s maintenance strategies, and to provide recommendations on current maintenance schemes for future operations of the wind farm. At first, several statistical techniques, namely principal component analysis, Pearson, Spearman and Kendall correlations, mutual information, regressional ReliefF and decision trees are used and compared to assess the data for dimensionality reduction and parameter selection. Next, a normal behavior model is constructed by an artificial neural network which performs condition monitoring analysis. Then, a model based on the mathematical form of a proportional hazards model is developed where it represents the stress condition of the WT. Finally, those two models are jointly employed in order to analyze the overall performance of the WT over the study period. Several cases are analyzed with five-year SCADA data and maintenance information is utilized to develop and validate the proposed approach.",,2017
eb9d0a4cf84e930a56dc73a7c25dfd1dbb46495f,https://www.semanticscholar.org/paper/eb9d0a4cf84e930a56dc73a7c25dfd1dbb46495f,Impact of health indicators on maintenance management and operation of power systems,"This article proposes a maintenance management and risk reduction approach. The approach introduces two reliability-based indexes called condition indicator and risk indicator. Condition indicator is a unit-less parameter that comes directly from monitored condition of a component and converts the categorical condition into a numerical value. Risk indicator in megawatt represents the risk imposed by the health of a component onto the system. To demonstrate application of the indicators, they are implemented through an hourly network constraint unit commitment problem and applied in a test system where the analysis of impact of condition of the generators to the operation is the new contribution. The results demonstrate how addition of such indicators will impact the operation of the grid and maintenance scheduling. The results show the benefit for the system operator as the overall failure risk in the system is taken into account, and the benefit for the asset owner as the direct impact of the maintenance to be carried out can be investigated. Two of the main outcomes of the maintenance management and risk reduction approach are as follows: asset owners can analyze their maintenance strategies and evaluate their impacts in the maintenance scheduling, and system operators can operate the grid with higher security and lower risk of failure.",,2017
13b6724d5bd1574567434930ab387ba0c202473d,https://www.semanticscholar.org/paper/13b6724d5bd1574567434930ab387ba0c202473d,Power transformers’ condition monitoring using neural modeling and the local statistical approach to fault diagnosis,"Abstract On-line monitoring of electric power transformers can provide a clear indication of their status and ageing behavior. This paper proposes neural modeling and the local statistical approach to fault diagnosis for the detection of incipient faults in power transformers. The method can detect transformer failures at their early stages and consequently can deter critical conditions for the power grid. A neural-fuzzy network is used to model the thermal condition of the power transformer in fault-free operation (the thermal condition is associated to a temperature variable known as hot-spot temperature). The output of the neural-fuzzy network is compared to measurements from the power transformer and the obtained residuals undergo statistical processing according to a fault detection and isolation algorithm. If a fault threshold (that is optimally defined according to detection theory) is exceeded, then deviation from normal operation can be detected at its early stages and an alarm can be launched. In several cases fault isolation can be also performed, i.e. the sources of fault in the power transformer model can be also identified. The performance of the proposed methodology is tested through simulation experiments.",,2016
38e79e8f9f4b9b6fd053dd2941f52263355e44d8,https://www.semanticscholar.org/paper/38e79e8f9f4b9b6fd053dd2941f52263355e44d8,Time-horizons in the planning and operation of transmission networks: an overview,"In the planning and operation of power systems, actions are taken in different processes and time-horizons. The purpose of these actions is to secure a high reliability level. Although the three main processes (grid development, asset management, and system operation) are described in literature, there has been no explicit study on the time-horizons (long-term, mid-term, and short-term) and actual time-scale (decades, years, months, etc.) that these processes focus on. This study aims at making a review of the various activities performed by transmission system operators while reviewing the concept of each time-horizon and methodologies developed in literature. As decisions taken in different time-horizons can influence each other, the interactions and overlapping are discussed.",,2016
4d5a882e125d41124fa895b3d68e9e8dfd80f235,https://www.semanticscholar.org/paper/4d5a882e125d41124fa895b3d68e9e8dfd80f235,A bibliographic review of trends in design and management of electrical power transmission transformers,"Electricity transmission substations are fixed infrastructure assets, and the power transformer is the most visible item of equipment. The technologies embedded in protection and control switchgear, as well as in power transformers change over the very long life of a substation, even though the basic functionality remains the same. Changes in equipment technologies present salient but real challenges in design of electricity transmission networks, and especially on acquisition, operation and maintenance, and disposal of transformers deployed in substations. In addition to obsolescence, some of the challenges include age-related degradation, as well as increasingly sophisticated loading requirements on substations. A bibliographic search between 1970 and 2014 indicates that new materials plus computer-aided modelling and tools are widely applied to design and manufacture transformers to achieve higher voltage and power ratings, while sensors, information and computing systems technologies and big data analytics are increasing applied to determine transformer health index. Empirical data obtained from a case study utility suggests that operators and maintainers tend to focus on technical health indices, and this raises concern as to the robustness of decisions to decommission, refurbish, replace, and dispose of transformers in electricity transmission substations. Keywords—electrical transformer technology trends; transformer replacement decisions; substation asset management",,2016
91abf468485548410c79d99ad738ec0dbf6bc085,https://www.semanticscholar.org/paper/91abf468485548410c79d99ad738ec0dbf6bc085,Prediction of events in the smart grid: Interruptions in distribution transformers,"This paper proposes a system for the prediction of events in the smart grid. The system infers a label indicating if an event is going to occur in a future time window, in a specific asset, from data of events generated by grid assets and exogenous variables (e.g. weather data). The system design presented follows a sliding-window classification approach, bag-of-words event representation and makes use of random forests models. The systems performance is evaluated in an experimental case study, backed by real data, with the aim of predicting future interruptions in distribution transformers. Performance results indicate that the system is able to deal with highly imbalanced data and validate its adequacy in dealing with the approached problem, achieving up to 0.75 area under the receiver operating characteristic curve in testing.",2016 IEEE International Power Electronics and Motion Control Conference (PEMC),2016
aa22fff04e1a7c327d2c7ae30f47979240c7f2dc,https://www.semanticscholar.org/paper/aa22fff04e1a7c327d2c7ae30f47979240c7f2dc,A review on prognosis and diagnosis of transformer oil quality using intelligent techniques based on dissolved gas analysis,"The prognosis and diagnosis of evaluating the oil quality for high voltage electrical power transformers for maintenance is ever-demanding. The durability of transformers function is somewhat driven by the excellence of its insulation which degrades with time because of changes in temperature and content of moisture. The accurate diagnoses of faults in early stages and the efficient assessment of oil quality using an intelligent program is the key challenges for protection of transformers from incipient faults that occur during operation to avoid economic losses. The dissolved gases analysis in oil is a predictable approach in the fault diagnosis and evaluating the quality of insulating oil in transformers. In the recent applications of artificial intelligence include Fuzzy Inference, Neural Networks, Genetic Algorithm, State Space and Search, and other Expert Systems has the ability to meet DGA standards. This paper represents review of most of the methods used to diagnose faults and assessment of insulating oil for transformers through the dissolved gases analysis DGA. Further the future work provides alternate techniques for fault diagnosis and bio oil based insulations for transformer protection.",2016 7th India International Conference on Power Electronics (IICPE),2016
af6dfc73fec1d3c6ffa1145799266029de5cc699,https://www.semanticscholar.org/paper/af6dfc73fec1d3c6ffa1145799266029de5cc699,Condition-based Failure Rate Modelling for Individual Components in the Power System,The electrical power grid is one of the most important infrastructures in the modernsociety. It supplies industrial and private customers with electricity and supportsother critical infrastructures ...,,2016
cf781c2eed684090e24456afcdf1a27052ce231c,https://www.semanticscholar.org/paper/cf781c2eed684090e24456afcdf1a27052ce231c,A literature survey on asset management in electrical power [transmission and distribution] system,"Asset management is one of the key components in a transforming electric power industry. Electric power industry is undergoing significant changes because of technical, socio-economical and environmental developments. Also, because of restructuring and deregulation, the focus has been on transmission and distribution assets that include transmission lines, power transformers, protection devices, substation equipment and support structures. This study aims to provide a detailed exposure to asset management classification, various interesting maintenance methods and theories developed. The work encompasses the issue of data management in recent years. Because of the use of various smart metering devices, large amounts of information are being collected. The advent of data-mining techniques has changed the asset management scenario, and it has been covered in this survey paper. In the end, it also discusses various risk assessment techniques in asset management developed and used for academic research and industries. It is accompanied with survey results from pan-European Transmission System Operator (TSOs) on various aspects in asset management.",,2016
f137666c7513b385e63a6ed401a2e625a3a42cd9,https://www.semanticscholar.org/paper/f137666c7513b385e63a6ed401a2e625a3a42cd9,Eco-efficient control of the cooling systems for power transformers,Abstract Operation of large transformers requires heat transfer by the cooling systems. An appropriate control of the cooling system by Programmable Logic Controllers allows one to decrease the “loss of life” of the insulation system of the transformer. Additional diagnostic functions aimed at improved asset management may also be easily implemented. Practical examples of eco-friendly solutions implemented at PPH Energo-Silesia Ltd. are presented and discussed in detail. Asset management of transformer system may include techniques aimed at heat recovery and noise reduction.,,2016
f41333231eaabb00e3981cbcf5f6595ca39c7103,https://www.semanticscholar.org/paper/f41333231eaabb00e3981cbcf5f6595ca39c7103,Individual failure rates for transformers within a population based on diagnostic measures,The high monetary value of a transformer has placed the transformer life-time optimization into the focus of asset management. The average failure rate has created reasonable results within reliabi ...,,2016
35560cc356639b508ae114dc52047409ef264f5b,https://www.semanticscholar.org/paper/35560cc356639b508ae114dc52047409ef264f5b,"Classification, domains and risk assessment in asset management: A literature study","This paper presents a literature study on asset management in electrical power transmission and distribution system. Due to restructure and deregulation of electric power industry in recent times, the focus has been on transmission and distribution assets that include transmission lines, transformers, power plants, substations and support structures. The study aims to provide a first of its kind exposure to asset management classification, various interesting maintenance methods and theories developed in last two decades. In the end, it also discusses various risk assessment techniques in asset management developed and used for academic research and industries.",2015 50th International Universities Power Engineering Conference (UPEC),2015
3eebd2e6051eb2321db0ab215e33e55febcb7b9d,https://www.semanticscholar.org/paper/3eebd2e6051eb2321db0ab215e33e55febcb7b9d,A Dynamic Integrated Fault Diagnosis Method for Power Transformers,"In order to diagnose transformer fault efficiently and accurately, a dynamic integrated fault diagnosis method based on Bayesian network is proposed in this paper. First, an integrated fault diagnosis model is established based on the causal relationship among abnormal working conditions, failure modes, and failure symptoms of transformers, aimed at obtaining the most possible failure mode. And then considering the evidence input into the diagnosis model is gradually acquired and the fault diagnosis process in reality is multistep, a dynamic fault diagnosis mechanism is proposed based on the integrated fault diagnosis model. Different from the existing one-step diagnosis mechanism, it includes a multistep evidence-selection process, which gives the most effective diagnostic test to be performed in next step. Therefore, it can reduce unnecessary diagnostic tests and improve the accuracy and efficiency of diagnosis. Finally, the dynamic integrated fault diagnosis method is applied to actual cases, and the validity of this method is verified.",TheScientificWorldJournal,2015
47c19f2bd5fb23ab30e41c63fe0ef035f82a00f7,https://www.semanticscholar.org/paper/47c19f2bd5fb23ab30e41c63fe0ef035f82a00f7,Condition Monitoring Techniques of Power Transformers: A Review,"Power transformers provide a vital link between the generation and distribution of produced energy. Such static equipment is subjected to abuse during operation in generation and distribution stations and leads to catastrophic failures. This paper reviewed the techniques in the field of condition monitoring of power transformers in recent years. Transformer monitoring and diagnosis are the effective techniques for preventing the eventual failures and contributing to ensure the plan’s reliability. This paper provided a survey on the existing techniques for monitoring, diagnosis, condition evaluation, maintenance, life assessment and possibility of extending the life of the existing assets of power transformers with be appropriate classifications. Thus, this survey could help researchers through providing better techniques for condition monitoring of power transformers.",,2015
6e9ee5753fdfdbab698735a4bd0c97650cc3fcc3,https://www.semanticscholar.org/paper/6e9ee5753fdfdbab698735a4bd0c97650cc3fcc3,"Classification, Domains and Risk Assessment in Asset Management: A Literature Study","This paper presents a literature study on asset management in electrical power transmission and distribution system. Due to restructure and deregulation of electric power industry in recent times, the focus has been on transmission and distribution assets that include transmission lines, transformers, power plants, substations and support structures. The study aims to provide a first of its kind exposure to asset management classification, various interesting maintenance methods and theories developed in last two decades. In the end, it also discusses various risk assessment techniques in asset management developed and used for academic research and industries.",,2015
7724fc3a269dec57fc85742f9b648eb51815951c,https://www.semanticscholar.org/paper/7724fc3a269dec57fc85742f9b648eb51815951c,The ISO 55 00X Asset Management Standard: What is in for Rocket Sciences'?,"Asset management (AM) is the core business function of grid-based asset management organizations (GAMO). GAMO are looking for compliance with a new international AM standard (ISO 55 000). Currently, a limited perspective â€“ consisting of New Public Management (NPM) and project management (PM) â€“ provides meaning for the new AM standard. However, the limited perspective is not sufficient in aligning AM / GAMO with energy transition and environmental management successfully. The article is aiming at enabling the ISO AM standard to become a co-creational force in energy transition and environmental management. Based on professional engagement and substantial literature review the article employs â€sreflective practice' and causal loop diagrams to identify and elaborate issues of concern that need to be addressed by an enriched perspective on ISO AM: 1) organizational â€sline of sight' (complement key performance indicators with evidence-based causal relationships), 2) control of work (complement formal institutions with AM professionalism), 3) management accounting (advance decision support for the management of the capex/opex relationship), 4) transition modeling (advance agent-based models of AM), and 5) the sustainable management of the resource soil (assess the ecosystem services/disservices that arise from underground urban space use by GAMO during transition times).",,2015
888c5ce0c1e62fa4c429bd60dac375c6e9954ba8,https://www.semanticscholar.org/paper/888c5ce0c1e62fa4c429bd60dac375c6e9954ba8,Faults diagnosis and assessment of transformer insulation oil quality: intelligent methods based on dissolved gas analysis a-review,"The search for determining accurate faults and assessing the oil quality of high voltage electrical power transformers for life-long maintenance is ever-demanding. The durability of transformers function is significantly decided by the excellence of its insulation which deteriorates over time due to temperature fluctuations and moisture contents. The accurate diagnoses of faults in early stages and the efficient assessment of oil quality using an intelligent program is the key challenges in protecting transformers from potential failures occur during operation to avoid economic losses. The dissolved gases analysis in oil is a reliable method in the diagnosis of faults and assessing the quality of insulating oil in transformers. Recently, application of artificial intelligence (AI) has included fuzzy logic, expert system (EPS), and artificial neural network (ANN), Expert system and fuzzy logic can take DGA standards. This paper represents the review most of the methods used to diagnose faults and assessment of insulating oil for transformers through the dissolved gases analysis DGA.",,2015
e332014385ae977489ee3872a9fd969b91096286,https://www.semanticscholar.org/paper/e332014385ae977489ee3872a9fd969b91096286,A new model for Assessment and Optimization of Number of Spare Transformers and their Locations in Distribution Systems,"In this paper, a new model has been presented to determine the number of spare transformers and their locations for distribution stations. The number of spare transformers must be so that they need minimum investment. Furthermore, they must be sufficient for replacing with transformers that have been damaged. For this reason, in this paper a new purpose function has been presented to maximize profit in distribution company’s budgeting and planning. For determining the number of spares that must be available in a stock room, this paper considers the number of spares and transformer’s fault at the same time. The number of spare transformers is determined so that at least one spare transformer will be available for replacing with the failed transformers. This paper considers time required for purchasing or repairing a failed transformer to determine the number of required spare transformers. Furthermore, whatever the number of spare equipment are increased, cost of maintenance will be increased, so an economic comparison must be done between reduced costs from reducing of outage time and increased costs from spare transformers existence.",,2015
d8a249356757a1e5d05aa456cba6c583c6e9aa63,https://www.semanticscholar.org/paper/d8a249356757a1e5d05aa456cba6c583c6e9aa63,Design of early fault detection technique for electrical assets using infrared thermograms,"Abstract Infrared thermography is a non destructive temperature measuring technique, widely used in agriculture, process industries, manufacturing, pharmaceutical industries, and construction industries to detect anomalies, to predict possible faults, or to check the quality of the object. In this paper, two systems, real time and off line, are proposed to monitor the temperature variations and analyze hot regions in the electrical assets using infrared thermograms. This novel technique helps to prevent the electrical assets before any catastrophe would happen in the future. The color based segmentation technique is used to blotch hot regions in the thermograms of electrical systems. A redness area based algorithm is also proposed to analyze the hot regions and also to estimate rate of change of hotness in electrical assets for early detection and prediction of faults.",,2014
a86fbee3129d1a561a63d361c67699e22acbc328,https://www.semanticscholar.org/paper/a86fbee3129d1a561a63d361c67699e22acbc328,An approach to fault diagnosis of nonlinear systems using neural networks with invariance to Fourier transform,"A neural network with Gauss-Hermite polynomial activation functions is used for approximating the nonlinear system’s dynamics out of a set of input-output data. Thus the output of the neural network provides a series expansion that takes the form of a weighted sum of Gauss-Hermite basis functions. Knowing that the Gauss-Hermite basis functions satisfy the orthogonality property and remain unchanged under the Fourier transform, subjected only to a change of scale, one has that the considered neural network provides the spectral analysis of the output of the monitored system. Actually, the squares of the weights of the output layer of the neural network denote the distribution of energy into the associated spectral components for the output signal of the monitored nonlinear system. By observing changes in the amplitude of the aforementioned spectral components one can have also an indication about malfunctioning of the monitored system and can detect the existence of failures. Moreover, since specific faults are associated with amplitude changes of specific spectral components of the system fault isolation can be also performed.",J. Ambient Intell. Humaniz. Comput.,2013
0b38fd615306890a32ce4fb0fd155e74e3b6a693,https://www.semanticscholar.org/paper/0b38fd615306890a32ce4fb0fd155e74e3b6a693,Detailed three-phase circuit model for power transformers over wide frequency range based on design parameters,"This paper presents a detailed three-phase transformer model, the elements of which are expressed analytically according to the physical layout and the design construction parameters of the power transformer. These expressions have been calculated theoretically and verified through finite elements simulations. The proposed model allows to obtain the internal voltage distribution through the three-phase transeywords: igh frequency ower transformers esign parameters urge voltage ightning discharge former in any type of operating condition, particularly when it is simulated in an electromagnetic time domain transient simulation tool, providing an external and internal characterization of the transformer in a frequency band that can appear in a power system (up to 1 MHz). The obtained results have been compared with both lightning and low frequency tests measurements, showing a good agreement. © 2012 Elsevier B.V. All rights reserved.",,2012
673cf00fdbf8003c3bfb1944dc66d9a969a8f471,https://www.semanticscholar.org/paper/673cf00fdbf8003c3bfb1944dc66d9a969a8f471,Prioritization of maintenance activities from an electricity company,"Due to aging and wear of the electrical equipment existing in power system and also due to the fast technological change is necessary to take timely and appropriate decisions (maintenance, repair, relocation, refurbishment, replacement) for moral or/and physically damaged components and adding supplementary elements (features), including the introduction of new technologies. This paper presents the concept of asset management as a complex process of decision-making on the assets managed by an electricity company, the stages of implementing an asset management system to quantify the real technical state of the equipment, and finally the importance of the power substations from an electricity company, with the aim to prioritize the maintenance activities. In addition to the theoretical presentation of the asset management concept, it was performed a determination card of the importance index of a power substation from power system.",2012 13th International Conference on Optimization of Electrical and Electronic Equipment (OPTIM),2012
6c91eb3ffa9c5a3122b25deaaff5cd750b0f6f64,https://www.semanticscholar.org/paper/6c91eb3ffa9c5a3122b25deaaff5cd750b0f6f64,"Determination of phenol, m-cresol and o-cresol in transformer oil by HPLC method","Abstract Paper and mineral transformer oil are the major insulating materials used in transformers. Besides them, various materials are used for insulation or construction purposes like hard paper, laminated wood, rubber, resins, coatings, adhesives and other. These materials are in contact with the oil, due to thermal and electrical stresses they degrade and finally breakdown, producing gaseous, liquid and solid degradation products. The degradation products are partly soluble in the oil and partly excreted in the form of sludge. Some degradation products are characteristic for specific materials, so-called markers, like furans for cellulose, phenol and cresols for phenolic resins. It was confirmed that phenol, m -cresol and o -cresol are not present in new oils and that their presence may indicate degradation of insulation material. Samples of laminated pressboard and laminated wood were exposed to accelerated ageing tests to confirm the origin of phenol, m -cresol and o -cresol in transformer oil. The paper describes the method for determination of phenol, m -cresol and o -cresol in transformer oil by a high performance liquid chromatography (HPLC). Sample preparation by liquid–liquid extraction, compound separation in a single run and detection with a photo diode array detector are also described. Detection of phenol, m -cresol and o -cresol in transformer oil from operating transformers by HPLC technique provides an additional diagnostic tool for assessing normal or abnormal condition of transformer insulation, and presents a complementary technique to dissolved gas analysis.",,2012
bb501a7d7e3ab2d2a95f25c46d4362bb7adf8223,https://www.semanticscholar.org/paper/bb501a7d7e3ab2d2a95f25c46d4362bb7adf8223,Detailed three-phase circuit model for power transformers over wide frequency range based on design parameters,"Abstract This paper presents a detailed three-phase transformer model, the elements of which are expressed analytically according to the physical layout and the design construction parameters of the power transformer. These expressions have been calculated theoretically and verified through finite elements simulations. The proposed model allows to obtain the internal voltage distribution through the three-phase transformer in any type of operating condition, particularly when it is simulated in an electromagnetic time domain transient simulation tool, providing an external and internal characterization of the transformer in a frequency band that can appear in a power system (up to 1 MHz). The obtained results have been compared with both lightning and low frequency tests measurements, showing a good agreement.",,2012
511fec929deb2037fe4de69fd5341eb947705c03,https://www.semanticscholar.org/paper/511fec929deb2037fe4de69fd5341eb947705c03,"Development of Low Cost Medical Drone, Using COTS Equipment","This paper describes the development of a low cost Drone System developed with 3D printer and Commercial of the Shelf equipment (COTS), for the use in a pandemic scenario, where the authorities have a lack of resources to guarantee of the law, order and sanitary procedures. In the beginning of the COVID-19 pandemic, due the lack of knowledge of this disease, only the strict necessary services were working, directly affecting the medical workforce, cleaning services and others related, as well the social relationship between the people. The infected “places”, e.g., Hospital and places where people tested positive for COVID-19, were physically isolated, with limited communication and restrict access. Considering the intrinsic challenges by this situational hazard scenario, three Drone model were developed, the Medical Drone System (MDS). The first system is called by Cargo Drone, it was developed to carrier medical equipment and/or medicines between two points, the second development was the Aerial Eye Drone, to remotely check the people temperature on the ground using thermal cameras. The third system, is called by Sterilizer Drone. It is employed for spraying/disinfect the environment, e.g., urban region (train, metro, bus stations or indoor big places). During the pandemic scenario, we had a lack of resources to develop our equipment, employees, logistics and money. For this reason, the manufacture process was changed to use COTS equipment, 3D printers and other machines that allowed us to increase the automatization of the manufacture process. In addition to the development and manufacture challenges, the Drone operation is a factor that shall be considered. The Drone will flight over the cities, in VLOS or BVLOS envelop, e.g. restrict areas, and according with our laws, the equipment must guarantee that the airworthiness follow the requirement. The Drone operation will be monitored in real time by the local operator and/or for a situation room, using IoT devices, that shall be able to control de Drone remotely, access the air space controller, and manages the data, which will reflect the situational analysis of the situation / areas, allowing a better management of available resources.",2021 IEEE Aerospace Conference (50100),2021
189d4c0c6f9134990c207c0c2e557859b57cc8fd,https://www.semanticscholar.org/paper/189d4c0c6f9134990c207c0c2e557859b57cc8fd,Distributed-force-feedback-based reflex with online learning for adaptive quadruped motor control,"Biological motor control mechanisms (e.g., central pattern generators (CPGs), sensory feedback, reflexes, and motor learning) play a crucial role in the adaptive locomotion of animals. However, the interaction and integration of these mechanisms - necessary for generating the efficient, adaptive locomotion responses of legged robots to diverse terrains - have not yet been fully realized. One issue is that of achieving adaptive motor control for fast postural adaptation across various terrains. To address this issue, this study proposes a novel distributed-force-feedback-based reflex with online learning (DFRL). It integrates force-sensory feedback, reflexes, and learning to cooperate with CPGs in producing adaptive motor commands. The DFRL is based on a simple neural network that uses plastic synapses modulated online by a fast dual integral learner. Experimental results on different quadruped robots show that the DFRL can (1) automatically and rapidly adapt the CPG patterns (motor commands) of the robots, enabling them to realize appropriate body postures during locomotion and (2) enable the robots to effectively accommodate themselves to various slope terrains, including steep ones. Consequently, the DFRL-controlled robots can achieve efficient adaptive locomotion, to tackle complex terrains with diverse slopes.",Neural Networks,2021
1e253d8d0b2412c8ca59493057849164a72b2c26,https://www.semanticscholar.org/paper/1e253d8d0b2412c8ca59493057849164a72b2c26,A Phase Control Method for the Dynamical Attractor of the HR Neuron Model: The Rotation-Transition Process and Its Experimental Realization,"Since the definitions of the biological neuron model are similar to the oscillator structures, many control theorems are used in common with the biological neuron model. While the stability and the synchronization etc. control methods are frequently studied subject for these nonlinear systems, the “rotation-transition” concept draws attention in the recent studies dealing with nonlinear dynamical systems. The studies about the rotation-transition of the nonlinear systems are usually focused on the chaotic oscillator structures. On the other hand, the concept of the rotated attractor is also encountered in the dynamics of biological systems and there is no research about the rotation-transition of biological neuron models. In this study, the rotation-transition process of the Hindmarsh–Rose neuron model has been performed for the first time. In this context, firstly, the HR neuron model is converted to a rotated structure by using the Euler’s rotation theorem. Then, the characteristics outcomes of the rotated HR neuron model are analyzed by calculating the equilibrium points and Lyapunov exponents. The functionality of the rotated HR neuron model has been tested by the numerical simulation studies. Lastly, the rotated HR neuron model is implemented by using FPGA device. Briefly, this conversion process is modeled mathematically, then supported by the results of numerical simulations and finally verified by the results of the FPGA based experimental realizations. Thus, a phase control method for the dynamical attractor of a neuron model is achieved without the need for any coupling identification in this system.",Neural Process. Lett.,2021
2321e96c8f2db37d9d9264c1cde86e1720d7f5f7,https://www.semanticscholar.org/paper/2321e96c8f2db37d9d9264c1cde86e1720d7f5f7,On addressing the similarities between STDP concept and synaptic/memristive coupled neurons by realizing of the memristive synapse based HR neurons,,"Engineering Science and Technology, an International Journal",2021
28186cc185c4faafbbe5d2dbc870bc48947651bd,https://www.semanticscholar.org/paper/28186cc185c4faafbbe5d2dbc870bc48947651bd,A reference spike train-based neurocomputing method for enhanced tactile discrimination of surface roughness,"Spike trains (STs) induced by external stimuli are complex and challenging to decode the embedded spatiotemporal information. Although various methods have been developed to characterize STs, few applications have been reported in tactile discrimination applications. In this paper, a neurocomputing method based on reference spike train (RST) is proposed to establish a neural computation scheme, on which existing ST metrics could be fed into various traditional models directly. Moreover, existing metrics in the field of statistics and vector measurement are introduced together to extract more discriminative features. With the binning technique and feature selection algorithm applied, the neural computation scheme is aimed at taking advantage of as maximal as possible information contained in tactile signals. Based on our designed artificial fingertip, the effect is validated by improving the recognition accuracy from 77.6% to 83.4% when it is applied to the discrimination of eight roughness surfaces. Furthermore, properties of RST, such as spike intervals and distributions, are evaluated and it is found that RSTs with uniform distribution perform the best for tactile discrimination.",Neural Comput. Appl.,2021
88420dc1e7be5c9309ee123d93784f707fe99e02,https://www.semanticscholar.org/paper/88420dc1e7be5c9309ee123d93784f707fe99e02,A four-state adaptive Hopf oscillator,"Adaptive oscillators (AOs) are nonlinear oscillators with plastic states that encode information. Here, an analog implementation of a four-state adaptive oscillator, including design, fabrication, and verification through hardware measurement, is presented. The result is an oscillator that can learn the frequency and amplitude of an external stimulus over a large range. Notably, the adaptive oscillator learns parameters of external stimuli through its ability to completely synchronize without using any pre- or post-processing methods. Previously, Hopf oscillators have been built as two-state (a regular Hopf oscillator) and three-state (a Hopf oscillator with adaptive frequency) systems via VLSI and FPGA designs. Building on these important implementations, a continuous-time, analog circuit implementation of a Hopf oscillator with adaptive frequency and amplitude is achieved. The hardware measurements and SPICE simulation show good agreement. To demonstrate some of its functionality, the circuit’s response to several complex waveforms, including the response of a square wave, a sawtooth wave, strain gauge data of an impact of a nonlinear beam, and audio data of a noisy microphone recording, are reported. By learning both the frequency and amplitude, this circuit could be used to enhance applications of AOs for robotic gait, clock oscillators, analog frequency analyzers, and energy harvesting.",PloS one,2021
326e0d9d455f451a37b94b54f50a3b586f30461c,https://www.semanticscholar.org/paper/326e0d9d455f451a37b94b54f50a3b586f30461c,Gait Control of Hexapod Robot Based on Field-Programmable Gate Array and Central Pattern Generator,"Received: 3 June 2020 Accepted: 29 August 2020 This paper attempts to improve the terrain adaptability of hexapod robot through gait control. Firstly, the multi-leg coupling in the tripodal gait of the hexapod robot was modeled by Hopf oscillator. Then, annular central pattern generator (CPG) was adopted to simulate the leg movements of hexapod robot between signals. Furthermore, a physical prototype was designed for the gait control test on field-programmable gate array (FPGA), and the algorithm of the rhythmic output of the model was programmed in Verilog, a hardware description language. Finally, the effectiveness of our gait control method was verified through the simulation on Xilinx. The results show that the phase difference of the CPG network remained stable; the designed hexapod robot moved at about 5.15cm/s stably in a tripodal gait, and outperformed wheeled and tracked robots in terrain adaptation. The research findings lay a solid basis for the design of all-terrain multi-leg robots.",,2020
191d1ddcf37d2d311de1830550d9ed3f05091a1b,https://www.semanticscholar.org/paper/191d1ddcf37d2d311de1830550d9ed3f05091a1b,Programmable coupled oscillators for synchronized locomotion,"The striking similarity between biological locomotion gaits and the evolution of phase patterns in coupled oscillatory network can be traced to the role of central pattern generator located in the spinal cord. Bio-inspired robotics aim at harnessing this control approach for generation of rhythmic patterns for synchronized limb movement. Here, we utilize the phenomenon of synchronization and emergent spatiotemporal pattern from the interaction among coupled oscillators to generate a range of locomotion gait patterns. We experimentally demonstrate a central pattern generator network using capacitively coupled Vanadium Dioxide nano-oscillators. The coupled oscillators exhibit stable limit-cycle oscillations and tunable natural frequencies for real-time programmability of phase-pattern. The ultra-compact 1 Transistor-1 Resistor implementation of oscillator and bidirectional capacitive coupling allow small footprint area and low operating power. Compared to biomimetic CMOS based neuron and synapse models, our design simplifies on-chip implementation and real-time tunability by reducing the number of control parameters. Designing alternative paradigms for bio-inspired analog computing that harnesses collective dynamics remains a challenge. Here, the authors exploit the synchronization dynamics of coupled vanadium dioxide-based insulator-to-metal phase-transition nano-oscillators for adaptive locomotion control.",Nature Communications,2019
227275ef72b82e5ab073bdab65b4c7444bfe75cd,https://www.semanticscholar.org/paper/227275ef72b82e5ab073bdab65b4c7444bfe75cd,An Alternative Approach for Setting the Optimum Coupling Parameters Among the Neural Central Pattern Generators Considering the Amplitude and the Phase Error Calculations,"In general, the equivalent amplitude values and the specific phase differences between the oscillators/neurons are desired to obtain the smooth movements in the CPG based robotic applications. However, in the literature, the error minimization functions calculate either the amplitude or the phase errors between the nonlinear dynamics. This study offers an alternative error minimization approach. This approach calculates both the amplitude and the phase errors, simultaneously. The proposed approach, the RMS function and the phase error function have been utilized as the cost functions of the genetic and the ABC algorithms for the performance evaluation of the proposed approach. These functions have been assessed for estimating the coupling parameters of the electrically coupled HR neurons. According to the results, the proposed approach has minimum errors when compared with the other two functions. On the other hand, to utilize these estimated coupling parameters in the real-time applications, to create the CPG networks by using the coupled neurons and to use these emulated neurons in a locomotion control problem offer a particular importance for the developments in this field. Here, the HR neurons, which are coupled with the estimated parameters, have been implemented with FPGA device by using the SGDSP tool. Thus, the applicability to the real-time systems of the proposed approach has been verified with a hardware realization. Then, the trot gait pattern of a quadruped robot has been controlled by using these emulated neuronal responses, so the coupled biological neurons have been used as a controller in a CPG based multi-legged robotic application, successfully.",Neural Processing Letters,2019
762b881733dd003a6cd12944c19e16907c9d7abf,https://www.semanticscholar.org/paper/762b881733dd003a6cd12944c19e16907c9d7abf,Snake Robot Controlled by Biomimetic CPGs,Locomotion is one of the most basic abilities in animals. Neurobiologists have established that locomotion results from the activity of half-center oscillators that provides alternation of bursts. Central Pattern Generators (CPGs) are neural networks capable of producing rhythmic patterned outputs without rhythmic sensory or central input. We propose a network of several biomimetic CPGs using biomimetic neuron model and synaptic plasticity. This network is implemented on a FPGA (Field Programmable Gate Array). We designed one unsupervised snake robot using this network of CPG. It is composed of one head wagon and 7 slave wagon. Infrared sensors are also embedded in the head wagon. This robot can reproduce the locomotion of one snake. The hardware robot is also described in this paper.,J. Robotics Netw. Artif. Life,2019
83a20da63fc888909e078e56df416280165375f6,https://www.semanticscholar.org/paper/83a20da63fc888909e078e56df416280165375f6,A Microcontroller Implementation Of Hindmarsh-Rose Neuron Model-Based Biological Central Pattern Generator,"Central Pattern Generator (CPG) has an important role in controlling the locomotion part of the animals. Bio-inspired Central Pattern Generators can find application areas in robotic and control applications. FPGA implementations of Central Pattern Generators have already been studied in literature. Not all institutes have FPGA systems. In this paper, it is shown that like STM32F103 devices which use the Cortex-M3, a Hindmarsh-Rose (HR) neuron model can be made using a cheap microcontroller board. The experimental results verify that the system is successfully able to reproduce the original Central Pattern Generator patterns.",2019 1st International Informatics and Software Engineering Conference (UBMYK),2019
317c9e6cfeb538573a2a045568e7df10cee19a0d,https://www.semanticscholar.org/paper/317c9e6cfeb538573a2a045568e7df10cee19a0d,Spiking Central Pattern Generators through Reverse Engineering of Locomotion Patterns,"In robotics, there have been proposed methods for locomotion of nonwheeled robots based on artificial neural networks; those built with plausible neurons are called spiking central pattern generators (SCPGs). In this chapter, we present a generalization of reported deterministic and stochastic reverse engineering methods for automatically designing SCPG for legged robots locomotion systems; such methods create a spiking neural network capable of endogenously and periodically replicating one or several rhythmic signal sets, when a spiking neuron model and one or more locomotion gaits are given as inputs. Designed SCPGs have been implemented in different robotic controllers for a variety of robotic platforms. Finally, some aspects to improve and/or complement these SCPG-based locomotion systems are pointed out.","Cognitive and Computational Neuroscience - Principles, Algorithms and Applications",2018
41f6ed664e880820e25a77d052d03c585a86264e,https://www.semanticscholar.org/paper/41f6ed664e880820e25a77d052d03c585a86264e,Dynamics of Optoelectronic Oscillators With Electronic and Laser Nonlinearities,"We present a theoretical and experimental study of a low-frequency optoelectronic oscillator featuring both laser-diode and Van der Pol-like nonlinearities. In this architecture, the device performing the electrical-to-optical conversion is the laser-diode itself instead of an external electro-optical modulator, while the electric branch of the oscillator is characterized by a Van der Pol nonlinear transfer function. We show that the system displays a complex autonomous dynamics, induced by the competition between these two nonlinearities. In the case of small delay, the system displays harmonic and relaxation oscillations. When the delay is large, the interplay between the two nonlinearities leads to a period-doubling route of bifurcations as the feedback gain is increased, and ultimately to fully developed chaos. Our experimental measurements are in good agreement with the theoretical analysis.",IEEE Journal of Quantum Electronics,2018
8abc1240fd02c210ad2a95f7e12c53ee61c26680,https://www.semanticscholar.org/paper/8abc1240fd02c210ad2a95f7e12c53ee61c26680,"Modeling, simulation, and implementation issues of CPGs for neuromorphic engineering applications","Neuromorphic engineering is a discipline used to develop hardware, which can mimic the characteristics and abilities of biological systems by investigating their physiological structures and data transfer mechanisms. The recent studies about the neuromorphic systems mostly consist of robotic applications whose designs are inspired by Central Pattern Generators (CPGs). CPGs are special neural networks which can produce coordinated rhythmic activity patterns and these rhythmic movements are modeled mathematically, tested with simulation programs and verified by hardware implementations. A reconfigurable hardware platform (Field Programmable Gate Array “FPGA”) is compatible with numerical simulation tools, allows software control over hardware, has a user‐friendly interface and allows real time modifications. Thus, recently, it is preferred in CPG based robotic applications. In this study, the details of the modeling, simulation and implementation stages of several CPG structures are introduced by using a digital reconfigurable hardware platform. In order to show the conceptual learning achievements of these stages and to assess the contribution to the modeling, simulation and implementation skills of the students, a training course has been planned for the undergraduate students at Erciyes University. This process has been held in an educative manner supported by a survey and an experimental examination, so that this training course has been evaluated by the trainees in terms of the advantage, practicality, and challenge.",Comput. Appl. Eng. Educ.,2018
ac9e47dfcb22a2777d41ea5c1149e7482a842df0,https://www.semanticscholar.org/paper/ac9e47dfcb22a2777d41ea5c1149e7482a842df0,A novel hardware-efficient CPG model based on asynchronous cellular automaton,"A novel hardware-efficient central pattern generator (CPG) model the dynamics of which is described by an asynchronous cellular automaton is proposed. It is shown that the proposed model can generate multi-phase synchronized periodic signals, which are suitable for controlling a serpentine motion of a snake-like robot. The proposed model is then implemented on a field programmable gate array (FPGA) and is used to control a snake-like robot. It is shown by experimental validation using a prototype machine that the proposed model can realize rhythmic locomotor activity in snakes. Moreover, it is shown that the proposed model consumes much fewer hardware resources (FPGA slices) than a typical conventional CPG model. Also, parameter setting methods to adjust the locomotion of the robot are shown.",IEICE Electron. Express,2018
bbbf44262d5e6dd9feddaac00ec08548ed4e8e54,https://www.semanticscholar.org/paper/bbbf44262d5e6dd9feddaac00ec08548ed4e8e54,Digital Hardware Implementation of a Biological Central Pattern Generator,"Central Pattern Generator (CPG) plays a key role in controlling the locomotion part of the animals. Bio-inspired CPGs can be employed in many robotic and control applications. A digital hardware implementation of a central pattern generator based on Hindmarsh-Rose (HR) neuron model is presented in this paper. Aiming an efficient implementation, the neuron module is implemented using multiplier-less Piecewise Linear (PWL) method. The CPG network is built by coupling HR neuron modules to produce the anti-phase patterns in the output of the network. The system has been developed by Hardware Description Language (HDL) and synthesized based on an Altera FPGA. Synthesis results for a block of CPG indicate that it takes less than 1% of the resources of a Stratix IV Altera FPGA for the proposed system. The results have been compared for the proposed digital hardware and the original CPG implementation. Also, hardware implementation results verify that the system is successfully able to reproduce the original CPG patterns.",2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS),2018
22d86c1d6d359fbd5a4c05579cfabd01b58eccb3,https://www.semanticscholar.org/paper/22d86c1d6d359fbd5a4c05579cfabd01b58eccb3,A Novel Hardware-Efficient CPG Model Based on Nonlinear Dynamics of Asynchronous Cellular Automaton,"A novel hardware-efficient central pattern generator (CPG) model based on the nonlinear dynamics of an asynchronous cellular automaton is presented. It is shown that the presented model can generate multi-phase synchronized periodic signals, which are suitable for controlling a snake robot. Then, the presented model is implemented on a field programmable gate array (FPGA) and is connected to a snake robot hardware. It is shown by real machine experiments that the presented model can realize rhythmic spinal locomotions of the snake robot. Moreover, it is shown that the presented model consumes much fewer hardware resources (FPGA slices) than a standard simple CPG model.",ICONIP,2017
3cba44e61f202267bc95625b87db4385e05a29d2,https://www.semanticscholar.org/paper/3cba44e61f202267bc95625b87db4385e05a29d2,Neuromorphic photonic networks using silicon photonic weight banks,"Photonic systems for high-performance information processing have attracted renewed interest. Neuromorphic silicon photonics has the potential to integrate processing functions that vastly exceed the capabilities of electronics. We report first observations of a recurrent silicon photonic neural network, in which connections are configured by microring weight banks. A mathematical isomorphism between the silicon photonic circuit and a continuous neural network model is demonstrated through dynamical bifurcation analysis. Exploiting this isomorphism, a simulated 24-node silicon photonic neural network is programmed using “neural compiler” to solve a differential system emulation task. A 294-fold acceleration against a conventional benchmark is predicted. We also propose and derive power consumption analysis for modulator-class neurons that, as opposed to laser-class neurons, are compatible with silicon photonic platforms. At increased scale, Neuromorphic silicon photonics could access new regimes of ultrafast information processing for radio, control, and scientific computing.",Scientific Reports,2017
4246d60507e8164c55a8a5c0b402c5e786ddc70c,https://www.semanticscholar.org/paper/4246d60507e8164c55a8a5c0b402c5e786ddc70c,A Survey of Neuromorphic Computing and Neural Networks in Hardware,"Neuromorphic computing has come to refer to a variety of brain-inspired computers, devices, and models that contrast the pervasive von Neumann computer architecture. This biologically inspired approach has created highly connected synthetic neurons and synapses that can be used to model neuroscience theories as well as solve challenging machine learning problems. The promise of the technology is to create a brain-like ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities. In this work, we provide a comprehensive survey of the research and motivations for neuromorphic computing over its history. We begin with a 35-year review of the motivations and drivers of neuromorphic computing, then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications. We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of neuromorphic computing fulfilled. The goals of this work are to provide an exhaustive review of the research conducted in neuromorphic computing since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed.",ArXiv,2017
4d8fa54a23581d052296c31ae955cf711d01210f,https://www.semanticscholar.org/paper/4d8fa54a23581d052296c31ae955cf711d01210f,OFDM symbol identification by an unsupervised learning system under dynamically changing channel effects,"Orthogonal frequency-division multiplexing (OFDM) is one of the most successful digital communication techniques. Nevertheless, the decrease in inter-symbol interference in quadrature amplitude modulation (QAM) over dispersive channels is still challenging. Different researches recently proposed the idea of using unsupervised learning as an alternative to the classic approaches to equalization of OFDM channels. In those purposes, the identification of a received QAM symbol is possible by the comparison of its position on the in-phase/quadrature (IQ) plane relative to the positions of previously arrived symbols, generally processed by the Kohonen’s Self-Organizing Map (SOM) algorithm. This work presents the SOM unsupervised learning method executed on an embedded system applied to QAM symbols identification. The system is implemented on an FPGA, a configurable digital circuit able to meet the low power and parallel process requirements of mobile applications. Also, in order to extend the classical set of experiments to evaluate our system, this paper proposes a theoretical model of the time-varying scheme representing the transition between different channel characteristics, obtained from real measurements available on a public repository. The model is employed to verify our purpose under dynamically both changing and realistic conditions. On the assumption that it is provided enough IQ symbols for the initial training process, the hardware implementation of SOM is able to track and identify the time-varying distorted QAM constellation. No knowledge of channel characteristics is necessary. The system spends only some microseconds at start-up to reach about 100% performance, and no dedicated training phase is needed afterward.",Neural Computing and Applications,2018
ad81864fed1050df117f4590d49a3700b7f3f40f,https://www.semanticscholar.org/paper/ad81864fed1050df117f4590d49a3700b7f3f40f,A real-time FPGA implementation of a biologically inspired central pattern generator network,"We engineer a basic CPG with conductance-based KomendantovKononenko neuron model.We propose a multiplier-less FPGA implementation method with low hardware cost.The neural dynamics are highlighted in the design in a biorealistic manner.We employ piecewise linearization method to obtain the reduced neuron model. Central pattern generators (CPGs) functioning as biological neuronal circuits are responsible for generating rhythmic patterns to control locomotion. In this paper, a biologically inspired CPG composed of two reciprocally inhibitory neurons was implemented on a reconfigurable FPGA with real-time computational speed and considerably low hardware cost. High-accuracy neural circuit implementation can be computationally expensive, especially for a high-dimensional conductance-based neuron model. Thus, we aimed to present an efficient multiplier-less hardware implementation method for the investigation of real-time hardware CPG (hCPG) networks. In order to simplify the hardware implementation, a modified neuron model without nonlinear parts was given to decrease the complexity of the original model. A simple CPG network involving two chemical coupled neurons was realized which represented the pyloric dilator (PD) and lateral pyloric (LP) neurons in the crustacean pyloric CPG. The implementation results of the hCPG network showed that rhythmic behaviors were successfully reproduced and the resource consumption was dramatically reduced by using our multiplier-less implementation method. The presented FPGA-based implementation of hCPG network with remarkable performance set a prototype for the realization of other large-scale CPG networks and could be applied in bio-inspired robotics and motion rehabilitation for locomotion control.",Neurocomputing,2017
adde5fd3346da73402acc4be343a2d89b9dcaa26,https://www.semanticscholar.org/paper/adde5fd3346da73402acc4be343a2d89b9dcaa26,An FPGA distributed implementation model for embedded SOM with on-line learning,"Neuroengineering has contributed to the increasing capability of embedded hardware to efficiently execute neural computation models. These hardware structures, suitable for implementing only the recall phase or both phases — learning and recall — of artificial neural networks (ANNs) are generally identified as neuromorphic systems. Some features of the FPGA technology resemble characteristics usually associated to ANNs, such as the parallel processing and the configurability of digital circuits. Embedded neural systems elaborated to execute Self-Organizing Maps (SOMs) can take advantage of the circuit parallelism to speed-up training process and also of the design flexibility by the hardware reconfiguration enabled by FPGA chips. Hardware-based SOMs capable of executing the training process on chip are relevant because they can be employed in a wide variety of stand-alone applications. loT and mobile robotics are examples of some challenging research fields that use unsupervised learning to extract information from the surrounding environment and require the portability of embedded systems. This work presents a distributed architecture to implement SOM learning and recall algorithms into FPGAs. The distributed model does not employ any type of central control unit hence allowing a simple hardware redesign process during the configuration of the neural system. The set of experiments used for verifying the proposed architecture is specified in a data stream format. The aim of choosing streaming condition is to simulate applications in which the FPGA-based SOM must process a continuous flow of information autonomously. All the steps of the SOM learning algorithm to process an input sample are performed in a single clock cycle and implementation results show a maximum clock speed of 2.38 MHz. Synthesis reports on FPGA implementation of the distributed architecture for the experiments carried out herein also indicate that the factor of increase in consumption of chip resources is lower than the increment in the total number of SOM connections.",2017 International Joint Conference on Neural Networks (IJCNN),2017
b70dceff8de656607313e8666013f42fef1bb4bc,https://www.semanticscholar.org/paper/b70dceff8de656607313e8666013f42fef1bb4bc,K3P: A walking gait generator algorithm,"Generating a walking pattern for a legged robot is not an easy task. In the literature there are different proposed approaches: mathematical, model-based and bioinspired methods in order to generate such walking patterns for legged robots. In this article we present the K3P algorithm, conceived to command a robotic legged platform to travel along an arbitrary trajectory, using the velocity of the center of mass as reference for the movements of the legs. The backbone of the K3P algorithm is a kinematic planner, where the center of mass of the robot is propelled forward at the commanded speed and direction while the legs are reconfigured to steadily support the body of the robot. In comparison to other approaches, the K3P algorithm does not use precomputed pattern nor trajectory for the legs or body; instead, the gait generation pattern is done online, during the actual walking of the robot. In this document, we present all the specific details of the algorithm, as well as numeric results of the walking of an hexapod in a virtual test scenario.","2017 14th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)",2017
ebf8c599a2998c1c412e55233a75e84dfd6a29e8,https://www.semanticscholar.org/paper/ebf8c599a2998c1c412e55233a75e84dfd6a29e8,Central Pattern Generators (CPG) biomimétiques en temps-réel sur FPGA pour des expérimentations biohybrides,"L'hybridation est une technique qui consiste a interconnecter un reseau de neurones biologiques et un reseau de neurones artificiels. Elle est notamment utilisee dans la recherche en neuroscience et a des fins therapeutiques. L'objectif a long-terme est de remplacer les reseaux de neurones endommages par des systemes artificiels. Ceux-ci requierent le developpement de modeles de neurones dont l'activite electrique est similaire a l'activite des reseaux biologiques vivants. Cette correspondance permet de produire une stimulation adequate afin de restaurer la fonction neurale desiree. Dans cet article, un reseau de neurones artificiels numeriques avec une architecture configurable a ete realise. Le reseau de neurones artificiels permet d'emuler l'activite de CPGs (Central Pattern Generator), a l'origine de la locomotion chez les animaux. Cette activite permet de declencher une serie de stimulations sur une moelle epiniere lesee et de recreer ainsi la locomotion precedemment perdue. Ces resultats sont une premiere etape vers des solutions hybrides artificiel / biologique basees sur la micro-stimulation electrique pour la restauration de fonctions du Systeme Nerveux Central (SNC).",,2017
8e4d685effe25ab5f6b7f81235bd89b27c289a99,https://www.semanticscholar.org/paper/8e4d685effe25ab5f6b7f81235bd89b27c289a99,Neural networks within multi-core optic fibers,"Hardware implementation of artificial neural networks facilitates real-time parallel processing of massive data sets. Optical neural networks offer low-volume 3D connectivity together with large bandwidth and minimal heat production in contrast to electronic implementation. Here, we present a conceptual design for in-fiber optical neural networks. Neurons and synapses are realized as individual silica cores in a multi-core fiber. Optical signals are transferred transversely between cores by means of optical coupling. Pump driven amplification in erbium-doped cores mimics synaptic interactions. We simulated three-layered feed-forward neural networks and explored their capabilities. Simulations suggest that networks can differentiate between given inputs depending on specific configurations of amplification; this implies classification and learning capabilities. Finally, we tested experimentally our basic neuronal elements using fibers, couplers, and amplifiers, and demonstrated that this configuration implements a neuron-like function. Therefore, devices similar to our proposed multi-core fiber could potentially serve as building blocks for future large-scale small-volume optical artificial neural networks.",Scientific reports,2016
970ff5216f30c29d69d61139be94822484ca8fca,https://www.semanticscholar.org/paper/970ff5216f30c29d69d61139be94822484ca8fca,Fast FPGA-based method for Matsuoka parameters tuning,"In this paper we present a novel method for real time hardware implementation of Central Pattern Generators (CPGs) for bipedal robot walking. We introduce a closed form solution for Matsuoka CPG model which is a widely applied parametric neuron-based method for walking pattern generation. Existing parameter tuning methods including trial and error, optimization methods like genetic algorithms or etc. are both computationally slow and inefficient. Our methodology is arguably fast and accurate and can be implemented on FPGA in online applications.",2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS),2016
a106dd6e2ca27ca7f708c78fb4e402f527fbd82e,https://www.semanticscholar.org/paper/a106dd6e2ca27ca7f708c78fb4e402f527fbd82e,Prescription of rhythmic patterns for legged locomotion,"As the engine behind many life phenomena, motor information generated by the central nervous system plays a critical role in the activities of all animals. In this work, a novel, macroscopic and model-independent approach is presented for creating different patterns of coupled neural oscillations observed in biological central pattern generators (CPG) during the control of legged locomotion. Based on a simple distributed state machine, which consists of two nodes sharing pre-defined number of resources, the concept of oscillatory building blocks (OBBs) is summarised for the production of elaborated rhythmic patterns. Various types of OBBs can be designed to construct a motion joint of one degree of freedom with adjustable oscillatory frequencies and duty cycles. An OBB network can thus be potentially built to generate a full range of locomotion patterns of a legged animal with controlled transitions between different rhythmic patterns. It is shown that gait pattern transition can be achieved by simply changing a single parameter of an OBB module. Essentially, this simple mechanism allows for the consolidation of a methodology for the construction of artificial CPG architectures behaving as an asymmetric Hopfield neural network. Moreover, the proposed CPG model introduced here is amenable to analogue and/or digital circuit integration.",Neural Computing and Applications,2017
ade5faed74e8e56fb107b4e58d96fea21d869947,https://www.semanticscholar.org/paper/ade5faed74e8e56fb107b4e58d96fea21d869947,A Review of Image Interest Point Detectors: From Algorithms to FPGA Hardware Implementations,"Fast and accurate image feature detectors are an important challenge in computer vision as they are the basis for high-level image processing analysis and understanding. However, image feature detectors cannot be easily applied in real-time embedded computing scenarios, such as autonomous robots and vehicles, mainly due to the fact that they are time consuming and require considerable computational resources. For embedded and low power devices, speed and memory efficiency is of main concern, and therefore, there have been several recent attempts to improve this performance gap through dedicated hardware implementations of feature detectors. Thanks to the fine grain massive parallelism and flexibility of software-like methodologies, reconfigurable hardware devices, such as Field Programmable Gate Arrays (FPGAs), have become a common choice to speed up computations. In this chapter, a review of hardware implementations of feature detectors using FPGAs targeted to embedded computing scenarios is presented. The necessary background and fundamentals to introduce feature detectors and their mapping to FPGA-based hardware implementations are presented. Then we provide an analysis of some relevant state-of-the-art hardware implementations, which represent current research solutions proposed in this field. The review addresses a broad range of techniques, methods, systems and solutions related to algorithm-to-hardware mapping of image interest point detectors. Our goal is not only to analyze, compare and consolidate past research work but also to appreciate their findings and discuss their applicability. Some possible directions for future research are presented.",,2016
116d6e724d0d15fbb2e84d741477102f9d988ed3,https://www.semanticscholar.org/paper/116d6e724d0d15fbb2e84d741477102f9d988ed3,iCub Whole-Body Control through Force Regulation on Rigid Non-Coplanar Contacts,"This paper details the implementation on the humanoid robot iCub of state-of-the-art algorithms for whole-body control. We regulate the forces between the robot and its surrounding environment to stabilize a desired robot posture. We assume that the forces and torques are exerted on rigid contacts. The validity of this assumption is guaranteed by constraining the contact forces and torques, e.g. the contact forces must belong to the associated friction cones. The implementation of this control strategy requires to estimate the external forces acting on the robot, and the internal joint torques. We then detail algorithms to obtain these estimations when using a robot with an iCub-like sensor set, i.e. distributed six-axis force-torque sensors and whole-body tactile sensors. A general theory for identifying the robot inertial parameters is also presented. From an actuation standpoint, we show how to implement a joint torque control in the case of DC brushless motors. In addition, the coupling mechanism of the iCub torso is investigated. The soundness of the entire control architecture is validated in a real scenario involving the robot iCub balancing and making contacts at both arms.",Front. Robot. AI,2015
3547f22c730f0fee4b57a11001e467f248d43248,https://www.semanticscholar.org/paper/3547f22c730f0fee4b57a11001e467f248d43248,Perception-driven adaptive CPG-based locomotion for hexapod robots,"According to neurobiological studies, rhythmic motion in animals is controlled by neural circuits known as central pattern generators (CPGs), which are robust against transient perturbations. Yet, CPGs can integrate sensory feedback that potentially enables adaptive locomotion solutions. Despite previous works, the construction of practical embedded neuromorphic locomotion systems exhibiting similar properties and organization observed in CPGs is still reduced. In this paper a CPG-based control strategy able to modulate motion speed and manage smoothly gait transitions in hexapod robots according to visual information is proposed. Fuzzy logic and finite state machines are the base of the proposed integration mechanism used to map perception into locomotion parameters according to a sensed situation. A vision sensor is integrated in the CPG-based control loop to provide feedback in obstacle avoidance and target tracking behaviors within simplified experimental environments. Experimental results using an hexapod robot confirm both the effectiveness of the proposed control strategy and its use as an experimental embedded platform to investigate further adaptive locomotion, particularly about ways that biological systems fuse information from visual cues to adapt locomotion.",Neurocomputing,2015
cfc8a362f7f7e7b1bce51caac0db50dfb52b7f13,https://www.semanticscholar.org/paper/cfc8a362f7f7e7b1bce51caac0db50dfb52b7f13,Implementation of biomimetic central pattern generators on field-programmable gate array,"This study is a step towards the design of neuroprostheses using artificial biomimetic neural networks like the central pattern generator (CPG) we could find in the leech’s heartbeat system. We propose a resource-frugal implementation of CPG on a field-programmable gate array (FPGA) platform. Using Izhikevich’s neuron model and short-term plasticity synapse model, our implementation can host and mimic 500 CPGs in real time. Our results have been validated by comparing them to biological data. Our study shows a solid step towards hybridization of biological nervous system and artificial neural networks.",,2015
f2ff5247c19f6900264c0e9c51d4de7394aa8f7e,https://www.semanticscholar.org/paper/f2ff5247c19f6900264c0e9c51d4de7394aa8f7e,A CPG system based on spiking neurons for hexapod robot locomotion,"In this paper, we propose a locomotion system based on a central pattern generator (CPG) for a hexapod robot, suitable for embedded hardware implementation. The CPG system was built as a network of spiking neurons, which produce rhythmic signals for three different gaits (walk, jogging and run) in the hexapod robot. The spiking neuron model used in this work is a simplified form of the well-known generalized Integrate-and-Fire neuron model, which can be trained using the Simplex method. The use of spiking neurons makes the system highly suitable for digital hardware implementations that exploit the inherent parallelism to replicate the intrinsic, computationally efficient, distributed control mechanism of CPGs. The system has been implemented on a Spartan 6 FPGA board and fully validated on a hexapod robot. Experimental results show the effectiveness of the proposed approach, based on existing models and techniques, for hexapod rhythmic locomotion.",Neurocomputing,2015
70ac48d994aa4a85884384dcbad501b9f2451821,https://www.semanticscholar.org/paper/70ac48d994aa4a85884384dcbad501b9f2451821,Versatile educational and research robotic platform based on reconfigurable hardware,"This paper presents the development of a field-programmable gate array (FPGA)-based platform. This platform is intended for the community as an educational and efficient prototyping tool, in digital signal processing, robotics, and control, but it can also be used as to develop custom robotic architectures. The proposed platform centered around an FPGA device is embedded on an off-the-shelf Phoenix hexapod robot. The platform is equipped with a camera module targeted to real time computer vision. From an academic point of view, the main use for the developed platform is to be employed as a didactic resource that facilitates the understanding of theoretical concepts commonly used in engineering courses and to speed up the development cycle in hands-on practice. A set of software tools and low-level drivers have been developed to configure the vision sensor, transfer images to/from a computer and to manage the testing of image and digital processing and control tasks in a transparent way. To validate the platform a hardware vision architecture and a locomotion control module have been created. The high level control is performed in a soft-processor that simulates the Arduino ONE micro controller. The soft-processor takes information from the vision sensor to generate controls signals for a generic module able to take a digital input and deliver a pulse-width modulation (PWM) output.",2014 International Conference on ReConFigurable Computing and FPGAs (ReConFig14),2014
025ad7c103205bb5d742fe679bda0cf3da401a67,https://www.semanticscholar.org/paper/025ad7c103205bb5d742fe679bda0cf3da401a67,Real-time biomimetic Central Pattern Generators in an FPGA for hybrid experiments,"This investigation of the leech heartbeat neural network system led to the development of a low resources, real-time, biomimetic digital hardware for use in hybrid experiments. The leech heartbeat neural network is one of the simplest central pattern generators (CPG). In biology, CPG provide the rhythmic bursts of spikes that form the basis for all muscle contraction orders (heartbeat) and locomotion (walking, running, etc.). The leech neural network system was previously investigated and this CPG formalized in the Hodgkin–Huxley neural model (HH), the most complex devised to date. However, the resources required for a neural model are proportional to its complexity. In response to this issue, this article describes a biomimetic implementation of a network of 240 CPGs in an FPGA (Field Programmable Gate Array), using a simple model (Izhikevich) and proposes a new synapse model: activity-dependent depression synapse. The network implementation architecture operates on a single computation core. This digital system works in real-time, requires few resources, and has the same bursting activity behavior as the complex model. The implementation of this CPG was initially validated by comparing it with a simulation of the complex model. Its activity was then matched with pharmacological data from the rat spinal cord activity. This digital system opens the way for future hybrid experiments and represents an important step toward hybridization of biological tissue and artificial neural networks. This CPG network is also likely to be useful for mimicking the locomotion activity of various animals and developing hybrid experiments for neuroprosthesis development.",Front. Neurosci.,2013
bc7c3e5cad38f54171c3ecd3a8ec2f3dd3e78b12,https://www.semanticscholar.org/paper/bc7c3e5cad38f54171c3ecd3a8ec2f3dd3e78b12,"Design, modeling and analysis of a novel self-crossing mechanism","Abstract In this paper, a novel mobile mechanism based on Bennett mechanism is proposed, which can realize self-crossing locomotion. Unlike the most of the self-crossing mechanisms, the proposed mechanism can be assembled modularly, which has better environment adaptability. Firstly, on the basis of revealing mechanism of the self-crossing movement, configuration of the self-crossing mechanism is designed. The mechanism consists of n Bennett mechanisms connected in series by 2(n-1) 3R limbs that are symmetrically distributed on both sides of n Bennett mechanisms. Then, kinematic analysis of the mechanism is carried out based on finite and instantaneous screw theory, including mobility analysis and gait analysis. For the former, the number of degrees of freedom that the mechanism can achieve self-crossing locomotion is obtained, and for the latter, the trajectory of end point of the mechanism in the self-crossing movement is obtained. Finally, On the basis of theoretical analysis, simulation is conducted, and the results show that the proposed novel mechanism can realize self-crossing locomotion without interference, which verified the rationality of the mechanism. This paper provides a useful reference for the design and analysis of self-crossing mobile mechanism.",,2021
3160ca4f436b9d72dd480a156eb652dc1ce4a74a,https://www.semanticscholar.org/paper/3160ca4f436b9d72dd480a156eb652dc1ce4a74a,Robot Assistance in Dynamic Smart Environments—A Hierarchical Continual Planning in the Now Framework,"By coupling a robot to a smart environment, the robot can sense state beyond the perception range of its onboard sensors and gain greater actuation capabilities. Nevertheless, incorporating the states and actions of Internet of Things (IoT) devices into the robot’s onboard planner increases the computational load, and thus can delay the execution of a task. Moreover, tasks may be frequently replanned due to the unanticipated actions of humans. Our framework aims to mitigate these inadequacies. In this paper, we propose a continual planning framework, which incorporates the sensing and actuation capabilities of IoT devices into a robot’s state estimation, task planing and task execution. The robot’s onboard task planner queries a cloud-based framework for actuators, capable of the actions the robot cannot execute. Once generated, the plan is sent to the cloud back-end, which will inform the robot if any IoT device reports a state change affecting its plan. Moreover, a Hierarchical Continual Planning in the Now approach was developed in which tasks are split-up into subtasks. To delay the planning of actions that will not be promptly executed, and thus to reduce the frequency of replanning, the first subtask is planned and executed before the subsequent subtask is. Only information relevant to the current (sub)task is provided to the task planner. We apply our framework to a smart home and office scenario in which the robot is tasked with carrying out a human’s requests. A prototype implementation in a smart home, and simulator-based evaluation results, are presented to demonstrate the effectiveness of our framework.",Sensors,2019
5971816e17eca7d9db6e7503018c0f373b34db7b,https://www.semanticscholar.org/paper/5971816e17eca7d9db6e7503018c0f373b34db7b,Trajectory Planning and the Target Search by the Mobile Robot in an Environment Using a Behavior-Based Neural Network Approach,"SUMMARY Navigation and path analysis in a cluttered environment is a challenging task over the last few decades. In this paper, a behavior-based neural network (BNN) and reactive control architecture have been presented for navigation of the mobile robot. Two different reactive behaviors have been taken as inputs function. Obstacle position is the first reactive behavior given by u(o), whereas obstacle angle u(n) according to the target position is the second reactive behavior. The angular velocity and steering angle are the output of the controller. The backpropagation architecture reduces the errors of weight function and records the best weight data that match the BNN controller. Using the BNN algorithm, the robot reacts quickly as compared to other developed techniques. To validate the performance of the controller, simulation and experimental results have been compared in the common platforms. The deviation in results for both the scenarios is found to be within 10%. The results of the BNN algorithm have also been compared with other existing techniques. Effectiveness of the proposed technique is measured in terms of smoothness of the realistic path, collision point detection, path length, and performance time.",Robotica,2019
defd7de183256252fc3e23339abfcdbc88e0dabb,https://www.semanticscholar.org/paper/defd7de183256252fc3e23339abfcdbc88e0dabb,Symbolic Planning with Edge-Valued Multi-Valued Decision Diagrams-Masterthesis,"Symbolic representations have attracted increasing attention in optimal planning. Binary Decision Diagrams (BDDs) form the basis for symbolic search algorithms. Closely related are Algebraic Decision Diagrams (ADDs) used to represent heuristic functions. Furthermore, progress was made in dealing with models that take state-dependent action costs into account. Here, costs are represented as Edge-Valued Multi-Valued Decision Diagrams (EVMDDs), which can be exponentially more compact than the corresponding ADD representation. However, they were not yet considered in the field of symbolic planning. In this work, EVMDD-based symbolic search is studied for applications in optimal planning. In order to realize EVMDD-based planning the representations of state sets and transition relations with EVMDDs are defined. Furthermore, it is shown how to compute the operations required for EVMDD-A*. This EVMDD-based version of symbolic A* generalizes the BDD variant and allows to solve planning tasks with state-dependent action costs. It is shown that the proposed approach is sound, complete and optimal. A planning system called Symple is introduced which implements EVMDD-A* with progression, regression and bidirectional search. Due to the lack of domains with state-dependent action costs, a new benchmark set consisting of several domains is created. Experiments show that BDD-A* is superior on many tasks with unit-costs while Symple with EVMDD-A* outperforms all other approaches in domains with state-dependent action costs. The results highlight the usefulness of symbolic approaches and the feasibility of dealing with models that go beyond unit costs.",,2019
bcaea96df13a18b8d060371560ecd7373c74c6a5,https://www.semanticscholar.org/paper/bcaea96df13a18b8d060371560ecd7373c74c6a5,Symbolic Planning with Edge-Valued Multi-Valued Decision Diagrams,"Symbolic representations have attracted significant attention in optimal planning. Binary Decision Diagrams (BDDs) form the basis for symbolic search algorithms. Closely related are Algebraic Decision Diagrams (ADDs), used to represent heuristic functions. Also, progress was made in dealing with models that take state-dependent action costs into account. Here, costs are represented as Edge-valued Multivalued Decision Diagrams (EVMDDs), which can be exponentially more compact than the corresponding ADD representation. However, they were not yet considered for symbolic planning. In this work, we study EVMDD-based symbolic search for optimal planning. We define EVMDD-based representations of state sets and transition relations, and show how to compute the necessary operations required for EVMDDA . This EVMDD-based version of symbolic A generalizes its BDD variant, and allows to solve planning tasks with state-dependent action costs. We prove theoretically that our approach is sound, complete and optimal. Additionally, we present an empirical analysis comparing EVMDD-A to BDD-A and explicit A search. Our results underscore the usefulness of symbolic approaches and the feasibility of dealing with models that go beyond unit costs.",ICAPS,2018
f18732ee87fa9f142ddcd11fc9cf41d1e5e2c593,https://www.semanticscholar.org/paper/f18732ee87fa9f142ddcd11fc9cf41d1e5e2c593,Architecture for incorporating Internet-of-Things sensors and actuators into robot task planning in dynamic environments,"Robots are being deployed in a wide range of smart environments that are equipped with sensors and actuators. These devices can provide valuable information beyond the perception range of a robot's on-board sensors, or provide additional actuators that can complement the robot's actuation abilities. Traditional robot task planners do not take these additional sensor and actuators abilities into account. This paper introduces an enhanced robotic planning framework which improves robots' ability to operate in dynamically changing environments. To keep planning time short, the amount of knowledge in the planner's world model is minimized.",2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS),2017
53743cb8438e0084762a3dd9aed0ec8552b76dda,https://www.semanticscholar.org/paper/53743cb8438e0084762a3dd9aed0ec8552b76dda,A Mobile Edge Computing (MEC)-Enabled Transcoding Framework for Blockchain-Based Video Streaming,"Blockchain technology is reshaping the video streaming industry by changing how humans create, distribute and consume videos. Leveraging blockchain technology, some emerging video streaming platforms aim to eliminate the centralized video streaming servers by building peer-to-peer content distribution architectures and cryptocurrency-based payment systems. On these blockchain-based platforms, the source video streams are required to be transcoded into multiple versions to meet heterogeneous user demands, which is a computationally intensive and energy consuming process. Meanwhile, the block size of the blockchain has significant impacts on the performance of blockchain-based video streaming systems. In this article, we propose a novel MEC-enabled transcoding framework for blockchain-based video streaming while an adaptive block size scheme is designed for the underlying blockchains. The system architecture of the proposed framework is presented to enable coordination of different aspects. Then we address the video transcoding and block size issues by using the ADMM method, and smart contract is used to facilitate distributed optimization among non-trusting entities. Simulation results are presented to show the effectiveness of the proposed framework.",IEEE Wireless Communications,2020
c73a94a99a8f3cafa4240836ddc4d1c4319a6dda,https://www.semanticscholar.org/paper/c73a94a99a8f3cafa4240836ddc4d1c4319a6dda,Collaborative hierarchical caching and transcoding in edge network with CE-D2D communication,"Abstract To support multimedia applications, Mobile Edge Computing (MEC) servers offer storage and computing capacities to handle videos close to end-users. However, the high load in peak hours consumes the limited available bandwidth of existing cellular and backhaul links leading to low network performance. Hence, an elastic system model is required to maintain the high Quality of Experience (QoE) as the resource demands increase. Caching popular videos at mobile devices is considered a promising technique for content delivery. Yet, mobile users offer small capacities that are not adequate for large-sized video sharing. In this paper, we extend the collaborative caching and processing framework in edge networks (Collaborative Edge - CE) to include the users' mobile video sharing (Device-to-Device - D2D). We propose a caching strategy to cache only the chunks of videos to be watched and instead of offloading one video content by one edge node, helpers (MEC servers and users) will collaborate to store and share different chunks to optimize the storage/transmission resources usage. To only cache popular contents, we designed a D2D-aware proactive chunks caching on users’ devices based on our chunks popularity model. Next, we formulate this CE-D2D collaborative problem as a linear program. Due to the NP-hardness of the problem, we introduce a sub-optimal relaxation and an online heuristic using the proactive caching and presenting a near optimal data offloading and a profitable payment determination, with polynomial time complexity. The simulation results show that our policies and heuristics outperform other edge caching approaches by more than 10% in terms of hit ratio, average delay, and cost.",J. Netw. Comput. Appl.,2020
319e0d6b4e5fed2006b2750623305ad0d9ae8189,https://www.semanticscholar.org/paper/319e0d6b4e5fed2006b2750623305ad0d9ae8189,A Novel Resource Management Scheme for Blockchain-based Video Streaming with Mobile Edge Computing Menting,"Blockchain-based video streaming systems aim to build decentralized peer-to-peer networks with flexible monetization mechanisms. In this paper, we propose a novel blockchain-based framework for video streaming with mobile edge computing (MEC). With the trust and traceability features of the blockchain, we design an incentive mechanism to facilitate the collaborations among content creators, video transcoders and consumers, without the intervention of any third party. In addition, we present a block size adaptation scheme for blockchain-based video streaming. Moreover, we consider two offloading modes, i.e., offloading to the nearby MEC nodes or a group of device-to-device (D2D) users, to avoid the overload of MEC nodes. Then, we formulate the issues of resource allocation, scheduling of offloading, and adaptive block size as an optimization problem. We employ a low-complexity alternating direction method of multipliers (ADMM)-based algorithm to solve the problem in a distributed fashion. Simulation results are presented to show the effectiveness of the proposed scheme.",,2019
acaa094ff459c376a177382e8b3d28787205972b,https://www.semanticscholar.org/paper/acaa094ff459c376a177382e8b3d28787205972b,Distributed Resource Allocation in Blockchain-Based Video Streaming Systems With Mobile Edge Computing,"Blockchain-based video streaming systems aim to build decentralized peer-to-peer networks with flexible monetization mechanisms for video streaming services. On these blockchain-based platforms, video transcoding, which is computationally intensive and time-consuming, is still a major challenge. Meanwhile, the block size of the underlying blockchain has significant impacts on the system performance. Therefore, this paper proposes a novel blockchain-based framework with an adaptive block size for video streaming with mobile edge computing (MEC). First, we design an incentive mechanism to facilitate collaboration among content creators, video transcoders, and consumers. In addition, we present a block size adaptation scheme for blockchain-based video streaming. Moreover, we consider two offloading modes, i.e., offloading to the nearby MEC nodes or a group of device-to-device (D2D) users, to avoid the overload of MEC nodes. Then, we formulate the issues of resource allocation, scheduling of offloading, and adaptive block size as an optimization problem. We employ a low-complexity alternating direction method of the multipliers-based algorithm to solve the problem in a distributed fashion. Simulation results are presented to show the effectiveness of the proposed scheme.",IEEE Transactions on Wireless Communications,2019
ae2a38b405f33efb4c117074a506814c01741f87,https://www.semanticscholar.org/paper/ae2a38b405f33efb4c117074a506814c01741f87,A big video data transcoding service for social media over federated clouds,"Nowadays, the advent of social networks have revolutionised the traditional communication media. In recent years, the number of social media providers has rapidly grown. In this context, one of the major problems is the on-demand video streaming provisioning. In fact, more and more users require to post and access in real-time videos from anywhere in a short time. Therefore, a denial of service condition can cause for social media providers a loss of users and a consequent lose of money. Commonly, videos, before to be delivered, must be transcoded in order to fits both users’ hardware/software device and network capabilities, raising a big video data processing issue. In order to address such a concern, in this paper, we propose a Cloud federation system that enables social media providers to work together so as to take the advantages of a scalable video processing service. Experimental results demonstrate how the overhead due to setup and maintenance tasks of the federated environment is negligible compared to the benefits in terms of video transcoding performance. Moreover, we also demonstrate how Cloud federation can lighten and speed up the whole video processing service, by introducing an additional parallelization level.",Multimedia Tools and Applications,2019
46680a77e6ce983ab5aea7748ae8dffe7f8c57ba,https://www.semanticscholar.org/paper/46680a77e6ce983ab5aea7748ae8dffe7f8c57ba,Joint Access and Resource Management for Delay-Sensitive Transcoding in Ultra-Dense Networks with Mobile Edge Computing,"Driven by the large-scale video traffic, mobile edge computing (MEC) has emerged as a promising technique that extends cloud-computing capabilities to the proximate small base stations (SBSs) in wireless networks, especially in ultra-dense networks (UDNs). With MEC, video transcoding, which processes the adaptive bitrates of a video and provides the adaptive video streaming to users, can significantly release the backhaul burden of networks. However, video transcoding is a time-consuming task, and how to guarantee quality-of- service (QoS) for large video data with MEC is still challenging. To address this issue, in this paper, we propose a joint SBSs selection, tasks scheduling, and resource allocation approach for achieving a delay- optimal transcoding under the constraints of network cost. Specifically, to reduce the delay, a set of SBSs are formed into a Virtual SBSs Group (VSG) to perform the video transcoding and delivering in parallel for a given user. Then, the joint tasks scheduling and feasible resource allocation are performed to minimizing total delay while maintaining a low network cost. The optimization problem is formulated as a mixed integer non- convex programming problem and a three-stage search solution is proposed to solve it. Simulation results show that our proposed approach can significantly improve the transcoding performance while satisfying the resource consumption constraint.",2018 IEEE International Conference on Communications (ICC),2018
db9d57d91d4f4030dd39cd1c8e2e365c082159d2,https://www.semanticscholar.org/paper/db9d57d91d4f4030dd39cd1c8e2e365c082159d2,DUPLEX: An Architecture for a Data-Universal Plane for Information Exchange,"In order to efficiently retrieve information in general, and multimedia content in particular, new network architectures are required, centered around information and content distribution. Most Information-Centric architectures are build upon an asymmetry: the nodes request information, such as multimedia data or a video stream, but the nodes themselves are either not addressed, or addressed by a host name. We propose to address the nodes by the information they contain, so that both requests for informations and responses with information can therefore be routed based upon a related, if not similar, content-routing mechanism.",2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR),2018
23de08ee861cae2dcdeb996d4caa6d55641e7e1d,https://www.semanticscholar.org/paper/23de08ee861cae2dcdeb996d4caa6d55641e7e1d,Towards resource-efficient and QoS-aware video adaptation in media cloud,"Video streaming dominates Internet traffic, accounting for more than 70 percent of North American downstream traffic at peak time. However, limited bandwidth capacity, unstable network condition, and diverse viewing devices inherently deteriorate user experiences, triggering a tussle between the growing demand of video traffic and the quality of viewing experiences. Video adaptation is the de facto solution for video streaming over heterogeneous viewing devices and under time-varying network connections. For video adaptation, each video must be transcoded into multiple representations in different bitrates and resolutions. The client-side can dynamically select the best possible quality representation according to the current network condition and device capacity. Nevertheless, embracing video adaptation in video streaming faces many challenges regarding operational cost, Quality of Service (QoS), and Quality of Experience (QoE). First, video transcoding is compute-intensive, and transcoding source videos into multiple representations and storing them consume tremendous resources. Adopting video adaptation mechanism can thus greatly increase the operational cost for video streaming. To reduce the operational cost, we propose the partial transcoding scheme for cost-efficient video transcoding. Specifically, the frequently requested video chunks are cached, resulting in storage cost; while the seldom requested video chunks are transcoded online when being requested, resulting in computing cost. We aim to minimize the longterm overall cost by determining whether a video chunk should be cached or transcoded online. We also design the virtual caching scheme, vCache, by considering the practical implementation under the Network Functions Virtualization (NFV) infrastructure. vCache can dynamically provision computing resources to ensure that transcoding delays will not affect streaming services. Second, the video generation rate in an online video service is time-varying, and maintaining a fixed number of servers for transcoding to meet the peak workload may waste",,2017
39e57b7a9c0386a1756b88c2c2220100fb41847c,https://www.semanticscholar.org/paper/39e57b7a9c0386a1756b88c2c2220100fb41847c,Resource Provisioning and Profit Maximization for Transcoding in Clouds: A Two-Timescale Approach,"Transcoding is widely adopted for content adaptation; however, it may incur excessive resource consumption and processing delays. Taking advantage of cloud infrastructure, cloud-based transcoding can elastically allocate resources under time-varying workloads and perform multiple transcodings in parallel to reduce delays. To provide transcoding as a cloud service, cloud transcoding systems require some intelligent mechanisms to provision resources and schedule tasks to satisfy user requirements while maximizing financial profit. To this end, we propose a two-timescale stochastic optimization framework for maximizing service profit while achieving performance requirements by jointly provisioning resources and scheduling tasks under a hierarchical control architecture. Our method analytically integrates service revenue, processing delay, and resource consumption in one optimization framework. We derive the offline exact solution and design some approximate online solutions for task scheduling and resource provisioning. We implement an open source cloud transcoding system, called Morph, and evaluate the performance of our method in a real environment. Empirical studies verify that our method can reduce resource consumption and achieve a higher profit compared with baseline schemes.",IEEE Transactions on Multimedia,2017
8dd6f20ab8c215c48410793ab116f357e02c5f5a,https://www.semanticscholar.org/paper/8dd6f20ab8c215c48410793ab116f357e02c5f5a,Advancing Multimedia Distribution vCache : Supporting Cost-Efficient Adaptive Bitrate Streaming,"V ideo streaming dominates Internet traffic, accounting for more than 70 percent of North American downstream traffic at peak time.1 However, limited bandwidth capacity, unstable network conditions, and diverse viewing devices inherently deteriorate user experiences, triggering a tussle between the growing demand for video traffic and the quality of viewing experiences.2 Adaptive bitrate (ABR) streaming is a widely adopted solution for improving viewing experiences under such conditions. Figure 1a illustrates the video processing flow for ABR streaming. Each video must be transcoded into multiple representations and then cached in streaming servers. A media presentation description (MPD) file is required to manifest the available representations for a video.3 When starting a video session, the video player first obtains the MPD file and then selects the best possible quality representations according to the current network conditions and device capacity. However, transcoding is compute-intensive and consumes tremendous resources. Caching multiple representations of a video requires several times more storage space than just caching one representation. Thus, ABR streaming of videos can greatly increase operational costs. In contrast to the tremendous resource consumption of ABR streaming, only a small percentage of video chunks are frequently requested by users. Specifically, the top 10 percent of the most popular videos account for almost 80 percent of total views.4,5 Furthermore, for 60 percent of video sessions, less than 20 percent of the durations are viewed; most users abort viewing within 40 seconds.6,7 These user viewing patterns reveal that users consume only a small fraction of video chunks. Considering the tremendous computing and storage resource consumption required to transcode and cache videos, is it necessary to pre-transcode each video and cache all video chunks? To answer this question, we designed vCache, a network function virtualization (NFV)-based virtual caching scheme for managing videos for ABR streaming to minimize overall operational costs.",,2017
93936406e649baa8606193a795623fdd9ecfd3a6,https://www.semanticscholar.org/paper/93936406e649baa8606193a795623fdd9ecfd3a6,vCache: Supporting Cost-Efficient Adaptive Bitrate Streaming,"In adaptive bitrate (ABR) streaming, each video must be transcoded into multiple representations. Transcoding and caching videos consume tremendous resources, and only a small percentage of video chunks are frequently requested. Thus a question arises: is it necessary to pre-transcode each video and cache all video chunks? To answer this, the authors designed a network function virtualization (NFV)-based virtual cache (vCache). In vCache, video chunks have two mutually exclusive caching states: physically cached and virtually cached. A physically cached video chunk can be directly read from storage, and it consumes storage resources. A virtually cached video chunk will be transcoded online when being requested, and it consumes computing resources. With NFV, vCache can dynamically manage video chunks cost-effectively and can intelligently provision resources to guarantee transcoding delays won't affect streaming services. Results from experiments show that vCache can greatly reduce operational costs for ABR. This article is part of a special issue on advancing multimedia distribution.",IEEE MultiMedia,2017
08fca29c15182e6c25412b2175e91ba74fdce907,https://www.semanticscholar.org/paper/08fca29c15182e6c25412b2175e91ba74fdce907,Morph: A Fast and Scalable Cloud Transcoding System,"Morph is an open source cloud transcoding system. It can leverage the scalability of the cloud infrastructure to encode and transcode video contents in fast speed, and dynamically provision the resources in cloud to accommodate the workload. The system is composed of a master node that performs the video file segmentation, concentration, and task scheduling operations; and multiple worker nodes that perform the transcoding for video blocks. Morph can transcode the video blocks of a video file on multiple workers in parallel to achieve fast speed, and automatically manage the data transfers and communications between the master node and the worker nodes. The worker nodes can join into or leave the transcoding cluster at any time for dynamic resource provisioning. The system is very modular, and all of the algorithms can be easily modified or replaced. We release the source code of Morph under MIT License, hoping that it can be shared among various research communities.",ACM Multimedia,2016
0aa651fe8da41ee72aa4d6b04104be9a55ffc2a3,https://www.semanticscholar.org/paper/0aa651fe8da41ee72aa4d6b04104be9a55ffc2a3,An Open-Source Scale Model Platform for Teaching Autonomous Vehicle Technologies,"Emerging technologies in the context of Autonomous Vehicles (AV) have drastically evolved the industry’s qualification requirements. AVs incorporate complex perception and control systems. Teaching the associated skills that are necessary for the analysis of such systems becomes a very difficult process and existing solutions do not facilitate learning. In this study, our efforts are devoted to proposingan open-source scale model vehicle platform that is designed for teaching the fundamental concepts of autonomous vehicles technologies that are adapted to undergraduate and technical students. The proposed platform is as realistic as possible in order to present and address all of the fundamental concepts that are associated with AV. It includes all on-board components of a stand-alone system, including low and high level functions. Such functionalities are detailed and a proof of concept prototype is presented. A set of experiments is carried out, and the results obtained using this prototype validate the usability of the model for the analysis of time- and energy-constrained systems, as well as distributed embedded perception systems.",Sensors,2021
19beac25f312ae79684d188a25430ae4e814ddcf,https://www.semanticscholar.org/paper/19beac25f312ae79684d188a25430ae4e814ddcf,Learn-to-Race: A Multimodal Control Environment for Autonomous Racing,"Existing research on autonomous driving primarily focuses on urban driving, which is insufficient for characterising the complex driving behaviour underlying highspeed racing. At the same time, existing racing simulation frameworks struggle in capturing realism, with respect to visual rendering, vehicular dynamics, and task objectives, inhibiting the transfer of learning agents to realworld contexts. We introduce a new environment, where agents Learn-to-Race (L2R) in simulated competitionstyle racing, using multimodal information—from virtual cameras to a comprehensive array of inertial measurement sensors. Our environment, which includes a simulator and an interfacing training framework, accurately models vehicle dynamics and racing conditions. In this paper, we release the Arrival simulator for autonomous racing. Next, we propose the L2R task with challenging metrics, inspired by learning-to-drive challenges, Formulastyle racing, and multimodal trajectory prediction for autonomous driving. Additionally, we provide the L2R framework suite, facilitating simulated racing on high-precision models of real-world tracks. Finally, we provide an official L2R task dataset of expert demonstrations, as well as a series of baseline experiments and reference implementations. We make all code available: https://github. com/learn-to-race/l2r.",ArXiv,2021
460cdb3a6b2def8e718e62859913cb153b0d89f1,https://www.semanticscholar.org/paper/460cdb3a6b2def8e718e62859913cb153b0d89f1,Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap Time Simulation Using Machine Learning,"The widespread development of driverless vehicles has led to the formation of autonomous racing competitions, where the high speeds and fierce rivalry in motorsport provide a testbed to accelerate technology development. A particular challenge for an autonomous vehicle is that of identifying a target trajectory or in the case of a racing car, the ideal racing line. Many existing approaches to identifying the racing line are either not the time-optimal solutions, or have solution times which are computationally expensive, thus rendering them unsuitable for real-time application using on-board processing hardware. This paper describes a machine learning approach to generating an accurate prediction of the racing line in real-time on desktop processing hardware. The proposed algorithm is a dense feed-forward neural network, trained using a dataset comprising racing lines for a large number of circuits calculated via a traditional optimal control lap time simulation. The network is capable of predicting the racing line with a mean absolute error of ±0.27m, meaning that the accuracy outperforms a human driver, and is comparable to other parts of the autonomous vehicle control system. The system generates predictions within 33ms, making it over 9,000 times faster than traditional methods of finding the optimal racing line. Results suggest that a data-driven approach may therefore be favourable for real-time generation of nearoptimal racing lines than traditional computational methods.",Vehicle System Dynamics,2021
61117ee6d927beb56572f4bcc0e8a922308344d7,https://www.semanticscholar.org/paper/61117ee6d927beb56572f4bcc0e8a922308344d7,Real-world Deep Reinforcement Learning via Simulation for Autonomous Driving,ii,,2021
254769ef4d8b1b668d9292ab2bb8b1cb210b7ee5,https://www.semanticscholar.org/paper/254769ef4d8b1b668d9292ab2bb8b1cb210b7ee5,Robust Multi-Agent Reinforcement Learning with Model Uncertainty,"In this work, we study the problem of multi-agent reinforcement learning (MARL) with model uncertainty, which is referred to as robust MARL. This is naturally motivated by some multi-agent applications where each agent may not have perfectly accurate knowledge of the model, e.g., all the reward functions of other agents. Little a priori work on MARL has accounted for such uncertainties, neither in problem formulation nor in algorithm design. In contrast, we model the problem as a robust Markov game, where the goal of all agents is to find policies such that no agent has the incentive to deviate, i.e., reach some equilibrium point, which is also robust to the possible uncertainty of the MARL model. We first introduce the solution concept of robust Nash equilibrium in our setting, and develop a Qlearning algorithm to find such equilibrium policies, with convergence guarantees under certain conditions. In order to handle possibly enormous state-action spaces in practice, we then derive the policy gradients for robust MARL, and develop an actor-critic algorithm with function approximation. Our experiments demonstrate that the proposed algorithm outperforms several baseline MARL methods that do not account for the model uncertainty, in several standard but uncertain cooperative and competitive MARL environments.",NeurIPS,2020
397febc82ff4058124967240cf30b6dc7cef7f6b,https://www.semanticscholar.org/paper/397febc82ff4058124967240cf30b6dc7cef7f6b,Ember: energy management of batteryless event detection sensors with deep reinforcement learning,"Energy management can extend the lifetime of batteryless, energy-harvesting systems by judiciously utilizing the energy available. Duty cycling of such systems is especially challenging for event detection, as events arrive sporadically and energy availability is uncertain. If the node sleeps too much, it may miss important events; if it depletes energy too quickly, it will stop operating in low energy conditions and miss events. Thus, accurate event prediction is important in making this tradeoff. We propose Ember, an energy management system based on deep reinforcement learning to duty cycle event-driven sensors in low energy conditions. We train a policy using historical real-world data traces of motion, temperature, humidity, pressure, and light events. The resulting policy can learn to capture up to 95% of the events without depleting the node. Without historical data for training when deploying a node at a new location, we propose a self-supervised mechanism to collect ground-truth data while learning from the data at the same time. Ember learns to capture the majority of events within a week without any historical data and matches the performance of the policies trained with historical data in a few weeks. We deployed 40 nodes running Ember for indoor sensing and demonstrate that the learned policies generalize to real-world settings as well as outperform state-of-the-art techniques.",SenSys,2020
43def4fa14f1fbf34bb8637ee60b2ffdd9644ffc,https://www.semanticscholar.org/paper/43def4fa14f1fbf34bb8637ee60b2ffdd9644ffc,MB2C: Model-Based Deep Reinforcement Learning for Multi-zone Building Control,"Reinforcement learning has been widely studied for controlling Heating, Ventilation, and Air conditioning (HVAC) systems. Most of the existing works are focused on Model-Free Reinforcement Learning (MFRL), which learns an agent by extensively trial-and-error interaction with a real building. However, one of the fundamental problems with MFRL is the very large amount of training data required to converge to acceptable performance. Although simulation models have been used to generate sufficient training data to accelerate the training process, MFRL needs a high-fidelity building model for simulation, which is also hard to calibrate. As a result, Model-Based Reinforcement Learning (MBRL) has been used for HVAC control. While MBRL schemes can achieve excellent sample efficiency (i.e. less training data), they often lag behind model-free approaches in terms of asymptotic control performance (i.e. high energy savings while meeting occupants' thermal comfort). In this paper, we conduct a set of experiments to analyze the limitations of current MBRL-based HVAC control methods, in terms of model uncertainty and controller effectiveness. Using the lessons learned, we develop MB2C, a novel MBRL-based HVAC control system that can achieve high control performance with excellent sample efficiency. MB2C learns the building dynamics by employing an ensemble of environment-conditioned neural networks. It then applies a new control method, Model Predictive Path Integral (MPPI), for HVAC control. It produces candidate action sequences by using an importance sampling weighted algorithm that scales better to high state and action dimensions of multi-zone buildings. We evaluate MB2C using EnergyPlus simulations in a five-zone office building. The results show that MB2C can achieve 8.23% more energy savings compared to the state-of-the-art MBRL solution while maintaining similar thermal comfort. MB2C can reduce the training data set by an order of magnitude (10.52×) while achieving comparable performance to MFRL approaches.",BuildSys@SenSys,2020
46cfb4d78eb72639ac199e4ba1dbcc8138c29e5e,https://www.semanticscholar.org/paper/46cfb4d78eb72639ac199e4ba1dbcc8138c29e5e,Le jumeau numérique dans le pilotage de performance,"HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Le jumeau numérique dans le pilotage de performance Amel Souifi, Zohra Cherfi, Zolghadri Marc, Maher Barkallah, Mohamed Haddar",,2021
64bb06d6f9fc00feebe2af824f05c96893e4869a,https://www.semanticscholar.org/paper/64bb06d6f9fc00feebe2af824f05c96893e4869a,Digital twin-based research on the prediction method for the complex product assembly abnormal events,"ABSTRACT The emergence of abnormal events (e.g. personnel abnormalities, equipment failures, etc.) on the assembly floor of complex products can seriously affect normal assembly progress. In response to the problems of poor timeliness and lack of predictability in the control of abnormal events on the assembly floor, a method for predicting abnormal events on the assembly floor of complex products based on digital twin technology is proposed. A model for predicting abnormal assembly events is constructed with the physical assembly workshop, virtual assembly workshop, assembly workshop twin data platform and abnormal events prediction service system working together, and its prediction operation mechanism is designed based on the classification of abnormal events and the workflow of the mechanism under different states is analysed. The Grey-Markov method is used to predict abnormal assembly events and provide real-time information for the planning and scheduling system. In order to verify the effectiveness of this scheme, combined with the electrical multiple units bogie assembly workshop, the prediction of the number of equipment failures at the bottleneck station is achieved. The prediction accuracy is much better than that of the GM(1,1) model and can be applied to actual production.",International Journal of Computer Integrated Manufacturing,2021
96f486e4f389524d570111b3828c20a7f780e7a8,https://www.semanticscholar.org/paper/96f486e4f389524d570111b3828c20a7f780e7a8,Communication-Efficient Federated Learning for Digital Twin Edge Networks in Industrial IoT,"The rapid development of artificial intelligence and 5G paradigm, opens up new possibilities for emerging applications in industrial Internet of Things (IIoT). However, the large amount of data, the limited resources of Internet of Things devices, and the increasing concerns of data privacy, are major obstacles to improve the quality of services in IIoT. In this article, we propose the digital twin edge networks (DITENs) by incorporating digital twin into edge networks to fill the gap between physical systems and digital spaces. We further leverage the federated learning to construct digital twin models of IoT devices based on their running data. Moreover, to mitigate the communication overhead, we propose an asynchronous model update scheme and formulate the federated learning scheme as an optimization problem. We further decompose the problem and solve the subproblems based on the deep neural network model. Numerical results show that our proposed federated learning scheme for DITEN improves the communication efficiency and reduces the transmission energy cost.",IEEE Transactions on Industrial Informatics,2021
df5d4af700dbc52999ed041c74bbc609afaad1b7,https://www.semanticscholar.org/paper/df5d4af700dbc52999ed041c74bbc609afaad1b7,A Warehouse Management System with UAV Based on Digital Twin and 5G Technologies,"In this paper, a warehouse management system with UAV based on digital twin and 5G technology will be introduced. The system aim at the problems of imperfect information exchange, disorder of cargo statistics and laborious manual cargo inventory, in order to realize intelligent, controllable and convenient warehouse management, a warehouse management system with UAV based on digital twin and 5G technology is developed. We use Ali cloud as data processing center and 5G communication as the core exchange means. The digital twin platform and the entity warehouse are successfully docked. The flight data and cargo information of the entity warehouse with UAV are uploaded to Ali cloud through 5G communication, and then are sent to the digital twin platform to get real-time warehouse data and visual feedback. At the same time, the instructions are sent by the digital twin platform to operate the UAV. In addition, the instructions are uploaded to Ali cloud, and then are sent to the entity warehouse through the cloud for real-time remote control of the UAV, which realizes the two-way information interaction between the virtual platform and the real platform. Ultimately, the problems of low intelligent level in the logistics warehouse management system and the dilatory feedback of goods information in warehouse are solved.","2020 7th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS)",2020
f53afbb7ca82de26be908332f65570f466183b3e,https://www.semanticscholar.org/paper/f53afbb7ca82de26be908332f65570f466183b3e,Interactive Digital Twins Framework for Asset Management Through Internet,"Digitalization is influencing the design, operation and management, as well as planning functions for products and services across a myriad of industries. In our research we focus on the specific needs and challenges in the asset management of remote critical infrastructure. We propose a single Digital Twin framework which can synchronize the data and communication protocols across multiple devices to support exchanging data between the physical world and the cyber world under any scenario, anywhere and at any time. Our framework can support the synchronization of 1000 different sensors and actuators. The results of our Digital Twin are demonstrated using embedded, front-end sensing for offshore energy assets. It can filter and translate complex data and messages from any embedded sensor and operating system. Furthermore, we show how a complete Digital Twin framework allows end-users to simulate future events capturing the interactions between the environment, people and assets, enabling a better understanding of operational risks and remaining useful life of assets.",2020 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT),2020
3d485da94094e70ad8dc697ff8b9b41994751c4a,https://www.semanticscholar.org/paper/3d485da94094e70ad8dc697ff8b9b41994751c4a,Review on Neural Network Identification for Maneuvering UAVs,"Unmanned Aerial Vehicles (UAV) need high mobility in performing military tasks. In this paper, we summarized the UAVs identification methods based on neural network, which takes the characteristics of strong nonlinearity and coupling into consideration. These methods provide some feasible approaches for identifying small maneuvering UAVs. Maneuvering UAV systems are required to be identified more quickly and accurately. In recent years, improvements in many aspects bring new development opportunities to identify maneuvering UAV systems, such as the increase of sampling rate of sensors, the development of computational fluid dynamics (CFD) and embedded technology, the widespread use of deep learning in control area and the rise of neural network chips. We are expected to get more precise maneuvering UAV models based on neural network identification methods with the help of more preeminent software and more advanced hardware.","2018 International Conference on Sensing,Diagnostics, Prognostics, and Control (SDPC)",2018
b8866de81cf0a75eed7f98a0ac03d22791dacd35,https://www.semanticscholar.org/paper/b8866de81cf0a75eed7f98a0ac03d22791dacd35,Nonlinear aircraft system identification using artificial neural networks enhanced by empirical mode decomposition,"Abstract This paper aims to improve the performance of artificial neural networks used for the aircraft system identification by taking flight dynamic characteristics into consideration. In the proposed method, flight dynamic modes are recognized, isolated, and inputted individually to feed-forward neural networks. This method has several advantages such as being adaptive, involving all observable modes in the identification process, considering interactions between longitudinal and lateral-directional modes, and reducing noise effects. Simulated and real flight data of the HARV aircraft at high-angle of attack maneuvers are employed to train the neural networks and evaluate them. Results demonstrate improved accuracy and generality of the proposed method in comparison with the conventional ones.",,2018
48ca31ab788e8caf9d4be3a207c9500bf81744da,https://www.semanticscholar.org/paper/48ca31ab788e8caf9d4be3a207c9500bf81744da,An adaptive neural network approach to the tracking control of micro aerial vehicles in constrained space,"ABSTRACT This paper presents an adaptive neural network approach to the trajectory tracking control of micro aerial vehicles especially when they are flying in a limited indoor area. Differing from conventional controllers, the proposed controller employs the outer position loop to directly generate angular velocity commands in the presence of unknown aerodynamics and disturbances and then the fast inner loop to handle the angular rate control. Adaptive neural networks are deployed to estimate all the uncertain factors with the adaptation law derived from the Lyapunov function. To achieve a real-time performance, a norm estimation approach of ideal weights is designed to achieve a high bandwidth and lighten the burden of computation burden. Meanwhile, a barrier Lyapunov function is introduced to guarantee the constraint of vehicle positions as well as the validity of the neural network estimation. Simulations and practical flight tests are conducted to verify the feasibility and effectiveness of the proposed control strategy.",Int. J. Syst. Sci.,2017
54b2c77f023f94aadbfc7f9c1b57e76f0c187633,https://www.semanticscholar.org/paper/54b2c77f023f94aadbfc7f9c1b57e76f0c187633,Application of robotics in onshore oil and gas industry - A review Part I,"With ever increasing global demand and depleting resources for fossil fuels, oil and gas industry is now positively looking for advanced robotic solutions to increase their productivity and safety. With time easy resources of the fossil fuels are shrinking and newly searched reservoirs, to feed supply demands of global consumption, are mostly located in extreme environmental conditions such as hot deserts, deep water and arctic zone etc. Production of the fossil fuels, in such inhospitable environmental conditions, poses difficult challenges to health, safety and environment (HSE). Tragic incidents like Exxon Valdez and Deepwater Horizon oil spills are examples of such challenges. Therefore, oil and gas industry has lot to learn from successful implementation of robotics and automation for dull, dirty and dangerous (3D) tasks of manufacturing industry. Most of the robotics technologies, currently used in the oil and gas industry, are mainly focused on inspection, maintenance and repair (IMR) of plant facilities with higher frequency and accuracy. Fundamental idea, involved in the automatization of these processes, is based on the principle of teleoperation with skilled operator. Automation of 3D tasks not only improves HSE standards but also lead to much needed economic efficiency by reducing production cycle, floor space and number of staff members required for continuous inspection and manipulation of plant facilities. Considering the risks involved in this industry usage of completely autonomous robots, first without achieving very high reliability, is still a far fetch choice. Therefore, semi-autonomous robots, where actions are performed by robots but cognitive decisions are still taken by skilled operator, is an excellent choice for this industry as a near future solution. In the onshore oil and gas industry robotic solutions are used both in upstream and downstream processes, such as site survey, drilling, production and transportation, mainly focused in the form of in-pipe inspection robots (IPIRs), tank inspection robots (TIRs), unmanned aerial vehicles (UAVs) and wireless sensor networks (WSNs) etc. This paper presents the state of art robotic solutions currently used in onshore oil and gas facilities. We present review for application of robotics in onshore oil and gas industry.Robotic automation used in all the five stages of petroleum industry is described.Pipe and tank inspection are two most important areas of robotics application.Aviation robotics and Wireless Sensor Networks are also becoming popular.For safety and productivity teleoperation robotics is the future of this industry.",Robotics Auton. Syst.,2016
3bdf3bb8f26b88874709398888a59cadd395d13b,https://www.semanticscholar.org/paper/3bdf3bb8f26b88874709398888a59cadd395d13b,System identification of a small low-cost unmanned aerial vehicle using flight data from low-cost sensors,System Identification of a Small Low-Cost Unmanned Aerial Vehicle Using Flight Data from Low-Cost Sensors,,2014
4f7a5b9e235e03463726530681d6238aeea77691,https://www.semanticscholar.org/paper/4f7a5b9e235e03463726530681d6238aeea77691,Recursive Gauss-Newton based for neural network modelling of rotorcraft dynamics training algorithm an unmanned,The ability to model the time varying dynamics of an unmanned rotorcraft is an important aspect in the development of adaptive flight controller. This paper presents a recursive Gauss-Newton based training algorithm to model the attitude dynamics of a small scale rotorcraft based unmanned aerial system using the neural network (NN) modelling approach. It focuses on selection of optimised network for recursive algorithm that offers good generalisation performance with the aid of the cross validation method proposed. The recursive method is then compared with the off'-line Levenberg-Marquardt (LM) training method to evaluate the generalisation performance and adaptability ofthe model. The results indicate that the recursive Gauss-Newton (rGN) method gives slightly lower generalisation perfbrmance compared with its off-line counterpart but adapts well to the dynamic changes that occur during flight. The proposed recursive algorithm was found effective in representing helicopter dynamics with acceptable accuracy within the available computational time constraint.,,2014
724d92bc38759cca24a108f21cb109e48bc77352,https://www.semanticscholar.org/paper/724d92bc38759cca24a108f21cb109e48bc77352,"Small low-cost unmanned aerial vehicle system identification: Brief sensor survey and data quality, consistency checking, and reconstruction","This paper serves as the next chapter in a series of papers on system identification (system ID) for small low-cost unmanned aerial vehicles (UAVs). The purpose of this paper is to answer the question of, what is the next step in the process of system ID once a method of system ID and a model type have been selected? The focus of this paper is to show how sensors, data quality, and data consistency and reconstruction techniques provide an answer to this question. The paper also provides a broader scope for utilizing data consistency and reconstruction in small low-cost UAVs and how it can increase mission assurance and fault tolerance. A brief survey of small low-cost Micro-Electro-Mechanical systems (MEMS) sensors used in UAVs is given. Included in the survey is the data types provided by each sensor and issues of each sensor from a system ID perspective. The process of determining and improving data quality, utilizing data consistency checking and reconstruction techniques is outlined. The paper concludes with guidelines and lessons learned about sensor data for system ID and a future research direction.",2014 International Conference on Unmanned Aircraft Systems (ICUAS),2014
8fb7ad2268200a4440eb336872f7971bc85e4bd4,https://www.semanticscholar.org/paper/8fb7ad2268200a4440eb336872f7971bc85e4bd4,A Survey and Categorization of Small Low-Cost Unmanned Aerial Vehicle System Identification,"Remote sensing has traditionally be done with satellites and manned aircraft. While these methods can yield useful scientific data, satellites and manned aircraft have limitations in data frequency, process time, and real time re-tasking. Small low-cost unmanned aerial vehicles (UAVs) can bridge the gap for personal remote sensing for scientific data. Precision aerial imagery and sensor data requires an accurate dynamics model of the vehicle for controller development. One method of developing a dynamics model is system identification (system ID). The purpose of this paper is to provide a survey and categorization of current methods and applications of system ID for small low-cost UAVs. This paper also provides background information on the process of system ID with in-depth discussion on practical implementation for UAVs. This survey divides the summaries of system ID research into five UAV groups: helicopter, fixed-wing, multirotor, flapping-wing, and lighter-than-air. The research literature is tabulated into five corresponding UAV groups for further research.",J. Intell. Robotic Syst.,2014
645eaefe6d9b8a0157b5089c3e33bc8d983d503c,https://www.semanticscholar.org/paper/645eaefe6d9b8a0157b5089c3e33bc8d983d503c,Small low-cost unmanned aerial vehicle system identification: A survey and categorization,"Small low-cost unmanned aerial vehicles (UAVs) provide greater possibilities for personal scientific research than other conventional platforms such as satellites or manned aircraft. In order to provide precision aerial imagery or other scientific data, an accurate model of vehicle dynamics is needed for controller development and tuning. The purpose of this paper is to provide a survey of current methods and applications of system identification (system ID) for small low-cost UAVs. This survey divides UAVs into 5 groups: helicopter, fixed-wing, multirotor, flapping-wing, and lighter-than-air. The current state of system ID research with respect to various types of UAVs is reviewed based on research literature. System ID methods and application are tabulated for further research. Concluding remarks are given and applications for system ID methods to small low-cost UAVs are recommended.",2013 International Conference on Unmanned Aircraft Systems (ICUAS),2013
fdfc2203b8fb346ecf0083b4d4956a329b79c4f9,https://www.semanticscholar.org/paper/fdfc2203b8fb346ecf0083b4d4956a329b79c4f9,Control of an unmanned aerial vehicle using a neuronal network,"The need for an unmanned aerial vehicle (UAV) controller to operate autonomously and to manage its operations with minimal assistance from humans or rule-based controllers has steadily increased over the years. Numerous approaches have been attempted to address the challenge of developing a UAV with full autonomy. In this paper, a neuronal network-based learning model named NeuraBASE is presented as a possible solution towards autonomy. This neuronal network represents a learning hierarchy of interconnected neurons capable of storing sequences of sensor and motor neuron events. The model is evaluated using experimental scenarios simulated with the STAGE simulation platform, which involves navigational control towards a stationary target. Results show that navigational control with a simple neuronal network can be achieved.","2013 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",2013
65234e40115977eaccb3306dc10a50156cd6c392,https://www.semanticscholar.org/paper/65234e40115977eaccb3306dc10a50156cd6c392,Recursive Gauss-Newton based training algorithm for neural network modelling of an unmanned helicopter dynamics,This paper presents a recursive Gauss-Newton based training algorithm to model the dynamics of a small scale helicopter system using neural network modelling approach. It focuses on selection of optimized network for recursive algorithm that offers good generalization performance with the aid of the cross validation method proposed. The recursive method is then compared with off-line Levenberg-Marquardt (LM) training method to evaluate the generalization performance and adaptability of the model prediction. The results indicate that the recursive Gauss-Newton method gives slightly lower generalization performance compared to its off-line counterpart but adapts well to the dynamic changes that occur during flight. The proposed recursive algorithm was found effective in representing coupled helicopter dynamics with acceptable accuracy within the available computational timing constraint.,2012 19th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),2012
00794574cf4c9bae135d25df8e0aacf01825fb45,https://www.semanticscholar.org/paper/00794574cf4c9bae135d25df8e0aacf01825fb45,Introduction to cognitive computing and its various applications,"Abstract Cognitive computing is an intelligent system that converses with and mimics the human being in a natural form by learning at scale, reasoning with purpose. Cognitive computing is the third era of computing and now cognitive computing has attracted considerable attention in both academia and industry. Machines and humans’ intelligence gets combined to solve the most complex problems of the world. Complicated problems can be solved by computing framework without intervention of humans. Natural language processing with emotion analysis, artificial intelligence (AI), machine learning, neural networks are building blocks of cognitive computing process to tackle problems as the way human beings do. Nowadays, advance technologies adapt cognitive computing in many areas to assist human experts in smart decision making for the betterment of businesses. Current technology expectations are to make human life better and to help them work in better ways. Nowadays, there is explosive data growth, business conditions are also changing rapidly so intelligent, hassle-free, and enhanced interactions amongst human beings and technology can be effectively addressed by cognitive systems. AI is in use in many apps like the Alexa: Amazon voice assistant, Netflix and Amazon algorithms which recommend the next to watch or buy. Some examples of personal assistants that uses cognitive computing are Alexa, Siri, Google assistant, and Cortana. Advancement of technology and its adoption in the public and private sectors will greatly affect the future of cognitive computing due to technology evolutionary paths and trends. Cognitive systems must be adaptive, interactive, iterative, and stateful and contextual in commercial and widespread applications. Some of the applications that can use cognitive computing to gain benefits from this type of technology are cognitive computing for changing business values, Financial and Investment firms, Healthcare and veterinary medicine, Travel and Tourism, Health and wellness, Education and learning, Agriculture, Communication and network technology.",Cognitive Computing for Human-Robot Interaction,2021
40cd384acccd5ecf3883069a523c25a2034ce908,https://www.semanticscholar.org/paper/40cd384acccd5ecf3883069a523c25a2034ce908,Perceptual and Semantic Processing in Cognitive Robots,"The challenge in human–robot interaction is to build an agent that can act upon human implicit statements, where the agent is instructed to execute tasks without explicit utterance. Understanding what to do under such scenarios requires the agent to have the capability to process object grounding and affordance learning from acquired knowledge. Affordance has been the driving force for agents to construct relationships between objects, their effects, and actions, whereas grounding is effective in the understanding of spatial maps of objects present in the environment. The main contribution of this paper is to propose a methodology for the extension of object affordance and grounding, the Bloom-based cognitive cycle, and the formulation of perceptual semantics for the context-based human–robot interaction. In this study, we implemented YOLOv3 to formulate visual perception and LSTM to identify the level of the cognitive cycle, as cognitive processes synchronized in the cognitive cycle. In addition, we used semantic networks and conceptual graphs as a method to represent knowledge in various dimensions related to the cognitive cycle. The visual perception showed average precision of 0.78, an average recall of 0.87, and an average F1 score of 0.80, indicating an improvement in the generation of semantic networks and conceptual graphs. The similarity index used for the lingual and visual association showed promising results and improves the overall experience of human–robot interaction.",Electronics,2021
aeffa61495610db41149040e97ce6159a98107f6,https://www.semanticscholar.org/paper/aeffa61495610db41149040e97ce6159a98107f6,Learning in LIDA,"Abstract LIDA is a systems-level, biologically-inspired cognitive architecture. More than a decade of research on LIDA has seen much conceptual work on its learning mechanisms, and resulted in a set of conceptual commitments that constrain those mechanisms; perhaps the most essential of these constraints is the Conscious Learning Hypothesis from Global Workspace Theory, which asserts that all significant learning requires consciousness. Despite these successes, many conceptual challenges remain, and bridging the divide between LIDA’s conceptual model and its implementations has been challenging. The contributions of this paper are threefold: We present a detailed survey of learning in LIDA, during which we clarify, elaborate on, and synthesize together ideas from numerous papers, using updated terminology that reflects the continuing evolution of LIDA. We explore foundational issues in learning, such as, “What must be innate or built-in?” versus “What can be learned?”, the nature of LIDA’s representations, and the relationship between the LIDA conceptual model and its computational realizations. Finally, we provide a roadmap for future work. We believe that this paper will direct and catalyze our research endeavors, and provide a thorough introduction to the conceptual foundations of LIDA’s learning mechanisms that will be useful to anyone that would like a deeper understanding of LIDA or for those that plan to implement LIDA-based agents.",Cognitive Systems Research,2020
d594ab2577fcca7176a570f59c3cb788c220b8dd,https://www.semanticscholar.org/paper/d594ab2577fcca7176a570f59c3cb788c220b8dd,Hippocampal formation-inspired probabilistic generative model,"We constructed a hippocampal formation (HPF)-inspired probabilistic generative model (HPF-PGM) using the structure-constrained interface decomposition method. By modeling brain regions with PGMs, this model is positioned as a module that can be integrated as a whole-brain PGM. We discuss the relationship between simultaneous localization and mapping (SLAM) in robotics and the findings of HPF in neuroscience. Furthermore, we survey the modeling for HPF and various computational models, including brain-inspired SLAM, spatial concept formation, and deep generative models. The HPF-PGM is a computational model that is highly consistent with the anatomical structure and functions of the HPF, in contrast to typical conventional SLAM models. By referencing the brain, we suggest the importance of the integration of egocentric/allocentric information from the entorhinal cortex to the hippocampus and the use of discrete-event queues.",ArXiv,2021
fb39d026177c1d8f1594af64e5bd758fc82caa41,https://www.semanticscholar.org/paper/fb39d026177c1d8f1594af64e5bd758fc82caa41,Autonomous cognition development with lifelong learning: A self-organizing and reflecting cognitive network,"Abstract Lifelong learning is still a great challenge for cognitive robots since the continuous streaming data they encounter is usually enormous and no-stationary. Traditional cognitive methods suffer from large storage and computation consumption in this situation. Therefore, we propose a self-organizing and reflecting cognitive network (SORCN) to realize robotic lifelong cognitive development through incremental learning and regular reflecting. The network integrates a self-organizing incremental neural network (SOINN) with a modified CFS clustering algorithm. SOINN develops concise object concepts to alleviate storage consumption. Moreover, we modify SOINN by an efficient competitive method based on reflection results to reduce the learning computation. The modified CFS clustering algorithm is designed for reflecting knowledge learned by SOINN periodically. It improves the traditional CFS as a three-step clustering method including clustering, merging and splitting. Specifically, an autonomous center selection strategy is employed for CFS to cater to online learning. Moreover, a series of cluster merging and splitting strategies are proposed to enable CFS to cluster data incrementally and improve its clustering effect. Additionally, the reflection results are utilized to adjust the topological structure of SOINN and guide the future learning. Experimental results demonstrate that SORCN can achieve better learning effectiveness and efficiency over several state-of-art algorithms.",Neurocomputing,2021
32e162fc5b95ae3996561075d00dfd498dec7522,https://www.semanticscholar.org/paper/32e162fc5b95ae3996561075d00dfd498dec7522,References,,Computational Models for Cognitive Vision,2020
380415fdaae3945fb795f292768383b7a298e51c,https://www.semanticscholar.org/paper/380415fdaae3945fb795f292768383b7a298e51c,Robustness Improvement of Visual Templates Matching Based on Frequency-Tuned Model in RatSLAM,"This paper describes an improved brain-inspired simultaneous localization and mapping (RatSLAM) that extracts visual features from saliency maps using a frequency-tuned (FT) model. In the traditional RatSLAM algorithm, the visual template feature is organized as a one-dimensional vector whose values only depend on pixel intensity; therefore, this feature is susceptible to changes in illumination intensity. In contrast to this approach, which directly generates visual templates from raw RGB images, we propose an FT model that converts RGB images into saliency maps to obtain visual templates. The visual templates extracted from the saliency maps contain more of the feature information contained within the original images. Our experimental results demonstrate that the accuracy of loop closure detection was improved, as measured by the number of loop closures detected by our method compared with the traditional RatSLAM system. We additionally verified that the proposed FT model-based visual templates improve the robustness of familiar visual scene identification by RatSLAM.",Frontiers in Neurorobotics,2020
3a323d5bf0e8ebf5b7cab39c510f57dafdc0429f,https://www.semanticscholar.org/paper/3a323d5bf0e8ebf5b7cab39c510f57dafdc0429f,Socially emotional brain-inspired cognitive architecture framework for artificial intelligence,"Abstract Artificial Intelligence of the next generation needs to interact with users socially, convincing them in its ability to understand human minds, including emotions. For this to happen, an artificial emotional intelligence is needed, capable of adequate, believable behavior in social emotional interactions. Building on previous developments, the present work extends the general framework of emotional Biologically Inspired Cognitive Architecture (eBICA: Samsonovich, 2013, 2018), endowing it with fluents describing, in addition to appraisals, somatic markers, feelings, emotions, moods, emotional reactions and biases. Key building blocks that integrate them are moral schemas and semantic maps. The model describes interaction of three factors: plans and commitments, moral and ethical values, and somatic comfort. Learning in this framework includes self-organization of semantic maps that in turn may provide guidance for active humanlike learning. Implications for empirical studies and practical applications are discussed together with the expected impact.",Cognitive Systems Research,2020
7285f88c061b91acaeb549b2df7137dc88d821f4,https://www.semanticscholar.org/paper/7285f88c061b91acaeb549b2df7137dc88d821f4,Modeling reverse thinking for machine learning,"Human inertial thinking schemes can be formed through learning, which are then applied to quickly solve similar problems later. However, when problems are significantly different, inertial thinking generally presents the solutions that are definitely imperfect. In such cases, people will apply creative thinking, such as reverse thinking, to solve problems. Similarly, machine learning methods also form inertial thinking schemes through learning the knowledge from a large amount of data. However, when the testing samples are vastly different, the formed inertial thinking schemes will inevitably generate errors. This kind of inertial thinking is called illusion inertial thinking. Because all machine learning methods do not consider the illusion inertial thinking, in this paper we propose a new method that uses the reverse thinking to correct the illusion inertial thinking, which increases the generalization ability of machine learning methods. Experimental results on benchmark data sets validated the proposed method.",Soft Comput.,2020
b6e94f937143e36cd53e185c662721f27514fbae,https://www.semanticscholar.org/paper/b6e94f937143e36cd53e185c662721f27514fbae,Towards intrinsic autonomy through evolutionary computation,"This paper presents an embodied open-ended environment driven evolutionary algorithm capable of evolving behaviors of autonomous agents without any explicit description of objectives, evaluation metrics or cooperative dynamics. The main novelty of our technique is obtaining intrinsically motivated autonomy of a virtual robot in continuous activity, by internalizing evolutionary dynamics in order to achieve adaptation of a neural controller, and with no need to frequently restart the agent’s initial conditions as in traditional training methods. Our work is grounded on ideas from the enactive artificial intelligence field and the biological concept of enaction, from which it is argued that what makes a living being “intentional” is the ability to autonomously, adaptively rearrange their microstructure to suit some function in order to maintain its own constitution. We bring an alternative understanding of intrinsic motivation than that traditionally approached by intrinsic motivated reinforcement learning, and so we also make a brief discussion of the relationship between both paradigms and the autonomy of an agent. We show the autonomous development of foraging and navigation behaviors of a virtual robot.",Artificial Intelligence Review,2019
21dbf106c66f7f7ccf1eb84d052d97cf1769eace,https://www.semanticscholar.org/paper/21dbf106c66f7f7ccf1eb84d052d97cf1769eace,Federated Learning Application on Depression Treatment Robots(DTbot),"Depression is one of the most prevalent psychiatric disorders and an important public health problem. Its etiology is multifaceted, and the specific pathophysiological mechanisms are still unclear. At present, the main treatment methods for depression are medication, psychotherapy and physical therapy, and clinical applications usually combine two or three methods. Psychotherapy is currently mainly oriented towards the traditional face-to-face communication with psychologists, and is rarely combined with the current rapid development of technology. In this paper, we aim to design an intelligent robot that incorporates deep learning methods to help doctors treat patients more efficiently. The problem is that the current models of robots are trained by uploading data to a server, and then having the server train the robot. There are disadvantages of this approach. First, patient videos and conversations are private information. So uploading those private information to the server can lead to patient information leakage, which is bad. Second, the data recorded in daily life, including audio and video, are very large files that are slow to transfer and tend to cause package loss and other problems in the process. Training a multi-robot model in combination with federal learning would be a good solution to these two problems. The article combines federal learning with basic deep learning methods to design a depression treatment robot(DTbot) that can treat patients with more privacy and efficiency while handling their personal information.",2021 IEEE 13th International Conference on Computer Research and Development (ICCRD),2021
224ee28a179c71ee8cfb97142027abf7f6693f01,https://www.semanticscholar.org/paper/224ee28a179c71ee8cfb97142027abf7f6693f01,Fair Federated Learning for Heterogeneous Face Data,"We consider the problem of achieving fair classification in Federated Learning (FL) under data heterogeneity. Most of the approaches proposed for fair classification require diverse data that represent the different demographic groups involved. In contrast, it is common for each client to own data that represents only a single demographic group. Hence the existing approaches cannot be adopted for fair classification models at the client level. To resolve this challenge, we propose several aggregation techniques. We empirically validate these techniques by comparing the resulting fairness metrics and accuracy on CelebA, UTK, and FairFace datasets.",ArXiv,2021
328d8b2881e6f345df1f2e51c415cc35fdf94450,https://www.semanticscholar.org/paper/328d8b2881e6f345df1f2e51c415cc35fdf94450,A Systematic Literature Review on Federated Machine Learning,"Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.",ACM Comput. Surv.,2020
937ae26417907f038c5d44ca70c5419b99092269,https://www.semanticscholar.org/paper/937ae26417907f038c5d44ca70c5419b99092269,User profile-driven large-scale multi-agent learning from demonstration in federated human-robot collaborative environments,"Learning from Demonstration (LfD) has been established as the dominant paradigm for efficiently transferring skills from human teachers to robots. In this context, the Federated Learning (FL) conceptualization has very recently been introduced for developing large-scale human-robot collaborative environments, targeting to robustly address, among others, the critical challenges of multi-agent learning and longterm autonomy. In the current work, the latter scheme is further extended and enhanced, by designing and integrating a novel user profile formulation for providing a fine-grained representation of the exhibited human behavior, adopting a Deep Learning (DL)-based formalism. In particular, a hierarchically organized set of key information sources is considered, including: a) User attributes (e.g. demographic, anthropomorphic, educational, etc.), b) User state (e.g. fatigue detection, stress detection, emotion recognition, etc.) and c) Psychophysiological measurements (e.g. gaze, electrodermal activity, heart rate, etc.) related data. Then, a combination of Long Short-Term Memory (LSTM) and stacked autoencoders, with appropriately defined neural network architectures, is employed for the modelling step. The overall designed scheme enables both shortand long-term analysis/interpretation of the human behavior (as observed during the feedback capturing sessions), so as to adaptively adjust the importance of the collected feedback samples when aggregating information originating from the same and different human teachers, respectively.",ArXiv,2021
99f73bf6e4e8ac7d5c8be3fbf71000193e849b67,https://www.semanticscholar.org/paper/99f73bf6e4e8ac7d5c8be3fbf71000193e849b67,Towards Open and Expandable Cognitive AI Architectures for Large-Scale Multi-Agent Human-Robot Collaborative Learning,"Learning from Demonstration (LfD) constitutes one of the most robust methodologies for constructing efficient cognitive robotic systems. Despite the large body of research works already reported, current key technological challenges include those of multi-agent learning and long-term autonomy. Towards this direction, a novel cognitive architecture for multi-agent LfD robotic learning is introduced in this paper, targeting to enable the reliable deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the Deep Learning (DL)) field, by establishing a Federated Learning (FL)-based framework for incarnating a multi-human multi-robot collaborative learning environment. The fundamental conceptualization relies on employing multiple AI-empowered cognitive processes (implementing various robotic tasks) that operate at the edge nodes of a network of robotic platforms, while global AI models (underpinning the aforementioned robotic tasks) are collectively created and shared among the network, by elegantly combining information from a large number of human-robot interaction instances. Regarding pivotal novelties, the designed cognitive architecture a) introduces a new FL-based formalism that extends the conventional LfD learning paradigm to support large-scale multi-agent operational settings, b) elaborates previous FL-based self-learning robotic schemes so as to incorporate the human in the learning loop and c) consolidates the fundamental principles of FL with additional sophisticated AI-enabled learning methodologies for modelling the multi-level inter-dependencies among the robotic tasks. The applicability of the proposed framework is explained using an example of a real-world industrial case study (subject to ongoing research activities) for agile production-based Critical Raw Materials (CRM) recovery.",IEEE Access,2020
b408358a5d2300e1fc6cc1a58a18d45a2b75420d,https://www.semanticscholar.org/paper/b408358a5d2300e1fc6cc1a58a18d45a2b75420d,Federated Learning for Internet of Things: A Comprehensive Survey,"The Internet of Things (IoT) is penetrating many facets of our daily life with the proliferation of intelligent services and applications empowered by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may not be feasible in realistic application scenarios due to the high scalability of modern IoT networks and growing data privacy concerns. Federated Learning (FL) has emerged as a distributed collaborative AI approach that can enable many intelligent IoT applications, by allowing for AI training at distributed IoT devices without the need for data sharing. In this article, we provide a comprehensive survey of the emerging applications of FL in IoT networks, beginning from an introduction to the recent advances in FL and IoT to a discussion of their integration. Particularly, we explore and analyze the potential of FL for enabling a wide range of IoT services, including IoT data sharing, data offloading and caching, attack detection, localization, mobile crowdsensing, and IoT privacy and security. We then provide an extensive survey of the use of FL in various key IoT applications such as smart healthcare, smart transportation, Unmanned Aerial Vehicles (UAVs), smart cities, and smart industry. The important lessons learned from this review of the FL-IoT services and applications are also highlighted. We complete this survey by highlighting the current challenges and possible directions for future research in this booming area.",IEEE Communications Surveys & Tutorials,2021
5e1acfaa16a9e55415ad0248a8a3d2f0f261c03a,https://www.semanticscholar.org/paper/5e1acfaa16a9e55415ad0248a8a3d2f0f261c03a,Towards Federated Learning in Edge Computing for Real-Time Traffic Estimation in Smart Cities,"The wide proliferation of sensors and devices of Internet of Things (IoT), together with Artificial Intelligence (AI), has created the so-called Smart Environments. From a network perspective, these solutions suffer from high latency and increased data transmission. This paper proposes a Federated Learning (FL) architecture for Real-Time Traffic Estimation, supported by Roadside Units (RSU’s) for model aggregation. The solution envisages that learning will be done on clients with their local data, and fully distributed on the Edge, with high learning rates, low latency, and less bandwidth usage. To achieve that, this paper discusses tools and requirements for FL implementation towards a model for real-time traffic estimation, as well as how such solution could be evaluated using VANET and network simulators. As a first practical step, we show a preliminary evaluation of a learning model using a data set of cars that demonstrate a distributed learning strategy. In the future, we will use a similar distributed strategy within our proposed architecture.",,2020
6edd085285217ad85acb90e4a3e04d32c82eb3a2,https://www.semanticscholar.org/paper/6edd085285217ad85acb90e4a3e04d32c82eb3a2,Federated Learning for Vehicular Internet of Things: Recent Advances and Open Issues,"Federated learning (FL) is a distributed machine learning approach that can achieve the purpose of collaborative learning from a large amount of data that belong to different parties without sharing the raw data among the data owners. FL can sufficiently utilize the computing capabilities of multiple learning agents to improve the learning efficiency while providing a better privacy solution for the data owners. FL attracts tremendous interests from a large number of industries due to growing privacy concerns. Future vehicular Internet of Things (IoT) systems, such as cooperative autonomous driving and intelligent transport systems (ITS), feature a large number of devices and privacy-sensitive data where the communication, computing, and storage resources must be efficiently utilized. FL could be a promising approach to solve these existing challenges. In this paper, we first conduct a brief survey of existing studies on FL and its use in wireless IoT. Then, we discuss the significance and technical challenges of applying FL in vehicular IoT, and point out future research directions.",IEEE Open Journal of the Computer Society,2020
b528242e8a4ca523964732bcb7510acf12664ae8,https://www.semanticscholar.org/paper/b528242e8a4ca523964732bcb7510acf12664ae8,Incentive Mechanism Design for Federated Learning: A Two-stage Stackelberg Game Approach,"Federated Learning (FL) is a newly-emerging distributed ML model, where a server can coordinate multiple workers to cooperatively train a learning model by using their private datasets, while ensuring these datasets not to be revealed to others. In this paper, we focus on the incentive mechanism design for FL systems. Taking the incentives into consideration, we first design two utility functions for the server and workers, respectively. Then, we model the corresponding utility optimization problem as a two-stage Stackelberg game by seeing the server as a leader and the workers as some followers. Next, we derive an optimal Equilibrium solution for the both stages of the whole game. Based on this solution, we design an incentive mechanism that can ensure the server to achieve the optimal utility, while stimulating workers to do their best to train the ML model. Finally, we conduct extensive simulations to demonstrate the significant performance of the proposed mechanism.",2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS),2020
df5b10c6c04d62c4190525a348fb906ae15c6024,https://www.semanticscholar.org/paper/df5b10c6c04d62c4190525a348fb906ae15c6024,Federated Reinforcement Learning for Fast Personalization,"Understanding user behavior and adapting to it has been an important focus area for applications. That adaptation is commonly called Personalization. Personalization has been sought after in gaming, personal assistants, dialogue managers, and other popular application categories. One of the challenges of personalization methods is the time they take to adapt to the user behavior or reactions. This sometimes is detrimental to user experience. The contribution of this work is twofold: (1) showing the applicability of granular (per user) personalization through the use of reinforcement learning, and (2) proposing a novel mitigation strategy to decrease the personalization time, through federated learning. To our knowledge, this paper is among the first to present an overall architecture for federated reinforcement learning (FRL), which includes the grouping policy, the learning policy, and the federation policy. We demonstrate the efficacy of the proposed architecture on a non-player character in the Atari game Pong, and scale the implementation across 3, 4, and 5 users. We demonstrate the success of the proposal through achieving a median improvement of ~17% on the personalization time.",2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),2019
eb7a8fa2cfebfaecd665ffe9ffee55f2b1408f90,https://www.semanticscholar.org/paper/eb7a8fa2cfebfaecd665ffe9ffee55f2b1408f90,FACE MASK DETECTION USING DEEP LEARNING,"In the Covid-19 Pandemic all countries government warned the citizens to wear a mask whenever they are away from home. They ordered not to leave house without a face mask. In every public premise, offices, in transportation the government and office officials held a face mask compulsory poster. The police and others usually warn and alert a person who does not wear a face mask. In the offices at the entrance the people are examined individually for face mask manually.",,2021
9e2ad27cb8a3d36bd0fac661964c753e57d862e1,https://www.semanticscholar.org/paper/9e2ad27cb8a3d36bd0fac661964c753e57d862e1,A Comprehensive Survey on Implementation of Image Processing Algorithms using FPGA,"Image processing is an unceasingly growing area with a range of applications including cryptography, medicine, video surveillance, remote sensing, and many more. Implementing sophisticated algorithms to process the large amount of data using software solutions makes the response slower, and that's where hardware implementation comes into the picture. Field Programmable Gate Arrays (FPGAs) are getting popular due to low latency, connectivity, parallel computing, and flexibility. The unique architecture of the FPGA has made it possible to use the technology for applying in many applications to have better and faster results. This paper is aiming at providing a comprehensive survey on the hardware implementations of image processing algorithms to facilitate the improvement in efficiency using FPGAs. The widely used Xilinx PYNQ is also presented in this paper as they play a major role in reducing the development time.",2020 5th IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE),2020
55c1d400109cdf8ee5cc1f4e0f05ba7c5eadb28a,https://www.semanticscholar.org/paper/55c1d400109cdf8ee5cc1f4e0f05ba7c5eadb28a,"Big Data, Big Data Analytics application to Smart home technologies and services for geriatric rehabilitation",,Smart Home Technologies and Services for Geriatric Rehabilitation,2022
11ffda0b0bcb4518775ffab5d705421422125c0b,https://www.semanticscholar.org/paper/11ffda0b0bcb4518775ffab5d705421422125c0b,Role of Edge Computing to Leverage IoT-Assisted AAL Ecosystem,"The medical advancement in recent years is addressing challenges of the dependent people like senior citizens, physically challenged, and cognitively impaired individuals by providing technical aids to promote a healthier society. The radical improvement in the digital world is trying to make their life smoother by creating a smart living environment via ambient assisted living (AAL) rather than hospitalization. In this chapter, an Edge-based AAL-IoT ecosystem is introduced with the prime objective of delivering telehealthcare to elderly and telerehabilitation to disabled individuals. The proposed framework focuses on developing smart home, an intelligent atmosphere for real-time monitoring in regard to meet the needs of independent and isolated individuals. The supporting technologies to leverage the edge computing concept, to enable scalability and reliability are also studied. A case study on proposed architecture for quarantined patient monitoring remotely in the event of epidemic or pandemic diseases is presented.",,2021
9ed292124c77430fd21fbd87d4614674c6d859ff,https://www.semanticscholar.org/paper/9ed292124c77430fd21fbd87d4614674c6d859ff,"A Review on Edge Analytics: Issues, Challenges, Opportunities, Promises, Future Directions, and Applications","Edge technology aims to bring Cloud resources (specifically, the compute, storage, and network) to the closed proximity of the Edge devices, i.e., smart devices where the data are produced and consumed. Embedding computing and application in Edge devices lead to emerging of two new concepts in Edge technology, namely, Edge computing and Edge analytics. Edge analytics uses some techniques or algorithms to analyze the data generated by the Edge devices. With the emerging of Edge analytics, the Edge devices have become a complete set. Currently, Edge analytics is unable to provide full support for the execution of the analytic techniques. The Edge devices cannot execute advanced and sophisticated analytic algorithms following various constraints such as limited power supply, small memory size, limited resources, etc. This article aims to provide a detailed discussion on Edge analytics. A clear explanation to distinguish between the three concepts of Edge technology, namely, Edge devices, Edge computing, and Edge analytics, along with their issues. Furthermore, the article discusses the implementation of Edge analytics to solve many problems in various areas such as retail, agriculture, industry, and healthcare. In addition, the research papers of the state-of-the-art edge analytics are rigorously reviewed in this article to explore the existing issues, emerging challenges, research opportunities and their directions, and applications.",ArXiv,2021
e2d1a05660cecc23ff04e0a8472c6670a74ac5a8,https://www.semanticscholar.org/paper/e2d1a05660cecc23ff04e0a8472c6670a74ac5a8,Phishing Prevention Using Defense in Depth,"Phishing attacks are very damaging, costing even moderately sized companies an average of over $1 million per year. It is also a fast growing and quickly evolving threat with nearly 1.5 million phishing websites created each month while each phishing site having an average duration of 54 h. The combination of the potential damage done by phishing attacks and the complex task of “staying ahead of the phishers” requires a layered approach composed of multiple complimentary components. In this paper, we investigate phishing prevention from three different perspectives including web security gateway, email security gateway, and in-depth security awareness training.","Advances in Security, Networks, and Internet of Things",2021
ea97175d7bfabb77239abbff142d679171dc3f24,https://www.semanticscholar.org/paper/ea97175d7bfabb77239abbff142d679171dc3f24,"Ambient Assisted Living: A Review of Technologies, Methodologies and Future Perspectives for Healthy Aging of Population","Over the last decade, there has been considerable and increasing interest in the development of Active and Assisted Living (AAL) systems to support independent living. The demographic change towards an aging population has introduced new challenges to today’s society from both an economic and societal standpoint. AAL can provide an arrary of solutions for improving the quality of life of individuals, for allowing people to live healthier and independently for longer, for helping people with disabilities, and for supporting caregivers and medical staff. A vast amount of literature exists on this topic, so this paper aims to provide a survey of the research and skills related to AAL systems. A comprehensive analysis is presented that addresses the main trends towards the development of AAL systems both from technological and methodological points of view and highlights the main issues that are worthy of further investigation.",Sensors,2021
388e6da6de31d8286be6d74aa2fb134ac5ddc566,https://www.semanticscholar.org/paper/388e6da6de31d8286be6d74aa2fb134ac5ddc566,"Developing applications in large scale, dynamic fog computing: A case study","In recent years, fog computing has emerged as a new distributed system model for a large class of applications that are data‐intensive or delay‐sensitive. By exploiting widely distributed computing infrastructure that is located closer to the network edge, communication cost and service response time can be significantly reduced. However, developing this class of applications is not straightforward and requires addressing three key challenges, ie, supporting the dynamic nature of the edge network, managing the context‐dependent characteristics of application logic, and dealing with the large scale of the system. In this paper, we present a case study in building fog computing applications using our open source platform Distributed Node‐RED (DNR). In particular, we show how applications can be decomposed and deployed to a geographically distributed infrastructure using DNR, and how existing software components can be adapted and reused to participate in fog applications. We present a lab‐based implementation of a fog application built using DNR that addresses the first two of the issues highlighted earlier. To validate that our approach also deals with large scale, we augment our live trial with a large scale simulation of the application model, conducted in Omnet++, which shows the scalability of the model and how it supports the dynamic nature of fog applications.",Softw. Pract. Exp.,2020
2dfb3b34a0ce447a42b25a62c0fc062695f081b1,https://www.semanticscholar.org/paper/2dfb3b34a0ce447a42b25a62c0fc062695f081b1,"Context-dependent exogenous coordination for building large scale, dynamic fog computing applications","Recently, fog computing has emerged as a new system model for applications that are dataintensive or delay-sensitive. Thanks to the computing infrastructure that is closer to the network edge, communication cost and response time are significantly reduced. While promising, fog computing has its unique challenges, particularly due to its large number of computing elements, their geographic distribution and the dynamic nature of the edge network. First, the large scale complexity of fog computing poses new challenges in the application development process. By analysing various application models, we provide a new taxonomy with important trade-offs that help fog computing developers to navigate their design space in building fog applications. From here, we found that exogenous coordination, where there is a clear separation of concerns between computation and communication activities, is a suitable approach in supporting the complexity of many fog computing scenarios. Second, the geo-distribution of fog devices introduces new applications that depend on such devices’ physical context. While we found exogenous coordination to be a suitable approach, it is a software-focused concept that does not cater specifically to those hardware contexts. We propose to extend exogenous coordination with coordination primitives that help to express context-dependent fog application logic. Our proposal includes a clear separation of concerns between contextual and application data, context-dependent constraints for fog application components, and context-bounded communication cardinality among them. Third, the dynamic nature of the edge network requires certain degrees of system moni-",,2019
5b0e73511ebe5eefa1ad9bacad971d139aafb024,https://www.semanticscholar.org/paper/5b0e73511ebe5eefa1ad9bacad971d139aafb024,"Taxonomy of an Application Model: Toward Building Large Scale, Connected Vehicle Applications","With the advent of advanced computing systems beyond personal computing, such as mobile computing, cloud computing or recently, vehicular ad-hoc network, it is crucial that we understand the application development process of each type of these systems. Better understanding of how applications are built in different environment allows us to design better application models and system supports for developers. This paper studies the taxonomy of application models and defines its consisting aspects, namely application scope, application abstraction level, application structure, communication model and programming model. With the better understanding of the application models in general, we lay out the requirements for developing a class of large scale connected vehicle applications.",DIVANet,2019
c28972cca42d98bda3576002c110d085604b4355,https://www.semanticscholar.org/paper/c28972cca42d98bda3576002c110d085604b4355,A scalable CNN architecture and its application to short exposure stellar images processing on a HPRC,"Abstract A CNN-based algorithm for short exposure image processing and an application-specific computing architecture developed to accelerate its execution are presented. Algorithm is based on a flexible and scalable Cellular Neural Networks (CNN) architecture specifically designed to optimize the projection of CNN kernels on a programmable circuit. The objective of the proposed algorithm is to minimize the adverse effect that atmospheric disturbance has on the images obtained by terrestrial telescopes. Algorithm main features are that it can be adapted to the detection of several astronomical objects and it supports multi-stellar images. The implementation platform made use of a High Performance Reconfigurable Computer (HPRC) combining general purpose standard microprocessors with custom hardware accelerators based on FPGAs, to speed up execution time. The hardware/software partitioning and co-design process have been carried out using high level design tools, instead of traditional Hardware Description Languages (HDLs). Results are presented in terms of circuit area/speed, processing performance and output quality.",Neurocomputing,2015
0b27af886a920d5340d15ffd23aefd8885250578,https://www.semanticscholar.org/paper/0b27af886a920d5340d15ffd23aefd8885250578,ADAPTIVE POWER MANAGEMENT FOR COMPUTERS AND MOBILE DEVICES,"Power consumption has become a major concern in the design of computing systems today. High power consumption increases cooling cost, degrades the system reliability and also reduces the battery life in portable devices. Modern computing/communication devices support multiple power modes which enable power and performance tradeoff. Dynamic power management (DPM), dynamic voltage and frequency scaling (DVFS), and dynamic task migration for workload consolidation are system level power reduction techniques widely used during runtime. In the first part of the dissertation, we concentrate on the dynamic power management of the personal computer and server platform where the DPM, DVFS and task migrations techniques are proved to be highly effective. A hierarchical energy management framework is assumed, where task migration is applied at the upper level to improve server utilization and energy efficiency, and DPM/DVFS is applied at the lower level to manage the power mode of individual processor. This work focuses on estimating the performance impact of workload consolidation and searching for optimal DPM/DVFS that adapts to the changing workload. Machine learning based modeling and reinforcement learning based policy optimization techniques are investigated. Mobile computing has been weaved into everyday lives to a great extend in recent years. Compared to traditional personal computer and server environment, the mobile computing environment is obviously more context-rich and the usage of mobile computing device is clearly imprinted with user’s personal signature. The ability to learn such signature enables immense potential in workload prediction and energy or battery life management. In the second part of the dissertation, we present two mobile device power management techniques which take advantage of the context-rich characteristics of mobile platform and make adaptive energy management decisions based on different user behavior. We firstly investigate the user battery usage behavior modeling and apply the model directly for battery energy management. The first technique aims at maximizing the quality of service (QoS) while keeping the risk of battery depletion below a given threshold. The second technique is an user-aware streaming strategies for energy efficient smartphone video playback applications (e.g. YouTube) that minimizes the sleep and wake penalty of cellular module and at the same time avoid the energy waste from excessive downloading. Runtime power and thermal management has attracted substantial interests in multi-core distributed embedded systems. Fast performance evaluation is an essential step in the research of distributed power and thermal management. In last part of the dissertation, we present an FPGA based emulator of multi-core distributed embedded system designed to support the research in runtime power/thermal management. Hardware and software supports are provided to carry out basic power/thermal management actions including inter-core or inter-FPGA communications, runtime temperature monitoring and dynamic frequency scaling. ADAPTIVE POWER MANAGEMENT FOR COMPUTERS AND MOBILE DEVICES by Hao Shen B.S., Southeast University, 2008 Dissertation Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Electrical and Computer Engineering Syracuse University December 2014 Copyright © Hao Shen December 2014 All Rights Reserved",,2014
a8bd9eb2263120a66ed5a1d3fceb53eb5f4100d4,https://www.semanticscholar.org/paper/a8bd9eb2263120a66ed5a1d3fceb53eb5f4100d4,An efficient and expandable hardware implementation of multilayer cellular neural networks,"Abstract This paper proposes a new CNN architecture conceived for hardware implementation of complex ML-CNNs on programmable devices. The architecture is completely modular and expandable, and includes advanced features such as non-linear templates, time-variant coefficients or multi-layer structure. We also present an implementation platform based on the pre-designed but user-configurable FPGA processing modules that inherit the modularity and expandability of the logical architecture. All the modules share the same, properly designed, I/O interface, so the platform can be configured to accommodate CNNs of any size or structure, composed of a number of processing blocks that can be physically distributed over several FPGA boards. Our Carthagonova architecture makes use of a temporal processing approach with a super-pipelined unfolded cell structure, leading to the maximum degree of parallelism while still keeping the most efficient use of FPGA resources. Both the CNN architecture and the hardware platform have been validated by the implementation of a real-time video processing system, showing that they conform a valuable set of tools for the development of CNN-based applications.",Neurocomputing,2013
20b297f9fcc373fe8578b229235624bdda2b8ae1,https://www.semanticscholar.org/paper/20b297f9fcc373fe8578b229235624bdda2b8ae1,An FPGA-Based Distributed Computing System with Power and Thermal Management Capabilities,"Runtime power and thermal management has attracted substantial interests in multi-core distributed embedded systems. Fast performance evaluation is an essential step in the research of distributed power and thermal management. Compared to software simulation, an FPGA-based evaluation platform provides fast emulation speed which enables us to test the performance of power/thermal management policies with real-life applications and OS. Compared to computer clusters, an FPGA-based platform has the flexibility to be configured into any network topology and hardware sniffer for performance monitoring can be added easily. This paper presents an FPGA based emulator of multi-core distributed embedded system designed to support the research in runtime power/thermal management. The system consists of multiple FPGAs connecting through Ethernet with each FPGA configured as a multi-core system. Hardware and software supports are provided to carry out basic power/thermal management actions including inter-core or inter-FPGA communications, runtime temperature monitoring and dynamic frequency scaling.",2011 Proceedings of 20th International Conference on Computer Communications and Networks (ICCCN),2011
2ed90764e820d1f50a177fc55985ca8566356aab,https://www.semanticscholar.org/paper/2ed90764e820d1f50a177fc55985ca8566356aab,Towards the vision of a social robot in every home: A navigation strategy via enhanced subsumption architecture,,,2020
15a7be7b9a50c84ac8421be3214d3c4748325fae,https://www.semanticscholar.org/paper/15a7be7b9a50c84ac8421be3214d3c4748325fae,Data augmentation for deep learning based semantic segmentation and crop-weed classification in agricultural robotics,"Abstract Deep learning methods such as convolutional neural networks (CNN) have become popular for addressing crops and weeds classification problems in agricultural robotics. However, to have satisfactory performance and avoid overfitting, training deep neural nets typically requires thousands of labeled images. This leads to tedious pixelwise labeling for semantic segmentation. In this paper, we hinge on the recent development in data augmentation and utilize the concept further for semantic segmentation and classification of crops and weeds. To be specific, we propose a novel data augmentation framework, based on the random image cropping and patching (RICAP) method, which is originally designed to augment data for generic image classification. The proposed framework introduces novel enhancements to the original RICAP so that it can be effectively used for data augmentation of semantic segmentation tasks. We evaluate the proposed methodology on two datasets from different farms. Comprehensive experimental evaluations and ablation studies show that the proposed framework can effectively improve segmentation accuracies, and the enhancements made over the original RICAP actually contribute to the performance gain. On average, the proposed method increases the mean accuracy and mean intersection over union (IOU) of the deep neural net with the conventional data augmentation (random flipping, rotation and colour jitter) from 91.01 to 94.02 and from 63.59 to 70.77 respectively for Narrabri dataset, and from 97.99 to 98.51 and from 74.26 to 77.09 respectively for Bonn dataset. The limitation of the proposed method, especially when a large number of training data is available, has also been discussed.",Computers and Electronics in Agriculture,2021
2bb9fba127b57ace5f480e55ab8f896111b55151,https://www.semanticscholar.org/paper/2bb9fba127b57ace5f480e55ab8f896111b55151,Real time detection of inter-row ryegrass in wheat farms using deep learning,"A key challenge for autonomous precision weeding is to reliably and accurately detect weed plants and crop plants in real time to minimise damage to surrounding crop plants while performing weeding actions. Specifically for a wheat farm, classifying ryegrass weed plants is particularly difficult even with human eyes since ryegrass shows visually very similar shape and texture to the crop plants themselves. A Deep Neural Network (DNN) that exploits the geometric location of ryegrass is proposed for the real time segmentation of inter-row ryegrass weeds in a wheat field. Our proposed method introduces two subnets in a conventional encoder-decoder style DNN to improve segmentation accuracy. The two subnets treat inter-row and intra-row pixels differently, and provide corrections to preliminary segmentation results of the conventional encoder-decoder DNN. A dataset captured in a wheat farm by an agricultural robot at different time instances is used to evaluate the segmentation performance, and the proposed method performs the best among various popular semantic segmentation algorithms. The proposed method runs at 48.95 Frames Per Second (FPS) with a consumer level graphics processing unit, thus is real-time deployable at camera frame rate.",,2021
2d9978d3d17a02d03d5fedccc388a2ba5a3a2367,https://www.semanticscholar.org/paper/2d9978d3d17a02d03d5fedccc388a2ba5a3a2367,GaNDLF: A Generally Nuanced Deep Learning Framework for Scalable End-to-End Clinical Workflows in Medical Imaging,"Deep Learning (DL) has greatly highlighted the potential impact of optimized machine learning in both the scientific and clinical communities. The advent of open-source DL libraries from major industrial entities, such as TensorFlow (Google), PyTorch (Facebook), and MXNet (Apache), further contributes to DL promises on the democratization of computational analytics. However, increased technical and specialized background is required to develop DL algorithms, and the variability of implementation details hinders their reproducibility. Towards lowering the barrier and making the mechanism of DL development, training, and inference more stable, reproducible, and scalable, without requiring an extensive technical background, this manuscript proposes the Generally Nuanced Deep Learning Framework (GaNDLF). With built-in support for k-fold cross-validation, data augmentation, multiple modalities and output classes, and multi-GPU training, as well as the ability to work with both radiographic and histologic imaging, GaNDLF aims to provide an end-to-end solution for all DL-related tasks, to tackle problems in medical imaging and provide a robust application framework for deployment in clinical workflows.",ArXiv,2021
46012097e36ae1c32fe497f75e0477abe06bad34,https://www.semanticscholar.org/paper/46012097e36ae1c32fe497f75e0477abe06bad34,An ensemble model of convolution and recurrent neural network for skin disease classification,"Skin cancer is one of the rapidly growing diseases in the world. Especially, millions of cases are reported every year by all types of skin cancer in America. Early detection of skin cancer using dermoscopy, the light source, and the magnification device are used to inspect the skin lesions. A dermatologist observed hypodermic structures are normally invisible. However, accurate and effective skin disease classification by humans is not straightforward and requires a long time of practice. Furthermore, it is often inaccurate and difficult to reproduce, being unable to completely use the long‐term dependence connection between specific image key features and image labels even for experienced dermatologists. Therefore, it needs to develop a computer‐aided diagnostic system for reliable skin cancer diagnosis. Classical methods focus on designing and combining hand‐craft features from input data and face vanishing or exploding of loss gradient problem, whereas the bidirectional long short term memory (BLSTM) network does not need any prior knowledge or pre‐designing, and it is an expert in keeping the associated information in both directions. Thus, to improve the classification performance for handling these problems, we proposed a hybrid classification method based on the deep convolutional neural network and stacked BLSTM network. Firstly, deep features are extracted from input skin disease facial images. Next, the sequential features among input data are learned using a dual BLSTM network, where dual BLSTM through max‐pooling, the forward and backward long short term memory (LSTM) hidden states of both the feature matrix and its transpose concatenates for inputting into a dense, fully connected (FC) layer. Finally, the softmax function is used to classify skin disease images. To improve the generalization capability, we evaluate our method on two skin disease image datasets and compare their local image descriptors. The proposed method achieved the best mean accuracy of 91.73%, which shows significant improvements in skin disease classification compared with state‐of‐the‐art skin disease classification methods.",International Journal of Imaging Systems and Technology,2021
523726af6b76c8e201b209a571ca183c3373b51f,https://www.semanticscholar.org/paper/523726af6b76c8e201b209a571ca183c3373b51f,Multi-Spectral Image Synthesis for Crop/Weed Segmentation in Precision Farming,"An effective perception system is a fundamental component for farming robots, as it enables them to properly perceive the surrounding environment and to carry out targeted operations. The most recent approaches make use of state-of-the-art machine learning techniques to learn an effective model for the target task. However, those methods need a large amount of labelled data for training. A recent approach to deal with this issue is data augmentation through Generative Adversarial Networks (GANs), where entire synthetic scenes are added to the training data, thus enlarging and diversifying their informative content. In this work, we propose an alternative solution with respect to the common data augmentation techniques, applying it to the fundamental problem of crop/weed segmentation in precision farming. Starting from real images, we create semi-artificial samples by replacing the most relevant object classes (i.e., crop and weeds) with their synthesized counterparts. To do that, we employ a conditional GAN (cGAN), where the generative model is trained by conditioning the shape of the generated object. Moreover, in addition to RGB data, we take into account also near-infrared (NIR) information, generating four channel multi-spectral synthetic images. Quantitative experiments, carried out on three publicly available datasets, show that (i) our model is capable of generating realistic multi-spectral images of plants and (ii) the usage of such synthetic images in the training process improves the segmentation performance of state-of-the-art semantic segmentation Convolutional Networks.",Robotics Auton. Syst.,2020
5ad02d9314570167b6541af9a0e594aa180753fc,https://www.semanticscholar.org/paper/5ad02d9314570167b6541af9a0e594aa180753fc,Semantic 3D Mapping from Deep Image Segmentation,"The perception and identification of visual stimuli from the environment is a fundamental capacity of autonomous mobile robots. Current deep learning techniques make it possible to identify and segment objects of interest in an image. This paper presents a novel algorithm to segment the object’s space from a deep segmentation of an image taken by a 3D camera. The proposed approach solves the boundary pixel problem that appears when a direct mapping from segmented pixels to their correspondence in the point cloud is used. We validate our approach by comparing baseline approaches using real images taken by a 3D camera, showing that our method outperforms their results in terms of accuracy and reliability. As an application of the proposed algorithm, we present a semantic mapping approach for a mobile robot’s indoor environments.",,2021
5e51f14092090c30990bbdcd53729a2e6c000d37,https://www.semanticscholar.org/paper/5e51f14092090c30990bbdcd53729a2e6c000d37,Real-Time Multiobject Tracking Based on Multiway Concurrency,"This paper explored a pragmatic approach to research the real-time performance of a multiway concurrent multiobject tracking (MOT) system. At present, most research has focused on the tracking of single-image sequences, but in practical applications, multiway video streams need to be processed in parallel by MOT systems. There have been few studies on the real-time performance of multiway concurrent MOT systems. In this paper, we proposed a new MOT framework to solve multiway concurrency scenario based on a tracking-by-detection (TBD) model. The new framework mainly focuses on concurrency and real-time based on limited computing and storage resources, while considering the algorithm performance. For the former, three aspects were studied: (1) Expanded width and depth of tracking-by-detection model. In terms of width, the MOT system can support the process of multiway video sequence at the same time; in terms of depth, image collectors and bounding box collectors were introduced to support batch processing. (2) Considering the real-time performance and multiway concurrency ability, we proposed one kind of real-time MOT algorithm based on directly driven detection. (3) Optimization of system level—we also utilized the inference optimization features of NVIDIA TensorRT to accelerate the deep neural network (DNN) in the tracking algorithm. To trade off the performance of the algorithm, a negative sample (false detection sample) filter was designed to ensure tracking accuracy. Meanwhile, the factors that affect the system real-time performance and concurrency were studied. The experiment results showed that our method has a good performance in processing multiple concurrent real-time video streams.",Sensors,2021
6cff7d794705e6e578e505b500457c848526a8b3,https://www.semanticscholar.org/paper/6cff7d794705e6e578e505b500457c848526a8b3,An ultra-fast bi-phase advanced network for segmenting crop plants from dense weeds,,Biosystems Engineering,2021
8c963dc8b6dea7e5da3a595cd0c9974b7d536c26,https://www.semanticscholar.org/paper/8c963dc8b6dea7e5da3a595cd0c9974b7d536c26,OverlapNet: a siamese network for computing LiDAR scan similarity with applications to loop closing and localization,"Localization and mapping are key capabilities of autonomous systems. In this paper, we propose a modified Siamese network to estimate the similarity between pairs of LiDAR scans recorded by autonomous cars. This can be used to address both, loop closing for SLAM and global localization. Our approach utilizes a deep neural network exploiting different cues generated from LiDAR data. It estimates the similarity between pairs of scans using the concept of image overlap generalized to range images and furthermore provides a relative yaw angle estimate. Based on such predictions, our method is able to detect loop closures in a SLAM system or to globally localize in a given map. For loop closure detection, we use the overlap prediction as the similarity measurement to find loop closure candidates and integrate the candidate selection into an existing SLAM system to improve the mapping performance. For global localization, we propose a novel observation model using the predictions provided by OverlapNet and integrate it into a Monte-Carlo localization framework. We evaluate our approach on multiple datasets collected using different LiDAR scanners in various environments. The experimental results show that our method can effectively detect loop closures surpassing the detection performance of state-of-the-art methods and that it generalizes well to different environments. Furthermore, our method reliably localizes a vehicle in typical urban environments globally using LiDAR data collected in different seasons.",Autonomous Robots,2021
8db80d5535959193ce79850404ce0bcb130bdc17,https://www.semanticscholar.org/paper/8db80d5535959193ce79850404ce0bcb130bdc17,Active Bayesian Multi-class Mapping from Range and Semantic Segmentation Observations,"Many robot applications call for autonomous exploration and mapping of unknown and unstructured environments. Information-based exploration techniques, such as Cauchy-Schwarz quadratic mutual information (CSQMI) and fast Shannon mutual information (FSMI), have successfully achieved active binary occupancy mapping with range measurements. However, as we envision robots performing complex tasks specified with semantically meaningful objects, it is necessary to capture semantic categories in the measurements, map representation, and exploration objective. This work develops a Bayesian multi-class mapping algorithm utilizing range-category measurements. We derive a closed-form efficiently computable lower bound for the Shannon mutual information between the multi-class map and the measurements. The bound allows rapid evaluation of many potential robot trajectories for autonomous exploration and mapping. We compare our method against frontier-based and FSMI exploration and apply it in a 3-D photo-realistic simulation environment.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021
a73bed3d03dee9e46021b42280819a2a9a7fffd9,https://www.semanticscholar.org/paper/a73bed3d03dee9e46021b42280819a2a9a7fffd9,Dense Incremental Metric-Semantic Mapping for Multi-Agent Systems via Sparse Gaussian Process Regression,"We develop an online probabilistic metric-semantic mapping approach for mobile robot teams relying on streaming RGB-D observations. The generated maps contain full continuous distributional information about the geometric surfaces and semantic labels (e.g., chair, table, wall). Our approach is based on online Gaussian Process (GP) training and inference, and avoids the complexity of GP classification by regressing a truncated signed distance function (TSDF) of the regions occupied by different semantic classes. Online regression is enabled through a sparse pseudo-point approximation of the GP posterior. To scale to large environments, we further consider spatial domain partitioning via an octree data structure with overlapping leaves. An extension to the multi-robot setting is developed by having each robot execute its own online measurement update and then combine its posterior parameters via local weighted geometric averaging with those of its neighbors. This yields a distributed information processing architecture in which the GP map estimates of all robots converge to a common map of the environment while relying only on local one-hop communication. Our experiments demonstrate the effectiveness of the probabilistic metric-semantic mapping technique in 2-D and 3-D environments in both single and multi-robot settings.",ArXiv,2021
aaecae16fcb13afd2ed0079d8ff14e7ca343d3b4,https://www.semanticscholar.org/paper/aaecae16fcb13afd2ed0079d8ff14e7ca343d3b4,The UMA-SAR Dataset: Multimodal data collection from a ground vehicle during outdoor disaster response training exercises,"This article presents a collection of multimodal raw data captured from a manned all-terrain vehicle in the course of two realistic outdoor search and rescue (SAR) exercises for actual emergency responders conducted in Málaga (Spain) in 2018 and 2019: the UMA-SAR dataset. The sensor suite, applicable to unmanned ground vehicles (UGVs), consisted of overlapping visible light (RGB) and thermal infrared (TIR) forward-looking monocular cameras, a Velodyne HDL-32 three-dimensional (3D) lidar, as well as an inertial measurement unit (IMU) and two global positioning system (GPS) receivers as ground truth. Our mission was to collect a wide range of data from the SAR domain, including persons, vehicles, debris, and SAR activity on unstructured terrain. In particular, four data sequences were collected following closed-loop routes during the exercises, with a total path length of 5.2 km and a total time of 77 min. In addition, we provide three more sequences of the empty site for comparison purposes (an extra 4.9 km and 46 min). Furthermore, the data is offered both in human-readable format and as rosbag files, and two specific software tools are provided for extracting and adapting this dataset to the users’ preference. The review of previously published disaster robotics repositories indicates that this dataset can contribute to fill a gap regarding visual and thermal datasets and can serve as a research tool for cross-cutting areas such as multispectral image fusion, machine learning for scene understanding, person and object detection, and localization and mapping in unstructured environments. The full dataset is publicly available at: www.uma.es/robotics-and-mechatronics/sar-datasets.",Int. J. Robotics Res.,2021
e64a10a05a44395046cf5d8a6e3cbed274045449,https://www.semanticscholar.org/paper/e64a10a05a44395046cf5d8a6e3cbed274045449,Deep Learning Techniques for In-Crop Weed Identification: A Review,"Weeds are a significant threat to the agricultural productivity and the environment. The increasing demand for sustainable agriculture has driven innovations in accurate weed control technologies aimed at reducing the reliance on herbicides. With the great success of deep learning in various vision tasks, many promising image-based weed detection algorithms have been developed. This paper reviews recent developments of deep learning techniques in the field of image-based weed detection. The review begins with an introduction to the fundamentals of deep learning related to weed detection. Next, recent progresses on deep weed detection are reviewed with the discussion of the research materials including public weed datasets. Finally, the challenges of developing practically deployable weed detection methods are summarized, together with the discussions of the opportunities for future research. We hope that this review will provide a timely survey of the field and attract more researchers to address this inter-disciplinary research problem. ∗Corresponding author Email address: hukun_sdu@hotmail.com (Kun Hu) Preprint submitted to Journal Name March 30, 2021 ar X iv :2 10 3. 14 87 2v 1 [ cs .C V ] 2 7 M ar 2 02 1",ArXiv,2021
0cd34c5464447c2b578156d2e2c4bab7bb14d7b5,https://www.semanticscholar.org/paper/0cd34c5464447c2b578156d2e2c4bab7bb14d7b5,Close-Proximity Underwater Terrain Mapping Using Learning-based Coarse Range Estimation,"This paper presents a novel approach to underwater terrain mapping for Autonomous Underwater Vehicles (AUVs) operating in close proximity to complex 3D environments. The proposed methodology creates a probabilistic elevation map of the terrain using a monocular image learning-based scene range estimator as a sensor. This scene range estimator can filter transient objects such as fish and lighting variations. The mapping approach considers uncertainty in both the estimated scene range and robot pose as the AUV moves through the environment. The resulting elevation map can be used for reactive path planning and obstacle avoidance to allow robotic systems to approach the underwater terrain as closely as possible. The performance of our approach is evaluated in a simulated underwater environment by comparing the reconstructed terrain to ground truth reference maps, as well as demonstrated using AUV field data collected within in a coral reef environment. The simulations and field results show that the proposed approach is feasible for obstacle detection and range estimation using a monocular camera in reef environments.",ArXiv,2020
20c711a665154b3caaa73524f5f1e39a58a12fbb,https://www.semanticscholar.org/paper/20c711a665154b3caaa73524f5f1e39a58a12fbb,Robust joint stem detection and crop-weed classification using image sequences for plant-specific treatment in precision farming,,J. Field Robotics,2020
3f6b59164baf2454e0befac4d8df0d29a9566cec,https://www.semanticscholar.org/paper/3f6b59164baf2454e0befac4d8df0d29a9566cec,Automated Evaluation of Semantic Segmentation Robustness for Autonomous Driving,"One of the fundamental challenges in the design of perception systems for autonomous vehicles is validating the performance of each algorithm under a comprehensive variety of operating conditions. In the case of vision-based semantic segmentation, there are known issues when encountering new scenarios that are sufficiently different to the training data. In addition, even small variations in environmental conditions, such as illumination and precipitation, can affect the classification performance of the segmentation model. Given the reliance on visual information, these effects often translate into poor semantic pixel classification which can potentially lead to catastrophic consequences when driving autonomously. This paper presents a novel method for analyzing the robustness of semantic segmentation models and provides a number of metrics to evaluate the classification performance over a variety of environmental conditions. The process incorporates an additional sensor (lidar) to automate the process and improve the system integrity, eliminating the need for labor-intensive hand labeling of validation data. The experimental results are presented based on multiple datasets collected at different times of the year with different environmental conditions. We extract the ”Road” class using the lidar to demonstrate the concepts, but this could be extended to other classes with different feature detection algorithms. These results show that the semantic segmentation performance varies depending on the weather, camera parameters, and existence of shadows. The results also demonstrate how the metrics can be used to compare and validate the performance after making improvements to a model, and compare the performance of different networks.",IEEE Transactions on Intelligent Transportation Systems,2018
4809e072d27e372ee9da783873f103141643cde2,https://www.semanticscholar.org/paper/4809e072d27e372ee9da783873f103141643cde2,Data Augmentation Using GANs for Crop/Weed Segmentation in Precision Farming,"Farming robots need a fast and robust image segmentation module to apply targeted treatments, which require the ability to distinguish, in real time, between crop and weeds. Existing solutions make use of visual classifiers that are trained on large annotated datasets. However, generating large datasets with pixel-wise annotations is an extremely time-consuming task. In this work, we tackle the crop/weed segmentation problem by using a synthetic image generation method to augment the training dataset without the need of manually labelling the images. The proposed approach consists in training a Generative Adversarial Network (GAN), which can automatically generate realistic agricultural scenes. As a difference with respect to common GAN approaches, where the network learns how to reproduce an entire scene, we generate only instances of the objects of interest in the scene, namely crops. This allows to build a generative model that is more compact and easier to train. The generated objects are then placed into real images of agricultural datasets, thus creating new images that can be used for training. To evaluate the performance of the proposed approach, quantitative experiments have been carried out using different segmentation network architectures, showing that our method well generalizes across multiple architectures.",2020 IEEE Conference on Control Technology and Applications (CCTA),2020
4e94adf8ed4d33f2b77252c40fafc8fd0ecfa196,https://www.semanticscholar.org/paper/4e94adf8ed4d33f2b77252c40fafc8fd0ecfa196,"Artificial Intelligence Applications and Innovations: 16th IFIP WG 12.5 International Conference, AIAI 2020, Neos Marmaras, Greece, June 5–7, 2020, Proceedings, Part I","s of Invited Talks Smartphone, Parkinson’s and Depression: A New AI-Based Prognostic Perspective Leontios Hadjileontiadis Khalifa University of Science and Technology, UAE, and Aristotle University of Thessaloniki, Greece leontios@auth.gr Abstract. Machine Learning (ML) is a branch of Artificial Intelligence (AI) based on the idea that systems can learn from data, identify patterns, and make decisions with minimal human intervention. While many ML algorithms have been around for a long time, the ability to automatically apply complex mathematical calculations to big data – over and over, faster and faster, deeper and deeper – is a recent development, leading to the realization of the so called Deep Learning (DL). The latter has an intuitive capability that is similar to biological brains. It is able to handle the inherent unpredictability and fuzziness of the natural world. In this keynote, the main aspects of ML and DL will be presented, and the focus will be placed in the way they are used to shed light upon the Human Behavioral Modeling. In this vein, AI-based approaches will be presented for identifying fine-motor skills deterioration due to early Parkinson’s and depression symptoms reflected in the keystroke dynamics, while interacting with a smartphone. These approaches provide a new and unobtrusive way for gathering and analyzing dense sampled big data, contributing to further understanding disease symptoms at a very early stage, guiding personalized and targeted interventions that sustain the patient’s quality of life. Machine Learning (ML) is a branch of Artificial Intelligence (AI) based on the idea that systems can learn from data, identify patterns, and make decisions with minimal human intervention. While many ML algorithms have been around for a long time, the ability to automatically apply complex mathematical calculations to big data – over and over, faster and faster, deeper and deeper – is a recent development, leading to the realization of the so called Deep Learning (DL). The latter has an intuitive capability that is similar to biological brains. It is able to handle the inherent unpredictability and fuzziness of the natural world. In this keynote, the main aspects of ML and DL will be presented, and the focus will be placed in the way they are used to shed light upon the Human Behavioral Modeling. In this vein, AI-based approaches will be presented for identifying fine-motor skills deterioration due to early Parkinson’s and depression symptoms reflected in the keystroke dynamics, while interacting with a smartphone. These approaches provide a new and unobtrusive way for gathering and analyzing dense sampled big data, contributing to further understanding disease symptoms at a very early stage, guiding personalized and targeted interventions that sustain the patient’s quality of life. Deep Learning, Knowledge Representation and Transfer with Brain-Inspired Spiking Neural Network Architectures",AIAI,2020
4f26f39d2b3226b9e92dc97f0ad857d912ed6f6e,https://www.semanticscholar.org/paper/4f26f39d2b3226b9e92dc97f0ad857d912ed6f6e,Gradient and Log-based Active Learning for Semantic Segmentation of Crop and Weed for Agricultural Robots,"Annotated datasets are essential for supervised learning. However, annotating large datasets is a tedious and time-intensive task. This paper addresses active learning in the context of semantic segmentation with the goal of reducing the human labeling effort. Our application is agricultural robotics and we focus on the task of distinguishing between crop and weed plants from image data. A key challenge in this application is the transfer of an existing semantic segmentation CNN to a new field, in which growth stage, weeds, soil, and weather conditions differ. We propose a novel approach that, given a trained model on one field together with rough foreground segmentation, refines the network on a substantially different field providing an effective method of selecting samples to annotate for supporting the transfer. We evaluated our approach on two challenging datasets from the agricultural robotics domain and show that we achieve a higher accuracy with a smaller number of samples compared to random sampling as well as entropy based sampling, which consequently reduces the required human labeling effort.",2020 IEEE International Conference on Robotics and Automation (ICRA),2020
576ed0cc914daf86e44dff9313dbcbb11f57edb3,https://www.semanticscholar.org/paper/576ed0cc914daf86e44dff9313dbcbb11f57edb3,Dense Incremental Metric-Semantic Mapping via Sparse Gaussian Process Regression,"We develop an online probabilistic metric-semantic mapping approach for autonomous robots relying on streaming RGB-D observations. We cast this problem as a Bayesian inference task, requiring encoding both the geometric surfaces and semantic labels (e.g., chair, table, wall) of the unknown environment. We propose an online Gaussian Process (GP) training and inference approach, which avoids the complexity of GP classification by regressing a truncated signed distance function representation of the regions occupied by different semantic classes. Online regression is enabled through sparse GP approximation, compressing the training data to a finite set of inducing points, and through spatial domain partitioning into an Octree data structure with overlapping leaves. Our experiments demonstrate the effectiveness of this technique for large-scale probabilistic metric-semantic mapping of 3D environments. A distinguishing feature of our approach is that the generated maps contain full continuous distributional information about the geometric surfaces and semantic labels, making them appropriate for uncertainty-aware planning.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
59e2b2bea9a681aa2069319212fde6253b136e47,https://www.semanticscholar.org/paper/59e2b2bea9a681aa2069319212fde6253b136e47,Classifying Obstacles and Exploiting Class Information for Humanoid Navigation Through Cluttered Environments,"Humanoid robots are often supposed to share their workspace with humans and thus have to deal with objects used by humans in their everyday life. In this article, we present our novel approach to h...",Int. J. Humanoid Robotics,2020
5abc89c7a7414e9243503dd11a130a6def5d30e2,https://www.semanticscholar.org/paper/5abc89c7a7414e9243503dd11a130a6def5d30e2,Semantic Segmentation for the Estimation of Plant and Soil Parameters on Agricultural Machines,"Many machine vision problems in agriculture, like plant classification, soil cover estimation or agronomic process evaluation in general, can be solved with semantic segmentation approaches. Naturally growing non-rigid organic and inorganic materials and plants are often characterized by blurred class transitions and high intra-class variance. Especially outdoor uncontrolled plant growth and plant decomposition lead to strong occlusions, cluttered scenes and strong illumination variances in images. An agricultural vision system has to cope with these challenges. This work presents four different applications for semantic segmentation in agriculture: (1) soil cover estimation, (2) estimation of grass-legumes ratio, (3) grassland swath detection and (4) grassland cut segmentation. For training, TensorFlow and a convolutional neural network are used. We investigate the influence of different pre-training methods to improve the overall classification performance with a limited number of training samples. The best test accuracy was achieved by initializing the weights from a model based on a semi-artificial clover and grass data set. The use cases with images from closer perspectives, (1) and (2), resulted in less accuracy compared to use cases (3) and (4). In general, all use cases can be solved with sufficient accuracy. Keywords–Semantic Segmentation; Agriculture.",,2020
72a2869fc1601ed8b4cbef07979f8797c0cff1e3,https://www.semanticscholar.org/paper/72a2869fc1601ed8b4cbef07979f8797c0cff1e3,Improving Applications of Systems of Systems using Ultra Fast Instance Segmentation,"Computer Vision is a valuable tool that can be used to enhance the components of many working systems. In particular, many applications can be improved by incorporating instance segmentation into their designs to help better process visual information in the surrounding environment. However, instance segmentation algorithms have traditionally been too slow to be used by any real-time systems that could benefit from using them. This includes examples such as self-driving vehicles or autonomous drones. In this work we provide an overview of the shortcomings for current instance segmentation algorithms, introduce an ongoing effort to create a new one that achieves ultrafast speeds without sacrificing competitive accuracy, and explain the advantages of employing an ultra-fast real-time version of one as a component in different systems.",2020 IEEE 15th International Conference of System of Systems Engineering (SoSE),2020
9163245f003a5a9c658ccfdec61bc6e1f6f4971a,https://www.semanticscholar.org/paper/9163245f003a5a9c658ccfdec61bc6e1f6f4971a,Towards Adapting Autonomous Vehicle Technology for the Improvement of Personal Mobility Devices,"Personal Mobility Devices (PMDs) incorporated with autonomy, have great potential in becoming an essential building block of smart transportation infrastructures of the future. However, autonomous vehicle technologies currently employ large and expensive sensors / computers and resource intensive algorithms, which are not suitable for low cost, small form factor PMDs. In this paper, a mobility scooter is retrofitted with a low cost sensing and computing package with the aim of achieving autonomous driving capability. As a first step, a novel, real time, low cost and resource efficient vision only localisation framework based on Convolutional Neural Network (CNN) oriented feature extraction and extended Kalman filter oriented state estimation is presented. Real world experiments in a suburban environment are presented to demonstrate the effectiveness of the proposed localisation framework.",2020 5th International Conference on Innovative Technologies in Intelligent Systems and Industrial Applications (CITISIA),2020
944af9311d93d39642eb54075e006460f007a0ed,https://www.semanticscholar.org/paper/944af9311d93d39642eb54075e006460f007a0ed,Data Augmentation for Deep Learning based Cattle Segmentation in Precision Livestock Farming,"Accurate segmentation of cattle is a prerequisite for feature extraction and estimation. Convolutional neural networks (CNN) based approaches that train models on the largescale labeled datasets have achieved high levels of segmentation performance. However, pixel-wise manual labeling of a cattle image is challenging and time consuming due to the irregularity of the cattle contour. In this regard, data augmentation for deep learning based cattle segmentation is required. Our proposed data augmentation approach uses random image cropping and patching to expand the number of training images and their corresponding labels, then, a state-of-the-art deep neural net is trained to segment cattle images. Here we apply these techniques to images of cattle in a feedlot environment. Our data augmentation-based approach segmented cattle from a complex background with 99.5% mean Accuracy (mAcc) and 97.3% mean Intersection of Unions (mIoU), improving current techniques including a combination of random flipping, rotation and color jitter.",2020 IEEE 16th International Conference on Automation Science and Engineering (CASE),2020
990ebefc7e640a1aa87483276574208b618ba13b,https://www.semanticscholar.org/paper/990ebefc7e640a1aa87483276574208b618ba13b,Monocular Localization in HD Maps by Combining Semantic Segmentation and Distance Transform,"Easy, yet robust long-term localization is still an open topic in research. Existing approaches require either dense maps, expensive sensors, specialized map features or proprietary detectors.We propose using semantic segmentation on a monocular camera to localize directly in a HD map as used for automated driving. This combines lightweight, yet powerful HD maps with the simplicity of monocular vision and the flexibility of neural networks.The major challenges arising from this combination are data association and robustness against misdetections. Association is solved efficiently by applying distance transform on binary per-class images. This provides not only a fast lookup table for a smooth gradient as needed for pose-graph optimization, but also dynamic association by default.A sliding-window pose graph optimization combines single image detections with vehicle odometry, smoothing results and helping overcome even misclassifications in consecutive frames.Evaluation against a highly accurate 6D visual localization shows that our approach can achieve accuracy levels as required for automated driving, being one of the most lightweight and flexible methods to do so.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
9c76e667e9f06344c64581863f715648b5082ef9,https://www.semanticscholar.org/paper/9c76e667e9f06344c64581863f715648b5082ef9,"Applied Machine Vision and IoT",,,2020
b59a557fab0d7c6e6672fa16619be147f686c9d6,https://www.semanticscholar.org/paper/b59a557fab0d7c6e6672fa16619be147f686c9d6,Counting of Grapevine Berries in Images via Semantic Segmentation using Convolutional Neural Networks,"Abstract The extraction of phenotypic traits is often very time and labour intensive. Especially the investigation in viticulture is restricted to an on-site analysis due to the perennial nature of grapevine. Traditionally skilled experts examine small samples and extrapolate the results to a whole plot. Thereby different grapevine varieties and training systems, e.g. vertical shoot positioning (VSP) and semi minimal pruned hedges (SMPH) pose different challenges. In this paper we present an objective framework based on automatic image analysis which works on two different training systems. The images are collected semi automatic by a camera system which is installed in a modified grape harvester. The system produces overlapping images from the sides of the plants. Our framework uses a convolutional neural network to detect single berries in images by performing a semantic segmentation. Each berry is then counted with a connected component algorithm. We compare our results with the Mask-RCNN, a state-of-the-art network for instance segmentation and with a regression approach for counting. The experiments presented in this paper show that we are able to detect green berries in images despite of different training systems. We achieve an accuracy for the berry detection of 94.0% in the VSP and 85.6% in the SMPH.",ArXiv,2020
c1349310d20e4c9802056a632d95916e7fb0ea28,https://www.semanticscholar.org/paper/c1349310d20e4c9802056a632d95916e7fb0ea28,Tensor-Based CUDA Optimization for ANN Inferencing Using Parallel Acceleration on Embedded GPU,"With image processing, robots acquired visual perception skills; enabling them to become autonomous. Since the emergence of Artificial Intelligence (AI), sophisticated tasks such as object identification have become possible through inferencing Artificial Neural Networks (ANN). Be that as it may, Autonomous Mobile Robots (AMR) are Embedded Systems (ESs) with limited on-board resources. Thus, efficient techniques in ANN inferencing are required for real-time performance. This paper presents the process of optimizing ANNs inferencing using tensor-based optimization on embedded Graphical Processing Unit (GPU) with Computer Unified Device Architecture (CUDA) platform for parallel acceleration on ES. This research evaluates renowned network, namely, You-Only-Look-Once (YOLO), on NVIDIA Jetson TX2 System-On-Module (SOM). The findings of this paper display a significant improvement in inferencing speed in terms of Frames-Per-Second (FPS) up to 3.5 times the non-optimized inferencing speed. Furthermore, the current CUDA model and TensorRT optimization techniques are studied, comments are made on its implementation for inferencing, and improvements are proposed based on the results acquired. These findings will contribute to ES developers and industries will benefit from real-time performance inferencing for AMR automation solutions.",AIAI,2020
ca8b19726fbae5c3c517ab9e1c8284befff7f60b,https://www.semanticscholar.org/paper/ca8b19726fbae5c3c517ab9e1c8284befff7f60b,A Unified Model for Real-Time Crop Recognition and Stem Localization Exploiting Cross-Task Feature Fusion,"Robotic mechanical weed control is a promising solution to reduce the usage of herbicides. Efficient and accurate detection of crop stems is the premise of most robotic mechanical weeding machines. This paper proposes a unified convolutional neural network model, called UniStemNet, for real-time crop recognition and stem detection. The UniStemNet consists of a backbone network and two subnets to perform the two tasks simultaneously. According to the difference of targets in the two tasks, the varied-span feature fusion structure is established in the subnets. To improve the stem detection performance, a cross-task feature fusion strategy is devised which introduces a top-down guidance from the crop recognition subnet to the stem detection subnet. Experimental results demonstrate that the proposed UniStemNet can significantly outperform the state-of-the-art crop stem detection method, and perform comparably with leadingedge crop recognition methods. The results also validate the remarkable effect of the cross-task feature fusion strategy on improving the stem detection performance. The UniStemNet can process a 400×300 image within 6 ms. The code and dataset are available at https://github.com/ZhangXG001/Real-Time-Crop-Recognition-and-Stem-Localization.git.",2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),2020
d98b62f6756e1b5c2faa5189ebc6359b8a5d50d6,https://www.semanticscholar.org/paper/d98b62f6756e1b5c2faa5189ebc6359b8a5d50d6,Performance improvements of a sweet pepper harvesting robot in protected cropping environments,"Using robots to harvest sweet peppers in protected cropping environments has remained unsolved despite considerable effort by the research community over several decades. In this paper, we present the robotic harvester, Harvey, designed for sweet peppers in protected cropping environments that achieved a 76.5% success rate on 68 fruit (within a modified scenario) which improves upon our prior work which achieved 58% on 24 fruit and related sweet pepper harvesting work which achieved 33% on 39 fruit (for their best tool in a modified scenario). This improvement was primarily achieved through the introduction of a novel peduncle segmentation system using an efficient deep convolutional neural network, in conjunction with three-dimensional postfiltering to detect the critical cutting location. We benchmark the peduncle segmentation against prior art demonstrating an improvement in performance with a (Formula presented.) score of 0.564 compared to 0.302. The robotic harvester uses a perception pipeline to detect a target sweet pepper and an appropriate grasp and cutting pose used to determine the trajectory of a multimodal harvesting tool to grasp the sweet pepper and cut it from the plant. A novel decoupling mechanism enables the gripping and cutting operations to be performed independently. We perform an in-depth analysis of the full robotic harvesting system to highlight bottlenecks and failure points that future work could address.",J. Field Robotics,2020
e2f8fc422b20e18c57e3a376adcf9c459c662918,https://www.semanticscholar.org/paper/e2f8fc422b20e18c57e3a376adcf9c459c662918,OMNIVIL—An Autonomous Mobile Manipulator for Flexible Production,"Flexible production is a key element in modern industrial manufacturing. Autonomous mobile manipulators can be used to execute various tasks: from logistics, to pick and place, or handling. Therefore, autonomous robotic systems can even increase the flexibility of existing production environments. However, the application of robotic systems is challenging due to their complexity and safety concerns. This paper addresses the design and implementation of the autonomous mobile manipulator OMNIVIL. A holonomic kinematic design provides high maneuverability and the implemented sensor setup with the underlying localization strategies are robust against typical static and dynamic uncertainties in industrial environments. For a safe and efficient human–robot collaboration (HRC), a novel workspace monitoring system (WMS) is developed to detect human co-workers and other objects in the workspace. The multilayer sensor setup and the parallel data analyzing capability provide superior accuracy and reliability. An intuitive zone-based navigation concept is implemented, based on the workspace monitoring system. Preventive behaviors are predefined for a conflict-free interaction with human co-workers. A workspace analyzing tool is implemented for adaptive manipulation, which significantly simplifies the determination of suitable platform positions for a manipulation task.",Sensors,2020
fdb8db21df775846b08d9a3cc258991ae1fc4de6,https://www.semanticscholar.org/paper/fdb8db21df775846b08d9a3cc258991ae1fc4de6,Learning Non-Unique Segmentation with Reward-Penalty Dice Loss,"Semantic segmentation is one of the key problems in the field of computer vision, as it enables computer image understanding. However, most research and applications of semantic segmentation focus on addressing unique segmentation problems, where there is only one gold standard segmentation result for every input image. This may not be true in some problems, e.g., medical applications. We may have non-unique segmentation annotations as different surgeons may perform successful surgeries for the same patient in slightly different ways. To comprehensively learn non-unique segmentation tasks, we propose the reward-penalty Dice loss (RPDL) function as the optimization objective for deep convolutional neural networks (DCNN). RPDL is capable of helping DCNN learn non-unique segmentation by enhancing common regions and penalizing outside ones. Experimental results show that RPDL improves the performance of DCNN models by up to 18.4% compared with other loss functions on our collected surgical dataset.",2020 International Joint Conference on Neural Networks (IJCNN),2020
fea9500951473aa1d283ef1e686161c73bf674f4,https://www.semanticscholar.org/paper/fea9500951473aa1d283ef1e686161c73bf674f4,FAIRS - Soft Focus Generator and Attention for Robust Object Segmentation from Extreme Points,"Semantic segmentation from user inputs has been actively studied to facilitate interactive segmentation for data annotation and other applications. Recent studies have shown that extreme points can be effectively used to encode user inputs. A heat map generated from the extreme points can be appended to the RGB image and input to the model for training. In this study, we present FAIRS -- a new approach to generate object segmentation from user inputs in the form of extreme points and corrective clicks. We propose a novel approach for effectively encoding the user input from extreme points and corrective clicks, in a novel and scalable manner that allows the network to work with a variable number of clicks, including corrective clicks for output refinement. We also integrate a dual attention module with our approach to increase the efficacy of the model in preferentially attending to the objects. We demonstrate that these additions help achieve significant improvements over state-of-the-art in dense object segmentation from user inputs, on multiple large-scale datasets. Through experiments, we demonstrate our method's ability to generate high-quality training data as well as its scalability in incorporating extreme points, guiding clicks, and corrective clicks in a principled manner.",ArXiv,2020
2419a186ab3de44b226bbfecc1caa983034f0939,https://www.semanticscholar.org/paper/2419a186ab3de44b226bbfecc1caa983034f0939,Accelerated Inference in Markov Random Fields via Smooth Riemannian Optimization,"<italic>M</italic>arkov random fields (MRFs) are a popular model for several pattern recognition and reconstruction problems in robotics and computer vision. Inference in MRFs is intractable in general and related work resorts to approximation algorithms. Among those techniques, semidefinite programming (SDP) relaxations have been shown to provide accurate estimates, while scaling poorly with the problem size and being typically slow for practical applications. Our first contribution is to design a dual ascent method to solve standard SDP relaxations that takes advantage of the geometric structure of the problem to speed up computation. This technique, named <italic>dual ascent Riemannian staircase</italic> (<monospace>DARS</monospace>), is able to solve large problem instances <italic>in seconds</italic>. Our second contribution is to develop a second and faster approach. The backbone of this second approach is a novel SDP relaxation combined with a fast and scalable solver based on smooth Riemannian optimization. We show that this approach, named <italic>Fast Unconstrained SEmidefinite Solver</italic> (<monospace>FUSES</monospace>), can solve large problems <italic>in milliseconds</italic>. Contrarily to local MRF solvers, e.g., loopy belief propagation, our approaches do not require an initial guess. Moreover, we leverage recent results from optimization theory to provide per-instance sub-optimality guarantees. We demonstrate the proposed approaches in multi-class image segmentation problems. Extensive experimental evidence shows that: 1) <monospace>FUSES</monospace> and <monospace>DARS</monospace> produce near-optimal solutions, attaining an objective within 0.1% of the optimum; 2) <monospace>FUSES</monospace> and <monospace>DARS</monospace> are remarkably faster than general-purpose SDP solvers, and <monospace>FUSES</monospace> is more than two orders of magnitude faster than <monospace>DARS</monospace> while attaining similar solution quality; and 3) <monospace>FUSES</monospace> is faster than local search methods while being a global solver.",IEEE Robotics and Automation Letters,2018
4c4fe49df01e9ddd3e68b11b3d94fdba7ce244c2,https://www.semanticscholar.org/paper/4c4fe49df01e9ddd3e68b11b3d94fdba7ce244c2,Tillage Machine Control Based on a Vision System for Soil Roughness and Soil Cover Estimation,"Soil roughness and soil cover are important control variables for plant cropping. A certain level of soil roughness can prevent soil erosion, but to rough soil prevents good plant emergence. Local heterogeneities in the field make it difficult to get homogeneous soil roughness. Residues, like straw, influences the soil roughness estimation and play an important role in preventing soil erosion. We propose a system to control the tillage intensity of a power harrow by varying the driving speed and PTO speed of a tractor. The basis for the control algorithm is a roughness estimation system based on an RGB stereo camera. A soil roughness index is calculated from the reconstructed soil surface point cloud. The vision system also integrates an algorithm to detect soil cover, like residues. Two different machine learning methods for pixel-wise semantic segmentation of soil cover were implemented, an entangled random forest and a convolutional neural net. The pixel-wise classification of each image into soil, living organic matter, dead organic matter and stone allow for mapping of soil cover during tillage. The results of the semantic segmentation of soil cover were compared to ground truth labelled data using the grid method. The soil roughness measurements were validated using the manual sieve analysis. The whole control system was validated in field trials on different locations.",ICVS,2019
5aba0bcf8ed32cfae9edcd7d60269295706e8157,https://www.semanticscholar.org/paper/5aba0bcf8ed32cfae9edcd7d60269295706e8157,Crop and Weeds Classification for Precision Agriculture Using Context-Independent Pixel-Wise Segmentation,"Precision agriculture is gaining increasing attention because of the possible reduction of agricultural inputs (e.g., fertilizers and pesticides) that can be obtained by using hightech equipment, including robots. In this paper, we focus on an agricultural robotics system that addresses the weeding problem by means of selective spraying or mechanical removal of the detected weeds. In particular, we describe a deep learning based method to allow a robot to perform an accurate weed/crop classification using a sequence of two Convolutional Neural Networks (CNNs) applied to RGB images. The first network, based on an encoder-decoder segmentation architecture, performs a pixelwise, plant-type agnostic, segmentation between vegetation and soil that enables to extract a set of connected blobs representing plant instances. We show that such network can be trained also using external, ready to use pixel-wise labeled data sets coming from different contexts. Each plant is hence classified between crop and weeds by using the second network. Quantitative experimental results, obtained on real world data, demonstrate that the proposed approach can achieve good classification results also on challenging images.",2019 Third IEEE International Conference on Robotic Computing (IRC),2019
64e23f006fda19bbbbc324b1353851ebca95aa02,https://www.semanticscholar.org/paper/64e23f006fda19bbbbc324b1353851ebca95aa02,RangeNet ++: Fast and Accurate LiDAR Semantic Segmentation,"Perception in autonomous vehicles is often carried out through a suite of different sensing modalities. Given the massive amount of openly available labeled RGB data and the advent of high-quality deep learning algorithms for image-based recognition, high-level semantic perception tasks are pre-dominantly solved using high-resolution cameras. As a result of that, other sensor modalities potentially useful for this task are often ignored. In this paper, we push the state of the art in LiDAR-only semantic segmentation forward in order to provide another independent source of semantic information to the vehicle. Our approach can accurately perform full semantic segmentation of LiDAR point clouds at sensor frame rate. We exploit range images as an intermediate representation in combination with a Convolutional Neural Network (CNN) exploiting the rotating LiDAR sensor model. To obtain accurate results, we propose a novel post-processing algorithm that deals with problems arising from this intermediate representation such as discretization errors and blurry CNN outputs. We implemented and thoroughly evaluated our approach including several comparisons to the state of the art. Our experiments show that our approach outperforms state-of-the-art approaches, while still running online on a single embedded GPU. The code can be accessed at https://github.com/PRBonn/lidar-bonnetal.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019
92e04ffff5042dfeb95be8d42c6966db340a08d6,https://www.semanticscholar.org/paper/92e04ffff5042dfeb95be8d42c6966db340a08d6,Utilization of the open source datasets for semantic segmentation in automotive vision,"Great advancements in deep-learning-based machine vision are boosting the automotive industry potential to accurately recognize vehicle environment. The need for high quality datasets is of critical importance when training neural networks which are used to detect and classify objects in front of the vehicle. Available open source datasets for semantic segmentation can be used by a wide community of researchers to develop next generation self-driving functions. Those datasets have severe limitations such as class imbalance, unobserved objects, erroneous labelling and limited number of covered scenarios. In this paper, we propose a sequence of steps to combine and manipulate existing open source datasets to maximize the inference performance. Those steps include relabeling with outlier removal, class-driven balancing of validation and training datasets, as well as targeted image manipulation for scarce classes. Our evaluation indicates the improved inference accuracy when compared to the usage of most common open source datasets.",2019 IEEE 9th International Conference on Consumer Electronics (ICCE-Berlin),2019
930ba1d5e6ec01855ffd02d5226bce9f22982144,https://www.semanticscholar.org/paper/930ba1d5e6ec01855ffd02d5226bce9f22982144,Shelf Commodity Identification Method Based on Hybrid Fully Convolutional Automatic Encoder,"At present, the semantic information segmentation algorithms mainly include FCN (Fully Convolutional Network), PSPNet (Pyramid Scene Parsing Network), Deeplab and so on. In view of the inadequate results of features extracted by these algorithms from RGB image, a hybrid fully convolutional autoencoder neural network (HFCAN) structure, which introduces fully convolutional neural network and stacked sparse autoencoder, is proposed in this paper. Using the FCN to generate the thermal high-dimensional feature map of the shelf commodity, and then performing the up-sampling operation on the segmented feature map. During the up-sampling operation, the convolution features are refined by the stacked sparse autoencoder (SAE), and the image boundary details are retained, so that the classification results are more accurate. The experimental results show that the hybrid fully convolutional autoencoder model proposed in this paper can not only shorten the training time and testing time of neural network by nearly 50%, but also improve the accuracy of shelf commodity identification by nearly 95%.",IEEE Access,2019
9436734be1a0c84e10fe3b65bb0552abc1bf8ba3,https://www.semanticscholar.org/paper/9436734be1a0c84e10fe3b65bb0552abc1bf8ba3,Investigations on the inference optimization techniques and their impact on multiple hardware platforms for Semantic Segmentation,"In this work, the task of pixel-wise semantic segmentation in the context of self-driving with a goal to reduce the inference time is explored. Fully Convolutional Network (FCN-8s, FCN-16s, and FCN-32s) with a VGG16 encoder architecture and skip connections is trained and validated on the Cityscapes dataset. Numerical investigations are carried out for several inference optimization techniques built into TensorFlow and TensorRT to quantify their impact on the inference time and network size. Finally, the trained network is ported on to an embedded platform (Nvidia Jetson TX1) and the inference time, as well as the total energy consumed for inference across hardware platforms, are compared.",ArXiv,2019
a6613412d185f4ce802a662190a95dc7660fe01c,https://www.semanticscholar.org/paper/a6613412d185f4ce802a662190a95dc7660fe01c,Weed Detection in Perennial Ryegrass With Deep Learning Convolutional Neural Network,"Precision herbicide application can substantially reduce herbicide input and weed control cost in turfgrass management systems. Intelligent spot-spraying system predominantly relies on machine vision-based detectors for autonomous weed control. In this work, several deep convolutional neural networks (DCNN) were constructed for detection of dandelion (Taraxacum officinale Web.), ground ivy (Glechoma hederacea L.), and spotted spurge (Euphorbia maculata L.) growing in perennial ryegrass. When the networks were trained using a dataset containing a total of 15,486 negative (images contained perennial ryegrass with no target weeds) and 17,600 positive images (images contained target weeds), VGGNet achieved high F1 scores (≥0.9278), with high recall values (≥0.9952) for detection of E. maculata, G. hederacea, and T. officinale growing in perennial ryegrass. The F1 scores of AlexNet ranged from 0.8437 to 0.9418 and were generally lower than VGGNet at detecting E. maculata, G. hederacea, and T. officinale. GoogleNet is not an effective DCNN at detecting these weed species mainly due to the low precision values. DetectNet is an effective DCNN and achieved high F1 scores (≥0.9843) in the testing datasets for detection of T. officinale growing in perennial ryegrass. Moreover, VGGNet had the highest Matthews correlation coefficient (MCC) values, while GoogleNet had the lowest MCC values. Overall, the approach of training DCNN, particularly VGGNet and DetectNet, presents a clear path toward developing a machine vision-based decision system in smart sprayers for precision weed control in perennial ryegrass.",Front. Plant Sci.,2019
c39881d58721dceb92909e2fbcd8994c4c1c207e,https://www.semanticscholar.org/paper/c39881d58721dceb92909e2fbcd8994c4c1c207e,Detecting Untraversable Regions for Navigating Mobile Robot on Pedestrian Lanes,"The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. ...Pedestrian lane following for autonomous navigation without pre-built maps in unconstrained outdoor environments is investigated. We extend the occupancy grid based mapping method which is dominantly applied in indoor environments to more open outdoor environments with far fewer surrounding objects. A stereo camera with middle ranging capability is used to capture color and depth data of road scenes. The color images are semantically parsed into different regions by using a pre-trained convolutional neural network (CNN). By taking advantages of the depth data, all 3D points of the image regions with non-road class labels are determined as untraversable ones and processed into pseudo laser scans. The pseudo laser scans are further projected into obstacle cells of the local occupancy grid map. By proposing a virtual wall and following it, the robot can autonomously move along the unconstrained pedestrian lanes and keep to the right. We test the navigation system in outdoor and indoor environments using the TurtleBot2 platform. The good performance of occupancy grid mapping and the effectiveness of lane following are validated by the blind test results.",ICIRA,2019
f444cd325d3a2012764f4c516fe1d139ddbb10db,https://www.semanticscholar.org/paper/f444cd325d3a2012764f4c516fe1d139ddbb10db,Improving Underwater Obstacle Detection using Semantic Image Segmentation,"This paper presents two novel approaches for improving image-based underwater obstacle detection by combining sparse stereo point clouds with monocular semantic image segmentation. Generating accurate image-based obstacle maps in cluttered underwater environments, such as coral reefs, are essential for robust robotic path planning and navigation. However, these maps can be challenged by factors including visibility, lighting and dynamic objects (e.g. fish) that may lead to falsely identified free space or dynamic objects which trajectory planners may react to undesirably. We propose combining feature-based stereo matching with learning-based segmentation to produce a more robust obstacle map. This approach considers direct binary learning of the presence or absence of underwater obstacles, as well as a multiclass learning approach to classify their distance (near, mid and far) in the scene. An enhancement to the binary map is also shown by including depth information from sparse stereo matching to produce 3D obstacle maps of the scene. The performance is evaluated using field data collected in cluttered, and at times, visually degraded coral reef environments. The results show improved image-wide obstacle detection, rejection of transient objects (such as fish), and range estimation compared to feature-based sparse and dense stereo point clouds alone.",2019 International Conference on Robotics and Automation (ICRA),2019
271625fab106f41a6a24173071ecd0394324f222,https://www.semanticscholar.org/paper/271625fab106f41a6a24173071ecd0394324f222,Classifying Obstacles and Exploiting Knowledge About Classes for Efficient Humanoid Navigation,"In this paper, we propose a new approach to humanoid navigation through cluttered environments that exploits knowledge about different obstacle classes and selects appropriate robot actions. To classify objects from RGB images and decide whether an obstacle can be overcome by the robot with a corresponding action, e.g., by pushing or carrying it aside or stepping over or onto it, we train a convolutional neural network (CNN). Based on the associated action costs, we compute a cost grid of the environment on which a 2D path can be efficiently planned. This path encodes the necessary actions that need to be carried out to reach the goal. We implemented our framework in ROS and tested it in various scenarios with a Nao robot. As the experiments demonstrate, using the CNN the robot can robustly classify the observed obstacles into the different classes and exploit this information to efficiently compute solution paths. Our system finds paths also through regions where traditional planning methods are not able to calculate a solution or require substantially more time.",2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),2018
4f21af16d9ccfb6cb317bdcf930ba7e9c5832f27,https://www.semanticscholar.org/paper/4f21af16d9ccfb6cb317bdcf930ba7e9c5832f27,Interpretation and Alignment of 2D Indoor Maps : Towards a Heterogeneous Map Representation,"Mobile robots are increasingly being used in automation solutions with notable examples in service robots, such as home-care, and warehouses. Autonomy of mobile robots is particularly challenging, ...",,2018
55403bb058249e2f7a1e3741012ea8af450ea77f,https://www.semanticscholar.org/paper/55403bb058249e2f7a1e3741012ea8af450ea77f,A Sweet Pepper Harvesting Robot for Protected Cropping Environments,"Using robots to harvest sweet peppers in protected cropping environments has remained unsolved despite considerable effort by the research community over several decades. In this paper, we present the robotic harvester, Harvey, designed for sweet peppers in protected cropping environments that achieved a 76.5% success rate (within a modified scenario) which improves upon our prior work which achieved 58% and related sweet pepper harvesting work which achieved 33\%. This improvement was primarily achieved through the introduction of a novel peduncle segmentation system using an efficient deep convolutional neural network, in conjunction with 3D post-filtering to detect the critical cutting location. We benchmark the peduncle segmentation against prior art demonstrating a considerable improvement in performance with an F_1 score of 0.564 compared to 0.302. The robotic harvester uses a perception pipeline to detect a target sweet pepper and an appropriate grasp and cutting pose used to determine the trajectory of a multi-modal harvesting tool to grasp the sweet pepper and cut it from the plant. A novel decoupling mechanism enables the gripping and cutting operations to be performed independently. We perform an in-depth analysis of the full robotic harvesting system to highlight bottlenecks and failure points that future work could address.",ArXiv,2018
abefa5253251092a447665b1dc860351be6a414a,https://www.semanticscholar.org/paper/abefa5253251092a447665b1dc860351be6a414a,Discussing resilience in the context of cyber physical systems,"Abstract Cyber-Physical Systems (CPSs) are increasingly more complex and integrated into our everyday lives forming the basis of smart infrastructures, products, and services. Consequently, there is a greater need for their ability to perform their required functions under expected and unexpected adverse events. Moreover, the multitude of threats and their rapid evolution pushes the development of approaches that go beyond pure technical reliability, rather encompassing multi-dimensional performance of a socio-technical system. These dimensions call for the notion of resilience, to be used as a staging area for modelling system performance. While a large number of documents deal with this kind of problem for systems including CPSs, a comprehensive review on the topic is still lacking. The scope of this paper is to survey available literature for understanding to which extent CPSs contribute to system resilience, and to synthetize the approaches developed in this domain. More than 500 documents were reviewed through a protocol based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) review technique. This survey identifies main models and methods categorizing them on the basis of the hazards of interest and their effects on security, privacy, safety and business continuity. It also summarizes main conceptual frameworks and metrics used to assess and compare the resilience capabilities of a system including also CPSs. This cross-domain survey highlights the dominant techno-centric unit of analysis for available literature, still highlighting emerging trends towards more systemic representations of system threats, even socio-technically oriented, and respective modern investigation approaches.",Comput. Ind. Eng.,2021
e87fed422a2df353c9efd4a1861a3326bc35a559,https://www.semanticscholar.org/paper/e87fed422a2df353c9efd4a1861a3326bc35a559,Review of Design Elements within Power Infrastructure Cyber–Physical Test Beds as Threat Analysis Environments,"Cyber–physical systems (CPSs) are an integral part of modern society; thus, enhancing these systems’ reliability and resilience is paramount. Cyber–physical testbeds (CPTs) are a safe way to test and explore the interplay between the cyber and physical domains and to cost-effectively enhance the reliability and resilience of CPSs. Here a review of CPT elements, broken down into physical components (simulators, emulators, and physical hardware), soft components (communication protocols, network timing protocols), and user interfaces (visualization-dashboard design considerations) is presented. Various methods used to validate CPS performance are reviewed and evaluated for potential applications in CPT performance validation. Last, initial simulated results for a CPT design, based on the IEEE 33 bus system, are presented, along with a brief discussion on how model-based testing and fault–injection-based testing (using scaling and ramp-type attacks) may be used to help validate CPT performance.",,2021
24ce923adc9bcabf4b56d5692995ce233cf408c6,https://www.semanticscholar.org/paper/24ce923adc9bcabf4b56d5692995ce233cf408c6,Data Driven Hourly Taxi Drop-offs Prediction using TLC Trip Record Data,"Crowdsourcing applications are proven to be a promising tool to gather valuable information, which can be used for a wide range of tasks, such as ensuring public safety. Traffic data collected using these applications have been used for efficient evacuation planning in large cities. In this paper, we propose to use regression-based machine learning methods to predict hourly taxi rides for a given location in a target day of week and month. The presented method can be used for the following purposes: 1) Predicting the number of taxi rides for a given location at a given time, 2) Identifying hot spots in a city, 3) Getting a rough count of the population density at a given location at a targeted hour, and 4) Planing evacuation routes for possible disasters. The presented approach has potential use for resource planning and evacuation in large cities. The Taxi and Limousine Commission (TLC) trip record data collected from 2017 to 2018 was used for this experiment. It was found that random forest regression can successfully predict hourly taxi drop-offs for a given taxi zone as well as for the entire city of New York.",2019 12th International Conference on Human System Interaction (HSI),2019
3ba76c0a59d2a5cac9d5f9a0839e587356198b65,https://www.semanticscholar.org/paper/3ba76c0a59d2a5cac9d5f9a0839e587356198b65,Data-driven Stochastic Anomaly Detection on Smart-Grid communications using Mixture Poisson Distributions,"Characterizing communications in smart-grid distributed control systems is fundamental for understanding the expected behavior and identify abnormal scenarios. In this paper, we present a stochastic data-driven approach to model the the communication network in smart-grid systems. Our approach uses Mixture Poisson distributions to model the packet communication between the network devices. The network is modeled using a directed graph, where each edge represents a Poisson distribution of the packets being transmitted. Parameters are learned using mini-batch Expectation Maximization in order to scale to large datasets. The advantages of the presented approach are 1) unsupervised data-driven discovery of representative communication patterns, 2) intuitive visualization of the expected behavior, 3) scalability to large datasets, and 4) coherent and interpretable model. Tests were conducted in a simulated SCADA microgrid distributed control system environment.",IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society,2019
40ef3c69ef3a7a35fec9b4cdbc4514899debee86,https://www.semanticscholar.org/paper/40ef3c69ef3a7a35fec9b4cdbc4514899debee86,Attack Scenario-based Validation of the Idaho CPS Smart Grid Cybersecurity Testbed (ISAAC),"The use of smart and distributed devices is increasing in Cyber Physical Systems (CPS). The smart and distributed devices are capable of extensive inter- and intra- networking. Consequently, cyber attack attempts against CPS have been increasing in recent years. The potential for widespread loss of resources for utilities is high if a cyber-attack is executed successfully on a CPS. Realistic and comprehensive cyber-physical testbeds are becoming increasingly necessary to analyze and secure CPS organizations. One such comprehensive and realistic testbed, ISAAC - the Idaho CPS Smart Grid Cybersecurity Testbed, was previously presented. Validating testbeds with realistic experiments is of paramount importance in increasing the usability of a testbed. We present a mapping of ISAAC to the Purdue reference model. We also validate ISAAC by performing a realistic attack-scenario on the testbed. Our results indicate that ISAAC can simulate realistic scenarios.",2019 IEEE Texas Power and Energy Conference (TPEC),2019
9d66196003344fd840cb50bd3dc0bfaa91a459e0,https://www.semanticscholar.org/paper/9d66196003344fd840cb50bd3dc0bfaa91a459e0,Cyber and Physical Anomaly Detection in Smart-Grids,"The inclusion of Information and Communication Technologies (ICTs) in industrial control systems (ICSs) has opened ICSs to several attack vectors, which are increasingly targeting critical infrastructure. Accurate detection and distinction between benign physical disturbances, malicious cyber-attacks, and malicious physical-attacks are necessary to protect critical infrastructure. While cyber sensors provide a useful tool to identify and mitigate cyber attacks, they often ignore the physical behavior of the system at hand. In this paper, we present a cyber-physical sensor called IREST (ICS Resilient Security Technology). The sensor takes a holistic approach in detecting anomalies by considering both cyber and physical disturbances in a complex system. The sensor was tested under different cyber-physical scenarios using the Idaho CPS SCADA Cybersecurity (ISAAC) testbed. The test scenarios capture different operational states of the CPS testbed, including various cyber and physical anomalies. The experiments show that the IREST sensor is able to detect both cyber and physical anomalies. The sensor has the benefit that training requires only normal data and is able to detect disturbances that have not been seen before. The presented approach provides a scalable framework for cyber-physical security research that can be expanded in the future.",2019 Resilience Week (RWS),2019
e34365d762c4750e6639a89282554c4dc5ed5426,https://www.semanticscholar.org/paper/e34365d762c4750e6639a89282554c4dc5ed5426,ISAAC: The Idaho CPS Smart Grid Cybersecurity Testbed,"The landscape of cyber and other threats to Cyber Physical Systems (CPS), such as the Power Grid, is growing rapidly. Realistic and reconfigurable testbeds are needed to be able to develop, test, improve, and deploy practical cybersecurity solutions for CPS. We introduce the design of ISAAC, the Idaho CPS Smart Grid Cybersecurity Testbed. ISAAC is a cross-domain, distributed, and reconfigurable testbed, which emulates a realistic power utility and provides researchers with the tools needed to develop and test integrated cybersecurity solutions. Some components of ISAAC are fully functional, with ongoing research projects utilizing the functional components. When fully developed, the capabilities of ISAAC will include: 1) Multiple emulated power utility substations and control networks; 2) Emulating wide-area power transmission and distribution systems, 3) Emulated SCADA control centers, 4) Advanced visualization and cyber-analytics, including machine learning. ISAAC will enable the development, testing, evaluation, and validation of holistic cyber-physical security approaches for cyber physical systems and the Smart Grid. We hope that our endeavor, ISAAC, will help further the boundaries of CPS research and education.",2019 IEEE Texas Power and Energy Conference (TPEC),2019
cb999e27911869314d7f10e58cdf7688e0af1a01,https://www.semanticscholar.org/paper/cb999e27911869314d7f10e58cdf7688e0af1a01,"On Critical Infrastructures, Their Security and Resilience - Trends and Vision","This short paper is presented in observance and promotion of November, the National Month of Critical Infrastructure Security and Resilience (CISR), established by the United States Department of Homeland Security in 2013. The CISR term focuses on essential assets (critical infrastructures) and two ultimate goals of making them secure and resilient. These assets and goals were put together in 2013 in the now well-known Presidential Policy Directive on CISR (PPD-21). This paper presents easy-to-ready material laying down the building blocks of CISR - what it means to you as a regular citizen, professional, or government worker. This paper presents concepts behind security and resilience pertinent to various types of activities - from every day to field-specific activities. This paper also presents basic elements to the field: 1. high-level introduction to the organizational units dealing with CISR in the United States; 2. explanation of basic terms and a list of further reading material; and 3. several discussion topics on the vision and future of CISR in critical infrastructure cyber-physical systems.",ArXiv,2018
043454093561e9d4880a095a4cfe83c7ea74dab2,https://www.semanticscholar.org/paper/043454093561e9d4880a095a4cfe83c7ea74dab2,Work-in-Progress: Making Machine Learning Real-Time Predictable,"Machine learning (ML) on edge computing devices is becoming popular in the industry as a means to make control systems more intelligent and autonomous. The new trend is to utilize embedded edge devices, as they boast higher computational power and larger memories than before, to perform ML tasks that had previously been limited to cloud-hosted deployments. In this work, we assess the real-time predictability and consider data privacy concerns by comparing traditional cloud services with edge-based ones for certain data analytics tasks. We identify the subset of ML problems appropriate for edge devices by investigating if they result in real-time predictable services for a set of widely used ML libraries. We specifically enhance the Caffe library to make it more suitable for real-time predictability. We then deploy ML models with high accuracy scores on an embedded system, exposing it to industry sensor data from the field, to demonstrates its efficacy and suitability for real-time processing.",2018 IEEE Real-Time Systems Symposium (RTSS),2018
8e76c41f4df07fdc512cb13f8e9b14e1692577ed,https://www.semanticscholar.org/paper/8e76c41f4df07fdc512cb13f8e9b14e1692577ed,A Survey on AI-Driven Digital Twins in Industry 4.0: Smart Manufacturing and Advanced Robotics,"Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.",Sensors,2021
8ee8d51b5c29f6aadd0b6dcff2a475373a3a021b,https://www.semanticscholar.org/paper/8ee8d51b5c29f6aadd0b6dcff2a475373a3a021b,"The Role of AI, Machine Learning, and Big Data in Digital Twinning: A Systematic Literature Review, Challenges, and Opportunities","Digital twinning is one of the top ten technology trends in the last couple of years, due to its high applicability in the industrial sector. The integration of big data analytics and artificial intelligence/machine learning (AI-ML) techniques with digital twinning, further enriches its significance and research potential with new opportunities and unique challenges. To date, a number of scientific models have been designed and implemented related to this evolving topic. However, there is no systematic review of digital twinning, particularly focusing on the role of AI-ML and big data, to guide the academia and industry towards future developments. Therefore, this article emphasizes the role of big data and AI-ML in the creation of digital twins (DTs) or DT-based systems for various industrial applications, by highlighting the current state-of-the-art deployments. We performed a systematic review on top of multidisciplinary electronic bibliographic databases, in addition to existing patents in the field. Also, we identified development-tools that can facilitate various levels of the digital twinning. Further, we designed a big data driven and AI-enriched reference architecture that leads developers to a complete DT-enabled system. Finally, we highlighted the research potential of AI-ML for digital twinning by unveiling challenges and current opportunities.",IEEE Access,2021
1899bc883c7045cdd95eb8ea428d60e9871f1968,https://www.semanticscholar.org/paper/1899bc883c7045cdd95eb8ea428d60e9871f1968,Information-Based Model Discrimination for Digital Twin Behavioral Matching,"Digital Twin allows creating virtual representations of complex physical systems. However, making the Digital Twin behavior matching with the real system is challenging due to the number of unknown parameters. Its search can be done using optimization-based techniques, producing a family of models based on different system datasets. So, a discrimination criterion is required to determine the best Digital Twin model. This paper presents an information theory-based discrimination criterion to determine the best Digital Twin model resulting from a behavioral matching process. The Information Gain of a model is employed as a discrimination criterion. Box-Jenkins models are used to define the family of models for each behavioral matching result. The proposed method is compared with other information-based metrics and the $\nu$gap metric. As a study case, the discrimination method is applied to the Digital Twin for a real-time vision feedback infrared temperature uniformity control system. Obtained results show that information-based methodologies are useful for selecting an accurate Digital Twin model representing the system among a family of plants.",2020 2nd International Conference on Industrial Artificial Intelligence (IAI),2020
a279d5704618d1036f6de8e56d7f9d88b658d8eb,https://www.semanticscholar.org/paper/a279d5704618d1036f6de8e56d7f9d88b658d8eb,"Assessing physical accessibility conditions to tourist attractions. The case of Maspalomas Costa Canaria urban area (Gran Canaria, Spain)","Abstract In this research, a methodology for the analysis of accessibility conditions for people with physical disabilities was developed. The analysis is based on an assessment of the sidewalk network in two tourist areas located in Maspalomas Costa Canaria (Gran Canaria, Spain). ArcMap's Network Analyst was used, and Spanish regulations on accessibility in urbanized public spaces, as well as the points of origin (tourist accommodation, bus stops and reserved parking lots for people with reduced mobility) and destination (access points to the beach and other tourist elements, some of them with heritage value) for typical users were considered. After application of the methodology, a set of potential routes were obtained. The results reveal deficient walkability, with breaks in the accessibility chain in both study areas. It is concluded that new measures to improve accessibility are required which can be used as a basis for the development of new tourist products to reinforce the competitiveness of the tourist destination.",,2020
b78d9aea2740e9a1c0d2cee802e98960d5522209,https://www.semanticscholar.org/paper/b78d9aea2740e9a1c0d2cee802e98960d5522209,"A Route Evaluation Method Considering the Subjective Evaluation on Walkability, Safety, and Pleasantness by Elderly Pedestrians","To improve the quality of life (QOL) of elderly people, we propose a route planning method considering the subjective evaluation on walkability, safety, and pleasantness of the users. By using this method, it is possible to plan a route with lower physical load, higher safety, and more enjoyable for each elderly user. To quantify their preferences, the acceptable time delay is used for the cost functions. In this study, we confirmed that the factors can take into consideration the mental and physical situation of the user and acquired the quantitative cost functions for these factors. The cost functions were constructed based on the subjective evaluation data. The basic validity of the method was confirmed by a subjective evaluation experiment.",Learning and Analytics in Intelligent Systems,2019
dcb5702b57b6343ce443067b2a89686173d2d417,https://www.semanticscholar.org/paper/dcb5702b57b6343ce443067b2a89686173d2d417,Multi-Path Deep CNN with Residual Inception Network for Single Image Super-Resolution,"Recent research on single-image super-resolution (SISR) using deep convolutional neural networks has made a breakthrough and achieved tremendous performance. Despite their significant progress, numerous convolutional neural networks (CNN) are limited in practical applications, owing to the requirement of the heavy computational cost of the model. This paper proposes a multi-path network for SISR, known as multi-path deep CNN with residual inception network for single image super-resolution. In detail, a residual/ResNet block with an Inception block supports the main framework of the entire network architecture. In addition, remove the batch normalization layer from the residual network (ResNet) block and max-pooling layer from the Inception block to further reduce the number of parameters to preventing the over-fitting problem during the training. Moreover, a conventional rectified linear unit (ReLU) is replaced with Leaky ReLU activation function to speed up the training process. Specifically, we propose a novel two upscale module, which adopts three paths to upscale the features by jointly using deconvolution and upsampling layers, instead of using single deconvolution layer or upsampling layer alone. The extensive experimental results on image super-resolution (SR) using five publicly available test datasets, which show that the proposed model not only attains the higher score of peak signal-to-noise ratio/structural similarity index matrix (PSNR/SSIM) but also enables faster and more efficient calculations against the existing image SR methods. For instance, we improved our method in terms of overall PSNR on the SET5 dataset with challenging upscale factor 8× as 1.88 dB over the baseline bicubic method and reduced computational cost in terms of number of parameters 62% by deeply-recursive convolutional neural network (DRCN) method.",Electronics,2021
f865d00d47ae2099c4403bc984f26bc74d792dc4,https://www.semanticscholar.org/paper/f865d00d47ae2099c4403bc984f26bc74d792dc4,Improving Decision-Making-Process for Robot Navigation Under Uncertainty,"Designing an autonomous system is a challenging task nowadays, and this is mainly due to two challenges such as conceiving a reliable system in terms of decisions accuracy (performance) and guaranteeing the robustness of the system to noisy inputs. A system is called efficient, if it is simultaneously reliable and robust. In this paper, we consider robot navigation under uncertain environments in which robot sensors may generate disturbed measures affecting the robot decisions. We aim to propose an efficient decision-making model, based on Deep Neural Network (DNN), for robot navigation. Hence, we propose an adversarial training step based on data augmentation to improve robot decisions under uncertain environment. Our contribution is based on investigating data augmentation which is based on uncertainty noise to improve the robustness and performance of the decision model. We also focus on two metrics, Efficiency and Pareto Front, combining robustness and performance to select the best data augmentation rate. In the experiment stage, our approach is validated on a public robotic data-set.",ICAART,2021
4fa8d845ddca3eabd913db1d6b8239abcb5f89f2,https://www.semanticscholar.org/paper/4fa8d845ddca3eabd913db1d6b8239abcb5f89f2,Driverless vehicle security: Challenges and future research opportunities,"Abstract As self-driving vehicles become increasingly popular, new generations of attackers will seek to exploit vulnerabilities introduced by the technologies that underpin such vehicles for a range of motivations (e.g. curiosity, criminally-motivated, financially-motivated and state-sponsored). For example, vulnerabilities in self-driving vehicles may be exploited to be used in terrorist attacks such as driving into places of mass gatherings (i.e. using driverless vehicles as weapons to cause death or serious bodily injury). This survey presents a categorized summary of security methodologies developed to secure sensing, positioning, vision, and network technologies that can be equipped in driverless-vehicles. These technologies have the potential to benefit their security from tailored machine learning models. Future research opportunities are also identified.",Future Gener. Comput. Syst.,2020
54298fec5878c53b443ec041d328042257557bc4,https://www.semanticscholar.org/paper/54298fec5878c53b443ec041d328042257557bc4,Lidar Based Intelligent Obstacle Avoidance System for Autonomous Ground Vehicles,"Autonomous ground vehicles (AGVs) started occupying our day-to-day life. AGVs can be programmed to be smart with the current technological advancements. In doing so, we can apply them to assist humans in many aspects like reducing road accidents, enabling us to use cars without driving knowledge, autonomous patrolling in dangerous zones, and autonomous farming. For AGVs to operate at this level of automation, it must be equipped with sensory perception devices to be aware of its surroundings, and also, a way to perceives this data is crucial. As a first step towards this, researchers have developed a vast number of camera vision-based efficient neural network algorithms for detecting and avoiding obstacles. Unfortunately, an AGV cannot survive only with computer vision as it suffers from several effects like night driving and erroneous estimation of distance information. Camera vision and lidar vision together is suitable for AGVs to operate in all conditions like day, night, and fog. We propose a novel neural network model, which transforms the lidar sensor data into obstacle avoidance decisions, which is integrated into the hybrid vision of any AGV. Existing lidar sensor-based obstacle detection and avoidance systems like 2D collision cone approaches are not suitable for real-time applications, as they lag in providing accurate and quick responses, which leads to collisions. The proposed intelligent Field of View (FOV) mechanism replaces classical mathematical approaches, which accurately mimics the behavior of human drivers. The model quickly takes decisions with a high level of accuracy to command the AGV upon being obstructed with obstacles in the trajectory. This makes the AGV drive in obstacle rich environments without manual maneuvering autonomously.",,2020
57bf9ee3310d20a7b226db598d7d2e0b7e8ea7d1,https://www.semanticscholar.org/paper/57bf9ee3310d20a7b226db598d7d2e0b7e8ea7d1,Exploring Strategies for Adapting Traditional Vehicle Design Frameworks to Autonomous Vehicle Design,"Exploring Strategies for Adapting Traditional Vehicle Design Frameworks to Autonomous Vehicle Design by Alex Munoz MS, American Public University, 2015 BA, American Public University, 2012 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Information Technology Walden University August 2019 Abstract Fully autonomous vehicles are expected to revolutionize transportation, reduce the cost of ownership, contribute to a cleaner environment, and prevent the majority of traffic accidents and related fatalities. Even though promising approaches for achieving full autonomy exist, developers and manufacturers have to overcome a multitude of challenged before these systems could find widespread adoption. This multiple case study explored the strategies some IT hardware and software developers of self-driving cars use to adapt traditional vehicle design frameworks to address consumer and regulatory requirements in autonomous vehicle designs. The population consisted of autonomous driving technology software and hardware developers who are currently working on fully autonomous driving technologies from or within the United States, regardless of their specialization. The theory of dynamic capabilities was the conceptual framework used for the study. Interviews from 7 autonomous vehicle hard and software engineers, together with 15 archival documents, provided the data points for the study. A thematic analysis was used to code and group results by themes. When looking at theFully autonomous vehicles are expected to revolutionize transportation, reduce the cost of ownership, contribute to a cleaner environment, and prevent the majority of traffic accidents and related fatalities. Even though promising approaches for achieving full autonomy exist, developers and manufacturers have to overcome a multitude of challenged before these systems could find widespread adoption. This multiple case study explored the strategies some IT hardware and software developers of self-driving cars use to adapt traditional vehicle design frameworks to address consumer and regulatory requirements in autonomous vehicle designs. The population consisted of autonomous driving technology software and hardware developers who are currently working on fully autonomous driving technologies from or within the United States, regardless of their specialization. The theory of dynamic capabilities was the conceptual framework used for the study. Interviews from 7 autonomous vehicle hard and software engineers, together with 15 archival documents, provided the data points for the study. A thematic analysis was used to code and group results by themes. When looking at the results through the lens of dynamic capability theory, notable themes included regulatory uncertainty, functional safety, rapid iteration, and achieving a competitive advantage. Based on the findings of the study, implications for social change include the need for better regulatory frameworks to provide certainty, consumer education to manage expectations, and universal development standards that could integrate regulatory and design needs into a single approach. Exploring Strategies for Adapting Traditional Vehicle Design Frameworks to Autonomous Vehicle Design by Alex Munoz MS, American Public University, 2015 BA, American Public University, 2012 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Information Technology Walden University October 2019 Dedication I want to dedicate this study to my loving wife, Elena, and my curious daughter, Sarah, for supporting me throughout the study process and often sacrificing time together when I had to focus on my research. Thank you both, and I am hoping that my meticulous, dedicated, and steadfast enthusiasm for learning will equally inspire them today and in the future to embark on similar journeys. Furthermore, I want to dedicate this doctoral study to all my friends who lent an ear and their eyes when I needed it most, and who continued to support my efforts, even when I was unable to share much time with them. Acknowledgments There are not enough words I can find that adequately express my gratitude for the chair of my committee, Dr. Nicholas Harkiolakis. Dr. Harkiolakis provided me with encouragement, direction, and inspiration throughout my journey as a doctoral student, while also sparking my curiosity to rethink approaches and often providing unfiltered feedback to push me when needed. Dr. Harkiolakis is a knowledgeable and relatable mentor whom I came to respect and admire, and hope to continue to be able to work with in the future. Furthermore, I would like to thank the other members of my study committee, Dr. Burchell and Dr. McKeeby, for providing their valuable feedback throughout the study approval process and steering my work in the appropriate direction.",,2020
68bd768133df2dc33880e717c04aad3180c4b621,https://www.semanticscholar.org/paper/68bd768133df2dc33880e717c04aad3180c4b621,Self Driving Car using Deep Learning Technique,"The biggest challenge of a self-driving car is autonomous lateral motion so the main aim of this paper is to clone drives for better performance of the autonomous car for which we are using multilayer neural networks and deep learning techniques. We will focus to achieve autonomous cars driving in stimulator conditions. Within the simulator, preprocessing the image obtained from the camera placed in the car imitate the driver’s vision and then the reaction, which is the steering angle of the car. The neural network trains the deep learning technique on the basis of photos taken from a camera in manual mode which provides a condition for running the car in autonomous mode, utilizing the trained multilayered neural network. The driver imitation algorithm fabricated and characterized in the paper is all about the profound learning technique that is centered around the NVIDIA CNN model. Keywords— Deep learning, neural network, Convolutional neural network, stimulator, NVIDIA model.",,2020
afd26f28e4f81532eff21323290bd411c8d7c92f,https://www.semanticscholar.org/paper/afd26f28e4f81532eff21323290bd411c8d7c92f,Self-driving Cars: An Overview of Various Autonomous Driving Systems,"A car that can navigate by itself without being dependent on human for inputs is known as a self-driving car. There has been a great advancement in automobile industry which is bringing new technologies every day. There are various types of autonomous cars and they are divided based on their level of automation, which includes level 0 to level 5. Advanced methodologies are used to build these cars, and concepts like machine learning and computer vision play a vital role in development of these cars. The accuracy varies based on lots of factors including both internal and external factors. This paper presents survey done on various technologies used in these cars with their results and also about their current trends.",,2020
3e6dfb625462897a1094656ed863c1583f476aea,https://www.semanticscholar.org/paper/3e6dfb625462897a1094656ed863c1583f476aea,Recent Advances and Trends in On-Board Embedded and Networked Automotive Systems,"Modern cars consist of a number of complex embedded and networked systems with steadily increasing requirements in terms of processing and communication resources. Novel automotive applications, such as automated driving, rise new needs and novel design challenges that cover a broad range of hardware/software engineering aspects. In this context, this paper provides an overview of the current technological challenges in on-board and networked automotive systems. This paper encompasses both the state-of-the-art design strategies and the upcoming hardware/software solutions for the next generation of automotive systems, with a special focus on embedded and networked technologies. In particular, this paper surveys current solutions and future trends on models and languages for automotive software development, on-board computational platforms, in-car network architectures and communication protocols, and novel design strategies for cybersecurity and functional safety.",IEEE Transactions on Industrial Informatics,2019
80546ea02d4b7a24a7e620336901fbf213999c85,https://www.semanticscholar.org/paper/80546ea02d4b7a24a7e620336901fbf213999c85,Accelerating DNN-based 3D point cloud processing for mobile computing,"3D point cloud data, which are produced by various 3D sensors such as LIDAR and stereo cameras, have been widely deployed by industry leaders such as Google, Uber, Tesla, and Mobileye, for mobile robotic applications such as autonomous driving and humanoid robots. Point cloud data, which are composed of reliable depth information, can provide accurate location and shape characteristics for scene understanding, such as object recognition and semantic segmentation. However, deep neural networks (DNNs), which directly consume point cloud data, are particularly computation-intensive because they have to not only perform multiplication-and-accumulation (MAC) operations but also search neighbors from the irregular 3D point cloud data. Such a task goes beyond the capabilities of general-purpose processors in realtime to figure out the solution as the scales of both point cloud data and DNNs increase from application to application. We present the first accelerator architecture that dynamically configures the hardware on-the-fly to match the computation of both neighbor point search and MAC computation for point-based DNNs. To facilitate the process of neighbor point search and reduce the computation costs, a grid-based algorithm is introduced to search neighbor points from a local region of grids. Evaluation results based on the scene recognition and segmentation tasks show that the proposed design harvests 16.4 × higher performance and saves 99.95% of energy than an NVIDIA Tesla K40 GPU baseline in point cloud scene understanding applications.",Science China Information Sciences,2019
9ca0c90074d0122d86e2f610f60c5f42e9620319,https://www.semanticscholar.org/paper/9ca0c90074d0122d86e2f610f60c5f42e9620319,Design and Implementation of Driverless Car using Machine Learning,"Asst. Prof., Dept of Electronics and Communication Engineering, ATRIA INSTITUTE OF TECHNOLOGY, Bangalore, Karnataka, India. -------------------------------------------------------------------------------***-----------------------------------------------------------------------------Abstract Autonomous driving has been a big fuss among companies because of the entanglement of the problem which has endless applications. Companies like Google, Tesla and Uber have applied algorithms to commercial cars and had some success. These algorithms varies from traditional control to machine learning. In this paper we will use one of the Machine learning techniques SVM (Support Vector Machines) with the goal of navigating the driverless car with maintaining traffic rules and avoiding accident. This technique mainly detects sign boards, classifies it and takes decision accordingly. This paper mainly includes object recognition and zone based control using different types of sensors. It also has live video streaming which is used for monitoring purposes.",,2019
f43661df98dcf1512458aa8a239ac9597cb857fd,https://www.semanticscholar.org/paper/f43661df98dcf1512458aa8a239ac9597cb857fd,Bangla License Plate Recognition Using Convolutional Neural Networks (CNN),"In the last few years, the deep learning technique in particular Convolutional Neural Networks (CNNs) is using massively in the field of computer vision and machine learning. This deep learning technique provides state-of-the-art accuracy in different classification, segmentation, and detection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100, Microsoft COCO, and ImageNet [1], [2]. However, there are a lot of research has been conducted for Bangla License plate recognition with traditional machine learning approaches in last decade. None of them are used to deploy a physical system for Bangla License Plate Recognition System (BLPRS) due to their poor recognition accuracy. In this paper, we have implemented CNNs based Bangla license plate recognition system with better accuracy that can be applied for different purposes including roadside assistance, automatic parking lot management system, vehicle license status detection and so on. Along with that, we have also created and released a very first and standard database for BLPRS.",2019 22nd International Conference on Computer and Information Technology (ICCIT),2018
0a496597b382e48e7ff5bbec791703e499f7359b,https://www.semanticscholar.org/paper/0a496597b382e48e7ff5bbec791703e499f7359b,"Security, SDN, and VANET technology of driver-less cars","Driver-less cars have become the latest technological advancement in the transportation industry. They are expected to revolutionize transportation by making it safer, more convenient, and more efficient. However, there are many technological issues with the security of driver-less cars, and the catastrophic effects these security issues can have on the public. Having proper security measures in place for driver-less cars poses an issue to their adoption into society, and is one of the largest inhibiting factors. This paper discusses the autonomous technology of driver-less cars, and the security problems with this technology. Exploring the current communication technologies of vehicular ad hoc networking, and how artificial neural networks and software defined networking can help to protect driver-less cars from malicious attacks.",2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC),2018
e0bfcf965b402f3f209f26ae20ee88bc4d0002ab,https://www.semanticscholar.org/paper/e0bfcf965b402f3f209f26ae20ee88bc4d0002ab,AI Thinking for Cloud Education Platform with Personalized Learning,"Artificial Intelligence (AI) thinking is a framework beyond procedural thinking and based on cognitive and adaptation to automatically learn deep and wide rules and semantics from experiments. This paper presents Cloud-eLab, an open and interactive cloudbased learning platform for AI Thinking, aiming to inspire i) Deep and Wide learning, ii) Cognitive and Adaptation learning concepts for education. It has been successfully used in various machine learning courses in practice, and has the expandability to support more AI modules. In this paper, we describe the block diagram of the proposed AI Thinking education platform, and provide two education application scenarios for unfolding Deep and Wide learning as well as Cognitive and Adaptation learning concepts. Cloud-eLab education platform will deliver personalized content for each student with flexibility to repeat the experiments at their own pace which allow the learner to be in control of the whole learning process.",HICSS,2018
2e2efc72ef3573c2a2ce108c5b210b6d08f52f11,https://www.semanticscholar.org/paper/2e2efc72ef3573c2a2ce108c5b210b6d08f52f11,An investigation on the use of convolutional neural network for image classification in embedded systems,"The study of Convolutional Neural Network (CNN) for image classification is basically carried out on high performance and parallel platforms, so that the results of the literature cannot be replied on embedded systems. The aim of our work is to investigate CNN architectures that can run in such limited platforms and still maintain or improve the results of the current approaches. To that end, we specify and evaluate the performance of several CNN frameworks using different network configurations and dataset pre-processing techniques. The results of our final approach show that its classification efficiency is close to the best results of the literature, however using a much lower computational power.",2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI),2017
81ab6f9e9d0934c50a69a31443eadf34e5ab58ed,https://www.semanticscholar.org/paper/81ab6f9e9d0934c50a69a31443eadf34e5ab58ed,"Optimal task replication considering reliability, performance, and energy consumption for parallel computing in cloud systems","Abstract In a cloud-based cyber–physical system, many jobs consist of multiple parallel tasks. The cloud system usually adopts active task replication to improve performance and guarantee the reliability of a job. This technology creates redundant replicas for each task and then executes the replicas concurrently. In the cloud system, each replica is a virtual machine (VM) image that can be easily assigned to different physical machines (PMs) to overcome resource heterogeneity. However, how to design a rational task replication strategy (including replica creation and VM assignment) is indeed a complex issue. It should comprehensively consider correlations and tradeoffs among reliability, performance, and energy consumption. This paper first proposes a reliability-performance correlation model for a job executed by using active task replication. We design a general method to avoid analyzing complex failure correlations and give a Bayesian approach to calculate the performability metric of the job. The paper also proposes a reliability-energy correlation model to evaluate random energy consumption of a PM hosting multiple VMs by using mixed random variables. Finally, an expected net profit optimization model and a genetic algorithm are developed to search for an optimal task replication strategy balancing tradeoffs among reliability, performance, and energy consumption. Illustrative examples are provided.",Reliab. Eng. Syst. Saf.,2021
6eb60dfe9bfaf886a124f73fe9fb1bae2232ef95,https://www.semanticscholar.org/paper/6eb60dfe9bfaf886a124f73fe9fb1bae2232ef95,Adoption of machine learning technology for failure prediction in industrial maintenance: A systematic review,"Abstract Failure prediction is the task of forecasting whether a material system of interest will fail at a specific point of time in the future. This task attains significance for strategies of industrial maintenance, such as predictive maintenance. For solving the prediction task, machine learning (ML) technology is increasingly being used, and the literature provides evidence for the effectiveness of ML-based prediction models. However, the state of recent research and the lessons learned are not well documented. Therefore, the objective of this review is to assess the adoption of ML technology for failure prediction in industrial maintenance and synthesize the reported results. We conducted a systematic search for experimental studies in peer-reviewed outlets published from 2012 to 2020. We screened a total of 1,024 articles, of which 34 met the inclusion criteria. We focused on understanding the datasets analyzed, the preprocessing to generate features, and the training and evaluation of prediction models. The results reveal (1) a broad range of systems and domains addressed, (2) the adoption of up-to-date approaches to preprocessing and training, (3) some lack of performance evaluation mitigating the overfitting problem, and (4) considerable heterogeneity in the reporting of experimental designs and results. We identify opportunities for future research and suggest ways to facilitate the comparison and integration of evidence obtained from single studies.",Journal of Manufacturing Systems,2021
982248098bd6b1be2d72369ae3d083f551eefced,https://www.semanticscholar.org/paper/982248098bd6b1be2d72369ae3d083f551eefced,"Modeling Live Video Streaming: Real-Time Classification, QoE Inference, and Field Evaluation","Social media, professional sports, and video games are driving rapid growth in live video streaming, on platforms such as Twitch and YouTube Live. Live streaming experience is very susceptible to short-time-scale network congestion since client playback buffers are often no more than a few seconds. Unfortunately, identifying such streams and measuring their QoE for network management is challenging, since content providers largely use the same delivery infrastructure for live and videoon-demand (VoD) streaming, and packet inspection techniques (including SNI/DNS query monitoring) cannot always distinguish between the two. In this paper, we design, build, and deploy ReCLive: a machine learning method for live video detection and QoE measurement based on network-level behavioral characteristics. Our contributions are four-fold: (1) We analyze about 23,000 video streams from Twitch and YouTube, and identify key features in their traffic profile that differentiate live and on-demand streaming. We release our traffic traces as open data to the public; (2) We develop an LSTM-based binary classifier model that distinguishes live from on-demand streams in real-time with over 95% accuracy across providers; (3) We develop a method that estimates QoE metrics of live streaming flows in terms of resolution and buffer stall events with overall accuracies of 93% and 90%, respectively; and (4) Finally, we prototype our solution, train it in the lab, and deploy it in a live ISP network serving more than 7,000 subscribers. Measurements from the field show that 99.8% of Twitch videos are streamed live, while this measure is only 2.3% for YouTube. Further, during peak hours as many as 15% of live video streams are played at low-definition resolution and about 7% of them experience a buffer stall. Our method provides ISPs with fine-grained visibility into live video streams, enabling them to measure and improve user experience.",ArXiv,2021
9b13e7810b046ed4b50e78a5884f94683290a7ea,https://www.semanticscholar.org/paper/9b13e7810b046ed4b50e78a5884f94683290a7ea,Software-Defined Multi-domain Tactical Networks: Foundations and Future Directions,"Software Defined Networking (SDN) has emerged as a programmable approach for provisioning and managing network resources by defining a clear separation between the control and data forwarding planes. Nowadays SDN has gained significant attention in the military domain. Its use in the battlefield communication facilitates the end-to-end interactions and assists the exploitation of edge computing resources for processing data in the proximity. However, there are still various challenges related to the security and interoperability among several heterogeneous, dynamic, intermittent, and data packet technologies like multi-bearer network (MBN) that need to be addressed to leverage the benefits of SDN in tactical environments. In this chapter, we explicitly analyse these challenges and review the current research initiatives in SDN-enabled tactical networks. We also present a taxonomy on SDN-based tactical network orchestration according to the identified challenges and map the existing works to the taxonomy aiming at determining the research gaps and suggesting future directions.",Mobile Edge Computing,2020
e29b257e143b014cb08ee3ad8a8fa1cf23738d33,https://www.semanticscholar.org/paper/e29b257e143b014cb08ee3ad8a8fa1cf23738d33,ReCLive: Real-Time Classification and QoE Inference of Live Video Streaming Services,"Social media, professional sports, and video games are driving rapid growth in live video streaming, on platforms such as Twitch and YouTube Live. Live streaming experience is very susceptible to short-time-scale network congestion since client playback buffers are often no more than a few seconds. Unfortunately, identifying such streams and measuring their QoE for network management is challenging, since content providers largely use the same delivery infrastructure for live and video-on-demand (VoD) streaming, and packet inspection techniques (including SNI/DNS query monitoring) cannot always distinguish between the two. In this paper, we design and develop ReCLive: a machine learning method for live video detection and QoE measurement based on network-level behavioral characteristics.",2021 IEEE/ACM 29th International Symposium on Quality of Service (IWQOS),2021
ece7be64a44b4b237f7e9e21b786f1bc8b64fadd,https://www.semanticscholar.org/paper/ece7be64a44b4b237f7e9e21b786f1bc8b64fadd,Towards threshold‐agnostic heavy‐hitter classification,,International Journal of Network Management,2021
903875c807e8bb0d8cbb6045081c4e5549131574,https://www.semanticscholar.org/paper/903875c807e8bb0d8cbb6045081c4e5549131574,Detecting Behavioral Change of IoT Devices Using Clustering-Based Network Traffic Modeling,"The Internet of Things (IoT) is increasingly becoming a major challenge for network administrators to manage connected devices and sensors ranging from smart lights to smoke alarms and security cameras, at scale. IoT devices use an extensive variety of firmware and provide little (or no) access for the management of their operating systems and configurations. Operators of the IoT infrastructure, therefore, need to employ traffic classification models (trained by historical data) to automatically detect their assets on the network and ensure the health of devices against cyber attacks by monitoring their network behavior. On the other hand, IoT manufacturers often automatically perform firmware upgrades from cloud servers to devices that are operational in the field. This can potentially lead to a change of device behavior which makes it difficult for network operators to maintain classification models (incorporating changes without retraining the entire model). In this article, we develop a modular device classification architecture that allows operators to automatically detect IoT devices by their network activity and dynamically accommodate legitimate changes in assets (either addition of new device profile or upgrade of existing profiles). Our contributions are threefold: 1) we identify key traffic attributes that can be obtained from flow-level network telemetry to characterize the behavior of various IoT device types. We develop an unsupervised one-class clustering method for each device to detect their normal network behavior; 2) we tune device-specific clustering models and use them to classify IoT devices from their network traffic in real time. We enhance our classification by developing methods for automatic conflict resolution and noise filtering; and 3) we evaluate the efficacy of our scheme by applying it to traffic traces (benign and attack) from ten real IoT devices and demonstrate its ability to detect behavioral changes with an overall accuracy of more than 94%.",IEEE Internet of Things Journal,2020
9f4722294a2c99f18dec9e24446c283f7edb6920,https://www.semanticscholar.org/paper/9f4722294a2c99f18dec9e24446c283f7edb6920,Managing IoT Cyber-Security Using Programmable Telemetry and Machine Learning,"Cyber-security risks for Internet of Things (IoT) devices sourced from a diversity of vendors and deployed in large numbers, are growing rapidly. Therefore, management of these devices is becoming increasingly important to network operators. Existing network monitoring technologies perform traffic analysis using specialized acceleration on network switches, or full inspection of packets in software, which can be complex, expensive, inflexible, and unscalable. In this paper, we use SDN paradigm combined with machine learning to leverage the benefits of programmable flow-based telemetry with flexible data-driven models to manage IoT devices based on their network activity. Our contributions are three-fold: (1) We analyze traffic traces of 17 real consumer IoT devices collected in our lab over a six-month period and identify a set of traffic flows (per-device) whose time-series attributes computed at multiple timescales (from a minute to an hour) characterize the network behavior of various IoT device types, and their operating states (i.e., booting, actively interacted with user, or being idle); (2) We develop a multi-stage architecture of inference models that use flow-level attributes to automatically distinguish IoT devices from non-IoTs, classify individual types of IoT devices, and identify their states during normal operations. We train our models and validate their efficacy using real traffic traces; and (3) We quantify the trade-off between performance and cost of our solution, and demonstrate how our monitoring scheme can be used in operation for detecting behavioral changes (firmware upgrade or cyber attacks).",IEEE Transactions on Network and Service Management,2020
d28f3595f430a79c73fd524398ac7fe712c447ac,https://www.semanticscholar.org/paper/d28f3595f430a79c73fd524398ac7fe712c447ac,IoT Behavioral Monitoring via Network Traffic Analysis,"Smart homes, enterprises, and cities are increasingly being equipped with a plethora of Internet of Things (IoT), ranging from smart-lights to security cameras. While IoT networks have the potential to benefit our lives, they create privacy and security challenges not seen with traditional IT networks. Due to the lack of visibility, operators of such smart environments are not often aware of their IoT assets, let alone whether each IoT device is functioning properly safe from cyber-attacks. This thesis is the culmination of our efforts to develop techniques to profile the network behavioral pattern of IoTs, automate IoT classification, deduce their operating context, and detect anomalous behavior indicative of cyber-attacks. We begin this thesis by surveying IoT ecosystem, while reviewing current approaches to vulnerability assessments, intrusion detection, and behavioral monitoring. For our first contribution, we collect traffic traces and characterize the network behavior of IoT devices via attributes from traffic patterns. We develop a robust machine learning-based inference engine trained with these attributes and demonstrate real-time classification of 28 IoT devices with over 99% accuracy. Our second contribution enhances the classification by reducing the cost of attribute extraction while also identifying IoT device states. Prototype implementation and evaluation demonstrate the ability of our supervised machine learning method to detect behavioral changes for five IoT devices. Our third and final contribution develops a modularized unsupervised inference engine that dynamically accommodates the addition of new IoT devices and/or updates to existing ones, without requiring system-wide retraining of the model. We demonstrate via experiments that our model can automatically detect attacks and firmware changes in ten IoT devices with over 94% accuracy.",ArXiv,2020
2633dc5f91059fc0ec8328054e7dbf50a5caa823,https://www.semanticscholar.org/paper/2633dc5f91059fc0ec8328054e7dbf50a5caa823,Reinforcement Learning for Robot Navigation with Adaptive ExecutionDuration (AED) in a Semi-Markov Model,"Deep reinforcement learning (DRL) algorithms have proven effective in robot navigation, especially in unknown environments, through directly mapping perception inputs into robot control commands. Most existing methods adopt uniform execution duration with robots taking commands at fixed intervals. As such, the length of execution duration becomes a crucial parameter to the navigation algorithm. In particular, if the duration is too short, then the navigation policy would be executed at a high frequency, with increased training difficulty and high computational cost. Meanwhile, if the duration is too long, then the policy becomes unable to handle complex situations, like those with crowded obstacles. It is thus tricky to find the “sweet” duration range; some duration values may render a DRL model to fail to find a navigation path. In this paper, we propose to employ adaptive execution duration to overcome this problem. Specifically, we formulate the navigation task as a Semi-Markov Decision Process (SMDP) problem to handle adaptive execution duration. We also improve the distributed proximal policy optimization (DPPO) algorithm and provide its theoretical guarantee for the specified SMDP problem. We evaluate our approach both in the simulator and on an actual robot. The results show that our approach outperforms the other DRL-based method (with fixed execution duration) by 10.3% in terms of the navigation success rate.",ArXiv,2021
49cf9e8d9496de64b24c168b8b7390a83fc41861,https://www.semanticscholar.org/paper/49cf9e8d9496de64b24c168b8b7390a83fc41861,SA-MATD3: Self-attention-based multi-agent continuous control method in cooperative environments,"Cooperative problems under continuous control have always been the focus of multi-agent reinforcement learning. Existing algorithms suffer from the problem of uneven learning degree with the increase of the number of agents. In this paper, a new structure for a multi-agent actor critic is proposed, and the self-attention mechanism is applied in the critic network and the value decomposition method used to solve the uneven problem. The proposed algorithm makes full use of the samples in the replay memory buffer to learn the behavior of a class of agents. First, a new update method is proposed for policy networks that promotes learning efficiency. Second, the utilization of samples is improved, at the same time reflecting the ability of perspectivetaking among groups. Finally, the ""deceptive signal"" in training is eliminated and the learning degree among agents is more uniform than in the existing methods. Multiple experiments were conducted in two typical scenarios of a multi-agent particle environment. Experimental results show that the proposed algorithm can perform better than the state-of-the-art ones, and that it exhibits higher learning efficiency with an increasing number of agents.",Information Sciences,2021
8bf002ba41c1aec025a72584095c0cf840fdcb3a,https://www.semanticscholar.org/paper/8bf002ba41c1aec025a72584095c0cf840fdcb3a,Crowd-Aware Robot Navigation for Pedestrians with Multiple Collision Avoidance Strategies via Map-based Deep Reinforcement Learning,"It is challenging for a mobile robot to navigate through human crowds. Existing approaches usually assume that pedestrians follow a predefined collision avoidance strategy, like social force model (SFM) or optimal reciprocal collision avoidance (ORCA). However, their performances commonly need to be further improved for practical applications, where pedestrians follow multiple different collision avoidance strategies. In this paper, we propose a map-based deep reinforcement learning approach for crowd-aware robot navigation with various pedestrians. We use the sensor map to represent the environmental information around the robot, including its shape and observable appearances of obstacles. We also introduce the pedestrian map that specifies the movements of pedestrians around the robot. By applying both maps as inputs of the neural network, we show that a navigation policy can be trained to better interact with pedestrians following different collision avoidance strategies. We evaluate our approach under multiple scenarios both in the simulator and on an actual robot. The results show that our approach allows the robot to successfully interact with various pedestrians and outperforms compared methods in terms of the success rate.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
c12dff5ce0c189dab6307781ac2133625aff85d6,https://www.semanticscholar.org/paper/c12dff5ce0c189dab6307781ac2133625aff85d6,Visuomotor Reinforcement Learning for Multirobot Cooperative Navigation,"This article investigates the multirobot cooperative navigation problem based on raw visual observations. A fully end-to-end learning framework is presented, which leverages graph neural networks to learn local motion coordination and utilizes deep reinforcement learning to generate visuomotor policy that enables each robot to move to its goal without the need of environment map and global positioning information. Experimental results show that, with a few tens of robots, our approach achieves comparable performance with the state-ofthe-art imitation learning-based approaches with bird-view state inputs. We also illustrate our generalizability to crowded and large environments and our scalability to ten times number of the training robots. In addition, we demonstrate that our model trained for multirobot case can also improve the success rate in the single-robot navigation task in unseen environments. Note to Practitioners—With the development of intelligent industrial and logistic systems, robotic transportation systems are widely implemented. However, existing multirobot path coordination and navigation approaches are basically under some unreasonable assumptions, which are very hard to be implemented in practical scenarios. This article aims to greatly promote the real application of learning-based multirobot cooperative navigation approach, in order to achieve the following. First, we introduce an end-to-end reinforcement learning framework instead of the Manuscript received June 25, 2021; accepted August 24, 2021. This article was recommended for publication by Associate Editor T. Xu and Editor D. O. Popa upon evaluation of the reviewers’ comments. This work was supported in part by the Natural Science Foundation of China under Grant 62073222 and Grant U1913204, in part by Shanghai Municipal Education Commission and Shanghai Education Development Foundation through “Shu Guang” Project under Grant 19SG08, in part by Shenzhen Science and Technology Program under Grant JSGG20201103094400002, and in part by the Science and Technology Commission of Shanghai Municipality under Grant 21511101900. (Zhe Liu and Qiming Liu contributed equally to this work.) (Corresponding author: Hesheng Wang.) Zhe Liu is with the Department of Computer Science and Technology, University of Cambridge, Cambridge CB2 1TN, U.K. (e-mail: zl457@cam.ac.uk). Qiming Liu, Ling Tang, and Hongye Wang are with the Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: qimingliu@sjtu.edu.cn; elftat@sjtu.edu.cn; wanghongye@sjtu.edu.cn). Kefan Jin is with the MOE Key Laboratory of Marine Intelligent Equipment and System and the State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: jinkefan@sjtu.edu.cn). Ming Liu is with the Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong (e-mail: eelium@ust.hk). Hesheng Wang is with the Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: wanghesheng@sjtu.edu.cn). Color versions of one or more figures in this article are available at https://doi.org/10.1109/TASE.2021.3114327. Digital Object Identifier 10.1109/TASE.2021.3114327 commonly used imitation learning strategy, as the latter one needs exhaustive training data to cover all the scenarios and does not have the required generalizability. Second, we directly use the raw sensor data instead of the commonly used birdeye-view semantic observations, as the latter one is generally not representative of practical application scenario from the robot perspective and cannot solve the occlusion issue. Third, we interpret our learned model to illustrate which parts of the input and shared observations contribute most to the robots’ final actions. The above interpretability ensures predictability (thus safety) of our visuomotor policy in practical applications. Our learned visuomotor policy has the ability to coordinate dozens of robots by only using raw visual observations in unknown environments without map nor global localization information, this is the first time in the literature. Our future work includes solving the sim-to-real issue and conducting physical experiments.",IEEE Transactions on Automation Science and Engineering,2021
dbd4458812d4a4cfe8dbe248638fa7de7a1b4eae,https://www.semanticscholar.org/paper/dbd4458812d4a4cfe8dbe248638fa7de7a1b4eae,Non-Communication Decentralized Multi-Robot Collision Avoidance in Grid Map Workspace with Double Deep Q-Network,"This paper presents a novel decentralized multi-robot collision avoidance method with deep reinforcement learning, which is not only suitable for the large-scale grid map workspace multi-robot system, but also directly processes Lidar signals instead of communicating between the robots. According to the particularity of the workspace, we handcrafted a reward function, which considers both the collision avoidance among the robots and as little as possible change of direction of the robots during driving. Using Double Deep Q-Network (DDQN), the policy was trained in the simulation grid map workspace. By designing experiments, we demonstrated that the learned policy can guide the robot well to effectively travel from the initial position to the goal position in the grid map workspace and to avoid collisions with others while driving.",Sensors,2021
efe11c345c18a32be6868b54a1a773452b68a951,https://www.semanticscholar.org/paper/efe11c345c18a32be6868b54a1a773452b68a951,Robot Navigation in Crowd Based on Dual Social Attention Deep Reinforcement Learning,"Finding a feasible, collision-free path in line with social activities is an important and challenging task for robots working in dense crowds. In recent years, many studies have used deep reinforcement learning techniques to solve this problem. In particular, it is necessary to find an efficient path in a short time which often requires predicting the interaction with neighboring agents. However, as the crowd grows and the scene becomes more and more complex, researchers usually simplify the problem to a one-way human-robot interaction problem. But, in fact, we have to consider not only the interaction between humans and robots but also the influence of human-human interactions on the movement trajectory of the robot. Therefore, this article proposes a method based on deep reinforcement learning to enable the robot to avoid obstacles in the crowd and navigate smoothly from the starting point to the target point. We use a dual social attention mechanism to jointly model human-robot and human-human interaction. All sorts of experiments demonstrate that our model can make robots navigate in dense crowds more efficiently compared with other algorithms.",Mathematical Problems in Engineering,2021
fab4b767e3ae70e8e04e991e8d626fe6b3184213,https://www.semanticscholar.org/paper/fab4b767e3ae70e8e04e991e8d626fe6b3184213,Learning Navigation Policies for Mobile Robots in Deep Reinforcement Learning with Random Network Distillation,"Learning navigation policies considers the task of training a model that can find collision-free paths for mobile robots, where various Deep Reinforcement Learning (DRL) methods have been applied with promising results. However, the natural reward function for the task is usually sparse, i.e., obtaining a penalty for the collision and a positive reward for arriving the target position, which makes it difficult to learn. In particular, for some complex navigation environments, it is hard to search a collision-free path by the random exploration, which leads to a rather slow learning speed and solutions with poor performance. In this paper, we propose a DRL based approach to train an end-to-end navigation planner, i.e, the policy neural network, that directly translates the local grid map and the relative goal of the robot into its moving actions. To handle the sparse reward problem, we augment the normal extrinsic reward from the environment with intrinsic reward signals measured by random network distillation (RND). In specific, the intrinsic reward is calculated by two different networks from RND, which encourages the agent to explore a state that has not been seen before. The experimental results show that by augmenting the reward function with intrinsic reward signals by RND, solutions with better performance can be learned more efficiently and more stably in our approach. We also deploy the trained model to a real robot, which can perform collision avoidance in navigation tasks without any parameter tuning. A video of our experiments can be found at https://youtu.be/b1GJrWfO8pw.",ICIAI,2021
b5e7f624faf8270148a798ccb59c0b7f1cd6363d,https://www.semanticscholar.org/paper/b5e7f624faf8270148a798ccb59c0b7f1cd6363d,Service planning oriented efficient object search: A knowledge-based framework for home service robot,,Expert Syst. Appl.,2022
1c9c12a5c9f3cfd9cd1eefbe818bfb92d37520ac,https://www.semanticscholar.org/paper/1c9c12a5c9f3cfd9cd1eefbe818bfb92d37520ac,"Cloud-based mission control of USV fleet: Architecture, implementation and experiments","Abstract In this paper, a cloud-based mission control architecture is proposed to achieve flexible remote access and coordinated mission control among a fleet of unmanned surface vehicles (USVs). First, a cloud-based mission control architecture that renders easy, timely and prioritized remote access to the USVs regardless of the remote operator’s location is proposed. It is achieved by leveraging remote cloud-based technology and local Operating onboard System. Decentralized property of the architecture accomplishes scalable monitoring, remote control, data acquisition and missions sharing for an USV fleet. Second, the related software interfaces are required for this task: the user interface of the remote client that is used for mission control/planning and data visualization and that is applicable across mobile robotic systems; and the back-end interface for the local USVs that bridges robotic and cloud server and provides seamless integration with the well-established Robot Operating System (ROS). ROS is nowadays, the most widely used framework for robotics developments. Furthermore, the proposed cloud-based mission control architecture is implemented on a fleet of real vehicles, H2Omni-X USVs, and the performance of the remote experimentation is demonstrated during sea trials at the Adriatic coast, Croatia, representing the practical contribution of this paper.",,2021
20e98555758331fb21f7b1e307921514606cf238,https://www.semanticscholar.org/paper/20e98555758331fb21f7b1e307921514606cf238,Techniques of Robotics for Automation Using AI and the IoT,,,2021
2491e22e57c42cb127014d7cda83435e988a3189,https://www.semanticscholar.org/paper/2491e22e57c42cb127014d7cda83435e988a3189,RoSmEEry: Robotic Simulated Environment for Evaluation and Benchmarking of Semantic Mapping Algorithms,"Human-robot interaction requires a common understanding of the operational environment, which can be provided by a representation that blends geometric and symbolic knowledge: a semantic map. Through a semantic map the robot can interpret user commands by grounding them to its sensory observations. Semantic mapping is the process that builds such a representation. Despite being fundamental to enable cognition and high-level reasoning in robotics, semantic mapping is a challenging task due to generalization to different scenarios and sensory data types. In fact, it is difficult to obtain a rich and accurate semantic map of the environment and of the objects therein. Moreover, to date, there are no frameworks that allow for a comparison of the performance in building semantic maps for a given environment. To tackle these issues we design RoSmEEry, a novel framework based on the Gazebo simulator, where we introduce an accessible and ready-to-use methodology for a systematic evaluation of semantic mapping algorithms. We release our framework, as an open-source package, with multiple simulation environments with the aim to provide a general set-up to quantitatively measure the performances in acquiring semantic knowledge about the environment.",ArXiv,2021
32c67f34f4fd3767e380aa6cd5a1dfc26b8461f3,https://www.semanticscholar.org/paper/32c67f34f4fd3767e380aa6cd5a1dfc26b8461f3,An algorithm for modeling an environment and creating a semantic model of its topology,"Abstract This paper discusses the problem of a semantic topology map generation during the environment mapping process. A method is proposed which provides a model of a mobile robot’s working space. The proposed world representation is divided into two maps: semantic topology map and metric map. The first one is created by employing graph structure which describes relations between different zones generated during exploration of the environment, and the metric one which defines zones by expandable polygonal chain of border points. The acquired hierarchical world model can be used in the path planning and decision tasks in a human-friendly way by the means of semantic sentences. Such approach increases versatility of human-robot cooperation. The proposed algorithm has been validated in an experiment and the obtained results which shows a good performance of the devised method are presented.",KES,2021
33a87f57b347fa99786c135e269a8c9dd0857078,https://www.semanticscholar.org/paper/33a87f57b347fa99786c135e269a8c9dd0857078,A Survey on Evolution of Cognitive Robotics with Internet of Things,"The Internet of Things (IoT) is shifting across various fields, specifically the Autonomous Internet of Mobile Things (IoMT), Autonomous Internet of Things (A-iOT), Autonomous System of Things (ASoAT), Internet (ASoT), and the Autonomous System of Things (ASoT) as well as to reflect/embr /Use the Internet of IoT in Internet of Mobile Things (IoMT), Autonomous Internet of Things (A-IoT), Autonomous (A-iTC) as well as in Internet of Mobile Things (IoMT) and Autonomous system (AS), melding context-based network technology and complex objects with smooth plat-forms and app incorporation, as critical IoT advancements, presenting new network creation and expansion threats, and implementation problems, and general sensor/ limitations, and sensors and actuators, are several of the new development and operational issues that also pose a new challenges, it requires to handle The expansion of interregional rivalry represents fresh interregional problems. Because parallel processing and concurrency in the Internet of Things need different approaches to accommodate intelligent “components,”, we are currently have to devise new ways to integrate collaborative robots (COBOTS) “cognitive devices” and/on-service environments will rapidly add additional services, sustain, and change, and becoming part of IoT networks. For both of these reasons, resource aspects, self-healing, self-repairing, and context-based/service compositions of cognitive resources are crucial for application development and network incorporation. to include: This chapter is written to provide a concise summary of the IoRT philosophy, technology, and possible problems as well as their various advances and implementations so that the reader can get a sense of their potential outcomes.",,2021
36bb7c2bdb08680d93f225f1959a396ac5cb205f,https://www.semanticscholar.org/paper/36bb7c2bdb08680d93f225f1959a396ac5cb205f,Survey on Cloud Robotics Architecture and Model-Driven Reference Architecture for Decentralized Multicloud Heterogeneous-Robotics Platform,"Robotics engineering is gradually becoming an essential part of our daily life. However, it has been generating Big Data and seeking large computation cost because of the diversified sensors and processing requirements involved in heterogeneous robotics and their workflows. Therefore, cloud computing has become the incumbent platform for robotics. There are numerous works related to the architecture for cloud robotics. However, most cloud robotics architectures are ad hoc and are not based on a model. Inherent drawbacks of ad hoc approaches include being strictly domain specific and minimally customizable and adaptable. Moreover, heterogeneous cloud robotics platforms have been operating diverse requirements of industries and households. Nevertheless, there are certain benchmarks set to be achieved by Industry 4.0 and norms by Society 5.0. Those benchmarks and norms lead to new products and services in cross industries and alleviate the impending drawbacks. However, those should be achieved while retaining both the sovereignty and security of the respective systems and industries. This is equally applicable and an enormous challenge to the system-of-systems involving the cloud robotics domain. Therefore, we surveyed cloud robotics architectures. Then, we learned a top-down design approach involving a unified architectural framework as the cognitive approach for the highly variable and systematically complex challenges to be achieved in the next-generation cloud robotics domain. Reference architecture is a well-known approach for instantiating top-down unified architectural framework processes. Therefore, we proposed an architectural design process and modeling for the reference architecture for next-generation cloud robotics platforms.",IEEE Access,2021
37e6e2c5c012b4bf79c7feec7a5bcc39d02c8b7f,https://www.semanticscholar.org/paper/37e6e2c5c012b4bf79c7feec7a5bcc39d02c8b7f,Automatic Creation of a Domain Specific Thesaurus Using Siamese Networks,"Recent trends have increasingly indicated a shift in search technologies across all applications from syntactic and lexical matching approaches to semantic methods, aiming to understand the intent and contextual meaning of search queries, in order to yield more relevant and accurate results. Such methods often rely on semantic ontologies to map query words to concepts and aid in expansion. However, most applications require a domain specific language definition in order to overcome issues of ambiguity and misinterpretation of meaning. General purpose ontologies are often lacking in this purpose and fail to yield appropriate results in specific applications. In this paper, we propose a novel method of building a domain specific thesaurus for aiding semantic search through automatically creating a refined general thesaurus, followed by training a Siamese Network in two phases to classify candidate synonyms as relevant or non-relevant to the particular domain. We focus on the application of tag-based gallery image retrieval and extract and utilise information from Google's Conceptual Captions dataset in order to improve our model's performance. In order to investigate and justify our training method and architecture, we conduct an ablation study and compare results with our model. We further analytically and empirically demonstrate the advantage of representing terms in a domain-specific environment through semantic vectors fine-tuned on corpora related to the domain. Although our experiments are focused on building a word ontology specific to image retrieval, our method is generic and can be generalised to any field requiring a domain specific semantic language.",2021 IEEE 15th International Conference on Semantic Computing (ICSC),2021
6a46d49aee13b70c7898e2970ee756d613503e71,https://www.semanticscholar.org/paper/6a46d49aee13b70c7898e2970ee756d613503e71,"The Internet of Cooperative Agents Architecture (X-IoCA) for Robots, Hybrid Sensor Networks, and MEC Centers in Complex Environments: A Search and Rescue Case Study","Cloud robotics and advanced communications can foster a step-change in cooperative robots and hybrid wireless sensor networks (H-WSN) for demanding environments (e.g., disaster response, mining, demolition, and nuclear sites) by enabling the timely sharing of data and computational resources between robot and human teams. However, the operational complexity of such multi-agent systems requires defining effective architectures, coping with implementation details, and testing in realistic deployments. This article proposes X-IoCA, an Internet of robotic things (IoRT) and communication architecture consisting of a hybrid and heterogeneous network of wireless transceivers (H2WTN), based on LoRa and BLE technologies, and a robot operating system (ROS) network. The IoRT is connected to a feedback information system (FIS) distributed among multi-access edge computing (MEC) centers. Furthermore, we present SAR-IoCA, an implementation of the architecture for search and rescue (SAR) integrated into a 5G network. The FIS for this application consists of an SAR-FIS (including a path planner for UGVs considering risks detected by a LoRa H-WSN) and an ROS-FIS (for real-time monitoring and processing of information published throughout the ROS network). Moreover, we discuss lessons learned from using SAR-IoCA in a realistic exercise where three UGVs, a UAV, and responders collaborated to rescue victims from a tunnel accessible through rough terrain.",Sensors,2021
900bb4bc35157a26df1b0976e1ddf45aa3657676,https://www.semanticscholar.org/paper/900bb4bc35157a26df1b0976e1ddf45aa3657676,Towards Practical Cloud Offloading for Low-cost Ground Vehicle Workloads,"Low-cost Ground Vehicles (LGVs) have been widely adopted to conduct various tasks in our daily life. However, the limited on-board battery capacity and computation resources prevent LGVs from taking more complex and intelligent workloads. A promising approach is to offload the computation from local LGVs to remote servers. However, current cloud-robotic research and platforms are still at a very early stage. Compared to other systems and devices, optimizing LGV workload offloading faces more challenges, such as the uncertainty of environments and the mobility feature of devices.In this paper, we explore the opportunities of optimizing cloud offloading of LGV workloads from the perspectives of performance, energy efficiency and network robustness. We first build an analytical model to reveal the computation role and impact of each function in LGV workloads. Then we propose several optimization strategies (fine-grained migration, cloud acceleration, real-time monitoring and adjustment) to accelerate workload computation, reduce on-board energy consumption, and increase the network robustness. We implement an end-to-end cloud-robotic framework with such strategies to achieve dynamic and adaptive offloading. Evaluations on physical LGVs show that our strategies can significantly reduce the total energy consumption by 2.12× and mission completion time by 2.53×, and maintain strong robust ness under poor network quality.",2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2021
90b7618ce56e3f97454c05f0a610e48662d4be7f,https://www.semanticscholar.org/paper/90b7618ce56e3f97454c05f0a610e48662d4be7f,Towards a General and Complete Social Assistive Robotic Architecture,,IHIET,2021
91da1dca9bf56ab1599ee5681091e0bf42bb2bcb,https://www.semanticscholar.org/paper/91da1dca9bf56ab1599ee5681091e0bf42bb2bcb,"ViMantic, a distributed robotic architecture for semantic mapping in indoor environments",,Knowl. Based Syst.,2021
a6fa43ed3de751e155bf8ff979d43c89821e3fa7,https://www.semanticscholar.org/paper/a6fa43ed3de751e155bf8ff979d43c89821e3fa7,Edge Computing Assisted Autonomous Flight for UAV: Synergies between Vision and Communications,"Autonomous flight for UAVs relies on visual information for avoiding obstacles and ensuring safe collision-free flight. In addition to visual clues, safe UAVs often need connectivity with the ground station. In this article, we study the synergies between vision and communications for edge-computing-enabled UAV flight. By proposing a framework of edge computing assisted autonomous flight (ECAAF), we illustrate that vision and communications can interact with and assist each other with the aid of edge computing and offloading, and further speed up UAV mission completion. ECAAF consists of three functionalities that are discussed in detail: edge computing for 3D map acquisition, radio map construction from the 3D map, and online trajectory planning. During ECAAF, the interactions of communication capacity, video offloading, 3D map quality, and channel state of the trajectory form a positive feedback loop. Simulation results verify that the proposed method can improve mission performance by enhancing connectivity. Finally, we conclude with some future research directions.",IEEE Communications Magazine,2020
ec546f3cf74d0e526277265c4a84fed45c7e252c,https://www.semanticscholar.org/paper/ec546f3cf74d0e526277265c4a84fed45c7e252c,Distributed Data Storage and Fusion for Collective Perception in Resource-Limited Mobile Robot Swarms,"In this letter, we propose an approach to the distributed storage and fusion of data for collective perception in resource-limited robot swarms. We demonstrate our approach in a distributed semantic classification scenario. We consider a team of mobile robots, in which each robot runs a pre-trained classifier of known accuracy to annotate objects in the environment. We provide two main contributions: (i) a decentralized, shared data structure for efficient storage and retrieval of the semantic annotations, specifically designed for low-resource mobile robots; and (ii) a voting-based, decentralized algorithm to reduce the variance of the calculated annotations in presence of imperfect classification. We discuss theory and implementation of both contributions, and perform an extensive set of realistic simulated experiments to evaluate the performance of our approach.",IEEE Robotics and Automation Letters,2020
214102cca56c5c19c8de7110cc63a8e300b93ab1,https://www.semanticscholar.org/paper/214102cca56c5c19c8de7110cc63a8e300b93ab1,Cross-Layer Design for Secure and Resilient Cyber-Physical Systems: A Decision and Game Theoretic Approach,,Advances in Information Security,2020
2c32fc014c98305f2fcc701357d7c7cddec61978,https://www.semanticscholar.org/paper/2c32fc014c98305f2fcc701357d7c7cddec61978,Voice Control of Fetch Robot Using Amazon Alexa,"With the rapid development of computers and technology, virtual assistants (VA) are becoming more and more common and intelligent. However, virtual assistants, such as Apple’s Siri, Amazon’s Alexa, and Google Assistant, do not currently have any physical functions. As an important part of the internet of things (IoT), the field of robotics has become a new trend in the usage of VA. In this project, a mobile robot, Fetch, is connected with the Amazon Echo Dot through the Amazon web service (AWS) and a local robot operation system (ROS) bridge server. We demonstrated that the robot could be controlled by voice commands through an Amazon Alexa. Given certain commands, Fetch was able to move in a desired direction as well as track and follow a target object. The follow model was also learned by Neural Network training, which allows for the target position to be predicted in future maps. Voice Control of Fetch Robot Using Amazon Alexa",,2020
2fef1cb98dcdc211515d47a7ab70974927f5681d,https://www.semanticscholar.org/paper/2fef1cb98dcdc211515d47a7ab70974927f5681d,Autonomous Navigation Framework for Intelligent Robots Based on a Semantic Environment Modeling,"Humans have an innate ability of environment modeling, perception, and planning while simultaneously performing tasks. However, it is still a challenging problem in the study of robotic cognition. We address this issue by proposing a neuro-inspired cognitive navigation framework, which is composed of three major components: semantic modeling framework (SMF), semantic information processing (SIP) module, and semantic autonomous navigation (SAN) module to enable the robot to perform cognitive tasks. The SMF creates an environment database using Triplet Ontological Semantic Model (TOSM) and builds semantic models of the environment. The environment maps from these semantic models are generated in an on-demand database and downloaded in SIP and SAN modules when required to by the robot. The SIP module contains active environment perception components for recognition and localization. It also feeds relevant perception information to behavior planner for safely performing the task. The SAN module uses a behavior planner that is connected with a knowledge base and behavior database for querying during action planning and execution. The main contributions of our work are the development of the TOSM, integration of SMF, SIP, and SAN modules in one single framework, and interaction between these components based on the findings of cognitive science. We deploy our cognitive navigation framework on a mobile robot platform, considering implicit and explicit constraints for autonomous robot navigation in a real-world environment. The robotic experiments demonstrate the validity of our proposed framework.",,2020
5941b2e9655e5c4447dcdc393e1785f9555a5500,https://www.semanticscholar.org/paper/5941b2e9655e5c4447dcdc393e1785f9555a5500,A Survey of Ontologies for Simultaneous Localization and Mapping in Mobile Robots,"Autonomous robots are playing important roles in academic, technological, and scientific activities. Thus, their behavior is getting more complex, particularly, in tasks related to mapping an environment and localizing themselves. These tasks comprise the Simultaneous Localization and Mapping (SLAM) problem. Representation of knowledge related to the SLAM problem with a standard, flexible, and well-defined model, provides the base to develop efficient and interoperable solutions. As many existing works demonstrate, Semantic Web seems to be a clear approach, since they have formulated ontologies, as the base data model to represent such knowledge. In this article, we survey the most popular and recent SLAM ontologies with our aim being threefold: (i) propose a classification of SLAM ontologies according to the main knowledge needed to model the SLAM problem; (ii) identify existing ontologies for classifying, comparing, and contrasting them, in order to conceptualize SLAM domain for mobile robots; and (iii) pin-down lessons to learn from existing solutions in order to design better solutions and identify new research directions and further improvements. We compare the identified SLAM ontologies according to the proposed classification and, finally, we explore new data fields to enrich existing ontologies and highlight new possibilities in terms of performance and efficiency for SLAM solutions.",ACM Comput. Surv.,2020
5f9d5df4888eddd7645c267c0366677a218af138,https://www.semanticscholar.org/paper/5f9d5df4888eddd7645c267c0366677a218af138,A Survey of Ontologies for Simultaneous Localization and Mapping in Mobile Robots,"Autonomous robots are playing important roles in academic, technological, and scientific activities. Thus, their behavior is getting more complex, particularly, in tasks related to mapping an envir...",,2020
73c8ac96ca993eb875b201e30eb715f0265bb393,https://www.semanticscholar.org/paper/73c8ac96ca993eb875b201e30eb715f0265bb393,A Methodological Approach to Compare Ontologies: Proposal and Application for SLAM Ontologies,"Representation of the knowledge related to any domain with flexible and well-defined models, such as ontologies, provides the base to develop efficient and interoperable solutions. Hence, a proliferation of ontologies in many domains is unleashed. It is necessary to define how to compare such ontologies to decide which one is the most suitable for specific needs of users/developers. Since the emerging developing of ontologies, several studies have proposed criteria to evaluate them. Nevertheless, there is still a lack of practical and reproducible guidelines to drive a comparative evaluation of ontologies as a systematic process. In this paper, we propose a methodological process to qualitatively and quantitatively compare ontologies at Lexical, Structural, and Domain Knowledge levels, considering Correctness and Quality perspectives. Since the evaluation methods of our proposal are based in a golden-standard, it can be customized to compare ontologies in any domain. To show the suitability of our proposal, we apply our methodological approach to conduct a comparative study of ontologies in the robotic domain, in particularly for the Simultaneous Localization and Mapping (SLAM) problem. With this study case, we demonstrate that with this methodological comparative process, we are able to identify the strengths and weaknesses of ontologies, as well as the gaps still needed to fill in the target domain (SLAM for our study case).",iiWAS,2020
8097c655f6354f90b802e1266c96c6814f67a856,https://www.semanticscholar.org/paper/8097c655f6354f90b802e1266c96c6814f67a856,Cloud-based remote control framework for unmanned surface vehicles,"Abstract This paper proposes a cloud-based mission control framework for a fleet of unmanned vehicles. The framework enables easy remote access to fleet operations regardless of operator location. By leveraging cloud-based technologies the framework accomplishes scalable monitoring, remote control, data acquisition and sharing. While the front-end is applicable across mobile robotic systems, the back-end presented in this paper provides integration with the Robot Operating System (ROS); thus, enabling integration of various marine robotic agents based on the same robot framework. The proposed framework operation is demonstrated on the H2OmniX unmanned surface vehicles during trials in Biograd na Moru, Croatia.",,2020
89d77ac00b7f44ed1b90e9644e2483f6d2bb6f6d,https://www.semanticscholar.org/paper/89d77ac00b7f44ed1b90e9644e2483f6d2bb6f6d,Engineering Challenges Ahead for Robot Teamwork in Dynamic Environments,,,2020
8c60a0a3646ed78f3f1691734f9252d0ccb1e0e8,https://www.semanticscholar.org/paper/8c60a0a3646ed78f3f1691734f9252d0ccb1e0e8,Role and task allocation framework for Multirobot collaboration with latent knowledge estimation,"Correspondence Mohammad Salah Uddin East West University Computer Science & Engineering Department, Dhaka, Bangladesh Email: uddin@ewubd.edu Summary In this work a novel framework for modeling role and task allocation in Cooperative Heterogeneous Multi-Robot Systems (CHMRSs) is presented. This framework encodes a CHMRS as a set of multi-dimensional relational structures (MDRSs). This set of structure defines collaborative tasks through both temporal and spatial relations between processes of heterogeneous robots. These relations are enriched with tensors which allow for geometrical reasoning about collaborative tasks. A learning schema is also proposed in order to derive the components of each MDRS. According to this schema, the components are learnt from data reporting the situated history of the processes executed by the team of robots. Data are organized as a MultiRobot Collaboration Treebank (MRCT) in order to support learning. Moreover, a generative approach, based on a probabilistic model, is combined together with NonNegative Tensor Decomposition (NTD) for both building the tensors and estimating latent knowledge. Preliminary evaluation of the performance of this framework is performed in simulation with three heterogeneous robots, namely, two Unmanned Ground Vehicles (UGVs) and one Unmanned Aerial Vehicle (UAV).",,2020
99d7fb8df34dbf71d4ba3c67b5227c4df9b367d2,https://www.semanticscholar.org/paper/99d7fb8df34dbf71d4ba3c67b5227c4df9b367d2,"Survey on Cloud Based Robotics Architecture, Challenges and Applications","The emergence of the cloud computing, and the other advanced technologies has made possible the extension of the computing and the data distribution competencies of the robotics that are networked by developing an cloud based robotic architecture by utilizing both the centralized and decentralized cloud that is manages the machine to cloud and the machine to machine communication respectively. The incorporation of the robotic system with the cloud makes probable the designing of the cost effective robotic architecture that enjoys the enhanced efficiency and a heightened realtime performance. This cloud based robotics designed by amalgamation of robotics and the cloud technologies empowers the web enabled robots to access the services of cloud on the fly. The paper is a survey about the cloud based robotic architecture, explaining the forces that necessitate the robotics merged with the cloud, its application and the major concerns and the challenges endured in the robotics that is integrated with the cloud. The paper scopes to provide a detailed study on the changes influenced by the cloud computing over the industrial",UbiComp 2020,2020
ac5c52c6b46b83ca1db1bbe8e635891d98a89100,https://www.semanticscholar.org/paper/ac5c52c6b46b83ca1db1bbe8e635891d98a89100,Ontologies for cloud robotics,"Abstract Cloud robotics (CR) is currently a growing area in the robotic community. Indeed, the use of cloud computing to share data and resources of distributed robotic systems leads to the design and development of cloud robotic systems (CRS) which constitute useful technologies for a wide range of applications such as smart manufacturing, aid and rescue missions. However, in order to get coherent agent-to-cloud communications and efficient agent-to-agent collaboration within these CRS, there is a need to formalize the knowledge representation in CR. Hence, the use of ontologies provides a mean to define formal concepts and their relations in an interoperable way. This paper presents standard robotic ontologies and their extension in the CR domain as well as their possible implementations in the case of a real-world CR scenario.",The Knowledge Engineering Review,2020
c2d87a7d2fd7cdb5b5f25dd4228374797694576f,https://www.semanticscholar.org/paper/c2d87a7d2fd7cdb5b5f25dd4228374797694576f,New Architecture: Cloud-Enabled CPS,,,2020
dc8db98bdad8aee95213ed5518c891f3a05a76e8,https://www.semanticscholar.org/paper/dc8db98bdad8aee95213ed5518c891f3a05a76e8,A categorization of simultaneous localization and mapping knowledge for mobile robots,"Autonomous robots are playing important roles in academic, technological, and scientific activities. Thus, their behavior is getting more complex. The main tasks of autonomous robots include mapping an environment and localize themselves. These tasks comprise the Simultaneous Localization and Mapping (SLAM) problem. Representation of the SLAM knowledge (e.g., robot characteristics, environment information, mapping and location information), with a standard and well-defined model, provides the base to develop efficient and interoperable solutions. However, as far as we know, there is not a common classification of such knowledge. Many existing works based on Semantic Web, have formulated ontologies to model information related to only some SLAM aspects, without a standard arrangement. In this paper, we propose a categorization of the knowledge managed in SLAM, based on existing ontologies and SLAM principles. We also classify recent and popular ontologies according to our proposed categories and highlight the lessons to learn from existing solutions.",SAC,2020
dcbad6309549438342fa6c1d0369392afada53a4,https://www.semanticscholar.org/paper/dcbad6309549438342fa6c1d0369392afada53a4,A Software Stack for Composable Cloud Robotics System,"Modern cloud robotic applications face new challenges in managing today’s highly distributed and heterogeneous environment. For example, the application programmers must make numerous systematical decisions between the local robot and the cloud server, such as computation deployment, data sharing and function integration.",ICA3PP,2020
e5ce18983f18966d77a641ba0a24455313ce0d6d,https://www.semanticscholar.org/paper/e5ce18983f18966d77a641ba0a24455313ce0d6d,Engineering Challenges Ahead for Robot Teamwork in Dynamic Environments,"The increasing number of robots around us creates a demand for connecting these robots in order to achieve goal-driven teamwork in heterogeneous multi-robot systems. In this paper, we focus on robot teamwork specifically in dynamic environments. While the conceptual modeling of multi-agent teamwork was studied extensively during the last two decades and commercial multi-agent applications were built based on the theoretical foundations, the steadily increasing use of autonomous robots in many application domains gave the topic new significance and shifted the focus more toward engineering concerns for multi-robot systems. From a distributed systems perspective, we discuss general engineering challenges that apply to robot teamwork in dynamic application domains and review state-of-the-art solution approaches for these challenges. This leads us to open research questions that need to be tackled in future work.",,2020
f4bec9f6259cee2b80e22c819d0142a2b8c59d46,https://www.semanticscholar.org/paper/f4bec9f6259cee2b80e22c819d0142a2b8c59d46,Knowledge Acquisition and Reasoning Systems for Service Robots: A Short Review of the State of the Art,"Understanding the environment is an essential capability for mobile service robots to achieve autonomy. While this has proven to be a very challenging task, researchers have come up with a variety of solutions to enable robots to interact with and understand the environment around them. This capability allows robots to make more intelligent decisions using acquired knowledge. In parallel, equipping robots with situation awareness capability is also of equal importance since the semantic context of various entities can change with the change in the situation. This paper aims to deliver a review of the state of the art artificial intelligence approaches taken by researchers to enable robots to acquire and process knowledge of their environment and situation leading to robotic awareness. The focal points include various techniques used for knowledge acquisition, decision management, reasoning, situation awareness, human-robot interaction, and planning. The goal is to compile the modern techniques used in this field based on which future research directions could be defined.",2020 5th International Conference on Robotics and Automation Engineering (ICRAE),2020
f9b39aeef3cbd6a07e685d37e3b07598e05c8925,https://www.semanticscholar.org/paper/f9b39aeef3cbd6a07e685d37e3b07598e05c8925,"Semantics for Robotic Mapping, Perception and Interaction: A Survey","For robots to navigate and interact more richly with the world around them, they will likely require a deeper understanding of the world in which they operate. In robotics and related research fields, the study of understanding is often referred to as semantics, which dictates what does the world ‘mean’ to a robot, and is strongly tied to the question of how to represent that meaning. With humans and robots increasingly operating in the same world, the prospects of human-robot interaction also bring semantics and ontology of natural language into the picture. Driven by need, as well as by enablers like increasing availability of training data and computational resources, semantics is a rapidly growing research area in robotics. The field has received significant attention in the research literature to date, but most reviews and surveys have focused on particular aspects of the topic: the technical research issues regarding its use in specific robotic topics like mapping or segmentation, or its relevance to one particular application domain like autonomous driving. A new treatment is therefore required, and is also timely because so much relevant research has occurred since many of the key surveys were published. This survey paper therefore provides an overarching snapshot of where semantics in robotics stands today. We establish a taxonomy for semantics research in or relevant to robotics, split into four broad categories of activity, in which semantics are extracted, used, or both. Within these broad categories we survey dozens of major topics including fundamentals from the computer vision field and key robotics research areas utilizing semantics, including mapping, navigation and interaction with the world. The paper also covers key practical considerations, including enablers like increased data availability and improved computational hardware, and major application areas where semantics is or is likely to play a key role. In creating this survey, we hope to provide researchers across academia and industry with a comprehensive reference that helps facilitate future research in this exciting field.",Found. Trends Robotics,2021
28372469bfab0f0205980304c2aea21c8dfc9f40,https://www.semanticscholar.org/paper/28372469bfab0f0205980304c2aea21c8dfc9f40,A Novel Semantic SLAM Framework for Humanlike High-Level Interaction and Planning in Global Environment,"In this paper, we propose a novel semantic SLAM framework based on human cognitive skills and capabilities that endow the robot with high level interaction and planning in real-world dynamic environment. Two-fold strengths of our framework aims at contributing: 1) A semantic map resulting from the integration of SLAM with the Triplet Ontological Semantic Model (TOSM); 2) Human-like robotic perception system that is optimal and biologically plausible for place and object recognition in dynamic environment proposing semantic descriptor and CNN .We demonstrate the effectiveness of our proposed framework using mobile robot with Zed camera (3D sensor) and a laser range finder (2D sensor) in real-world indoor environment. Experimental results demonstrate the practical merit of our proposed framework.",,2019
307cf91dabf468b85451c433846fe3a38d3a885c,https://www.semanticscholar.org/paper/307cf91dabf468b85451c433846fe3a38d3a885c,Security Issues and Solutions in Cloud Robotics: A Survey,"Reliability comes with security and security comes with latest technology and any technology is best suited for any application area until it possess a high security features. Security is considered to be one of the prominent feature which makes it more acceptable and deployable to diversified and multidisciplinary applications. The paper try to put forth an in depth review on various security aspects confining more on the security details related to cloud robotics. Cloud robotics is a term involved and emerged with the fusion of two dipole concepts namely cloud computing and robotics. Security flaws in these two technologies are the major concerns and can affect the cloud robotics. Cloud computing suffers from various type of vulnerabilities like Network based attacks, Data storage based attacks, Virtualization based attacks is also prone to operating system level attacks. The same way robotics also suffers from attacks namely denial of service attack, and dictionary attack etc. Thus it can be termed as that cloud robotics need to be safeguard from all such threats mentioned above. The draft in particular thus throws light on the different cryptographic algorithms: RSA (Rivest Shamir Andelmen), AES (Advanced Encryption Standard), ECC (Elliptic Curve Cryptography). Exclusive to the algorithms cited above, the article discusses few more methods and techniques concerning to security which can be aptly applied to cloud robotics to make it more safe and secure.",Communications in Computer and Information Science,2018
3160ca4f436b9d72dd480a156eb652dc1ce4a74a,https://www.semanticscholar.org/paper/3160ca4f436b9d72dd480a156eb652dc1ce4a74a,Robot Assistance in Dynamic Smart Environments—A Hierarchical Continual Planning in the Now Framework,"By coupling a robot to a smart environment, the robot can sense state beyond the perception range of its onboard sensors and gain greater actuation capabilities. Nevertheless, incorporating the states and actions of Internet of Things (IoT) devices into the robot’s onboard planner increases the computational load, and thus can delay the execution of a task. Moreover, tasks may be frequently replanned due to the unanticipated actions of humans. Our framework aims to mitigate these inadequacies. In this paper, we propose a continual planning framework, which incorporates the sensing and actuation capabilities of IoT devices into a robot’s state estimation, task planing and task execution. The robot’s onboard task planner queries a cloud-based framework for actuators, capable of the actions the robot cannot execute. Once generated, the plan is sent to the cloud back-end, which will inform the robot if any IoT device reports a state change affecting its plan. Moreover, a Hierarchical Continual Planning in the Now approach was developed in which tasks are split-up into subtasks. To delay the planning of actions that will not be promptly executed, and thus to reduce the frequency of replanning, the first subtask is planned and executed before the subsequent subtask is. Only information relevant to the current (sub)task is provided to the task planner. We apply our framework to a smart home and office scenario in which the robot is tasked with carrying out a human’s requests. A prototype implementation in a smart home, and simulator-based evaluation results, are presented to demonstrate the effectiveness of our framework.",Sensors,2019
3f5a6f3808b1c6d62e899d6f6125404ee0f51382,https://www.semanticscholar.org/paper/3f5a6f3808b1c6d62e899d6f6125404ee0f51382,A novel map-merging technique for occupancy grid-based maps using multiple robots: a semantic approach,"Map merging is a noteworthy phenomenon for cases such as search and rescue and disaster areas in which the duration is quite significant when gathering information about an environment. It is obvious that the total mapping time decreases if the number of agents (robots) increases. However, the use of multiple agents leads to problems such as task allocation schemes and the fusing of local maps. Examining the present methods, it is generally observed that the common features of local maps have been found and the global map is formed by obtaining related transformation between local maps. However, such implementations may be risky when local maps have symmetrical areas. Hence, a novel and semantic approach has been developed to solve this problem. The developed method counts on the reliability level of feature points. If relevant feature points are trusted, local maps are merged according to the best point or points. The simulation results from a robot operating system and a real-time experiment support the proposed method’s efficiency, and mapping can be performed even for environments that have symmetrical similar parts and the task time can thus be reduced.",Turkish J. Electr. Eng. Comput. Sci.,2019
6def5ec68752dbaf6b8a603ab7391c83ef977886,https://www.semanticscholar.org/paper/6def5ec68752dbaf6b8a603ab7391c83ef977886,Cut & recombine: reuse of robot action components based on simple language instructions,"Human beings can generalize from one action to similar ones. Robots cannot do this and progress concerning information transfer between robotic actions is slow. We have designed a system that performs action generalization for manipulation actions in different scenarios. It relies on an action representation for which we perform code-snippet replacement, combining information from different actions to form new ones. The system interprets human instructions via a parser using simplified language. It uses action and object names to index action data tables (ADTs), where execution-relevant information is stored. We have created an ADT database from three different sources (KUKA LWR, UR5, and simulation) and show how a new ADT is generated by cutting and recombining data from existing ADTs. To achieve this, a small set of action templates is used. After parsing a new instruction, index-based searching finds similar ADTs in the database. Then the action template of the new action is matched against the information in the similar ADTs. Code snippets are extracted and ranked according to matching quality. The new ADT is created by concatenating code snippets from best matches. For execution, only coordinate transforms are needed to account for the poses of the objects in the new scene. The system was evaluated, without additional error correction, using 45 unknown objects in 81 new action executions, with 80% success. We then extended the method including more detailed shape information, which further reduced errors. This demonstrates that cut & recombine is a viable approach for action generalization in service robotic applications.",Int. J. Robotics Res.,2019
8193122b2cf5ec63ead24f36d3093f7f55e23d46,https://www.semanticscholar.org/paper/8193122b2cf5ec63ead24f36d3093f7f55e23d46,Cooperative Heterogeneous Multi-Robot Systems,"The emergence of the Internet of things and the widespread deployment of diverse computing systems have led to the formation of heterogeneous multi-agent systems (MAS) to complete a variety of tasks. Motivated to highlight the state of the art on existing MAS while identifying their limitations, remaining challenges, and possible future directions, we survey recent contributions to the field. We focus on robot agents and emphasize the challenges of MAS sub-fields including task decomposition, coalition formation, task allocation, perception, and multi-agent planning and control. While some components have seen more advancements than others, more research is required before effective autonomous MAS can be deployed in real smart city settings that are less restrictive than the assumed validation environments of MAS. Specifically, more autonomous end-to-end solutions need to be experimentally tested and developed while incorporating natural language ontology and dictionaries to automate complex task decomposition and leveraging big data advancements to improve perception algorithms for robotics.",ACM Comput. Surv.,2019
a004387cee67efefacec44cc332391f1ea9dd7b7,https://www.semanticscholar.org/paper/a004387cee67efefacec44cc332391f1ea9dd7b7,A Review of Semantic Sensor Technologies in Internet of Things Architectures,"Intelligent sensors should be seamlessly, securely, and trustworthy interconnected to enable automated high-level smart applications. Semantic metadata can provide contextual information to support the accessibility of these features, making it easier for machines and humans to process the sensory data and achieve interoperability. The unique overview of sensor ontologies according to the semantic needs of the layers of IoT solutions can serve a guideline of engineers and researchers interested in the development of intelligent sensor-based solutions. The explored trends show that ontologies will play an even more essential role in interlinked IoT systems as interoperability and the generation of controlled linkable data sources should be based on semantically enriched sensory data.",Complex.,2019
a3dfee3a4f8c9e6b997ae85008263af97affaf78,https://www.semanticscholar.org/paper/a3dfee3a4f8c9e6b997ae85008263af97affaf78,Invited Paper: Distributed Computing in Cyber-Physical Intelligence: Robotic Perception as an Example,"Intelligent cyber-physical systems, such as robots, are emerging computing devices that autonomously and directly interact with the physical world. The new characteristics of these devices motivate further research questions different from those addressed in traditional computing technology. Based on an in-depth investigation of the relationship between a typical example, robotic perception, and distributed computing, this paper tries to explore the challenges and opportunities brought by intelligent cyber-physical systems to distributed computing. The preliminary answers to three questions are given: ""Why should we introduce distributed computing into cyber-physical intelligence"", ""What kind of distributed architecture can contribute to cyber-physical intelligence"" and ""What challenges brought by intelligent cyber-physical systems to distributed computing infrastructure?"" A multi-scale hybrid distributed architecture for cyber-physical intelligence named as Music as well as our initial practices towards enabling this architecture is also presented.",2019 IEEE International Conference on Service-Oriented System Engineering (SOSE),2019
b831ba1fedbc504afeeb6fe70be23bdd6e3857ae,https://www.semanticscholar.org/paper/b831ba1fedbc504afeeb6fe70be23bdd6e3857ae,Leveraging cloud computing for the semantic web: review and trends,"Semantic and cloud computing technologies have become vital elements for developing and deploying solutions across diverse fields in computing. While they are independent of each other, they can be integrated in diverse ways for developing solutions and this has been significantly explored in recent times. With the migration of web-based data and applications to cloud platforms and the evolution of the web itself from a social, web 2.0 to a semantic, web 3.0 comes as the convergence of both technologies. While several concepts and implementations have been provided regarding interactions between the two technologies from existing research, without an explicit classification of the modes of interaction, it can be quite challenging to articulate the interaction modes; hence, building upon them can be a very daunting task. Hence, this research identifies and describes the modes of interaction between them. Furthermore, a “cloud-driven” interaction mode which focuses on fully maximising cloud computing characteristics and benefits for driving the semantic web is described, providing an approach for evolving the semantic web and delivering automated semantic annotation on a large scale to web applications.",,2020
c8702335d72eaeb2319d0dd3ddfb9a226aa1e337,https://www.semanticscholar.org/paper/c8702335d72eaeb2319d0dd3ddfb9a226aa1e337,Fast Robot Learning using Prospection and Experimental Knowledge : A Cognitive Approach with Narrative-Enabled Episodic Memories and Symbolic Knowledge,"Humans employ data-efficient learning mechanisms to obtain new skills and to improve the existing ones. Robots have already replaced humans in terms of labor in performing repetitive and dangerous tasks in structured environments like factories. On the other hand, developing completely autonomous robotic systems for unstructured environments, like a household, is still a challenge for roboticists due to the infeasibility of programming every possible case and today’s data-hungry machine learning approaches. In order to assist humans in such environments, I believe that robots should be able to gain and improve skills using human-like learning mechanisms regularly. For this purpose, I present a cognition-enabled fast learning framework in this dissertation which makes use of symbolic knowledge, episodic memories, and cloud robotics services along with a cutting-edge deep imitation learning methodology in order to reduce the dependency on big experiment data. Using this framework, robots can (1) imitate tasks demonstrated by a human demonstrator in virtual-reality, (2) adapt the actions of itself and others to new conditions, and (3) prospect which task parameters lead to the desired goal. To validate these abilities, I have provided some experimental results. These experiments were conducted with four different service robots in various kitchen environments. The human demonstrations were recorded inside a game-with-a-purpose using virtual-reality equipment. Such a setup enables roboticists to crowdsource their training data by eliminating the requirement of being in the same environment with the robot.",,2019
cbc5215db6d8ad0dc53cf64d4c186e654f459af3,https://www.semanticscholar.org/paper/cbc5215db6d8ad0dc53cf64d4c186e654f459af3,A Survey of Knowledge Representation in Service Robotics,"Abstract Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modeling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.",Robotics Auton. Syst.,2018
01f99a866a0303403bf3c37681e68fe47e2eae2a,https://www.semanticscholar.org/paper/01f99a866a0303403bf3c37681e68fe47e2eae2a,A fast incremental map segmentation algorithm based on spectral clustering and quadtree,"Currently, state-of-the-art simultaneous localization and mapping methods are capable of generating large-scale and dense environmental maps. One primary reason may be the applications of map partitioning strategies. An efficient map partitioning method will decrease the time complexity of simultaneous localization and mapping algorithm and, more importantly, will make robots understand a place anthropomorphically. In this article, we propose a novel map segmentation algorithm based on quadtree and spectral clustering. The map is first organized hierarchically using quadtree, and then a user-friendly criterion is utilized to construct the corresponding Laplacian matrix for quadtree so that spectral clustering can be solved efficiently based on the sparse property of the matrix. In this article, we go further to provide a real-time, incremental, parallel algorithm that can be implemented on multi-core CPU/GPU to enhance the performance of the proposed basic algorithm. Our algorithms are verified under multiple environments including both simulation and real-world data, and the results reveal that the algorithm can provide a correct and user-friendly segmentation result in a short runtime.",,2018
0e234590f4c91b0eb15cec18c46011d956896f19,https://www.semanticscholar.org/paper/0e234590f4c91b0eb15cec18c46011d956896f19,An Industrial Robot System Based on Edge Computing: An Early Experience,"As more sensors and actuators are deployed in industrial manufacturing, the industry requires a new production system architecture that offers better real-time and network transmission performance. Yet cloud computing (based on a centralized datacenter) is limited in its possibilities, because it suffers from heavy bandwidth costs and lengthy time delays. As a solution, we propose an industrial robot system based on edge computing. Here, we present its three-layer architecture in detail: the cloud, edge, and physical resource layers. Initially, we deploy an edge node near the data sources, to integrate various devices’ interfaces and acts as a raw data filter. Then, we apply the proposed system on the robotic welding of the membrane wall cell. Finally, we test the system by conducting an experiment. The results demonstrate the system’s feasibility and prove that the system yields better real-time and network transmission performance than a cloud-based scenario.",HotEdge,2018
17d309de8e4e3eafa1373784a5efa5cf35d1e5b9,https://www.semanticscholar.org/paper/17d309de8e4e3eafa1373784a5efa5cf35d1e5b9,Cloud robot: semantic map building for intelligent service task,"When a robot provides intelligent services, it needs to obtain a semantic map of the complex environment. The robot’s vision is commonly used to obtain the semantic concepts and relations of objects and rooms in indoor environments, which are labeled semantic information on the map. In an actual indoor environment, because of the great variety of objects and complex arrangements, a key problem is building a semantic map successfully in which the scale of the semantic database is large and the query speed is highly efficient. However, this is often a difficult problem to solve. Combined with cloud technology, the semantic acquisition structure of an environment based on the cloud is constructed by designing a cloud semantic database; the cloud robot can not only obtain the geometric description of the environment but also obtain the semantic map that contains the objects’ relationships based on a rich semantic database of the complex environment. It solves the problems of low-reliability when adding semantic information, errors in updating the map and the lack of scalability in the process of constructing the semantic map. An SVM (Support Vector Machine) algorithm is used to classify the semantic subdatabase on the foundation of which the feature model database is formed by extracting key feature points based on network text classification. Combining the semantic subdatabase with the semantic classification list, the objects can be quickly identified. Based on the abundant cloud semantic database, the cloud semantic map for intelligent service tasks can be implemented. The classification efficiency of the simulated experiments in the semantic database is analyzed, and the validity of the method is verified.",Applied Intelligence,2018
1a4696401d822c632735b070dacdf88a50c7acfc,https://www.semanticscholar.org/paper/1a4696401d822c632735b070dacdf88a50c7acfc,Towards robust grasps: Using the environment semantics for robotic object affordances,"In this talk I will look back over four years of long-term deployments of autonomous mobile robots in everyday environments. From this I will present examples of the kinds of things that mobile robots can learn over long autonomous operations in such environments, including navigation information, human activities, object models, and mission schedules. Following this I will explore the issues (software, hardware, and social) that impacted upon the autonomy of our deployed robots, and look at what we can learn from these experiences as both AI practitioners and as engineers deploying robots in real environments. Dr. Maarten Sierhuis, Chief Technology Director at Nissan Research Center Silicon Valley, Founder of Ejenta Title: Seamless Autonomous Mobility (SAM) Abstract: Artificial intelligence will make vehicles able to drive autonomously in a wide variety of scenarios. However, unexpected situations can still arise as these long-term autonomous vehicles interact in the world, potentially limiting the uses of fully autonomous driving in the near future. Nissan’s Seamless Autonomous Mobility provides a solution that can overcome this issue through the intelligent integration of humans. Artificial intelligence will make vehicles able to drive autonomously in a wide variety of scenarios. However, unexpected situations can still arise as these long-term autonomous vehicles interact in the world, potentially limiting the uses of fully autonomous driving in the near future. Nissan’s Seamless Autonomous Mobility provides a solution that can overcome this issue through the intelligent integration of humans. Dr. Peter Wurman, VP of Engineering at Cogitai, Former Co-founder of Kiva Systems Title: The Disruptive Power of Robots Abstract: Kiva Systems introduced swarms of agile robots into an industry dominated by stationary conveyor systems. The path from concept through successful startup and eventual acquisition involved challenges on all fronts. In this talk I’ll explain the business problem that motivated the innovation, Kiva technology and the benefits it brought to customers, and the future of applications of robotics in warehouses. Kiva Systems introduced swarms of agile robots into an industry dominated by stationary conveyor systems. The path from concept through successful startup and eventual acquisition involved challenges on all fronts. In this talk I’ll explain the business problem that motivated the innovation, Kiva technology and the benefits it brought to customers, and the future of applications of robotics in warehouses.",AAAI 2018,2018
46fe64b3a4e819eae20fed1dd299b6790b201870,https://www.semanticscholar.org/paper/46fe64b3a4e819eae20fed1dd299b6790b201870,Ontology Based Image Recognition : A Review,"Due to lack of domain knowledge about the semantics of the image, image retrieval rate is usually unsatisfying. To improve this, image labels must be provided by the author of the dataset. Applying ontology in digital image recognition to extract relevant information such as timeline, features, visualization to help understand and interpret it, so that we can focus on the most relevant information.",,2018
4f3f56f5688a80c15ba4ca632f1da19fd56ea436,https://www.semanticscholar.org/paper/4f3f56f5688a80c15ba4ca632f1da19fd56ea436,A Survey of Knowledge Representation for Learning in Service Robotics,"Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modelling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.",,2018
5f1c8801eb3e4aba93e821a5094c058458d04978,https://www.semanticscholar.org/paper/5f1c8801eb3e4aba93e821a5094c058458d04978,Semantic Mapping for Autonomous Robots in Urban Environments,"Increasing autonomy and interactivity of mobile robotic technologies require the inclusion of semantic information in environment representations. This thesis focuses on representations and methods for semantic mapping in particular for urban environments. It covers the estimation of spatial relations between objects using Probabilistic Logic, including a novel inference method for Markov Logic Networks. Moreover, the benefits of combining different sources of semantic information with sensor data are shown in a scene interpretation and a semantic localization task.",,2018
658f7781aa5f80d75da19b4cf3e86af52318df42,https://www.semanticscholar.org/paper/658f7781aa5f80d75da19b4cf3e86af52318df42,RoboCloud: augmenting robotic visions for open environment modeling using Internet knowledge,"Modeling an open environment that contains unpredictable objects is a challenging problem in the field of robotics. In traditional approaches, when a robot encounters an unknown object, a mistake will inevitably be added to the robot’s environmental model, severely constraining the robot’s autonomy, and possibly leading to disastrous consequences in certain settings. The abundant knowledge accumulated on the Internet has the potential to remedy the uncertainties that result from encountering with unknown objects. However, robotic applications generally pay considerable attention to quality of service (QoS). For this reason, directly accessing the Internet, which can be unpredictable, is generally not acceptable. RoboCloud is proposed as a novel approach to environment modeling that takes advantage of the Internet without sacrificing the critical properties of QoS. RoboCloud is a “mission cloud–public cloud” layered cloud organization model in which the mission cloud provides QoS-available environment modeling capability with built-in prior knowledge while the public cloud is the existing services provided by the Internet. The “cloud phase transition” mechanism seeks help from the public cloud only when a request is outside the knowledge of the mission cloud and the QoS cost is acceptable. We have adopted semantic mapping, a typical robotic environment modeling task, to illustrate and substantiate our approach and key mechanism. Experiments using open 2D and 3D datasets with real robots have demonstrated that RoboCloud is able to augment robotic visions for open environment modeling.",Sci. China Inf. Sci.,2018
6dbb03523b801d30b08547076371a6d2a5ac521a,https://www.semanticscholar.org/paper/6dbb03523b801d30b08547076371a6d2a5ac521a,Dynamische Konfiguration verteilter Informationsverarbeitung in Gruppen heterogener Agenten,,,2018
70206b09df8129ba35b7cf7468db310ccdd1ba0b,https://www.semanticscholar.org/paper/70206b09df8129ba35b7cf7468db310ccdd1ba0b,Artificial Intelligence for Long-Term Robot Autonomy: A Survey,"Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty, and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e., weeks, months, or years) poses many challenges. Some of these have been investigated by subdisciplines of Artificial Intelligence (AI) including navigation and mapping, perception, knowledge representation and reasoning, planning, interaction, and learning. The different subdisciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this letter, we survey and discuss AI techniques as “enablers” for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.",IEEE Robotics and Automation Letters,2018
722222113ccd5c0a5bf6d93db5596138219ee8e7,https://www.semanticscholar.org/paper/722222113ccd5c0a5bf6d93db5596138219ee8e7,A Study of Robotic Cooperation in Cloud Robotics: Architecture and Challenges,"Networked robotics involves a collection of robots working together to perform complex tasks, such as search and rescue task in disaster management. Because such tasks are beyond the capacity of a single powerful robot, networked robotics has been widely researched. However, the modes of cooperation in traditional networked robotics have been restricted by the inherent physical constraint that all computations are performed in the robotic network, with knowledge sharing being limited to the collective storage in the network. Cloud robotics, which allows robots to benefit from the rich storage, computation, and communication resources of modern data centers, is widely accepted as a promising approach to efficient robot cooperation in applications, such as disaster management. In this paper, we study robotic cooperation in cloud robotics. We first give a conceptual view of the nature of this cooperation. We then propose three novel robotic cooperation frameworks for cloud robotics: robotic knowledge sharing cooperation, robotic physical-task cooperation, and robotic computation task cooperation. Finally, we identify several critical challenges, and illustrate the potential benefits of robotic cooperation in cloud robotics.",IEEE Access,2018
7a3defd7260836107f7dee87aff408d4e236b999,https://www.semanticscholar.org/paper/7a3defd7260836107f7dee87aff408d4e236b999,A Bayesian based Methodology for Indirect Object Search,"The main goal of this paper is to propose a Bayesian based methodology for implementing robot informed search for objects. The methodology uses convolutions between observation likelihoods of secondary objects and spatial relation masks for estimating the probability map of the object being searched for, and also a search procedure that uses this probability map. A method for computing complex spatial relation masks by using a basis composed of basic relation masks and a database of co-occurrences of objects is used. Each basic relation mask corresponds to a qualitative spatial relation (QSR), such as: ‘very near’, ‘near’, or ‘far’. The search procedure takes into account the probability that the main object can be in different regions on the map and the distance to those regions. Also, the object search procedure is able to detect objects and generate new plans while moving. The proposed methodology is compared with uninformed and alternative informed search approaches using simulations and real-world experiments with a service robot. In simulations, the use of the proposed methodology increases the detection rate from 28% (direct uninformed search) to 79%, when the main object can be detected within a maximum distance of 1 meter. In the real world experiments, the use of the proposed methodology increases the detection rate from 40% (direct uninformed search) to 87% when using convolutions with soft masks, global search, and information on the positive detection of secondary objects. The detection rates obtained when using the proposed methodology are also much higher than those obtained by alternative informed search methods, both in the simulated and in the real-world experiments.",J. Intell. Robotic Syst.,2018
8c6d202ecd958ae2809e10e837029fda8c7c0983,https://www.semanticscholar.org/paper/8c6d202ecd958ae2809e10e837029fda8c7c0983,A Survey of Knowledge Representation and Retrieval for Learning in Service Robotics,"Within the realm of service robotics, researchers have placed a great amount of effort into learning motions and manipulations for task execution by robots. The task of robot learning is very broad, as it involves many tasks such as object detection, action recognition, motion planning, localization, knowledge representation and retrieval, and the intertwining of computer vision and machine learning techniques. In this paper, we focus on how knowledge can be gathered, represented, and reproduced to solve problems as done by researchers in the past decades. We discuss the problems which have existed in robot learning and the solutions, technologies or developments (if any) which have contributed to solving them. Specifically, we look at three broad categories involved in task representation and retrieval for robotics: 1) activity recognition from demonstrations, 2) scene understanding and interpretation, and 3) task representation in robotics datasets and networks. Within each section, we discuss major breakthroughs and how their methods address present issues in robot learning and manipulation.",ArXiv,2018
90c023a09ad3d187d90948484490f47d1f59c2c1,https://www.semanticscholar.org/paper/90c023a09ad3d187d90948484490f47d1f59c2c1,SOMA : A Framework for Understanding Change in Everyday Environments Using Semantic Object Maps,"Understanding change related to the dynamics of people and objects in everyday environments is a challenging problem. At the same time, it is a key requirement in many applications of autonomous mobile service robots. In this paper we present a novel semantic mapping framework which maps locations of objects, regions of interest, and movements of people over time. Our aim with this framework is twofold: (1) we want to allow robots to reason semantically, spatially, and temporally about their environment, and (2) we want to enable researchers to investigate research questions in the context of long-term scenarios in dynamic environments. Experimental results demonstrate the effectiveness of the framework which was deployed on mobile robot systems in real-world environments over several months.",,2018
ad51140c8d5f56e2d205befa2f98c33566bd7b4f,https://www.semanticscholar.org/paper/ad51140c8d5f56e2d205befa2f98c33566bd7b4f,A Comprehensive Survey of Recent Trends in Cloud Robotics Architectures and Applications,"Cloud robotics has recently emerged as a collaborative technology between cloud computing and service robotics enabled through progress in wireless networking, large scale storage and communication technologies, and the ubiquitous presence of Internet resources over recent years. Cloud computing empowers robots by offering them faster and more powerful computational capabilities through massively parallel computation and higher data storage facilities. It also offers access to open-source, big datasets and software, cooperative learning capabilities through knowledge sharing, and human knowledge through crowdsourcing. The recent progress in cloud robotics has led to active research in this area spanning from the development of cloud robotics architectures to its varied applications in different domains. In this survey paper, we review the recent works in the area of cloud robotics technologies as well as its applications. We draw insights about the current trends in cloud robotics and discuss the challenges and limitations in the current literature, open research questions and future research directions.",Robotics,2018
ad5f8a03b2117d360bbe1e8774e806760f024a3a,https://www.semanticscholar.org/paper/ad5f8a03b2117d360bbe1e8774e806760f024a3a,Landmark-Based Robot Navigation: A Paradigm Shift from Onboard Processing to Cloud,"Cloud robotics is one of the important and upcoming technologies of the twenty-first century. It is in actual fact a computing system which is distributed in nature, and the processing is performed over the cloud, for computation of huge amount of tasks. Cloud services help robots to find its application, both in the indoor or outdoor environment for various purposes in our everyday life. Before the advent of cloud, the robots were mostly independent and performed computation and storage in the onboard computer or microchip. This led to huge overhead on the processing power of the robot. Therefore, the survey is organized around two major aspects of robot navigation, i.e. robotics with onboard information and robotics with cloud infrastructure. This paper highlights the change in the technologies for robot navigation and the benefits of cloud infrastructure.","Advances in Communication, Cloud, and Big Data",2018
b0a3fd245ccbe6c8857369df7d9cf1b2c4870edd,https://www.semanticscholar.org/paper/b0a3fd245ccbe6c8857369df7d9cf1b2c4870edd,A Reinforcement Learning-Based Resource Allocation Scheme for Cloud Robotics,"In recent years, robotic systems combined with cloud computing capability have become an emerging topic of discussion in academic fields. The concept of cloud robotics allows the system to offload computing-intensive tasks from the robots to the cloud. An appropriate resource allocation scheme is necessary for the cloud computing service platform to efficiently allocate its computing resources, when the robots send requests asking for computing service. This paper proposes a resource allocation scheme based on reinforcement learning (RL), which can make the cloud to decide whether a request should be accepted and how many resources are supposed to be allocated. The scheme realizes an autonomous management of computing resources through online learning, reduces human participation in scheme planning, and improves the overall utility of the system in the long run. Numerical results demonstrate that the proposed RL-based computing resource allocation scheme has better performances than the greedy allocation scheme.",IEEE Access,2018
c6aa5603e9cbea9a984bf2568b3647374b7324c2,https://www.semanticscholar.org/paper/c6aa5603e9cbea9a984bf2568b3647374b7324c2,ALI HUSSNAIN APPLICATION OF CLOUD ROBOTICS FOR AUTOMATIC MANIPULATION,"ALI HUSSNAIN: APPLICATION OF CLOUD ROBOTICS FOR AUTOMATIC MANIPULATION Tampere University of technology Master of Science Thesis, 73 pages MAY 2018 Master’s Degree Programme in Automation Engineering Major: Factory Automation and Industrial Informatics Engineering Examiner: Professor Jose L. Martinez Lastra Supervisor: Dr. Borja Ramis Ferrer",,2018
c95ab510567a2cd14f5a941dac0f036701f08197,https://www.semanticscholar.org/paper/c95ab510567a2cd14f5a941dac0f036701f08197,SOAP: SDN overlay across providers for IoT cognition services,"With the rapid development of cloud computing, big data, robotic cloud and other emerging technologies, more and more intelligent machines and terminals are now embedded with sensors or actuators that need continuous connectivity over the Internet. Terminals attached to the 5G edges are expected to have sophisticated cognitive capabilities to satisfy future IoT services and application. The enabler for such smart services is the capability to establish low throughput connectivity channel across various terminals roaming in the globe to support real time collaborative decisions. Existing mobility protocols and routing standards are inefficient to support such requirement as of their centralized design concept that enforces round trip propagation delay and induces high latency as of excess tunnel headers and signaling overheads. This research establishes a real prototype to illustrate how Software Defined Networking (SDN) can be adopted to automatically established overlay networks over any hybrid infrastructure that can be geographically separated by WAN to provide seamless LAN extension. SOAP overlays identify terminals during the dynamic IP allocation of their join processes and connect them regardless of their location with minimum latency and delay. The overlay network can be expanded cross service providers managed by different SDN controllers. The evaluation of SOAP performance shows strong advancement over existing protocols as of eliminating signaling overheads and restricting tunnel usage to shared paths for connecting WAN separated providers. SOAP ensures wire speed performance inside provider and delivers feasible solution across providers under direct/indirect service level agreements.",2018 International Conference on Innovative Trends in Computer Engineering (ITCE),2018
dc4b97e730317f238363c0e4c1d6913a7ff19af5,https://www.semanticscholar.org/paper/dc4b97e730317f238363c0e4c1d6913a7ff19af5,Hitchhiking Based Symbiotic Multi-Robot Navigation in Sensor Networks,"Robot navigation is a complex process that involves real-time localization, obstacle avoidance, map update, control, and path planning. Thus, it is also a computationally expensive process, especially in multi-robot systems. This paper presents a cooperative multi-robot navigation scheme in which a robot can ‘hitchhike’ another robot, i.e., two robots going to the same (or close) destination navigate together in a leader–follower system assisted by visual servoing. Although such cooperative navigation has many benefits compared to traditional approaches with separate navigation, there are many constraints to implementing such a system. A sensor network removes those constraints by enabling multiple robots to communicate with each other to exchange meaningful information such as their respective positions, goal and destination locations, and drastically improves the efficiency of symbiotic multi-robot navigation through hitchhiking. We show that the proposed system enables efficient navigation of multi-robots without loss of information in a sensor network. Efficiency improvements in terms of reduced waiting time of the hitchhiker, not missing potential drivers, best driver-profile match, and velocity tuning are discussed. Novel algorithms for partial hitchhiking, and multi-driver hitchhiking are proposed. A novel case of hitchhiking based simultaneous multi-robot teleoperation by a single operation is also proposed. All the proposed algorithms are verified by experiments in both simulation and real environment.",Robotics,2018
098e068bfde047cf90f964c8b1f11224f511cd27,https://www.semanticscholar.org/paper/098e068bfde047cf90f964c8b1f11224f511cd27,A cloud service for robotic mental simulations,"Robotic agents that do everyday manipulation tasks can hugely benefit from being able to predict consequences of their actions just before the execution. However, such a simulation technique is usually computationally-expensive and may not be achieved with agents' self computing power. For this problem, cloud robotics may offer a solution. Cloud robotics is an emerging field in the intersection of robotics and cloud computing which enables robots to access a greater amount of processing power and storage capacity than it can employ within itself. In this work, we introduce a mental simulation service to, one of the cloud engines, openEASE [1]. Using this service, researchers and robots can describe the world model, the state of the agent and the problem that is being dealt with. In return, it simulates the world and runs a learning algorithm and suggests a solution how the robotic agent can handle the problem. This service does not only offer a free remote access to simulation which is computationally expensive but also thanks to OPEnEASE's rich reasoning techniques these simulated experiments can be reasoned later on using prolog queries.",2017 IEEE International Conference on Robotics and Automation (ICRA),2017
582e7ca855aacce883150c4bff0b0049a5c157bc,https://www.semanticscholar.org/paper/582e7ca855aacce883150c4bff0b0049a5c157bc,"Internet of Robotic Things-Converging Sensing / Actuating , Hypoconnectivity , Artificial Intelligence and IoT Platforms","The Internet of Things (IoT) concept is evolving rapidly and influencing new developments in various application domains, such as the Internet of Mobile Things (IoMT), Autonomous Internet of Things (A-IoT), Autonomous System of Things (ASoT), Internet of Autonomous Things (IoAT), Internet of Things Clouds (IoT-C) and the Internet of Robotic Things (IoRT) etc. are progressing/advancing by using IoT technology. The IoT influence represents new development and deployment challenges in different areas such as seamless platform integration, context based cognitive network integration, new mobile sensor/actuator network paradigms, things identification (addressing, naming in IoT) and dynamic things discoverability and many others. The IoRT represents new convergence challenges and their need to be addressed, in one side the programmability and the communication of multiple heterogeneous mobile/autonomous/robotic things for cooperating, coordination, configuration, exchange of information, security, safety and protection. Developments in IoT heterogeneous parallel processing/communication and dynamic systems based on parallelism and concurrency that require new ideas for integrating the intelligent ""devices"", collaborative robots (COBOTS), into IoT applications. Dynamic maintainability, self-healing, self-repair of resources, changing resource state, (re-) configuration and context based IoT systems for service implementation and integration with IoT network service composition are of paramount importance when new ""cognitive devices"" are becoming active participants in IoT applications. The chapter aims to be an overview of the IoRT concept, technologies, architectures and applications and to provide a comprehensive coverage of future challenges, developments and applications. This chapter aims to be an overview of the IoRT concept, technologies, architectures and applications and to provide a comprehensive coverage of trends and future challenges, developments and applications. 2",,2017
5f3c29c1d4eaf50ae72b3d6a23c97faa603b83d6,https://www.semanticscholar.org/paper/5f3c29c1d4eaf50ae72b3d6a23c97faa603b83d6,A review of spatial reasoning and interaction for real-world robotics,"Truly universal helper robots capable of coping with unknown, unstructured environments must be capable of spatial reasoning, i.e. establishing geometric relations between objects and locations, expressing those in terms understandable by humans. It is therefore desirable that spatial and semantic environment representations are tightly interlinked. 3D robotic mapping and the generation of consistent metric representations of space are highly useful for navigation and exploration, but they do not capture symbol-level information about the environment. This is, however, essential for reasoning, and enables interaction via natural language, which is arguably the most common and natural communication channel used and understood by humans. This article presents a review of research in three major fields relevant for this discussion of spatial reasoning and interaction. Firstly, dialogue systems are an integral part of modern approaches to situated human–robot interaction. Secondly, interactive robots must be equipped with environment representations and reasoning methods that are suitable for both navigation and task fulfillment, as well as for interaction with human partners. Thirdly, at the interface between these domains are systems that ground language in systemic environment representation and which allow the integration of information from natural language descriptions into robotic maps. For each of these areas, important approaches are outlined and relations between the fields are highlighted, and challenging applications as well as open problems are discussed.",Adv. Robotics,2017
605bdaefb979cd9a0f33d393d8a5f9bcfe0073bf,https://www.semanticscholar.org/paper/605bdaefb979cd9a0f33d393d8a5f9bcfe0073bf,Real-time cloud robotics in practical smart city applications,"Smart mobile devices are one of the main factors of realizing the smart city of tomorrow. To this aim, in this paper, we investigate utilizing cloud robotics as a practical processing platform for making the existing inexpensive mobile devices such as robots smarter and collaborative. Smart cities with the scattered massive number of sensors would need complicated infrastructure to connect and process large quantities of data. Cloud robotics has emerged as an efficient computing means in intensive data processing applications. Hence, we introduce C2RO cloud robotics platform that uses real-time stream processing technology to virtually connect the energy-efficient and low-cost city mobile devices or sensors. Moreover, to mitigate the effects of latency, we propose the hybrid cloud robotics computation model used in C2RO cloud robotics platform as a processing model employing both edge and cloud computing technologies in robotics. We demonstrate the superiority of C2RO platform through practical experiments and show that our proposed computational model provides significant optimization in the latency and processing rate, and achieves the real-time target of a high-profile urban project.","2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)",2017
78060e6d163e77626bdcb72cb1be0e6819fb7d45,https://www.semanticscholar.org/paper/78060e6d163e77626bdcb72cb1be0e6819fb7d45,Intuitive Instruction of Industrial Robots : A Knowledge-Based Approach,"With more advanced manufacturing technologies, small and medium sized enterprises can compete with low-wage labor by providing customized and high quality products. For small production series, robotic systems can provide a cost-effective solution. However, for robots to be able to perform on par with human workers in manufacturing industries, they must become flexible and autonomous in their task execution and swift and easy to instruct. This will enable small businesses with short production series or highly customized products to use robot coworkers without consulting expert robot programmers. The objective of this thesis is to explore programming solutions that can reduce the programming effort of sensor-controlled robot tasks. The robot motions are expressed using constraints, and multiple of simple constrained motions can be combined into a robot skill. The skill can be stored in a knowledge base together with a semantic description, which enables reuse and reasoning. The main contributions of the thesis are 1) development of ontologies for knowledge about robot devices and skills, 2) a user interface that provides simple programming of dual-arm skills for non-experts and experts, 3) a programming interface for task descriptions in unstructured natural language in a user-specified vocabulary and 4) an implementation where low-level code is generated from the high-level descriptions. The resulting system greatly reduces the number of parameters exposed to the user, is simple to use for non-experts and reduces the programming time for experts by 80%. The representation is described on a semantic level, which means that the same skill can be used on different robot platforms. The research is presented in seven papers, the first describing the knowledge representation and the second the knowledge-based architecture that enables skill sharing between robots. The third paper presents the translation from high-level instructions to low-level code for force-controlled motions. The two following papers evaluate the simplified programming prototype for non-expert and expert users. The last two present how program statements are extracted from unstructured natural language descriptions.",,2017
7acc8da5b98f292c829931c80fdb0af6664b2451,https://www.semanticscholar.org/paper/7acc8da5b98f292c829931c80fdb0af6664b2451,Cloud robotics in Smart Manufacturing Environments: Challenges and countermeasures,"Abstract In Smart Manufacturing Environments (SME), the use of cloud robotics is based on the integration of cloud computing and industrial robots, which provides a new technological approach to task execution and resource sharing compared to traditional industrial robots. However, research on cloud robotics in SME still faces some challenges. First, highly flexible load scheduling mechanisms are immature. Second, traditional optimization mechanisms for the network service quality do not meet the requirements of smart manufacturing due to time variability and service quality dynamics. And, finally, existing learning algorithms used without cloud-assisted resources cause great resource wasting. Accordingly, this paper explores main technologies related to cloud robotics in SME. The research contents include self-adaptive adjustment mechanisms for the service quality of a cloud robot network, computing load allocation mechanisms for cloud robotics, and group learning based on a cloud platform. The results presented in this paper are helpful to understand the internal mechanisms of perception and interaction, intelligent scheduling and control of cloud robot systems oriented to smart manufacturing, and the design of a cloud architecture oriented to group learning.",Comput. Electr. Eng.,2017
8d42cdf275a59535a9f0e109d81e280e37af0338,https://www.semanticscholar.org/paper/8d42cdf275a59535a9f0e109d81e280e37af0338,An Adaptive Robotics Middleware for a cloud-based bridgeOS,"Robotic applications and their capabilities have grown exponentially in recent years, but hardware limitations and environment restrictions still lead to unfulfilled requirements. As Cloud Computing matured, however, robotics began taking advantage of its elastic resources by offloading computation and data to the cloud, effectively creating what is now called Cloud Robotics. Although a multitude of frameworks have been proposed over the years, each with its own unique specifications and goals, none has become dominant nor able to provide a standard and generic solution linking both robots, users and the cloud. An innovative platform, bridgeOS, attempts to take on this role by providing a new solution and framework, integrating recent Services paradigms, using a web-oriented approach and supporting a prominent software for networked robotics, the Robot Operating System (ROS). To accomplish this, we propose a cloud-based extension for the bridgeOS framework, capable of dynamic service deployments for the robots, and add support for adaptive decision making, based on available resources and performance metrics, to optimize in real time, both how those services are distributed and how well they perform. Overall, the middleware we developed is robust, resilient, versatile and capable of scaling to hundreds of components. Our experimental results show that it is a viable solution, with benefits exceeding the overhead it generates.",,2017
9c7ebd71d02ffc0463b92ff64663e600f120d018,https://www.semanticscholar.org/paper/9c7ebd71d02ffc0463b92ff64663e600f120d018,Road geometry estimation for urban semantic maps using open data,"Graphical Abstract Abstract Complex robotic tasks require the use of knowledge that cannot be acquired with the sensor repertoire of a mobile, autonomous robot alone. For robots navigating in urban environments, geospatial open data repositories such as OpenStreetMap (OSM) provide a source for such knowledge. We propose the integration of a 3D metric environment representation with the semantic knowledge from such a database. The application we describe uses street network information from OSM to improve street geometry information determined from laser data. This approach is evaluated on a challenging data-set of the Munich inner city.",Adv. Robotics,2017
b1b5407577ccbf9ffa686032306e9b9841165753,https://www.semanticscholar.org/paper/b1b5407577ccbf9ffa686032306e9b9841165753,Building Multiversal Semantic Maps for Mobile Robot Operation,"A probabilistic stance is proposed for tackling the symbol grounding problem.The outcome of such grounding is accommodated in a novel semantic map representation.This semantic map considers different interpretations of the robot workspace.A more coherent robot operation is achieved by exploring such interpretations.Our proposal has been assessed employing the Robot@Home dataset. Semantic maps augment metric-topological maps with meta-information, i.e. l semantic knowledge aimed at the planning and execution of high-level robotic tasks. Semantic knowledge typically encodes human-like concepts, like types of objects and rooms, which are connected to sensory data when symbolic representations of percepts from the robot workspace are grounded to those concepts. Such a symbol grounding is usually carried out by algorithms that individually categorize each symbol and provide a crispy outcome a symbol is either a member of a category or not. Such approach is valid for a variety of tasks, but it fails at: (i) dealing with the uncertainty inherent to the grounding process, and (ii) jointly exploiting the contextual relations among concepts (e.g. microwaves are usually in kitchens). This work provides a solution for probabilistic symbol grounding that overcomes these limitations. Concretely, we rely on Conditional Random Fields (CRFs) to model and exploit contextual relations, and to provide measurements about the uncertainty coming from the possible groundings in the form of beliefs (e.g. an object can be categorized (grounded) as a microwave or as a nightstand with beliefs 0.6 and 0.4, respectively). Our solution is integrated into a novel semantic map representation called Multiversal Semantic Map (MvSmap), which keeps the sets of different groundings, or universes, as instances of ontologies annotated with the obtained beliefs for their posterior exploitation. The suitability of our proposal has been proven with the Robot@Home dataset, a repository that contains challenging multi-modal sensory information gathered by a mobile robot in home environments.",Knowl. Based Syst.,2017
b55b11a37640a0e7c2b1a75edc3d930cb24c69b4,https://www.semanticscholar.org/paper/b55b11a37640a0e7c2b1a75edc3d930cb24c69b4,Industrial Big Data Analysis in Smart Factory: Current Status and Research Strategies,"Under the background of cyber-physical systems and Industry 4.0, intelligent manufacturing has become an orientation and produced a revolutionary change. Compared with the traditional manufacturing environments, the intelligent manufacturing has the characteristics as highly correlated, deep integration, dynamic integration, and huge volume of data. Accordingly, it still faces various challenges. In this paper, we summarize and analyze the current research status in both domestic and aboard, including industrial big data collection, modeling of the intelligent product lines based on ontology, the predictive diagnosis based on industrial big data, group learning of product line equipment and the product line reconfiguration of intelligent manufacturing. Based on the research status and the problems, we propose the research strategies, including acquisition schemes of industrial big data under the environment of intelligent, ontology modeling and deduction method based intelligent product lines, predictive diagnostic methods on production lines based on deep neural network, deep learning among devices based on cloud supplements and 3-D self-organized reconfiguration mechanism based on the supplements of cloud. In our view, this paper will accelerate the implementation of smart factory.",IEEE Access,2017
baa51a78a1af684a88dadf00ab0efc956fa1fd27,https://www.semanticscholar.org/paper/baa51a78a1af684a88dadf00ab0efc956fa1fd27,Learning from Internet: Handling Uncertainty in Robotic Environment Modeling,"Uncertainty is a great challenge for environment perception of autonomous robots. For instance, while building semantic maps (i.e., maps with semantic labels such as object names), the robot may encounter unexpected objects of which it has no knowledge. It will lead to inevitable failures in traditional environment modeling software. The abundant knowledge being accumulated on the Internet has the potential to assist robots to handle such kind of uncertainly. However, existing researches have not touched this issue yet. This paper proposes a cloud-based semantic mapping engine named SemaCloud, which can not only augment robot's environment modeling capability by the rich cloud resources but also cope with uncertainty by utilizing the Internet knowledge on necessary. It adopts a state-of-art Deep Neural Network (DNN) for real-time and accurate recognition of pre-trained objects. If an object is beyond the knowledge of this DNN, a special mechanism named QoS-aware cloud phase transition is triggered to seek help from existing recognition services on the Internet. By a set of carefully-designed algorithms, it can maximize benefits and minimize the negative impacts on the Quality of Service (QoS) properties of robotic applications, which is essential to many robot scenarios. The experiments on both open datasets and real robots show that our work can handle uncertainly successfully in robotic semantic mapping without sacrificing critical real-time constraints.",Internetware,2017
f18732ee87fa9f142ddcd11fc9cf41d1e5e2c593,https://www.semanticscholar.org/paper/f18732ee87fa9f142ddcd11fc9cf41d1e5e2c593,Architecture for incorporating Internet-of-Things sensors and actuators into robot task planning in dynamic environments,"Robots are being deployed in a wide range of smart environments that are equipped with sensors and actuators. These devices can provide valuable information beyond the perception range of a robot's on-board sensors, or provide additional actuators that can complement the robot's actuation abilities. Traditional robot task planners do not take these additional sensor and actuators abilities into account. This paper introduces an enhanced robotic planning framework which improves robots' ability to operate in dynamically changing environments. To keep planning time short, the amount of knowledge in the planner's world model is minimized.",2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS),2017
026caa591a702cbf0d1593b23c196e62bda352a6,https://www.semanticscholar.org/paper/026caa591a702cbf0d1593b23c196e62bda352a6,Performance evaluation of remote navigation with network delay for low-cost mobile robots,"In this paper, we discuss the effect of network delay on remote navigation for low-cost simple robots using cloud environments. First, we conduct the experiment of remote navigation using a robot simulator and show the result which does not navigate a robot adequately under the network condition with pseudo-delay. Then, from the result, we derive the necessity of the control model in considering network delay and design the delay-conscious control model in slowing the observation and quickening the control according to the predefined delay model.",2016 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI),2016
3a588186a7667827670e3ef4c0fcd5edda5eca58,https://www.semanticscholar.org/paper/3a588186a7667827670e3ef4c0fcd5edda5eca58,Extracting Semantic Information from Visual Data: A Survey,"The traditional environment maps built by mobile robots include both metric ones and topological ones. These maps are navigation-oriented and not adequate for service robots to interact with or serve human users who normally rely on the conceptual knowledge or semantic contents of the environment. Therefore, the construction of semantic maps becomes necessary for building an effective human-robot interface for service robots. This paper reviews recent research and development in the field of visual-based semantic mapping. The main focus is placed on how to extract semantic information from visual data in terms of feature extraction, object/place recognition and semantic representation methods.",Robotics,2016
446a82db766c7112b416a8019801f9e56d9eefb3,https://www.semanticscholar.org/paper/446a82db766c7112b416a8019801f9e56d9eefb3,Cloud robotics: Current status and open issues,"With the development of cloud computing, big data, and other emerging technologies, the integration of cloud technology and multi-robot systems makes it possible to design multi-robot systems with improved energy efficiency, high real-time performance, and low cost. In order to address the potential of clouds in enhancing robotics for industrial systems, this paper describes the basic concepts and development process of cloud robotics and the overall architecture of these systems. Then, the major driving forces behind the development of cloud robotics are carefully analyzed from the point of view of cloud computing, big data, open source resources, robot cooperative learning, and network connectivity. Subsequently, the key issues and challenges in the current cloud robotic systems are proposed, and some possible solutions are also given. Finally, the potential value of cloud robotic systems in different practical applications is discussed.",IEEE Access,2016
5a33b8f8292e4c38a355bd27bd5f3475240e49e0,https://www.semanticscholar.org/paper/5a33b8f8292e4c38a355bd27bd5f3475240e49e0,Cloud Robotics: Insight and Outlook,"With the development of cloud computing, big data and other emerging Technology, the integration of cloud technology and multi-robot system makes it possible to make the multi robot system with high performance and high complexity. This paper briefly describes the concept and development process of the cloud robot and the overall architecture of the cloud robot system. In this paper, the major elements of cloud robot are analyzed from the point of view of big data, cloud computing, open source resources and robot cooperative learning. The key problems to be solved in the current cloud robot system are proposed. Finally, we prospect the future development of the cloud robot.",,2016
5ddd67ce559efcf63f296e41e5a1cb53f339016a,https://www.semanticscholar.org/paper/5ddd67ce559efcf63f296e41e5a1cb53f339016a,Building semantic maps for blind people to navigate at home,"The traditional environment maps built by robots include both metric ones and topological ones. These maps are navigation-oriented and not adequate for service robots to interact with or serve human users who normally rely on conceptual knowledge or semantic contents of the environment. Therefore, the construction of semantic maps becomes necessary for building an effective human-robot interface for service robots. This paper aims to build a 3D environment map with an RGB-D sensor and extract semantic information from the RGB images to help blind people navigate at home. A novel approach is presented to diagnose and eliminate errors during semantic extraction.",2016 8th Computer Science and Electronic Engineering (CEEC),2016
5fd9f3fc869446b443c1a4520b3fb48f59de951d,https://www.semanticscholar.org/paper/5fd9f3fc869446b443c1a4520b3fb48f59de951d,Web Based Teleoperation of a Humanoid Robot,"The Cloud-based Advanced Robotics Laboratory (CARL) integrates a whole body controller and web-based teleoperation to enable any device with a web browser to access and control a humanoid robot. By integrating humanoid robots with the cloud, they are accessible from any Internet-connected device. Increased accessibility is important because few people have access to state-of-the-art humanoid robots limiting their rate of development. CARL's implementation is based on modern software libraries, frameworks, and middleware including Node.js, Socket.IO, ZMQ, ROS, Robot Web Tools, and ControlIt! Feasibility is demonstrated by having inexperienced human operators use a smartphone's web-browser to control Dreamer, a torque-controlled humanoid robot based on series elastic actuators, and make it perform a dual-arm manipulation task. The implementation serves as a proof-of-concept and foundation upon which many advanced humanoid robot technologies can be researched and developed.",ArXiv,2016
6da86d37ecb65dc3c6127a092806433f0a68f0da,https://www.semanticscholar.org/paper/6da86d37ecb65dc3c6127a092806433f0a68f0da,Industrial IoT Technologies and Applications,"This paper introduces the background of developing big data platform for telecom operators, and the benefits for telecom operators to using big data platform in some aspects that may improve forward and back changings. This document also presents a method of build big data platform using Hadoop according to the particularities of the data and systems in the telecom operators, and the implementation of this method in the internet department of a provincelevel telecom operator company.","Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering",2016
75d403ef1d52725c8fa39dad7858c8117573c4cf,https://www.semanticscholar.org/paper/75d403ef1d52725c8fa39dad7858c8117573c4cf,Semantic region estimation of assistant robot for the elderly long-term operation in indoor environment,"In this work, in order to improve spatial recognition abilities for the long-term operation tasks of the assistant robot for the elderly, a novel approach of semantic region estimation is proposed. We define a novel graph-based semantic region descriptions, which are estimated in a dynamically fashion. We propose a two-level update algorithm, namely, Symbols update level and Regions update level. The algorithm firstly adopts particle filter to update weights of the symbols, and then use the Viterbi algorithm to estimate the region the robot stays in based on those weights, optimally. Experimental results demonstrate that our proposed approach can solve problems of the long-term operation and kidnapped robot problem.",China Communications,2016
80910807801fe1197a3d2d6585b5fc7592ad048e,https://www.semanticscholar.org/paper/80910807801fe1197a3d2d6585b5fc7592ad048e,Leveraging Large-Scale Semantic Networks for Adaptive Robot Task Learning and Execution,"This work seeks to leverage semantic networks containing millions of entries encoding assertions of commonsense knowledge to enable improvements in robot task execution and learning. The specific application we explore in this project is object substitution in the context of task adaptation. Humans easily adapt their plans to compensate for missing items in day-to-day tasks, substituting a wrap for bread when making a sandwich, or stirring pasta with a fork when out of spoons. Robot plan execution, however, is far less robust, with missing objects typically leading to failure if the robot is not aware of alternatives. In this article, we contribute a context-aware algorithm that leverages the linguistic information embedded in the task description to identify candidate substitution objects without reliance on explicit object affordance information. Specifically, we show that the task context provided by the task labels within the action structure of a task plan can be leveraged to disambiguate information within a noisy large-scale semantic network containing hundreds of potential object candidates to identify successful object substitutions with high accuracy. We present two extensive evaluations of our work on both abstract and real-world robot tasks, showing that the substitutions made by our system are valid, accepted by users, and lead to a statistically significant reduction in robot learning time. In addition, we report the outcomes of testing our approach with a large number of crowd workers interacting with a robot in real time.",Big Data,2016
845c1a9a43924a5ac907861f3b98f8f32f009832,https://www.semanticscholar.org/paper/845c1a9a43924a5ac907861f3b98f8f32f009832,"Internet of Robotic Things: Concept, Technologies, and Challenges","Internet of Things allow massive number of uniquely addressable “things” to communicate with each other and transfer data over existing internet or compatible network protocols. This paper proposes a new concept which tackles the issues for supporting control and monitoring activities at deployment sites and industrial automations, where intelligent things can monitor peripheral events, induce sensor data acquired from a variety of sources, use ad hoc, local, and distributed “machine intelligence” to determine appropriate course of actions, and then act to control or disseminate static or dynamic position aware robotic things in the physical world through a seamless manner by providing a means for utilizing them as Internet of robotic things (IoRT). Although progressive advancements can be seen in multi-robotic systems, robots are constantly getting enriched by easier developmental functionalities, such vertical robotic service centric silos are not enough for continuously and seamlessly supporting for which they are meant. In this paper, a novel concept—IoRT is presented that highlights architectural principles, vital characteristics, as well as research challenges. The aim of this paper is to provide a better understanding of the architectural assimilation of IoRT and identify important research directions on this term.",IEEE Access,2016
ce4d9ef2c5befee2c33753c371a6441f1973b5ff,https://www.semanticscholar.org/paper/ce4d9ef2c5befee2c33753c371a6441f1973b5ff,"System for Creation, Programming and Availability of Distributed Robot Teams using Collective Knowledge","This paper addresses the problem of programming, control and availability of distributed robots teams. Systems based on robots working together collaboratively has been the subject of much research in recent years. Because the rapid spread of technologies in mobile devices and Internet, as well as the benefits that robotics adds to the various everyday applications, the trend is that more and more it is present in various activities of human beings. For distributed robots systems there is a latent need for research to enable the use of such systems by end users with no or almost no experience with programming or robotics. Thus, this paper proposes a system architecture that allows the creation and programming of robots teams, allowing and users to manage them as a single system and simple way using collective knowledge acquired both programmers as of the and users. The tests are performed by an application that was developed under the concepts of this architecture. It provides a set of special operations by which and users can connect, create and control robots teams at high level. The experiments use LEGO Mindstorms® robots as members of two robot teams. The process of creation, programming and control of the teams is presented in well defined steps. The results are satisfactory and show that the operating strategy of the proposed system meets fundamental aspects at the system level such as modularity, flexibility and ease of access for end users.",IEEE Latin America Transactions,2016
fed25a2c0a09fca602d0060a8d037054d4357d87,https://www.semanticscholar.org/paper/fed25a2c0a09fca602d0060a8d037054d4357d87,Using semantic maps for room recognition to aid visually impaired people,"Millions of people in the world suffer from vision impairment or even vision loss. Guide sticks and dogs have been deployed to lead them around various obstacles. However, both of them are not capable of interacting with human users who normally rely on conceptual knowledge or semantic contents of the environment. This paper first builds a 3D semantic indoor environment map with an RGB-D sensor. Then, the map is used for room recognition during the revisits based on appearance by applying a convolutional neural network. Representative objects extracted from the semantic map are used to diagnose and eliminate errors during room recognition. The proposed method result in a 97.8% accuracy even with lighting condition and small object location changes.",2016 22nd International Conference on Automation and Computing (ICAC),2016
026ec82b1fd695b02ae0e59dc1fc8fddb2b61666,https://www.semanticscholar.org/paper/026ec82b1fd695b02ae0e59dc1fc8fddb2b61666,Efficient Search for Known Objects in Unknown Environments Using Autonomous Indoor Robots,"We consider the problem of a robotic system searching for a specific object in an unmapped environment. We operate in a human environment, using a wheeled robot equipped with vision and distance sensors. The vision system is linked to a knowledge base containing object templates constructed from primitive geometric components, supporting recognition of objects. Given that some visual inputs may match several different objects, we build a multiple-hypothesis representation of the environment. These multiple hypotheses are used by a task planner to generate paths that avoid obstacles and explore areas where the target object might be. Plans also exploit behaviour to disambiguate the possible worlds in order to reduce anticipated future search effort. Replanning takes place when actions fail or when it becomes clear that the current plan will not find the target. In this case, the most recent knowledge of the environment will be used to direct exploration to the most useful parts of the search area. Experimental evaluation in simulation confirms the validity of our methods, and shows decreased time to find the target compared with a reactive system which explores the area greedily based on estimates of the expected increase in area viewed.",,2015
1d8e137d4e91c27b1ebd2c4fe0936fb1f47b537b,https://www.semanticscholar.org/paper/1d8e137d4e91c27b1ebd2c4fe0936fb1f47b537b,A proposal for semantic map representation and evaluation,"Semantic mapping is the incremental process of “mapping” relevant information of the world (i.e., spatial information, temporal events, agents and actions) to a formal description supported by a reasoning engine. Current research focuses on learning the semantic of environments based on their spatial location, geometry and appearance. Many methods to tackle this problem have been proposed, but the lack of a uniform representation, as well as standard benchmarking suites, prevents their direct comparison. In this paper, we propose a standardization in the representation of semantic maps, by defining an easily extensible formalism to be used on top of metric maps of the environments. Based on this, we describe the procedure to build a dataset (based on real sensor data) for benchmarking semantic mapping techniques, also hypothesizing some possible evaluation metrics. Nevertheless, by providing a tool for the construction of a semantic map ground truth, we aim at the contribution of the scientific community in acquiring data for populating the dataset.",2015 European Conference on Mobile Robots (ECMR),2015
4d9351c8c32e530b2acf5186c974c471ec46175a,https://www.semanticscholar.org/paper/4d9351c8c32e530b2acf5186c974c471ec46175a,Workshop on Task Planning for Intelligent Robots in Service and Manufacturing,"Automated task planning for robots is usually implemented on a motion primitive domain, where the focus is on constructing meaningful, general motion primitives. In this work we propose planning on the higher abstraction level of robot skills. In this context, skills are general, functional blocks that contain both sensing and action, have a welldefined expected outcome and set of preconditions, and are thus immediately useful for planning. By using a world model, which is focused on the skills, we show that this is in fact the case. We show automated task planning and execution, as a sequence of skills and their parameters, based on the desired goal state and the current state from the world model. Experiments show that the approach is immediately applicable, given a skill-equipped robot, and that inconsistencies between the world model and physical world are overcome simply by replanning.",,2015
6f9fc6214b8e3c62f7669430743c61ba64f29192,https://www.semanticscholar.org/paper/6f9fc6214b8e3c62f7669430743c61ba64f29192,A Survey of Research on Cloud Robotics and Automation,"The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowdsourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation systems by providing access to: a) datasets, publications, models, benchmarks, and simulation tools; b) open competitions for designs and systems; and c) open-source software. This survey includes over 150 references on results and open challenges. A website with new developments and updates is available at: http://goldberg.berkeley.edu/cloud-robotics/.",IEEE Transactions on Automation Science and Engineering,2015
e645fb499e47bf34e82448e737d0ce7aca7c4722,https://www.semanticscholar.org/paper/e645fb499e47bf34e82448e737d0ce7aca7c4722,Augmenting and reasoning in semantically enriched maps using open data,"—Complex robotic tasks require the use of knowledge that cannot be aquired with the sensor repertoire of a mobile, autonomous robot alone. For robots navigating in urban environments, geospatial open data repositories such as OpenStreetMap provide a source for auch knowledge. We propose the integration of a 3D metric environment representation with the semantic knowledge from such a data base, and describe an application where road network information fromOpenStreetMapisusedtoimproveroadgeometry informationdeterminedfromlaserdata.Thisapproach is evaluated on a challenging data set of the Munich inner city.",,2015
f93f4b617bc453a8c7d0891c3c6599a653541f2c,https://www.semanticscholar.org/paper/f93f4b617bc453a8c7d0891c3c6599a653541f2c,"Crop-planning, making smarter agriculture with climate data","Agriculture has an important tradition in Latin America and large areas have maintained stable conditions for decades with constant practices and yield. Planning processes in those areas have not suffered any change for years and some countries like Colombia have not modified its rural policies in the last three of four decades; on the other hand, natural and environmental conditions have changed dramatically in the last years as a consequence of climate change and climate variability modifying established practices for traditional crops. Since farmers have suffered several effects on its production process they have realized the importance of supporting future actions on reliable climate data, scientific development have also grown in last decades and planning offices are looking for better practices, today' scientists and planning offices are trying to link all this reality in a new paradigm called “Climate Smart Agriculture”. The Research program on Climate Change, Agriculture and Food Security - CCAFS follows this interest of linking its research results with open data sources, software developers and Latin American problems therefore in 2014 they performed a hackathon in Lima to develop new applications that help farmers to support their decision on scientific information. “Crop-planning” is one product designed and developed at CCAFS's hackathon conceived as a worldwide platform for sharing and sowing crop calendars and agro-climate data, it compiles open dataset like historical production, land cover, local climate conditions and integrates an interface for crowdsourced collection of dates of agricultural activities, it is designed to offer easy access to relevant data and updated crop calendars from farmers and also share management practices from local authorities. Although it is farmer oriented, principal users are technical assistants that deal with the application and share knowledge with farmers, they will use their experience to warranty knowledge management and overcome technical difficulties of web and mobile platforms in rural areas.",2015 Fourth International Conference on Agro-Geoinformatics (Agro-geoinformatics),2015
008a8e8bac5d207c912d9bb5d29774d252761844,https://www.semanticscholar.org/paper/008a8e8bac5d207c912d9bb5d29774d252761844,Evaluation and Quality Assurance of Fog Computing-Based IoT for Health Monitoring System,"Computation and data sensitivity are the metrics of the current Internet of Things (IoT). In cloud data centers, current analytics are often hosted and reported on suffering from high congestion, limited bandwidth, and security mechanisms. Various platforms are developed in the area of fog computing and thus implemented and assessed to run analytics on multiple devices, including IoT devices, in a distributed way. Fog computing advances the paradigm of cloud computing on the network edge, introducing a number of options and facilities. Fog computing enhances the processing, verdicts, and interventions to occur through IoT devices and spreads only the necessary details. The ideas of fog computing based on IoT in healthcare frameworks are exploited by shaping the disseminated delegate layer of insight between sensor hubs and the cloud. The cloud proposed a system adapted to overcome various challenges in omnipresent medical services frameworks, such as portability, energy efficiency, adaptability, and unwavering quality issues, by accepting the right to take care of certain weights of the sensor network and a distant medical service group. An overview of e-health monitoring system in the context of testing and quality assurance of fog computing is presented in this paper. Relevant papers were analyzed in a comprehensive way for the identification of relevant information. The study has compiled contributions of the existing methodologies, methods, and approaches in fog computing e-healthcare.",Wirel. Commun. Mob. Comput.,2021
103ffa04cdaeb9e6dd107a1321118a1fd0c5932a,https://www.semanticscholar.org/paper/103ffa04cdaeb9e6dd107a1321118a1fd0c5932a,Fog Computing in Healthcare: A Review,"The Internet of things (IoT) connects multiple devices worldwide. It is a growing field in the healthcare system such as health monitoring and tracking, fitness program, and remote medical assistance. With the advent of IoT based technologies in healthcare, it can alleviate the pressure on healthcare systems and can reduce the healthcare cost, and increase the computing and processing speed. Cloud computing was introduced to manage larger and complex healthcare data in the IoT environment. Cloud computing uses centralized cloud data centers. The central server manages the data for all the IoT devices. The integration of IoT with the cloud has some major issues such as latency, bandwidth overuse, real-time response delays, protection, and privacy. So the concept of edge computing and fog computing came into existence to overcome these issues. This paper review the IoT-Fog-based system model architectures, similar paradigm, issues, and difficulties in the area of cloud computing and finally, the performance of some of these proposed systems is assessed using the iFogSim simulator.",,2021
1d2a680bbf8591f4c58d77f1fdee3f320f27cc9c,https://www.semanticscholar.org/paper/1d2a680bbf8591f4c58d77f1fdee3f320f27cc9c,Multi-Oriented Run Length Based Static and Dynamic Features Fused with Choquet Fuzzy Integral for Human Fall Detection in Videos,,Journal of Visual Communication and Image Representation,2021
754c5bbbd720c7079157e151f270b44ed62f6ea8,https://www.semanticscholar.org/paper/754c5bbbd720c7079157e151f270b44ed62f6ea8,Application of IoT‐Fog based real‐time monitoring system for open‐cast mines—A survey,,,2021
81804d7e422785f90e6ebf08c7f0c0b5b5851da5,https://www.semanticscholar.org/paper/81804d7e422785f90e6ebf08c7f0c0b5b5851da5,UI-GAN: Generative Adversarial Network-Based Anomaly Detection Using User Initial Information for Wearable Devices,"This article proposes an automatic fall detection method for a wearable device that can promptly alert caregivers when a fall is detected, which could reduce the injuries of elder people. To do this, we propose a novel generative adversarial network (GAN-) based fall detection method using a heart rate sensor and an accelerometer. Acquiring fall data compared with normal behavioral data can be an arduous process. Instead, we introduce a compelling GAN-based anomaly detection partially surrounded with User Initial information features (UI-GAN). Although GAN-based anomaly detection methods have been previously proposed, each model has its adequate suitability for each anomaly detection application. Therefore, this study firstly evaluates suitable GAN-based anomaly detection models for fall detection from among nine recently proposed GAN-based models. From UI-GAN, performance improvements are observed in the fall detection when using the UI information. To objectively demonstrate the competitive performance of UI-GAN, we compare it with eight other recently presented fall detection studies and have observed that it leads to better results. Lastly, since the target application in this study is the use of UI-GAN with a wearable device, the sufficiently satisfied latency of UI-GAN on the smartwatch is estimated. This study is the first attempt to use the initial information of users in GAN, and we hope that the effectiveness of the UI information is expected to be seen in other applications.",IEEE Sensors Journal,2021
aaaac73f2b711793c1993b71323614cbe244a27d,https://www.semanticscholar.org/paper/aaaac73f2b711793c1993b71323614cbe244a27d,A Study of Fall Detection in Assisted Living: Identifying and Improving the Optimal Machine Learning Method,"This paper makes four scientific contributions to the field of fall detection in the elderly to contribute to their assisted living in the future of Internet of Things (IoT)-based pervasive living environments, such as smart homes. First, it presents and discusses a comprehensive comparative study, where 19 different machine learning methods were used to develop fall detection systems, to deduce the optimal machine learning method for the development of such systems. This study was conducted on two different datasets, and the results show that out of all the machine learning methods, the k-NN classifier is best suited for the development of fall detection systems in terms of performance accuracy. Second, it presents a framework that overcomes the limitations of binary classifier-based fall detection systems by being able to detect falls and fall-like motions. Third, to increase the trust and reliance on fall detection systems, it introduces a novel methodology based on the usage of k-folds cross-validation and the AdaBoost algorithm that improves the performance accuracy of the k-NN classifier-based fall detection system to the extent that it outperforms all similar works in this field. This approach achieved performance accuracies of 99.87% and 99.66%, respectively, when evaluated on the two datasets. Finally, the proposed approach is also highly accurate in detecting the activity of standing up from a lying position to infer whether a fall was followed by a long lie, which can cause minor to major health-related concerns. The above contributions address multiple research challenges in the field of fall detection, that we identified after conducting a comprehensive review of related works, which is also presented in this paper.",J. Sens. Actuator Networks,2021
ea97175d7bfabb77239abbff142d679171dc3f24,https://www.semanticscholar.org/paper/ea97175d7bfabb77239abbff142d679171dc3f24,"Ambient Assisted Living: A Review of Technologies, Methodologies and Future Perspectives for Healthy Aging of Population","Over the last decade, there has been considerable and increasing interest in the development of Active and Assisted Living (AAL) systems to support independent living. The demographic change towards an aging population has introduced new challenges to today’s society from both an economic and societal standpoint. AAL can provide an arrary of solutions for improving the quality of life of individuals, for allowing people to live healthier and independently for longer, for helping people with disabilities, and for supporting caregivers and medical staff. A vast amount of literature exists on this topic, so this paper aims to provide a survey of the research and skills related to AAL systems. A comprehensive analysis is presented that addresses the main trends towards the development of AAL systems both from technological and methodological points of view and highlights the main issues that are worthy of further investigation.",Sensors,2021
0727c772d0f0389c29d3269ee4e4dc9cb2b1d568,https://www.semanticscholar.org/paper/0727c772d0f0389c29d3269ee4e4dc9cb2b1d568,CNN-Based Fall Detection Strategy with Edge Computing Scheduling in Smart Cities,"The livelihood problem, especially the medical wisdom, has played an important role during the process of the building of smart cities. For the medical wisdom, the fall detection has attracted the considerable attention from the global researchers and medical institutions. It is very difficult for the traditional fall detection strategies to realize the intelligent detection with the following three reasons: (i) the data collection cannot reach the real-time level; (ii) the adopted detection methods cannot satisfy the enough stability; and (iii) the computation overhead of collection device is very high, which causes the barely satisfactory detection effect. Therefore, this paper proposes Convolutional Neural Network (CNN)-based fall detection strategy with edge computing consideration, where the global network view ability of Software-Defined Networking (SDN) is used to collect the generated data from smartphone. Meanwhile, on one hand, the edge computing is exploited to put some computation tasks at the edge server by the scheduling technique. On the other hand, CNN is equipped with both edge server and smartphone, and it is leveraged to train the related data and further give the guidance of fall detection. The experimental results show that the novel fall detection strategy has a more accurate rate, transmission delay, and stability than two cutting-edge strategies.",,2020
8070a703cc8aa98c8cd0aee24a597903154cf9c3,https://www.semanticscholar.org/paper/8070a703cc8aa98c8cd0aee24a597903154cf9c3,Smart Environments and Social Robots for Age-Friendly Integrated Care Services,"The world is facing major societal challenges because of an aging population that is putting increasing pressure on the sustainability of care. While demand for care and social services is steadily increasing, the supply is constrained by the decreasing workforce. The development of smart, physical, social and age-friendly environments is identified by World Health Organization (WHO) as a key intervention point for enabling older adults, enabling them to remain as much possible in their residences, delay institutionalization, and ultimately, improve quality of life. In this study, we survey smart environments, machine learning and robot assistive technologies that can offer support for the independent living of older adults and provide age-friendly care services. We describe two examples of integrated care services that are using assistive technologies in innovative ways to assess and deliver of timely interventions for polypharmacy management and for social and cognitive activity support in older adults. We describe the architectural views of these services, focusing on details about technology usage, end-user interaction flows and data models that are developed or enhanced to achieve the envisioned objective of healthier, safer, more independent and socially connected older people.",International journal of environmental research and public health,2020
6eb60dfe9bfaf886a124f73fe9fb1bae2232ef95,https://www.semanticscholar.org/paper/6eb60dfe9bfaf886a124f73fe9fb1bae2232ef95,Adoption of machine learning technology for failure prediction in industrial maintenance: A systematic review,"Abstract Failure prediction is the task of forecasting whether a material system of interest will fail at a specific point of time in the future. This task attains significance for strategies of industrial maintenance, such as predictive maintenance. For solving the prediction task, machine learning (ML) technology is increasingly being used, and the literature provides evidence for the effectiveness of ML-based prediction models. However, the state of recent research and the lessons learned are not well documented. Therefore, the objective of this review is to assess the adoption of ML technology for failure prediction in industrial maintenance and synthesize the reported results. We conducted a systematic search for experimental studies in peer-reviewed outlets published from 2012 to 2020. We screened a total of 1,024 articles, of which 34 met the inclusion criteria. We focused on understanding the datasets analyzed, the preprocessing to generate features, and the training and evaluation of prediction models. The results reveal (1) a broad range of systems and domains addressed, (2) the adoption of up-to-date approaches to preprocessing and training, (3) some lack of performance evaluation mitigating the overfitting problem, and (4) considerable heterogeneity in the reporting of experimental designs and results. We identify opportunities for future research and suggest ways to facilitate the comparison and integration of evidence obtained from single studies.",Journal of Manufacturing Systems,2021
228552ed3578ff988ba13b1b607ba9b141bd730e,https://www.semanticscholar.org/paper/228552ed3578ff988ba13b1b607ba9b141bd730e,SSD-EMB: An Improved SSD Using Enhanced Feature Map Block for Object Detection,"The development of deep learning has achieved great success in object detection, but small object detection is still a difficult and challenging task in computer vision. To address the problem, we propose an improved single-shot multibox detector (SSD) using enhanced feature map blocks (SSD-EMB). The enhanced feature map block (EMB) consists of attention stream and feature map concatenation stream. The attention stream allows the proposed model to focus on the object regions rather than background owing to channel averaging and the effectiveness of the normalization. The feature map concatenation stream provides additional semantic information to the model without degrading the detection speed. By combining the output of these two streams, the enhanced feature map, which improves the detection of a small object, is generated. Experimental results show that the proposed model has high accuracy in small object detection. The proposed model not only achieves good detection accuracy, but also has a good detection speed. The SSD-EMB achieved a mean average precision (mAP) of 80.4% on the PASCAL VOC 2007 dataset at 30 frames per second on an RTX 2080Ti graphics processing unit, an mAP of 79.9% on the VOC 2012 dataset, and an mAP of 26.6% on the MS COCO dataset.",Sensors,2021
02d4e18bc3677be373ff3f31c4a5702cb4e1f520,https://www.semanticscholar.org/paper/02d4e18bc3677be373ff3f31c4a5702cb4e1f520,Pre-trained Language Models in Biomedical Domain: A Survey fromMultiscale Perspective,1,,2021
0c4e7243e5d28bfdbb7cfbc0d523f7fc6e572733,https://www.semanticscholar.org/paper/0c4e7243e5d28bfdbb7cfbc0d523f7fc6e572733,redBERT: A Topic Discovery and Deep SentimentClassification Model on COVID-19 OnlineDiscussions Using BERT NLP Model,"A Natural Language Processing (NLP) method was used to uncover various issues and sentiments surrounding COVID-19 from social media and get a deeper understanding of fluctuating public opinion in situations of wide-scale panic to guide improved decision making with the help of a sentiment analyser created for the automated extraction of COVID-19 related discussions based on topic modelling. Moreover, the BERT model was used for the sentiment classification of COVID-19 Reddit comments. These findings shed light on the importance of studying trends and using computational techniques to assess human psyche in times of distress.",medRxiv,2021
0cea4db3dea404ed55b3a179b496357dc5c8ff80,https://www.semanticscholar.org/paper/0cea4db3dea404ed55b3a179b496357dc5c8ff80,Pre-trained Language Models in Biomedical Domain: A Systematic Survey,1,ArXiv,2021
1e2cfba04ee527c353859387356ba2c039857316,https://www.semanticscholar.org/paper/1e2cfba04ee527c353859387356ba2c039857316,"Physical activity, sedentary behaviour, and sleep on Twitter: A multicountry and fully labelled dataset for public health surveillance research (Preprint)"," BACKGROUND Advances in automated data processing and machine learning (ML) models, together with the unprecedented growth in the number of social media users who publicly share and discuss health-related information, have made public health surveillance (PHS) one of the long-lasting social media applications. However, the existing PHS systems feeding on social media data have not been widely deployed in national surveillance systems, which appears to stem from the lack of practitioners and the public’s trust in social media data. More robust and reliable datasets over which supervised machine learning models can be trained and tested reliably is a significant step toward overcoming this hurdle. OBJECTIVE The health implications of daily behaviours (physical activity, sedentary behaviour, and sleep (PASS)), as an evergreen topic in PHS, are widely studied through traditional data sources such as surveillance surveys and administrative databases, which are often several months out of date by the time they are utilized, costly to collect, and thus limited in quantity and coverage. In this paper, we present LPHEADA, a multicountry and fully Labelled digital Public HEAlth DAtaset of tweets originated in Australia, Canada, the United Kingdom (UK), or the United States (US). METHODS We collected the data of this study from Twitter using the Twitter livestream application programming interface (API) between 28th November 2018 to 19th June 2020. To obtain PASS-related tweets for manual annotation, we iteratively used regular expressions, unsupervised natural language processing, domain-specific ontologies and linguistic analysis. We used Amazon Mechanical Turk (AMT) to label the collected data to self-reported PASS categories and implemented a quality control pipeline to monitor and manage the validity of crow-generated labels. Moreover, we used ML, latent semantic analysis, linguistic analysis, and label inference analysis to validate different components of the dataset. RESULTS LPHEADA contains 366,405 crowd-generated labels (three labels per tweet) for 122,135 PASS-related tweets, labelled by 708 unique annotators on AMT. In addition to crowd-generated labels, LPHEADA provides details about the three critical components of any PHS system: place, time, and demographics (gender, age range) associated with each tweet. CONCLUSIONS Publicly available datasets for digital PASS surveillance are usually isolated and only provide labels for small subsets of the data. We believe that the novelty and comprehensiveness of the dataset provided in this study will help develop, evaluate, and deploy digital PASS surveillance systems. LPHEADA will be an invaluable resource for both public health researchers and practitioners.",,2021
43d34b287faa3240fc83c9ebd94251a2658bd110,https://www.semanticscholar.org/paper/43d34b287faa3240fc83c9ebd94251a2658bd110,Task unit bid- spatial coverage and post input density (TUBSC_PID) based crowd sourcing network,"A huge number of items are associated with the Internet of Things (IoT) which is fixed with software, electronics and sensors. It has a wide variety of applications, namely smart homes, smart grids and smart cities. The sensor devices combine with Internet of Things (IoT) operates as robot system to execute data collection task. The IoT control objects, sense devices and gathers data. In crowd sourcing network there are two main issues, namely to guarantee the Quality of Service (QoS) of tasks and to reduce the data collection cost. There is also some problems arise between the task circulator and the data reporter in terms of profit. Since, IoT sensing devices have increased a lot, the relationship for finishing the task is very much important. In this paper, a novel framework called Task Unit Bit-based Spatial Coverage and Post Input density (TUBSC_PID) has been proposed. The input density is applied to estimate the contribution of a single data collector to a particular sensing task. A Task Unit Bid-based task selection strategy is proposed to choose the task which provides more contribution density and higher profit to the system. A novel spatial coverage technique is also applied to cover all the information obtained from the data collector. The present and post input density is applied to estimate the contribution of a single data collector to a particular sensing task as well as future sensing tasks. This method reduces the cost of data selection and maximizes the system profit. Experimental results predict that compared to the traditional techniques, namely Random Task selection with Input Density Reporter selection (RTCDR) and Collaborative Multi-Tasks Data Collection Scheme (CMDCS), the profit of the system is improved by 96.1%.",Multim. Tools Appl.,2020
67eda330b15dbb5c855c6be0cdb7bf867592c488,https://www.semanticscholar.org/paper/67eda330b15dbb5c855c6be0cdb7bf867592c488,A graph-based approach for population health analysis using Geo-tagged tweets,"We propose in this work a graph-based approach for automatic public health analysis using social media. In our approach, graphs are created to model the interactions between features and between tweets in social media. We investigated different graph properties and methods in constructing graph-based representations for population health analysis. The proposed approach is applied in two case studies: (1) estimating health indices, and (2) classifying health situation of counties in the US. We evaluate our approach on a dataset including more than one billion tweets collected in three years 2014, 2015, and 2016, and the health surveys from the Behavioral Risk Factor Surveillance System. We conducted realistic and large-scale experiments on various textual features and graph-based representations. Experimental results verified the robustness of the proposed approach and its superiority over existing ones in both case studies, confirming the potential of graph-based approach for modeling interactions in social networks for population health analysis.",Multim. Tools Appl.,2020
94a22e443caa92b6165b263e221b49e8a526eeec,https://www.semanticscholar.org/paper/94a22e443caa92b6165b263e221b49e8a526eeec,"Physical activity, sedentary behaviour, and sleep on Twitter: A labelled dataset for public health research","Advances in automated data processing, together with the unprecedented growth in user-generated social media (SM) content, have made public health surveillance (PHS) one of the long-lasting SM applications. However, the existing PHS systems feeding on SM data have not been widely deployed in national surveillance systems, which appears to stem from the lack of practitioners' trust in SM data. More robust datasets over which machine learning (ML) models can be trained/tested reliably is a significant step toward overcoming this hurdle. The health implications of physical activity, sedentary behaviour, and sleep (PASS) are widely studied through traditional data sources, which are often out-of-date, costly to collect, and thus limited in quantity and coverage. We present LPHEADA, a multicountry and fully Labelled digital Public HEAlth DAtaset of tweets originated in Australia/Canada/United Kingdom/United States between November 2018-June 2020. LPHEADA contains 366,405 labels for 122,135 PASS-related tweets and provides details about the place/time/demographics associated with each tweet. LPHEADA is publicly available and can be utilized to develop (un)supervised ML models for digital PASS surveillance.",medRxiv,2021
97b8d6ea1ca95652dc26863a159c8909cbf80e63,https://www.semanticscholar.org/paper/97b8d6ea1ca95652dc26863a159c8909cbf80e63,Digital bioethics: introducing new methods for the study of bioethical issues,"The online space has become a digital public square, where individuals interact and share ideas on the most trivial to the most serious of matters, including discussions of controversial ethical issues in science, technology and medicine. In the last decade, new disciplines like computational social science and social data science have created methods to collect and analyse such data that have considerably expanded the scope of social science research. Empirical bioethics can benefit from the integration of such digital methods to investigate novel digital phenomena and trace how bioethical issues take shape online. Here, using concrete examples, we demonstrate how novel methods based on digital approaches in the social sciences can be used effectively in the domain of bioethics. We show that a digital turn in bioethics research aligns with the established aims of empirical bioethics, integrating with normative analysis and expanding the scope of the discipline, thus offering ways to reinforce the capacity of bioethics to tackle the increasing complexity of present-day ethical issues in science and technology. We propose to call this domain of research in bioethics digital bioethics.",Journal of medical ethics,2021
a6df0cdd1a9e1dbd720219227156f8bed07e93e8,https://www.semanticscholar.org/paper/a6df0cdd1a9e1dbd720219227156f8bed07e93e8,Citizen science and online data: Opportunities and challenges for snake ecology and action against snakebite,"The secretive behavior and life history of snakes makes studying their biology, distribution, and the epidemiology of venomous snakebite challenging. One of the most useful, most versatile, and easiest to collect types of biological data are photographs, particularly those that are connected with geographic location and date-time metadata. Photos verify occurrence records, provide data on phenotypes and ecology, and are often used to illustrate new species descriptions, field guides and identification keys, as well as in training humans and computer vision algorithms to identify snakes. We scoured eleven online and two offline sources of snake photos in an attempt to collect as many photos of as many snake species as possible, and attempt to explain some of the inter-species variation in photograph quantity among global regions and taxonomic groups, and with regard to medical importance, human population density, and range size. We collected a total of 725,565 photos—between 1 and 48,696 photos of 3098 of the world's 3879 snake species (79.9%), leaving 781 “most wanted” species with no photos (20.1% of all currently-described species as of the December 2020 release of The Reptile Database). We provide a list of most wanted species sortable by family, continent, authority, and medical importance, and encourage snake photographers worldwide to submit photos and associated metadata, particularly of “missing” species, to the most permanent and useful online archives: The Reptile Database, iNaturalist, and HerpMapper.",Toxicon: X,2021
afee77467b99472c69c2e9b62175755505c16d1e,https://www.semanticscholar.org/paper/afee77467b99472c69c2e9b62175755505c16d1e,Qualitative analysis of visual risk communication on twitter during the Covid-19 pandemic,"Background The Covid-19 pandemic is characterized by uncertainty and constant change, forcing governments and health authorities to ramp up risk communication efforts. Consequently, visuality and social media platforms like Twitter have come to play a vital role in disseminating prevention messages widely. Yet to date, only little is known about what characterizes visual risk communication during the Covid-19 pandemic. To address this gap in the literature, this study’s objective was to determine how visual risk communication was used on Twitter to promote the World Health Organisations (WHO) recommended preventative behaviours and how this communication changed over time. Methods We sourced Twitter’s 500 most retweeted Covid-19 messages for each month from January–October 2020 using Crowdbreaks. For inclusion, tweets had to have visuals, be in English, come from verified accounts, and contain one of the keywords ‘covid19’, ‘coronavirus’, ‘corona’, or ‘covid’. Following a retrospective approach, we then performed a qualitative content analysis of the 616 tweets meeting inclusion criteria. Results Our results show communication dynamics changed over the course of the pandemic. At the start, most retweeted preventative messages came from the media and health and government institutions, but overall, personal accounts with many followers (51.3%) predominated, and their tweets had the highest spread (10.0%, i.e., retweet count divided by followers). Messages used mostly photographs and images were found to be rich with information. 78.1% of Tweets contained 1–2 preventative messages, whereby ‘stay home’ and ‘wear a mask’ frequented most. Although more tweets used health loss framing, health gain messages spread more. Conclusion Our findings can inform the didactics of future crisis communication. The results underscore the value of engaging individuals, particularly influencers, as advocates to spread health risk messages and promote solidarity. Further, our findings on the visual characteristic of the most retweeted tweets highlight factors that health and government organisations should consider when creating visual health messages for Twitter. However, that more tweets used the emotive medium of photographs often combined with health loss framing raises concerns about persuasive tactics. More research is needed to understand the implications of framing and its impact on public perceptions and behaviours.",BMC Public Health,2021
b58f6f75e8b6f1272ac264a1ad61f4c2bed40b43,https://www.semanticscholar.org/paper/b58f6f75e8b6f1272ac264a1ad61f4c2bed40b43,Evaluating the motivation of Red Cross Health volunteers in the COVID-19 pandemic: a mixed-methods study protocol,"Introduction Voluntary organisations provide essential support to vulnerable populations and front-line health responders to the COVID-19 pandemic. The French Red Cross (FRC) is prominent among organisations offering health and support services in the current crisis. Comprised primarily of lay volunteers and some trained health workers, FRC volunteers in the Paris (France) region have faced challenges in adapting to pandemic conditions, working with sick and vulnerable populations, managing limited resources and coping with high demand for their services. Existing studies of volunteers focus on individual, social and organisational determinants of motivation, but attend less to contextual ones. Public health incertitude about the COVID-19 pandemic is an important feature of this pandemic. Whether and how uncertainty interacts with volunteer understandings and experiences of their work and organisational relations to contribute to Red Cross worker motivation is the focus of this investigation. Methods and analysis This mixed-methods study will investigate volunteer motivation using ethnographic methods and social network listening. Semi-structured interviews and observations will illuminate FRC volunteer work relations, experiences and concerns during the pandemic. A questionnaire targeting a sample of Paris region volunteers will allow quantification of motivation. These findings will iteratively shape and be influenced by a social media (Twitter) analysis of biomedical and public health uncertainties and debates around COVID-19. These tweets provide insight into a French lay public’s interpretations of these debates. We evaluate whether and how socio-political conditions and discourses concerning COVID-19 interact with volunteer experiences, working conditions and organisational relations to influence volunteer motivation. Data collection began on 15 June 2020 and will continue until 15 April 2021. Ethics and dissemination The protocol has received ethical approval from the Institut Pasteur Institutional Review Board (no 2020-03). We will disseminate findings through peer-reviewed articles, conference presentations and recommendations to the FRC.",BMJ Open,2021
b6fdddfd5c89f654c98da4940198fdf114d18f22,https://www.semanticscholar.org/paper/b6fdddfd5c89f654c98da4940198fdf114d18f22,Clusters of science and health related Twitter users become more isolated during the COVID-19 pandemic,"COVID-19 represents the most severe global crisis to date whose public conversation can be studied in real time. To do so, we use a data set of over 350 million tweets and retweets posted by over 26 million English speaking Twitter users from January 13 to June 7, 2020. We characterize the retweet network to identify spontaneous clustering of users and the evolution of their interaction over time in relation to the pandemic’s emergence. We identify several stable clusters (super-communities), and are able to link them to international groups mainly involved in science and health topics, national elites, and political actors. The science- and health-related super-community received disproportionate attention early on during the pandemic, and was leading the discussion at the time. However, as the pandemic unfolded, the attention shifted towards both national elites and political actors, paralleled by the introduction of country-specific containment measures and the growing politicization of the debate. Scientific super-community remained present in the discussion, but experienced less reach and became more isolated within the network. Overall, the emerging network communities are characterized by an increased self-amplification and polarization. This makes it generally harder for information from international health organizations or scientific authorities to directly reach a broad audience through Twitter for prolonged time. These results may have implications for information dissemination along the unfolding of long-term events like epidemic diseases on a world-wide scale.",Scientific reports,2020
cee25c70f2d17057dcb15928fcd996c0f70cd807,https://www.semanticscholar.org/paper/cee25c70f2d17057dcb15928fcd996c0f70cd807,Winds of Change: Impact of COVID-19 on Vaccine-related Opinions of Twitter users,"Administering COVID-19 vaccines at a societal scale has been deemed as the most appropriate way to defend against the COVID-19 pandemic. This global vaccination drive naturally fueled a possibility of Pro-Vaxxers and Anti-Vaxxers strongly expressing their supports and concerns regarding the vaccines on social media platforms. Understanding this online discourse is crucial for policy makers. This understanding is likely to impact the success of vaccination drives and might even impact the final outcome of our fight against the pandemic. The goal of this work is to improve this understanding using the lens of Twitter-discourse data. We first develop a classifier that categorizes users according to their vaccine-related stance with high precision (97%). Using this method we detect and investigate specific user-groups who posted about vaccines in pre-COVID and COVID times. Specifically, we identify distinct topics that these users talk about, and investigate how vaccine-related discourse has changed between pre-COVID times and COVID times. Finally, for the first time, we investigate the change of vaccine-related stances in Twitter users and shed light on potential reasons for such changes in stance. Our dataset and classifier are available at https://github.com/sohampoddar26/covid-vax-stance.",ArXiv,2021
d0b7deb6f97f4fa01fb682c08b770aab53422ba3,https://www.semanticscholar.org/paper/d0b7deb6f97f4fa01fb682c08b770aab53422ba3,redBERT: A topic discovery and deep sentiment classification model on COVID-19 online discussions using BERT NLP model,"A natural language processing (NLP) method was used to uncover various issues and sentiments surrounding COVID-19 from social media and get a deeper understanding of fluctuating public opinion in situations of wide-scale panic to guide improved decision making with the help of a sentiment analyser created for the automated extraction of COVID-19-related discussions based on topic modelling. Moreover, the BERT model was used for the sentiment classification of COVID-19 Reddit comments. These findings shed light on the importance of studying trends and using computational techniques to assess the human psyche in times of distress. Copyright © 2021, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",,2021
dfc41c1241df328169c4829a056a3d05f97c01fc,https://www.semanticscholar.org/paper/dfc41c1241df328169c4829a056a3d05f97c01fc,Deep Learning for Sentiment Analysis,"Sentiment analysis is an important area of natural language processing that can help inform business decisions by extracting sentiment information from documents. The purpose of this chapter is to introduce the reader to selected concepts and methods of deep learning and show how deep models can be used to increase performance in sentiment analysis. It discusses the latest advances in the field and covers topics including traditional sentiment analysis approaches, the fundamentals of sentence modelling, popular neural network architectures, autoencoders, attention modelling, transformers, data augmentation methods, the benefits of transfer learning, the potential of adversarial networks, and perspectives on explainable AI. The authors' intent is that through this chapter, the reader can gain an understanding of recent developments in this area as well as current trends and potentials for future research.",,2021
f48e6066aa7312adeeb8dcf2eec89c4ffd6630d9,https://www.semanticscholar.org/paper/f48e6066aa7312adeeb8dcf2eec89c4ffd6630d9,"Physical activity, sedentary behaviour, and sleep on Twitter: A multicountry and fully labelled dataset for public health surveillance research (Preprint)",,JMIR Public Health and Surveillance,2021
fbf20b24b885764a492ca477a5d7379aecb94b14,https://www.semanticscholar.org/paper/fbf20b24b885764a492ca477a5d7379aecb94b14,Classifying vaccine sentiment tweets by modelling domain-specific representation and commonsense knowledge into context-aware attentive GRU,"Vaccines are an important public health measure, but vaccine hesitancy and refusal can create clusters of low vaccine coverage and reduce the effectiveness of vaccination programs. Social media provides an opportunity to estimate emerging risks to vaccine acceptance by including geographical location and detailing vaccine-related concerns. Methods for classifying social media posts, such as vaccine-related tweets, use language models (LMs) trained on general domain text. However, challenges to measuring vaccine sentiment at scale arise from the absence of tonal stress and gestural cues and may not always have additional information about the user, e.g., past tweets or social connections. Another challenge in LMs is the lack of ‘commonsense’ knowledge that are apparent in users' metadata, i.e., emoticons, positive and negative words etc. In this study, to classify vaccine sentiment tweets with limited information, we present a novel end-to-end framework consisting of interconnected components that use domain-specific LM trained on vaccine-related tweets and models commonsense knowledge into a bidirectional gated recurrent network (CK-BiGRU) with context-aware attention. We further leverage syntactical, user metadata and sentiment information to capture the sentiment of a tweet. We experimented using two popular vaccine-related Twitter datasets and demonstrate that our proposed approach outperforms state-of-the-art models in identifying pro-vaccine, anti-vaccine and neutral tweets.",2021 International Joint Conference on Neural Networks (IJCNN),2021
0a638a8f0d09238f3829f04bd69fe96693cded68,https://www.semanticscholar.org/paper/0a638a8f0d09238f3829f04bd69fe96693cded68,Addressing machine learning concept drift reveals declining vaccine sentiment during the COVID-19 pandemic,"Social media analysis has become a common approach to assess public opinion on various topics, including those about health, in near real-time. The growing volume of social media posts has led to an increased usage of modern machine learning methods in natural language processing. While the rapid dynamics of social media can capture underlying trends quickly, it also poses a technical problem: algorithms trained on annotated data in the past may underperform when applied to contemporary data. This phenomenon, known as concept drift, can be particularly problematic when rapid shifts occur either in the topic of interest itself, or in the way the topic is discussed. Here, we explore the effect of machine learning concept drift by focussing on vaccine sentiments expressed on Twitter, a topic of central importance especially during the COVID-19 pandemic. We show that while vaccine sentiment has declined considerably during the COVID-19 pandemic in 2020, algorithms trained on pre-pandemic data would have largely missed this decline due to concept drift. Our results suggest that social media analysis systems must address concept drift in a continuous fashion in order to avoid the risk of systematic misclassification of data, which is particularly likely during a crisis when the underlying data can change suddenly and rapidly.",ArXiv,2020
126fb7df6bcab2b70000dfe5b940ada63ae1ba6a,https://www.semanticscholar.org/paper/126fb7df6bcab2b70000dfe5b940ada63ae1ba6a,COVID-Twitter-BERT: A Natural Language Processing Model to Analyse COVID-19 Content on Twitter,"In this work, we release COVID-Twitter-BERT (CT-BERT), a transformer-based model, pretrained on a large corpus of Twitter messages on the topic of COVID-19. Our model shows a 10-30% marginal improvement compared to its base model, BERT-Large, on five different classification datasets. The largest improvements are on the target domain. Pretrained transformer models, such as CT-BERT, are trained on a specific target domain and can be used for a wide variety of natural language processing tasks, including classification, question-answering and chatbots. CT-BERT is optimised to be used on COVID-19 content, in particular social media posts from Twitter.",ArXiv,2020
15ac9cb0bb0c9e59f59dbafced26399748b76082,https://www.semanticscholar.org/paper/15ac9cb0bb0c9e59f59dbafced26399748b76082,Keep calm and carry on vaccinating: Is anti-vaccination sentiment contributing to declining vaccine coverage in England?,"BACKGROUND In England, coverage for childhood vaccines have decreased since 2012/13 in the context of an increasingly visible anti-vaccination discourse. We determined whether anti-vaccination sentiment is the likely cause of this decline in coverage. METHODS Descriptive study triangulating a range of data sources (vaccine coverage, cross-sectional survey of attitudes towards vaccination, UK-specific Twitter social media) and assessing them against the following Bradford Hill criteria: strength of association, consistency, specificity, temporality, biological gradient and coherence. RESULTS Strength of association: compared with well-documented vaccine scares, the decline in childhood vaccination seen since 2012/13 is 4-20 times smaller; consistency: while coverage for completed courses of the hexavalent and meningococcal vaccines decreased by 0.5-1.2 percentage points (pp) between 2017 and 2019, coverage for the first dose of these vaccines increased 0.5-0.7 pp; specificity: Since 2012-13, coverage decreased for some vaccines (hexavalent, MMR, HPV, shingles) and increased for others (MenACWY, Td/IPV, antenatal pertussis, influenza in 2 years of children), with no age-specific patterns. Temporality and biological gradient: the decline in vaccine coverage was preceded by an increase in vaccine confidence and a decrease in the proportion of parents encountering anti-vaccination materials. Coherence: attitudes towards vaccination expressed on Twitter in the UK became increasingly positive between 2017 and 2019 as vaccine coverage for childhood vaccines decreased. CONCLUSIONS In England, trends in vaccine coverage between 2012/13 and 2018/19 were not homogenous and varied in magnitude and direction according to vaccine, dose and region. In addition, confidence in vaccines increased during the same period. These findings are not compatible with anti-vaccination sentiment causing a decline in vaccine coverage In England.",Vaccine,2020
3e189b98454eb4fe827d6e25fdc09ca3077820d6,https://www.semanticscholar.org/paper/3e189b98454eb4fe827d6e25fdc09ca3077820d6,International expert communities on Twitter become more isolated during the COVID-19 pandemic,"COVID-19 represents the most severe global crisis to date whose public conversation can be studied in real time. To do so, we use a data set of over 350 million tweets and retweets posted by over 26 million English speaking Twitter users from January 13 to June 7, 2020. In characterizing the complex retweet network, we identify several stable communities, and are able to link them to scientific expert groups, national elites, and political actors. We find that scientific expert communities received a disproportionate amount of attention early on during the pandemic, and were leading the discussion at the time. However, as the pandemic unfolded, the attention shifted towards both national elites and political actors, paralleled by the introduction of country-specific containment measures and the growing politicization of the debate. Scientific experts remained present in the discussion, but experienced less reach and a higher degree of segregation and isolation. Overall, the emerging communities are characterized by an increased self-amplification and polarization. This makes it generally harder for information from international health organizations or authorities to reach a broad audience. These results may have implications for information dissemination in future global crises.",ArXiv,2020
4437668f236ccb9f5819e5ca14183ecdcb6bf145,https://www.semanticscholar.org/paper/4437668f236ccb9f5819e5ca14183ecdcb6bf145,DOT: a crowdsourcing Mobile application for disease outbreak detection and surveillance in Mauritius,"Early detection of disease outbreaks is crucial and even small improvements in detection can significantly impact on a country’s public health. In this work, we investigate the use of a crowdsourcing application and a real-time disease outbreak surveillance system for five diseases; Influenza, Gastroenteritis, Upper Respiratory Tract Infection (URTI), Scabies and Conjunctivitis, that are closely monitored in Mauritius. We also analyze and correlate the collected data with past statistics. A crowdsourcing mobile application known as Disease Outbreak Tracker ( DOT ) was implemented and made public. A real-time disease surveillance system using the Early Aberration Reporting System algorithm (EARS) for analysis of the collected data was also implemented. The collected data were correlated to historical data for 2017. Data were successfully collected and plotted on a daily basis. The results show that a few cases of Flu and Scabies were reported in some districts. The EARS methods C1, C2 and C3 also depicted spikes above the set threshold on some days. The study covers data collected over a period of one month. Once symptoms data were collected using DOT , probabilistic methods were used to find the disease or diseases that the user was suffering from. The data were further processed to find the extent of the disease outbreak district-wise, per disease. These data were represented graphically for a rapid understanding of the situation in each district. Our findings concur with existing data for the same period for previous years showing that the crowdsourcing application can aid in the detection of disease outbreaks.",Health and technology,2020
5358698ec24b5421961861dcaf2db8d0928f5190,https://www.semanticscholar.org/paper/5358698ec24b5421961861dcaf2db8d0928f5190,Promoting immunization resiliency in the digital information age.,"The avalanche of online information on immunization is having a major impact on the percentage of the population who choose to get vaccinated. Vaccine misinformation spreads widely with the interactive Web 2.0 and social media; this can bury science-based information. A plethora of immunization misinformation online is affecting trust in health care professionals and in public immunization programs. There are no simple solutions to this, but seven evidence-based strategies can help. First, listen to patients' and parents' concerns, and demonstrate responsiveness by adopting best immunization practices, such as pain mitigation. Second, recognize and alert others to anti-immunization tactics, namely, conspiracy theories, fake experts, selectivity, demands that vaccines be 100% safe and effective, misrepresentation and false logic. Third, avoid unproductive debates with those who have strongly held views, both in person and when using social media. Be respectful, stick to your key message, identify where to find useful information and exit. Fourth, consider establishing an attractive, easily searchable online presence that reflects the complex art of persuasion. Emphasize the benefits of vaccine, use reader-friendly graphics and highlight facts with stories to strengthen your case. Fifth, work with social media platform providers, not to stifle freedom of expression, but to help ensure that misinformation is not favoured in searches. Sixth, promote curriculum development in the schools to improve students' understanding of the benefits and safety of immunization and to foster critical thinking skills. To do this, optimize the use of age-appropriate comics and interactive learning tools such as electronic games. Seventh, to shift the narrative in specific communities with low vaccination rates, work with community leaders to build tailored programs that foster trust and reflect local values.",Canada communicable disease report = Releve des maladies transmissibles au Canada,2020
68a73f9b62b2ca8b8b6965f56b51dcd391b76fa4,https://www.semanticscholar.org/paper/68a73f9b62b2ca8b8b6965f56b51dcd391b76fa4,The Risk to Population Health Equity Posed by Automated Decision Systems: A Narrative Review,"Artificial intelligence is already ubiquitous, and is increasingly being used to autonomously make ever more consequential decisions. However, there has been relatively little research into the consequences for equity of the use of narrow AI and automated decision systems in medicine and public health. A narrative review using a hermeneutic approach was undertaken to explore current and future uses of AI in medicine and public health, issues that have emerged, and longer-term implications for population health. Accounts in the literature reveal a tremendous expectation on AI to transform medical and public health practices, especially regarding precision medicine and precision public health. Automated decisions being made about disease detection, diagnosis, treatment, and health funding allocation have significant consequences for individual and population health and wellbeing. Meanwhile, it is evident that issues of bias, incontestability, and erosion of privacy have emerged in sensitive domains where narrow AI and automated decision systems are in common use. As the use of automated decision systems expands, it is probable that these same issues will manifest widely in medicine and public health applications. Bias, incontestability, and erosion of privacy are mechanisms by which existing social, economic and health disparities are perpetuated and amplified. The implication is that there is a significant risk that use of automated decision systems in health will exacerbate existing population health inequities. The industrial scale and rapidity with which automated decision systems can be applied to whole populations heightens the risk to population health equity. There is a need therefore to design and implement automated decision systems with care, monitor their impact over time, and develop capacities to respond to issues as they emerge.",ArXiv,2020
9c62906c8cdf33f25589f57acc6e8447a10eaa2d,https://www.semanticscholar.org/paper/9c62906c8cdf33f25589f57acc6e8447a10eaa2d,Assessing Public Opinion on CRISPR-Cas9: Combining Crowdsourcing and Deep Learning,"Background The discovery of the CRISPR-Cas9–based gene editing method has opened unprecedented new potential for biological and medical engineering, sparking a growing public debate on both the potential and dangers of CRISPR applications. Given the speed of technology development and the almost instantaneous global spread of news, it is important to follow evolving debates without much delay and in sufficient detail, as certain events may have a major long-term impact on public opinion and later influence policy decisions. Objective Social media networks such as Twitter have shown to be major drivers of news dissemination and public discourse. They provide a vast amount of semistructured data in almost real-time and give direct access to the content of the conversations. We can now mine and analyze such data quickly because of recent developments in machine learning and natural language processing. Methods Here, we used Bidirectional Encoder Representations from Transformers (BERT), an attention-based transformer model, in combination with statistical methods to analyze the entirety of all tweets ever published on CRISPR since the publication of the first gene editing application in 2013. Results We show that the mean sentiment of tweets was initially very positive, but began to decrease over time, and that this decline was driven by rare peaks of strong negative sentiments. Due to the high temporal resolution of the data, we were able to associate these peaks with specific events and to observe how trending topics changed over time. Conclusions Overall, this type of analysis can provide valuable and complementary insights into ongoing public debates, extending the traditional empirical bioethics toolset.",Journal of medical Internet research,2020
a75bb9c6989aaf2a686498dd3e2bdcd459f10e4f,https://www.semanticscholar.org/paper/a75bb9c6989aaf2a686498dd3e2bdcd459f10e4f,COVID-19 Misinformation Spread in Eight Countries: Exponential Growth Modeling Study (Preprint),"BACKGROUND The epidemic of misinformation about COVID-19 transmission, prevention, and treatment has been going on since the start of the pandemic. However, data on the exposure and impact of misinformation is not readily available. OBJECTIVE We aim to characterize and compare the start, peak, and doubling time of COVID-19 misinformation topics across 8 countries using an exponential growth model usually employed to study infectious disease epidemics. METHODS COVID-19 misinformation topics were selected from the World Health Organization Mythbusters website. Data representing exposure was obtained from the Google Trends application programming interface for 8 English-speaking countries. Exponential growth models were used in modeling trends for each country. RESULTS Searches for “coronavirus AND 5G” started at different times but peaked in the same week for 6 countries. Searches for 5G also had the shortest doubling time across all misinformation topics, with the shortest time in Nigeria and South Africa (approximately 4-5 days). Searches for “coronavirus AND ginger” started at the same time (the week of January 19, 2020) for several countries, but peaks were incongruent, and searches did not always grow exponentially after the initial week. Searches for “coronavirus AND sun” had different start times across countries but peaked at the same time for multiple countries. CONCLUSIONS Patterns in the start, peak, and doubling time for “coronavirus AND 5G” were different from the other misinformation topics and were mostly consistent across countries assessed, which might be attributable to a lack of public understanding of 5G technology. Understanding the spread of misinformation, similarities and differences across different contexts can help in the development of appropriate interventions for limiting its impact similar to how we address infectious disease epidemics. Furthermore, the rapid proliferation of misinformation that discourages adherence to public health interventions could be predictive of future increases in disease cases.",,2020
ac5513e6936a1dbf348272026a35eaf9f6674815,https://www.semanticscholar.org/paper/ac5513e6936a1dbf348272026a35eaf9f6674815,Linguist Geeks on WNUT-2020 Task 2: COVID-19 Informative Tweet Identification using Progressive Trained Language Models and Data Augmentation,"Since the outbreak of COVID-19, there has been a surge of digital content on social media. The content ranges from news articles, academic reports, tweets, videos, and even memes. Among such an overabundance of data, it is crucial to distinguish which information is actually informative or merely sensational, redundant or false. This work focuses on developing such a language system that can differentiate between Informative or Uninformative tweets associated with COVID-19 for WNUT-2020 Shared Task 2. For this purpose, we employ deep transfer learning models such as BERT along other techniques such as Noisy Data Augmentation and Progress Training. The approach achieves a competitive F1-score of 0.8715 on the final testing dataset.",WNUT,2020
ddc9de9b67cf269ca491bb38e6643d319aef2b46,https://www.semanticscholar.org/paper/ddc9de9b67cf269ca491bb38e6643d319aef2b46,Promouvoir la résilience vaccinale à l’ère de l’information numérique,"L’avalanche d’informations sur la vaccination en ligne a une énorme incidence sur le pourcentage de la population qui choisit de se faire vacciner. La désinformation sur les vaccins peut se répandre largement dans le Web 2.0 interactif et les médias sociaux, ce qui peut noyer les informations scientifiques fondés sur les données probantes. La multitude d’informations erronées sur la vaccination que l’on trouve en ligne mine la confiance des gens envers les professionnels de la santé et les programmes de vaccination publics. Il n’y a pas de solutions simples, mais sept stratégies fondées sur des données probantes peuvent vous aider à contrer ce phénomène. Tout d’abord, renseignez-vous sur les préoccupations des patients et des parents et faites preuve de réceptivité en adoptant de meilleures pratiques de vaccination, comme l’atténuation de la douleur. Deuxièmement, sachez reconnaître les tactiques antivaccination et sensibiliser les autres à ce sujet, notamment, la théorie du complot, les faux experts, la sélectivité, le fait d’exiger que les vaccins soient sûrs et efficaces à 100 %, les assertions trompeuses et la logique fallacieuse. Troisièmement, évitez de vous engager dans de futiles débats avec ceux qui ont des opinions bien arrêtées, tant en personne et que sur les médias sociaux. Soyez respectueux; tenez-vous-en à votre message principal, indiquez où trouver d’autres informations utiles et quittez la conversation. Quatrièmement, envisagez d’établir une présence en ligne attrayante et facile à consulter qui intègre l’art complexe de la persuasion. Soulignez les avantages de la vaccination, utilisez des graphiques conviviaux et soulignez les faits par des récits de vécus qui renforcent votre cas. Cinquièmement, travaillez avec les fournisseurs de plateformes de médias sociaux; non pas pour étouffer la liberté d’expression, mais pour aider à ce que les faux renseignements n’apparaissent pas en premier dans les recherches. Sixièmement, promouvez l’élaboration d’un curriculum dans les écoles afin d’améliorer la compréhension des élèves en ce qui a trait aux avantages et à la sécurité de la vaccination et afin de favoriser la pensée critique. Pour ce faire, favorisez l’utilisation de bandes dessinées adaptées à l’âge des élèves et d’outils d’apprentissage interactifs tels que les jeux vidéo. Septièmement, pour modifier le discours de certaines communautés où il y a de plus faibles taux de vaccination, travaillez avec les responsables locaux à l’élaboration de programmes adaptés qui favorisent la confiance et reflètent les valeurs locales. Affiliations",,2020
e76731f0a44ea6e584b01347bc3051db90e27984,https://www.semanticscholar.org/paper/e76731f0a44ea6e584b01347bc3051db90e27984,TweetsCOV19 - A Knowledge Base of Semantically Annotated Tweets about the COVID-19 Pandemic,"Publicly available social media archives facilitate research in the social sciences and provide corpora for training and testing a wide range of machine learning and natural language processing methods. With respect to the recent outbreak of the Coronavirus disease 2019 (COVID-19), online discourse on Twitter reflects public opinion and perception related to the pandemic itself as well as mitigating measures and their societal impact. Understanding such discourse, its evolution, and interdependencies with real-world events or (mis)information can foster valuable insights. On the other hand, such corpora are crucial facilitators for computational methods addressing tasks such as sentiment analysis, event detection, or entity recognition. However, obtaining, archiving, and semantically annotating large amounts of tweets is costly. In this paper, we describe TweetsCOV19, a publicly available knowledge base of currently more than 8 million tweets, spanning October 2019 - April 2020. Metadata about the tweets as well as extracted entities, hashtags, user mentions, sentiments, and URLs are exposed using established RDF/S vocabularies, providing an unprecedented knowledge base for a range of knowledge discovery tasks. Next to a description of the dataset and its extraction and annotation process, we present an initial analysis and use cases of the corpus.",CIKM,2020
f1b5775275107763644ab003d263c79ac4d5bc53,https://www.semanticscholar.org/paper/f1b5775275107763644ab003d263c79ac4d5bc53,How do Twitter users react to TV broadcasts dedicated to vaccines in Italy?,"Abstract Background Social media monitoring during TV broadcasts dedicated to vaccines can provide information on vaccine confidence. We analyzed the sentiment of tweets published in reaction to two TV broadcasts in Italy dedicated to vaccines, one based on scientific evidence [Presadiretta (PD)] and one including anti-vaccine personalities [Virus (VS)]. Methods Tweets about vaccines published in an 8-day period centred on each of the two TV broadcasts were classified by sentiment. Differences in tweets’ and users’ characteristics between the two broadcasts were tested through Poisson, quasi-Poisson or logistic univariate regression. We investigated the association between users’ characteristics and sentiment through univariate quasi-binomial logistic regression. Results We downloaded 12 180 tweets pertinent to vaccines, published by 5447 users; 276 users tweeted during both broadcasts. Sentiment was positive in 50.4% of tweets, negative in 37.7% and neutral in 10.1% (remaining tweets were unclear or questions). The positive/negative ratio was higher for VS compared to PD (6.96 vs. 4.24, P<0.001). Positive sentiment was associated to the user’s number of followers (OR 1.68, P<0.001), friends (OR 1.83, P<0.001) and published tweets (OR 1.46, P<0.001) and to being a recurrent user (OR 3.26, P<0.001). Conclusions Twitter users were highly reactive to TV broadcasts dedicated to vaccines. Sentiment was mainly positive, especially among very active users. Displaying anti-vaccine positions on TV elicited a positive sentiment on Twitter. Listening to social media during TV shows dedicated to vaccines can provide a diverse set of data that can be exploited by public health institutions to inform tailored vaccine communication initiatives.",European journal of public health,2020
96da812dcbef580bc95001d12ec09f03ff6f923c,https://www.semanticscholar.org/paper/96da812dcbef580bc95001d12ec09f03ff6f923c,Recent Social Trends Among Romanian Twitter Users,"Abstract Online Social Networks have become a significant part of our quotidian life. In this paper, we aim to provide a proof of concept of how social media data can be effectively extracted, processed and analyzed with powerful open source tools like R. Moreover, we aim to build a reliable methodology for testing and validating social trends by using social media data. We used API routines to establish the connection between R and Twitter, Deep Learning Models to estimate the demographics of the users, Logistic Regression Models to estimate the predispositions of the users, and Propensity Score Matching to build comparable data sets. After analyzing the Romanian Twitter users, the results of our inquiry show that most of them are relatively young and the percentage of males is significantly higher than the percentage of females. Moreover, our results confirm that facial appearances play an essential role in the popularity of an individual.",Proceedings of the International Conference on Applied Statistics,2019
cfab8542a5dec87a0f9a7d04e3667a39a46bd73c,https://www.semanticscholar.org/paper/cfab8542a5dec87a0f9a7d04e3667a39a46bd73c,Combining Crowdsourcing and Deep Learning to Assess Public Opinion on CRISPR-Cas9,"The discovery of the CRISPR-Cas9-based gene editing method has opened un-precedented new potential for biological and medical engineering, sparking a growing public debate on both the potential and dangers of CRISPR applications. Given the speed of technology development, and the almost instantaneous global spread of news, its important to follow evolving debates without much delay and in sufficient detail, as certain events may have a major long-term impact on public opinion and later influence policy decisions. Social media networks such as Twitter have shown to be major drivers of news dissemination and public discourse. They provide a vast amount of semi-structured data in almost real-time and give direct access to the content of the conversations. Such data can now be mined and analyzed quickly because of recent developments in machine learning and natural language processing. Here, we used BERT, an attention-based transformer model, in combination with statistical methods to analyse the entirety of all tweets ever published on CRISPR since the publication of the first gene editing application in 2013. We show that the mean sentiment of tweets was initially very positive, but began to decrease over time, and that this decline was driven by rare peaks of strong negative sentiments. Due to the high temporal resolution of the data, we were able to associate these peaks with specific events, and to observe how trending topics changed over time. Overall, this type of analysis can provide valuable and complementary insights into ongoing public debates, extending the traditional empirical bioethics toolset.",,2019
dea36ae6b2c4b26a0f68271de8bbf0485fbfd634,https://www.semanticscholar.org/paper/dea36ae6b2c4b26a0f68271de8bbf0485fbfd634,A Review of Computational Intelligence Techniques in Wireless Sensor and Actuator Networks,"Wireless sensor and actuator networks (WSANs) are heterogeneous networks composed of many different nodes that can cooperatively sense the environment, determine an appropriate action to take, then change the environment’s state after acting on it. As a natural extension of wireless sensor networks (WSNs), WSANs inherit from them a variety of research challenges and bring forth many new ones. These challenges are related to dealing with imprecise and vague information, solving complicated optimization problems or collecting and processing data from multiple sources. Computational intelligence (CI) is an overarching term denoting a conglomerate of biologically and linguistically inspired techniques that provide robust solutions to NP-hard problems, reason in imprecise terms and yield high-quality yet computationally tractable approximate solutions to real-world problems. Many researchers have consequently turned to CI in hope of finding answers to a plethora of WSAN-related challenges. This paper reviews the application of several methodologies under the CI umbrella to the WSAN field. We describe and categorize existing works leaning on fuzzy systems, neural networks, evolutionary computation, swarm intelligence, learning systems, and their hybridizations to well-known or emerging WSAN problems along five major axes: 1) actuation; 2) communication; 3) sink mobility; 4) topology control; and 5) localization. The survey offers informative discussions to help reason through all the studies under consideration. Finally, we point to future research avenues by: 1) suggesting suitable CI techniques to specific problems; 2) borrowing concepts from WSNs that have yet to be applied to WSANs; or 3) describing the shortcomings of current methods in order to spark interest on the development of more refined models.",IEEE Communications Surveys & Tutorials,2018
4241129513a8407c3a598cf3724e50a4e743fd6d,https://www.semanticscholar.org/paper/4241129513a8407c3a598cf3724e50a4e743fd6d,Towards RegOps: A DevOps Pipeline for Medical Device Software,,PROFES,2021
92dfb6f46dcb158d281282a8cacd07f440a03508,https://www.semanticscholar.org/paper/92dfb6f46dcb158d281282a8cacd07f440a03508,Applying DevOps to Machine Learning Processes: A Systematic Mapping,"Práticas de DevOps têm sido cada vez mais utilizadas por equipes de engenharia de software com o intuito de aprimorar as etapas de desenvolvimento. Em processos que envolvem machine learning (ML), DevOps também pode ser aplicado a fim de implantar modelos de aprendizado de máquina em produção – prática também conhecida como MLOps. Neste mapeamento sistemático objetiva-se entender como DevOps tem sido aplicado a processos de machine learning e quais são os desafios enfrentados. Foram selecionados 15 artigos e observou-se que a maioria faz uso de práticas de CI/CD e propõe arquiteturas para a implantação de modelos de ML. Como maiores desafios, têm-se as características inerentes aos modelos de ML e resistência à mudança.",Anais do XVIII Encontro Nacional de Inteligência Artificial e Computacional (ENIAC 2021),2021
ea5ba646fe016f8a03a2519d53968a4723974faf,https://www.semanticscholar.org/paper/ea5ba646fe016f8a03a2519d53968a4723974faf,Automatic Waste Management and Segregation System using IoT,"This system is developed to overcome the challenges, barriers and to provide an opportunity for improvements in waste management and segregation system. The Automatic waste management and segregation system use the concept of IoT, where the proposed system is placed all over the cities, with an embedded system to segregate and monitor the level of the bin. The status of bins is sent to concerned authorities to evacuate the bins and the locations of bins are traced via the internet. This system reduces human intervention, interaction and also reduces the consumption of time and cost. Keywords-IR sensor, MQ sensor, Dry wet sensor, Arduino Uno, Node MCU, Bin.",,2021
11beeee16fa5996d0d4d1d9b1de7d96c5d52ae79,https://www.semanticscholar.org/paper/11beeee16fa5996d0d4d1d9b1de7d96c5d52ae79,Keypoint-Based Robotic Grasp Detection Scheme in Multi-Object Scenes,"Robot grasping is an important direction in intelligent robots. However, how to help robots grasp specific objects in multi-object scenes is still a challenging problem. In recent years, due to the powerful feature extraction capabilities of convolutional neural networks (CNN), various algorithms based on convolutional neural networks have been proposed to solve the problem of grasp detection. Different from anchor-based grasp detection algorithms, in this paper, we propose a keypoint-based scheme to solve this problem. We model an object or a grasp as a single point—the center point of its bounding box. The detector uses keypoint estimation to find the center point and regress to all other object attributes such as size, direction, etc. Experimental results demonstrate that the accuracy of this method is 74.3% in the multi-object grasp dataset VMRD, and the performance on the single-object scene Cornell dataset is competitive with the current state-of-the-art grasp detection algorithm. Robot experiments demonstrate that this method can help robots grasp the target in single-object and multi-object scenes with overall success rates of 94% and 87%, respectively.",Sensors,2021
2a8a507438b452ed5d8f3ad7c278a0904540184d,https://www.semanticscholar.org/paper/2a8a507438b452ed5d8f3ad7c278a0904540184d,Primitive Object Grasping for Finger Motion Synthesis,"We developed a new framework to generate hand and finger grasping motions. The proposed framework provides online adaptation to the position and orientation of objects and can generate grasping motions even when the object shape differs from that used during motion capture. This is achieved by using a mesh model, which we call primitive object grasping (POG), to represent the object grasping motion. The POG model uses a mesh deformation algorithm that keeps the original shape of the mesh while adapting to varying constraints. These characteristics are beneficial for finger grasping motion synthesis that satisfies constraints for mimicking the motion capture sequence and the grasping points reflecting the shape of the object. We verify the adaptability of the proposed motion synthesizer according to its position/orientation and shape variations of different objects by using motion capture sequences for grasping primitive objects, namely, a sphere, a cylinder, and a box. In addition, a different grasp strategy called a three‐finger grasp is synthesized to validate the generality of the POG‐based synthesis framework.",Comput. Graph. Forum,2021
31c92f827e37b7f7b2974528618f487eb04f68a3,https://www.semanticscholar.org/paper/31c92f827e37b7f7b2974528618f487eb04f68a3,A Single Target Grasp Detection Network Based on Convolutional Neural Network,"Grasp detection based on convolutional neural network has gained some achievements. However, overfitting of multilayer convolutional neural network still exists and leads to poor detection precision. To acquire high detection accuracy, a single target grasp detection network that generalizes the fitting of angle and position, based on the convolution neural network, is put forward here. The proposed network regards the image as input and grasping parameters including angle and position as output, with the detection manner of end-to-end. Particularly, preprocessing dataset is to achieve the full coverage to input of model and transfer learning is to avoid overfitting of network. Importantly, a series of experimental results indicate that, for single object grasping, our network has good detection results and high accuracy, which proves that the proposed network has strong generalization in direction and category.",Computational intelligence and neuroscience,2021
3bd2d2353fa281ffd5a247550f150d983de7ca50,https://www.semanticscholar.org/paper/3bd2d2353fa281ffd5a247550f150d983de7ca50,Grasp Detection under Occlusions Using SIFT Features,"Distinguishing target object under occlusions has become the forefront of research to cope with grasping study in general. In this paper, a novel framework which is able to be utilized for a parallel robotic gripper is proposed. There are two key steps for the proposed method in the process of grasping occluded object: generating template information and grasp detection using the matching algorithm. A neural network, trained by the RGB-D data from the Cornell Grasp Dataset, predicts multiple grasp rectangles on template images. A proposed matching algorithm is utilized to eliminate the influence caused by occluded parts on scene images and generates multiple grasp rectangles for objects under occlusions using the grasp information of matched template images. In order to improve the quality of matching result, the proposed matching algorithm improves the SIFT algorithm and combines it with the improved RANSAC algorithm. In this way, this paper obtains suitable grasp rectangles on scene images and offers a new thought about grasping detection under occlusions. The validation results show the effectiveness and efficiency of this approach.",Complexity,2021
6aa3b89a6919a71f1d309a44e6fdffce3ee2bf71,https://www.semanticscholar.org/paper/6aa3b89a6919a71f1d309a44e6fdffce3ee2bf71,REGRAD: A Large-Scale Relational Grasp Dataset for Safe and Object-Specific Robotic Grasping in Clutter,"Despite the impressive progress achieved in robotic grasping, robots are not skilled in sophisticated tasks (e.g. search and grasp a specified target in clutter). Such tasks involve not only grasping but the comprehensive perception of the world (e.g. the object relationships). Recently, encouraging results demonstrate that it is possible to understand highlevel concepts by learning. However, such algorithms are usually data-intensive, and the lack of data severely limits their performance. In this paper, we present a new dataset named REGRAD for the learning of relationships among objects and grasps. We collect the annotations of object poses, segmentations, grasps, and relationships for the target-driven relational grasping tasks. Our dataset is collected in both forms of 2D images and 3D point clouds. Moreover, since all the data are generated automatically, it is free to import new objects for data generation. We also released a real-world validation dataset to evaluate the sim-to-real performance of models trained on REGRAD. Finally, we conducted a series of experiments, showing that the models trained on REGRAD could generalize well to the realistic scenarios, in terms of both relationship and grasp detection. Our dataset and code could be found at: https://github.com/poisonwine/REGRAD.",ArXiv,2021
7885dc0870fe591a861f6ee8400288c35924b574,https://www.semanticscholar.org/paper/7885dc0870fe591a861f6ee8400288c35924b574,A Joint Network for Grasp Detection Conditioned on Natural Language Commands,"We consider the task of grasping a target object based on a natural language command query. Previous work primarily focused on localizing the object given the query, which requires a separate grasp detection module to grasp it. The cascaded application of two pipelines incurs errors in overlapping multi-object cases due to ambiguity in the individal outputs. This work proposes a model named Command Grasping Network (CGNet) to directly output command satisficing grasps from RGB image and textual command inputs. A dataset with ground truth (image, command, grasps) tuple is generated based on the VMRD dataset to train the proposed network. Experimental results on the generated test set show that CGNet outperforms a cascaded object-retrieval and grasp detection baseline by a large margin. Three physical experiments demonstrate the functionality and performance of CGNet.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021
7c1949a48e36e92e9bc44906fd5589c4653f9707,https://www.semanticscholar.org/paper/7c1949a48e36e92e9bc44906fd5589c4653f9707,Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation,"Grasping in cluttered scenes has always been a great challenge for robots, due to the requirement of the ability to well understand the scene and object information. Previous works usually assume that the geometry information of the objects is available, or utilize a step-wise, multi-stage strategy to predict the feasible 6-DoF grasp poses. In this work, we propose to formalize the 6-DoF grasp pose estimation as a simultaneous multi-task learning problem. In a unified framework, we jointly predict the feasible 6-DoF grasp poses, instance semantic segmentation, and collision information. The whole framework is jointly optimized and end-to-end differentiable. Our model is evaluated on large-scale benchmarks as well as the real robot system. On the public dataset, our method outperforms prior state-of-the-art methods by a large margin (+4.08 AP). We also demonstrate the implementation of our model on a real robotic platform and show that the robot can accurately grasp target objects in cluttered scenarios with a high success rate. Project link: https://openbyterobotics.github.io/sscl.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
e7046c1a5dbb1cf074d6c04eef3671d71b4ad0a7,https://www.semanticscholar.org/paper/e7046c1a5dbb1cf074d6c04eef3671d71b4ad0a7,Deep Learning for Robot Vision,,,2021
2ed90764e820d1f50a177fc55985ca8566356aab,https://www.semanticscholar.org/paper/2ed90764e820d1f50a177fc55985ca8566356aab,Towards the vision of a social robot in every home: A navigation strategy via enhanced subsumption architecture,,,2020
33a13d69cf3efeaf5c4871286ebb83d70eb15866,https://www.semanticscholar.org/paper/33a13d69cf3efeaf5c4871286ebb83d70eb15866,A Distributed Reward Algorithm for Inverse Kinematics of Arm Robot,"Traditional methods of inverse kinematics of robots always adopt analytical approach and numerical approach to solve the continuous state and action problems with experience and experiment mostly, which require much time and work in reality work scene, especially for robots with complex structure. This paper proposes a method based on reinforcement learning TD3 network, which is constructed by PyTorch to find the inverse solution from another point of view. A set of improved distributed multiple rewards which choose the position difference between adjacent joints as the reward standard are designed to optimize the solution, avoid solving unreachable points and prevent the mechanical structure from being damaged also in the environment of five-degree-of-freedom arm robot. The validity of above method is verified by simulation experiment results.","2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)",2020
39b768f1a9b5e0bdaa5fcf8b10c3133cb753b4a6,https://www.semanticscholar.org/paper/39b768f1a9b5e0bdaa5fcf8b10c3133cb753b4a6,Machine Vision Techniques Used in Agriculture and Food Industry: A Review,"Last few decades has seen lot of advancement in the technologies associated with the automation in agriculture and food industry. This includes a wide range of agricultural operations including seedbed preparation, intercultural operations, application of fertilizers and chemicals, harvesting, transportation, and grading. Researchers have developed robots that assist the farmers in getting these operations done and help them overcome the labour shortage problem. Artificial intelligence has changed the way decisions used to be made in agricultural and other operations and has made automation of many tasks feasible. Machine learning technique is a subtype of artificial intelligence which is used for processing of images of fruits, crop and other objects which can give a wide range of information that may be useful in decision making. With the advancement in GPU and software technology it is possible to process huge amount of data in real time. Further, with the availability of convolutional neural networks such as AlexNet, ResNet, International Journal of Current Microbiology and Applied Sciences ISSN: 2319-7706 Volume 9 Number 3 (2020) Journal homepage: http://www.ijcmas.com",,2020
5e9bc8f7dc58e9c0fcbd38607c8430ef1497cba9,https://www.semanticscholar.org/paper/5e9bc8f7dc58e9c0fcbd38607c8430ef1497cba9,"Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review","This paper presents a comprehensive survey on vision-based robotic grasping. We conclude three key tasks during vision-based robotic grasping, which are object localization, object pose estimation and grasp estimation. In detail, the object localization task contains object localization without classification, object detection and object instance segmentation. This task provides the regions of the target object in the input data. The object pose estimation task mainly refers to estimating the 6D object pose and includes correspondence-based methods, template-based methods and voting-based methods, which affords the generation of grasp poses for known objects. The grasp estimation task includes 2D planar grasp methods and 6DoF grasp methods, where the former is constrained to grasp from one direction. These three tasks could accomplish the robotic grasping with different combinations. Lots of object pose estimation methods need not object localization, and they conduct object localization and object pose estimation jointly. Lots of grasp estimation methods need not object localization and object pose estimation, and they conduct grasp estimation in an end-to-end manner. Both traditional methods and latest deep learning-based methods based on the RGB-D image inputs are reviewed elaborately in this survey. Related datasets and comparisons between state-of-the-art methods are summarized as well. In addition, challenges about vision-based robotic grasping and future directions in addressing these challenges are also pointed out.",Artificial Intelligence Review,2020
6d9b10288ed12e06c0aae5772f432421d6ba60e4,https://www.semanticscholar.org/paper/6d9b10288ed12e06c0aae5772f432421d6ba60e4,A Multi-Object Grasping Detection Based on the Improvement of YOLOv3 Algorithm,"YOLOv3 has achieved good results in the field of object detection. In order to achieve multi-object grasping detection, the network structure has been improved. The improved YOLOv3 algorithm is applied to the object position and pose detection in robotic grasping, and a deep learning model is proposed to predict the robot's grasping position, which can detect the occurrence of multiple objects in real time and grasp them in order according to the semantic information. For the specific application scenario, the corresponding dataset is made, and a corner detection method based on YOLOv3 is proposed to grasping position and pose detection. Compared with the traditional corner detection method, this method has semantic information in its detected corner. In the scene, we first classify and locate the object, then detect the corner of the object, and filter the corner of the false detection through the positioning of the object, and design the corresponding algorithm to complete the corner of the missed detection, so that the accuracy of the corner detection is greatly improved, reaching 99% in the self-made dataset. Finally, the position information of the corner is used to calculate the centroid position of the object, that is, the grasping point of the object. The point cloud information is obtained by depth camera, and the grasping pose of the object is calculated. This method can greatly improve the accuracy of grasping detection in specific scenes.",2020 Chinese Control And Decision Conference (CCDC),2020
916b7c0a148cd444653254d25df2aabbd513f9f7,https://www.semanticscholar.org/paper/916b7c0a148cd444653254d25df2aabbd513f9f7,Visual manipulation relationship recognition in object-stacking scenes,"Abstract Object manipulation in object-stacking scenes is a significant but challenging skill for intelligent robots. In most cases, the relationships among objects should be considered before manipulation to prevent chaos and damages. However, the analysis of object relationships in object-stacking scenes, especially for robotic manipulation, remains to be unsolved. To this end, this paper presents a new convolutional neural network (CNN) architecture, called Visual Manipulation Relationship Network (VMRN), to recognize the visual manipulation relationships (VMR) between objects in real-time. By considering the manipulation relationships in object-stacking scenes, it ensures that the robot can complete manipulation tasks safely and reliably. The core of our model is the Object Pairing Pooling Layer (OP2L), which makes it possible to recognize objects and all possible VMRs in one forward process. Moreover, to train VMRN, we contribute a dataset named Visual Manipulation Relationship Dataset (VMRD) consisting of 4683 images with more than 16,000 object instances and the VMRs between each object pair. The experimental results show that the proposed network architecture can detect objects and predict VMRs.",Pattern Recognit. Lett.,2020
ba1309612e7ea17543ae4ef93c2a81dc9b492694,https://www.semanticscholar.org/paper/ba1309612e7ea17543ae4ef93c2a81dc9b492694,Learning from Wearable-Based Teleoperation Demonstration,,,2020
c93832dc5fa54a955bad108429dfd3be4c714dc2,https://www.semanticscholar.org/paper/c93832dc5fa54a955bad108429dfd3be4c714dc2,Reconocimiento de objetos agarrados con sensorizado híbrido propioceptivo-táctil,"espanolEste trabajo se presenta una aproximacion hibrida propioceptiva-tactil para reconocer objetos agarrados. La informacion propioceptiva de una mano robotica es usada para estimar la geometria de contacto y asi, distinguir la forma de cada uno de los objetos que estan siendo agarrados. La geometria de contacto viene determinada por los datos articulares de la mano robotica cuando esta lleva a cabo un agarre en configuracion de cierre sobre la superficie del objeto. Ademas, la informacion tactil permite determinar propiedades de rigidez y flexibilidad del objeto agarrado, mejorando el proceso de reconocimiento cuando la geometria de contacto y por lo tanto, la forma de los objetos es similar. El metodo propuesto emplea tecnicas de clasificacion de aprendizaje supervisado para combinar los datos de ambos tipos de sensores e identificar el tipo de objeto con un porcentaje de acierto medio del 95,5% con metrica ‘accuracy’ y 95.3% con F1(F-score) aun en presencia de incertidumbre de medida y ambiguedad. Estas ratios de acierto se han alcanzado experimentando con 7 objetos domesticos y llevando a cabo mas de 3000 agarres. EnglishThis work presents a hybrid proprioceptive-tactile approach to recognize grasped objects. Proprioceptive data of a robotic hand are used to estimate contact geometry and thus, to distinguish the shape of each of the objects that are being grasped. The contact geometry is determined by the joint data of the robotic hand when it carries out a grip in closure grasps configuration on the object surface. In addition, the tactile data allow to robotic hand to determine rigidity and flexibility properties of the grasped object, improving the recognition process when the contact geometry and therefore, the shapes of different objects are similar. The proposed method employs supervised learning classification techniques to combine the data from both types of sensors and identify the type of object with an average success rate of 95,5% (with accuracy) and 95.3% (with F1 or F-score)even in the presence of measurement with uncertainty and ambiguity of pose. These success ratios have been achieved by experimenting with 7 different objects and performing more than 3000 grasps.","Actas de las XXXIX Jornadas de Automática, Badajoz, 5-7 de Septiembre de 2018",2020
ccb572d3be31406a148a750475f1f96bd66725de,https://www.semanticscholar.org/paper/ccb572d3be31406a148a750475f1f96bd66725de,Real-Time Object Detection With Reduced Region Proposal Network via Multi-Feature Concatenation,"In recent years, object detection became more and more important following the successful results from studies in deep learning. Two types of neural network architectures are used for object detection: one-stage and two-stage. In this paper, we analyze a widely used two-stage architecture called Faster R-CNN to improve the inference time and achieve real-time object detection without compromising on accuracy. To increase the computation efficiency, pruning is first adopted to reduce the weights in convolutional and fully connected (FC) layers. However, this reduces the accuracy of detection. To address this loss in accuracy, we propose a reduced region proposal network (RRPN) with dilated convolution and concatenation of multi-scale features. In the assisted multi-feature concatenation, we propose the intra-layer concatenation and proposal refinement to efficiently integrate the feature maps from different convolutional layers; this is then provided as an input to the RRPN. Using the proposed method, the network can find object bounding boxes more accurately, thus compensating for the loss arising from compression. Finally, we test the proposed architecture using ZF-Net and VGG16 as a backbone network on the image sets in PASCAL VOC 2007 or VOC 2012. The results show that we can compress the parameters of the ZF-Net-based network by 81.2% and save 66% of computation. The parameters of VGG16-based network are compressed by 73% and save 77% of computation. Consequently, the inference speed is improved from 27 to 40 frames/s for ZF-Net and 9 to 27 frames/s for VGG16. Despite significant compression rates, the accuracy of ZF-Net is increased from 2.2% to 60.2% mean average precision (mAP) and that of VGG16 is increased from 2.6% to 69.1% mAP.",IEEE Transactions on Neural Networks and Learning Systems,2020
d00fd3e25e3cbdd5ffcb092ca6bac57195f98b5f,https://www.semanticscholar.org/paper/d00fd3e25e3cbdd5ffcb092ca6bac57195f98b5f,Detecting Graspable Rectangles of Objects in Robotic Grasping,"Most convolutional neural network based grasp detection methods evaluate the predicted grasp by computing its overlap with the selected ground truth grasp. But for typical grasp datasets, not all graspable examples are labelled as ground truths. Hence, directly back propagating the generated loss during training could not fully reveal the graspable ability of the predicted grasp. In this paper, we integrate the grasp mapping mechanism with the convolutional neural network, and propose a multi-scale, multi-grasp detection model. First, we connect each labeled grasp and refine them by discarding inconsistent and redundant connections to form the grasp path. Then, the predicted grasp is mapped to the grasp path and the error between them is used for back-propagation as well as grasp evaluation. Last, they are combined into the multi-grasp detection framework to detect grasps with efficiency. Experimental results both on Cornell Grasping Dataset and real-world robotic grasping system verify the effectiveness of our proposed method. In addition, its detection accuracy keeps relatively stable even in the circumstance of high Jaccard threshold.",,2020
ddc8fc4bbb8bf68052378748592a1f8a07ba2fef,https://www.semanticscholar.org/paper/ddc8fc4bbb8bf68052378748592a1f8a07ba2fef,Clasificación de objetos usando percepción bimodal de palpación única en acciones de agarre robótico,"Este trabajo presenta un metodo para clasificar objetos agarrados con una mano robotica multidedo combinando en un descriptor hibrido datos propioceptivos y tactiles. Los datos propioceptivos se obtienen a partir de las posiciones articulares de la mano y los tactiles se extraen del contacto registrado por celulas de presion instaladas en las falanges. La aproximacion propuesta permite identificar el objeto aprendiendo de forma implicita su geometria y rigidez usando los datos que facilitan los sensores. En este trabajo demostramos que el uso de datos bimodales con tecnicas de aprendizaje supervisado mejora la tasa de reconocimiento. En la experimentacion, se han llevado a cabo mas de 3000 agarres de hasta 7 objetos domesticos distintos, obteniendo clasificaciones correctas del 95%con metrica F1, realizando una unica palpacion del objeto. Ademas, la generalizacion del metodo se ha verificado entrenando nuestro sistema con unos objetos y posteriormente, clasificando otros nuevos similares.",,2020
f9b39aeef3cbd6a07e685d37e3b07598e05c8925,https://www.semanticscholar.org/paper/f9b39aeef3cbd6a07e685d37e3b07598e05c8925,"Semantics for Robotic Mapping, Perception and Interaction: A Survey","For robots to navigate and interact more richly with the world around them, they will likely require a deeper understanding of the world in which they operate. In robotics and related research fields, the study of understanding is often referred to as semantics, which dictates what does the world ‘mean’ to a robot, and is strongly tied to the question of how to represent that meaning. With humans and robots increasingly operating in the same world, the prospects of human-robot interaction also bring semantics and ontology of natural language into the picture. Driven by need, as well as by enablers like increasing availability of training data and computational resources, semantics is a rapidly growing research area in robotics. The field has received significant attention in the research literature to date, but most reviews and surveys have focused on particular aspects of the topic: the technical research issues regarding its use in specific robotic topics like mapping or segmentation, or its relevance to one particular application domain like autonomous driving. A new treatment is therefore required, and is also timely because so much relevant research has occurred since many of the key surveys were published. This survey paper therefore provides an overarching snapshot of where semantics in robotics stands today. We establish a taxonomy for semantics research in or relevant to robotics, split into four broad categories of activity, in which semantics are extracted, used, or both. Within these broad categories we survey dozens of major topics including fundamentals from the computer vision field and key robotics research areas utilizing semantics, including mapping, navigation and interaction with the world. The paper also covers key practical considerations, including enablers like increased data availability and improved computational hardware, and major application areas where semantics is or is likely to play a key role. In creating this survey, we hope to provide researchers across academia and industry with a comprehensive reference that helps facilitate future research in this exciting field.",Found. Trends Robotics,2021
1a06a1f12b6bdd8dc52e99fdfe5011d1ad4abe06,https://www.semanticscholar.org/paper/1a06a1f12b6bdd8dc52e99fdfe5011d1ad4abe06,ROI-based Robotic Grasp Detection for Object Overlapping Scenes,"Grasp detection considering the affiliations between grasps and their owner in object overlapping scenes is a necessary and challenging task for the practical use of the robotic grasping approach. In this paper, a robotic grasp detection algorithm named ROI-GD is proposed to provide a feasible solution to this problem based on Region of Interest (ROI), which is the region proposal for objects. ROI-GD uses features from ROIs to detect grasps instead of the whole scene. It has two stages: the first stage is to provide ROIs in the input image and the second-stage is the grasp detector based on ROI features. We also contribute a multi-object grasp dataset, (a) which is much larger than Cornell Grasp Dataset, by labeling Visual Manipulation Relationship Dataset. Experimental results demonstrate that ROI-GD performs much better in object overlapping scenes and at the meantime, remains comparable with state-of-the-art grasp detection algorithms on Cornell Grasp Dataset and Jacquard Dataset. Robotic experiments demonstrate that ROI-GD can help robots grasp the target in single-object and multi-object scenes with the overall success rates of 92.5% and 83.8% respectively.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2018
2a9508dbb90e53481d1dfee70b1cdc8fad434f80,https://www.semanticscholar.org/paper/2a9508dbb90e53481d1dfee70b1cdc8fad434f80,Real-Time Robotic Grasping and Localization Using Deep Learning-Based Object Detection Technique,"This work aims to increase the impact of computer vision on robotic positioning and grasping in industrial assembly lines. Real-time object detection and localization problem is addressed for robotic grasp-and-place operation using Selective Compliant Assembly Robot Arm (SCARA). The movement of SCARA robot is guided by deep learning-based object detection for grasp task and edge detection-based position measurement for place task. Deep Convolutional Neural Network (CNN) model, called KSSnet, is developed for object detection based on CNN Alexnet using transfer learning approach. SCARA training dataset with 4000 images of two object categories associated with 20 different positions is created and labeled to train KSSnet model. The position of the detected object is included in prediction result at the output classification layer. This method achieved the state-of-the-art results at 100% precision of object detection, 100% accuracy for robotic positioning and 100% successful real-time robotic grasping within 0.38 seconds as detection time. A combination of Zerocross and Canny edge detectors is implemented on a circular object to simplify the place task. For accurate position measurement, the distortion of camera lens is removed using camera calibration technique where the measured position represents the desired location to place the grasped object. The result showed that the robot successfully moved to the measured position with positioning Root Mean Square Error (0.361, 0.184) mm and 100% for successful place detection.",2019 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS),2019
31820439d1372e3327d17be6677d5feacbd6eb47,https://www.semanticscholar.org/paper/31820439d1372e3327d17be6677d5feacbd6eb47,Convolutional multi-grasp detection using grasp path for RGBD images,"Abstract Generally, most grasp detection models follow the similar frameworks as that in object detection, which use the convolutional neural network to regress the grasp parameters directly. However, grasp detection and object detection are actually different, for the ground truths in object detection are unique while that in grasp detection are not exhaustive. A predicted grasp could still be applicable despite it does not coincide well with ground truth. In this paper, a novel grasp detection model is constructed to make a fairer evaluation on grasp candidate. Instead of using isolated ground truths, the grasp path is introduced to reveal the possible consequent distribution of ground truths. The grasp candidate is first mapped to grasp path, generating the mapped grasp, and the bias between them works as the estimated error for back-propagation. Experiments deployed on grasping dataset as well as real-world scenarios show that our proposed method could improve the detection accuracy. In addition, it can be well-generalized to detect unseen objects.",Robotics Auton. Syst.,2019
54d344cfa2b3ae78199940083d2cd2b69c7a9e28,https://www.semanticscholar.org/paper/54d344cfa2b3ae78199940083d2cd2b69c7a9e28,Fast geometry-based computation of grasping points on three-dimensional point clouds,"Industrial and service robots deal with the complex task of grasping objects that have different shapes and which are seen from diverse points of view. In order to autonomously perform grasps, the robot must calculate where to place its robotic hand to ensure that the grasp is stable. We propose a method to find the best pair of grasping points given a three-dimensional point cloud with the partial view of an unknown object. We use a set of straightforward geometric rules to explore the cloud and propose grasping points on the surface of the object. We then adapt the pair of contacts to a multi-fingered hand used in experimentation. We prove that, after performing 500 grasps of different objects, our approach is fast, taking an average of 17.5 ms to propose contacts, while attaining a grasp success rate of 85.5%. Moreover, the method is sufficiently flexible and stable to work with objects in changing environments, such as those confronted by industrial or service robots.",International Journal of Advanced Robotic Systems,2019
7852fb1112961d3c26707cf470bc6d7a5054b34f,https://www.semanticscholar.org/paper/7852fb1112961d3c26707cf470bc6d7a5054b34f,A Robotic Semantic Grasping Method For Pick-and-place Tasks,"In recent years, it has attracted significant interest for mobile robots to complete the grasping tasks. A fully autonomous robotic pick-and-place system requires dependable object recognition and localization in cluttered environments. Most of current robot grasping methods based on learning mostly train the models with exploiting human-labeled datasets, then grasping perpendicularly to the plane where the object is placed. In this paper, a robotic semantic grasping method is proposed to estimate six-degree-of-freedom (6DOF) grasping pose for the robotic manipulator, thereby a grip perpendicularly to the surface of the object can be achieved. Firstly, the graspable location is detected by an instance segmentation detection model and ellipse fitting method. Secondly, by processing the pixel mask and point clouds of the target object, the 6DOF grasping pose is estimated. Finally, the proposed method was implemented and tested in a real robot manipulator. Experimental results show that the proposed semantic grasping method enables to accomplish pick-and-place tasks in an unstructured scene.",2019 Chinese Automation Congress (CAC),2019
88eb490ff3c803a29747a809a8721acd805bb4d6,https://www.semanticscholar.org/paper/88eb490ff3c803a29747a809a8721acd805bb4d6,A Multi-task Convolutional Neural Network for Autonomous Robotic Grasping in Object Stacking Scenes,"Autonomous robotic grasping plays an important role in intelligent robotics. However, how to help the robot grasp specific objects in object stacking scenes is still an open problem, because there are two main challenges for autonomous robots: (1) it is a comprehensive task to know what and how to grasp; (2) it is hard to deal with the situations in which the target is hidden or covered by other objects. In this paper, we propose a multi-task convolutional neural network for autonomous robotic grasping, which can help the robot find the target, make the plan for grasping and finally grasp the target step by step in object stacking scenes. We integrate vision-based robotic grasping detection and visual manipulation relationship reasoning in one single deep network and build the autonomous robotic grasping system. Experimental results demonstrate that with our model, Baxter robot can autonomously grasp the target with a success rate of 90.6%, 71.9% and 59.4% in object cluttered scenes, familiar stacking scenes and complex stacking scenes respectively.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2018
c1aacd34b21c3a27a2d80ceb150e7676551591fa,https://www.semanticscholar.org/paper/c1aacd34b21c3a27a2d80ceb150e7676551591fa,Integrating Perception and Optimization for Dexterous Grasping and Manipulation,Dexterous grasping and manipulation of objects are fundamental abilities for robots. Our aim is to endow robots with human-like grasping and manipulation capabilities. Four issues are addressed with the focus on the integration between perception and optimization. This thesis develops approaches that integrate visual/tactile perception with optimization for grasp and manipulation learning.,,2019
f15d0cd6dfe3e17e6189da6dae21bd7be3ba2c37,https://www.semanticscholar.org/paper/f15d0cd6dfe3e17e6189da6dae21bd7be3ba2c37,Multi-Object Grasping Detection With Hierarchical Feature Fusion,"Grasping in cluttered and tight scenes is a necessary skill for intelligent robotics to achieve more general application. Such universal robotics can use their perception abilities to visually identify grasps from a stack of objects. However, most existing grasping detection methods based on deep learning just focus on estimating grasping pose with single-layer features. In this paper, we present a novel grasp detection algorithm termed as multi-object grasping detection network, which can utilize hierarchical features to learn object detector and grasping pose estimator simultaneously. The network is mainly composed of two branches: 1) Object detection branch which is based on the single shot multibox detection approach to discriminate object categories and locate object positions by bounding boxes; 2) Grasping pose estimation branch where hierarchical features are fused together to predict grasping position and orientation. To improve grasping detection performance, attention mechanism is employed in hierarchical feature fusion. For evaluating the proposed model, we build a multi-object grasping dataset where every image contains numerous different graspable objects. The extensive experiments demonstrate that the multi-object grasping detection method achieves the state-of-the-art performance on both object detection and grasping pose estimation.",IEEE Access,2019
f5390164a577af28e562d89f9e35bc5feafddf6f,https://www.semanticscholar.org/paper/f5390164a577af28e562d89f9e35bc5feafddf6f,Kernel Regularized Nonlinear Dictionary Learning for Sparse Coding,"For most sparse coding methods, data samples are first encoded as hand-crafted features, followed by another separate learning step that generates dictionary and sparse codes. However, such feature representations may not be optimally compatible with the learning process, thus producing suboptimal results. In this paper, we propose a new architecture for nonlinear dictionary learning with sparse coding, in which samples are mapped into sparse codes via carefully designed stacked auto-encoder (SAE) networks. We jointly learn a low-dimensional embedding of the data samples by means of an SAE and a dictionary in the low-dimensional space. Further, to leverage the prior knowledge, we develop a kernel regularized nonlinear dictionary learning method, which effectively incorporates the knowledge provided by the hand-crafted kernel. An iterative algorithm is developed to jointly search the solutions of the associated optimization problem and extensive experimental validations are performed to show that the proposed kernel regularized dictionary learning method achieves satisfactory performance.","IEEE Transactions on Systems, Man, and Cybernetics: Systems",2019
f68ff7401b39f4eb67cbe059c5e16274ac4406fb,https://www.semanticscholar.org/paper/f68ff7401b39f4eb67cbe059c5e16274ac4406fb,PointNetGPD: Detecting Grasp Configurations from Point Sets,"In this paper, we propose an end-to-end grasp evaluation model to address the challenging problem of localizing robot grasp configurations directly from the point cloud. Compared to recent grasp evaluation metrics that are based on handcrafted depth features and a convolutional neural network (CNN), our proposed PointNetGPD is lightweight and can directly process the 3D point cloud that locates within the gripper for grasp evaluation. Taking the raw point cloud as input, our proposed grasp evaluation network can capture the complex geometric structure of the contact area between the gripper and the object even if the point cloud is very sparse. To further improve our proposed model, we generate a large-scale grasp dataset with 350k real point cloud and grasps with the YCB object set for training. The performance of the proposed model is quantitatively measured both in simulation and on robotic hardware. Experiments on object grasping and clutter removal show that our proposed model generalizes well to novel objects and outperforms state-of-the-art methods. Code and video are available at https://lianghongzhuo.github.io/PointNetGPD.",2019 International Conference on Robotics and Automation (ICRA),2018
0066dc9131c25e93111fc092098f6c9db6255f1a,https://www.semanticscholar.org/paper/0066dc9131c25e93111fc092098f6c9db6255f1a,RoI-based Robotic Grasp Detection in Object Overlapping Scenes Using Convolutional Neural Network,"Grasp a specific target in object stacking and overlapping scenes is a necessary and challenging task for practical use of robotic grasp. In this paper, we propose a robotic grasp detection algorithm based on Region of Interest (RoI) to simultaneously detect targets and their grasps in object overlapping scenes. Our proposed algorithm uses Regions of Interest (RoIs) to detect grasps while doing classification and location regression of targets. To train the network, we contribute a much bigger multi-object grasp dataset than Cornell Grasp Dataset, which is based on Visual Manipulation Relationship Dataset. Experimental results demonstrate that our algorithm achieves 24.9% miss rate at 1FPPI and 68.2% mAP with grasp on our dataset. Robotic experiments demonstrate that our proposed algorithm can help robots grasp specific target in multi-object scenes at 84% success rate.",ArXiv,2018
139763a0b2e78b63b245a456f2b9dbde2d1d573c,https://www.semanticscholar.org/paper/139763a0b2e78b63b245a456f2b9dbde2d1d573c,"RPRG: Toward Real-time Robotic Perception, Reasoning and Grasping with One Multi-task Convolutional Neural Network","Autonomous robotic grasp plays an important role in intelligent robotics. However, it is challenging due to: (1) robotic grasp is a comprehensive task involving perception, planning and control; (2) autonomous robotic grasp in complex scenarios requires reasoning ability. In this paper, we propose a multi-task convolutional neural network for Robotic Perception, Reasoning and Grasping (RPRG), which can help robot find the target, make the plan for grasping and finally grasp the target step by step in object stacking scenes. We integrate vision-based robotic grasp detection and visual manipulation relationship reasoning in one single deep network and build the autonomous robotic grasp system. The proposed network has state-of-the-art performance in both tasks. Experiments demonstrate that with our model, Baxter robot can autonomously grasp the target with a success rate of 94.2%, 77.1% and 62.5% in object cluttered scenes, familiar stacking scenes and complex stacking scenes respectively at a speed of 6.5 FPS for each detection.",ArXiv,2018
35acc067686b33f6b75f604960e60dc69dadbfc3,https://www.semanticscholar.org/paper/35acc067686b33f6b75f604960e60dc69dadbfc3,Deep Learning for Object Detection and Grasping: A Survey,"Detecting and grasping objects in unstructured environments is an important yet difficult task. Fortunately, the breakthroughs from deep convolutional networks stimulate the development of object detection and grasping. The survey aims to serve as a comparison for region-based and region-free detection framework based on deep learning, and supplies the latest research results of object grasping with deep learning. Firstly, we briefly analyze the object detection and grasping. Then, the representative object detection methods based on deep learning are overviewed. Thirdly, we introduce the application of convolutional neural networks in object grasping. Finally, the potential trends in object detection and grasping based on deep learning are discussed.",2018 IEEE International Conference on Information and Automation (ICIA),2018
58d7d8c9259de34f2c6a7f4ec522f5fc09fbab11,https://www.semanticscholar.org/paper/58d7d8c9259de34f2c6a7f4ec522f5fc09fbab11,Research on adaptive grasping with object pose uncertainty by multi-fingered robot hand,"In the process of grasping objects by robot, the uncertainty of the object pose has greater impact on the stability of grasping. In this article, an adaptive grasping strategy is proposed to solve the problem of pose uncertainty in the grasping process. The strategy is based on the finger state function to switch control method, so as to realize the contact with the object by the fingers, and the application of grasp force to ensure the pre-grasp stability of the object; then, the object pose error is estimated through the contact between finger and object, and the pose error of the object is compensated according to the different error ranges to reduce the influence of the pose error on the grasp stability. Finally, the grasping experiments by humanoid robot are carried out to verify the performance of the adaptive grasping method proposed in this article.",,2018
59c23afa9e53f97a28da3abbecb3d1eb8d05985b,https://www.semanticscholar.org/paper/59c23afa9e53f97a28da3abbecb3d1eb8d05985b,A Survey on Deep Learning Methods for Robot Vision,"Deep learning has allowed a paradigm shift in pattern recognition, from using hand-crafted features together with statistical classifiers to using general-purpose learning procedures for learning data-driven representations, features, and classifiers together. The application of this new paradigm has been particularly successful in computer vision, in which the development of deep learning methods for vision applications has become a hot research topic. Given that deep learning has already attracted the attention of the robot vision community, the main purpose of this survey is to address the use of deep learning in robot vision. To achieve this, a comprehensive overview of deep learning and its usage in computer vision is given, that includes a description of the most frequently used neural models and their main application areas. Then, the standard methodology and tools used for designing deep-learning based vision systems are presented. Afterwards, a review of the principal work using deep learning in robot vision is presented, as well as current and future trends related to the use of deep learning in robotics. This survey is intended to be a guide for the developers of robot vision systems.",ArXiv,2018
a040e235254edac7fa5b991ce31aceb54749082a,https://www.semanticscholar.org/paper/a040e235254edac7fa5b991ce31aceb54749082a,"Object Recognition, Localization and Grasp Detection Using a Unified Deep Convolutional Neural Network with Multi-task Loss","Recognize an object and detect a good grasp in unstructured scenes is still a challenge. In this paper, the problem of detecting robotic grasps is expressed by a two-point representation in an unstructured scene with an RGB-D camera. A deep Convolutional Neural Network is designed to predict good grasps in real-time on GTX1080, with using region proposal techniques. A contribution of this work is our proposed network framework can perform classification, location and grasp detection simultaneously so that in a single step, it not only recognizes the category and bounding-box of the object, but also finds a good grasp line. Besides, in training process, we minimize a multi-task loss objective function of object classification, location and grasp detection in order to train the network end-to-end. Our experimental evaluation on a real robotic manipulator demonstrates that the robotic manipulator can fulfill the grasping task effectively.",2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),2018
b45e2580f40059205f2ba018428f6b8f33f44436,https://www.semanticscholar.org/paper/b45e2580f40059205f2ba018428f6b8f33f44436,Scene Recognition and Object Detection in a Unified Convolutional Neural Network on a Mobile Manipulator,"Environment understanding, object detection and recognition are crucial skills for robots operating in the real world. In this paper, we propose a Convolutional Neural Network with multi-task objectives: object detection and scene classification in one unified architecture. The proposed network reasons globally about an image to understand the scene, hypothesize object locations, and encodes global scene features with regional object features to improve object recognition. We evaluate our network on the standard SUN RGBD dataset. Experiments show that our approach outperforms state-of-the-arts. Network predictions are further transformed into continuous robot beliefs to ensure temporal coherence and extended to 3D space for robotics applications. We embed the whole framework in Robot Operating System, and evaluate its performance on a real robot for semantic mapping and grasp detection.",2018 IEEE International Conference on Robotics and Automation (ICRA),2018
d4c8b707f0360183f2efd8118a07fa46abb58646,https://www.semanticscholar.org/paper/d4c8b707f0360183f2efd8118a07fa46abb58646,Automated task planning using object arrangement optimization,"We present a method enabling a robot to automatically arrange objects using task and motion planning. Given an input scene consisting of cluttered objects, our method first constructs a target layout of objects as a guidance to the robot for arranging them. For constructing the layout, we use positive examples and pre-extract hierarchical, spatial and pairwise relationships between objects, to understand the user preference on arranging objects. Our method then enables a robot to arrange input objects to reach their target configurations using any task and motion planner. To efficiently arrange the objects, we also propose a priority layer that decides an order of arranging objects to take a small amount of actions. This is achieved by utilizing a dependency graph between objects. We test our method in three different scenes with varying numbers of objects, and apply our method to two well-known task and motion planners with the virtual PR2 robot. We demonstrate that we can use the robot to automatically arrange objects, and show that our priority layer reduces the total running time up to 2.15 times in those tested planners.",2018 15th International Conference on Ubiquitous Robots (UR),2018
eccf0ec99a00db2d95a5cb06747b6e80b1cb780c,https://www.semanticscholar.org/paper/eccf0ec99a00db2d95a5cb06747b6e80b1cb780c,A learning framework for semantic reach-to-grasp tasks integrating machine learning and optimization,"Abstract The ability to implement semantic Reach-to-grasp (RTG) tasks successfully is a crucial skill for robots. Given unknown objects in an unstructured environment, finding an feasible grasp configuration and generating a constraint-satisfied trajectory to reach it are challenging. In this paper, a learning framework which combines semantic grasp planning with trajectory generation is presented to implement semantic RTG tasks. Firstly, the object of interest is detected by using an object detection model trained by deep learning. A Bayesian-based search algorithm is proposed to find the grasp configuration with highest probability of success from the segmented image of the object using a trained quality network. Secondly, for robotic reaching movements, a model-based trajectory generation method inspired by the human internal model theory is designed to generate a constraint-satisfied trajectory. Finally, the presented framework is validated both in comparative analysis and on real-world experiments. Experimental results demonstrated that the proposed learning framework enables the robots to implement semantic RTG tasks in unstructured environments.",Robotics Auton. Syst.,2018
f2c81514000f2399fdf59f789b99990c512be143,https://www.semanticscholar.org/paper/f2c81514000f2399fdf59f789b99990c512be143,Visual Manipulation Relationship Network for Autonomous Robotics,"Robotic grasping is one of the most important fields in robotics, in which great progress has been made in recent years with the help of convolutional neural network (CNN). However, including multiple objects in one scene can invalidate the existing CNN-based grasp detection algorithms, because manipulation relationships among objects are not considered, which are required to guide the robot to grasp things in the right order. This paper presents a new CNN architecture called Visual Manipulation Relationship Network (VMRN) to help robots detect targets and predict the manipulation relationships in real time, which ensures that the robot can complete tasks in a safe and reliable way. To implement end-to-end training and meet real-time requirements in robot tasks, we propose the Object Pairing Pooling Layer (OP2L) to help to predict all manipulation relationships in one forward process. Moreover, in order to train VMRN, we collect a dataset named Visual Manipulation Relationship Dataset (VMRD) consisting of 5185 images with more than 17000 object instances and the manipulation relationships between all possible pairs of objects in every image, which is labeled by the manipulation relationship tree. The experimental results show that the new network architecture can detect objects and predict manipulation relationships simultaneously and meet the real-time requirements in robot tasks.",2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),2018
f533c6f9bf9db68a5a2826deb31fed169579bef8,https://www.semanticscholar.org/paper/f533c6f9bf9db68a5a2826deb31fed169579bef8,Experiment on impedance adaptation of under-actuated gripper using tactile array under unknown environment,"The experiment on impedance adaptation to achieve stable grasp for an under-actuated gripper grasping different unknown objects with tactile array is conducted. Under-actuated gripper has a wildly application in the field of space robot and industrial robot because of its better shape-adaptation. However it is difficult to achieve stable grasp owning to the uncertain properties of environment. A control strategy of adaptive matching the impedance parameters is proposed to achieve stable grasp. Firstly, the unknown objects are described as linear systems with unknown dynamics, and the parameters of the object are identified with the recursive least-squares (RLS) method through tactile sensor array. Then a desired impedance model is obtained by defining a cost function that includes the contact force, velocity and displacement errors, and the critical impedance parameters are found to minimize it. Finally, an experiment is presented and shows that the proposed impedance model can guarantee the stable grasp for various unknown objects.",Science China Information Sciences,2018
15981416a5b1dd7770c2946e53d33f477f5b00d5,https://www.semanticscholar.org/paper/15981416a5b1dd7770c2946e53d33f477f5b00d5,Research for path planning based on improved astart algorithm,"Astar algorithm (also calls as A∗ algorithm) is often applied into robot path planning because of its simple, high efficiency and optimized path, but some disadvantages are also in it. The path by the tradition A∗ algorithm often contains many redundant points and inflection points. In order to reduce these points, the improved A∗ algorithm is put forward in this paper, which simplified the path nodes by using the smoothing method and reduced the inflection points by weighted processing of evaluation function. In addition, the actual width of the robot is taken into account when the robot bypasses obstacles, and the concept of node priority to the process of generating sub-nodes is proposed to solving it. The simulation results proves the effectiveness of the improved A∗ algorithm.","2017 4th International Conference on Information, Cybernetics and Computational Social Systems (ICCSS)",2017
24b3bf1702d123d57510f9576496109aa4789270,https://www.semanticscholar.org/paper/24b3bf1702d123d57510f9576496109aa4789270,Robotic grasping using visual and tactile sensing,"Abstract Visual and tactile sensing are complementary factors in the task of robotic grasping. In this paper, a grasp detection deep network is first proposed to detect the grasp rectangle from the visual image， then a new metric using tactile sensing is designed to assess the stability of the grasp. By means of this scheme, a THU grasp dataset， which includes the visual information, corresponding tactile and grasp configurations， is collected to train the proposed deep network. Experiments results have demonstrated that the proposed grasp detection deep networks outperform other mainstream approaches in a public grasp dataset. Furthermore， the grasp success rate can be improved significantly in real world scenarios. The trained model has also been successfully implemented in a new robotic platform to perform the robotic grasping task in a cluttered scenario.",Inf. Sci.,2017
6f0670577834380b8211b29f8af3470dceb45519,https://www.semanticscholar.org/paper/6f0670577834380b8211b29f8af3470dceb45519,Robotic teleoperation systems using a wearable multimodal fusion device,"Teleoperation is of great importance in the area of robotics especially when people’s presence at the robot working space is unavailable. It provides an alternative to employ human intelligence in the control of the robot remotely. We establish robotic teleoperation systems with a wearable multimodal fusion device. The device is integrated with 18 low-cost inertial and magnetic measurement units, which cover all segments of the arm and hand. The multimodal fusion algorithm based on extended Kalman filter is deduced to determine the orientations and positions of each segment. Then, the robotic teleoperation systems using the proposed device are designed. The novel teleoperation schemes can be applied for 11DOF robotic arm–hand system and 10DOF robotic arm–hand system, in which the operator’s fingers are used for robotic hand teleoperation, and the arms with palm are used for robotic arm teleoperation. Meanwhile, the proposed robotic teleoperation systems are fully realized with a user-friendly human–machine interaction interface. Finally, a series of experiments are conducted with our robotic teleoperation system successfully.",,2017
8f30255dab5498cb8c6fbc5fedfa5ee001735d03,https://www.semanticscholar.org/paper/8f30255dab5498cb8c6fbc5fedfa5ee001735d03,Nadine: A Social Robot that Can Localize Objects and Grasp Them in a Human Way,"What makes a social humanoid robot behave like a human? It needs to understand and show emotions, has a chat box, a memory and also a decision-making process. However, more than that, it needs to recognize objects and be able to grasp them in a human way. To become an intimate companion, social robots need to behave the same way as real humans in all areas and understand real situations in order they can react properly. In this chapter, we describe our ongoing research on social robotics. It includes the making of articulated hands of Nadine Robot, the recognition of objects and their signification, as well as how to grasp them in a human way. State of the art is presented as well as some early results.",,2017
a09d1ea248e56f9d82346f8df07be36a4594f49d,https://www.semanticscholar.org/paper/a09d1ea248e56f9d82346f8df07be36a4594f49d,Deep learning for picking point detection in dense cluster,"This paper considers the problem of picking objects in cluster. This requires the robot to reliably detect the picking point for the known or unseen objects under the environment with occlusion, disorder and a variety of objects. We present a novel pipeline to detect picking point based on deep convolutional neural network (CNN). A two-dimensional picking configuration is proposed, thus an extensive data augmentation strategy is enabled and a labeled dataset is established quickly and easily. At last, we demonstrate the implementation of our method on a real robot and show that our method can accurately detect picking point of unseen objects and achieve a pick success of 91% in cluster bin-picking scenario.",2017 11th Asian Control Conference (ASCC),2017
dcf011d28a4aabf995296e6e6668f210ecc3fe78,https://www.semanticscholar.org/paper/dcf011d28a4aabf995296e6e6668f210ecc3fe78,A hybrid deep architecture for robotic grasp detection,"The robotic grasp detection is a great challenge in the area of robotics. Previous work mainly employs the visual approaches to solve this problem. In this paper, a hybrid deep architecture combining the visual and tactile sensing for robotic grasp detection is proposed. We have demonstrated that the visual sensing and tactile sensing are complementary to each other and important for the robotic grasping. A new THU grasp dataset has also been collected which contains the visual, tactile and grasp configuration information. The experiments conducted on a public grasp dataset and our collected dataset show that the performance of the proposed model is superior to state of the art methods. The results also indicate that the tactile data could help to enable the network to learn better visual features for the robotic grasp detection task.",2017 IEEE International Conference on Robotics and Automation (ICRA),2017
e60e287fa181eace7e716ccadcb12cef85ab11d6,https://www.semanticscholar.org/paper/e60e287fa181eace7e716ccadcb12cef85ab11d6,Vision-based Robotic Grasp Success Determination with Convolutional Neural Network,"We present two Convolutional Neural Network (CNN) models to determine whether a robot successfully grasps the target object using RGB image as input. As we know, this is the first time that vision is applied to help robot determine if something is grasped by itself. Our network performs end-to-end classification on our own dataset collected using Baxter Robot. This requires the network to acquire the refined spatial relationship between gripper and target in the image. Compared with traditional ways of using only force and distance sensors, which are restricted in terms of object size, weight and grasp postures, vision-based CNN models have potential ability to be applied in wider range and are more similar to human ways in aspect of perceiving environment. The experimental result shows that it is feasible to use images to help robot determine whether the target is grasped to overcome the drawbacks of only using force or distance sensors. In addition, we also test our networks on Baxter Robot, the results show that our models have good generalization ability and can fit the situation of real world well.","2017 IEEE 7th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",2017
ed2a9e275bb9c6c8465a34b5e977aa8da56a4f41,https://www.semanticscholar.org/paper/ed2a9e275bb9c6c8465a34b5e977aa8da56a4f41,Sparse Dictionary Learning for Identifying Grasp Locations,"The ability to grasp ordinary and potentially never-seen objects is an important task in both domestic and industrial robotics. For a system to accomplish this, it must autonomously identify grasping locations by using information from various sensors, such as Microsoft Kinect 3D camera. Despite numerous progress, significant work still remains to be done for this task. To this effect, we propose a dictionary learning and sparse representation (DLSR) framework for representing RGBD images from 3D sensors in the context of identifying grasping locations. In contrast to previously proposed approaches that relied on sophisticated regularization or very large datasets, our derived perception system has a fast training phase and can work with small datasets. It is also theoretically founded for dealing with masked-out entries, which are common with 3D sensors. We contribute by presenting a comparative study of several DLSR approach combinations for recognizing and detecting grasp candidates on the standard Cornell dataset. Experimental results show a performance improvement of 1.69% in detection and 3.16% in recognition over current state-of-the-art convolutional neural network (CNN). Even though nowadays most popular vision-based approach is CNN, this suggests that DLSR is also a viable alternative with interesting advantages that CNN has not.",2017 IEEE Winter Conference on Applications of Computer Vision (WACV),2017
fd14b4990a1a408892670c018a13bca62e7e9f93,https://www.semanticscholar.org/paper/fd14b4990a1a408892670c018a13bca62e7e9f93,Saliency based proposal refinement in robotic vision,"Detecting object grasps from the given image has attracted lots of research concerns in the field of robotic vision. Despite many solutions have been proposed, they tend to simply focus on the detection problem and strongly assume that the object has been placed in the ideal viewing position. In this paper, we propose to refine object proposal based on the saliency measurement. It can be used to refine the object detection results and further guides the self-movement of robotic arm to achieve a better grasping state. First, we dilate the inaccurate proposal to cover more object regions and extract object using saliency-like evaluation measurement. Then, we use superpixel-based sliding windows with various scales and aspect ratios to localize region with highest response. Compared with traditionally exhaustive sliding search, our method reduces the number of sliding windows and hence runs faster. Experiments on public dataset and real test both verify the effectiveness of our proposal method.",2017 IEEE International Conference on Real-time Computing and Robotics (RCAR),2017
d6d54eef35dc17a66993e9b6c3154358d61de048,https://www.semanticscholar.org/paper/d6d54eef35dc17a66993e9b6c3154358d61de048,Deep vision networks for real-time robotic grasp detection,"Grasping has always been a great challenge for robots due to its lack of the ability to well understand the perceived sensing data. In this work, we propose an end-to-end deep vision network model to predict possible good grasps from real-world images in real time. In order to accelerate the speed of the grasp detection, reference rectangles are designed to suggest potential grasp locations and then refined to indicate robotic grasps in the image. With the proposed model, the graspable scores for each location in the image and the corresponding predicted grasp rectangles can be obtained in real time at a rate of 80 frames per second on a graphic processing unit. The model is evaluated on a real robot-collected data set and different reference rectangle settings are compared to yield the best detection performance. The experimental results demonstrate that the proposed approach can assist the robot to learn the graspable part of the object from the image in a fast manner.",,2016
4a63b989d5e57db351ce5b780cf1fdbecc42591a,https://www.semanticscholar.org/paper/4a63b989d5e57db351ce5b780cf1fdbecc42591a,ADMM-Based Adaptive Sampling Strategy for Nonholonomic Mobile Robotic Sensor Networks,"This paper discusses the adaptive sampling problem in a nonholonomic mobile robotic sensor network for efficiently monitoring a spatial field. It is proposed to employ Gaussian process to model a spatial phenomenon and predict it at unmeasured positions, which enables the sampling optimization problem to be formulated by the use of the log determinant of a predicted covariance matrix at next sampling locations. The control, movement and nonholonomic dynamics constraints of the mobile sensors are also considered in the adaptive sampling optimization problem. In order to tackle the nonlinearity and nonconvexity of the objective function in the optimization problem we first exploit the linearized alternating direction method of multipliers (L-ADMM) method that can effectively simplify the objective function, though it is computationally expensive since a nonconvex problem needs to be solved exactly in each iteration. We then propose a novel approach called the successive convexified ADMM (SC-ADMM) that sequentially convexify the nonlinear dynamic constraints so that the original optimization problem can be split into convex subproblems. It is noted that both the L-ADMM algorithm and our SC-ADMM approach can solve the sampling optimization problem in either a centralized or a distributed manner. We validated the proposed approaches in 1000 experiments in a synthetic environment with a real-world dataset, where the obtained results suggest that both the L-ADMM and SC-ADMM techniques can provide good accuracy for the monitoring purpose. However, our proposed SC-ADMM approach computationally outperforms the L-ADMM counterpart, demonstrating its better practicality.",IEEE Sensors Journal,2021
4abeaff51eae2eb035b8ef8a900b6626406678c2,https://www.semanticscholar.org/paper/4abeaff51eae2eb035b8ef8a900b6626406678c2,An Information-Motivated Exploration Agent to Locate Stationary Persons with Wireless Transmitters in Unknown Environments,"Unmanned Aerial Vehicles (UAVs) show promise in a variety of applications and recently were explored in the area of Search and Rescue (SAR) for finding victims. In this paper we consider the problem of finding multiple unknown stationary transmitters in a discrete simulated unknown environment, where the goal is to locate all transmitters in as short a time as possible. Existing solutions in the UAV search space typically search for a single target, assume a simple environment, assume target properties are known or have other unrealistic assumptions. We simulate large, complex environments with limited a priori information about the environment and transmitter properties. We propose a Bayesian search algorithm, Information Exploration Behaviour (IEB), that maximizes predicted information gain at each search step, incorporating information from multiple sensors whilst making minimal assumptions about the scenario. This search method is inspired by the information theory concept of empowerment. Our algorithm shows significant speed-up compared to baseline algorithms, being orders of magnitude faster than a random agent and 10 times faster than a lawnmower strategy, even in complex scenarios. The IEB agent is able to make use of received transmitter signals from unknown sources and incorporate both an exploration and search strategy.",Sensors,2021
7588472967e84fb276b86b4a830da5f9c0e8ebd7,https://www.semanticscholar.org/paper/7588472967e84fb276b86b4a830da5f9c0e8ebd7,Online and Adaptive Parking Availability Mapping: An Uncertainty-Aware Active Sensing Approach for Connected Vehicles,"Research on connected vehicles represents a continuously evolving technological domain, fostered by the emerging Internet of Things paradigm and the recent advances in intelligent transportation systems. In the context of assisted driving, connected vehicle technology provides real-time information about the surrounding traffic conditions. In this regard, we propose an online and adaptive scheme for parking availability mapping. Specifically, we adopt an information-seeking active sensing approach to select the incoming data, thus preserving the onboard storage and processing resources; then, we estimate the parking availability through Gaussian Process Regression. We compare the proposed algorithm with several baselines, which attain lower performance in terms of mapping convergence speed and adaptation capabilities.",2021 IEEE Intelligent Vehicles Symposium Workshops (IV Workshops),2021
ad5e1f60da6c7d8871e35e46c1ef8af197e1e1a6,https://www.semanticscholar.org/paper/ad5e1f60da6c7d8871e35e46c1ef8af197e1e1a6,Opportunistic Multi-robot Environmental Sampling via Decentralized Markov Decision Processes,"We study the problem of information sampling with a group of mobile robots from an unknown environment. Each robot is given a unique region in the environment for the sampling task. The objective of the robots is to visit a subset of locations in the environment such that the collected information is maximized, and consequently, the underlying information model matches as close to reality as possible. The robots have limited communication ranges, and therefore can only communicate when nearby one another. The robots operate in a stochastic environment and their control uncertainty is handled using factored Decentralized Markov Decision Processes (Dec-MDP). When two or more robots communicate, they share their past noisy observations and use a Gaussian mixture model to update their local information models. This in turn helps them to obtain a better Dec-MDP policy. Simulation results show that our proposed strategy is able to predict the information model closer to the ground truth version than compared to other algorithms. Furthermore, the reduction in the overall uncertainty is more than comparable algorithms.",DARS,2021
cbd9d76e572c2146e272096a4448ca140ff1986b,https://www.semanticscholar.org/paper/cbd9d76e572c2146e272096a4448ca140ff1986b,LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning,"Efficient exploration is important for reinforcement learners (RL) to achieve high rewards. In multi-agent systems, coordinated exploration and behaviour is critical for agents to jointly achieve optimal outcomes. In this paper, we introduce a new general framework for improving coordination and performance of multi-agent reinforcement learners (MARL). Our framework, named Learnable Intrinsic-Reward Generation Selection algorithm (LIGS) introduces an adaptive learner, Generator that observes the agents and learns to construct intrinsic rewards online that coordinate the agents’ joint exploration and joint behaviour. Using a novel combination of reinforcement learning (RL) and switching controls, LIGS determines the best states to learn to add intrinsic rewards which leads to a highly efficient learning process. LIGS can subdivide complex tasks making them easier to solve and enables systems of RL agents to quickly solve environments with sparse rewards. LIGS can seamlessly adopt existing multi-agent RL algorithms and our theory shows that it ensures convergence to joint policies that deliver higher system performance. We demonstrate the superior performance of the LIGS framework in challenging tasks in Foraging and StarCraft II.",ArXiv,2021
cdabc8b5903c733297b8f524efcc1c1800f090c6,https://www.semanticscholar.org/paper/cdabc8b5903c733297b8f524efcc1c1800f090c6,Fully Distributed Informative Planning for Environmental Learning with Multi-Robot Systems,"This paper proposes a cooperative environmental learning algorithm working in a fully distributed manner. A multi-robot system is more effective for exploration tasks than a single robot, but it involves the following challenges: i) online distributed learning of environmental map using multiple robots; ii) generation of safe and efficient exploration path based on the learned map; and iii) maintenance of the scalability with respect to the number of robots. To this end, we divide the entire process into two stages of environmental learning and path planning. Distributed algorithms are applied in each stage and combined through communication between adjacent robots. The environmental learning algorithm uses a distributed Gaussian process, and the path planning algorithm uses a distributed Monte Carlo tree search. As a result, we build a scalable system without the constraint on the number of robots. Simulation results demonstrate the performance and scalability of the proposed system. Moreover, a real-world-dataset-based simulation validates the utility of our algorithm in a more realistic scenario.",ArXiv,2021
0ac1281cfd20499c47a4839c561089e32cfee77d,https://www.semanticscholar.org/paper/0ac1281cfd20499c47a4839c561089e32cfee77d,BeeCluster: drone orchestration via predictive optimization,"The rapid development of small aerial drones has enabled numerous drone-based applications, e.g., geographic mapping, air pollution sensing, and search and rescue. To assist the development of these applications, we propose BeeCluster, a drone orchestration system that manages a fleet of drones. BeeCluster provides a virtual drone abstraction that enables developers to express a sequence of geographical sensing tasks, and determines how to map these tasks to the fleet efficiently. BeeCluster's core contribution is predictive optimization, in which an inferred model of the future tasks of the application is used to generate an optimized flight and sensing schedule for the drones that aims to minimize the total expected execution time. We built a prototype of BeeCluster and evaluated it on five real-world case studies with drones in outdoor environments, measuring speedups from 11.6% to 23.9%.",MobiSys,2020
42413c946894f8ca1f2265f2f26e80a87da6cff3,https://www.semanticscholar.org/paper/42413c946894f8ca1f2265f2f26e80a87da6cff3,Fusion of information from multiple robots,"Abstract Whilst scaling the size of multi-robot team has its pros and cons as described in the previous chapter, often the size of the environment to be monitored necessitates a multi-robot setup. Thus, if a disconnected and decentralized team of agents is considered, multiple intermediate GP models (one model per agent) will be obtained with no communication overhead. Given the limited number of observations available to each agent, each of these will have the capability to explain the environmental dynamics to a certain extent, but the question is: which model can be trusted? Simply put, ignoring some of the models generated leads to information waste whilst multiple models cannot be used to decipher the true underlying dynamics unless they are fused. To this end, this chapter describes a novel discrete weighted posterior fusion mechanism referred to as FuDGE which allows for taking the confidence over the prediction of each expert whilst fusing the posteriors. As opposed to existing works which directly perform model fusion, this approach is amicable to real robot deployment in the sense that learning is only required whilst the robots are observing the environment and individual models are being optimized. At the end of all missions, the posteriors are fused based on the quality of learnt models. This fusion approach has shown promising results when evaluated over a real-world Ozone dataset.",,2020
48a4fcf3c8aea0ae464bb124872dc5672b44ebbb,https://www.semanticscholar.org/paper/48a4fcf3c8aea0ae464bb124872dc5672b44ebbb,Multi-Agent Safe Planning with Gaussian Processes,"Multi-agent safe systems have become an increasingly important area of study as we can now easily have multiple AI-powered systems operating together. In such settings, we need to ensure the safety of not only each individual agent, but also the overall system. In this paper, we introduce a novel multi-agent safe learning algorithm that enables decentralized safe navigation when there are multiple different agents in the environment. This algorithm makes mild assumptions about other agents and is trained in a decentralized fashion, i.e. with very little prior knowledge about other agents’ policies. Experiments show our algorithm performs well with the robots running other algorithms when optimizing various objectives.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
767427781b53687118a6ea77bdf7d56e9f9dc66d,https://www.semanticscholar.org/paper/767427781b53687118a6ea77bdf7d56e9f9dc66d,An Integrated Strategy for Autonomous Exploration of Spatial Processes in Unknown Environments,"Exploration of spatial processes, such as radioactivity or temperature is a fundamental task in many robotic applications. In the literature, robotic exploration is mainly carried out for applications where the environment is a priori known. However, for most real life applications this assumption often does not hold, specifically for disaster scenarios. In this paper, we propose a novel integrated strategy that allows a robot to explore a spatial process of interest in an unknown environment. To this end, we build upon two major blocks. First, we propose the use of GP to model the spatial process of interest, and process entropy to drive the exploration. Second, we employ registration algorithms for robot mapping and localization, and frontier-based exploration to explore the environment. However, map and process exploration can be conflicting goals. Our integrated strategy fuses the two aforementioned blocks through a trade-off between process and map exploration. We carry out extensive evaluations of our algorithm in simulated environments with respect to different baselines and environment setups using simulated GP data as a process at hand. Additionally, we perform experimental verification with a mobile holonomic robot exploring a simulated process in an unknown labyrinth environment. Demonstrated results show that our integrated strategy outperforms both frontier-based and GP entropy-driven exploration strategies.",Sensors,2020
78c9398da94970743e358ca5ea39efbe375f5eb9,https://www.semanticscholar.org/paper/78c9398da94970743e358ca5ea39efbe375f5eb9,An Approach to Reduce Communication for Multi-agent Mapping Applications,"In the context of a multi-agent system that uses a Gaussian process to estimate a spatial field of interest, we propose an approach that enables an agent to reduce the amount of data it shares with other agents. The main idea of the strategy is to rigorously assign a novelty metric to each measurement as it is collected, and only measurements that are sufficiently novel are communicated. We consider the ideal scenario where an agent can instantly share novel measurements, and we also consider the more practical scenario in which communication suffers from low bandwidth and is range-limited. For this scenario, an agent can only broadcast an informative subset of the novel measurements when the agent encounters other agents. We explore three different informative criteria for subset selection, namely entropy, mutual information, and a new criterion that reflects the value of a measurement. We apply our approach to three real-world datasets relevant to robotic mapping. The empirical findings show that an agent can reduce the amount of communicated measurements by two orders of magnitude and that the new criterion for subset selection yields superior predictive performance relative to entropy and mutual information.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
9da1ff75a3416c3693d4ba38a9c5c5cafccb2700,https://www.semanticscholar.org/paper/9da1ff75a3416c3693d4ba38a9c5c5cafccb2700,An Extended Bayesian Optimization Approach to Decentralized Swarm Robotic Search,"Swarm robotic search aims at searching targets using a large number of collaborating simple mobile robots, with applications to search and rescue and hazard localization. In this regard, decentralized swarm systems are touted for their coverage scalability, time efficiency, and fault tolerance. To guide the behavior of such swarm systems, two broad classes of approaches are available, namely, nature-inspired swarm heuristics and multi-robotic search methods. However, the ability to simultaneously achieve efficient scalability and provide fundamental insights into the exhibited behavior (as opposed to exhibiting a black-box behavior) remains an open problem. To address this problem, this paper extends the underlying search approach in batch-Bayesian optimization to perform search with embodied swarm agents operating in a (simulated) physical 2D arena. Key contributions lie in (1) designing an acquisition function that not only balances exploration and exploitation across the swarm but also allows modeling knowledge extraction over trajectories and (2) developing its distributed implementation to allow asynchronous task inference and path planning by the swarm robots. The resulting collective informative path planning approach is tested on target-search case studies of varying complexity, where the target produces a spatially varying (measurable) signal. Notably, superior performance, in terms of mission completion efficiency, is observed compared to exhaustive search and random walk baselines as well as a swarm optimization-based state-of-theart method. Favorable scalability characteristics are also demonstrated. [DOI: 10.1115/1.4046587]",J. Comput. Inf. Sci. Eng.,2020
9f9cac251c48afd012ad95ee77e3ea14e44ba849,https://www.semanticscholar.org/paper/9f9cac251c48afd012ad95ee77e3ea14e44ba849,Multi-Robot Active Sensing and Environmental Model Learning With Distributed Gaussian Process,"This letter deals with the problem of multiple robots working together to explore and gather at the global maximum of the unknown field. Given noisy sensor measurements obtained at the location of robots with no prior knowledge about the environmental map, Gaussian process regression can be an efficient solution to construct a map that represents spatial information with confidence intervals. However, because the conventional Gaussian process algorithm operates in a centralized manner, it is difficult to process information coming from multiple distributed sensors in real-time. In this work, we propose a multi-robot exploration algorithm that deals with the following challenges: i) distributed environmental map construction using networked sensing platforms; ii) online learning using successive measurements suitable for a multi-robot team; iii) multi-agent coordination to discover the highest peak of an unknown environmental field with collision avoidance. We demonstrate the effectiveness of our algorithm via simulation and a topographic survey experiment with multiple UAVs.",IEEE Robotics and Automation Letters,2020
d5dc97370d06868235ad74c8f59631147df213a3,https://www.semanticscholar.org/paper/d5dc97370d06868235ad74c8f59631147df213a3,Distributed Multi-Robot Information Gathering under Spatio-Temporal Inter-Robot Constraints†,"Information gathering (IG) algorithms aim to intelligently select the mobile robotic sensor actions required to efficiently obtain an accurate reconstruction of a physical process, such as an occupancy map, a wind field, or a magnetic field. Recently, multiple IG algorithms that benefit from multi-robot cooperation have been proposed in the literature. Most of these algorithms employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics. Moreover, they cannot deal with inter-robot restrictions such as collision avoidance or communication constraints. This paper presents a novel approach for multi-robot information gathering (MR-IG) that tackles the two aforementioned restrictions: (i) discretization of robot’s state space, and (ii) dealing with inter-robot constraints. Here we propose an algorithm that employs: (i) an underlying model of the physical process of interest, (ii) sampling-based planners to plan paths in a continuous domain, and (iii) a distributed decision-making algorithm to enable multi-robot coordination. In particular, we use the max-sum algorithm for distributed decision-making by defining an information-theoretic utility function. This function maximizes IG, while fulfilling inter-robot communication and collision avoidance constraints. We validate our proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness and scalability with respect to the number of robots of our approach.",Sensors,2020
d6830df12fe168c3fd3fd17a317b1cf087e49827,https://www.semanticscholar.org/paper/d6830df12fe168c3fd3fd17a317b1cf087e49827,Learning control for transmission and navigation with a mobile robot under unknown communication rates,"Abstract In tasks such as surveying or monitoring remote regions, an autonomous robot must move while transmitting data over a wireless network with unknown, position-dependent transmission rates. For such a robot, this paper considers the problem of transmitting a data buffer in minimum time, while possibly also navigating towards a goal position. Two approaches are proposed, each consisting of a machine-learning component that estimates the rate function from samples; and of an optimal-control component that moves the robot given the current rate function estimate. Simple obstacle avoidance is performed for the case without a goal position. In extensive simulations, these methods achieve competitive performance compared to known-rate and unknown-rate baselines. A real indoor experiment is provided in which a Parrot AR.Drone 2 successfully learns to transmit the buffer.",Control Engineering Practice,2020
ef2ddc8813df1551171a9aeec742cd7baece3152,https://www.semanticscholar.org/paper/ef2ddc8813df1551171a9aeec742cd7baece3152,Asynchronous Adaptive Sampling and Reduced-Order Modeling of Dynamic Processes by Robot Teams via Intermittently Connected Networks,"This work presents an asynchronous multi-robot adaptive sampling strategy through the synthesis of an intermittently connected mobile robot communication network. The objective is to enable a team of robots to adaptively sample and model a nonlinear dynamic spatiotemporal process. By employing an intermittently connected communication network, the team is not required to maintain an all-time connected network enabling them to cover larger areas, especially when the team size is small. The approach first determines the next meeting locations for data exchange and as the robots move towards these predetermined locations, they take measurements along the way. The data is then shared with other team members at the designated meeting locations and a reducedorder-model (ROM) of the process is obtained in a distributed fashion. The ROM is used to estimate field values in areas without sensor measurements, which informs the path planning algorithm when determining a new meeting location for the team. The main contribution of this work is an intermittent communication framework for asynchronous adaptive sampling of dynamic spatiotemporal processes. We demonstrate the framework in simulation and compare different reduced-order models under full, all-time and intermittent connectivity.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
194b6f8b9fe95717d0c2c94ba3336663df601e4b,https://www.semanticscholar.org/paper/194b6f8b9fe95717d0c2c94ba3336663df601e4b,DeepIG: Multi-Robot Information Gathering With Deep Reinforcement Learning,"State-of-the-art multi-robot information gathering (MR-IG) algorithms often rely on a model that describes the structure of the information of interest to drive the robots motion. This causes MR-IG algorithms to fail when they are applied to new IG tasks, as existing models cannot describe the information of interest. Therefore, we propose in this letter a MR-IG algorithm that can be applied to new IG tasks with little algorithmic changes. To this end, we introduce DeepIG: a MR-IG algorithm that uses deep reinforcement learning to allow robots to learn how to gather information. Nevertheless, there are IG tasks for which accurate models have been derived. Therefore, we extend DeepIG to exploit existing models for such IG tasks. This algorithm we term it model-based DeepIG (MB-DeepIG). First, we evaluate DeepIG in simulations, and in an indoor experiment with three quadcopters that autonomously map an unknown terrain profile built in our lab. Results demonstrate that DeepIG can be applied to different IG tasks without algorithmic changes, and that it is robust to measurement noise. Then, we benchmark MB-DeepIG against state-of-the-art information-driven Gaussian-processes-based IG algorithms. Results demonstrate that MB-DeepIG outperforms the considered benchmarks.",IEEE Robotics and Automation Letters,2019
40d2334c5fe8c3594605d2dbd835861f21084387,https://www.semanticscholar.org/paper/40d2334c5fe8c3594605d2dbd835861f21084387,Informative Path Planning with Local Penalization for Decentralized and Asynchronous Swarm Robotic Search,"Decentralized swarm robotic solutions to searching for targets that emit a spatially varying signal promise task parallelism, time efficiency, and fault tolerance. It is, however, challenging for swarm algorithms to offer scalability and efficiency, while preserving mathematical insights into the exhibited behavior. A new decentralized search method (called Bayes-Swarm), founded on batch Bayesian Optimization (BO) principles, is presented here to address these challenges. Unlike swarm heuristics approaches, Bayes-Swarm decouples the knowledge generation and task planning process, thus preserving insights into the emergent behavior. Key contributions lie in: 1) modeling knowledge extraction over trajectories, unlike in BO; 2) time-adaptively balancing exploration/exploitation and using an efficient local penalization approach to account for potential interactions among different robots' planned samples; and 3) presenting an asynchronous implementation of the algorithm. This algorithm is tested on case studies with bimodal and highly multimodal signal distributions. Up to 76 times better efficiency is demonstrated compared to an exhaustive search baseline. The benefits of exploitation/exploration balancing, asynchronous planning, and local penalization, and scalability with swarm size, are also demonstrated.",2019 International Symposium on Multi-Robot and Multi-Agent Systems (MRS),2019
54d1b12bd85a769af77f9bbaea73250fc3ac36df,https://www.semanticscholar.org/paper/54d1b12bd85a769af77f9bbaea73250fc3ac36df,Robotic Active Information Gathering for Spatial Field Reconstruction with Rapidly-Exploring Random Trees and Online Learning of Gaussian Processes †,"Information gathering (IG) algorithms aim to intelligently select a mobile sensor actions required to efficiently obtain an accurate reconstruction of a physical process, such as an occupancy map, or a magnetic field. Many recent works have proposed algorithms for IG that employ Gaussian processes (GPs) as underlying model of the process. However, most algorithms discretize the state space, which makes them computationally intractable for robotic systems with complex dynamics. Moreover, they are not suited for online information gathering tasks as they assume prior knowledge about GP parameters. This paper presents a novel approach that tackles the two aforementioned issues. Specifically, our approach includes two intertwined steps: (i) a Rapidly-Exploring Random Tree (RRT) search that allows a robot to identify unvisited locations, and to learn the GP parameters, and (ii) an RRT*-based informative path planning that guides the robot towards those locations by maximizing the information gathered while minimizing path cost. The combination of the two steps allows an online realization of the algorithm, while eliminating the need for discretization. We demonstrate that our proposed algorithm outperforms state-of-the-art both in simulations, and in a lab experiment in which a ground-based robot explores the magnetic field intensity within an indoor environment populated with obstacles.",Sensors,2019
5b4e58a8a3028ce5bf03d1f77217113c630b4984,https://www.semanticscholar.org/paper/5b4e58a8a3028ce5bf03d1f77217113c630b4984,Sensors Module Information Storage Actuators Module Reward Generator Observation Renderer Agent Communications Module,"State-of-the-art multi-robot information gathering (MR-IG) algorithms often rely on a model that describes the structure of the information of interest to drive the robots motion. This causes MR-IG algorithms to fail when they are applied to new IG tasks, as existing models cannot describe the information of interest. Therefore, we propose in this paper a MR-IG algorithm that can be applied to new IG tasks with little algorithmic changes. To this end, we introduce DeepIG: a MR-IG algorithm that uses Deep Reinforcement Learning to allow robots to learn how to gather information. Nevertheless, there are IG tasks for which accurate models have been derived. Therefore, we extend DeepIG to exploit existing models for such IG tasks. This algorithm we term it model-based DeepIG (MB-DeepIG). First, we evaluate DeepIG in simulations, and in an indoor experiment with three quadcopters that autonomously map an unknown terrain profile built in our lab. Results demonstrate that DeepIG can be applied to different IG tasks without algorithmic changes, and that it is robust to measurement noise. Then, we benchmark MB-DeepIG against state-of-the-art informationdriven Gaussian-processes-based IG algorithms. Results demonstrate that MB-DeepIG outperforms the considered benchmarks.",,2019
5e69b1d5699c4f6af682148d5e94d230a2111278,https://www.semanticscholar.org/paper/5e69b1d5699c4f6af682148d5e94d230a2111278,Recent advances in multirobot exploration of communication-restricted environments,,Intelligenza Artificiale,2020
6f088c15c36ece054de2e90c19bd283fc8013fc4,https://www.semanticscholar.org/paper/6f088c15c36ece054de2e90c19bd283fc8013fc4,Balanced Parallel Exploration of Orthogonal Regions,"We consider the use of multiple mobile agents to explore an unknown area. The area is orthogonal, such that all perimeter lines run both vertically and horizontally. The area may consist of unknown rectangular holes which are non-traversable internally. For the sake of analysis, we assume that the area is discretized into N points allowing the agents to move from one point to an adjacent one. Mobile agents communicate through face-to-face communication when in adjacent points. The objective of exploration is to develop an online algorithm that will explore the entire area while reducing the total work of all k agents, where the work is measured as the number of points traversed. We propose splitting the exploration into two alternating tasks, perimeter and room exploration. The agents all begin with the perimeter scan and when a room is found they transition to room scan after which they continue with perimeter scan until the next room is found and so on. Given the total traversable points N, our algorithm completes in total O ( N ) work with each agent performing O ( N / k ) work, namely the work is balanced. If the rooms are hole-free the exploration time is also asymptotically optimal, O ( N / k ) . To our knowledge, this is the first agent coordination algorithm that considers simultaneously work balancing and small exploration time.",Algorithms,2019
6fb120176640d4f8e0c0e6582f09f8ab1386dfd5,https://www.semanticscholar.org/paper/6fb120176640d4f8e0c0e6582f09f8ab1386dfd5,Multi-robot Field Exploration in Hex-Decomposed Environments for Dubins Vehicles,"Multi-robot systems can be useful in applications such as map building, surveillance, and search and rescue. To be efficient in practice, the robotic team should cooperatively explore a region of interest. However, when the environment is unknown, it is challenging to plan collision-free paths in real-time under both non-holonomic mobility constraints and energy constraints. We propose the Multi-robot Hex Decomposition Exploration (M-HDE) method for multiple Dubins vehicles to explore unknown environments. M-HDE ensures robots return to the initial (departure) position before energy runs out. Furthermore, when available energy level allow, M-HDE can achieve complete exploration of the environment. The proposed approach generates smooth, continuous paths for Dubins vehicles to follow at constant velocities, and offers geometric closed-form solutions for both team formation and paths. The performance is evaluated with a team of Turtlebots in simulated environments with obstacles in Gazebo.",2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),2019
8b5d81ffa3935c26a0cbe5f4f7444b71df5748a6,https://www.semanticscholar.org/paper/8b5d81ffa3935c26a0cbe5f4f7444b71df5748a6,Geometric Problems in Robot Exploration,. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Chapter 1: Balanced Parallel Exploration of Orthogonal Regions . . . . . . . . . . . 3 1.,,2019
dcafaefd429345adea1c6876f8ebc8db224cda47,https://www.semanticscholar.org/paper/dcafaefd429345adea1c6876f8ebc8db224cda47,Coordination Methods for Entropy-Based Multi-Agent Exploration Under Sparsity Constraints,"This paper is an extension of a previous work that examined a decentralized approach to evaluate the uncertainty of estimating a spatial process using guided model-based multi-agent exploration. The model is a superposition of fixed kernel functions, with each kernel playing the role of a feature. The measurements, collected by the agents, are then used to collectively estimate the weights of the features under sparsity constraints and derive the corresponding spatial uncertainty distribution to optimally guide the agents to reduce the uncertainty. This paper extends these results in several respects. First, we investigate different coordination strategies, which all aim to efficiently optimize the exploration criterion in a distributed multiagent setting. Second, we compare different features, specifically radial basis functions (RBFs), Lanczos kernels, Legendre polynomials, and discrete cosine functions. Third, we conduct hardware-in-the-loop experiments to validate the proposed coordination strategies using real robots. Results show that the coordination strategy together with the selected feature has a significant influence on the exploration performance.",2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP),2019
f5aac13dc703fb6e8bc55f439fc434457c043767,https://www.semanticscholar.org/paper/f5aac13dc703fb6e8bc55f439fc434457c043767,Sampling-Based Visual Path Planning Framework for a Multirotor UAV,"This paper proposes a sampling-based visual path planning framework for the servoing of a multirotor unmanned aerial vehicle. There are two main problems of the traditional image-based visual servoing: one is that it cannot guarantee the bounded control input because of the high disparity between the initial and desired features, the other is that it could lead to slow convergence rates caused by exponential attenuation over time and insufficient control inputs in the final phase. To overcome these problems, this paper proposes a sampling-based visual path planning framework to generate control inputs using reference features over the interval between the initial and desired features. Our proposed contribution can generate small and bounded control inputs in the large pose difference environments. In detail, it can maintain a small bounded error task function because of preventing singularities, uncertainties, and local minimums during calculating image Jacobian. Therefore, our proposed contribution can not only overcome the deficiencies of traditional image-based visual servoing approaches but also improve control performance. A variety of simulation results conducted to verify the performance of the proposed framework indicate that it can overcome the vulnerabilities of traditional image-based visual servoing with respect to large disparity environment and generate relative body velocity commands.",International Journal of Aeronautical and Space Sciences,2019
17ab35118764e589e43115a6f67f71f750dde211,https://www.semanticscholar.org/paper/17ab35118764e589e43115a6f67f71f750dde211,Distributed Sensing Subject to Temporal Logic Constraints,"This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.",2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2018
320a487e3ef9adb3a8326881512044622e29e121,https://www.semanticscholar.org/paper/320a487e3ef9adb3a8326881512044622e29e121,Global-Entropy Driven Exploration with Distributed Models under Sparsity Constraints,"This paper focuses on exploration when using different data distribution schemes and ADMM as a solver for swarms. By exploration, we mean the estimation of new measurement locations that are beneficial for the model estimation. In particular, the different distribution schemes are splitting-over-features or heterogeneous learning and splitting-over-examples or homogeneous learning. Each agent contributes a solution to solve the joint optimization problem by using ADMM and the consensus algorithm. This paper shows that some information is unknown to the individual agent, and thus, the estimation of new measurement positions is not possible without further communication. Therefore, this paper shows results for how to distribute only necessary information for a global exploration. We show the benefits between the proposed global exploration scheme and benchmark exploration schemes such as random walk and systematic traversing, i.e., meandering. The proposed waypoint estimation methods are then tested against each other and with other movement methods. This paper shows that a movement method, which considers the current information within the model, is superior to the benchmark movement methods.",Applied Sciences,2018
4d887104a995edbca3361135731c97367d032def,https://www.semanticscholar.org/paper/4d887104a995edbca3361135731c97367d032def,Distributed Multi-Robot Cooperation for Information Gathering Under Communication Constraints,"Many recent works have proposed algorithms for information gathering that benefit from multi-robot cooperation. However, most algorithms either employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics; or cannot deal with inter-robot restrictions like e.g. communication constraints. This paper presents an approach for multi-robot information gathering that tackles the two aforementioned issues. To this end we propose an algorithm that combines in an innovative manner Gaussian processes (GPs) to model the physical process of interest, RRT planners to plan paths in a continuous domain, and a distributed decision-making algorithm to achieve multi-robot cooperation. Specifically, we employ the Max-sum algorithm for distributed multi-robot cooperation by defining an information-theoretic utility function together with a path clustering approach. This function maximizes information gathering, subject to inter-robot communication constraints. We validate the proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness of the approach.",2018 IEEE International Conference on Robotics and Automation (ICRA),2018
7be3a93495c6d9c546be169c09118afd1c4bffa4,https://www.semanticscholar.org/paper/7be3a93495c6d9c546be169c09118afd1c4bffa4,Distributed multi-robot exploration under complex constraints,"Mobile robots have emerged as a prime alternative to explore physical processes of interest. This is particularly relevant in situations that have a high risk for humans, like e.g. in search and rescue missions, and for applications in which it is desirable to reduce the required time and manpower to gather information, like e.g. for environmental analysis. In such context, exploration tasks can clearly benefit from multi-robot coordination. In particular, distributed multi-robot coordination strategies offer enormous advantages in terms of both system’s efficiency and robustness, compared to single-robot systems. However, most state-of-the-art strategies employ discretization of robots’ state and action spaces. This makes them computationally intractable for robots with complex dynamics, and limits their generality. Moreover, most strategies cannot handle complex inter-robot constraints like e.g. communication constraints. The goal of this thesis is to develop a distributed multi-robot exploration algorithm that tackles the two aforementioned issues. To achieve this goal we first propose a single-robot myopic approach, in which we build to develop a non-myopic informative path planner. In a second step, we extend our non-myopic single-robot algorithm to the multi-robot case. Our proposed algorithms build on the following techniques: (i) Gaussian Processes (GPs) to model the spatial dependencies of a physical process of interest, (ii) sampling-based planners to calculate feasible paths; (iii) information metrics to guide robots towards informative locations; and (iv) distributed constraint optimization techniques for multi-robot coordination. We validated our proposed algorithms in simulations and experiments. Specifically, we carried out the following experiments: mapping of a magnetic field with a ground-based robot, mapping of a terrain profile with two quadcopters equipped with an ultrasound sensor, and exploration of a simulated wind field with three quadcopters. Results demonstrate the effectiveness of our approach to perform exploration tasks under complex constraints.",,2018
fd4872ed110ad2aec3c4a99c474cf3ff75336ae2,https://www.semanticscholar.org/paper/fd4872ed110ad2aec3c4a99c474cf3ff75336ae2,Virtual clustering: a communication cost reduction strategy for distributed consensus-based estimation in cooperative networks,"In this paper, we consider the problem of distributed consensus-based estimation in cooperative networks, e.g., wireless sensor networks (WSNs). To solve this problem and achieve an accurate consensus-based estimate solution, many iterative distributed algorithms require the information exchange among nodes at each iteration suffering from huge communication overhead. In our previous work, a new strategy of virtual clustering was discussed with the purpose of reducing communication overhead for distributed consensus-based estimation. By classifying the data using virtual clusters, data with reduced size will be transmitted during the distributed processing. Here, we further propose two methods to reduce the size of transmitted data for arbitrary network topologies. One method is based on finding the shortest path in a network and the other relies on linear independence of constraint qualification (LICQ). The study shows that both methods can successfully reduce communication overhead. Moreover, the second method outperforms the first one and provides the optimal communication cost for the distributed consensus-based estimation.",WSA,2018
0c2c43e161f54eca77b5fefa289ce0667110821f,https://www.semanticscholar.org/paper/0c2c43e161f54eca77b5fefa289ce0667110821f,Multi-UAV resource constrained online monitoring of large-scale spatio-temporal environment with homing guarantee,"We propose a homing constrained bi-objective optimization variant of budget-limited informative path planning for monitoring a spatio-temporal environment. The objective function consists of weighted combination of two components: model performance which must be maximized and travel distance which must be bounded by the maximum operational range. Besides this, we have additional constraints that guarantee that the robots will return to home (base station) upon completion of their respective missions. Optimizing over this objective function is essentially NP-hard owing to the conflicting constituents. Moreover, the appropriate choice of weights and additional homing guarantees further adds to complications. We employ Gaussian Process (GP) model [1] which is highly data driven i.e., the larger the amount of training data, the better the model performance. However, owing to limited resources, a robot can only collect a limited amount of training samples. Thus, with the introduction of our bi-objective cost function, it becomes possible to plan budget-limited (e.g., battery, flight time, travel distance etc.) informative tours using autonomous mobile robots to effectively select only the most informative (uncertain) locations from the environment. In this work, we develop an algorithm to autonomously choose the appropriate weights for the components based on available resources while ensuring homing and maintaining model quality. We perform simulations to verify the effectiveness of our proposed objective function on the publicly available Ozone Concentration dataset gathered from USA.",IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society,2017
2aae27d5d0aca7080087d62928abd288f706cba3,https://www.semanticscholar.org/paper/2aae27d5d0aca7080087d62928abd288f706cba3,Modeling and tracking of spatio-temporal scalar fields with multiple robots,"This paper focuses on evaluation of the sampling strategy under different conditions. We first implement a framework for modeling and tracking spatio-temporal scalar fields with multiple robots, using Gaussian Process, Voronoi partition, discrete and continuous optimization algorithms. Then, the sampling conditions are divided into four cases from two perspectives (asynchronous / synchronous sampling in continuous region / discrete set of locations) and are compared by simulations. The results show that there is no significant difference in the performance of sampling in continuous region and discrete set, but asynchronous sampling could give better prediction accuracy compared to synchronous sampling.",2017 36th Chinese Control Conference (CCC),2017
52bef101749e42eac19224a39e5c46cee047523b,https://www.semanticscholar.org/paper/52bef101749e42eac19224a39e5c46cee047523b,Online information gathering using sampling-based planners and GPs: An information theoretic approach,"Information gathering algorithms aim to intelligently select the robot actions required to efficiently obtain an accurate reconstruction of a physical process, such as an occupancy map, or a magnetic field. Many recent works have proposed algorithms for information gathering. However, these algorithms employ discretization of the state space, which makes them computationally intractable for robotic systems with complex dynamics. Moreover, most algorithms are not suited for online information gathering tasks. This paper presents a novel approach that tackles the two aforementioned issues. Specifically, our approach includes two intertwined steps: a Gaussian processes (GPs)-based prediction that allows a robot to identify highly unexplored locations, and an RRT∗-based informative path planning that guides the robot towards those locations. The combination of the two steps allows an online realization of the algorithm, while eliminates the need of discretization. We demonstrate the effectiveness of the proposed algorithm in simulations, as well as with an experiment in which a ground-based robot explores the magnetic field intensity within an indoor environment populated with obstacles.",2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2017
7cc4f383a427370ff6aaec300f9878dd6e4c6298,https://www.semanticscholar.org/paper/7cc4f383a427370ff6aaec300f9878dd6e4c6298,Gaussian Process-based Visual Servoing Framework for an Aerial Parallel Manipulator,"This paper proposes a Gaussian process-based visual servoing framework that not only overcome the weakness of the standard image-based visual servoing (IBVS) scheme but also improve the vision-enabled and real-time control performance. In particular, the proposed framework provides the Gaussian process-based sampled image path consisting of a set of the references between the initial and desired positions of a stationary or moving target in the image plane with respect to the height under the large translation and rotation error in order to overcome the weakness of the standard IBVS scheme. Furthermore, we applied the proposed framework to the aerial parallel manipulator during the picking-n-replacing mission. The developed vehicle has two vision system: one is the gimbal-stabilized pinhole camera on the host vehicle and the other is the fisheye camera with the one-dimensional light detection and ranging (LiDAR) fixed on the end-effector of the parallel manipulator. The proposed framework can generate the feasible control input according to each sensor system`s features. In this paper, the preliminary results and analysis are represented. The results of simulations and flight tests will be conducted to verify the performance of the proposed framework indicate that it can return the path points for the convergence of the desired position while the target is moving or stationary, even with the large scale difference.",,2017
99622ad4577d40d931922f5e74778a0fcc6f2ff5,https://www.semanticscholar.org/paper/99622ad4577d40d931922f5e74778a0fcc6f2ff5,Bayesian Online Learning for Information-based Multi-Agent Exploration with Unknown Radio Signal Distribution,Abstract Exploring an unknown environment with multiple robots is an enabling technology for many useful applications. This paper investigates decentralized motion planning for multi-agent exploration in a field with unknown received signal strength (RSS) distribution. The environment is modelled with a Gaussian process using Bayesian online learning by sharing the information obtained from the measurement history of each robot. Then we use the mean function of the Gaussian process to infer the multiple RSS source locations. The inferred source locations are modelled as the probability distribution using Gaussian mixture-probability hypothesis density (GM-PHD) filter. This modelling enables nonparametric approximation of mutual information between source locations and future robot positions. We combine the variance function of the Gaussian process and the mutual information to design an informative and noise-robust planning algorithm for multiple robots. The experimental performance is analyzed by comparing with the variance-based planning algorithm.,,2017
ac7bcdf3424e1dd1acb49bc790c01a862f6b50e3,https://www.semanticscholar.org/paper/ac7bcdf3424e1dd1acb49bc790c01a862f6b50e3,Detachable modular robot capable of cooperative climbing and multi agent exploration,"At the cross section of the fields of Uneven Terrain Navigation and Multi Agent Systems (MAS), in this work, a Detachable Compliant Modular Robot (DCMR) which can perform concurrent scene exploration by detaching into numerous parts, while preserving its ability to climb stairs is proposed and built. A spring is designed and used in the modular robot taking the worst-case-scenario of stairs encountered in an urban setting. In addition to the actuators at the wheels, an additional set of actuators per module are introduced to enable the detachment and re-attachment. The design additions and their trade-offs are discussed. Potential applications are presented with special focus on improving coverage of a map with obstacles/slabs large enough to merit exploration by climbing them. The problem of turning in crammed spaces is solved using the ability to detach of DCMR. The detaching & re-attaching capability, and stair climbing of the composite modular robot are demonstrated through experimentation using the prototype.",2017 IEEE International Conference on Robotics and Automation (ICRA),2017
b5ae7c5f1214b0667c257b2174d7baded17a0fdc,https://www.semanticscholar.org/paper/b5ae7c5f1214b0667c257b2174d7baded17a0fdc,Multirobot online construction of communication maps,"The importance of communication in many multirobot information-gathering tasks requires the availability of reliable communication maps. These provide estimates of the radio signal strength and can be used to predict the presence of communication links between different locations of the environment. In the problem we consider, a team of mobile robots has to build such maps autonomously in a robot-to-robot communication setting. The solution we propose models the signal's distribution with a Gaussian Process and exploits different online sensing strategies to coordinate and guide the robots during their data acquisition. Our methods show interesting operative insights both in simulations and on real TurtleBot 2 platforms.",2017 IEEE International Conference on Robotics and Automation (ICRA),2017
c498f17861a392853ed605f7a23b65c8f2e3c641,https://www.semanticscholar.org/paper/c498f17861a392853ed605f7a23b65c8f2e3c641,An asynchronous distributed constraint optimization approach to multi-robot path planning with complex constraints,"Multi-robot teams can play a crucial role in many applications such as exploration, or search and rescue operations. One of the most important problems within the multi-robot context is path planning. This has been shown to be particularly challenging, as the team of robots must deal with additional constraints, e.g. inter-robot collision avoidance, while searching in a much larger action space. Previous works have proposed solutions to this problem, but they present two major drawbacks: (i) algorithms suffer from a high computational complexity, or (ii) algorithms require a communication link between any two robots within the system. This paper presents a method to solve this problem, which is both computationally efficient and only requires local communication between neighboring agents. We formulate the multirobot path planning as a distributed constraint optimization problem. Specifically, in our approach the asynchronous distributed constraint optimization algorithm (Adopt) [15] is combined with sampling-based planners to obtain collision free paths, which allows us to take into account both kinematic and kinodynamic constraints of the individual robots. The paper analyzes the performance and scalability of the approach using simulations, and presents real experiments employing a team of several robots.",SAC,2017
c8a489dd109d82391d48d5ff568dfba684f7a712,https://www.semanticscholar.org/paper/c8a489dd109d82391d48d5ff568dfba684f7a712,Selective decentralization to improve reinforcement learning in unknown linear noisy systems,"In this paper, we answer the question of to what extend selective decentralization could enhance the learning and control performance when the system is noisy and unknown. Compared to the previous works in selective decentralization, in this paper, we add the system noise as another complexity in the learning and control problem. Thus, we only perform analysis for some simple toy examples of noisy linear system. In linear system, the Halminton-Jaccobi-Bellman (HJB) equation becomes Riccati equation with closed-form solution. Our previous framework in learning and control unknown system is based on the following principle: approximating the system using identification in order to apply model-based solution. Therefore, this paper would explore the learning and control performance on two aspects: system identification error and system stabilization. Our results show that selective decentralization show better learning performance than the centralization when the noise level is low.",2017 21st Asia Pacific Symposium on Intelligent and Evolutionary Systems (IES),2017
9d9f1524ef6a2af25cd1d20a3a19fb56b16bfa47,https://www.semanticscholar.org/paper/9d9f1524ef6a2af25cd1d20a3a19fb56b16bfa47,Full Stack Swarm Architecture,"Robot swarms are homogeneous multi-robot systems that form collective behaviour from decentralized local interactions. Swarms are a favorable choice for solving various problems in robotics as they are robust and fault tolerant in nature, the individual swarm agents themselves being cost effective alternatives to the solution. Developing swarm technology aids in large scale data collection and environmental exploration, package delivery, warehouse management, military reconnaissance, and search and rescue. With the growing interest in developing swarm systems, much researcher and developer time is spent migrating, integrating, and coordinating these various swarm solutions that become deprecated and isolated from the community in frequent cycle. Furthermore, despite the aforementioned swarm architectures provided insights into specific design considerations, there still lacks a generalized architecture that outlines a full swarm pipeline, and is modular enough in design to be readily interchanged with new components as both research and industry advance. We present an architecture for developing full stack swarm systems. Such a system must allow for easy design, deployment, interaction, and evaluation. Using our proposed architecture, we then implemented a framework titled: CMUSWARM, on the ROS platform using Gazebo with irobot create for simulation. We then conduct an evaluation of our architecture by comparing two simple swarm control-laws within the framework.",,
3bdb87927b67b29bddb3bf46000c459f28e3415e,https://www.semanticscholar.org/paper/3bdb87927b67b29bddb3bf46000c459f28e3415e,OpenDC 2.0: Convenient Modeling and Simulation of Emerging Technologies in Cloud Datacenters,"Cloud datacenters are important for the digital society, serving stakeholders across industry, government, and academia. Simulation is a critical part of exploring datacenter technologies, enabling scalable experimentation with millions of jobs and hundreds of thousands of machines, and what-if analysis in a matter of minutes to hours. Although the community has already developed powerful simulators, emerging technologies and applications in modern datacenters require new approaches. Addressing this requirement, in this work we propose OpenDC, a new platform for datacenter simulation. OpenDC includes novel models for emerging cloud-datacenter technologies and applications, such as serverless computing with FaaS deployment and TensorFlow-based machine learning. Our design also focuses on convenience, with a web-based interface for interactive experimentation, support for experiment automation, a library of prefabs for constructing and sharing datacenter designs, and support for diverse input formats and output metrics. We implement, validate, and open-source OpenDC 2.0, a significant redesign and release after a multi-year research and development process. We demonstrate the benefits of OpenDC for the field through a set of representative use-cases: serverless, machine learning, procurement of HPC-as-a-Service infrastructure, educational practices, and reproducibility studies. Overall, OpenDC helps understand how datacenters work, design datacenter infrastructure, and train the next generation of experts.","2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2021
4fb435fe5c3c84721e07653bafda3caadf2ebffb,https://www.semanticscholar.org/paper/4fb435fe5c3c84721e07653bafda3caadf2ebffb,"A survey of domains in workflow scheduling in computing infrastructures: Community and keyword analysis, emerging trends, and taxonomies","Abstract Workflows are prevalent in today’s computing infrastructures as they support many domains. Different Quality of Service (QoS) requirements of both users and providers makes workflow scheduling challenging. Meeting the challenge requires an overview of state-of-art in workflow scheduling. Sifting through literature to find the state-of-art can be daunting, for both newcomers and experienced researchers. Surveys are an excellent way to address questions regarding the different techniques, policies, emerging areas, and opportunities present, yet they rarely take a systematic approach and publish their tools and data on which they are based. Moreover, the communities behind these articles are rarely studied. We attempt to address these shortcomings in this work. We introduce and open-source an instrument used to combine and store article meta-data. Using this meta-data, we characterize and taxonomize the workflow scheduling community and four areas within workflow scheduling: (1) the workflow formalism, (2) workflow allocation, (3) resource provisioning, and (4) applications and services. In each characterization, we obtain important keywords overall and per year, identify keywords growing in importance, get insight into the structure and relations within each community, and perform a systematic literature survey per part to validate and complement our taxonomies",Future Gener. Comput. Syst.,2021
96e07ab04baa50b2924f5ffb9582a8bf53852be7,https://www.semanticscholar.org/paper/96e07ab04baa50b2924f5ffb9582a8bf53852be7,Smart Entrepreneurial Systems: An Application of Deep Reinforcement Learning in Improving Entrepreneurship Mentorship,,,2021
17d63c3b79872832dd28dba7412a437b17730b2b,https://www.semanticscholar.org/paper/17d63c3b79872832dd28dba7412a437b17730b2b,"A Survey and Annotated Bibliography of Workflow Scheduling in Computing Infrastructures: Community, Keyword, and Article Reviews - Extended Technical Report","Workflows are prevalent in today's computing infrastructures. The workflow model support various different domains, from machine learning to finance and from astronomy to chemistry. Different Quality-of-Service (QoS) requirements and other desires of both users and providers makes workflow scheduling a tough problem, especially since resource providers need to be as efficient as possible with their resources to be competitive. To a newcomer or even an experienced researcher, sifting through the vast amount of articles can be a daunting task. Questions regarding the difference techniques, policies, emerging areas, and opportunities arise. Surveys are an excellent way to cover these questions, yet surveys rarely publish their tools and data on which it is based. Moreover, the communities that are behind these articles are rarely studied. We attempt to address these shortcomings in this work. We focus on four areas within workflow scheduling: 1) the workflow formalism, 2) workflow allocation, 3) resource provisioning, and 4) applications and services. Each part features one or more taxonomies, a view of the community, important and emerging keywords, and directions for future work. We introduce and make open-source an instrument we used to combine and store article meta-data. Using this meta-data, we 1) obtain important keywords overall and per year, per community, 2) identify keywords growing in importance, 3) get insight into the structure and relations within each community, and 4) perform a systematic literature survey per part to validate and complement our taxonomies.",ArXiv,2020
9468302f6a5733d5e1059d2a9743c8e4176db829,https://www.semanticscholar.org/paper/9468302f6a5733d5e1059d2a9743c8e4176db829,Beyond Microbenchmarks: The SPEC-RG Vision for a Comprehensive Serverless Benchmark,"Serverless computing services, such as Function-as-a-Service (FaaS), hold the attractive promise of a high level of abstraction and high performance, combined with the minimization of operational logic. Several large ecosystems of serverless platforms, both open- and closed-source, aim to realize this promise. Consequently, a lucrative market has emerged. However, the performance trade-offs of these systems are not well-understood. Moreover, it is exactly the high level of abstraction and the opaqueness of the operational-side that make performance evaluation studies of serverless platforms challenging. Learning from the history of IT platforms, we argue that a benchmark for serverless platforms could help address this challenge. We envision a comprehensive serverless benchmark, which we contrast to the narrow focus of prior work in this area. We argue that a comprehensive benchmark will need to take into account more than just runtime overhead, and include notions of cost, realistic workloads, more (open-source) platforms, and cloud integrations. Finally, we show through preliminary real-world experiments how such a benchmark can help compare the performance overhead when running a serverless workload on state-of-the-art platforms.",ICPE Companion,2020
fb7cd40a41f314de521c518165fbb18cf7004af1,https://www.semanticscholar.org/paper/fb7cd40a41f314de521c518165fbb18cf7004af1,DQN based Reinforcement Learning Algorithm for Scheduling Workflows in the Cloud,"The 9th International Symposium on Computational Intelligence and Industrial Applications (ISCIIA2020) CITIC Jingling Hotel Beijing, Beijing, China, Oct.31-Nov.3, 2020 1 Abstract: With more and more scientific and social media applications, the amount of data is growing exponentially. Any type of computing applications, such as data calculation or analysis, can be described as workflows. Cloud computing provides an effective platform for executing large and complex workflow applications conveniently and cheaply through its delivering internet-based services as a pay-as-you-go model. However, the performance of workflow scheduler directly affects the Quality of Service (QoS) of the cloud users, and how to efficiently allocate the heterogeneous cloud resources to execute workflows still faces big challenges. In this work, an improved Deep Q Network (DQN)-based reinforcement learning (RL) algorithm for workflow scheduling is developed to optimize dual objectives like makespan and cost simultaneously. First, we test the performance of DQN and Actor-critic (AC) based RL algorithm in scheduling workflows respectively, then modify the reward function for the DQN algorithm to improve its convergence and universality for optimization problems. Extensive experiments are conducted to verify our approach and the simulation results show that the proposed algorithm can minimize both makespan and cost, as well as adjust user preference for the specific optimization objective and accordingly increase the diversity of generated scheduling schemes.",,2020
0c234b9726adeedba5db09215e5eebbc6fbb3de0,https://www.semanticscholar.org/paper/0c234b9726adeedba5db09215e5eebbc6fbb3de0,"The Design, Productization, and Evaluation of a Serverless Workflow-Management System","The need for accessible and cost-effective IT resources has led to the near-universal adoption of cloud computing. Within cloud computing, serverless computing has emerged as a model that further abstracts away operational complexity of heterogeneous cloud resources. Central to this form of computing is Function-as-a-Service (FaaS); a cloud model that enables users to express applications as functions, further decoupling the application logic from the hardware and other operational concerns. Although FaaS has seen rapid adoption for simple use cases, there are several issues that impede its use for more complex use cases. A key issue is the lack of systems that facilitate the reuse of existing functions to create more complex, composed functions. Current approaches for serverless function composition are either proprietary, resource inefficient, unreliable, or do not scale. To address this issue, we propose an approach to orchestrate composed functions using reliably and efficiently with workflows. As a prototype, we design and implement Fission Workflows: an open-source serverless workflow system which leverages the characteristics of serverless functions to improve the (re)usability, performance, and reliability of function compositions. We evaluate our prototype using both synthetic and real-world experiments, which show that the system is comparable with or better than state-of-the-art workflow systems, while costing significantly less. Based on the experimental evaluation and the industry interest in the Fission Workflows product, we believe that serverless workflow orchestration will enable the use of serverless applications for more complex use cases.",,2019
3d18a96ddd90ed679be2b533cd9f6ebb4808adce,https://www.semanticscholar.org/paper/3d18a96ddd90ed679be2b533cd9f6ebb4808adce,Scheduling Workloads of Workflows in Clusters and Clouds,"This dissertation addresses three key challenges that are characteristic to the online scheduling of workloads of workflows in modern distributed computing systems. The first challenge is the realistic estimation of the resource demand of a workflow, as it is important for making good task placement and resource allocation decisions. Usually, workflows consist of segments with different parallelism and different interconnection types between tasks which affect the order how the tasks become eligible. Moreover, realistic task runtime estimates are not always available. The second challenge is the efficient placement of workflow tasks on computing resources for minimizing average workflow slowdown while achieving fairness. A wrongly chosen task placement policy can easily degrade the performance and negatively affect the fair access of workflows to computing resources. The third challenge is the automatic allocation (autoscaling) of computing resources for workflows while meeting deadline and budget constraints. Computing clouds make it possible to easily lease and release resources. Such decisions should be made wisely to minimize slowdowns and deadline violations, and to efficiently use the leased resources to reduce incurred costs. To address these challenges, this dissertation proposes novel scheduling policies for workloads of workflows and investigates the applicability of relevant state-of-the-art policies to the online scenario. For new policies, implementation effort and suitability for production systems are kept in mind. The considered workflow scheduling policies are experimentally evaluated by conducting a wide set of simulation-based and real-world experiments on a private multicluster computer. Additionally, a Mixed Integer Programming (MIP) approach is used to validate the obtained real-world experimental results versus the optimal solution from a MIP solver.",,2019
562a5649feb2f335504f404e3dae6d3003244d88,https://www.semanticscholar.org/paper/562a5649feb2f335504f404e3dae6d3003244d88,A Systematic Design Space Exploration of Datacenter Schedulers,"Datacenter infrastructure has become vital for stakeholders across industry, academia and government. To operate efficiently, datacenter operators rely on a variety of complex scheduling techniques, to distribute user workloads across resources. In this work, we leverage a reference architecture for datacenter scheduling to design and implement an instrument for systematic design space exploration of datacenter schedulers. We construct a formal representation of the design space for datacenter schedulers, using scheduling policies collected from real-world schedulers. We then use a genetic algorithm in combination with trace-based simulation to explore the space, optimizing for workload metrics. Through several experiments, we assess the viability of the instrument. We find that our instrument is able to identify patterns in the workloads and adapt the scheduling policies appropriately. Overall, our work leads to numerous findings, which can become valuable for future comprehension and development of schedulers.",,2019
5b6b2e63ee5b70119830c7c0bbf8a5dc37b752e9,https://www.semanticscholar.org/paper/5b6b2e63ee5b70119830c7c0bbf8a5dc37b752e9,The AtLarge Vision on the Design of Distributed Systems and Ecosystems,"High-quality designs of distributed systems and services are essential for our digital economy and society. Threatening to slow down the stream of working designs, we identify the mounting pressure of scale and complexity of (eco-)systems, of ill-defined and wicked problems, and of unclear processes, methods, and tools. We envision design itself as a core research topic in distributed systems, to understand and improve the science and practice of distributed (eco-)system design. Toward this vision, we propose the AtLarge design framework, accompanied by a set of 8 core design principles. We also propose 10 key challenges, which we hope the community can address in the following 5 years. In our experience so far, the proposed framework and principles are practical, and lead to pragmatic and innovative designs for large-scale distributed systems.",2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS),2019
b04e9039160afed9b307eb8cb0a379e1599a89c3,https://www.semanticscholar.org/paper/b04e9039160afed9b307eb8cb0a379e1599a89c3,SpotWeb: Running Latency-sensitive Distributed Web Services on Transient Cloud Servers,"Many cloud providers offer servers with transient availability at a reduced cost. These servers can be unilaterally revoked by the provider, usually after a warning period to the user. Until recently, it has been thought that these servers are not suitable to run latency-sensitive workloads due to their transient availability. In this paper, we introduce SpotWeb, a framework for running latency-sensitive web workloads on transient computing platforms while maintaining the Quality-of-Service (QoS) of the running applications. SpotWeb is based on three novel concepts; using multi-period optimization---a novel approach developed in finance---for server selection; transiency-aware load-balancing; and using intelligent capacity over-provisioning. We implement SpotWeb and evaluate its performance in both simulations and testbed experiments. Our results show that SpotWeb reduces costs by up to 50% compared to state-of-the-art solutions while being scalable to hundreds of cloud server configurations.",HPDC,2019
a5af7a22e5e9d33f8bd52b147767bea33d5d4126,https://www.semanticscholar.org/paper/a5af7a22e5e9d33f8bd52b147767bea33d5d4126,A Trace-Based Performance Study of Autoscaling Workloads of Workflows in Datacenters,"To improve customer experience, datacenter operators offer support for simplifying application and resource management. For example, running workloads of workflows on behalf of customers is desirable, but requires increasingly more sophisticated autoscaling policies, that is, policies that dynamically provision resources for the customer. Although selecting and tuning autoscaling policies is a challenging task for datacenter operators, so far relatively few studies investigate the performance of autoscaling for workloads of workflows. Complementing previous knowledge, in this work we propose the first comprehensive performance study in the field. Using trace-based simulation, we compare state-of-the-art autoscaling policies across multiple application domains, workload arrival patterns (e.g., burstiness), and system utilization levels. We further investigate the interplay between autoscaling and regular allocation policies, and the complexity cost of autoscaling. Our quantitative study focuses not only on traditional performance metrics and on state-of-the-art elasticity metrics, but also on time-and memory-related autoscaling-complexity metrics. Our main results give strong and quantitative evidence about previously unreported operational behavior, for example, that autoscaling policies perform differently across application domains and allocation and provisioning policies should be co-designed.","2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)",2017
eed4998438ed045352d39cb3434f500b4084c326,https://www.semanticscholar.org/paper/eed4998438ed045352d39cb3434f500b4084c326,"A Reference Architecture for Datacenter Scheduling: Design, Validation, and Experiments","Datacenters act as cloud-infrastructure to stakeholders across industry, government, and academia. To meet growing demand yet operate efficiently, datacenter operators employ increasingly more sophisticated scheduling systems, mechanisms, and policies. Although many scheduling techniques already exist, relatively little research has gone into the abstraction of the scheduling process itself, hampering design, tuning, and comparison of existing techniques. In this work, we propose a reference architecture for datacenter schedulers. The architecture follows five design principles: components with clearly distinct responsibilities, grouping of related components where possible, separation of mechanism from policy, scheduling as complex workflow, and hierarchical multi-scheduler structure. To demonstrate the validity of the reference architecture, we map to it state-of-the-art datacenter schedulers. We find scheduler-stages are commonly underspecified in peer-reviewed publications. Through trace-based simulation and real-world experiments, we show underspecification of scheduler-stages can lead to significant variations in performance.","SC18: International Conference for High Performance Computing, Networking, Storage and Analysis",2018
bb79b809a7a10a27921de591c0c3d70d8f7ed910,https://www.semanticscholar.org/paper/bb79b809a7a10a27921de591c0c3d70d8f7ed910,Design and Development of IoT controlled Smart Surveillance cum Waste Cleaning Rover,"The rapid increase in utilization of technology and advancement made in robotics, provides a powerful driving force for rapid development of service robot. In sectors like shopping mall, flew market, lawns, enterprise premises, etc where mob of people gather, It is essential to sustain healthy public environment and security. Lot of man-power is used for scrutiny and cleaning of such areas. This paper focuses on Internet of Things based wireless cleaning rover developed on raspberry pi platform with control ability by web application from any distance. For cleaning operation vacuum system with necessary filter and air suction is used. The proposed is integration of sensors, camera and processing unit.",2021 2nd International Conference for Emerging Technology (INCET),2021
3b32af2153fa6097b484ac3add164b0b643d79d5,https://www.semanticscholar.org/paper/3b32af2153fa6097b484ac3add164b0b643d79d5,Artificial Potential Field for Dynamic Obstacle Avoidance with MPC-Based Trajectory Tracking for Multiple Quadrotors,This paper’s objective is to navigate multiple quadrotors using Artificial Potential Field (APF) technique for obstacle avoidance in a known environment. The idea is to use the dynamic potential field concept that does not depend on the quadrotor’s dynamics to ensure avoiding collisions among quadrotors. Each quadrotor navigates with repulsion force surrounding it to avoid obstacles including other quadrotors. The quadrotor follows its free-collision path using Model Predictive Control (MPC) as the trajectory tracker. The MPC controller task is to control each quadrotor independently to follow the planned path.,2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES),2020
d309948c10c66ca82c95f9e61a5646342182c336,https://www.semanticscholar.org/paper/d309948c10c66ca82c95f9e61a5646342182c336,TRAVERSE-Voice Commanded Self Navigating Indoor Robot,"When a human is taken to a new place, a new location per se, the individual first tries to perceive it, then gets to the geography of it and finally maps it. By mapping the whole location, the human goes around the place without any difficulty. In this project, the implementation will be done in such a way that the robot also consumes the parameters of the area in the same way as the human, by first perceiving the location entirely, followed by mapping the whole place and then going around it, thereby marking the location to absolute precision and making it flawless for navigation. <br><br>To accomplish this performance, a self-mapping algorithm using SLAM (Simultaneous Localization and Mapping), A* Algorithm for Path Planning is written and executed. The robot, by using ultrasonic sensors will measure the distances of the surrounding objects.<br>",SSRN Electronic Journal,2019
f10402aa309e80d69f37723a8008fe4db51896a0,https://www.semanticscholar.org/paper/f10402aa309e80d69f37723a8008fe4db51896a0,Autonomous Navigation and Collision Avoidance Surface Watercraft for Flood Relief Operations,"Floods are one of the deadliest natural disasters. They claim a lot of lives every year. This is partly due to the unavailability of basic amenities. Traditional modes of transport fails in the harsh environment created by the floods. Even though there are Remote Operated Vehicles (ROVs) and Unmanned Surface Vehicles (USVs) that are designed for marine and similar operations, they are expensive and thus cannot be deployed everywhere. This project is in accordance the UN SDG Goal 13.1, which aims at strengthening the adaptive capacity to climate-related hazards. This paper discusses the design of a low cost surface watercraft whose major objective is to support relief operations during floods. It has an embedded system with autonomous navigation and collision avoidance capability, specifically designed to be prototyped using ARM Cortex M4 microcontrollers. This can provide an economical technology driven solution to help rescuers deliver amenities to the people in inaccessible places.",2019 IEEE Global Humanitarian Technology Conference (GHTC),2019
375c3cb2f8cc3e78a43c448302c7bc03d77e6059,https://www.semanticscholar.org/paper/375c3cb2f8cc3e78a43c448302c7bc03d77e6059,A Dynamic Keypoints Selection Network for 6DoF Pose Estimation,"6 DoF poses estimation problem aims to estimate the rotation and translation parameters between two coordinates, such as object world coordinate and camera world coordinate. Although some advances are made with the help of deep learning, how to full use scene information is still a problem. Prior works tackle the problem by pixel-wise feature fusion but need to randomly selecte numerous points from images, which can not satisfy the demands of fast inference simultaneously and accurate pose estimation. In this work, we present a novel deep neural network based on dynamic keypoints selection designed for 6DoF pose estimation from a single RGBD image. Our network includes three parts, instance semantic segmentation, edge points detection and 6DoF pose estimation. Given an RGBD image, our network is trained to predict pixel category and the translation to edge points and center points. Then, a least-square fitting manner is applied to estimate the 6DoF pose parameters. Specifically, we propose a dynamic keypoints selection algorithm to choose keypoints from the foreground feature map. It allows us to leverage geometric and appearance information. During 6DoF pose estimation, we utilize the instance semantic segmentation result to filter out background points and only use foreground points to finish edge points detection and 6DoF pose estimation. Experiments on two commonly used 6DoF estimation benchmark datasets, YCB-Video and LineMoD, demonstrate that our method outperforms the state-ofthe-art methods and achieves significant improvements over other same category methods time efficiency.",Image and Vision Computing,2021
7db2b07c4be80b06a13ee10934074aa7c4c6c94a,https://www.semanticscholar.org/paper/7db2b07c4be80b06a13ee10934074aa7c4c6c94a,MPF6D: Masked Pyramid Fusion 6D Pose Estimation,"Object pose estimation has multiple important applications, such as robotic grasping and augmented reality. We present a new method to estimate the 6D pose of objects that improves upon the accuracy of current proposals and can still be used in real-time. Our method uses RGB-D data as input to segment objects and estimate their pose. It uses a neural network with multiple heads, one head estimates the object classification and generates the mask, the second estimates the values of the translation vector and the last head estimates the values of the quaternion that represents the rotation of the object. These heads leverage a pyramid architecture used during feature extraction and feature fusion. Our method can be used in real-time with its low inference time of 0.12 seconds and has high accuracy. With this combination of fast inference and good accuracy it is possible to use our method in robotic pick and place tasks and/or augmented reality applications.",SSRN Electronic Journal,2021
992bf8229f652b31f8d44fafed6b4d744f46f817,https://www.semanticscholar.org/paper/992bf8229f652b31f8d44fafed6b4d744f46f817,SporeAgent: Reinforced Scene-level Plausibility for Object Pose Refinement,"Observational noise, inaccurate segmentation and ambiguity due to symmetry and occlusion lead to inaccurate object pose estimates. While depthand RGB-based pose refinement approaches increase the accuracy of the resulting pose estimates, they are susceptible to ambiguity in the observation as they consider visual alignment. We propose to leverage the fact that we often observe static, rigid scenes. Thus, the objects therein need to be under physically plausible poses. We show that considering plausibility reduces ambiguity and, in consequence, allows poses to be more accurately predicted in cluttered environments. To this end, we extend a recent RL-based registration approach towards iterative refinement of object poses. Experiments on the LINEMOD and YCB-VIDEO datasets demonstrate the state-of-the-art performance of our depth-based refinement approach. Code is available at github.com/dornik/sporeagent.",ArXiv,2022
9c33a8ea95efcc3ac730c3ba302af4a17a6b1af0,https://www.semanticscholar.org/paper/9c33a8ea95efcc3ac730c3ba302af4a17a6b1af0,iCaps: Iterative Category-level Object Pose and Shape Estimation,"This paper proposes a category-level 6D object pose and shape estimation approach iCaps, which allows tracking 6D poses of unseen objects in a category and estimating their 3D shapes. We develop a category-level auto-encoder network using depth images as input, where feature embeddings from the auto-encoder encode poses of objects in a category. The auto-encoder can be used in a particle filter framework to estimate and track 6D poses of objects in a category. By exploiting an implicit shape representation based on signed distance functions, we build a LatentNet to estimate a latent representation of the 3D shape given the estimated pose of an object. Then the estimated pose and shape can be used to update each other in an iterative way. Our category-level 6D object pose and shape estimation pipeline only requires 2D detection and segmentation for initialization. We evaluate our approach on a publicly available dataset and demonstrate its effectiveness. In particular, our method achieves comparably high accuracy on shape estimation.",ArXiv,2021
aa262b568c6a4fd24b36fa37dc282bc0c9a46d2e,https://www.semanticscholar.org/paper/aa262b568c6a4fd24b36fa37dc282bc0c9a46d2e,OCRTOC: A Cloud-Based Competition and Benchmark for Robotic Grasping and Manipulation,"In this paper, we propose a cloud-based benchmark for robotic grasping and manipulation, called the OCRTOC benchmark. The benchmark focuses on the object rearrangement problem, specifically table organization tasks. We provide a set of identical real robot setups and facilitate remote experiments of standardized table organization scenarios in varying difficulties. In this workflow, users upload their solutions to our remote server and their code is executed on the real robot setups and scored automatically. After each execution, the OCRTOC team resets the experimental setup manually. We also provide a simulation environment that researchers can use to develop and test their solutions. With the OCRTOC benchmark, we aim to lower the barrier of conducting reproducible research on robotic grasping and manipulation and accelerate progress in this field. Executing standardized scenarios on identical real robot setups allows us to quantify algorithm performances and achieve fair comparisons. Using this benchmark we held a competition in the 2020 International Conference on Intelligence Robots and Systems (IROS 2020). In total, 59 teams took part in this competition worldwide. We present the results and our observations of the 2020 competition, and discuss our adjustments and improvements for the upcoming OCRTOC 2021 competition. The homepage of the OCRTOC competition is www.ocrtoc.org, and the OCRTOC software package is available at https://github.com/OCRTOC/OCRTOC_software_package.",IEEE Robotics and Automation Letters,2021
e5f1d0e2caf503a278802db1a88e1aed5c7aeb98,https://www.semanticscholar.org/paper/e5f1d0e2caf503a278802db1a88e1aed5c7aeb98,Toward Real-World Category-Level Articulation Pose Estimation,"Human life is populated with articulated objects. Current Category-level Articulation Pose Estimation (CAPE) methods are studied under the single-instance setting with a fixed kinematic structure for each category. Considering these limitations, we aim to study the problem of estimating part-level 6D pose for multiple articulated objects with unknown kinematic structures in a single RGB-D image, and reform this problem setting for real-world environments and suggest a CAPE-Real (CAPER) task setting. This setting allows varied kinematic structures within a semantic category, and multiple instances to co-exist in an observation of real world. To support this task, we build an articulated model repository ReArt-48 and present an efficient dataset generation pipeline, which contains Fast Articulated Object Modeling (FAOM) and Semi-Authentic MixEd Reality Technique (SAMERT). Accompanying the pipeline, we build a large-scale mixed reality dataset ReArtMix and a real world dataset ReArtVal. Accompanying the CAPER problem and the dataset, we propose an effective framework that exploits RGB-D input to estimate part-level pose for multiple instances in a single forward pass. In our method, we introduce object detection from RGB-D input to handle the multi-instance problem and segment each instance into several parts. To address the unknown kinematic structure issue, we propose an Articulation Parsing Network to analyze the structure of detected instance, and also build a Pair Articulation Pose Estimation module to estimate per-part 6D pose as well as joint property from connected part pairs. Extensive experiments demonstrate that the proposed method can achieve good performance on CAPER, CAPE and instance-level Robot Arm pose estimation problems. We believe it could serve as a strong baseline for future research on the CAPER task. The datasets and codes in our work will be made publicly available.",IEEE Transactions on Image Processing,2021
01e9d49a68d60f8731210d1d9dcfbf07027b7fd0,https://www.semanticscholar.org/paper/01e9d49a68d60f8731210d1d9dcfbf07027b7fd0,AI4Assembly A Human-Robot Collaboration Assembly Application with AI Support,"Artificial intelligence (AI) technologies can help to greatly improve the usability and performance of an application. Over the last few years, many approaches have been presented on how AI technologies can improve individual steps in an assembly application that uses human-robot collaboration. This paper presents a concept for an AI supported human-robot collaboration for an assembly application, in which the AI components extend and improve the assembly application in all areas and not just individual steps. This includes the setup of a new assembly sequence as well as the subsequent execution of the assembly. The implemented concept is also compared against the same application with a lower degree of automation.",2021 IEEE 8th International Conference on Industrial Engineering and Applications (ICIEA),2021
05d06e362254667379cd1f463285ace9455d3c1f,https://www.semanticscholar.org/paper/05d06e362254667379cd1f463285ace9455d3c1f,Fast Uncertainty Quantification for Deep Object Pose Estimation,"Deep learning-based object pose estimators are often unreliable and overconfident especially when the input image is outside the training domain, for instance, with sim2real transfer. Efficient and robust uncertainty quantification (UQ) in pose estimators is critically needed in many robotic tasks. In this work, we propose a simple, efficient, and plug-and-play UQ method for 6-DoF object pose estimation. We ensemble 2–3 pre-trained models with different neural network architectures and/or training data sources, and compute their average pair-wise disagreement against one another to obtain the uncertainty quantification. We propose four disagreement metrics, including a learned metric, and show that the average distance (ADD) is the best learning-free metric and it is only slightly worse than the learned metric, which requires labeled target data. Our method has several advantages compared to the prior art: 1) our method does not require any modification of the training process or the model inputs; and 2) it needs only one forward pass for each model. We evaluate the proposed UQ method on three tasks where our uncertainty quantification yields much stronger correlations with pose estimation errors than the baselines. Moreover, in a real robot grasping task, our method increases the grasping success rate from 35% to 90%. Video and code are available at https://sites.google.com/view/fastuq.",2021 IEEE International Conference on Robotics and Automation (ICRA),2020
062e850a89ab9422623ddd4bb0fa958a36a807ae,https://www.semanticscholar.org/paper/062e850a89ab9422623ddd4bb0fa958a36a807ae,GarmentNets: Category-Level Pose Estimation for Garments via Canonical Space Shape Completion,"This paper tackles the task of category-level pose estimation for garments. With a near infinite degree of freedom, a garment’s full configuration (i.e., poses) is often described by the per-vertex 3D locations of its entire 3D surface. However, garments are also commonly subject to extreme cases of self-occlusion, especially when folded or crumpled, making it challenging to perceive their full 3D surface. To address these challenges, we propose GarmentNets, where the key idea is to formulate the deformable object pose estimation problem as a shape completion task in the canonical space. This canonical space is defined across garments instances within a category, therefore, specifies the shared category-level pose. By mapping the observed partial surface to the canonical space and completing it in this space, the output representation describes the garment’s full configuration using a complete 3D mesh with the per-vertex canonical coordinate label. To properly handle the thin 3D structure presented on garments, we proposed a novel 3D shape representation using the generalized winding number field. Experiments demonstrate that GarmentNets is able to generalize to unseen garment instances and achieve significantly better performance compared to alternative approaches. Code and data can be found in https://garmentnets.cs.columbia.edu",ArXiv,2021
08189ce7ec387a47b490113a4040dec6f65a254e,https://www.semanticscholar.org/paper/08189ce7ec387a47b490113a4040dec6f65a254e,Memory based fusion for multi-modal deep learning,"The use of multi-modal data for deep machine learning has shown promise when compared to uni-modal approaches with fusion of multi-modal features resulting in improved performance in several applications. However, most state-of-the-art methods use naive fusion which processes feature streams independently, ignoring possible long-term dependencies within the data during fusion. In this paper, we present a novel Memory based Attentive Fusion layer, which fuses modes by incorporating both the current features and longterm dependencies in the data, thus allowing the model to understand the relative importance of modes over time. We introduce an explicit memory block within the fusion layer which stores features containing long-term dependencies of the fused data. The feature inputs from uni-modal encoders are fused through attentive composition and transformation followed by naive fusion of the resultant memory derived features with layer inputs. Following state-of-the-art methods, we have evaluated the performance and the generalizability of the proposed fusion approach on two different datasets with different modalities. In our experiments, we replace the naive fusion layer in benchmark networks with our proposed layer to enable a fair comparison. Experimental results indicate that the MBAF layer can generalise across different modalities and networks to enhance fusion and improve performance.",Inf. Fusion,2020
0824a425014fbcc20dd2d528cb587a88c57b7e89,https://www.semanticscholar.org/paper/0824a425014fbcc20dd2d528cb587a88c57b7e89,CentroidReg: A Global-to-Local Framework for Partial Point Cloud Registration,"Point cloud registration is a key problem for robotics, computer vision, and other applications. Previous global registration algorithms are sensitive to noises or partial occlusion, while local registration algorithms are highly dependent on initial angles. To solve these problems, we propose CentroidReg, a global-to-local framework for partial point cloud registration, desensitizing noises and initial angles. The partial point clouds have consistent global information (the centroid of the complete 3D shape) and local surface structures, which motivates us to combine rotation-invariant global and local information for correspondence generating. To estimate the centroid of the complete 3D shape for partial point clouds, we propose the CentroidNet with centroid voting and maximum likelihood estimation (MLE) aggregation. Then, we use the proposed RegistrationNet to extract hybrid rotation-invariant features (HRIF) combining global information of the entire 3D shape and local structures in the local area to describe each point. Furthermore, we propose the Reliable Correspondence Generating (RCG) module to generate correspondences in the overlapping area. Finally, a weighted differentiable singular value decomposition (SVD) step is performed to estimate the final rigid transformation. The proposed framework presents state-of-the-art performance on partial point cloud registration. Experiments show that our method is robust to initial angles and noises.",IEEE Robotics and Automation Letters,2021
08ab6c8a79f5756fe5317e8af5be6deb9cc96f6a,https://www.semanticscholar.org/paper/08ab6c8a79f5756fe5317e8af5be6deb9cc96f6a,FINet: Dual Branches Feature Interaction for Partial-to-Partial Point Cloud Registration,"Data association is important in the point cloud registration. In this work, we propose to solve the partial-to-partial registration from a new perspective, by introducing feature interactions between the source and the reference clouds at the feature extraction stage, such that the registration can be realized without the explicit mask estimation or attentions for the overlapping detection as adopted previously. Specifically, we present FINet, a feature interaction-based structure with the capability to enable and strengthen the information associating between the inputs at multiple stages. To achieve this, we first split the features into two components, one for the rotation and one for the translation, based on the fact that they belong to different solution spaces, yielding a dual branches structure. Second, we insert several interaction modules at the feature extractor for the data association. Third, we propose a transformation sensitivity loss to obtain rotation-attentive and translation-attentive features. Experiments demonstrate that our method performs higher precision and robustness compared to the state-of-the-art traditional and learning-based methods.",ArXiv,2021
09593a8485eaafa0a4cd86428c168159f0a7527f,https://www.semanticscholar.org/paper/09593a8485eaafa0a4cd86428c168159f0a7527f,A Pose Proposal and Refinement Network for Better 6D Object Pose Estimation,"In this paper, we present a novel, end-to-end 6D object pose estimation method that operates on RGB inputs. Our approach is composed of 2 main components: the first component classifies the objects in the input image and proposes an initial 6D pose estimate through a multi-task, CNN-based encoder/multi-decoder module. The second component, a refinement module, includes a renderer and a multi-attentional pose refinement network, which iteratively refines the estimated poses by utilizing both appearance features and flow vectors. Our refiner takes advantage of the hybrid representation of the initial pose estimates to predict the relative errors with respect to the target poses. It is further augmented by a spatial multi-attention block that emphasizes objects’ discriminative feature parts. Experiments on three benchmarks for 6D pose estimation show that our proposed pipeline outperforms state-of-the-art RGB-based methods with competitive runtime performance.",2021 IEEE Winter Conference on Applications of Computer Vision (WACV),2020
0ac1756dcb449114c868e88d9e38146b9ed39f1a,https://www.semanticscholar.org/paper/0ac1756dcb449114c868e88d9e38146b9ed39f1a,MaskUKF: An Instance Segmentation Aided Unscented Kalman Filter for 6D Object Pose and Velocity Tracking,"Tracking the 6D pose and velocity of objects represents a fundamental requirement for modern robotics manipulation tasks. This paper proposes a 6D object pose tracking algorithm, called MaskUKF, that combines deep object segmentation networks and depth information with a serial Unscented Kalman Filter to track the pose and the velocity of an object in real-time. MaskUKF achieves and in most cases surpasses state-of-the-art performance on the YCB-Video pose estimation benchmark without the need for expensive ground truth pose annotations at training time. Closed loop control experiments on the iCub humanoid platform in simulation show that joint pose and velocity tracking helps achieving higher precision and reliability than with one-shot deep pose estimation networks. A video of the experiments is available as Supplementary Material.",Frontiers in Robotics and AI,2021
0feafe8f2d4a581e0de67a599c5cc282370ecbb5,https://www.semanticscholar.org/paper/0feafe8f2d4a581e0de67a599c5cc282370ecbb5,BiLuNetICP: A Deep Neural Network for Object Semantic Segmentation and 6D Pose Recognition,"The ability of understanding a scene and predicting the pose of objects has attracted significant interests in recent years. Specifically, it is used with visual sensors to provide the information for a robotic manipulator to interact with the target. Thus, 6D pose estimation and object recognition from point clouds or RGB-D images are important tasks for visual servoing. In this article, we propose a learning based approach to perform 6D pose estimation for robotic manipulation using a BiLuNetICP pipeline. It consists of a multi-path convolutional neural network (CNN) for semantic segmentation on RGB images. The network extracts the object mask and uses it to merge with the depth information to perform 6D pose estimation by the Iterative Closest Point (ICP) algorithm. We collected our own dataset for training and evaluate with Intersection over Union (IoU). The proposed method is able to provide better results compared with Unet++ using a small amount of training data. For the robotic grasping application, we test and evaluate our approach using a HIWIN 6-axis robot with Asus Xtion Live 3D camera and our structured-light depth camera. The experimental results demonstrate its efficiency in computation and the high success rate in grasping.",IEEE Sensors Journal,2021
105b2e685b302f0a333aee4610c7083ad7c21b7e,https://www.semanticscholar.org/paper/105b2e685b302f0a333aee4610c7083ad7c21b7e,Impact of Segmentation and Color Spaces in 6D Pose Estimation,"6D pose estimation is an open challenge due to complex world objects and many possible problems when capturing data from the real world, e.g., occlusions, truncations, and noise in the data. Achieving accurate 6D poses will improve results in other open problems like robot grasping or positioning objects in augmented reality. MaskedFusion is one of the most accurate methods for 6D pose estimation but before estimating the pose, the object needs to be detected and segmented. One of the most important stages in the MaskedFusion 6D pose pipeline is image segmentation because, with good image segmentation, it is possible to discard the background or other non-relevant data that are around the object leaving only the data that are most relevant to the 6D pose estimation. We study the impact of using different image segmentation methods in the MaskedFusion 6D object pose estimation and we also study the impact of the color spaces in the MaskedFusion and DenseFusion methods. The experiments conducted, show how robust MaskedFusion is and that using some filtering operations after the predicted masks improves the accuracy of the method. We also show that, with one of the semantic segmentation methods tested, we achieve on average 97% accuracy on the LineMOD dataset, only 0.2% worst than the baseline that uses the ground truth masks provided by the dataset. With the modifications of the color spaces, we improved MaskedFusion in 1.1% and DenseFusion 0.3% in the LineMOD dataset and reach also 0.3% improvement for the MaskedFusion and 0.4% for the DenseFusion in the YCB-Video dataset.",2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),2021
10b58630243a614596bb31f91911b6ca60494f5e,https://www.semanticscholar.org/paper/10b58630243a614596bb31f91911b6ca60494f5e,Automobile indexation from 3D point clouds of urban scenarios,"In this paper, we introduce a methodology for the detection and segmentation of automobiles in urban scenarios. We use the LiDAR Velodyne HDL-64E to scan the surroundings. The method is comprised of three steps: (1) remove facades, ground plan, and unstructured objects, (2) smoothing data using robust principal component analysis (RPCA), and finally, (3) unstructured objects model and indexing. The dataset is partitioned into training with 4500 objects and test with 3000 objects. Mean Shift thresholds, the filter, the Delaunay parameters, and the histogram modelling are optimized via ROC analysis. It is observed that the car scan quality affects our method to a lesser degree when compared with state-of-the-art methods.",Automatika,2021
119678648278fca3190f865e634409d78f730719,https://www.semanticscholar.org/paper/119678648278fca3190f865e634409d78f730719,CloudAAE: Learning 6D Object Pose Regression with On-line Data Synthesis on Point Clouds,"It is often desired to train 6D pose estimation systems on synthetic data because manual annotation is expensive. However, due to the large domain gap between the synthetic and real images, synthesizing color images is expensive. In contrast, this domain gap is considerably smaller and easier to fill for depth information. In this work, we present a system that regresses 6D object pose from depth information represented by point clouds, and a lightweight data synthesis pipeline that creates synthetic point cloud segments for training. We use an augmented autoencoder (AAE) for learning a latent code that encodes 6D object pose information for pose regression. The data synthesis pipeline only requires texture-less 3D object models and desired viewpoints, and it is cheap in terms of both time and hardware storage. Our data synthesis process is up to three orders of magnitude faster than commonly applied approaches that render RGB image data. We show the effectiveness of our system on the LineMOD, LineMOD Occlusion, and YCB Video datasets. The implementation of our system is available at: https://github.com/GeeeG/CloudAAE.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021
14739e62c1bba4f5df5cc39d1edc5d8252ab62e9,https://www.semanticscholar.org/paper/14739e62c1bba4f5df5cc39d1edc5d8252ab62e9,Leveraging Self-Supervision for Cross-Domain Crowd Counting,"State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density. While effective, these data-driven approaches rely on large amount of data annotation to achieve good performance, which stops these models from being deployed in emergencies during which data annotation is either too costly or cannot be obtained fast enough. One popular solution is to use synthetic data for training. Unfortunately, due to domain shift, the resulting models generalize poorly on real imagery. We remedy this shortcoming by training with both synthetic images, along with their associated labels, and unlabeled real images. To this end, we force our network to learn perspective-aware features by training it to recognize upside-down real images from regular ones and incorporate into it the ability to predict its own uncertainty so that it can generate useful pseudo labels for fine-tuning purposes. This yields an algorithm that consistently outperforms state-of-the-art cross-domain crowd counting ones without any extra computation at inference time.",ArXiv,2021
14f9e82d60ac5fd7d2a05f40505dbcb5add93558,https://www.semanticscholar.org/paper/14f9e82d60ac5fd7d2a05f40505dbcb5add93558,Bridging the Reality Gap for Pose Estimation Networks using Sensor-Based Domain Randomization,"Since the introduction of modern deep learning methods for object pose estimation, test accuracy and efficiency has increased significantly. For training, however, large amounts of annotated training data are required for good performance. While the use of synthetic training data prevents the need for manual annotation, there is currently a large performance gap between methods trained on real and synthetic data. This paper introduces a new method, which bridges this gap.Most methods trained on synthetic data use 2D images, as domain randomization in 2D is more developed. To obtain precise poses, many of these methods perform a final refinement using 3D data. Our method integrates the 3D data into the network to increase the accuracy of the pose estimation. To allow for domain randomization in 3D, a sensor-based data augmentation has been developed. Additionally, we introduce the SparseEdge feature, which uses a wider search space during point cloud propagation to avoid relying on specific features without increasing run-time.Experiments on three large pose estimation benchmarks show that the presented method outperforms previous methods trained on synthetic data and achieves comparable results to existing methods trained on real data.",2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW),2020
1607af108b88957499f5c692d5693b45082b7fc0,https://www.semanticscholar.org/paper/1607af108b88957499f5c692d5693b45082b7fc0,A Multi-Hypothesis Approach to Pose Ambiguity in Object-Based SLAM,"In object-based Simultaneous Localization and Mapping (SLAM), 6D object poses offer a compact representation of landmark geometry useful for downstream planning and manipulation tasks. However, measurement ambiguity then arises as objects may possess complete or partial object shape symmetries (e.g., due to occlusion), making it difficult or impossible to generate a single consistent object pose estimate. One idea is to generate multiple pose candidates to counteract measurement ambiguity. In this paper, we develop a novel approach that enables an object-based SLAM system to reason about multiple pose hypotheses for an object, and synthesize this locally ambiguous information into a globally consistent robot and landmark pose estimation formulation. In particular, we (1) present a learned pose estimation network that provides multiple hypotheses about the 6D pose of an object; (2) by treating the output of our network as components of a mixture model, we incorporate pose predictions into a SLAM system, which, over successive observations, recovers a globally consistent set of robot and object (landmark) pose estimates. We evaluate our approach on the popular YCB-Video Dataset and a simulated video featuring YCB objects. Experiments demonstrate that our approach is effective in improving the robustness of object-based SLAM in the face of object pose ambiguity. 1",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
186c45ec08ce7969acd737f311628e7713d6aa85,https://www.semanticscholar.org/paper/186c45ec08ce7969acd737f311628e7713d6aa85,Occlusion-Aware Search for Object Retrieval in Clutter,"We address the manipulation task of retrieving a target object from a cluttered shelf. When the target object is hidden, the robot must search through the clutter for retrieving it. Solving this task requires reasoning over the likely locations of the target object. It also requires physics reasoning over multi-object interactions and future occlusions. In this work, we present a data-driven hybrid planner for generating occlusion-aware actions in closed-loop. The hybrid planner explores likely locations of the occluded target object as predicted by a learned distribution from the observation stream. The search is guided by a heuristic trained with reinforcement learning to act on observations with occlusions. We evaluate our approach in different simulation and real-world settings (video available on https://youtu.be/dY7YQ3LUVQg). The results validate that our approach can search and retrieve a target object in near real time in the real world while only being trained in simulation.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
1b72f455db1daad51d28c14639fe5f7eae768aab,https://www.semanticscholar.org/paper/1b72f455db1daad51d28c14639fe5f7eae768aab,Polarimetric Pose Prediction,"Light has many properties that can be passively measured by vision sensors. Colour-band separated wavelength and intensity are arguably the most commonly used ones for monocular 6D object pose estimation. This paper explores how complementary polarisation information, i.e. the orientation of light wave oscillations, can influence the accuracy of pose predictions. A hybrid model that leverages physical priors jointly with a data-driven learning strategy is designed and carefully tested on objects with different amount of photometric complexity. Our design not only significantly improves the pose accuracy in relation to photometric state-of-the-art approaches, but also enables object pose estimation for highly reflective and transparent objects.",ArXiv,2021
1bdd3aae245ee279bf57066a90d9cca335b586be,https://www.semanticscholar.org/paper/1bdd3aae245ee279bf57066a90d9cca335b586be,MixedFusion: 6D Object Pose Estimation from Decoupled RGB-Depth Features,"Estimating the 6D pose of objects is an important process for intelligent systems to achieve interaction with the real-world. As the RGB-D sensors become more accessible, the fusion-based methods have prevailed, since the point clouds provide complementary geometric information with RGB values. However, due to the difference in feature space between color image and depth image, the network structures that directly perform point-to-point matching fusion do not effectively fuse the features of the two. In this paper, we propose a simple but effective approach, named MixedFusion. Different from the prior works, we argue that the spatial correspondence of color and point clouds could be decoupled and reconnected, thus enabling a more flexible fusion scheme. By performing the proposed method, more informative points can be mixed and fused with rich color features. Extensive experiments are conducted on the challenging LineMod and YCB-Video datasets, which shows that our method significantly boosts the performance without introducing extra overheads. Furthermore, when the minimum tolerance of metric narrows, the proposed approach performs better for the high-precision demands.",2020 25th International Conference on Pattern Recognition (ICPR),2021
1c5915e6ada12a7332999cc26ce5815eaa04c08c,https://www.semanticscholar.org/paper/1c5915e6ada12a7332999cc26ce5815eaa04c08c,Adaptive Context-Aware Multi-Modal Network for Depth Completion,"Depth completion aims to recover a dense depth map from the sparse depth data and the corresponding single RGB image. The observed pixels provide the significant guidance for the recovery of the unobserved pixels’ depth. However, due to the sparsity of the depth data, the standard convolution operation, exploited by most of existing methods, is not effective to model the observed contexts with depth values. To address this issue, we propose to adopt the graph propagation to capture the observed spatial contexts. Specifically, we first construct multiple graphs at different scales from observed pixels. Since the graph structure varies from sample to sample, we then apply the attention mechanism on the propagation, which encourages the network to model the contextual information adaptively. Furthermore, considering the mutli-modality of input data, we exploit the graph propagation on the two modalities respectively to extract multi-modal representations. Finally, we introduce the symmetric gated fusion strategy to exploit the extracted multi-modal features effectively. The proposed strategy preserves the original information for one modality and also absorbs complementary information from the other through learning the adaptive gating weights. Our model, named Adaptive Context-Aware Multi-Modal Network (ACMNet), achieves the state-of-the-art performance on two benchmarks, i.e., KITTI and NYU-v2, and at the same time has fewer parameters than latest models. Our code is available at: https://github.com/sshan-zhao/ACMNet.",IEEE Transactions on Image Processing,2020
1c620dbb3a9e2e1cf24df9cdd3d0b199b27a70b0,https://www.semanticscholar.org/paper/1c620dbb3a9e2e1cf24df9cdd3d0b199b27a70b0,DexYCB: A Benchmark for Capturing Hand Grasping of Objects,"We introduce DexYCB, a new dataset for capturing hand grasping of objects. We first compare DexYCB with a related one through cross-dataset evaluation. We then present a thorough benchmark of state-of-the-art approaches on three relevant tasks: 2D object and keypoint detection, 6D object pose estimation, and 3D hand pose estimation. Finally, we evaluate a new robotics-relevant task: generating safe robot grasps in human-to-robot object handover. 1",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
20e4ea6c059df0b3e9c51bb975c13a02430ee296,https://www.semanticscholar.org/paper/20e4ea6c059df0b3e9c51bb975c13a02430ee296,Optimizing RGB-D Fusion for Accurate 6DoF Pose Estimation,"Today's standard object localization systems often do not meet the industry's demands regarding 2D and 3D accuracy for digital manufacturing applications. Two targets are considered: digital-based assistance and robotic inspection. 2D precision is necessary to provide accurate assistance whilst 3D precision is crucial to get an inspection as much close to the object's true state. In this letter, we propose a new pose estimation system which ensures highest both 2D and 3D precision. While most RGB-based solutions focus on obtaining best 2D accuracy, RGBD-based systems mainly use depth information to maximize 3D accuracy. Very few solutions propose a way to jointly optimize both constraints. Nonetheless, pose estimation should produce high accuracy as a slight 2D error can result in a large 3D error (and inversely). To address this problem, we present a new system which uses RGB-D to fully take advantage of the depth information. A new 3D primitive is proposed in order to minimize the effect of RGB-D noise on 3D coordinates accuracy. CNN Keypoint Detector (KPD) method is used to localize this new primitive in order to achieve pose estimation task. Finally, we propose a novel refinement method which ensures optimal precision as both RGB and depth information are fused. We show the results of our experimentation on widely-used and challenging Linemod and Occlusion datasets. We demonstrate that our solution outperforms state-of-the-art methods when taking into account both 3D and 2D accuracy.",IEEE Robotics and Automation Letters,2021
20f751603254a524c9b2de6c7076474e2260b945,https://www.semanticscholar.org/paper/20f751603254a524c9b2de6c7076474e2260b945,REDE: End-to-End Object 6D Pose Robust Estimation Using Differentiable Outliers Elimination,"Object 6D pose estimation is a fundamental task in many applications. Conventional methods solve the task by detecting and matching the keypoints, then estimating the pose. Recent efforts bringing deep learning into the problem mainly overcome the vulnerability of conventional methods to environmental variation due to the hand-crafted feature design. However, these methods cannot achieve end-to-end learning and good interpretability at the same time. In this letter, we propose REDE, a novel end-to-end object pose estimator using RGB-D data, which utilizes network for keypoint regression, and a differentiable geometric pose estimator for pose error back-propagation. Besides, to achieve better robustness when outlier keypoint prediction occurs, we further propose a differentiable outliers elimination method that regresses the candidate result and the confidence simultaneously. Via confidence weighted aggregation of multiple candidates, we can reduce the effect from the outliers in the final estimation. Finally, following the conventional method, we apply a learnable refinement process to further improve the estimation. The experimental results on three benchmark datasets show that REDE slightly outperforms the state-of-the-art approaches and is more robust to object occlusion. Our code is available at https://github.com/HuaWeitong/REDE.",IEEE Robotics and Automation Letters,2020
2379dbe5679a98ae82bbc5d91d4e63b66cac4131,https://www.semanticscholar.org/paper/2379dbe5679a98ae82bbc5d91d4e63b66cac4131,PyraPose: Feature Pyramids for Fast and Accurate Object Pose Estimation under Domain Shift,"Object pose estimation enables robots to understand and interact with their environments. Training with synthetic data is necessary in order to adapt to novel situations. Unfortunately, pose estimation under domain shift, i.e., training on synthetic data and testing in the real world, is challenging. Deep learning-based approaches currently perform best when using encoder-decoder networks but typically do not generalize to new scenarios with different scene characteristics. We argue that patch-based approaches, instead of encoder-decoder networks, are more suited for synthetic-to-real transfer because local to global object information is better represented. To that end, we present a novel approach based on a specialized feature pyramid network to compute multi-scale features for creating pose hypotheses on different feature map resolutions in parallel. Our single-shot pose estimation approach is evaluated on multiple standard datasets and outperforms the state of the art by up to ∼35 %. We also perform grasping experiments in the real world to demonstrate the advantage of using synthetic data to generalize to novel environments.",2021 IEEE International Conference on Robotics and Automation (ICRA),2020
25a94537099126977325c26886d849c0077f610d,https://www.semanticscholar.org/paper/25a94537099126977325c26886d849c0077f610d,Single-stage Keypoint-based Category-level Object Pose Estimation from an RGB Image,"Prior work on 6-DoF object pose estimation has largely focused on instance-level processing, in which a textured CAD model is available for each object being detected. Category-level 6-DoF pose estimation represents an important step toward developing robotic vision systems that operate in unstructured, real-world scenarios. In this work, we propose a single-stage, keypoint-based approach for category-level object pose estimation that operates on unknown object instances within a known category using a single RGB image as input. The proposed network performs 2D object detection, detects 2D keypoints, estimates 6-DoF pose, and regresses relative bounding cuboid dimensions. These quantities are estimated in a sequential fashion, leveraging the recent idea of convGRU for propagating information from easier tasks to those that are more difficult. We favor simplicity in our design choices: generic cuboid vertex coordinates, single-stage network, and monocular RGB input. We conduct extensive experiments on the challenging Objectron benchmark, outperforming state-ofthe-art methods on the 3D IoU metric (27.6% higher than the MobilePose single-stage approach and 7.1% higher than the related two-stage approach).",ArXiv,2021
2bf3159f0c60fe10cc2e4efac37c1b372a3c6203,https://www.semanticscholar.org/paper/2bf3159f0c60fe10cc2e4efac37c1b372a3c6203,Dynamic Grasping with Reachability and Motion Awareness,"Grasping in dynamic environments presents a unique set of challenges. A stable and reachable grasp can become unreachable and unstable as the target object moves, motion planning needs to be adaptive and in real time, the delay in computation makes prediction necessary. In this paper, we present a dynamic grasping framework that is reachability-aware and motion-aware. Specifically, we model the reachability space of the robot using a signed distance field which enables us to quickly screen unreachable grasps. Also, we train a neural network to predict the grasp quality conditioned on the current motion of the target. Using these as ranking functions, we quickly filter a large grasp database to a few grasps in real time. In addition, we present a seeding approach for arm motion generation that utilizes solution from previous time step. This quickly generates a new arm trajectory that is close to the previous plan and prevents fluctuation. We implement a recurrent neural network (RNN) for modelling and predicting the object motion. Our extensive experiments demonstrate the importance of each of these components and we validate our pipeline on a real robot.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
2d96599010e2862e681e433db6efdaec1693895d,https://www.semanticscholar.org/paper/2d96599010e2862e681e433db6efdaec1693895d,Ego-Interaction: Visual Hand-Object Pose Correction for VR Experiences,"Immersive virtual reality (VR) experiences may track both a user’s hands and a physical object at the same time and use the information to animate computer generated representations of the two interacting. However, to render visually without artefacts requires highly accurate tracking of the hands and the objects themselves as well as their relative locations – made even more difficult when the objects are articulated or deformable. If this tracking is incorrect, then the quality and immersion of the visual experience is reduced. In this paper we turn the problem around – instead of focusing on producing quality renders of hand-object interactions by improving tracking quality, we acknowledge there will be tracking errors and just focus on fixing the visualisations. We propose a Deep Neural Network (DNN) that modifies hand pose based on its relative position with the object. However, to train the network we require sufficient labelled data. We therefore also present a new dataset of hand-object interactions – Ego-Interaction. This is the first hand-object interaction dataset with egocentric RGBD videos and 3D ground truth data for both rigid and non-rigid objects. The Ego-Interaction dataset contains 92 sequences with 4 rigid, 1 articulated and 4 non-rigid objects and demonstrates hand-object interactions with 1 and 2 hands carefully captured, rigged and animated using motion capture. We provide our dataset as a general resource for researchers in the VR and AI community interested in other hand-object and egocentric tracking related problems.",MIG,2021
2efaabe03451837ee57df86b166d06167e75c99b,https://www.semanticscholar.org/paper/2efaabe03451837ee57df86b166d06167e75c99b,Precise grabbing of overlapping objects system based on end-to-end deep neural network,"Abstract In recent years, robotic arm technology is in dire need of reform because of the remarkable advances in artificial intelligence and computer vision. The traditional robotic arm techniques, e.g., template matching algorithm and iterative closest point algorithm, suffer from the low precision issue, especially when the target objects overlap with each other, resulting in inaccurate estimation of overlapping objects. This paper proposes a precise grabbing of overlapping objects system based on an end-to-end deep neural network. The successful grabbing is realized in the case of overlapping objects. First, the datasets needed for network training were established, utilizing structured light to obtain the point cloud information of the arbitrarily placed target objects. Furthermore, we collect the corresponding postures as data labels via the teaching device of the robotic arm, and train the network models using the datasets and labels. Finally, we can predict the postures of the target objects in real time and transmit the results to a robotic arm to complete the grabbing work. The experiment results indicate that the proposed grabbing system can grab small irregular objects accurately, only using the point cloud information, estimating the posture of multiple target objects in the scene simultaneously, and estimating the posture of overlapping small objects in the scene.",Comput. Commun.,2021
2f43f187b923f030706fba5f6572cfd8a666e74a,https://www.semanticscholar.org/paper/2f43f187b923f030706fba5f6572cfd8a666e74a,Distinctive 3D local deep descriptors,"We present a simple but yet effective method for learning distinctive 3D local deep descriptors (DIPs) that can be used to register point clouds without requiring an initial alignment. Point cloud patches are extracted, canonicalised with respect to their estimated local reference frame and encoded into rotation-invariant compact descriptors by a PointNet-based deep neural network. DIPs can effectively generalise across different sensor modalities because they are learnt end-to-end from locally and randomly sampled points. Because DIPs encode only local geometric information, they are robust to clutter, occlusions and missing regions. We evaluate and compare DIPs against alternative hand-crafted and deep descriptors on several indoor and outdoor datasets consiting of point clouds reconstructed using different sensors. Results show that DIPs (i) achieve comparable results to the state-of-the-art on RGB-D indoor scenes (3DMatch dataset), (ii) outperform state-of-the-art by a large margin on laser-scanner outdoor scenes (ETH dataset), and (iii) generalise to indoor scenes reconstructed with the Visual-SLAM system of Android ARCore. Source code: https://github.com/fabiopoiesi/dip.",2020 25th International Conference on Pattern Recognition (ICPR),2020
2fb7acc07247a4f30fe1bed998ba418376854728,https://www.semanticscholar.org/paper/2fb7acc07247a4f30fe1bed998ba418376854728,Deep Learning Based 6D Pose Estimation for Bin-Picking Using 3D Point Clouds,"Abstract—Estimating the 6D pose of objects is a core step for robot bin-picking tasks. The problem is that various objects are usually randomly stacked with heavy occlusion in real applications. In this work, we propose a method to regress 6D poses by predicting three points for each object in the 3D point cloud through deep learning. To solve the ambiguity of symmetric pose, we propose a labeling method to help the network converge better. Based on the predicted pose, an iterative method is employed for pose optimization. In real-world experiments, our method outperforms the classical approach in both precision and recall.",,2021
2fcf8164f1cec60ecd487f4d2ed75d4a2f0849ed,https://www.semanticscholar.org/paper/2fcf8164f1cec60ecd487f4d2ed75d4a2f0849ed,Mask-based Object Pose Estimation with Domain Transfer,"Object pose estimation is important for robots to understand and interact with the real world. This problem is challenging because the various objects, clutter and occlusions between objects in the scene. Deep learning methods show better performances than traditional problems in this problem but training a convolutional neural network needs lots of annotated data which is expensive to obtain. This paper proposes a general method by using domain transfer technology to efficiently solve object pose estimation problem. Besides, the proposed method obtains mask to achieve high quality performance by combing an instance segmentation framework, Mask R-CNN. We present the results of our experiments with the LineMOD dataset. We also deploy our method to robotic grasp object based on the estimated pose.",2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS),2021
2fe52e92b8693e0fe9e63d39acb9391a9b9693c5,https://www.semanticscholar.org/paper/2fe52e92b8693e0fe9e63d39acb9391a9b9693c5,PreSim: A 3D Photo-Realistic Environment Simulator for Visual AI,"Recent years have witnessed great advancement in visual artificial intelligence (AI) research based on deep learning. To take advantage of deep learning, we need to collect a large amount of data in various environments and conditions. However, collecting such data is time-consuming and labor-intensive. Apart from that, developing and testing visual AI algorithms for multisensory models is expensive and in some cases dangerous processes in the real world. We present PreSim, a 3D environment simulator which provides photo-realistic simulations using a view synthesis module and supports flexible configuration of multimodal sensors to address both of these issues. For our view synthesis module we introduce novel depth refinement, adaptive view selection and layered rendering, to provide realistic imagery. We demonstrate that PreSim has several advantages: (i) it provides a photo-realistic 3D environment which allows seamlessly integrating multisensory models in the virtual world and enables them to perceive and navigate scenes, (ii) it has an internal view synthesis module which allows transforming algorithms developed and tested in simulation to physical platforms without domain adaption, (iii) it can generate a large amount of data for vision-based applications, such as depth estimation and object pose estimation.",IEEE Robotics and Automation Letters,2021
308e888dcbad0af5bf03e8a4df6657c4cb4dbc83,https://www.semanticscholar.org/paper/308e888dcbad0af5bf03e8a4df6657c4cb4dbc83,Vote from the Center: 6 DoF Pose Estimation in RGB-D Images by Radial Keypoint Voting,"We propose a novel keypoint voting scheme based on intersecting spheres, that is more accurate than existing schemes and allows for a smaller set of more disperse keypoints. The scheme is based upon the distance between points, which as a 1D quantity can be regressed more accurately than the 2D and 3D vector and offset quantities regressed in previous work, yielding more accurate keypoint localization. The scheme forms the basis of the proposed RCVPose method for 6 DoF pose estimation of 3D objects in RGB-D data, which is particularly effective at handling occlusions. A CNN is trained to estimate the distance between the 3D point corresponding to the depth mode of each RGB pixel, and a set of 3 disperse keypoints defined in the object frame. At inference, a sphere centered at each 3D point is generated, of radius equal to this estimated distance. The surfaces of these spheres vote to increment a 3D accumulator space, the peaks of which indicate keypoint locations. The proposed radial voting scheme is more accurate than previous vector or offset schemes, and is robust to disperse keypoints. Experiments demonstrate RCVPose to be highly accurate and competitive, achieving state-of-the-art results on the LINEMOD (99.7%) and YCB-Video (97.2%) datasets, notably scoring +7.9% higher (71.1%) than previous methods on the challenging Occlusion LINEMOD dataset.",ArXiv,2021
30dd21d9ba914ecf4896a51ce5e900d54abd4895,https://www.semanticscholar.org/paper/30dd21d9ba914ecf4896a51ce5e900d54abd4895,FFB6D: A Full Flow Bidirectional Fusion Network for 6D Pose Estimation,"In this work, we present FFB6D, a Full Flow Bidirectional fusion network designed for 6D pose estimation from a single RGBD image. Our key insight is that appearance information in the RGB image and geometry information from the depth image are two complementary data sources, and it still remains unknown how to fully leverage them. Towards this end, we propose FFB6D, which learns to combine appearance and geometry information for representation learning as well as output representation selection. Specifically, at the representation learning stage, we build bidirectional fusion modules in the full flow of the two networks, where fusion is applied to each encoding and decoding layer. In this way, the two networks can leverage local and global complementary in-formation from the other one to obtain better representations. Moreover, at the output representation stage, we designed a simple but effective 3D keypoints selection algorithm considering the texture and geometry information of objects, which simplifies keypoint localization for precise pose estimation. Experimental results show that our method outperforms the state-of-the-art by large margins on several benchmarks. Code and video are available at https://github.com/ethnhe/FFB6D.git.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
3250155fa7416cb8f281ddb0753125a18b61aa7b,https://www.semanticscholar.org/paper/3250155fa7416cb8f281ddb0753125a18b61aa7b,Seeing Glass: Joint Point Cloud and Depth Completion for Transparent Objects,"The basis of many object manipulation algorithms is RGB-D input. Yet, commodity RGB-D sensors can only provide distorted depth maps for a wide range of transparent objects due light refraction and absorption. To tackle the perception challenges posed by transparent objects, we propose TranspareNet, a joint point cloud and depth completion method, with the ability to complete the depth of transparent objects in cluttered and complex scenes, even with partially filled fluid contents within the vessels. To address the shortcomings of existing transparent object data collection schemes in literature, we also propose an automated dataset creation workflow that consists of robot-controlled image collection and vision-based automatic annotation. Through this automated workflow, we created Toronto Transparent Objects Depth Dataset (TODD), which consists of nearly 15000 RGB-D images. Our experimental evaluation demonstrates that TranspareNet outperforms existing state-of-the-art depth completion methods on multiple datasets, including ClearGrasp, and that it also handles cluttered scenes when trained on TODD. Code and dataset will be released at https://www.pair.toronto.edu/TranspareNet/",ArXiv,2021
327a0f601783e53d8a8a32c4f5208aa53c3d25c9,https://www.semanticscholar.org/paper/327a0f601783e53d8a8a32c4f5208aa53c3d25c9,From IR Images to Point Clouds to Pose: Point Cloud-Based AR Glasses Pose Estimation,"In this paper, we propose two novel AR glasses pose estimation algorithms from single infrared images by using 3D point clouds as an intermediate representation. Our first approach “PointsToRotation” is based on a Deep Neural Network alone, whereas our second approach “PointsToPose” is a hybrid model combining Deep Learning and a voting-based mechanism. Our methods utilize a point cloud estimator, which we trained on multi-view infrared images in a semi-supervised manner, generating point clouds based on one image only. We generate a point cloud dataset with our point cloud estimator using the HMDPose dataset, consisting of multi-view infrared images of various AR glasses with the corresponding 6-DoF poses. In comparison to another point cloud-based 6-DoF pose estimation named CloudPose, we achieve an error reduction of around 50%. Compared to a state-of-the-art image-based method, we reduce the pose estimation error by around 96%.",J. Imaging,2021
34470ba9dec3753c2c061bdf6d209043e928d454,https://www.semanticscholar.org/paper/34470ba9dec3753c2c061bdf6d209043e928d454,Category-Level 6D Object Pose Estimation via Cascaded Relation and Recurrent Reconstruction Networks,"Category-level 6D pose estimation, aiming to predict the location and orientation of unseen object instances, is fundamental to many scenarios such as robotic manipulation and augmented reality, yet still remains unsolved. Precisely recovering instance 3D model in the canonical space and accurately matching it with the observation is an essential point when estimating 6D pose for unseen objects. In this paper, we achieve accurate category-level 6D pose estimation via cascaded relation and recurrent reconstruction networks. Specifically, a novel cascaded relation network is dedicated for advanced representation learning to explore the complex and informative relations among instance RGB image, instance point cloud and category shape prior. Furthermore, we design a recurrent reconstruction network for iterative residual refinement to progressively improve the reconstruction and correspondence estimations from coarse to fine. Finally, the instance 6D pose is obtained leveraging the estimated dense correspondences between the instance point cloud and the reconstructed 3D model in the canonical space. We have conducted extensive experiments on two well-acknowledged benchmarks of category-level 6D pose estimation, with significant performance improvement over existing approaches. On the representatively strict evaluation metrics of 3D75 and 5°2cm, our method exceeds the latest state-of-the-art SPD [1] by 4.9% and 17.7% on the CAMERA25 dataset, and by 2.7% and 8.5% on the REAL275 dataset. Codes are avaliable at https://wangjiaze.cn/projects/6DPoseEstimation.html.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
36a774834c0a19e3467338b73ab0fc1c78fb45b0,https://www.semanticscholar.org/paper/36a774834c0a19e3467338b73ab0fc1c78fb45b0,BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models,"Tracking the 6D pose of objects in video sequences is important for robot manipulation. Most prior efforts, however, often assume that the target object's CAD model, at least at a category-level, is available for offline training or during online template matching. This work proposes BundleTrack, a general framework for 6D pose tracking of novel objects, which does not depend upon 3D models, either at the instance or category-level. It leverages the complementary attributes of recent advances in deep learning for segmentation and robust feature extraction, as well as memory-augmented pose graph optimization for spatiotemporal consistency. This enables long-term, low-drift tracking under various challenging scenarios, including significant occlusions and object motions. Comprehensive experiments given two public benchmarks demonstrate that the proposed approach significantly outperforms state-of-art, category-level 6D tracking or dynamic SLAM methods. When compared against state-of-art methods that rely on an object instance CAD model, comparable performance is achieved, despite the proposed method’s reduced information requirements. An efficient implementation in CUDA provides a real-time performance of 10Hz for the entire framework. Code is available at: https://github.com/wenbowen123/BundleTrack",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
3882aa4b2370cae3f8b7b9c41e9088f8c056cdd9,https://www.semanticscholar.org/paper/3882aa4b2370cae3f8b7b9c41e9088f8c056cdd9,iNeRF: Inverting Neural Radiance Fields for Pose Estimation,"We present iNeRF, a framework that performs mesh-free pose estimation by ""inverting"" a Neural Radiance Field (NeRF). NeRFs have been shown to be remarkably effective for the task of view synthesis — synthesizing photorealistic novel views of real-world scenes or objects. In this work, we investigate whether we can apply analysis-by-synthesis via NeRF for mesh-free, RGB-only 6DoF pose estimation – given an image, find the translation and rotation of a camera relative to a 3D object or scene. Our method assumes that no object mesh models are available during either training or test time. Starting from an initial pose estimate, we use gradient descent to minimize the residual between pixels rendered from a NeRF and pixels in an observed image. In our experiments, we first study 1) how to sample rays during pose refinement for iNeRF to collect informative gradients and 2) how different batch sizes of rays affect iNeRF on a synthetic dataset. We then show that for complex real-world scenes from the LLFF dataset [21], iNeRF can improve NeRF by estimating the camera poses of novel images and using these images as additional training data for NeRF. Finally, we show iNeRF can perform categorylevel object pose estimation, including object instances not seen during training, with RGB images by inverting a NeRF model inferred from a single view.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
38fda727fed80bb04791d06ce869bd1164d42a13,https://www.semanticscholar.org/paper/38fda727fed80bb04791d06ce869bd1164d42a13,6D Pose Estimation with Correlation Fusion,"6D object pose estimation is widely applied in robotic tasks such as grasping and manipulation. Prior methods using RGB-only images are vulnerable to heavy occlusion and poor illumination, so it is important to complement them with depth information. However, existing methods using RGB-D data cannot adequately exploit consistent and complementary information between RGB and depth modalities. In this paper, we present a novel method to effectively consider the correlation within and across both modalities with attention mechanism to learn discriminative and compact multi-modal features. Then, effective fusion strategies for intra- and inter-correlation modules are explored to ensure efficient information flow between RGB and depth. To our best knowledge, this is the first work to explore effective intra- and inter-modality fusion in 6D pose estimation. The experimental results show that our method can achieve the state-of-the-art performance on LineMOD and YCB-Video dataset. We also demonstrate that the proposed method can benefit a real-world robot grasping task by providing accurate object pose estimation.",2020 25th International Conference on Pattern Recognition (ICPR),2019
3cb0a29bc4414d5979a9d3a94ec30dcab3ae43f7,https://www.semanticscholar.org/paper/3cb0a29bc4414d5979a9d3a94ec30dcab3ae43f7,H2O: Two Hands Manipulating Objects for First Person Interaction Recognition,"We present a comprehensive framework for egocentric interaction recognition using markerless 3D annotations of two hands manipulating objects. To this end, we propose a method to create a unified dataset for egocentric 3D interaction recognition. Our method produces annotations of the 3D pose of two hands and the 6D pose of the manipulated objects, along with their interaction labels for each frame. Our dataset, called H2O (2 Hands and Objects), provides synchronized multi-view RGB-D images, interaction labels, object classes, ground-truth 3D poses for left & right hands, 6D object poses, ground-truth camera poses, object meshes and scene point clouds. To the best of our knowledge, this is the first benchmark that enables the study of first-person actions with the use of the pose of both left and right hands manipulating objects and presents an unprecedented level of detail for egocentric 3D interaction recognition. We further propose the method to predict interaction classes by estimating the 3D pose of two hands and the 6D pose of the manipulated objects, jointly from RGB images. Our method models both interand intra-dependencies between both hands and objects by learning the topology of a graph convolutional network that predicts interactions. We show that our method facilitated by this dataset establishes a strong baseline for joint hand-object pose estimation and achieves state-of-the-art accuracy for first person interaction recognition.",ArXiv,2021
3d42457b57ef8afb678b0fdb9354c2bb15ada263,https://www.semanticscholar.org/paper/3d42457b57ef8afb678b0fdb9354c2bb15ada263,Similarity-Aware Fusion Network for 3D Semantic Segmentation,"In this paper, we propose a similarity-aware fusion network (SAFNet) to adaptively fuse 2D images and 3D point clouds for 3D semantic segmentation. Existing fusion-based methods achieve superior performances by integrating information from multiple modalities. However, they heavily rely on the projection-based correspondence between 2D pixels and 3D points and can only perform the information fusion in a fixed manner, so that their performances cannot be easily migrated to a more realistic scenario where the collected data often lack strict pair-wise features for prediction. To address this, we employ a late fusion strategy where we first learn the geometric and contextual similarities between the input and back-projected (from 2D pixels) point clouds and utilize them to guide the fusion of two modalities to further exploit complementary information. Specifically, we employ a geometric similarity module (GSM) to directly compare the spatial coordinate distributions of pair-wise 3D neighborhoods, and a contextual similarity module (CSM) to aggregate and compare spatial contextual information of corresponding central points. The two proposed modules can effectively measure how much image features can help predictions, enabling the network to adaptively adjust the contributions of two modalities to the final prediction of each point. Experimental results on ScanNetV2 [1] benchmark demonstrate that SAFNet outperforms existing state-of-the-art fusion-based approaches across various data integrity.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
3f4a6a6fb5f5ac3d3b1bc8b2d4646aed3b697772,https://www.semanticscholar.org/paper/3f4a6a6fb5f5ac3d3b1bc8b2d4646aed3b697772,Object Pose Estimation Incorporating Projection Loss and Discriminative Refinement,"The accurate estimation of three-dimensional (3D) object pose is important in a wide range of applications, such as robotics and augmented reality. The key to estimate object poses is matching feature points in the captured image with predefined ones of the 3D model of the object. Existing learning-based pose estimation systems utilize a voting strategy to estimate the feature points in a vector space for improving the accuracy of the estimated pose. However, the loss function of such approaches only takes account of the direction of the vector, resulting in an error-prone localization of feature points. Therefore, this paper considers a projection loss function dealing with the error of the vector field and incorporates a refinement network to revise the predicted pose to obtain a good final output. Experimental results show that the proposed methods outperform the state-of-the-art methods in ADD(-S) metric on the LINEMOD and Occlusion LINEMOD datasets. Moreover, the proposed method can be applied to real-world practical scenarios in real time to simultaneously estimate the poses of multiple objects.",IEEE Access,2021
423d5f1065d818142f2b5ecd10c90ee9572c7300,https://www.semanticscholar.org/paper/423d5f1065d818142f2b5ecd10c90ee9572c7300,FS-Net: Fast Shape-based Network for Category-Level 6D Object Pose Estimation with Decoupled Rotation Mechanism,"In this paper, we focus on category-level 6D pose and size estimation from a monocular RGB-D image. Previous methods suffer from inefficient category-level pose feature extraction, which leads to low accuracy and inference speed. To tackle this problem, we propose a fast shape-based network (FS-Net) with efficient category-level feature extraction for 6D pose estimation. First, we design an orientation aware autoencoder with 3D graph convolution for latent feature extraction. Thanks to the shift and scale-invariance properties of 3D graph convolution, the learned latent feature is insensitive to point shift and object size. Then, to efficiently decode category-level rotation information from the latent feature, we propose a novel decoupled rotation mechanism that employs two decoders to complementarily access the rotation information. For translation and size, we estimate them by two residuals: the difference between the mean of object points and ground truth translation, and the difference between the mean size of the category and ground truth size, respectively. Finally, to increase the generalization ability of the FS-Net, we propose an on-line box-cage based 3D deformation mechanism to augment the training data. Extensive experiments on two benchmark datasets show that the proposed method achieves state-of-the-art performance in both category- and instance-level 6D object pose estimation. Especially in category-level pose estimation, without extra synthetic data, our method outperforms existing methods by 6.3% on the NOCS-REAL dataset 1.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
42fe3e536cb5d1671f1629b27446448e2afb6a43,https://www.semanticscholar.org/paper/42fe3e536cb5d1671f1629b27446448e2afb6a43,Sparse Steerable Convolutions: An Efficient Learning of SE(3)-Equivariant Features for Estimation and Tracking of Object Poses in 3D Space,"As a basic component of SE(3)-equivariant deep feature learning, steerable convolution has recently demonstrated its advantages for 3D semantic analysis. The advantages are, however, brought by expensive computations on dense, volumetric data, which prevent its practical use for efficient processing of 3D data that are inherently sparse. In this paper, we propose a novel design of Sparse Steerable Convolution (SS-Conv) to address the shortcoming; SS-Conv greatly accelerates steerable convolution with sparse tensors, while strictly preserving the property of SE(3)-equivariance. Based on SS-Conv, we propose a general pipeline for precise estimation of object poses, wherein a key design is a Feature-Steering module that takes the full advantage of SE(3)-equivariance and is able to conduct an efficient pose refinement. To verify our designs, we conduct thorough experiments on three tasks of 3D object semantic analysis, including instance-level 6D pose estimation, category-level 6D pose and size estimation, and categorylevel 6D pose tracking. Our proposed pipeline based on SS-Conv outperforms existing methods on almost all the metrics evaluated by the three tasks. Ablation studies also show the superiority of our SS-Conv over alternative convolutions in terms of both accuracy and efficiency. Our code is released publicly at https://github.com/Gorilla-Lab-SCUT/SS-Conv.",ArXiv,2021
442bc3b98929feff80c8a1d3917cc99f6ab7ea90,https://www.semanticscholar.org/paper/442bc3b98929feff80c8a1d3917cc99f6ab7ea90,SynPo-Net—Accurate and Fast CNN-Based 6DoF Object Pose Estimation Using Synthetic Training,"Estimation and tracking of 6DoF poses of objects in images is a challenging problem of great importance for robotic interaction and augmented reality. Recent approaches applying deep neural networks for pose estimation have shown encouraging results. However, most of them rely on training with real images of objects with severe limitations concerning ground truth pose acquisition, full coverage of possible poses, and training dataset scaling and generalization capability. This paper presents a novel approach using a Convolutional Neural Network (CNN) trained exclusively on single-channel Synthetic images of objects to regress 6DoF object Poses directly (SynPo-Net). The proposed SynPo-Net is a network architecture specifically designed for pose regression and a proposed domain adaptation scheme transforming real and synthetic images into an intermediate domain that is better fit for establishing correspondences. The extensive evaluation shows that our approach significantly outperforms the state-of-the-art using synthetic training in terms of both accuracy and speed. Our system can be used to estimate the 6DoF pose from a single frame, or be integrated into a tracking system to provide the initial pose.",Sensors,2021
44c0446bb53e951cca8df07af91f1dea96045aea,https://www.semanticscholar.org/paper/44c0446bb53e951cca8df07af91f1dea96045aea,ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement,"Recently, the power of unconditional image synthesis has significantly advanced through the use of Generative Adversarial Networks (GANs). The task of inverting an image into its corresponding latent code of the trained GAN is of utmost importance as it allows for the manipulation of real images, leveraging the rich semantics learned by the network. Recognizing the limitations of current inversion approaches, in this work we present a novel inversion scheme that extends current encoder-based inversion methods by introducing an iterative refinement mechanism. Instead of directly predicting the latent code of a given real image using a single pass, the encoder is tasked with predicting a residual with respect to the current estimate of the inverted latent code in a self-correcting manner. Our residualbased encoder, named ReStyle, attains improved accuracy compared to current state-of-the-art encoder-based methods with a negligible increase in inference time. We analyze the behavior of ReStyle to gain valuable insights into its iterative nature. We then evaluate the performance of our residual encoder and analyze its robustness compared to optimization-based inversion and state-of-the-art encoders. Code is available via our project page: https: //yuval-alaluf.github.io/restyle-encoder/",ArXiv,2021
45d313df80c16781f2d7f032a618f9e891fb993f,https://www.semanticscholar.org/paper/45d313df80c16781f2d7f032a618f9e891fb993f,A Coarse-to-Fine Method for Estimating the Axis Pose Based on 3D Point Clouds in Robotic Cylindrical Shaft-in-Hole Assembly,"In this work, we propose a novel coarse-to-fine method for object pose estimation coupled with admittance control to promote robotic shaft-in-hole assembly. Considering that traditional approaches to locate the hole by force sensing are time-consuming, we employ 3D vision to estimate the axis pose of the hole. Thus, robots can locate the target hole in both position and orientation and enable the shaft to move into the hole along the axis orientation. In our method, first, the raw point cloud of a hole is processed to acquire the keypoints. Then, a coarse axis is extracted according to the geometric constraints between the surface normals and axis. Lastly, axis refinement is performed on the coarse axis to achieve higher precision. Practical experiments verified the effectiveness of the axis pose estimation. The assembly strategy composed of axis pose estimation and admittance control was effectively applied to the robotic shaft-in-hole assembly.",Sensors,2021
46ce5b5dfa6b53a991b9d0c6c390626cb3aedc3e,https://www.semanticscholar.org/paper/46ce5b5dfa6b53a991b9d0c6c390626cb3aedc3e,A System for Traded Control Teleoperation of Manipulation Tasks using Intent Prediction from Hand Gestures,"This paper presents a teleoperation system that includes robot perception and intent prediction from hand gestures. The perception module identifies the objects present in the robot workspace and the intent prediction module which object the user likely wants to grasp. This architecture allows the approach to rely on traded control instead of direct control: we use hand gestures to specify the goal objects for a sequential manipulation task, the robot then autonomously generates a grasping or a retrieving motion using trajectory optimization. The perception module relies on the model-based tracker to precisely track the 6D pose of the objects and makes use of a state of the art learning-based object detection and segmentation method, to initialize the tracker by automatically detecting objects in the scene. Goal objects are identified from user hand gestures using a trained a multi-layer perceptron classifier. After presenting all the components of the system and their empirical evaluation, we present experimental results comparing our pipeline to a direct traded control approach (i.e., one that does not use prediction) which shows that using intent prediction allows to bring down the overall task execution time.",2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),2021
47312ef986c0b9574a4f60bef2d56cfdd09afa20,https://www.semanticscholar.org/paper/47312ef986c0b9574a4f60bef2d56cfdd09afa20,ReAgent: Point Cloud Registration using Imitation and Reinforcement Learning,"Point cloud registration is a common step in many 3D computer vision tasks such as object pose estimation, where a 3D model is aligned to an observation. Classical registration methods generalize well to novel domains but fail when given a noisy observation or a bad initialization. Learning-based methods, in contrast, are more robust but lack in generalization capacity. We propose to consider iterative point cloud registration as a reinforcement learning task and, to this end, present a novel registration agent (ReAgent). We employ imitation learning to initialize its discrete registration policy based on a steady expert policy. Integration with policy optimization, based on our proposed alignment reward, further improves the agent’s registration performance. We compare our approach to classical and learning-based registration methods on both ModelNet40 (synthetic) and ScanObjectNN (real data) and show that our ReAgent achieves state-of-the-art accuracy. The lightweight architecture of the agent, moreover, enables reduced inference time as compared to related approaches. Code is available at github.com/dornik/reagent.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
49f8cff0578b3650b78ec3bc02109958a6b514a2,https://www.semanticscholar.org/paper/49f8cff0578b3650b78ec3bc02109958a6b514a2,DRNet: A Depth-Based Regression Network for 6D Object Pose Estimation,"This paper focuses on 6Dof object pose estimation from a single RGB image. We tackle this challenging problem with a two-stage optimization framework. More specifically, we first introduce a translation estimation module to provide an initial translation based on an estimated depth map. Then, a pose regression module combines the ROI (Region of Interest) and the original image to predict the rotation and refine the translation. Compared with previous end-to-end methods that directly predict rotations and translations, our method can utilize depth information as weak guidance and significantly reduce the searching space for the subsequent module. Furthermore, we design a new loss function function for symmetric objects, an approach that has handled such exceptionally difficult cases in prior works. Experiments show that our model achieves state-of-the-art object pose estimation for the YCB- video dataset (Yale-CMU-Berkeley).",Sensors,2021
4c5e724121ae0053c71ad5f3ba8435315dabe107,https://www.semanticscholar.org/paper/4c5e724121ae0053c71ad5f3ba8435315dabe107,Handling Object Symmetries in CNN-based Pose Estimation,"In this paper, we investigate the problems that Convolutional Neural Networks (CNN)-based pose estimators have with symmetric objects. We considered the value of the CNN’s output representation when continuously rotating the object and found that it has to form a closed loop after each step of symmetry. Otherwise, the CNN (which is itself a continuous function) has to replicate an uncontinuous function. On a 1-DOF toy example we show that commonly used representations do not fulfill this demand and analyze the problems caused thereby. In particular, we find that the popular min-over-symmetries approach for creating a symmetry-aware loss tends not to work well with gradient-based optimization, i.e. deep learning.We propose a representation called ""closed symmetry loop"" (csl) from these insights, where the angle of relevant vectors is multiplied by the symmetry order and then generalize it to 6-DOF. The representation extends our algorithm from [1] including a method to disambiguate symmetric equivalents during the final pose estimation. The algorithm handles continuous rotational symmetry (e.g. a bottle) and discrete rotational symmetry (e.g. a 4-fold symmetric box). It is evaluated on the T-LESS dataset, where it reaches state-of-the-art for unrefining RGB-based methods.",2021 IEEE International Conference on Robotics and Automation (ICRA),2020
4c864ffba707d382c21935224c79b8b99c6d2ab0,https://www.semanticscholar.org/paper/4c864ffba707d382c21935224c79b8b99c6d2ab0,Learning an end-to-end spatial grasp generation and refinement algorithm from simulation,"Novel object grasping is an important technology for robot manipulation in unstructured environments. For most of current works, a grasp sampling process is required to obtain grasp candidates, combined with a local feature extractor using deep learning. However, this pipeline is time–cost, especially when grasp points are sparse such as at the edge of a bowl. To tackle this problem, our algorithm takes the whole sparse point clouds as the input and requires no sampling or search process. Our work is combined with two steps. The first step is to predict poses, categories and scores (qualities) based on a SPH3D-GCN network. The second step is an iterative grasp pose refinement, which is to refine the best grasp generated in the first step. The whole weight sizes for these two steps are only about 0.81M and 0.52M, which takes about 73 ms for a whole prediction process including an iterative grasp pose refinement using a GeForce 840M GPU. Moreover, to generate training data of multi-object scene, a single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) combined with thin structures grasp planning are generated. Our experiment shows our work gets 76.67% success rate and 94.44% completion rate, which performs better than current state-of-the-art works.",Mach. Vis. Appl.,2021
4db555f3634743592713e071c6ec815f7ac08aa2,https://www.semanticscholar.org/paper/4db555f3634743592713e071c6ec815f7ac08aa2,Depth from Camera Motion and Object Detection,"This paper addresses the problem of learning to estimate the depth of detected objects given some measurement of camera motion (e.g., from robot kinematics or vehicle odometry). We achieve this by 1) designing a recurrent neural network (DBox) that estimates the depth of objects using a generalized representation of bounding boxes and uncalibrated camera movement and 2) introducing the Object Depth via Motion and Detection Dataset (ODMD). ODMD training data are extensible and configurable, and the ODMD benchmark includes 21,600 examples across four validation and test sets. These sets include mobile robot experiments using an end-effector camera to locate objects from the YCB dataset and examples with perturbations added to camera motion or bounding box data. In addition to the ODMD benchmark, we evaluate DBox in other monocular application domains, achieving state-of-the-art results on existing driving and robotics benchmarks and estimating the depth of objects using a camera phone.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
508c20e346bdf427f3f5b0638b1de784ce55bf52,https://www.semanticscholar.org/paper/508c20e346bdf427f3f5b0638b1de784ce55bf52,DProST: 6-DoF Object Pose Estimation Using Space Carving and Dynamic Projective Spatial Transformer,"Predicting the pose of an object is a core computer vision task. Most deep learning-based pose estimation methods require CAD data to use 3D intermediate representations or project 2D appearance. However, these methods cannot be used when CAD data for objects of interest are unavailable. Besides, the existing methods did not precisely reflect the perspective distortion to the learning process. In addition, information loss due to self-occlusion has not been studied well. In this regard, we propose a new pose estimation system consisting of a space carving module that reconstructs a reference 3D feature to replace the CAD data. Moreover, Our new transformation module, Dynamic Projective Spatial Transformer (DProST), transforms a reference 3D feature to reflect the pose while considering perspective distortion. Also, we overcome the selfocclusion problem by a new Bidirectional Z-buffering (BiZbuffer) method, which extracts both the front view and the self-occluded back view of the object. Lastly, we suggest a Perspective Grid Distance Loss (PGDL), enabling stable learning of the pose estimator without CAD data. Experimental results show that our method outperforms the stateof-the-art method on the LINEMOD dataset and comparable performance on LINEMOD-OCCLUSION dataset even compared to the methods that require CAD data in network training. The code will be released soon.",ArXiv,2021
52387d585d5cd97963f460741fdfa719ff078dc2,https://www.semanticscholar.org/paper/52387d585d5cd97963f460741fdfa719ff078dc2,SD-Pose: Semantic Decomposition for Cross-Domain 6D Object Pose Estimation,"The current leading 6D object pose estimation methods rely heavily on annotated real data, which is highly costly to acquire. To overcome this, many works have proposed to introduce computer-generated synthetic data. However, bridging the gap between the synthetic and real data remains a severe problem. Images depicting different levels of realism/semantics usually have different transferability between the synthetic and real domains. Inspired by this observation, we introduce an approach, SD-Pose, that explicitly decomposes the input image into multi-level semantic representations and then combines the merits of each representation to bridge the domain gap. Our comprehensive analyses and experiments show that our semantic decomposition strategy can fully utilize the different domain similarities of different representations, thus allowing us to outperform the state of the art on modern 6D object pose datasets without accessing any real data during training.",AAAI,2021
5b11ca437c51dbec0f01ab9465111b4a8c62ea97,https://www.semanticscholar.org/paper/5b11ca437c51dbec0f01ab9465111b4a8c62ea97,Improved Stacked Hourglass Network for Robust 6D Object Pose Estimation,"In this article, we introduce an accurate yet robust method to recover the 6D pose of the object from an RGB image. The core of our method is using the farthest point sampling algorithm to design a set of representative keypoints on the object model surface, and then use the improved stacked hourglass network (ISHN) with multi-scale aggregation module to localize them in the 2D image by predicting the keypoints heatmaps. Finally, the PnP algorithm can recover the 6D pose according to the 3D-2D relationship of keypoints. Besides, when the object is partially occluded, we can successfully recover the pose of the object by selecting the most confident keypoints. Our method can simultaneously detect and recover the 6D pose of the instance object in the RGB image without additional post-processing steps. Experimental results show that compared with the state-of-the-art RGB-based pose estimation methods, our method can achieve competitive or more superior performance on two benchmark datasets.",ISEEIE,2021
5daecb135e8f914ad05933fe4a5dffc8c068c340,https://www.semanticscholar.org/paper/5daecb135e8f914ad05933fe4a5dffc8c068c340,PoseRBPF: A Rao–Blackwellized Particle Filter for 6-D Object Pose Tracking,"Tracking 6-D poses of objects from videos provides rich information to a robot in performing different tasks such as manipulation and navigation. In this article, we formulate the 6-D object pose tracking problem in the Rao–Blackwellized particle filtering framework, where the 3-D rotation and the 3-D translation of an object are decoupled. This factorization allows our approach, called PoseRBPF, to efficiently estimate the 3-D translation of an object along with the full distribution over the 3-D rotation. This is achieved by discretizing the rotation space in a fine-grained manner and training an autoencoder network to construct a codebook of feature embeddings for the discretized rotations. As a result, PoseRBPF can track objects with arbitrary symmetries while still maintaining adequate posterior distributions. Our approach achieves state-of-the-art results on two 6-D pose estimation benchmarks. We open-source our implementation at https://github.com/NVlabs/PoseRBPF.",IEEE Transactions on Robotics,2019
5e907c675b455df48255ed7f0a7476ed245677ed,https://www.semanticscholar.org/paper/5e907c675b455df48255ed7f0a7476ed245677ed,Detecting Object Surface Keypoints From a Single RGB Image via Deep Learning Network for 6-DoF Pose Estimation,"Estimating the 6-DoF (Degree of Freedom) object pose from a single RGB image is one of the challenging tasks in the field of computer vision. Before the pose which is defined as the translation and rotation parameters can be derived by the traditional PnP algorithm, 2D image projections of a set of 3D object keypoints must be accurately detected. In this paper, we present techniques for defining 3D object surface keypoints and predicting their corresponding 2D counterparts via deep-learning network architectures. The main technique to designate 3D object keypoints is to employ quadratic fitting scheme for calculating the principal surface curvatures as the weights and then select from all surface points the ones mostly distributive with larger curvatures to describe the object shape as possible. However, the 2D projected keypoints are not directly regressed from the network, but encoded as the unit vector fields pointing to them, so that the voting scheme to recover back those 2D keypoints can be performed. Moreover, an effective loss function with the regularization term is adopted in training ResNet for predicting image projections of object keypoints by focusing on small-scale errors. Experimental results show that our proposed technique outperforms state-of-the-art approaches in both “2D projection” and “3D transformation” metrics.",IEEE Access,2021
5f8bd72a97771a9a3f2ec93d7644c77dc7af973f,https://www.semanticscholar.org/paper/5f8bd72a97771a9a3f2ec93d7644c77dc7af973f,Active Perception with Neural Networks,"Active perception has been employed in many domains, particularly in the field of robotics. The idea of active perception is to utilize the input data to predict the next action that can help robots to improve their performance. The main challenge lies in understanding the input data to be coupled with the action, and gathering meaningful information of the environment in an efficient way is necessary and desired. With recent developments of neural networks, interpreting the perceived data has become possible at the semantic level, and realtime interpretation based on deep learning has enabled the efficient closing of the perception-action loop. This report highlights recent progress in employing active perception based on neural networks for single and multi-agent systems.",ArXiv,2021
6084a88c75fe6342145a457652859d84cab9ba0d,https://www.semanticscholar.org/paper/6084a88c75fe6342145a457652859d84cab9ba0d,A Research on Advanced Technology of Target Detection in Unmanned Driving,"Unmanned driving leads the development of smart cities and safe transportation. It relies on a large amount of complex data generated during driving. This paper reviews the state-of-the-art research status of data collection and analysis techniques. We divide the data required for unmanned driving into two types: traffic scene data and driving behavior data. Firstly, by fully considering the different needs of enterprises, universities and related institutions, we have fully studied the algorithms proposed by scholars all over the world. Then we introduce mainstream 2D and 3D target detection algorithms based on RGBD and laser point clouds. Finally, the article introduces some of the most widely used urban road data sets.",Journal of Physics: Conference Series,2021
60ea609a4b10cd386774fe5c42272aabc30bda35,https://www.semanticscholar.org/paper/60ea609a4b10cd386774fe5c42272aabc30bda35,VideoPose: Estimating 6D object pose from videos,"We introduce a simple yet effective algorithm that uses convolutional neural networks to directly estimate object poses from videos. Our approach leverages the temporal information from a video sequence, and is computationally efficient and robust to support robotic and AR domains. Our proposed network takes a pre-trained 2D object detector as input, and aggregates visual features through a recurrent neural network to make predictions at each frame. Experimental evaluation on the YCB-Video dataset show that our approach is on par with the state-of-the-art algorithms. Further, with a speed of 30 fps, it is also more efficient than the state-of-the-art, and therefore applicable to a variety of applications that require real-time object pose estimation.",ArXiv,2021
6204ae73afd180ad5eb611911b05221ce82ce8ea,https://www.semanticscholar.org/paper/6204ae73afd180ad5eb611911b05221ce82ce8ea,Object SLAM-Based Active Mapping and Robotic Grasping,"This paper presents the first active object mapping framework for complex robotic manipulation and autonomous perception tasks. The framework is built on an object SLAM system integrated with a simultaneous multi-object pose estimation process that is optimized for robotic grasping. Aiming to reduce the observation uncertainty on target objects and increase their pose estimation accuracy, we also design an object-driven exploration strategy to guide the object mapping process, enabling autonomous mapping and high-level perception. Combining the mapping module and the exploration strategy, an accurate object map that is compatible with robotic grasping can be generated. Additionally, quantitative evaluations also indicate that the proposed framework has a very high mapping accuracy. Experiments with manipulation (including object grasping and placement) and augmented reality significantly demonstrate the effectiveness and advantages of our proposed framework.",2021 International Conference on 3D Vision (3DV),2020
733cd27d50bd9e6661af3619b40332cbf14a8151,https://www.semanticscholar.org/paper/733cd27d50bd9e6661af3619b40332cbf14a8151,L6DNet: Light 6 DoF Network for Robust and Precise Object Pose Estimation With Small Datasets,"Estimating the 3D pose of an object is a challenging task that can be considered within augmented reality or robotic applications. In this letter, we propose a novel approach to perform 6 DoF object pose estimation from a single RGB-D image. We adopt a hybrid pipeline in two stages: data-driven and geometric respectively. The data-driven step consists of a classification CNN to estimate the object 2D location in the image from local patches, followed by a regression CNN trained to predict the 3D location of a set of keypoints in the camera coordinate system. To extract the pose information, the geometric step consists in aligning the 3D points in the camera coordinate system with the corresponding 3D points in world coordinate system by minimizing a registration error, thus computing the pose. Our experiments on the standard dataset LineMod show that our approach is more robust and accurate than state-of-the-art methods. The approach is also validated to achieve a 6 DoF positioning task by visual servoing.",IEEE Robotics and Automation Letters,2021
74432a3a94653c9e610581313dff25858617bccb,https://www.semanticscholar.org/paper/74432a3a94653c9e610581313dff25858617bccb,Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview,"Object pose detection and tracking has recently attracted increasing attention due to its wide applications in many areas, such as autonomous driving, robotics, and augmented reality. Among methods for object pose detection and tracking, deep learning is the most promising one that has shown better performance than others. However, there is lack of survey study about latest development of deep learning based methods. Therefore, this paper presents a comprehensive review of recent progress in object pose detection and tracking that belongs to the deep learning technical route. To achieve a more thorough introduction, the scope of this paper is limited to methods taking monocular RGB/RGBD data as input, covering three kinds of major tasks: instance-level monocular object pose detection, category-level monocular object pose detection, and monocular object pose tracking. In our work, metrics, datasets, and methods about both detection and tracking are presented in detail. Comparative results of current state-of-the-art methods on several publicly available datasets are also presented, together with insightful observations and inspiring future research directions.",ArXiv,2021
76b7f18d522d52147791a37a42f2ba6f9883c284,https://www.semanticscholar.org/paper/76b7f18d522d52147791a37a42f2ba6f9883c284,GVnet: Gaussian model with voxel-based 3D detection network for autonomous driving,"This paper proposed a two-stage Voxel-based 3D Object detector which named GVnet. Voxel-based method mainly relies on sampling and Grouping point in voxel and the feature map generated by subsequent 3D CNN to control the quality of detection. Moreover, traditional voxel feature encoder (VFE) methods cannot adjust the quality of feature map through reasonable sampling. Therefore, the method we propose is an improvement to the existing VFE. The specific operations are: First calculate the corresponding Gaussian distribution of the original point cloud data, and then sampling any number of points by controlling the confidence value to improve the performance of voxel encoder and further improve the quality of the feature map output by the 3D CNN. In addition, a voxel ROI pooling method is proposed in stage two. In ROI Pooling, the receptive field in the original space and the corresponding raw point are obtained through the mapping relationship between feature and ROI, then change the raw point to adjust the receptive field to improve the performance of classification and regression. Finally, the experimental results on the KITTI, nuScenes and Waymo dataset show that the performance of GVnet under most of the evaluation indexes is better than the current detection methods, at the cost of only a small amount of inference time.",,2021
789ee734bed6131339af3912534a34e5894aeaf9,https://www.semanticscholar.org/paper/789ee734bed6131339af3912534a34e5894aeaf9,Generating Annotated Training Data for 6D Object Pose Estimation in Operational Environments with Minimal User Interaction,"Recently developed deep neural networks achieved state-of-the-art results in the subject of 6D object pose estimation for robot manipulation. However, those supervised deep learning methods require expensive annotated training data. Current methods for reducing those costs frequently use synthetic data from simulations, but rely on expert knowledge and suffer from the domain gap when shifting to the real world. Here, we present a proof of concept for a novel approach of autonomously generating annotated training data for 6D object pose estimation. This approach is designed for learning new objects in operational environments while requiring little interaction and no expertise on the part of the user. We evaluate our autonomous data generation approach in two grasping experiments, where we archive a similar grasping success rate as related work on a non autonomously generated data set.",ArXiv,2021
7b418b183b7117435d450d14297475837867a77c,https://www.semanticscholar.org/paper/7b418b183b7117435d450d14297475837867a77c,Cross-Regional Attention Network for Point Cloud Completion,"Point clouds generated from real-world scanning are always incomplete and ununiformly distributed, which would cause structural losses in 3D shape representations. Therefore, a learning-based method is introduced in this paper to repair partial point clouds and restore complete shapes of target objects. First, we sample several local regions of inputs, encode their features and fuse them with independently extracted global features. Second, we establish a graph to connect all local features together, and then implement convolution with multi-head attention on the graph. Graph attention mechanism enables each local feature vector to search across the regions and selectively absorb other local features based on their relationships in high-dimensional feature space. Third, we design a coarse decoder to collect cross-region features from the graph and generate skeletons of complete point clouds, and a folding-based decoder is leveraged to generate final point clouds with high resolution. Our network is trained on six categories of objects from the ModelNet dataset, its performance is compared with several existing methods, the results show that our network is able to generate dense complete point cloud with the highest accuracy.",2020 25th International Conference on Pattern Recognition (ICPR),2021
7c1949a48e36e92e9bc44906fd5589c4653f9707,https://www.semanticscholar.org/paper/7c1949a48e36e92e9bc44906fd5589c4653f9707,Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation,"Grasping in cluttered scenes has always been a great challenge for robots, due to the requirement of the ability to well understand the scene and object information. Previous works usually assume that the geometry information of the objects is available, or utilize a step-wise, multi-stage strategy to predict the feasible 6-DoF grasp poses. In this work, we propose to formalize the 6-DoF grasp pose estimation as a simultaneous multi-task learning problem. In a unified framework, we jointly predict the feasible 6-DoF grasp poses, instance semantic segmentation, and collision information. The whole framework is jointly optimized and end-to-end differentiable. Our model is evaluated on large-scale benchmarks as well as the real robot system. On the public dataset, our method outperforms prior state-of-the-art methods by a large margin (+4.08 AP). We also demonstrate the implementation of our model on a real robotic platform and show that the robot can accurately grasp target objects in cluttered scenarios with a high success rate. Project link: https://openbyterobotics.github.io/sscl.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
7d568288b1a13e0fc7416c97d8d5fa0afa617a4a,https://www.semanticscholar.org/paper/7d568288b1a13e0fc7416c97d8d5fa0afa617a4a,Fast Object Segmentation Learning with Kernel-based Methods for Robotics,"Object segmentation is a key component in the visual system of a robot that performs tasks like grasping and object manipulation, especially in presence of occlusions. Like many other computer vision tasks, the adoption of deep architectures has made available algorithms that perform this task with remarkable performance. However, adoption of such algorithms in robotics is hampered by the fact that training requires large amount of computing time and it cannot be performed on-line.In this work, we propose a novel architecture for object segmentation, that overcomes this problem and provides comparable performance in a fraction of the time required by the state-of-the-art methods. Our approach is based on a pre-trained Mask R-CNN, in which various layers have been replaced with a set of classifiers and regressors that are retrained for a new task. We employ an efficient Kernel-based method that allows for fast training on large scale problems. Our approach is validated on the YCB-Video dataset which is widely adopted in the computer vision and robotics community, demonstrating that we can achieve and even surpass performance of the state-of-the-art, with a significant reduction (~6×) of the training time.The code to reproduce the experiments is publicly available on GitHub1.",2021 IEEE International Conference on Robotics and Automation (ICRA),2020
7d7faae13b994f6d1f470b5fcd68a85f357cd6ed,https://www.semanticscholar.org/paper/7d7faae13b994f6d1f470b5fcd68a85f357cd6ed,"My House, My Rules: Learning Tidying Preferences with Graph Neural Networks","Robots that arrange household objects should do so according to the user’s preferences, which are inherently subjective and difficult to model. We present NeatNet: a novel Variational Autoencoder architecture using Graph Neural Network layers, which can extract a low-dimensional latent preference vector from a user by observing how they arrange scenes. Given any set of objects, this vector can then be used to generate an arrangement which is tailored to that user’s spatial preferences, with word embeddings used for generalisation to new objects. We develop a tidying simulator to gather rearrangement examples from 75 users, and demonstrate empirically that our method consistently produces neat and personalised arrangements across a variety of rearrangement scenarios.",ArXiv,2021
7fb981da7bbd1e44daadd28545bc1e0636341de9,https://www.semanticscholar.org/paper/7fb981da7bbd1e44daadd28545bc1e0636341de9,LRA-Net: local region attention network for 3D point cloud completion,"Incomplete Point clouds obtained from one-side scanning always result in structural loss in 3D shape representations, thus many learning-based methods are proposed to restore complete point clouds from partial ones. However, most of them only utilize global features of inputs to generate outputs, which might lose details. In this paper, a new method that utilizes both global and local features is proposed. First, Local features are extracted from inputs and analyzed under the conditions interpreted by global features. Second, conditional local feature vectors are deeply fused with each other via graph convolution and self-attention. Third, deeply-fused features are decoded for generating coarse point clouds. Last, global features extracted from inputs and coarse outputs are combined to generate fine outputs with high-density. Our network is trained and tested on eight categories of objects in ModelNet. The results show that our network is able to overcome instability in local feature awareness, restore complete point clouds with more details and smoother shapes, and outperform most of those existing methods both intuitively and quantitatively. Our source codes will be available at: https://github.com/wuhang100/LRA-Net.",International Conference on Machine Vision,2021
8012f5d4bb413283870dec81d9c63bebc709522c,https://www.semanticscholar.org/paper/8012f5d4bb413283870dec81d9c63bebc709522c,“Reading Pictures Instead of Looking”: RGB-D Image-Based Action Recognition via Capsule Network and Kalman Filter,"This paper proposes an action recognition algorithm based on the capsule network and Kalman filter called “Reading Pictures Instead of Looking” (RPIL). This method resolves the convolutional neural network’s over sensitivity to rotation and scaling and increases the interpretability of the model as per the spatial coordinates in graphics. The capsule network is first used to obtain the components of the target human body. The detected parts and their attribute parameters (e.g., spatial coordinates, color) are then analyzed by Bert. A Kalman filter analyzes the predicted capsules and filters out any misinformation to prevent the action recognition results from being affected by incorrectly predicted capsules. The parameters between neuron layers are evaluated, then the structure is pruned into a dendritic network to enhance the computational efficiency of the algorithm. This minimizes the dependence of in-depth learning on the random features extracted by the CNN without sacrificing the model’s accuracy. The association between hidden layers of the neural network is also explained. With a 90% observation rate, the OAD dataset test precision is 83.3%, the ChaLearn Gesture dataset test precision is 72.2%, and the G3D dataset test precision is 86.5%. The RPILNet also satisfies real-time operation requirements (>30 fps).",Sensors,2021
84e168890308ffdc0c00c52dc52717c814f30bc2,https://www.semanticscholar.org/paper/84e168890308ffdc0c00c52dc52717c814f30bc2,FS-Net Supplementary Material,"As stated in Section 3.5 of the paper, the 3D deformation mechanism is box-cage based and the deformations are applied in a canonical space. In the canonical coordinate system, every box edge is parallel to an axis (shown in Figure A). This property makes the 3D deformation calculation easier. For example, when we need to elongate/shrink the mug along Y axis by n times. We enlarge the distance between surface S1,2,3,4 and surface S5,6,7,8 by n times. Since these two surfaces are parallel to the XZ-plane, the x and z coordinates are unchanged. Then points coordinates are changed from [x, y, z] to [x, ny, z]. The calculations are similar when we need to elongate/shrink the mug along X or Z axis by n times:",,2021
8824b30f28f2326a870567135da8e4eacfa3cc30,https://www.semanticscholar.org/paper/8824b30f28f2326a870567135da8e4eacfa3cc30,Object-oriented Map Exploration and Construction Based on Auxiliary Task Aided DRL,"Environment exploration by autonomous robots through deep reinforcement learning (DRL) based methods has attracted more and more attention. However, existing methods usually focus on robot navigation to single or multiple fixed goals, while ignoring the perception and construction of external environments. In this paper, we propose a novel environment exploration task based on DRL, which requires a robot fast and completely perceives all objects of interest, and reconstructs their poses in a global environment map, as much as the robot can do. To this end, we design an auxiliary task aided DRL model, which is integrated with the auxiliary object detection and 6-DoF pose estimation components. The outcome of auxiliary tasks can improve the learning speed and robustness of DRL, as well as the accuracy of object pose estimation. Comprehensive experimental results on the indoor simulation platform AI2-THOR have shown the effectiveness and robustness of our method.",2020 25th International Conference on Pattern Recognition (ICPR),2021
8a4ad1b07585f5305ae05568c2539c24f52cdb0c,https://www.semanticscholar.org/paper/8a4ad1b07585f5305ae05568c2539c24f52cdb0c,"Object Detection and Pose Estimation from RGB and Depth Data for Real-time, Adaptive Robotic Grasping","In recent times, object detection and pose estimation have gained significant attention in the context of robotic vision applications. Both the identification of objects of interest as well as the estimation of their pose remain important capabilities in order for robots to provide effective assistance for numerous robotic applications ranging from household tasks to industrial manipulation. This problem is particularly challenging because of the heterogeneity of objects having different and potentially complex shapes, and the difficulties arising due to background clutter and partial occlusions between objects. As the main contribution of this work, we propose a system that performs real-time object detection and pose estimation, for the purpose of dynamic robot grasping. The robot has been pre-trained to perform a small set of canonical grasps from a few fixed poses for each object. When presented with an unknown object in an arbitrary pose, the proposed approach allows the robot to detect the object identity and its actual pose, and then adapt a canonical grasp in order to be used with the new pose. For training, the system defines a canonical grasp by capturing the relative pose of an object with respect to the gripper attached to the robot’s wrist. During testing, once a new pose is detected, a canonical grasp for the object is identified and then dynamically adapted by adjusting the robot arm’s joint angles, so that the gripper can grasp the object in its new pose. We conducted experiments using a humanoid PR2 robot and showed that the proposed framework can detect well-textured objects, and provide accurate pose estimation in the presence of tolerable amounts of out-ofplane rotation. The performance is also illustrated by the robot successfully grasping objects from a wide range of arbitrary poses.",ArXiv,2021
8bbcbe800c836e30de1ea7c4659a3e85ec36f151,https://www.semanticscholar.org/paper/8bbcbe800c836e30de1ea7c4659a3e85ec36f151,Driving Behavior-Aware Network for 3D Object Tracking in Complex Traffic Scenes,"Recently a large number of 3D object tracking methods have been extensively investigated and applied in a variety of applications using convolutional neural networks. Although most of them have made great progress in partial occlusion, the intricate interweaving of moving agents (e.g. pedestrians and vehicles) may lead to inferior performance of 3D object tracking in complex traffic scenes. To boost the performance of 3D object tracking in cases of severe occlusions, we present an end-to-end deep learning framework with a driving behavior-aware model that takes full advantage of spatial-temporal details in consecutive frames and learns the driving behavior from object variations in 2D center point, depth, rotation and translation in parallel. In contrast to prior work, our novelty formulates driving behavior that reasons about the possible motion trajectories of the investigated target for autonomous systems. We show in experiments that our method outperforms state-of-the-art approaches on 3D object tracking in the challenging nuScenes dataset.",IEEE Access,2021
8d14be5a3336820561d12d93b7257642613edf10,https://www.semanticscholar.org/paper/8d14be5a3336820561d12d93b7257642613edf10,Image-based attitude determination of co-orbiting satellites using deep learning technologies,"Active debris removal missions pose demanding guidance, navigation and control requirements. We present a novel approach which adopts deep learning technologies to the problem of attitude determination of an uncooperative debris satellite of an a-priori unknown geometry. A siamese convolutional neural network is developed, which detects and tracks inherently useful landmarks from sensor data, after training upon synthetic datasets of visual, LiDAR or RGB-D data. The method is capable of real-time performance while improving upon conventional computer vision-based approaches, and generalises well to previously unseen object geometries, enabling this approach to be a feasible solution for safely performing guidance and navigation in active debris removal, satellite servicing and other close proximity operations. The performance of the algorithm, its sensitivity to model parameters and its robustness to illumination and shadowing conditions, are analysed via numerical simulation.",Aerospace Science and Technology,2021
8d77455035d89b63f1bd01f6721d424faef738c0,https://www.semanticscholar.org/paper/8d77455035d89b63f1bd01f6721d424faef738c0,Improvement of Segmentation Accuracy for Pose Estimation by Selecting an Instance,"We improved accuracy of instance segmentation and pose estimation. Pose estimation is required to pick and place objects correctly if we develop a robot that stocks products. Mask R-CNN, a conventional method for instance segmentation tends to lower its accuracy under complex environments. Now, we focused on that robots deal with only one object per one task. We developed a new method that selects one instance that was segmented successfully and then refines it intensively. Our method lowered pose estimation error 1.3×.",2021 IEEE/SICE International Symposium on System Integration (SII),2021
9491014ae415fa3cadcf11e2b9bd063b6e10e66b,https://www.semanticscholar.org/paper/9491014ae415fa3cadcf11e2b9bd063b6e10e66b,Towards markerless computer-aided surgery combining deep segmentation and geometric pose estimation: application in total knee arthroplasty,"ABSTRACT Total knee arthroplasty (TKA) is a surgical procedure performed in patients suffering from knee arthritis. The correct positioning of the implants is strongly related to multiple surgical variables that have a tremendous impact on the success of the surgery. Computer-based navigation systems have been investigated and developed in order to assist the surgeon in accurately controlling those surgical variables. The existing technologies are very costly, require additional bone incisions for fixing markers to be tracked, and these markers are usually bulky, interfering with the standard surgical flow. This work presents a markerless navigation system that supports the surgeon in accurately performing the TKA procedure. The proposed system uses a mobile RGB-D camera for replacing the existing optical tracking systems and does not require markers to be tracked. We combine an effective deep learning-based approach for accurately segmenting the bone surface with a robust geometry-based algorithm for registering the bones with pre-operative models. The favourable performance of our pipeline is achieved by (1) employing a semi-supervised labelling approach for generating training data from real TKA surgery data, (2) using effective data augmentation techniques for improving the generalisation capability and (3) using appropriate depth data cleaning strategies. The construction of this complete markerless registration prototype that generalises for unseen intra-operative data is non-obvious, and relevant insights and future research directions can be derived. The experimental results show encouraging performance for video-based TKA.",Comput. methods Biomech. Biomed. Eng. Imaging Vis.,2020
9630b8d437ad55b8aa57b0e1e656e830892cb181,https://www.semanticscholar.org/paper/9630b8d437ad55b8aa57b0e1e656e830892cb181,RobotP: A Benchmark Dataset for 6D Object Pose Estimation,"Deep learning has achieved great success on robotic vision tasks. However, when compared with other vision-based tasks, it is difficult to collect a representative and sufficiently large training set for six-dimensional (6D) object pose estimation, due to the inherent difficulty of data collection. In this paper, we propose the RobotP dataset consisting of commonly used objects for benchmarking in 6D object pose estimation. To create the dataset, we apply a 3D reconstruction pipeline to produce high-quality depth images, ground truth poses, and 3D models for well-selected objects. Subsequently, based on the generated data, we produce object segmentation masks and two-dimensional (2D) bounding boxes automatically. To further enrich the data, we synthesize a large number of photo-realistic color-and-depth image pairs with ground truth 6D poses. Our dataset is freely distributed to research groups by the Shape Retrieval Challenge benchmark on 6D pose estimation. Based on our benchmark, different learning-based approaches are trained and tested by the unified dataset. The evaluation results indicate that there is considerable room for improvement in 6D object pose estimation, particularly for objects with dark colors, and photo-realistic images are helpful in increasing the performance of pose estimation algorithms.",Sensors,2021
964f3cada56d514c694e6f92f2836ad13da381fc,https://www.semanticscholar.org/paper/964f3cada56d514c694e6f92f2836ad13da381fc,6D-ViT: Category-Level 6D Object Pose Estimation via Transformer-based Instance Representation Learning,"This paper presents 6D-ViT, a transformer-based instance representation learning network, which is suitable for highly accurate category-level object pose estimation on RGB-D images. Specifically, a novel two-stream encoder-decoder framework is dedicated to exploring complex and powerful instance representations from RGB images, point clouds and categorical shape priors. For this purpose, the whole framework consists of two main branches, named Pixelformer and Pointformer. The Pixelformer contains a pyramid transformer encoder with an all-MLP decoder to extract pixelwise appearance representations from RGB images, while the Pointformer relies on a cascaded transformer encoder and an all-MLP decoder to acquire the pointwise geometric characteristics from point clouds. Then, dense instance representations (i.e., correspondence matrix, deformation field) are obtained from a multi-source aggregation network with shape priors, appearance and geometric information as input. Finally, the instance 6D pose is computed by leveraging the correspondence among dense representations, shape priors, and the instance point clouds. Extensive experiments on both synthetic and real-world datasets demonstrate that the proposed 3D instance representation learning framework achieves state-of-the-art performance on both datasets, and significantly outperforms all existing methods.",ArXiv,2021
96e6921be3f217f67b785ad537637d2aa26cee91,https://www.semanticscholar.org/paper/96e6921be3f217f67b785ad537637d2aa26cee91,V-MAO: Generative Modeling for Multi-Arm Manipulation of Articulated Objects,"Manipulating articulated objects requires multiple robot arms in gen1 eral. It is challenging to enable multiple robot arms to c collaboratively complete 2 manipulation tasks on articulated objects. In this paper, we present V-MAO, a 3 framework for learning multi-arm manipulation of articulated objects. Our frame4 work includes a variational generative model that learns contact point distribution 5 over object rigid parts for each robot arm. The training signal is obtained from 6 interaction with the simulation environment which is enabled by planning and 7 object-centric control. We deploy our framework in a customized MuJoCo sim8 ulation environment and demonstrate that our framework achieves a high success 9 rate on six different objects and two different robots. We also show that gener10 ative modeling can effectively learn the contact point distribution on articulated 11 objects. 12",ArXiv,2021
9906e71ae26bf6bd3b281303c9c9741f9eb478b8,https://www.semanticscholar.org/paper/9906e71ae26bf6bd3b281303c9c9741f9eb478b8,Projective Manifold Gradient Layer for Deep Rotation Regression,"Regressing rotations on SO(3) manifold using deep neural networks is an important yet unsolved problem. The gap between Euclidean network output space and the non-Euclidean SO(3) manifold imposes a severe challenge for neural network learning in both forward and backward passes. While several works have proposed different regression-friendly rotation representations, very few works have been devoted to improving the gradient backpropagating in the backward pass. In this paper, we propose a manifold-aware gradient that directly backpropagates into deep network weights. Leveraging Riemannian optimization to construct a novel projective gradient, our proposed regularized projective manifold gradient (RPMG) method helps networks achieve new state-of-the-art performance in a variety of rotation estimation tasks. Our proposed gradient layer can also be applied to other smooth manifolds such as the unit sphere.",ArXiv,2021
9baf20962a1bcbebd7d067f8e13ff182ef4ddc43,https://www.semanticscholar.org/paper/9baf20962a1bcbebd7d067f8e13ff182ef4ddc43,3DP3: 3D Scene Perception via Probabilistic Programming,"We present 3DP3, a framework for inverse graphics that uses inference in a structured generative model of objects, scenes, and images. 3DP3 uses (i) voxel models to represent the 3D shape of objects, (ii) hierarchical scene graphs to decompose scenes into objects and the contacts between them, and (iii) depth image likelihoods based on real-time graphics. Given an observed RGB-D image, 3DP3’s inference algorithm infers the underlying latent 3D scene, including the object poses and a parsimonious joint parametrization of these poses, using fast bottom-up pose proposals, novel involutive MCMC updates of the scene graph structure, and, optionally, neural object detectors and pose estimators. We show that 3DP3 enables scene understanding that is aware of 3D shape, occlusion, and contact structure. Our results demonstrate that 3DP3 is more accurate at 6DoF object pose estimation from real images than deep learning baselines and shows better generalization to challenging scenes with novel viewpoints, contact, and partial observability.",ArXiv,2021
9bfb99ba49442cd7ac6bb506750825b3e0b7aa08,https://www.semanticscholar.org/paper/9bfb99ba49442cd7ac6bb506750825b3e0b7aa08,Self-supervised Detection and Pose Estimation of Logistical Objects in 3D Sensor Data,"Localization of objects in cluttered scenes with machine learning methods is a fairly young research area. Despite the high potential of object localization for full process automation in Industry 4.0 and logistical environments, 3D data sets for such applications to train machine learning models are not openly available and only few publications have been made on that topic. To the authors knowledge, this is the first publication that describes a self-supervised and fully automated deep learning approach for object pose estimation using simulated 3D data. The solution covers the simulated generation of training data, the detection of objects in point clouds using a fully convolutional voting network and the computation of the pose for each detected object instance.",2020 25th International Conference on Pattern Recognition (ICPR),2021
9c5cc1bc2bd75455ab04cfc46de774f7fa32a860,https://www.semanticscholar.org/paper/9c5cc1bc2bd75455ab04cfc46de774f7fa32a860,Efficient Center Voting for Object Detection and 6D Pose Estimation in 3D Point Cloud,"We present a novel and efficient approach to estimate 6D object poses of known objects in complex scenes represented by point clouds. Our approach is based on the well-known point pair feature (PPF) matching, which utilizes self-similar point pairs to compute potential matches and thereby cast votes for the object pose by a voting scheme. The main contribution of this paper is to present an improved PPF-based recognition framework, especially a new center voting strategy based on the relative geometric relationship between the object center and point pair features. Using this geometric relationship, we first generate votes to object centers resulting in vote clusters near real object centers. Then we group and aggregate these votes to generate a set of pose hypotheses. Finally, a pose verification operator is performed to filter out false positives and predict appropriate 6D poses of the target object. Our approach is also suitable to solve the multi-instance and multi-object detection tasks. Extensive experiments on a variety of challenging benchmark datasets demonstrate that the proposed algorithm is discriminative and robust towards similar-looking distractors, sensor noise, and geometrically simple shapes. The advantage of our work is further verified by comparing to the state-of-the-art approaches.",IEEE Transactions on Image Processing,2021
9ff7a7b4b09a430c44db1cea04e02362a69d09eb,https://www.semanticscholar.org/paper/9ff7a7b4b09a430c44db1cea04e02362a69d09eb,SGPA: Structure-Guided Prior Adaptation for Category-Level 6D Object Pose Estimation,"Category-level 6D object pose estimation aims to predict the position and orientation for unseen objects, which plays a pillar role in many scenarios such as robotics and augmented reality. The significant intra-class variation is the bottleneck challenge in this task yet remains unsolved so far. In this paper, we take advantage of category prior to overcome this problem by innovating a structure-guided prior adaptation scheme to accurately estimate 6D pose for individual objects. Different from existing prior based methods, given one object and its corresponding category prior, we propose to leverage their structure similarity to dynamically adapt the prior to the observed object. The prior adaptation intrinsically associates the adopted prior with different objects, from which we can accurately reconstruct the 3D canonical model of the specific object for pose estimation. To further enhance the structure characteristic of objects, we extract low-rank structure points from the dense object point cloud, therefore more efficiently incorporating sparse structural information during prior adaptation. Extensive experiments on CAMERA25 and REAL275 benchmarks demonstrate significant performance improvement. Project homepage: https://www.cse.cuhk.edu. hk/ ̃kaichen/projects/sgpa/sgpa.html.",,2021
a03bf691acd6512d2ac0382dfd44f4b5908297aa,https://www.semanticscholar.org/paper/a03bf691acd6512d2ac0382dfd44f4b5908297aa,DemoGrasp: Few-Shot Learning for Robotic Grasping with Human Demonstration,"The ability to successfully grasp objects is crucial in robotics, as it enables several interactive downstream applications. To this end, most approaches either compute the full 6D pose for the object of interest or learn to predict a set of grasping points. While the former approaches do not scale well to multiple object instances or classes yet, the latter require large annotated datasets and are hampered by their poor generalization capabilities to new geometries. To overcome these shortcomings, we propose to teach a robot how to grasp an object with a simple and short human demonstration. Hence, our approach neither requires many annotated images nor is it restricted to a specific geometry. We first present a small sequence of RGB-D images displaying a human-object interaction. This sequence is then leveraged to build associated hand and object meshes that represent the depicted interaction. Subsequently, we complete missing parts of the reconstructed object shape and estimate the relative transformation between the reconstruction and the visible object in the scene. Finally, we transfer the a-priori knowledge from the relative pose between object and human hand with the estimate of the current object pose in the scene into necessary grasping instructions for the robot. Exhaustive evaluations with Toyota’s Human Support Robot (HSR) in real and synthetic environments demonstrate the applicability of our proposed methodology and its advantage in comparison to previous approaches.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
a2e3cc94a0eff4ea17408f0ba24a0ebd6cb6a6b5,https://www.semanticscholar.org/paper/a2e3cc94a0eff4ea17408f0ba24a0ebd6cb6a6b5,From SLAM to Situational Awareness: Challenges and Survey,"The knowledge that an intelligent and autonomous mobile robot has and is able to acquire of itself and the environment, namely the situation, limits its reasoning, decision-making, and execution skills to efficiently and safely perform complex missions. Situational awareness is a basic capability of humans that has been deeply studied in fields like Psychology, Military, Aerospace, Education, etc., but it has barely been considered in robotics, which has focused on ideas such as sensing, perception, sensor fusion, state estimation, localization and mapping, spatial AI, etc. In our research, we connected the broad multidisciplinary existing knowledge on situational awareness with its counterpart in mobile robotics. In this paper, we survey the state-of-the-art robotics algorithms, we analyze the situational awareness aspects that have been covered by them, and we discuss their missing points. We found out that the existing robotics algorithms are still missing manifold important aspects of situational awareness. As a consequence, we conclude that these missing features are limiting the performance of robotic situational awareness, and further research is needed to overcome this challenge. We see this as an opportunity, and provide our vision for future research on robotic situational awareness.",ArXiv,2021
a442e264eaa8be82b74b902f10fb83c73cd1a482,https://www.semanticscholar.org/paper/a442e264eaa8be82b74b902f10fb83c73cd1a482,PR-GCN: A Deep Graph Convolutional Network with Point Refinement for 6D Pose Estimation,"RGB-D based 6D pose estimation has recently achieved remarkable progress, but still suffers from two major limitations: (1) ineffective representation of depth data and (2) insufficient integration of different modalities. This paper proposes a novel deep learning approach, namely Graph Convolutional Network with Point Refinement (PR-GCN), to simultaneously address the issues above in a unified way. It first introduces the Point Refinement Network (PRN) to polish 3D point clouds, recovering missing parts with noise removed. Subsequently, the Multi-Modal Fusion Graph Convolutional Network (MMF-GCN) is presented to strengthen RGB-D combination, which captures geometry-aware intermodality correlation through local information propagation in the graph convolutional network. Extensive experiments are conducted on three widely used benchmarks, and stateof-the-art performance is reached. Besides, it is also shown that the proposed PRN and MMF-GCN modules are well generalized to other frameworks.",ArXiv,2021
a7720e03ebe71f391516dbefca47027a5d4e90e4,https://www.semanticscholar.org/paper/a7720e03ebe71f391516dbefca47027a5d4e90e4,Self-supervised Instance Detection by (and for) Pose Estimation,"Real-time object pose estimation is necessary for many robot manipulation algorithms. However, state-of-the-art methods for object pose estimation are trained for a specific set of objects; these methods thus need to be retrained to estimate the pose of each new object, often requiring tens of GPU-days of training for optimal performance. We propose to leverage a slow zero-shot pose estimator to self-supervise the training of a fast detection algorithm. This fast detector can then be used to filter the input to the pose estimator, drastically improving its inference speed. We show that this self-supervised training exceeds the performance of existing zero-shot detection methods on two widely used object pose estimation and detection datasets, without requiring any human annotations. Further, we show that the resulting method for pose estimation has a significantly faster inference speed, due to the ability to filter out large parts of the image. Thus, our method for self-supervised online learning of a detector (trained using pseudo-labels from a slow pose estimator) leads to accurate pose estimation at real-time speeds, without requiring human annotations. Supplementary materials can be found at https://georgegu1997.github.io/SSOID/",,2021
a94487efe33bc340cf40cf0e23d0f1da7dfa3ef1,https://www.semanticscholar.org/paper/a94487efe33bc340cf40cf0e23d0f1da7dfa3ef1,StablePose: Learning 6D Object Poses from Geometrically Stable Patches,"We introduce the concept of geometric stability to the problem of 6D object pose estimation and propose to learn pose inference based on geometrically stable patches extracted from observed 3D point clouds. According to the theory of geometric stability analysis, a minimal set of three planar/cylindrical patches are geometrically stable and determine the full 6DoFs of the object pose. We train a deep neural network to regress 6D object pose based on geometrically stable patch groups via learning both intra-patch geometric features and inter-patch contextual features. A subnetwork is jointly trained to predict per-patch poses. This auxiliary task is a relaxation of the group pose prediction: A single patch cannot determine the full 6DoFs but is able to improve pose accuracy in its corresponding DoFs. Working with patch groups makes our method generalize well for random occlusion and unseen instances. The method is easily amenable to resolve symmetry ambiguities. Our method achieves the state-of-the-art results on public benchmarks compared not only to depth-only but also to RGBD methods. It also performs well in category-level pose estimation.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
ae850ec60dd516661484216698fc795ecdead138,https://www.semanticscholar.org/paper/ae850ec60dd516661484216698fc795ecdead138,UDA-COPE: Unsupervised Domain Adaptation for Category-level Object Pose Estimation,"Learning to estimate object pose often requires groundtruth (GT) labels, such as CAD model and absolute-scale object pose, which is expensive and laborious to obtain in the real world. To tackle this problem, we propose an unsupervised domain adaptation (UDA) for category-level object pose estimation, called UDA-COPE. Inspired by the recent multi-modal UDA techniques, the proposed method exploits a teacher-student self-supervised learning scheme to train a pose estimation network without using target domain labels. We also introduce a bidirectional filtering method between predicted normalized object coordinate space (NOCS) map and observed point cloud, to not only make our teacher network more robust to the target domain but also to provide more reliable pseudo labels for the student network training. Extensive experimental results demonstrate the effectiveness of our proposed method both quantitatively and qualitatively. Notably, without leveraging target-domain GT labels, our proposed method achieves comparable or sometimes superior performance to existing methods that depend on the GT labels.",ArXiv,2021
aeaa9ba2a453a60478d66acbb15678a5dd882686,https://www.semanticscholar.org/paper/aeaa9ba2a453a60478d66acbb15678a5dd882686,Tangent Space Backpropagation for 3D Transformation Groups,"We address the problem of performing backpropagation for computation graphs involving 3D transformation groups SO(3), SE(3), and Sim(3). 3D transformation groups are widely used in 3D vision and robotics, but they do not form vector spaces and instead lie on smooth manifolds. The standard backpropagation approach, which embeds 3D transformations in Euclidean spaces, suffers from numerical difficulties. We introduce a new library, which exploits the group structure of 3D transformations and performs backpropagation in the tangent spaces of manifolds. We show that our approach is numerically more stable, easier to implement, and beneficial to a diverse set of tasks. Our plug-and-play PyTorch library is available at https://github.com/princeton-vl/lietorch.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
b07e11d983885e56fb0de6d9a54dba3049c8034f,https://www.semanticscholar.org/paper/b07e11d983885e56fb0de6d9a54dba3049c8034f,Towards Object-generic 6D Pose Estimation,"Pose estimation is a basic module in many robot manipulation pipelines. Estimating the pose of objects in the environment can be useful for grasping, motion planning, or manipulation. However, current stateof-the-art methods for pose estimation either rely on large annotated training sets or simulated data. Further, the long training times for these methods prohibit quick interaction with novel objects. To address these issues, we introduce a novel method for zero-shot object pose estimation in clutter. Our approach uses a hypothesis generation and scoring framework, with a focus on learning a scoring function that generalizes to objects not used for training. We achieve zero-shot generalization by rating hypotheses as a function of unordered point differences. We evaluate our method on challenging datasets with both textured and untextured objects in cluttered scenes and demonstrate that our method significantly outperforms previous methods on this task. We also demonstrate how our system can be used by quickly scanning and building a model of a novel object, which can immediately be used by our method for pose estimation. Our work allows users to estimate the pose of novel objects without requiring any retraining.",,2021
b0eea37647d8065f52b13c01d5198f79b6f57e2b,https://www.semanticscholar.org/paper/b0eea37647d8065f52b13c01d5198f79b6f57e2b,6-DoF Pose Estimation of Texture-Less Objects Based on DenseFusion,,Advances in Intelligent Automation and Soft Computing,2021
b38cb25edb76b07ca1c4dee6c38d575648ba4c2c,https://www.semanticscholar.org/paper/b38cb25edb76b07ca1c4dee6c38d575648ba4c2c,Efficient Object Manipulation to an Arbitrary Goal Pose: Learning-based Anytime Prioritized Planning,"We focus on the task of object manipulation to an arbitrary goal pose, in which a robot is supposed to pick an assigned object to place at the goal position with a specific pose. However, limited by the execution space of the manipulator with gripper, one-step picking, moving and releasing might be failed, where an intermediate object pose is required as a transition. In this paper, we propose a learningdriven anytime prioritized search-based solver to find a feasible solution with low path cost in a short time. In our work, the problem is formulated as a hierarchical learning problem, with the high level aiming at finding an intermediate object pose, and the low-level manipulator path planning between adjacent grasps. We learn an off-line training path cost estimator to predict approximate path planning costs, which serve as pseudo rewards to allow for pre-training the high-level planner without interacting with the simulator. To deal with the problem of distribution mismatch of the cost net and the actual execution cost space, a refined training stage is conducted with simulation interaction. A series of experiments carried out in simulation and real world indicate that our system can achieve better performances in the object manipulation task with less time and less cost.",ArXiv,2021
b546264ad8cc92a427fbf1dba6b0547af545cb3d,https://www.semanticscholar.org/paper/b546264ad8cc92a427fbf1dba6b0547af545cb3d,Q-attention: Enabling Efficient Learning for Vision-based Robotic Manipulation,"Despite the success of reinforcement learning methods, they have yet to have their breakthrough moment when applied to a broad range of robotic manipulation tasks. This is partly due to the fact that reinforcement learning algorithms are notoriously difficult and time consuming to train, which is exacerbated when training from images rather than full-state inputs. As humans perform manipulation tasks, our eyes closely monitor every step of the process with our gaze focusing sequentially on the objects being manipulated. With this in mind, we present our Attentiondriven Robotic Manipulation (ARM) algorithm, which is a general manipulation algorithm that can be applied to a range of sparse-rewarded tasks, given only a small number of demonstrations. ARM splits the complex task of manipulation into a 3 stage pipeline: (1) a Q-attention agent extracts interesting pixel locations from RGB and point cloud inputs, (2) a next-best pose agent that accepts crops from the Q-attention agent and outputs poses, and (3) a control agent that takes the goal pose and outputs joint actions. We show that current learning algorithms fail on a range of RLBench tasks, whilst ARM is successful. Videos and code found at: https://sites.google.com/view/q-attention.",ArXiv,2021
b784b2023593af98692b1d2063b53eca897512cd,https://www.semanticscholar.org/paper/b784b2023593af98692b1d2063b53eca897512cd,SAT: 2D Semantics Assisted Training for 3D Visual Grounding,"3D visual grounding aims at grounding a natural language description about a 3D scene, usually represented in the form of 3D point clouds, to the targeted object region. Point clouds are sparse, noisy, and contain limited semantic information compared with 2D images. These inherent limitations make the 3D visual grounding problem more challenging. In this study, we propose 2D Semantics Assisted Training (SAT) that utilizes 2D image semantics in the training stage to ease point-cloud-language joint representation learning and assist 3D visual grounding. The main idea is to learn auxiliary alignments between rich, clean 2D object representations and the corresponding objects or mentioned entities in 3D scenes. SAT takes 2D object semantics, i.e., object label, image feature, and 2D geometric feature, as the extra input in training but does not require such inputs during inference. By effectively utilizing 2D semantics in training, our approach boosts the accuracy on the Nr3D dataset from 37.7% to 49.2%, which significantly surpasses the non-SAT baseline with the identical network architecture and inference input. Our approach outperforms the state of the art by large margins on multiple 3D visual grounding datasets, i.e., +10.4% absolute accuracy on Nr3D, +9.9% on Sr3D, and +5.6% on ScanRef.",ArXiv,2021
b82336fa538b7383f0fae65d92b77fe8812446aa,https://www.semanticscholar.org/paper/b82336fa538b7383f0fae65d92b77fe8812446aa,Multi-View Object Pose Refinement With Differentiable Renderer,"This letter introduces a novel multi-view 6 DoF object pose refinement approach focusing on improving methods trained on synthetic data. It is based on the DPOD detector, which produces dense 2D-3D correspondences between the model vertices and the image pixels in each frame. We have opted for the use of multiple frames with known relative camera transformations, as it allows introduction of geometrical constraints via an interpretable ICP-like loss function. The loss function is implemented with a differentiable renderer and is optimized iteratively. We also demonstrate that a full detection and refinement pipeline, which is trained solely on synthetic data, can be used for auto-labeling real data. We perform quantitative evaluation on LineMOD, Occlusion, Homebrewed and YCB-V datasets and report excellent performance in comparison to the state-of-the-art methods trained on the synthetic and real data. We demonstrate empirically that our approach requires only a few frames and is robust to close camera locations and noise in extrinsic camera calibration, making its practical usage easier and more ubiquitous.",IEEE Robotics and Automation Letters,2021
bcacedb88c5a6435355b84e7e33c071f430d02e3,https://www.semanticscholar.org/paper/bcacedb88c5a6435355b84e7e33c071f430d02e3,Deep Point Cloud Reconstruction,"Point cloud obtained from 3D scanning is often sparse, noisy, and irregular. To cope with these issues, recent studies have been separately conducted to densify, denoise, and complete inaccurate point cloud. In this paper, we advocate that jointly solving these tasks leads to significant improvement for point cloud reconstruction. To this end, we propose a deep point cloud reconstruction network consisting of two stages: 1) a 3D sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into 3D points. In particular, we further improve the performance of transformer by a newly proposed module called amplified positional encoding. This module has been designed to differently amplify the magnitude of positional encoding vectors based on the points’ distances for adaptive refinements. Extensive experiments demonstrate that our network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNetPart datasets. Moreover, we underline the ability of our network to generalize toward real-world and unmet scenes. Implementation will be released soon.",ArXiv,2021
be76788da35f627efd1886cd6a3d015372328191,https://www.semanticscholar.org/paper/be76788da35f627efd1886cd6a3d015372328191,Multi-person Implicit Reconstruction from a Single Image,"We present a new end-to-end learning framework to obtain detailed and spatially coherent reconstructions of multiple people from a single image. Existing multi-person methods suffer from two main drawbacks: they are often model-based and therefore cannot capture accurate 3D models of people with loose clothing and hair; or they require manual intervention to resolve occlusions or interactions. Our method addresses both limitations by introducing the first end-to-end learning approach to perform model-free implicit reconstruction for realistic 3D capture of multiple clothed people in arbitrary poses (with occlusions) from a single image. Our network simultaneously estimates the 3D geometry of each person and their 6DOF spatial locations, to obtain a coherent multi-human reconstruction. In addition, we introduce a new synthetic dataset that depicts images with a varying number of inter-occluded humans and a variety of clothing and hair styles. We demonstrate robust, high-resolution reconstructions on images of multiple humans with complex occlusions, loose clothing and a large variety of poses and scenes. Our quantitative evaluation on both synthetic and real world datasets demonstrates state-of-the-art performance with significant improvements in the accuracy and completeness of the reconstructions over competing approaches.",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021
c1b3233a33a25768afebcfd108a67b7159f6fd65,https://www.semanticscholar.org/paper/c1b3233a33a25768afebcfd108a67b7159f6fd65,DualPoseNet: Category-level 6D Object Pose and Size Estimation using Dual Pose Network with Refined Learning of Pose Consistency,"Category-level 6D object pose and size estimation is to predict full pose configurations of rotation, translation, and size for object instances observed in single, arbitrary views of cluttered scenes. In this paper, we propose a new method of Dual Pose Network with refined learning of pose consistency for this task, shortened as DualPoseNet. DualPoseNet stacks two parallel pose decoders on top of a shared pose encoder, where the implicit decoder predicts object poses with a working mechanism different from that of the explicit one; they thus impose complementary supervision on the training of pose encoder. We construct the encoder based on spherical convolutions, and design a module of Spherical Fusion wherein for a better embedding of posesensitive features from the appearance and shape observations. Given no testing CAD models, it is the novel introduction of the implicit decoder that enables the refined pose prediction during testing, by enforcing the predicted pose consistency between the two decoders using a self-adaptive loss term. Thorough experiments on benchmarks of both categoryand instance-level object pose datasets confirm efficacy of our designs. DualPoseNet outperforms existing methods with a large margin in the regime of high precision. Our code is released publicly at https://github. com/Gorilla-Lab-SCUT/DualPoseNet.",ArXiv,2021
c3c087ba647465653a49a4be9213a39ac657af11,https://www.semanticscholar.org/paper/c3c087ba647465653a49a4be9213a39ac657af11,Dex-NeRF: Using a Neural Radiance Field to Grasp Transparent Objects,"The ability to grasp and manipulate transparent objects is a major challenge for robots. Existing depth cameras have difficulty detecting, localizing, and inferring the geometry of such objects. We propose using neural radiance fields (NeRF) to detect, localize, and infer the geometry of transparent objects with sufficient accuracy to find and grasp them securely. We leverage NeRF’s viewindependent learned density, place lights to increase specular reflections, and perform a transparency-aware depth-rendering that we feed into the Dex-Net grasp planner. We show how additional lights create specular reflections that improve the quality of the depth map, and test a setup for a robot workcell equipped with an array of cameras to perform transparent object manipulation. We also create synthetic and real datasets of transparent objects in real-world settings, including singulated objects, cluttered tables, and the top rack of a dishwasher. In each setting we show that NeRF and Dex-Net are able to reliably compute robust grasps on transparent objects, achieving 90 % and 100 % grasp-success rates in physical experiments on an ABB YuMi, on objects where baseline methods fail. See https://sites.google.com/view/dex-nerf for code, video, and datasets.",ArXiv,2021
c669a8c04888fdb40d7945b69bcfb55888e19c3a,https://www.semanticscholar.org/paper/c669a8c04888fdb40d7945b69bcfb55888e19c3a,GCCN: Geometric Constraint Co-attention Network for 6D Object Pose Estimation,"In 6D object pose estimation task, object models are usually available and represented as the point cloud set in canonical object frame, which are important references for estimating object poses to the camera frame. However, directly introducing object models as the prior knowledge (i.e., object model point cloud) will cause potential perturbations and even degenerate pose estimation performance. To make the most of object model priors and eliminate the problem, we present an end-to-end deep learning approach called the Geometric Constraint Co-attention Network (GCCN) for 6D object pose estimation. GCCN is designed to explicitly leverage the object model priors effectively with the co-attention mechanism. We add explicit geometric constraints to a co-attention module to inform the geometric correspondence relationships between points in the scene and object model priors and develop a novel geometric constraint loss to guide the training. In this manner, our method effectively eliminates the side effect of directly introducing the object model priors into the network. Experiments on the YCB-Video and LineMOD datasets demonstrate that our GCCN substantially improves the performance of pose estimation and is robust against heavy occlusions. We also demonstrate that GCCN is accurate and robust enough to be deployed in real-world robotic tasks.",ACM Multimedia,2021
c7fcb5f1f58b850a9ebbda4ca800163efecbe9f7,https://www.semanticscholar.org/paper/c7fcb5f1f58b850a9ebbda4ca800163efecbe9f7,Yolo+FPN: 2D and 3D Fused Object Detection With an RGB-D Camera,"In this paper we propose a new deep neural network system, called Yolo+FPN, which fuses both 2D and 3D object detection algorithms to achieve better real-time object detection results and faster inference speed, to be used on real robots. Finding an optimized fusion strategy to efficiently combine 3D object detection with 2D detection information is useful and challenging for both indoor and outdoor robots. In order to satisfy real-time requirements, a trade-off between accuracy and efficiency is needed. We not only have improved training and test accuracies and lower mean losses on the KITTI object detection benchmark comparing with our baseline method, but also achieve competitive average precision on 3D detection of all classes in three levels of difficulty comparing with other state-of-the-art methods. Also, we implemented Yolo+FPN system using an RGB-D camera, and compared the speed of object detection using different GPUs. For the real implementation of both indoor and outdoor scenes, we focus on person detection, which is the most challenging and important among the three classes.",2020 25th International Conference on Pattern Recognition (ICPR),2021
c80bf008837f3f4ddd265822f3a2893f7d501935,https://www.semanticscholar.org/paper/c80bf008837f3f4ddd265822f3a2893f7d501935,Can Robots Refill a Supermarket Shelf?: Motion Planning and Grasp Control,"Robots are becoming more widely used in the retail market, mostly for warehousing, but many in-store logistics processes are still difficult to automate. Both technological and methodological barriers hinder the use of robots for handling single products rather than the boxes containing them, as the experiences of the various editions of the Amazon Challenge demonstrated.",IEEE Robotics & Automation Magazine,2021
c8465cef353d50a95c588113c643b38f2dc2a609,https://www.semanticscholar.org/paper/c8465cef353d50a95c588113c643b38f2dc2a609,Vote-Based 3D Object Detection with Context Modeling and SOB-3DNMS,"Most existing 3D object detection methods recognize objects individually, without giving any consideration on contextual information between these objects. However, objects in indoor scenes are usually related to each other and the scene, forming the contextual information. Based on this observation, we propose a novel 3D object detection network, which is built on the state-of-the-art VoteNet but takes into consideration of the contextual information at multiple levels for detection and recognition of 3D objects. To encode relationships between elements at different levels, we introduce three contextual sub-modules, capturing contextual information at patch, object, and scene levels respectively, and build them into the voting and classification stages of VoteNet. In addition, at the post-processing stage, we also consider the spatial diversity of detected objects and propose an improved 3D NMS (non-maximum suppression) method, namely Survival-Of-the-Best 3DNMS (SOB-3DNMS), to reduce false detections. Experiments demonstrate that our method is an effective way to promote detection accuracy, and has achieved new state-of-the-art detection performance on challenging 3D object detection datasets, i.e., SUN RGBD and ScanNet, when only taking point cloud data as input.",Int. J. Comput. Vis.,2021
cfcf46cfb58b2c1cfd0f19c4a83f35721af3ece5,https://www.semanticscholar.org/paper/cfcf46cfb58b2c1cfd0f19c4a83f35721af3ece5,Heatmap Regression via Randomized Rounding,"Heatmap regression has become the mainstream methodology for deep learning-based semantic landmark localization. Though heatmap regression is robust to large variations in pose, illumination, and occlusion, it usually suffers from a sub-pixel localization problem. Specifically, considering that the activation point indices in heatmaps are always integers, quantization error thus appears when using heatmaps as the representation of numerical coordinates. Previous methods to overcome the sub-pixel localization problem usually rely on high-resolution heatmaps. As a result, there is always a trade-off between achieving localization accuracy and computational cost. In this paper, we formally analyze the quantization error and propose a simple yet effective quantization system. The proposed quantization system induced by the randomized rounding operation 1) encodes the fractional part of numerical coordinates into the ground truth heatmap using a probabilistic approach during training; and 2) decodes the predicted numerical coordinates from a set of activation points during testing. We prove that the proposed quantization system for heatmap regression is unbiased and lossless. Experimental results on popular facial landmark localization datasets (WFLW, 300W, COFW, and AFLW) and human pose estimation datasets (MPII and COCO) demonstrate the effectiveness of the proposed method for efficient and accurate semantic landmark localization.",IEEE transactions on pattern analysis and machine intelligence,2020
cff8790a63d2f2a6534cb6945823498fde6eebef,https://www.semanticscholar.org/paper/cff8790a63d2f2a6534cb6945823498fde6eebef,Learning to Generate Dense Point Clouds with Textures on Multiple Categories,"3D reconstruction from images is a core problem in computer vision. With recent advances in deep learning, it has become possible to recover plausible 3D shapes even from single RGB images. However, obtaining detailed geometry and texture for objects with arbitrary topology remains challenging. In this paper, we propose a novel approach for reconstructing point clouds from RGB images. Unlike other methods, we can recover dense point clouds with hundreds of thousands of points, and we also include RGB textures. In addition, we train our model on multiple categories, which leads to superior generalization to unseen categories com-pared to previous techniques. We achieve this using a two-stage approach, where we first infer an object coordinate map from the input RGB image, and then obtain the final point cloud using a reprojection and completion step. We show results on standard benchmarks that demonstrate the advantages of our technique.",2021 IEEE Winter Conference on Applications of Computer Vision (WACV),2019
d62c4098e7ba7906d6554f10c7e17cf416e70de7,https://www.semanticscholar.org/paper/d62c4098e7ba7906d6554f10c7e17cf416e70de7,ASPP-DF-PVNet: Atrous Spatial Pyramid Pooling and Distance-Filtered PVNet for occlusion resistant 6D object pose estimation,"Abstract Detecting objects and estimating their 6D poses from a single RGB image is quite challenging under severe occlusions. Recently, vector-field based methods have shown certain robustness to occlusion and truncation. Based on the vector-field representation, applying voting strategy to localize 2D keypoints can further reduce the influence of outliers. To improve the effectiveness of vector-field based deep network and voting scheme, we propose Atrous Spatial Pyramid Pooling and Distance-Filtered PVNet (ASPP-DF-PVNet), an occlusion resistant framework for 6D object pose estimation. ASPP-DF-PVNet utilizes the effective Atrous Spatial Pyramid Pooling (ASPP) module of Deeplabv3 to capture multi-scale features and encode global context information, which improves the accuracy of segmentation and vector-field prediction comparing to the original PVNet, especially under severe occlusions. Considering that the distances between pixels and keypoint hypotheses will affect the voting deviations, we then present a distance-filtered voting scheme which takes the voting distances into consideration to filter out the votes with large deviations. Experiments demonstrate that our method outperforms the state-of-the-art methods by a considerable margin without using pose refinement, and obtains competitive results against the methods with refinement on the LINEMOD and Occlusion LINEMOD datasets.",Signal Process. Image Commun.,2021
d85d16b003955c6996fafacea7f3c075c531225f,https://www.semanticscholar.org/paper/d85d16b003955c6996fafacea7f3c075c531225f,Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes,"Grasping unseen objects in unconstrained, cluttered environments is an essential skill for autonomous robotic manipulation. Despite recent progress in full 6-DoF grasp learning, existing approaches often consist of complex sequential pipelines that possess several potential failure points and run-times unsuitable for closed-loop grasping. Therefore, we propose an end-to-end network that efficiently generates a distribution of 6-DoF parallel-jaw grasps directly from a depth recording of a scene. Our novel grasp representation treats 3D points of the recorded point cloud as potential grasp contacts. By rooting the full 6-DoF grasp pose and width in the observed point cloud, we can reduce the dimensionality of our grasp representation to 4-DoF which greatly facilitates the learning process. Our class-agnostic approach is trained on 17 million simulated grasps and generalizes well to real world sensor data. In a robotic grasping study of unseen objects in structured clutter we achieve over 90% success rate, cutting the failure rate in half compared to a recent state-of-the-art method. Video of the real world experiments and code are available at https://research.nvidia.com/publication/2021-03_Contact-GraspNet%3A--Efficient.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021
d9343643990052d5d7357c85b72e59f7bae387fc,https://www.semanticscholar.org/paper/d9343643990052d5d7357c85b72e59f7bae387fc,Vision-Based Intelligent Perceiving and Planning System of a 7-DoF Collaborative Robot,"In this paper, an intelligent perceiving and planning system based on deep learning is proposed for a collaborative robot consisting of a 7-DoF (7-degree-of-freedom) manipulator, a three-finger robot hand, and a vision system, known as IPPS (intelligent perceiving and planning system). The lack of intelligence has been limiting the application of collaborative robots for a long time. A system to realize “eye-brain-hand” process is crucial for the true intelligence of robots. In this research, a more stable and accurate perceiving process was proposed. A well-designed camera system as the vision system and a new hand tracking method were proposed for operation perceiving and recording set establishment to improve the applicability. A visual process was designed to improve the accuracy of environment perceiving. Besides, a faster and more precise planning process was proposed. Deep learning based on a new CNN (convolution neural network) was designed to realize intelligent grasping planning for robot hand. A new trajectory planning method of the manipulator was proposed to improve efficiency. The performance of the IPPS was tested with simulations and experiments in a real environment. The results show that IPPS could effectively realize intelligent perceiving and planning for the robot, which could realize higher intelligence and great applicability for collaborative robots.",Computational intelligence and neuroscience,2021
de5e7d5e540f1a96be24d5263bb9a4e6037c5f67,https://www.semanticscholar.org/paper/de5e7d5e540f1a96be24d5263bb9a4e6037c5f67,Image guidance based 3D vehicle detection in traffic scene,"Abstract 3D vehicle detection is a significant step for traffic scene understanding. Several recent works have achieved state-of-the-art performance with only LiDAR point clouds. However, there are still existing challenges due to the intrinsic limitations of lidar data. In this paper, we propose a novel 3D vehicle detection method, in which visual information is introduced to remedy the deficiency of sparse point clouds. Our method is composed of two stages. In first stage, a novel proposal generator with the guidance of visual information is proposed. In the proposal generator, 2D detected bounding boxes are registered with 3D candidates from LiDAR by calibrating and then weighted non-maximum suppression (WNMS) is applied to increase the confidence of proposals to remove redundant proposals. In second stage, to construct a box predictor, instead of sampling in a sphere space, a novel sampling with cylinder space for pointnet++ is leveraged to learn local features of the point clouds. Furthermore, to achieve a better balance between confidence and localization accuracy of boxes, an Intersection-over-Union (IoU) prediction branch is modified and attached to the network. We conduct multiple experiments on the KITTI 3D object detection dataset and compare our method with state-of-the-art methods. The comparison results show that our algorithm is effective and can improve the performance of 3D vehicle detection.",Neurocomputing,2020
e0908b54b9f99b46cd220a34793e119571ee2483,https://www.semanticscholar.org/paper/e0908b54b9f99b46cd220a34793e119571ee2483,A Novel Depth and Color Feature Fusion Framework for 6D Object Pose Estimation,"This paper aims to solve the problem of estimating the 6D pose of an object under occlusion using RGB-D images. Most existing methods typically use the information of color and depth images separately to make predictions, which limits their performances in the presence of occlusion. Instead, we propose a pipeline to effectively fuse color and depth information and perform region-level pose estimation. Our method first uses a CNN to extract the color features, and then we obtain the fusion features by combining the color features into the point cloud. Unlike existing methods, the fusion features are in the form of point sets instead of feature maps. We further use a PointNet++-like network to process the fusion features, obtaining several region-level features. Each region-level feature can predict a pose with confidence. The pose with the highest confidence is chosen as the final output. Experiments show that the proposed method outperforms the state-of-the-art methods on both the LINEMOD and Occlusion LINEMOD datasets, indicating that the proposed pipeline can obtain accurate pose estimation results and is robust to occlusion.",IEEE Transactions on Multimedia,2021
e1b50fac70b8895183b5d0451ba648daa6e26875,https://www.semanticscholar.org/paper/e1b50fac70b8895183b5d0451ba648daa6e26875,ZePHyR: Zero-shot Pose Hypothesis Rating,"Pose estimation is a basic module in many robot manipulation pipelines. Estimating the pose of objects in the environment can be useful for grasping, motion planning, or manipulation. However, current state-of-the-art methods for pose estimation either rely on large annotated training sets or simulated data. Further, the long training times for these methods prohibit quick interaction with novel objects. To address these issues, we introduce a novel method for zero-shot object pose estimation in clutter. Our approach uses a hypothesis generation and scoring framework, with a focus on learning a scoring function that generalizes to objects not used for training. We achieve zero-shot generalization by rating hypotheses as a function of unordered point differences. We evaluate our method on challenging datasets with both textured and untextured objects in cluttered scenes and demonstrate that our method significantly outperforms previous methods on this task. We also demonstrate how our system can be used by quickly scanning and building a model of a novel object, which can immediately be used by our method for pose estimation. Our work allows users to estimate the pose of novel objects without requiring any retraining. Additional information can be found on our website https://bokorn.github.io/zephyr/",2021 IEEE International Conference on Robotics and Automation (ICRA),2021
e1d829ae45a4470b88bad974f8cd1cf27f59b586,https://www.semanticscholar.org/paper/e1d829ae45a4470b88bad974f8cd1cf27f59b586,StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation,"We present a large-scale stereo RGB image object pose estimation dataset named the StereOBJ-1M dataset. The dataset is designed to address challenging cases such as object transparency, translucency, and specular reflection, in addition to the common challenges of occlusion, symmetry, and variations in illumination and environments. In order to collect data of sufficient scale for modern deep learning models, we propose a novel method for efficiently annotating pose data in a multi-view fashion that allows data capturing in complex and flexible environments. Fully annotated with 6D object poses, our dataset contains over 396K frames and over 1.5M annotations of 18 objects recorded in 183 scenes constructed in 11 different environments. The 18 objects include 8 symmetric objects, 7 transparent objects, and 8 reflective objects. We benchmark two state-of-the-art pose estimation frameworks on StereOBJ-1M as baselines for future work. We also propose a novel object-level pose optimization method for computing 6D pose from keypoint predictions in multiple images.",ArXiv,2021
e2b521e9f3070e467184c08fcdaa4a796ba5ad09,https://www.semanticscholar.org/paper/e2b521e9f3070e467184c08fcdaa4a796ba5ad09,SynPick: A Dataset for Dynamic Bin Picking Scene Understanding,"We present SynPick, a synthetic dataset for dynamic scene understanding in bin-picking scenarios. In contrast to existing datasets, our dataset is both situated in a realistic industrial application domain—inspired by the well-known Amazon Robotics Challenge (ARC)—and features dynamic scenes with authentic picking actions as chosen by our picking heuristic developed for the ARC 2017. The dataset is compatible with the popular BOP dataset format. We describe the dataset generation process in detail, including object arrangement generation and manipulation simulation using the NVIDIA PhysX physics engine. To cover a large action space, we perform untargeted and targeted picking actions, as well as random moving actions. To establish a baseline for object perception, a state-of-the-art pose estimation approach is evaluated on the dataset. We demonstrate the usefulness of tracking poses during manipulation instead of single-shot estimation even with a naive filtering approach. The generator source code and dataset are publicly available.",2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),2021
e825efccd3ab4656f02bfd7ca9a1f18471fc5b6f,https://www.semanticscholar.org/paper/e825efccd3ab4656f02bfd7ca9a1f18471fc5b6f,DONet: Learning Category-Level 6D Object Pose and Size Estimation from Depth Observation,"We propose a method of Category-level 6D Object Pose and Size Estimation (COPSE) from a single depth image, without external pose-annotated real-world training data. While previous works [43, 39, 4] exploit visual cues in RGB(D) images, our method makes inferences based on the rich geometric information of the object in the depth channel alone. Essentially, our framework explores such geometric information by learning the unified 3D OrientationConsistent Representations (3D-OCR) module, and further enforced by the property of Geometry-constrained Reflection Symmetry (GeoReS) module. The magnitude information of object size and the center point is finally estimated by Mirror-Paired Dimensional Estimation (MPDE) module. Extensive experiments on the category-level NOCS benchmark demonstrate that our framework competes with state-of-the-art approaches that require labeled real-world images. We also deploy our approach to a physical Baxter robot to perform manipulation tasks on unseen but category-known instances, and the results further validate the efficacy of our proposed model.",ArXiv,2021
eaa1b2e90b8184509fa5fde0170fc929d0f6d439,https://www.semanticscholar.org/paper/eaa1b2e90b8184509fa5fde0170fc929d0f6d439,Learn to grasp unknown objects in robotic manipulation,"Grasping unfamiliar objects (unknown during training) based on limited prior knowledge is a challenging task in robotic manipulation. Recent solutions typically require predefined information of target objects, task-specific training data, or a huge experience data with training time-consuming to achieve usable generalization ability. This paper introduces a robotic grasping strategy based on the model-free deep reinforcement learning, named Deep Reinforcement Grasp Policy. The developed system demands minimal training time and limited simple objects in simulation and generalizes efficiently on novel objects in real-world scenario. Without requiring any type of prior object awareness or task-specific training data. Our scalable visual grasping system is entirely self-learning approach. The model trains end-to-end policies (from only visual observations to decisions-making) to seek optimal grasp strategy. A perception network utilizes a convolutional neural network that maps visual observations to grasp action as dense pixel-wise Q-values represent the location and orientation of a primitive action executed by a robot. In simulation and physical experiments, a six-DOF robot manipulator with a two-finger gripper is utilized to validate the developed method. The empirical results demonstrated successfully based only on minimal previous knowledge of a few hours of simulated training and simple objects.",Intell. Serv. Robotics,2021
eaea68de5d41066eec9967f6264b354537e2706e,https://www.semanticscholar.org/paper/eaea68de5d41066eec9967f6264b354537e2706e,Towards Deep Learning-based 6D Bin Pose Estimation in 3D Scans,"An automated robotic system needs to be as robust as possible and fail-safe in general while having relatively high precision and repeatability. Although deep learning-based methods are becoming research standard on how to approach 3D scan and image processing tasks, the industry standard for processing this data is still analytically-based. Our paper claims that analytical methods are less robust and harder for testing, updating, and maintaining. This paper focuses on a specific task of 6D pose estimation of a bin in 3D scans. Therefore, we present a high-quality dataset composed of synthetic data and real scans captured by a structured-light scanner with precise annotations. Additionally, we propose two different methods for 6D bin pose estimation, an analytical method as the industrial standard and a baseline data-driven method. Both approaches are crossevaluated, and our experiments show that augmenting the training on real scans with synthetic data improves our proposed data-driven neural model. This position paper is preliminary, as proposed methods are trained and evaluated on a relatively small initial dataset which we plan to extend in the future.",ArXiv,2021
ed4d88d89c7a1f185cc1b572d1804fbbbbce082b,https://www.semanticscholar.org/paper/ed4d88d89c7a1f185cc1b572d1804fbbbbce082b,SRT3D: A Sparse Region-Based 3D Object Tracking Approach for the Real World,"Region-based methods have become increasingly popular for model-based, monocular 3D tracking of texture-less objects in cluttered scenes. However, while they achieve state-of-the-art results, most methods are computationally expensive, requiring significant resources to run in real-time. In the following, we build on our previous work and develop SRT3D, a sparse region-based approach to 3D object tracking that bridges this gap in efficiency. Our method considers image information sparsely along so-called correspondence lines that model the probability of the object’s contour location. We thereby improve on the current state of the art and introduce smoothed step functions that consider a defined global and local uncertainty. For the resulting probabilistic formulation, a thorough analysis is provided. Finally, we use a pre-rendered sparse viewpoint model to create a joint posterior probability for the object pose. The function is maximized using second-order Newton optimization with Tikhonov regularization. During the pose estimation, we differM. Stoiber German Aerospace Center, 82234 Wessling, Germany Technical University of Munich, 80333 Munich, Germany E-mail: manuel.stoiber@dlr.de M. Pfanne German Aerospace Center, 82234 Wessling, Germany E-mail: martin.pfanne@dlr.de K. H. Strobl German Aerospace Center, 82234 Wessling, Germany E-mail: klaus.strobl@dlr.de R. Triebel German Aerospace Center, 82234 Wessling, Germany Technical University of Munich, 80333 Munich, Germany E-mail: rudolph.triebel@dlr.de A. Albu-Schäffer German Aerospace Center, 82234 Wessling, Germany Technical University of Munich, 80333 Munich, Germany E-mail: alin.albu-schaeffer@dlr.de entiate between global and local optimization, using a novel approximation for the first-order derivative employed in the Newton method. In multiple experiments, we demonstrate that the resulting algorithm improves the current state of the art both in terms of runtime and quality, performing particularly well for noisy and cluttered images encountered in the real world.",ArXiv,2021
edd5f20cf934fc497d473e8dad0cb02ba727e0bc,https://www.semanticscholar.org/paper/edd5f20cf934fc497d473e8dad0cb02ba727e0bc,Occlusion-Robust Object Pose Estimation with Holistic Representation,"Practical object pose estimation demands robustness against occlusions to the target object. State-of-the-art (SOTA) object pose estimators take a two-stage approach, where the first stage predicts 2D landmarks using a deep network and the second stage solves for 6DOF pose from 2D-3D correspondences. Albeit widely adopted, such two-stage approaches could suffer from novel occlusions when generalising and weak landmark coherence due to disrupted features. To address these issues, we develop a novel occlude-and-blackout batch augmentation technique to learn occlusion-robust deep features, and a multiprecision supervision architecture to encourage holistic pose representation learning for accurate and coherent landmark predictions. We perform careful ablation tests to verify the impact of our innovations and compare our method to SOTA pose estimators. Without the need of any post-processing or refinement, our method exhibits superior performance on the LINEMOD dataset. On the YCB-Video dataset our method outperforms all non-refinement methods in terms of the ADD(-S) metric. We also demonstrate the high data-efficiency of our method. Our code is available at http://github.com/BoChenYS/ROPE",ArXiv,2021
ef88663fe4a024c2d0a68f580dae9c1cf5711301,https://www.semanticscholar.org/paper/ef88663fe4a024c2d0a68f580dae9c1cf5711301,Learning Stereopsis from Geometric Synthesis for 6D Object Pose Estimation,"Current monocular-based 6D object pose estimation methods generally achieve less competitive results than RGBD-based methods, mostly due to the lack of 3D information. To make up this gap, this paper proposes a 3D geometric volume based pose estimation method with a short baseline two-view setting. By constructing a geometric volume in the 3D space, we combine the features from two adjacent images to the same 3D space. Then a network is trained to learn the distribution of the position of object keypoints in the volume, and a robust soft RANSAC solver is deployed to solve the pose in closed form. To balance accuracy and cost, we propose a coarse-to-fine framework to improve the performance in an iterative way. The experiments show that our method outperforms state-of-the-art monocular-based methods, and is robust in different objects and scenes, especially in serious occlusion situations.",ArXiv,2021
f02832f1b1986695921c7820f454348bfee09637,https://www.semanticscholar.org/paper/f02832f1b1986695921c7820f454348bfee09637,CMA: Cross-modal attention for 6D object pose estimation,"Abstract Deep learning methods for 6D object pose estimation based on RGB and depth (RGB-D) images have been successfully applied to robotic manipulation and grasping. Among these approaches, the fusion of RGB and depth modalities is one of the most critical issues. Most existing works performed fusion via either simple concatenation, or element-wise multiplication of the features generated by these two modalities. Despite achieving impressive progress, such fusion strategies do not explicitly consider the different contributions of RGB and depth modalities, leaving a gap for performance enhancement. In this paper, we present a Cross-Modal Attention (CMA) component for the problem of 6D object pose estimation. With the attention mechanism, features of two different modalities are aggregated adaptively through the attention weights, such that powerful representations from the RGB-D images can be efficiently extracted. Comprehensive experiments on both LINEMOD and YCB-Video datasets demonstrate that the proposed approach achieves state-of-the-art performance.",Comput. Graph.,2021
f18ba771f91fc82d5ad0a3a3421da832887b5a8f,https://www.semanticscholar.org/paper/f18ba771f91fc82d5ad0a3a3421da832887b5a8f,Point cloud completion using multiscale feature fusion and cross-regional attention,,Image Vis. Comput.,2021
f32a16a0d30ce68dd3d80a9ec7ffbaa75786e47d,https://www.semanticscholar.org/paper/f32a16a0d30ce68dd3d80a9ec7ffbaa75786e47d,VENet: Voting Enhancement Network for 3D Object Detection,"Hough voting, as has been demonstrated in VoteNet, is effective for 3D object detection, where voting is a key step. In this paper, we propose a novel VoteNet-based 3D detector with vote enhancement to improve the detection accuracy in cluttered indoor scenes. It addresses the limitations of current voting schemes, i.e., votes from neighboring objects and background have significant negative impacts. Before voting, we replace the classic MLP with the proposed Attentive MLP (AMLP) in the backbone network to get better feature description of seed points. During voting, we design a new vote attraction loss (VALoss) to enforce vote centers to locate closely and compactly to the corresponding object centers. After voting, we then devise a vote weighting module to integrate the foreground/background prediction into the vote aggregation process to enhance the capability of the original VoteNet to handle noise from background voting. The three proposed strategies all contribute to more effective voting and improved performance, resulting in a novel 3D object detector, termed VENet. Experiments show that our method outperforms state-of-the-art methods on benchmark datasets. Ablation studies demonstrate the effectiveness of the proposed components.",,2021
f345e2bc76b898cde003ede0e58bcc93851f64dc,https://www.semanticscholar.org/paper/f345e2bc76b898cde003ede0e58bcc93851f64dc,Automatic 3D Object Recognition and Localization for Robotic Grasping,"With the emergence of Industry 4.0 and its highly re-configurable manufacturing context, the typical fixedposition grasping systems are no longer usable. This reality underlined the necessity for fully automatic and adaptable robotic grasping systems. With that in mind, the primary purpose of this paper is to join Machine Learning models for detection and pose estimation into an automatic system to be used in a grasping environment. The developed system uses Mask-RCNN and Densefusion models for the recognition and pose estimation of objects, respectively. The grasping is executed, taking into consideration both the pose and the object’s ID, as well as allowing for user and application adaptability through an initial configuration. The system was tested both on a validation dataset and in a real-world environment. The main results show that the system has more difficulty with complex objects; however, it shows promising results for simpler objects, even with training on a reduced dataset. It is also able to generalize to objects slightly different than the ones seen in training. There is an 80% success rate in the best cases for simple grasping attempts.",ICINCO,2021
f37f92c7da0e690e7c3fecf56c4cd8e9f86485aa,https://www.semanticscholar.org/paper/f37f92c7da0e690e7c3fecf56c4cd8e9f86485aa,GPR: Grasp Pose Refinement Network for Cluttered Scenes,"Object grasping in cluttered scenes is a widely investigated field of robot manipulation. Most of the current works focus on estimating grasp pose from point clouds based on an efficient single-shot grasp detection network. However, due to the lack of geometry awareness of the local grasping area, it may cause severe collisions and unstable grasp configurations. In this paper, we propose a two-stage grasp pose refinement network which detects grasps globally while fine-tuning low-quality grasps and filtering noisy grasps locally. Furthermore, we extend the 6-DoF grasp with an extra dimension as grasp width which is critical for collisionless grasping in cluttered scenes. It takes a single-view point cloud as input and predicts dense and precise grasp configurations. To enhance the generalization ability, we build a synthetic single-object grasp dataset including 150 commodities of various shapes, and a complex multi-object cluttered scene dataset including 100k point clouds with robust, dense grasp poses and mask annotations. Experiments conducted on Yumi IRB-1400 Robot demonstrate that the model trained on our dataset performs well in real environments and outperforms previous methods by a large margin.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021
f38430d335b2dee8a232afe03ece08de1ef962a1,https://www.semanticscholar.org/paper/f38430d335b2dee8a232afe03ece08de1ef962a1,Object pose estimation for robot loading in accommodation space using alpha-shape algorithm,"Robots with visual sensors have been used in various goods logistics, such as bin picking or uploading. However, there are more and more demands for the automatic blanking and loading, and it is necessary to solve the problem of object pose estimation in changing accommodation space. This paper proposes a method for pose estimation in the accommodation space using alpha-shape algorithm and improved fruit fly optimization algorithm (FOA). The alpha-shape volume variety of object and measured space is set to the objective function, and the pose variety of object is set to six variables of improved FOA. The experiments were performed by setting parameters of improved FOA and considering the four space types represented the common accommodation shapes. Compared with previous work using convex hull, the new study using alpha-shape algorithm not only keeps the object in the accommodation space, but also maintains the object pose which is at the bottom of the space and can meet the practical requirement of object placement by robot arms.",Soft Comput.,2021
f5cc6d291e5ca1d4fdbcc2ce0f1a776d8f7623ef,https://www.semanticscholar.org/paper/f5cc6d291e5ca1d4fdbcc2ce0f1a776d8f7623ef,Three-Dimensional Target Detection Based on RGB-D Data,"Received: 15 September 2020 Accepted: 25 January 2021 The current three-dimensional (3D) target detection model has a low accuracy, because the surface information of the target can only be partially represented by its two-dimensional (2D) image detector. To solve the problem, this paper studies the 3D target detection in the RGB-D data of indoor scenes, and modifies the frustum PointNet (F-PointNet), a model superior in point cloud data processing, to detect indoor targets like sofa, chair, and bed. The 2D image detector of F-PointNet was replaced with you only look once (YOLO) v3 and faster region-based convolutional neural network (R-CNN) respectively. Then, the FPointNet models with the two 2D image detectors were compared on SUN RGB-D dataset. The results show that the model with YOLO v3 did better in target detection, with a clear advantage in mean average precision (>6.27).",Traitement du Signal,2021
fb2769a88b3eb152779694768038d3715a9274ba,https://www.semanticscholar.org/paper/fb2769a88b3eb152779694768038d3715a9274ba,Broad Generalization in Robotics Will Require Broad Datasets,"In order for robots to robustly perform a wide range of different tasks 1 in open-world settings, they must be able to generalize broadly, handling diverse 2 environments, objects, and situations. Machine learning, and deep learning in par3 ticular, provides a powerful tool for enabling generalization. However, although 4 deep learning overtook other fields such as computer vision in just a few years, en5 abling the same kind of broad generalization in robotics has been comparatively 6 more challenging. Unlike in supervised learning domains, where large datasets 7 that are representative of real-world settings have been in use for some time, 8 robotic learning experiments typically involve collecting narrow and specialized 9 datasets for each method, robot, and laboratory, and these datasets are typically 10 discarded afterwards. We will argue that in order to enable broad generalization 11 in robotic learning, we must move toward a robotic learning methodology that 12 utilizes broad datasets, and this will only be possible once we routinely reuse data 13 across methods, experiments, laboratories, and robots. We will discuss the impor14 tance of such data reuse, and the kinds of technical and practical components that 15 may make it possible in the future. 16",,2021
fcbafddad5d96b8905ec2bde4bce301d088df102,https://www.semanticscholar.org/paper/fcbafddad5d96b8905ec2bde4bce301d088df102,NeRF-GTO: Using a Neural Radiance Field to Grasp Transparent Objects,"Transparent objects are a bane for robot manipulation tasks. Existing 1 depth sensors have difficulty detecting, localizing, and inferring their geometry, 2 making grasping contacts with them precarious. We propose using neural radi3 ance fields (NeRF) to detect, localize, and infer the geometry of transparent ob4 jects with sufficient accuracy to find and perform grasps. We leverage NeRF’s 5 view-independent learned density, combined with placing lights to increase spec6 ular reflections, and perform a transparency-aware depth-rendering that we feed 7 into the Dex-Net grasp planner. We show how additional lights create specular 8 reflections that improve the quality of the depth map, and test a possible setup for 9 a robot workcell equipped with an array of cameras to perform transparent object 10 manipulation. We also create synthetic and real datasets of transparent objects 11 in real-world settings, including cluttered tables, laboratory setting, and the top 12 rack of a dishwasher. In each setting we show that NeRF and Dex-Net are able to 13 compute grasps on transparent objects. See supplementary material for code and 14 datasets. 15",,2021
fe62989859c6a964042b43e048b7fd6c83225c75,https://www.semanticscholar.org/paper/fe62989859c6a964042b43e048b7fd6c83225c75,Data Generation for Learning to Grasp in a Bin-picking Scenario,"The rise of deep learning has greatly transformed the pipeline of robotic grasping from model-based approach to data-driven stream. Along this line, a large scale of grasping data either collected from simulation or from real world examples become extremely important. In this paper, we present our recent work on data generation in simulation for a bin-picking scene. 77 objects from the YCB object data sets are used to generate the dataset with PyBullet, where different environment conditions are taken into account including lighting, camera pose, sensor noise and so on. In all, 100K data samples are collected in terms of ground truth segmentation, RGB, 6D pose and point cloud. All the data examples including the source code are made available online.",ArXiv,2021
ffe07f0d862ea715ddb40ff42d71efe83269e324,https://www.semanticscholar.org/paper/ffe07f0d862ea715ddb40ff42d71efe83269e324,Progressive Deep Learning Framework for Recognizing 3D Orientations and Object Class Based on Point Cloud Representation,"Deep learning approaches to estimating full 3D orientations of objects, in addition to object classes, are limited in their accuracies, due to the difficulty in learning the continuous nature of three-axis orientation variations by regression or classification with sufficient generalization. This paper presents a novel progressive deep learning framework, herein referred to as 3D POCO Net, that offers high accuracy in estimating orientations about three rotational axes yet with efficiency in network complexity. The proposed 3D POCO Net is configured, using four PointNet-based networks for independently representing the object class and three individual axes of rotations. The four independent networks are linked by in-between association subnetworks that are trained to progressively map the global features learned by individual networks one after another for fine-tuning the independent networks. In 3D POCO Net, high accuracy is achieved by combining a high precision classification based on a large number of orientation classes with a regression based on a weighted sum of classification outputs, while high efficiency is maintained by a progressive framework by which a large number of orientation classes are grouped into independent networks linked by association subnetworks. We implemented 3D POCO Net for full three-axis orientation variations and trained it with about 146 million orientation variations augmented from the ModelNet10 dataset. The testing results show that we can achieve an orientation regression error of about 2.5° with about 90% accuracy in object classification for general three-axis orientation estimation and object classification. Furthermore, we demonstrate that a pre-trained 3D POCO Net can serve as an orientation representation platform based on which orientations as well as object classes of partial point clouds from occluded objects are learned in the form of transfer learning.",Sensors,2021
03216a011a0741e914bf5377832f58823393a234,https://www.semanticscholar.org/paper/03216a011a0741e914bf5377832f58823393a234,P4Contrast: Contrastive Learning with Pairs of Point-Pixel Pairs for RGB-D Scene Understanding,"Self-supervised representation learning is a critical problem in computer vision, as it provides a way to pretrain feature extractors on large unlabeled datasets that can be used as an initialization for more efficient and effective training on downstream tasks. A promising approach is to use contrastive learning to learn a latent space where features are close for similar data samples and far apart for dissimilar ones. This approach has demonstrated tremendous success for pretraining both image and point cloud feature extractors, but it has been barely investigated for multi-modal RGBD scans, especially with the goal of facilitating high-level scene understanding. To solve this problem, we propose contrasting “pairs of point-pixel pairs”, where positives include pairs of RGB-D points in correspondence, and negatives include pairs where one of the two modalities has been disturbed and/or the two RGB-D points are not in correspondence. This provides extra flexibility in making hard negatives and helps networks to learn features from both modalities, not just the more discriminating one of the two. Experiments show that this proposed approach yields better performance on three large-scale RGB-D scene understanding benchmarks (ScanNet, SUN RGB-D, and 3RScan) than previous pretraining approaches.",ArXiv,2020
08d3081424399ad434b5f9258216d01175025feb,https://www.semanticscholar.org/paper/08d3081424399ad434b5f9258216d01175025feb,Detecting 6D Poses of Target Objects From Cluttered Scenes by Learning to Align the Point Cloud Patches With the CAD Models,"6D target object detection is of great importance to many applications such as robotics, industrial automation, and unmanned vehicles and is increasingly influencing broad industries including manufacturing, transportation, and retail industries, to name a few. This paper focuses on detecting the 6D poses of the target objects from the point cloud of a cluttered scene. However, conventional point cloud-based 6D object detection methods rely on the robustness of key-point detection results that are not straightforward for humans to understand. The drawback makes conventional point cloud-based methods require expert knowledge to tune. In this paper, we introduced a 6D target object detection method that uses segmented object point cloud patches instead of key points to predict object 6D poses and identity. Our main contributions are an end-to-end data-driven pose correction model that is enhanced with a novel simple yet efficient basis spanning layer booster. Experiments show that although the proposed model is trained only using object CAD models, its 6D detection performance matches that of the models using view data. Thus, the proposed method is suitable for 6D detection applications that have object CAD models instead of labeled scene data.",IEEE Access,2020
0a5f86cd4afb808630e9ef0af91f8a6120118f97,https://www.semanticscholar.org/paper/0a5f86cd4afb808630e9ef0af91f8a6120118f97,DGCM-Net: Dense Geometrical Correspondence Matching Network for Incremental Experience-Based Robotic Grasping,"This article presents a method for grasping novel objects by learning from experience. Successful attempts are remembered and then used to guide future grasps such that more reliable grasping is achieved over time. To transfer the learned experience to unseen objects, we introduce the dense geometric correspondence matching network (DGCM-Net). This applies metric learning to encode objects with similar geometry nearby in feature space. Retrieving relevant experience for an unseen object is thus a nearest neighbor search with the encoded feature maps. DGCM-Net also reconstructs 3D-3D correspondences using the view-dependent normalized object coordinate space to transform grasp configurations from retrieved samples to unseen objects. In comparison to baseline methods, our approach achieves an equivalent grasp success rate. However, the baselines are significantly improved when fusing the knowledge from experience with their grasp proposal strategy. Offline experiments with a grasping dataset highlight the capability to transfer grasps to new instances as well as to improve success rate over time from increasing experience. Lastly, by learning task-relevant grasps, our approach can prioritize grasp configurations that enable the functional use of objects.",Frontiers in Robotics and AI,2020
0dd8329bf3e832cf848bf43ec9c0b42b50668d5c,https://www.semanticscholar.org/paper/0dd8329bf3e832cf848bf43ec9c0b42b50668d5c,Multi-Class Object Detection Using 2D Poses,"Object detection (OD) methods are finding application in various fields. The OD problem can be divided into two sub-problems, namely object classification and localization. While the former aims to answer the question what class a given object belongs to, the latter focuses on locating an object within a given image. For localization, both implicit representations, which border the object and its features (e.g. bounding boxes, polygons and masks), and explicit representations, which describe the object’s pose in an image (e.g. 6D pose, keypoints), are used. The 2D pose is a simple, yet effective representation that has so far been overlooked. In this paper, we therefore motivate and formulate the use of 2D poses for object localization. Furthermore, we present RetinaNet-2DP, an anchor-based convolutional neural network (CNN) that is capable of detecting objects using 2D poses. To do so, we propose the idea of Anchor Poses and the Gaussian Kernel Distance as a similarity metric between poses. Experiments on the DOTA dataset and two robotics use cases from industry emphasize the performance of the network architecture and more generally demonstrate the potential of the proposed localization representation. Finally, we critically assess our findings and present an outlook of future work.",2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),2020
1195fbeed30ebfb13432b9a85c131af299c1dd42,https://www.semanticscholar.org/paper/1195fbeed30ebfb13432b9a85c131af299c1dd42,HybridPose: 6D Object Pose Estimation Under Hybrid Representations,"We introduce HybridPose, a novel 6D object pose estimation approach. HybridPose utilizes a hybrid intermediate representation to express different geometric information in the input image, including keypoints, edge vectors, and symmetry correspondences. Compared to a unitary representation, our hybrid representation allows pose regression to exploit more and diverse features when one type of predicted representation is inaccurate (e.g., because of occlusion). Different intermediate representations used by HybridPose can all be predicted by the same simple neural network, and outliers in predicted intermediate representations are filtered by a robust regression module. Compared to state-of-the-art pose estimation approaches, HybridPose is comparable in running time and is significantly more accurate. For example, on Occlusion Linemod dataset, our method achieves a prediction speed of 30 fps with a mean ADD(-S) accuracy of 79.2%, representing a 67.4% improvement from the current state-of-the-art approach.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
13bca34692c68e12bc99afd5065aa367859c5404,https://www.semanticscholar.org/paper/13bca34692c68e12bc99afd5065aa367859c5404,LatentFusion: End-to-End Differentiable Reconstruction and Rendering for Unseen Object Pose Estimation,"Current 6D object pose estimation methods usually require a 3D model for each object. These methods also require additional training in order to incorporate new objects. As a result, they are difficult to scale to a large number of objects and cannot be directly applied to unseen objects. We propose a novel framework for 6D pose estimation of unseen objects. We present a network that reconstructs a latent 3D representation of an object using a small number of reference views at inference time. Our network is able to render the latent 3D representation from arbitrary views. Using this neural renderer, we directly optimize for pose given an input image. By training our network with a large number of 3D shapes for reconstruction and rendering, our network generalizes well to unseen objects. We present a new dataset for unseen object pose estimation--MOPED. We evaluate the performance of our method for unseen object pose estimation on MOPED as well as the ModelNet and LINEMOD datasets. Our method performs competitively to supervised methods that are trained on those objects. Code and data will be available at https://keunhong.com/publications/latentfusion/",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019
1b8a64a967feb1d892f0e4621f25c8ebdd339c37,https://www.semanticscholar.org/paper/1b8a64a967feb1d892f0e4621f25c8ebdd339c37,Multi-Path Learning for Object Pose Estimation Across Domains,"We introduce a scalable approach for object pose estimation trained on simulated RGB views of multiple 3D models together. We learn an encoding of object views that does not only describe an implicit orientation of all objects seen during training, but can also relate views of untrained objects. Our single-encoder-multi-decoder network is trained using a technique we denote ”multi-path learning”: While the encoder is shared by all objects, each decoder only reconstructs views of a single object. Consequently, views of different instances do not have to be separated in the latent space and can share common features. The resulting encoder generalizes well from synthetic to real data and across various instances, categories, model types and datasets. We systematically investigate the learned encodings, their generalization, and iterative refinement strategies on the ModelNet40 and T-LESS dataset. Despite training jointly on multiple objects, our 6D Object Detection pipeline achieves state-of-the-art results on T-LESS at much lower runtimes than competing approaches.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019
1ea5c0ecf39d1edebd664909ce43125ca11fba68,https://www.semanticscholar.org/paper/1ea5c0ecf39d1edebd664909ce43125ca11fba68,APE: A More Practical Approach To 6-Dof Pose Estimation,"Recent advances in deep learning have shown high success in obtaining the 6-DoF pose of rigid objects. However, most works rely on a pre-existing dataset and do not tackle the data gathering part. The time-consuming and tedious tasks required to build datasets are, to a large extent, what is keeping these techniques from being more widely used in practical applications. We present a whole pipeline from data gathering to pose recognition and an example application of robot grasping. For our data gathering method we require as minimum user intervention as possible and, even without using depth information or 3D models, by using a novel RGB-only Neural Network design we are able to obtain results very close to the state of the art. We call this method Affordable Pose Estimation (APE).",2020 IEEE International Conference on Image Processing (ICIP),2020
1f3d6f3a51051b9dae95e9fa7c8bdf8ed41fa78a,https://www.semanticscholar.org/paper/1f3d6f3a51051b9dae95e9fa7c8bdf8ed41fa78a,GeoFusion: Geometric Consistency Informed Scene Estimation in Dense Clutter,"We propose GeoFusion, a SLAM-based scene estimation method for building an object-level semantic map in dense clutter. In dense clutter, objects are often in close contact and severe occlusions, which brings more false detections and noisy pose estimates from existing perception methods. To solve these problems, our key insight is to consider geometric consistency at the object level within a general SLAM framework. The geometric consistency is defined in two parts: geometric consistency score and geometric relation. The geometric consistency score describes the compatibility between object geometry model and observation point cloud. Meanwhile, it provides a reliable measure to filter out false positives in data association. The geometric relation represents the relationship (e.g., contact) between geometric features (e.g., planes) among objects. The geometric relation makes the graph optimization for poses more robust and accurate. GeoFusion can robustly and efficiently infer the object labels, 6D object poses, and spatial relations from continuous noisy semantic measurements. We quantitatively evaluate our method using observations from a Fetch mobile manipulation robot. Our results demonstrate greater robustness against false estimates than frame-by-frame pose estimation from the state-of-the-art convolutional neural network.",IEEE Robotics and Automation Letters,2020
203c97e20f18d5a300741c17ba06701408d283c4,https://www.semanticscholar.org/paper/203c97e20f18d5a300741c17ba06701408d283c4,Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes,"3D object detection has attracted much attention thanks to the advances in sensors and deep learning methods for point clouds. Current state-of-the-art methods like VoteNet regress direct offset towards object centers and box orientations with an additional Multi-Layer-Perceptron network. Both their offset and orientation predictions are not accurate due to the fundamental difficulty in rotation classification. In the work, we disentangle the direct offset into Local Canonical Coordinates (LCC), box scales and box orientations. Only LCC and box scales are regressed while box orientations are generated by a canonical voting scheme. Finally, a LCC-aware back-projection checking algorithm iteratively cuts out bounding boxes from the generated vote maps, with the elimination of false positives. Our model achieves state-of-the-art performance on challenging large-scale datasets of real point cloud scans: ScanNet, SceneNN with 11.4 and 5.3 mAP improvement respectively. Code is available on this https URL.",ArXiv,2020
235e3264d5c0ff3bb91844c100365a18ce952a22,https://www.semanticscholar.org/paper/235e3264d5c0ff3bb91844c100365a18ce952a22,6D Pose Estimation of Objects Using Limited Training Data,II,,2020
24a65056973cddd5ba993a57e3ba5dc76027e3a6,https://www.semanticscholar.org/paper/24a65056973cddd5ba993a57e3ba5dc76027e3a6,G2L-Net: Global to Local Network for Real-Time 6D Pose Estimation With Embedding Vector Features,"In this paper, we propose a novel real-time 6D object pose estimation framework, named G2L-Net. Our network operates on point clouds from RGB-D detection in a divide-and-conquer fashion. Specifically, our network consists of three steps. First, we extract the coarse object point cloud from the RGB-D image by 2D detection. Second, we feed the coarse object point cloud to a translation localization network to perform 3D segmentation and object translation prediction. Third, via the predicted segmentation and translation, we transfer the fine object point cloud into a local canonical coordinate, in which we train a rotation localization network to estimate initial object rotation. In the third step, we define point-wise embedding vector features to capture viewpoint-aware information. To calculate more accurate rotation, we adopt a rotation residual estimator to estimate the residual between initial rotation and ground truth, which can boost initial pose estimation performance. Our proposed G2L-Net is real-time despite the fact multiple steps are stacked via the proposed coarse-to-fine framework. Extensive experiments on two benchmark datasets show that G2L-Net achieves state-of-the-art performance in terms of both accuracy and speed.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
24dedfafea0c95c78fd64bb2f68a716f5be3c367,https://www.semanticscholar.org/paper/24dedfafea0c95c78fd64bb2f68a716f5be3c367,MLCVNet: Multi-Level Context VoteNet for 3D Object Detection,"In this paper, we address the 3D object detection task by capturing multi-level contextual information with the self-attention mechanism and multi-scale feature fusion. Most existing 3D object detection methods recognize objects individually, without giving any consideration on contextual information between these objects. Comparatively, we propose Multi-Level Context VoteNet (MLCVNet) to recognize 3D objects correlatively, building on the state-of-the-art VoteNet. We introduce three context modules into the voting and classifying stages of VoteNet to encode contextual information at different levels. Specifically, a Patch-to-Patch Context (PPC) module is employed to capture contextual information between the point patches, before voting for their corresponding object centroid points. Subsequently, an Object-to-Object Context (OOC) module is incorporated before the proposal and classification stage, to capture the contextual information between object candidates. Finally, a Global Scene Context (GSC) module is designed to learn the global scene context. We demonstrate these by capturing contextual information at patch, object and scene levels. Our method is an effective way to promote detection accuracy, achieving new state-of-the-art detection performance on challenging 3D object detection datasets, i.e., SUN RGBD and ScanNet. We also release our code at https://github.com/NUAAXQ/MLCVNet.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
25552aea62c1e7643befb978566a209f7384a263,https://www.semanticscholar.org/paper/25552aea62c1e7643befb978566a209f7384a263,TANet: Towards Fully Automatic Tooth Arrangement,"Determining optimal target tooth arrangements is a key step of treatment planning in digital orthodontics. Existing practice for specifying the target tooth arrangement involves tedious manual operations with the outcome quality depending heavily on the experience of individual specialists, leading to inefficiency and undesirable variations in treatment results. In this work, we proposed a learning-based method for fast and automatic tooth arrangement. To achieve this, we formulate the tooth arrangement task as a novel structured 6-DOF pose prediction problem and solve it by proposing a new neural network architecture to learn from a large set of clinical data that encode successful orthodontic treatment cases. Our method has been validated with extensive experiments and shows promising results both qualitatively and quantitatively.",ECCV,2020
257d7634bd4a187dff73cd9b7139645a6829c45f,https://www.semanticscholar.org/paper/257d7634bd4a187dff73cd9b7139645a6829c45f,6D Pose Estimation of Texture-Less Object in RGB-D Images,"6D pose estimation for grasping and manipulation is a crucial task in industrial applications. Prior works overly depend on abundant texture information, which limits their performances for texture-less objects. This paper presents a two-phase method of 6D pose estimation of texture-less objects using deep learning, which consists of pose estimation and pose refinement. In order to eliminate dependence on texture, RGB-D images are only used to obtain approximated pose. A network of point clouds as input data is proposed to iteratively refine the pose. Moreover, a physically-simulated environment is constructed to generate dataset. Several experimental results show the proposed method performs best for five out of thirteen objects on the LINEMOD dataset and achieves 98.3% average recognition rate on self-made industrial parts dataset.",,2020
2954806bd77912a233a5a64a6afda989f12e047a,https://www.semanticscholar.org/paper/2954806bd77912a233a5a64a6afda989f12e047a,Symmetry Detection of Occluded Point Cloud Using Deep Learning,"Symmetry detection has been a classical problem in computer graphics, many of which using traditional geometric methods. In recent years, however, we have witnessed the arising deep learning changed the landscape of computer graphics. In this paper, we aim to solve the symmetry detection of the occluded point cloud in a deep-learning fashion. To the best of our knowledge, we are the first to utilize deep learning to tackle such a problem. In such a deep learning framework, double supervisions: points on the symmetry plane and normal vectors are employed to help us pinpoint the symmetry plane. We conducted experiments on the YCB- video dataset and demonstrate the efficacy of our method.",ArXiv,2020
29d6d63fee29c185358cd6a4271f537e01a5ab3b,https://www.semanticscholar.org/paper/29d6d63fee29c185358cd6a4271f537e01a5ab3b,Learning Object Depth from Camera Motion and Video Object Segmentation,"Video object segmentation, i.e., the separation of a target object from background in video, has made significant progress on real and challenging videos in recent years. To leverage this progress in 3D applications, this paper addresses the problem of learning to estimate the depth of segmented objects given some measurement of camera motion (e.g., from robot kinematics or vehicle odometry). We achieve this by, first, introducing a diverse, extensible dataset and, second, designing a novel deep network that estimates the depth of objects using only segmentation masks and uncalibrated camera movement. Our data-generation framework creates artificial object segmentations that are scaled for changes in distance between the camera and object, and our network learns to estimate object depth even with segmentation errors. We demonstrate our approach across domains using a robot camera to locate objects from the YCB dataset and a vehicle camera to locate obstacles while driving.",ECCV,2020
2c2a8254dd0beac80ba43f57794e3dc2a3a2ecc6,https://www.semanticscholar.org/paper/2c2a8254dd0beac80ba43f57794e3dc2a3a2ecc6,GraspFusionNet: a two-stage multi-parameter grasp detection network based on RGB–XYZ fusion in dense clutter,"Robotic grasping of diverse range of novel objects is a great challenge in dense clutter, which is also critical to many applications. However, current methods are vulnerable to perception uncertainty for dense stacked objects, resulting in limited accuracy of multi-parameter grasp prediction. In this paper, we propose a two-stage grasp detection pipeline including sampling and predicting stages. The first sampling stage applies fully convolutional network to generate grasp proposal regions, which contain potential graspable objects. Among grasp proposal region, the second prediction stage predicts complete grasp parameters based on fusion of RGB–XYZ heightmaps, which are converted from color and depth images. To perceive essential structures of stable grasping, 2D CNN and 3D CNN are used to learn color and geometric features to predict multi-parameter grasp, respectively. The direct mapping from heightmaps to grasp parameters is realized based on a multi-task loss. Experiments on a self-built dataset and an open dataset are conducted to analyze the network performance. The results indicate that the proposed two-stage method achieves the best performance among other grasp detection algorithms. Robotic experiments demonstrate generalization ability and robustness in dense clutter for novel objects, and the proposed method achieves average grasp success rate of 82.4%, which is also better than other state-of-the-art methods. Our self-built dataset and robotic grasping video are available at https://github.com/liuwenhai/toteGrasping.git.",Machine Vision and Applications,2020
2cc02be21610a0b8879ab5e2013e433171e8bdfe,https://www.semanticscholar.org/paper/2cc02be21610a0b8879ab5e2013e433171e8bdfe,6D Object Pose Estimation With Color/Geometry Attention Fusion,"The 6D object pose is widely applied in robotic grasping, virtual reality and visual navigation. However, heavy occlusion, changing light conditions and cluttered scenes make this problem challenging. To address these issues, we propose a novel approach that effectively extracts color and depth features from RGB-D images considering the local and global geometric relationships. After that, we apply a graph attention mechanism to fully exploit representations between these features and then fuse them together to predict the 6D pose of a given object. The evaluation results indicate that our method significantly improves the accuracy of the estimated 6D pose and achieves the state-of-the-art performance on LineMOD, YCB-Video, and a new dataset. Ablation studies demonstrate the effect of our network modules.","2020 16th International Conference on Control, Automation, Robotics and Vision (ICARCV)",2020
300bd40c90eb2feed6f8f2aa487df50b92e22213,https://www.semanticscholar.org/paper/300bd40c90eb2feed6f8f2aa487df50b92e22213,ATTENTION-DRIVEN ROBOTIC MANIPULATION,"Despite the success of reinforcement learning methods, they have yet to have their breakthrough moment when applied to a broad range of robotic manipulation tasks. This is partly due to the fact that reinforcement learning algorithms are notoriously difficult and time consuming to train, which is exacerbated when training from images rather than full-state inputs. As humans perform manipulation tasks, our eyes closely monitor every step of the process with our gaze focusing sequentially on the objects being manipulated. With this in mind, we present our Attention-driven Robotic Manipulation (ARM) algorithm, which is a general manipulation algorithm that can be applied to a range of real-world sparserewarded tasks without any prior task knowledge. ARM splits the complex task of manipulation into a 3 stage pipeline: (1) a Q-attention agent extracts interesting pixel locations from RGB and point cloud inputs, (2) a next-best pose agent that accepts crops from the Q-attention agent and outputs poses, and (3) a control agent that takes the goal pose and outputs joint actions. We show that current state-of-the-art reinforcement learning algorithms catastrophically fail on a range of RLBench tasks, whilst ARM is successful within a few hours.",,2020
336d4ce91cbf92805b8ed837d29d0d7baa740470,https://www.semanticscholar.org/paper/336d4ce91cbf92805b8ed837d29d0d7baa740470,3DOPE-DL: Accuracy Evaluation of a Deep Learning Framework for 3D Object Pose Estimation,"This work investigates the uncertainty in 3D pose estimation of DenseFusion, a Deep Learning-based 3D Object Pose Estimation (3DOPE) framework. The accuracy and precision of object spatial localization is evaluated on the benchmark Yale Carnegie Berkeley-Video Dataset. The Average Euclidean Distance metric is employed as a figure of merit for the quantitative data analysis. Moreover, the Average Rotational and Translational Distances among the estimated and the ground-truth poses are analyzed. Results gathered on the YCB- Video Dataset are validated on a newly collected 3DOPE dataset, the ISS Dataset. The latter is populated by harnessing a 3D scanner, an RGB-D camera, and an anthropomorphic robot. Outcomes highlight an Average Euclidean Distance value of 1.8 mm on the best-processed item in the YCB-Video Dataset. Similarly, an Average Euclidean Distance value of 1.9 mm is achieved on the ISS Dataset. Eventually, the measurement uncertainty of the six components of the 3D poses is inspected. The latter assessment is performed on the ISS Dataset by relying on the ISO GUM [1].",2020 IEEE International Workshop on Metrology for Industry 4.0 & IoT,2020
34588033080412b07d8a24eb56122cb48e2437af,https://www.semanticscholar.org/paper/34588033080412b07d8a24eb56122cb48e2437af,SymmetryNet: Learning to Predict Reflectional and Rotational Symmetries of 3D Shapes from Single-View RGB-D Images,"We study the problem of symmetry detection of 3D shapes from single-view RGB-D images, where severely missing data renders geometric detection approach infeasible. We propose an end-to-end deep neural network which is able to predict both reflectional and rotational symmetries of 3D objects present in the input RGB-D image. Directly training a deep model for symmetry prediction, however, can quickly run into the issue of overfitting. We adopt a multi-task learning approach. Aside from symmetry axis prediction, our network is also trained to predict symmetry correspondences. In particular, given the 3D points present in the RGB-D image, our network outputs for each 3D point its symmetric counterpart corresponding to a specific predicted symmetry. In addition, our network is able to detect for a given shape multiple symmetries of different types. We also contribute a benchmark of 3D symmetry detection based on single-view RGB-D images. Extensive evaluation on the benchmark demonstrates the strong generalization ability of our method, in terms of high accuracy of both symmetry axis prediction and counterpart estimation. In particular, our method is robust in handling unseen object instances with large variation in shape, multi-symmetry composition, as well as novel object categories.",ACM Trans. Graph.,2020
348f662a4f1c00e87a7ac6a3ac923c356a1a61d2,https://www.semanticscholar.org/paper/348f662a4f1c00e87a7ac6a3ac923c356a1a61d2,Manipulation-Oriented Object Perception in Clutter through Affordance Coordinate Frames,"In order to enable robust operation in unstructured environments, robots should be able to generalize manipulation actions to novel object instances. For example, to pour and serve a drink, a robot should be able to recognize novel containers which afford the task. Most importantly, robots should be able to manipulate these novel containers to fulfill the task. To achieve this, we aim to provide robust and generalized perception of object affordances and their associated manipulation poses for reliable manipulation. In this work, we combine the notions of affordance and category-level pose, and introduce the Affordance Coordinate Frame (ACF). With ACF, we represent each object class in terms of individual affordance parts and the compatibility between them, where each part is associated with a part category-level pose for robot manipulation. In our experiments, we demonstrate that ACF outperforms state-of-the-art methods for object detection, as well as category-level pose estimation for object parts. We further demonstrate the applicability of ACF to robot manipulation tasks through experiments in a simulated environment.",ArXiv,2020
36720b77dce012fd5ae734af0633067efc92c5f3,https://www.semanticscholar.org/paper/36720b77dce012fd5ae734af0633067efc92c5f3,DCNet: Dense Correspondence Neural Network for 6DoF Object Pose Estimation in Occluded Scenes,"6DoF object pose estimation is essential for many real-world applications. Although great progress has been made, challenges still remain in estimating 6D pose for occluded objects. Current RGB-D approaches predict 6DoF pose directly, which is sensitive to occlusion in cluttered scenes. In this work, we propose DCNet, an end-to-end framework for estimating 6DoF object poses. DCNet first converts pixels in the image plane to point clouds in the camera coordinate system and then establishes dense correspondences between the camera coordinate system and the object coordinate system. Based on these two systems, we fuse 2D appearance and 3D geometric features by pixel-wise concatenation to construct dense correspondences, from which the pose is calculated through the least-squares fitting algorithm. Dense correspondences guarantee enough point pairs for a robust 6DoF pose estimation, even if the occlusion is heavy. Experimental results demonstrate that DCNet outperforms the state-of-the-art methods on LINEMOD, Occlusion LINEMOD and YCB-Video datasets, especially in terms of the robustness to occlusion scenes.",ACM Multimedia,2020
3732bbe940c1d15c65280e5e30ffab3a0bf65933,https://www.semanticscholar.org/paper/3732bbe940c1d15c65280e5e30ffab3a0bf65933,Learning latent geometric consistency for 6D object pose estimation in heavily cluttered scenes,"Abstract 6D object pose (3D rotation and translation) estimation from RGB-D image is an important and challenging task in computer vision and has been widely applied in a variety of applications such as robotic manipulation, autonomous driving, augmented reality etc. Prior works extract global feature or reason about local appearance from an individual frame, which neglect the spatial geometric relevance between two frames, limiting their performance for occluded or truncated objects in heavily cluttered scenes. In this paper, we present a dual-stream network for estimating 6D pose of a set of known objects from RGB-D images. Our novelty stands in contrast to prior work that learns latent geometric consistency in pairwise dense feature representations from multiple observations of the same objects in a self-supervised manner. We show in experiments that our method outperforms state-of-the-art approaches on 6D object pose estimation in two challenging datasets, YCB-Video and LineMOD.",J. Vis. Commun. Image Represent.,2020
3868104a19947ca5e147b4bbf5f6cdab0691d5a3,https://www.semanticscholar.org/paper/3868104a19947ca5e147b4bbf5f6cdab0691d5a3,PrimA6D: Rotational Primitive Reconstruction for Enhanced and Robust 6D Pose Estimation,"In this letter, we introduce a rotational primitive prediction based 6D object pose estimation using a single image as an input. We solve for the 6D object pose of a known object relative to the camera using a single image with occlusion. Many recent state-of-the-art (SOTA) two-step approaches have exploited image keypoints extraction followed by PnP regression for pose estimation. Instead of relying on bounding box or keypoints on the object, we propose to learn orientation-induced primitive so as to achieve the pose estimation accuracy regardless of the object size. We leverage a Variational AutoEncoder (VAE) to learn this underlying primitive and its associated keypoints. The keypoints inferred from the reconstructed primitive image are then used to regress the rotation using PnP. Lastly, we compute the translation in a separate localization module to complete the entire 6D pose estimation. When evaluated over public datasets, the proposed method yields a notable improvement over the LINEMOD, the Occlusion LINEMOD, and the YCB-Video dataset. We further provide a synthetic-only trained case presenting comparable performance to the existing methods which require real images in the training phase.",IEEE Robotics and Automation Letters,2020
3868d2bea802d4b913abdb1da196d30dfd38377e,https://www.semanticscholar.org/paper/3868d2bea802d4b913abdb1da196d30dfd38377e,MobilePose: Real-Time Pose Estimation for Unseen Objects with Weak Shape Supervision,"In this paper, we address the problem of detecting unseen objects from RGB images and estimating their poses in 3D. We propose two mobile friendly networks: MobilePose-Base and MobilePose-Shape. The former is used when there is only pose supervision, and the latter is for the case when shape supervision is available, even a weak one. We revisit shape features used in previous methods, including segmentation and coordinate map. We explain when and why pixel-level shape supervision can improve pose estimation. Consequently, we add shape prediction as an intermediate layer in the MobilePose-Shape, and let the network learn pose from shape. Our models are trained on mixed real and synthetic data, with weak and noisy shape supervision. They are ultra lightweight that can run in real-time on modern mobile devices (e.g. 36 FPS on Galaxy S20). Comparing with previous single-shot solutions, our method has higher accuracy, while using a significantly smaller model (2~3% in model size or number of parameters).",ArXiv,2020
39ba32d233760cb891d0587f41454119f392b61a,https://www.semanticscholar.org/paper/39ba32d233760cb891d0587f41454119f392b61a,3D Object Classification on Partial Point Clouds: A Practical Perspective,"A point cloud is a popular shape representation adopted in 3D object classification, which covers the whole surface of an object and is usually well aligned. However, such an assumption can be invalid in practice, as point clouds collected in real-world scenarios are typically scanned from visible object parts observed under arbitrary SO(3) viewpoint, which are thus incomplete due to self and inter-object occlusion. In light of this, this paper introduces a practical setting to classify partial point clouds of object instances under any poses. Compared to the classification of complete object point clouds, such a problem is made more challenging in view of geometric similarities of local shape across object classes and intra-class dissimilarities of geometries restricted by their observation view. We consider that specifying the location of partial point clouds on their object surface is essential to alleviate suffering from the aforementioned challenges, which can be solved via an auxiliary task of 6D object pose estimation. To this end, a novel algorithm in an alignment-classification manner is proposed in this paper, which consists of an alignment module predicting object pose for the rigid transformation of visible point clouds to their canonical pose and a typical point classifier such as PointNet++ and DGCNN. Experiment results on the popular ModelNet40 and ScanNet datasets, which are adapted to a single-view partial setting, demonstrate the proposed method can outperform three alternative schemes extended from representative point cloud classifiers for complete point clouds.",ArXiv,2020
3d16db2f41e07e075dd9415e67d5b04aeca314f9,https://www.semanticscholar.org/paper/3d16db2f41e07e075dd9415e67d5b04aeca314f9,LIT: Light-Field Inference of Transparency for Refractive Object Localization,"Translucency is prevalent in everyday scenes. As such, perception of transparent objects is essential for robots to perform manipulation. Compared with texture-rich or texture-less Lambertian objects, transparency induces significant uncertainty on object appearances. Ambiguity can be due to changes in lighting, viewpoint, and backgrounds, each of which brings challenges to existing object pose estimation algorithms. In this work, we propose LIT, a two-stage method for transparent object pose estimation using light-field sensing and photorealistic rendering. LIT employs multiple filters specific to light-field imagery in deep networks to capture transparent material properties, with robust depth and pose estimators based on generative sampling. Along with the LIT algorithm, we introduce the light-field transparent object dataset ProLIT for the tasks of recognition, localization and pose estimation. With respect to this ProLIT dataset, we demonstrate that LIT can outperform both state-of-the-art end-to-end pose estimation methods and a generative pose estimator on transparent objects. The link of supplementary material can be found at: https://sites.google.com/umich.edu/prolit",IEEE Robotics and Automation Letters,2019
3d42bb4a8ee9a7db5bc136d48023bd33fb13df66,https://www.semanticscholar.org/paper/3d42bb4a8ee9a7db5bc136d48023bd33fb13df66,Survey on 6D Pose Estimation of Rigid Object,"Estimating 6D pose of rigid objects has gained increasing attention as it has become an curcial problem in rapidly growing technology related to robotics, augmented reality and autonomous driving. Therefore, the research on 6D pose estimation technology is of great significance. In this paper, firstly, current position of the field is summarized regarding object pose estimation. We found that deep learning combined with traditional methods can produce better results. Then, pose ambiguity which is an open problem needed further study is raised. Finally, the main problems of the current research and possible development directions are identified.",2020 39th Chinese Control Conference (CCC),2020
3d5b1473530f4ae8a4015841cc163dd6c19b014d,https://www.semanticscholar.org/paper/3d5b1473530f4ae8a4015841cc163dd6c19b014d,Out-of-region keypoint localization for 6D pose estimation,"Abstract This paper addresses the problem of instance level 6D pose estimation from a single RGB image. Our approach simultaneously detects objects and recovers poses by predicting the 2D image locations of the object's 3D bounding box vertices. Specifically, we focus on the challenge of locating virtual keypoints outside the object region proposals, and propose a boundary-based keypoint representation which incorporates classification and regression schemes to reduce output space. Moreover, our method predicts localization confidences and alleviates the influence of difficult keypoints by a voting process. We implement the proposed method based on 2D detection pipeline, meanwhile bridge the feature gap between detection and pose estimation. Our network has real-time processing capability, which runs 30 fps on a GTX 1080Ti GPU. For single object and multiple objects pose estimation on two benchmark datasets, our approach achieves competitive or superior performance compared with state-of-the-art RGB based pose estimation methods.",Image Vis. Comput.,2020
3f5ed09c470339c271c95b1ab522cf307df4e449,https://www.semanticscholar.org/paper/3f5ed09c470339c271c95b1ab522cf307df4e449,PointNet++ Grasping: Learning An End-to-end Spatial Grasp Generation Algorithm from Sparse Point Clouds,"Grasping for novel objects is important for robot manipulation in unstructured environments. Most of current works require a grasp sampling process to obtain grasp candidates, combined with local feature extractor using deep learning. This pipeline is time-costly, expecially when grasp points are sparse such as at the edge of a bowl.In this paper, we propose an end-to-end approach to directly predict the poses, categories and scores (qualities) of all the grasps. It takes the whole sparse point clouds as the input and requires no sampling or search process. Moreover, to generate training data of multi-object scene, we propose a fast multi-object grasp detection algorithm based on Ferrari Canny metrics. A single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) are generated. A PointNet++ based network combined with multi-mask loss is introduced to deal with different training points. The whole weight size of our network is only about 11.6M, which takes about 102ms for a whole prediction process using a GeForce 840M GPU. Our experiment shows our work get 71.43% success rate and 91.60% completion rate, which performs better than current state-of-art works.",2020 IEEE International Conference on Robotics and Automation (ICRA),2020
3f742582b4bf396d7df8688681e2b4a5d4177b1f,https://www.semanticscholar.org/paper/3f742582b4bf396d7df8688681e2b4a5d4177b1f,6D Object Pose Estimation by Visual Descriptor,"One essential component for object pose estimation is to extract the objects' features with suitable representation. For symmetrical objects and smooth objects that lack texture, the pose estimation results are not satisfactory because it is difficult to extract and represent these objects' feature information. This work introduces a new method to represent objects' features by constructing pixel-level visual descriptors and performing a 6D pose estimation based on the RGB-D image. Compared with traditional RGB images, RGB-D images can provide richer information, and image descriptors constructed based on RGB-D images can extract and represent object features more effectively. We also use a network to refine the pose estimation result instead of using ICP to improve refinement speed. The proposed architecture has made satisfactory improvement on the YCB-Video dataset, especially for symmetric objects and other categories that are difficult to regress in the past.",,2020
45fff05a2822d5bbb7c42dfe5c249e08b6c06313,https://www.semanticscholar.org/paper/45fff05a2822d5bbb7c42dfe5c249e08b6c06313,Part Recognition and Pose Estimation Based on Convolutional Neural Network,"Automated sorting of parts is the basis and premise of an automated production system. In order to accurately and quickly solve the problem of part type recognition and pose estimation, this paper proposes a method of part recognition and pose estimation based on convolutional neural network. By adapting and optimizing the application of the existing mature network model, the training can be used for the type recognition of mechanical parts and the posture estimation of the network model, which provides an accurate information foundation for industrial automation sorting and assembly. At the same time, a virtual data set generation method based on OSG is proposed. A large number of training data sets are generated in the virtual scene to ensure the accuracy of model training.","2020 2nd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)",2020
46994658d9095ac1af90e0710249226d1d8820e8,https://www.semanticscholar.org/paper/46994658d9095ac1af90e0710249226d1d8820e8,VeREFINE: Integrating Object Pose Verification With Physics-Guided Iterative Refinement,"Accurate and robust object pose estimation for robotics applications requires verification and refinement steps. In this work, we propose to integrate hypotheses verification with object pose refinement guided by physics simulation. This allows the physical plausibility of individual object pose estimates and the stability of the estimated scene to be considered in a unified optimization. The proposed method is able to adapt to scenes of multiple objects and efficiently focuses on refining the most promising object poses in multi-hypotheses scenarios. We call this integrated approach VeREFINE and evaluate it on three datasets with varying scene complexity. The generality of the approach is shown by using three state-of-the-art pose estimators and three baseline refiners. Results show improvements over all baselines and on all datasets. Furthermore, our approach is applied in real-world grasping experiments and outperforms competing methods in terms of grasp success rate. Code is publicly available at github.com/dornik/verefine.",IEEE Robotics and Automation Letters,2019
486b2f348251d61af0655fcec3a4b3abbf015ae2,https://www.semanticscholar.org/paper/486b2f348251d61af0655fcec3a4b3abbf015ae2,Deep instance segmentation and 6D object pose estimation in cluttered scenes for robotic autonomous grasping,"This paper aims to design a deep neural network for object instance segmentation and six-dimensional (6D) pose estimation in cluttered scenes and apply the proposed method in real-world robotic autonomous grasping of household objects.,A novel deep learning method is proposed for instance segmentation and 6D pose estimation in cluttered scenes. An iterative pose refinement network is integrated with the main network to obtain more robust final pose estimation results for robotic applications. To train the network, a technique is presented to generate abundant annotated synthetic data consisting of RGB-D images and object masks in a fast manner without any hand-labeling. For robotic grasping, the offline grasp planning based on eigengrasp planner is performed and combined with the online object pose estimation.,The experiments on the standard pose benchmarking data sets showed that the method achieves better pose estimation and time efficiency performance than state-of-art methods with depth-based ICP refinement. The proposed method is also evaluated on a seven DOFs Kinova Jaco robot with an Intel Realsense RGB-D camera, the grasping results illustrated that the method is accurate and robust enough for real-world robotic applications.,A novel 6D pose estimation network based on the instance segmentation framework is proposed and a neural work-based iterative pose refinement module is integrated into the method. The proposed method exhibits satisfactory pose estimation and time efficiency for the robotic grasping.",Ind. Robot,2020
486c76e7d8a4bcf3dce64bbc42551a0c73120fc9,https://www.semanticscholar.org/paper/486c76e7d8a4bcf3dce64bbc42551a0c73120fc9,CosyPose: Consistent multi-view multi-object 6D pose estimation,"We introduce an approach for recovering the 6D pose of multiple known objects in a scene captured by a set of input images with unknown camera viewpoints. First, we present a single-view single-object 6D pose estimation method, which we use to generate 6D object pose hypotheses. Second, we develop a robust method for matching individual 6D object pose hypotheses across different input images in order to jointly estimate camera viewpoints and 6D poses of all objects in a single consistent scene. Our approach explicitly handles object symmetries, does not require depth measurements, is robust to missing or incorrect object hypotheses, and automatically recovers the number of objects in the scene. Third, we develop a method for global scene refinement given multiple object hypotheses and their correspondences across views. This is achieved by solving an object-level bundle adjustment problem that refines the poses of cameras and objects to minimize the reprojection error in all views. We demonstrate that the proposed method, dubbed CosyPose, outperforms current state-of-the-art results for single-view and multi-view 6D object pose estimation by a large margin on two challenging benchmarks: the YCB-Video and T-LESS datasets. Code and pre-trained models are available on the project webpage https://www.di.ens.fr/willow/research/cosypose/.",ECCV,2020
48d571402eb5aa67dc989b400f813462a97f8d88,https://www.semanticscholar.org/paper/48d571402eb5aa67dc989b400f813462a97f8d88,"Flange-Based Hand-Eye Calibration Using a 3D Camera With High Resolution, Accuracy, and Frame Rate","Point cloud data provides three-dimensional (3D) measurement of the geometric details in the physical world, which relies heavily on the quality of the machine vision system. In this paper, we explore the potentials of a 3D scanner of high quality (15 million points per second), accuracy (up to 0.150 mm), and frame rate (up to 20 FPS) during static and dynamic measurements of the robot flange for direct hand-eye calibration and trajectory error tracking. With the availability of high-quality point cloud data, we can exploit the standardized geometric features on the robot flange for 3D measurement, which are directly accessible for hand-eye calibration problems. In the meanwhile, we tested the proposed flange-based calibration methods in a dynamic setting to capture point cloud data in a high frame rate. We found that our proposed method works robustly even in dynamic environments, enabling a versatile hand-eye calibration during motion. Furthermore, capturing high-quality point cloud data in real-time opens new doors for the use of 3D scanners, capable of detecting sensitive anomalies of refined details even in motion trajectories. Codes and sample data of this calibration method is provided at Github (https://github.com/ancorasir/flange_handeye_calibration).",Frontiers in Robotics and AI,2020
48d5edd8d705f5c51f01a1d958de375cca8b06f5,https://www.semanticscholar.org/paper/48d5edd8d705f5c51f01a1d958de375cca8b06f5,Memory Based Attentive Fusion,"The use of multi-modal data for deep machine learning has shown promise when compared to uni-modal approaches, where fusion of multi-modal features has resulted in improved performance. However, most state-of-the-art methods use naive fusion which processes feature streams from a given time-step and ignores long-term dependencies within the data during fusion. In this paper, we present a novel Memory Based Attentive Fusion (MBAF) layer, which fuses modes by incorporating both the current features and long-term dependencies in the data, thus allowing the model to understand the relative importance of modes over time. We define an explicit memory block within the fusion layer which stores features containing long-term dependencies of the fused data. The inputs to our layer are fused through attentive composition and transformation, and the transformed features are combined with the input to generate the fused layer output. Following existing state-of-the-art methods, we have evaluated the performance and the generalizability of the proposed approach on the IEMOCAP and PhysioNet-CMEBS datasets with different modalities. In our experiments, we replace the naive fusion layer in benchmark networks with our proposed layer to enable a fair comparison. Experimental results indicate that MBAF layer can generalise across different modalities and networks to enhance the fusion and improve performance.",ArXiv,2020
4902b147c0ebefa592ef84f832a5c56d16468f6c,https://www.semanticscholar.org/paper/4902b147c0ebefa592ef84f832a5c56d16468f6c,Neural Object Learning for 6D Pose Estimation Using a Few Cluttered Images,"Recent methods for 6D pose estimation of objects assume either textured 3D models or real images that cover the entire range of target poses. However, it is difficult to obtain textured 3D models and annotate the poses of objects in real scenarios. This paper proposes a method, Neural Object Learning (NOL), that creates synthetic images of objects in arbitrary poses by combining only a few observations from cluttered images. A novel refinement step is proposed to align inaccurate poses of objects in source images, which results in better quality images. Evaluations performed on two public datasets show that the rendered images created by NOL lead to state-of-the-art performance in comparison to methods that use 13 times the number of real images. Evaluations on our new dataset show multiple objects can be trained and recognized simultaneously using a sequence of a fixed scene.",ECCV,2020
4992351369d85eea3c18f679b6dd8d40353cccd8,https://www.semanticscholar.org/paper/4992351369d85eea3c18f679b6dd8d40353cccd8,VST3D-Net:Video-Based Spatio-Temporal Network for 3D Shape Reconstruction from a Video,"In this paper, we propose the Video-based Spatio-Temporal 3D Network (VST3D-Net), which is a novel learning approach of viewpoint-invariant 3D shape reconstruction from monocular video. In our VST3D-Net, a spatial feature extraction subnetwork is designed to encode the local and global spatial relationships of the object in the image. The extracted latent spatial features have implicitly embedded both shape and pose information. Although a single view can also be used to recover a 3D shape, more rich shape information of the dynamic object can be explored and leveraged from video frames. To generate the viewpoint-free 3D shape, we design a temporal correlation feature extractor. It handles the temporal consistency of the shape and pose of the moving object simultaneously. Therefore, both the canonical 3D shape and the corresponding pose at different frame are recovered by the network. We validate our approach on the ShapeNet-based video dataset and ApolloCar3D dataset. The experimental results show the proposed VST3D-Net can outperform the state-of-the-art approaches both in accuracy and efficiency.",2020 International Conference on 3D Immersion (IC3D),2020
4b58306dcec16c19964e5733bb3f4ed92b348d7a,https://www.semanticscholar.org/paper/4b58306dcec16c19964e5733bb3f4ed92b348d7a,Bridging the Performance Gap Between Pose Estimation Networks Trained on Real And Synthetic Data Using Domain Randomization,"Since the introduction of deep learning methods, pose estimation performance has increased drastically. Usually, large amounts of manually annotated training data are required for these networks to perform. While training on synthetic data can avoid the manual annotation, this introduces another obstacle. There is currently a large performance gap between methods trained on real and synthetic data. This paper introduces a new method, which bridges the gap between real and synthetically trained networks. As opposed to other methods, the network utilizes 3D point clouds. This allows both for domain randomization in 3D and to use neighboring geometric information during inference. Experiments on three large pose estimation benchmarks show that the presented method outperforms previous methods trained on synthetic data and achieves comparable-and sometimes superior-results to existing methods trained on real data.",ArXiv,2020
4b7ee88703d221ce9cc074747e5bc256cf4a72ce,https://www.semanticscholar.org/paper/4b7ee88703d221ce9cc074747e5bc256cf4a72ce,6D Object Pose Regression via Supervised Learning on Point Clouds,"This paper addresses the task of estimating the 6 degrees of freedom pose of a known 3D object from depth information represented by a point cloud. Deep features learned by convolutional neural networks from color information have been the dominant features to be used for inferring object poses, while depth information receives much less attention. However, depth information contains rich geometric information of the object shape, which is important for inferring the object pose. We use depth information represented by point clouds as the input to both deep networks and geometry-based pose refinement and use separate networks for rotation and translation regression. We argue that the axis-angle representation is a suitable rotation representation for deep learning, and use a geodesic loss function for rotation regression. Ablation studies show that these design choices outperform alternatives such as the quaternion representation and L2 loss, or regressing translation and rotation with the same network. Our simple yet effective approach clearly outperforms state-of-the-art methods on the YCB-video dataset.",2020 IEEE International Conference on Robotics and Automation (ICRA),2020
4dee1d180e2e400c7c02f02b7dfbe9688fed6047,https://www.semanticscholar.org/paper/4dee1d180e2e400c7c02f02b7dfbe9688fed6047,A Manufacturing-Oriented Intelligent Vision System Based on Deep Neural Network for Object Recognition and 6D Pose Estimation,"Nowadays, intelligent robots are widely applied in the manufacturing industry, in various working places or assembly lines. In most manufacturing tasks, determining the category and pose of parts is important, yet challenging, due to complex environments. This paper presents a new two-stage intelligent vision system based on a deep neural network with RGB-D image inputs for object recognition and 6D pose estimation. A dense-connected network fusing multi-scale features is first built to segment the objects from the background. The 2D pixels and 3D points in cropped object regions are then fed into a pose estimation network to make object pose predictions based on fusion of color and geometry features. By introducing the channel and position attention modules, the pose estimation network presents an effective feature extraction method, by stressing important features whilst suppressing unnecessary ones. Comparative experiments with several state-of-the-art networks conducted on two well-known benchmark datasets, YCB-Video and LineMOD, verified the effectiveness and superior performance of the proposed method. Moreover, we built a vision-guided robotic grasping system based on the proposed method using a Kinova Jaco2 manipulator with an RGB-D camera installed. Grasping experiments proved that the robot system can effectively implement common operations such as picking up and moving objects, thereby demonstrating its potential to be applied in all kinds of real-time manufacturing applications.",Frontiers in Neurorobotics,2021
511d2fb9a57ba5022b7ee9e1ea56adb4b9b23cbe,https://www.semanticscholar.org/paper/511d2fb9a57ba5022b7ee9e1ea56adb4b9b23cbe,"Reconstruct, Rasterize and Backprop: Dense shape and pose estimation from a single image","This paper presents a new system to obtain dense object reconstructions along with 6-DoF poses from a single image. Geared towards high fidelity reconstruction, several recent approaches leverage implicit surface representations and deep neural networks to estimate a 3D mesh of an object, given a single image. However, all such approaches recover only the shape of an object; the reconstruction is often in a canonical frame, unsuitable for downstream robotics tasks. To this end, we leverage recent advances in differentiable rendering (in particular, rasterization) to close the loop with 3D reconstruction in camera frame.We demonstrate that our approach—dubbed reconstruct, rasterize and backprop (RRB)—achieves significantly lower pose estimation errors compared to prior art, and is able to recover dense object shapes and poses from imagery. We further extend our results to an (offline) setup, where we demonstrate a dense monocular object-centric egomotion estimation system.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2020
5887c12275bd463145adf9dafe149da81d046182,https://www.semanticscholar.org/paper/5887c12275bd463145adf9dafe149da81d046182,Learning Canonical Shape Space for Category-Level 6D Object Pose and Size Estimation,"We present a novel approach to category-level 6D object pose and size estimation. To tackle intra-class shape variations, we learn canonical shape space (CASS), a unified representation for a large variety of instances of a certain object category. In particular, CASS is modeled as the latent space of a deep generative model of canonical 3D shapes with normalized pose. We train a variational auto-encoder (VAE) for generating 3D point clouds in the canonical space from an RGBD image. The VAE is trained in a cross-category fashion, exploiting the publicly available large 3D shape repositories. Since the 3D point cloud is generated in normalized pose (with actual size), the encoder of the VAE learns view-factorized RGBD embedding. It maps an RGBD image in arbitrary view into a poseindependent 3D shape representation. Object pose is then estimated via contrasting it with a pose-dependent feature of the input RGBD extracted with a separate deep neural networks. We integrate the learning of CASS and pose and size estimation into an end-to-end trainable network, achieving the state-of-the-art performance.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
588a3bc49b0c89cf33c80bbeb5d6bd0d2f6a527f,https://www.semanticscholar.org/paper/588a3bc49b0c89cf33c80bbeb5d6bd0d2f6a527f,GeoFusion: Geometric Consistency informed Scene Estimation in Dense Clutter.,"We propose GeoFusion, a SLAM-based scene estimation method for building an object-level semantic map in dense clutter. In dense clutter, objects are often in close contact and severe occlusions, which brings more false detections and noisy pose estimates from existing perception methods. To solve these problems, our key insight is to consider geometric consistency at the object level within a general SLAM framework. The geometric consistency is defined in two parts: geometric consistency score and geometric relation. The geometric consistency score describes the compatibility between object geometry model and observation point cloud. Meanwhile, it provides a reliable measure to filter out false positives in data association. The geometric relation represents the relationship (e.g. contact) between geometric features (e.g. planes) among objects. The geometric relation makes the graph optimization for poses more robust and accurate. GeoFusion can robustly and efficiently infer the object labels, 6D object poses, and spatial relations from continuous noisy semantic measurements. We quantitatively evaluate our method using observations from a Fetch mobile manipulation robot. Our results demonstrate greater robustness against false estimates than frame-by-frame pose estimation from the state-of-the-art convolutional neural network.",,2020
58a261696a2a31e616dab16847031cc22449c4da,https://www.semanticscholar.org/paper/58a261696a2a31e616dab16847031cc22449c4da,"Reconstruct Locally, Localize Globally: A Model Free Method for Object Pose Estimation","Six degree-of-freedom pose estimation of a known object in a single image is a long-standing computer vision objective. It is classically posed as a correspondence problem between a known geometric model, such as a CAD model, and image locations. If a CAD model is not available, it is possible to use multi-view visual reconstruction methods to create a geometric model, and use this in the same manner. Instead, we propose a learning-based method whose input is a collection of images of a target object, and whose output is the pose of the object in a novel view. At inference time, our method maps from the RoI features of the input image to a dense collection of object-centric 3D coordinates, one per pixel. This dense 2D-3D mapping is then used to determine 6dof pose using standard PnP plus RANSAC. The model that maps 2D to object 3D coordinates is established at training time by automatically discovering and matching image landmarks that are consistent across multiple views. We show that this method eliminates the requirement for a 3D CAD model (needed by classical geometry-based methods and state-of-the-art learning-based methods alike) but still achieves performance on a par with the prior art.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
5c4bd909ab34860540125b1ee708433b962af933,https://www.semanticscholar.org/paper/5c4bd909ab34860540125b1ee708433b962af933,Cloud-Edge Hybrid Robotic Systems for Physical Human Robot Interactions,Cloud-Edge Hybrid Robotic Systems for Physical Human Robot Interactions,,2020
5da610515325a2940481bffad14db9e2784ada5e,https://www.semanticscholar.org/paper/5da610515325a2940481bffad14db9e2784ada5e,On the Capability of Neural Networks to Generalize to Unseen Category-Pose Combinations,"Recognizing an object's category and pose lies at the heart of visual understanding. Recent works suggest that deep neural networks (DNNs) often fail to generalize to category-pose combinations not seen during training. However, it is unclear when and how such generalization may be possible. Does the number of combinations seen during training impact generalization? Is it better to learn category and pose in separate networks, or in a single shared network? Furthermore, what are the neural mechanisms that drive the network's generalization? In this paper, we answer these questions by analyzing state-of-the-art DNNs trained to recognize both object category and pose (position, scale, and 3D viewpoint) with quantitative control over the number of category-pose combinations seen during training. We also investigate the emergence of two types of specialized neurons that can explain generalization to unseen combinations---neurons selective to category and invariant to pose, and vice versa. We perform experiments on MNIST extended with position or scale, the iLab dataset with vehicles at different viewpoints, and a challenging new dataset for car model recognition and viewpoint estimation that we introduce in this paper, the Biased-Cars dataset. Our results demonstrate that as the number of combinations seen during training increases, networks generalize better to unseen category-pose combinations, facilitated by an increase in the selectivity and invariance of individual neurons. We find that learning category and pose in separate networks compared to a shared one leads to an increase in such selectivity and invariance, as separate networks are not forced to preserve information about both category and pose. This enables separate networks to significantly outperform shared ones at predicting unseen category-pose combinations.",ArXiv,2020
5e9bc8f7dc58e9c0fcbd38607c8430ef1497cba9,https://www.semanticscholar.org/paper/5e9bc8f7dc58e9c0fcbd38607c8430ef1497cba9,"Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review","This paper presents a comprehensive survey on vision-based robotic grasping. We conclude three key tasks during vision-based robotic grasping, which are object localization, object pose estimation and grasp estimation. In detail, the object localization task contains object localization without classification, object detection and object instance segmentation. This task provides the regions of the target object in the input data. The object pose estimation task mainly refers to estimating the 6D object pose and includes correspondence-based methods, template-based methods and voting-based methods, which affords the generation of grasp poses for known objects. The grasp estimation task includes 2D planar grasp methods and 6DoF grasp methods, where the former is constrained to grasp from one direction. These three tasks could accomplish the robotic grasping with different combinations. Lots of object pose estimation methods need not object localization, and they conduct object localization and object pose estimation jointly. Lots of grasp estimation methods need not object localization and object pose estimation, and they conduct grasp estimation in an end-to-end manner. Both traditional methods and latest deep learning-based methods based on the RGB-D image inputs are reviewed elaborately in this survey. Related datasets and comparisons between state-of-the-art methods are summarized as well. In addition, challenges about vision-based robotic grasping and future directions in addressing these challenges are also pointed out.",Artificial Intelligence Review,2020
5fa528031067766ed8f7a33f408d9eb3ec78102c,https://www.semanticscholar.org/paper/5fa528031067766ed8f7a33f408d9eb3ec78102c,Cascade Graph Neural Networks for RGB-D Salient Object Detection,"In this paper, we study the problem of salient object detection (SOD) for RGB-D images using both color and depth information.A major technical challenge in performing salient object detection fromRGB-D images is how to fully leverage the two complementary data sources. Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D saliency this http URL this work, we introduceCascade Graph Neural Networks(Cas-Gnn),a unified framework which is capable of comprehensively distilling and reasoning the mutual benefits between these two data sources through a set of cascade graphs, to learn powerful representations for RGB-D salient object detection. Cas-Gnn processes the two data sources individually and employs a novelCascade Graph Reasoning(CGR) module to learn powerful dense feature embeddings, from which the saliency map can be easily inferred. Contrast to the previous approaches, the explicitly modeling and reasoning of high-level relations between complementary data sources allows us to better overcome challenges such as occlusions and ambiguities. Extensive experiments demonstrate that Cas-Gnn achieves significantly better performance than all existing RGB-DSOD approaches on several widely-used benchmarks.",ECCV,2020
5fee84991bba4422c88ab0b2c7cba31e3d67220d,https://www.semanticscholar.org/paper/5fee84991bba4422c88ab0b2c7cba31e3d67220d,Adaptive and Azimuth-Aware Fusion Network of Multimodal Local Features for 3D Object Detection,"This paper focuses on the construction of stronger local features and the effective fusion of image and LiDAR data. We adopt different modalities of LiDAR data to generate richer features and present an adaptive and azimuth-aware network to aggregate local features from image, bird's eye view maps and point cloud. Our network mainly consists of three subnetworks: ground plane estimation network, region proposal network and adaptive fusion network. The ground plane estimation network extracts features of point cloud and predicts the parameters of a plane which are used for generating abundant 3D anchors. The region proposal network generates features of image and bird's eye view maps to output region proposals. To integrate heterogeneous image and point cloud features, the adaptive fusion network explicitly adjusts the intensity of multiple local features and achieves the orientation consistency between image and LiDAR data by introduce an azimuth-aware fusion module. Experiments are conducted on KITTI dataset and the results validate the advantages of our aggregation of multimodal local features and the adaptive fusion network.",Neurocomputing,2019
60e02426feb3ca9345659f54deaf5070110f530a,https://www.semanticscholar.org/paper/60e02426feb3ca9345659f54deaf5070110f530a,Predictively Encoded Graph Convolutional Network for Noise-Robust Skeleton-based Action Recognition,"In skeleton-based action recognition, graph convolutional networks (GCNs), which model human body skeletons using graphical components such as nodes and connections, have achieved remarkable performance recently. However, current state-of-the-art methods for skeleton-based action recognition usually work on the assumption that the completely observed skeletons will be provided. This may be problematic to apply this assumption in real scenarios since there is always a possibility that captured skeletons are incomplete or noisy. In this work, we propose a skeleton-based action recognition method which is robust to noise information of given skeleton features. The key insight of our approach is to train a model by maximizing the mutual information between normal and noisy skeletons using a predictive coding manner. We have conducted comprehensive experiments about skeleton-based action recognition with defected skeletons using NTU-RGB+D and Kinetics-Skeleton datasets. The experimental results demonstrate that our approach achieves outstanding performance when skeleton samples are noised compared with existing state-of-the-art methods.",ArXiv,2020
638aae7deafa5b73a9d03bfa12f1751cf2d347c3,https://www.semanticscholar.org/paper/638aae7deafa5b73a9d03bfa12f1751cf2d347c3,Cutting Pose Prediction from Point Clouds,"The challenge of getting machines to understand and interact with natural objects is encountered in important areas such as medicine, agriculture, and, in our case, slaughterhouse automation. Recent breakthroughs have enabled the application of Deep Neural Networks (DNN) directly to point clouds, an efficient and natural representation of 3D objects. The potential of these methods has mostly been demonstrated for classification and segmentation tasks involving rigid man-made objects. We present a method, based on the successful PointNet architecture, for learning to regress correct tool placement from human demonstrations, using virtual reality. Our method is applied to a challenging slaughterhouse cutting task, which requires an understanding of the local geometry including the shape, size, and orientation. We propose an intermediate five-Degree of Freedom (DoF) cutting plane representation, a point and a normal vector, which eases the demonstration and learning process. A live experiment is conducted in order to unveil issues and begin to understand the required accuracy. Eleven cuts are rated by an expert, with 8/11 being rated as acceptable. The error on the test set is subsequently reduced through the addition of more training data and improvements to the DNN. The result is a reduction in the average translation from 1.5 cm to 0.8 cm and the orientation error from 4.59° to 4.48°. The method’s generalization capacity is assessed on a similar task from the slaughterhouse and on the very different public LINEMOD dataset for object pose estimation across view points. In both cases, the method shows promising results. Code, datasets, and other materials are available in Supplementary Materials.",Sensors,2020
63f3391dea0416b9e23acc96dcd3ac02ba3f84a3,https://www.semanticscholar.org/paper/63f3391dea0416b9e23acc96dcd3ac02ba3f84a3,Grasping pose estimation for SCARA robot based on deep learning of point cloud,"With the development of 3D measurement technology, 3D vision sensors and object pose estimation methods have been developed for robotic loading and unloading. In this work, an end-to-end deep learning method on point clouds, PointNetRGPE, is proposed to estimating the grasping pose of SCARA robot. In PointNetRGPE model, the point cloud and class number are fused into a point-class vector, and several PointNet-like networks are used to estimate the robot grasping pose, containing 3D translation and 1D rotation. Considering that rotational symmetry is very common in man-made and industrial environments, a novel architecture is introduced into PointNetRGPE to solve the pose estimation problem with rotational symmetry in the z -axis direction. Additionally, an experimental platform is built containing an industrial robot and a binocular stereo vision system, and a dataset with three subsets is set up. Finally, the PointNetRGPE is tested on the dataset, and the success rates of three subsets are 98.89%, 98.89%, and 94.44% respectively.",,2020
674dd1fa7c67df6b5c68f3b5910790b980ebf413,https://www.semanticscholar.org/paper/674dd1fa7c67df6b5c68f3b5910790b980ebf413,Top-1 CORSMAL Challenge 2020 Submission: Filling Mass Estimation Using Multi-modal Observations of Human-robot Handovers,"Human-robot object handover is a key skill for the future of human-robot collaboration. CORSMAL 2020 Challenge focuses on the perception part of this problem: the robot needs to estimate the filling mass of a container held by a human. Although there are powerful methods in image processing and audio processing individually, answering such a problem requires processing data from multiple sensors together. The appearance of the container, the sound of the filling, and the depth data provide essential information. We propose a multi-modal method to predict three key indicators of the filling mass: filling type, filling level, and container capacity. These indicators are then combined to estimate the filling mass of a container. Our method obtained Top-1 overall performance among all submissions to CORSMAL 2020 Challenge on both public and private subsets while showing no evidence of overfitting. Our source code is publicly available: https://github.com/v-iashin/CORSMAL",ICPR Workshops,2020
688117eabd3d7c573497a995e008915820d48b59,https://www.semanticscholar.org/paper/688117eabd3d7c573497a995e008915820d48b59,A Novel Pose Proposal Network and Refinement Pipeline for Better Object Pose Estimation,"In this paper, we present a novel deep learning pipeline for 6D object pose estimation and refinement from RGB inputs. The first component of the pipeline leverages a region proposal framework to estimate multi-class single-shot 6D object poses directly from an RGB image and through a CNN-based encoder multi-decoders network. The second component, a multi-attentional pose refinement network (MARN), iteratively refines the estimated pose. MARN takes advantage of both visual and flow features to learn a relative transformation between an initially predicted pose and a target pose. MARN is further augmented by a spatial multi-attention block that emphasizes objects' discriminative feature parts. Experiments on three benchmarks for 6D pose estimation show that the proposed pipeline outperforms state-of-the-art RGB-based methods with competitive runtime performance.",ArXiv,2020
6b7b8f57007119f723ddee754b801448a0322bb0,https://www.semanticscholar.org/paper/6b7b8f57007119f723ddee754b801448a0322bb0,Fast and High-Quality GPU-based Deliberative Perception for Object Pose Estimation,"Pose estimation of known objects is fundamental to tasks such as robotic grasping and manipulation. The need for reliable grasping imposes stringent accuracy requirements on pose estimation in cluttered, occluded scenes in dynamic environments. Modern methods employ large sets of training data to learn features and object templates in order to find correspondence between models and observed data. However these methods require extensive annotation of ground truth poses. An alternative is to use algorithms that search for the best explanation of the observed scene in a space of possible rendered scenes. A recently developed algorithm, PERCH (PErception Via SeaRCH) does so by using depth data to converge to a globally optimal solution using a search over a specially constructed tree. While PERCH offers strong guarantees on accuracy, the current formulation suffers from low scalability owing to its high runtime. In addition, the sole reliance on depth data for pose estimation restricts the algorithm to scenes where no two objects have the same shape. In this work, we propose PERCH 2.0, a deliberative pose estimation approach that takes advantage of GPU acceleration and RGB data. We show that our approach can achieve an order of magnitude speedup over PERCH and meets scalability requirements for evaluating thousands of poses in parallel. We demonstrate that the proposed work directly allows for an extension of deliberative pose estimation methods to new domains such as object articulation, conveyor picking and 6-Dof pose estimation. Our combined deliberative and discriminative framework for 6-DoF pose estimation achieves a higher accuracy than purely data-driven approaches without the need for any ground truth pose annotation.",,2020
6bf1bd1cd1d6b8b9234f8942bb094d575642ddd5,https://www.semanticscholar.org/paper/6bf1bd1cd1d6b8b9234f8942bb094d575642ddd5,Accurate 6D Object Pose Estimation by Pose Conditioned Mesh Reconstruction,"Current 6D object pose estimation methods consist of Deep Convo-lutional Neural Networks fully optimized for a single object but with its architecture standardized among objects with different shapes. In contrast to previous works, we explicitly exploit each object’s distinct topological information with an automated process and prior to any post-processing refinement stage. In order to achieve this, we propose a learning framework in which a Graph Convolutional Neural Network reconstructs a Pose Conditioned 3D mesh of the object. A robust estimation of the allocentric orientation of the target object is recovered by computing, in a differentiable manner, the Procrustes’ alignment between the canonical and reconstructed dense 3D meshes. Our method is capable of self validating its pose estimation by measuring the quality of the reconstructed mesh, which is invaluable in real life applications. In our experiments on the LINEMOD, OCCLUSION and YCB-Video benchmarks, the proposed method outperforms state-of-the-arts.","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2019
6cb72ede4878bbc94cb30146e1ba53da911ea75c,https://www.semanticscholar.org/paper/6cb72ede4878bbc94cb30146e1ba53da911ea75c,PP-Net: simultaneous pose and shape reconstruction from a single depth map,"Complete 3D information of the object is required in many fields. However, single-view observation always leads to the loss of 3D information. We introduce a learning based approach to simultaneously estimate the pose and shape of a given object from a single depth map.To address the problem, a depth map is firstly converted to be the corresponding partial point cloud, then an autoencoder-based network is proposed to learn this pose estimation as well as shape completion process. In the learning paradigm ,we utilize a novel pose representation, structured point list (SPL) to describe objects pose, which enables the network to understand the pose of the input object relative to the perspective. Compared with directly shape reconstruction, we find that adding SPL estimation as an intermediate supervision can both improve the accuracy of reconstruction and accelerate the convergence speed for training. Our method achieved SOTA results on both rigid and non-rigid objects reconstructions.",SPIE/COS Photonics Asia,2020
6fb6bd77dbd983c11e8bcc7dbea3c9b5254ea6c5,https://www.semanticscholar.org/paper/6fb6bd77dbd983c11e8bcc7dbea3c9b5254ea6c5,EP-Net: More Efficient Pose Estimation Network with the Classification-based Key-points Detection,"The performance of the 6D object pose algorithm is mainly constrained by difficult challenges such as texture, occlusion, symmetry, etc. However, recent works are more about superior single-target performance, but inefficient and less accurate for multi-object tasks. In this article, several previous work are referred to improve the efficiency of the algorithm to better serve complex scenarios, We use a two-stage pipeline to obtain the high-precision pose of the multi-object, in which the first stage is the key point detection, and the second stage solves PnP to obtain the 6DoF pose. We propose a simpler and more efficient classification-based key point detection algorithm for key points on the object surface. Experiments show that the proposed method outperforms the SOTA methods and robust on the LINEMOD, Occlusion-LINEMOD, and YCB-Video datasets. Especially, we outperform the SOTA methods on the challenging Occluded-LINEMOD dataset by a large margin. Our approach is more robust to occlusion and more efficient to multi-object pose estimation task. The code will be available at: https://github.com/CvHadesSun/E2P.",,2020
6fedd42554d7933c392bfbef3840a70af6930db6,https://www.semanticscholar.org/paper/6fedd42554d7933c392bfbef3840a70af6930db6,Benchmark for Human-to-Robot Handovers of Unseen Containers With Unknown Filling,"The real-time estimation through vision of the physical properties of objects manipulated by humans is important to inform the control of robots for performing accurate and safe grasps of objects handed over by humans. However, estimating the 3D pose and dimensions of previously unseen objects using only RGB cameras is challenging due to illumination variations, reflective surfaces, transparencies, and occlusions caused both by the human and the robot. In this letter, we present a benchmark for dynamic human-to-robot handovers that do not rely on a motion capture system, markers, or prior knowledge of specific objects. To facilitate comparisons, the benchmark focuses on cups with different levels of transparencies and with an unknown amount of an unknown filling. The performance scores assess the overall system as well as its components in order to help isolate modules of the pipeline that need improvements. In addition to the task description and the performance scores, we also present and distribute as open source a baseline implementation for the overall pipeline to enable comparisons and facilitate progress.",IEEE Robotics and Automation Letters,2020
7261cec38a980f33794b2c753408f737c127f908,https://www.semanticscholar.org/paper/7261cec38a980f33794b2c753408f737c127f908,Deep Gated Multi-modal Learning: In-hand Object Pose Changes Estimation using Tactile and Image Data,"For in-hand manipulation, estimation of the object pose inside the hand is one of the important functions to manipulate objects to the target pose. Since in-hand manipulation tends to cause occlusions by the hand or the object itself, image information only is not sufficient for in-hand object pose estimation. Multiple modalities can be used in this case, the advantage is that other modalities can compensate for occlusion, noise, and sensor malfunctions. Even though deciding the utilization rate of a modality (referred to as reliability value) corresponding to the situations is important, the manual design of such models is difficult, especially for various situations. In this paper, we propose deep gated multi-modal learning, which self-determines the reliability value of each modality through end-to-end deep learning. For the experiments, an RGB camera and a GelSight tactile sensor were attached to the parallel gripper of the Sawyer robot, and the object pose changes were estimated during grasping. A total of 15 objects were used in the experiments. In the proposed model, the reliability values of the modalities were determined according to the noise level and failure of each modality, and it was confirmed that the pose change was estimated even for unknown objects. 1",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019
7401983c65519cbff3ba5699337355fc91e78823,https://www.semanticscholar.org/paper/7401983c65519cbff3ba5699337355fc91e78823,Parts-Based Articulated Object Localization in Clutter Using Belief Propagation,"Robots working in human environments must be able to perceive and act on challenging objects with articulations, such as a pile of tools. Articulated objects increase the dimensionality of the pose estimation problem, and partial observations under clutter create additional challenges. To address this problem, we present a generative-discriminative parts-based recognition and localization method for articulated objects in clutter. We formulate the problem of articulated object pose estimation as a Markov Random Field (MRF). Hidden nodes in this MRF express the pose of the object parts, and edges express the articulation constraints between parts. Localization is performed within the MRF using an efficient belief propagation method. The method is informed by both part segmentation heatmaps over the observation, generated by a neural network, and the articulation constraints between object parts. Our generative-discriminative approach allows the proposed method to function in cluttered environments by inferring the pose of occluded parts using hypotheses from the visible parts. We demonstrate the efficacy of our methods in a tabletop environment for recognizing and localizing hand tools in uncluttered and cluttered configurations.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
777d44351cf9fd94e6d26a3433d8bfb2cddd3e1f,https://www.semanticscholar.org/paper/777d44351cf9fd94e6d26a3433d8bfb2cddd3e1f,Self-supervised 6D Object Pose Estimation for Robot Manipulation,"To teach robots skills, it is crucial to obtain data with supervision. Since annotating real world data is timeconsuming and expensive, enabling robots to learn in a self- supervised way is important. In this work, we introduce a robot system for self-supervised 6D object pose estimation. Starting from modules trained in simulation, our system is able to label real world images with accurate 6D object poses for self-supervised learning. In addition, the robot interacts with objects in the environment to change the object configuration by grasping or pushing objects. In this way, our system is able to continuously collect data and improve its pose estimation modules. We show that the self-supervised learning improves object segmentation and 6D pose estimation performance, and consequently enables the system to grasp objects more reliably. A video showing the experiments can be found at https://youtu.be/W1Y0Mmh1Gd8.",2020 IEEE International Conference on Robotics and Automation (ICRA),2019
79f9b67c887fc3823416ef818bbc63ae0fb1d1bf,https://www.semanticscholar.org/paper/79f9b67c887fc3823416ef818bbc63ae0fb1d1bf,3D Point-to-Keypoint Voting Network for 6D Pose Estimation,"Object 6D pose estimation is an important research topic in the field of computer vision due to its wide application requirements and the challenges brought by complexity and changes in the real-world. We think fully exploring the characteristics of spatial relationship between points will help to improve the pose estimation performance, especially in the scenes of background clutter and partial occlusion. But this information was usually ignored in previous work using RGB image or RGB-D data. In this paper, we propose a framework for 6D pose estimation from RGB-D data based on spatial structure characteristics of 3D keypoints. We adopt point-wise dense feature embedding to vote for 3D keypoints, which makes full use of the structure information of the rigid body. After the direction vectors pointing to the keypoints are predicted by CNN, we use RANSAC voting to calculate the coordinate of the 3D keypoints, then the pose transformation can be easily obtained by the least square method. In addition, a spatial dimension sampling strategy for points is employed, which makes the method achieve excellent performance on small training sets. The proposed method is verified on two benchmark datasets, LINEMOD and OCCLUSION LINEMOD. The experimental results show that our method outperforms the state-of-the-art approaches, achieves ADD(-S) accuracy of 98.7% on LINEMOD dataset and 52.6% on OCCLUSION LINEMOD dataset in real-time.","2020 16th International Conference on Control, Automation, Robotics and Vision (ICARCV)",2020
7bbce51c8e25e52f8f19ed9d1420560368fa35f8,https://www.semanticscholar.org/paper/7bbce51c8e25e52f8f19ed9d1420560368fa35f8,Deep Orientation Uncertainty Learning based on a Bingham Loss,"Reasoning about uncertain orientations is one of the core problems in many perception tasks such as object pose estimation or motion estimation. In these scenarios, poor illumination conditions, sensor limitations, or appearance invariance may result in highly uncertain estimates. In this work, we propose a novel learning based representation for orientation uncertainty. Characterizing uncertainty over unit quaternions with the Bingham distribution allows us to formulate a loss that naturally captures the antipodal symmetry of the representation. We discuss the interpretability of the learned distribution parameters and demonstrate the feasibility of our approach on several challenging real-world pose estimation tasks involving uncertain orientations.",ICLR,2020
7c4be71e076b3675457c3e24e67071b03689b45c,https://www.semanticscholar.org/paper/7c4be71e076b3675457c3e24e67071b03689b45c,I Like to Move It: 6D Pose Estimation as an Action Decision Process,"Object pose estimation is an integral part of robot vision and augmented reality. Robust and accurate pose prediction of both object rotation and translation is a crucial element to enable precise and safe human-machine interactions and to allow visualization in mixed reality. Previous 6D pose estimation methods treat the problem either as a regression task or discretize the pose space to classify. We reformulate the problem as an action decision process where an initial pose is updated in incremental discrete steps that sequentially move a virtual 3D rendering towards the correct solution. A neural network estimates likely moves from a single RGB image iteratively and determines so an acceptable final pose. In comparison to previous approaches that learn an object-specific pose embedding, a decision process allows for a lightweight architecture while it naturally generalizes to unseen objects. Moreover, the coherent action for process termination enables dynamic reduction of the computation cost if there are insignificant changes in a video sequence. While other methods only provide a static inference time, we can thereby automatically increase the runtime depending on the object motion. We evaluate robustness and accuracy of our action decision network on video scenes with known and unknown objects and show how this can improve the state-of-the-art on YCB videos significantly.",ArXiv,2020
7dbf2cdaf5a5e72d26b21a0494eee69c6f4f9fe2,https://www.semanticscholar.org/paper/7dbf2cdaf5a5e72d26b21a0494eee69c6f4f9fe2,ZoomNet: Part-Aware Adaptive Zooming Neural Network for 3D Object Detection,"3D object detection is an essential task in autonomous driving and robotics. Though great progress has been made, challenges remain in estimating 3D pose for distant and occluded objects. In this paper, we present a novel framework named ZoomNet for stereo imagery-based 3D detection. The pipeline of ZoomNet begins with an ordinary 2D object detection model which is used to obtain pairs of left-right bounding boxes. To further exploit the abundant texture cues in rgb images for more accurate disparity estimation, we introduce a conceptually straight-forward module – adaptive zooming, which simultaneously resizes 2D instance bounding boxes to a unified resolution and adjusts the camera intrinsic parameters accordingly. In this way, we are able to estimate higher-quality disparity maps from the resized box images then construct dense point clouds for both nearby and distant objects. Moreover, we introduce to learn part locations as complementary features to improve the resistance against occlusion and put forward the 3D fitting score to better estimate the 3D detection quality. Extensive experiments on the popular KITTI 3D detection dataset indicate ZoomNet surpasses all previous state-of-the-art methods by large margins (improved by 9.4% on APbv (IoU=0.7) over pseudo-LiDAR). Ablation study also demonstrates that our adaptive zooming strategy brings an improvement of over 10% on AP3d (IoU=0.7). In addition, since the official KITTI benchmark lacks fine-grained annotations like pixel-wise part locations, we also present our KFG dataset by augmenting KITTI with detailed instance-wise annotations including pixel-wise part location, pixel-wise disparity, etc.. Both the KFG dataset and our codes will be publicly available at https://github.com/detectRecog/ZoomNet.",AAAI,2020
8326c50db66a567dd5ce06f668730effccfe4318,https://www.semanticscholar.org/paper/8326c50db66a567dd5ce06f668730effccfe4318,End-to-End Differentiable 6DoF Object Pose Estimation with Local and Global Constraints,"Inferring the 6DoF pose of an object from a single RGB image is an important but challenging task, especially under heavy occlusion. While recent approaches improve upon the two stage approaches by training an end-to-end pipeline, they do not leverage local and global constraints. In this paper, we propose pairwise feature extraction to integrate local constraints, and triplet regularization to integrate global constraints for improved 6DoF object pose estimation. Coupled with better augmentation, our approach achieves state of the art results on the challenging Occlusion Linemod dataset, with a 9% improvement over the previous state of the art, and achieves competitive results on the Linemod dataset.",ArXiv,2020
87395d78b72e0fc6dc0468ce44587f5f3c7a9728,https://www.semanticscholar.org/paper/87395d78b72e0fc6dc0468ce44587f5f3c7a9728,6D Pose Estimation with Two-stream Net,"In this poster, we present a heterogeneous architecture for estimating 6D object pose from RGB images. First, we use a two-stream network to extract robust 3D-to-2D embedding feature correspondence. The segmentation stream processes the RGB information and spatial features individually. Then, we construct another fusion network to couple color and positional features, and predict the locations of keypoints in the regression stream. The pose can be obtained by an efficient RANSAC-based PnP algorithm. Moreover, we design an end-to-end iterative pose refinement procedure that further improves the reliable pose estimation. Our method outperforms state-of-the-art approaches in two public datasets.",SIGGRAPH Posters,2020
8d42ad7ceaadf9eb8e48ae7a1da8ffc5a61baf57,https://www.semanticscholar.org/paper/8d42ad7ceaadf9eb8e48ae7a1da8ffc5a61baf57,C-Reference: Improving 2D to 3D Object Pose Estimation Accuracy via Crowdsourced Joint Object Estimation,"Converting widely-available 2D images and videos, captured using an RGB camera, to 3D can help accelerate the training of machine learning systems in spatial reasoning domains ranging from in-home assistive robots to augmented reality to autonomous vehicles. However, automating this task is challenging because it requires not only accurately estimating object location and orientation, but also requires knowing currently unknown camera properties (e.g., focal length). A scalable way to combat this problem is to leverage people's spatial understanding of scenes by crowdsourcing visual annotations of 3D object properties. Unfortunately, getting people to directly estimate 3D properties reliably is difficult due to the limitations of image resolution, human motor accuracy, and people's 3D perception (i.e., humans do not ""see"" depth like a laser range finder). In this paper, we propose a crowd-machine hybrid approach that jointly uses crowds' approximate measurements of multiple in-scene objects to estimate the 3D state of a single target object. Our approach can generate accurate estimates of the target object by combining heterogeneous knowledge from multiple contributors regarding various different objects that share a spatial relationship with the target object. We evaluate our joint object estimation approach with 363 crowd workers and show that our method can reduce errors in the target object's 3D location estimation by over 40%, while requiring only $35$% as much human time. Our work introduces a novel way to enable groups of people with different perspectives and knowledge to achieve more accurate collective performance on challenging visual annotation tasks.",Proc. ACM Hum. Comput. Interact.,2020
8d4f4c1a1d5409bd3183881084f223327195bdf5,https://www.semanticscholar.org/paper/8d4f4c1a1d5409bd3183881084f223327195bdf5,Robust 3D Hand Detection from a Single RGB-D Image in Unconstrained Environments,"Three-dimensional hand detection from a single RGB-D image is an important technology which supports many useful applications. Practically, it is challenging to robustly detect human hands in unconstrained environments because the RGB-D channels can be affected by many uncontrollable factors, such as light changes. To tackle this problem, we propose a 3D hand detection approach which improves the robustness and accuracy by adaptively fusing the complementary features extracted from the RGB-D channels. Using the fused RGB-D feature, the 2D bounding boxes of hands are detected first, and then the 3D locations along the z-axis are estimated through a cascaded network. Furthermore, we represent a challenging RGB-D hand detection dataset collected in unconstrained environments. Different from previous works which primarily rely on either the RGB or D channel, we adaptively fuse the RGB-D channels for hand detection. Specifically, evaluation results show that the D-channel is crucial for hand detection in unconstrained environments. Our RGB-D fusion-based approach significantly improves the hand detection accuracy from 69.1 to 74.1 comparing to one of the most state-of-the-art RGB-based hand detectors. The existing RGB- or D-based methods are unstable in unseen lighting conditions: in dark conditions, the accuracy of the RGB-based method significantly drops to 48.9, and in back-light conditions, the accuracy of the D-based method dramatically drops to 28.3. Compared with these methods, our RGB-D fusion based approach is much more robust without accuracy degrading, and our detection results are 62.5 and 65.9, respectively, in these two extreme lighting conditions for accuracy.",Sensors,2020
8f531b4147d18d43babd42e652b16f23f267f652,https://www.semanticscholar.org/paper/8f531b4147d18d43babd42e652b16f23f267f652,Self-supervised Human Detection and Segmentation via Multi-view Consensus,"Self-supervised detection and segmentation of foreground objects in complex scenes is gaining attention as their fully-supervised counterparts require overly large amounts of annotated data to deliver sufficient accuracy in domain-specific applications. However, existing self-supervised approaches predominantly rely on restrictive assumptions on appearance and motion, which precludes their use in scenes depicting highly dynamic activities or involve camera motion. To mitigate this problem, we propose using a multi-camera framework in which geometric constraints are embedded in the form of multi-view consistency during training via coarse 3D localization in a voxel grid and fine-grained offset regression. In this manner, we learn a joint distribution of proposals over multiple views. At inference time, our method operates on single RGB images. We show that our approach outperforms state-of-the-art self-supervised person detection and segmentation techniques on images that visually depart from those of standard benchmarks, as well as on those of the classical Human3.6M dataset.",ArXiv,2020
8fc4fd443a7b4b3983f9543d895896a55cbead0f,https://www.semanticscholar.org/paper/8fc4fd443a7b4b3983f9543d895896a55cbead0f,Selective Embedding with Gated Fusion for 6D Object Pose Estimation,"Deep learning method for 6D object pose estimation based on RGB image and depth (RGB-D) has been successfully applied to robot grasping. The fusion of RGB and depth is one of the most important difficulties. Previous works on the fusion of these two features are mostly concatenated together without considering the different contributions of the two types of features to pose estimation. We propose a selective embedding with gated fusion structure called SEGate, which can adjust the weights of RGB and depth features adaptively. Furthermore, we aggregate the local features of point clouds according to the distance between them. More specifically, the close point clouds contribute a lot to local features, while the distant point clouds contribute a little. Experiments show that our approach achieves the state-of-art performance in both LineMOD and YCB-Video datasets. Meanwhile, our approach is more robust to the pose estimation of occluded objects.",Neural Processing Letters,2020
919aafbddc9c317c93cfb484b4e840b4342fe1d5,https://www.semanticscholar.org/paper/919aafbddc9c317c93cfb484b4e840b4342fe1d5,EPOS: Estimating 6D Pose of Objects With Symmetries,"We present a new method for estimating the 6D pose of rigid objects with available 3D models from a single RGB input image. The method is applicable to a broad range of objects, including challenging ones with global or partial symmetries. An object is represented by compact surface fragments which allow handling symmetries in a systematic manner. Correspondences between densely sampled pixels and the fragments are predicted using an encoder-decoder network. At each pixel, the network predicts: (i) the probability of each object's presence, (ii) the probability of the fragments given the object's presence, and (iii) the precise 3D location on each fragment. A data-dependent number of corresponding 3D locations is selected per pixel, and poses of possibly multiple object instances are estimated using a robust and efficient variant of the PnP-RANSAC algorithm. In the BOP Challenge 2019, the method outperforms all RGB and most RGB-D and D methods on the T-LESS and LM-O datasets. On the YCB-V dataset, it is superior to all competitors, with a large margin over the second-best RGB method. Source code is at: cmp.felk.cvut.cz/epos.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
9245ef5f5bcb5da7f661f729dc2eb1f882c3b7d8,https://www.semanticscholar.org/paper/9245ef5f5bcb5da7f661f729dc2eb1f882c3b7d8,SHREC 2020 Track: 6D Object Pose Estimation,"6D pose estimation is crucial for augmented reality, virtual reality, robotic manipulation and visual navigation. However, the problem is challenging due to the variety of objects in the real world. They have varying 3D shape and their appearances in captured images are affected by sensor noise, changing lighting conditions and occlusions between objects. Different pose estimation methods have different strengths and weaknesses, depending on feature representations and scene contents. At the same time, existing 3D datasets that are used for data-driven methods to estimate 6D poses have limited view angles and low resolution. To address these issues, we organize the Shape Retrieval Challenge benchmark on 6D pose estimation and create a physically accurate simulator that is able to generate photo-realistic color-and-depth image pairs with corresponding ground truth 6D poses. From captured color and depth images, we use this simulator to generate a 3D dataset which has 400 photo-realistic synthesized color-and-depth image pairs with various view angles for training, and another 100 captured and synthetic images for testing. Five research groups register in this track and two of them submitted their results. Data-driven methods are the current trend in 6D object pose estimation and our evaluation results show that approaches which fully exploit the color and geometric features are more robust for 6D pose estimation of reflective and texture-less objects and occlusion. This benchmark and comparative evaluation results have the potential to further enrich and boost the research of 6D object pose estimation and its applications. CCS Concepts • Information systems → Multimedia and multimodal retrieval; Evaluation of retrieval results; Specialized information retrieval;",3DOR,2020
942252a57acbe0322884b27b2b55b209a47d39f3,https://www.semanticscholar.org/paper/942252a57acbe0322884b27b2b55b209a47d39f3,Q-PointNet: Intelligent Stacked-Objects Grasping Using a RGBD Sensor and a Dexterous Hand,"We report on the development of a deep-learnt grasping algorithm, Q-PointNet, which is capable of determining an adequate strategy for grasping a partially exposed object in a stacked pile. The grasping strategy includes the gripper’s posture and the finger mode, whether two fingers or three fingers. Because our predicted outputs are quaternion and mode, we also explain fully how to utilize the hybrid loss function to reach our goal within the limited training dataset. Moreover, according to the pose prediction, we developed an algorithm to estimate object width, and it is used to adjust the width from finger to finger of the gripper. In the end, the grasp experiments and their operation flows are presented, and the results show that our approach can grasp specific objects with a high accuracy in a stacked scenario.",2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),2020
958a3b24dfccab4872c8aeff1fb8ef68e989d07f,https://www.semanticscholar.org/paper/958a3b24dfccab4872c8aeff1fb8ef68e989d07f,KeyPose: Multi-View 3D Labeling and Keypoint Estimation for Transparent Objects,"Estimating the 3D pose of desktop objects is crucial for applications such as robotic manipulation. Many existing approaches to this problem require a depth map of the object for both training and prediction, which restricts them to opaque, lambertian objects that produce good returns in an RGBD sensor. In this paper we forgo using a depth sensor in favor of raw stereo input. We address two problems: first, we establish an easy method for capturing and labeling 3D keypoints on desktop objects with an RGB camera; and second, we develop a deep neural network, called KeyPose, that learns to accurately predict object poses using 3D keypoints, from stereo input, and works even for transparent objects. To evaluate the performance of our method, we create a dataset of 15 clear objects in five classes, with 48K 3D-keypoint labeled images. We train both instance and category models, and show generalization to new textures, poses, and objects. KeyPose surpasses state-of-the-art performance in 3D pose estimation on this dataset by factors of 1.5 to 3.5, even in cases where the competing method is provided with ground-truth depth. Stereo input is essential for this performance as it improves results compared to using monocular input by a factor of 2. We will release a public version of the data capture and labeling pipeline, the transparent object database, and the KeyPose models and evaluation code. Project website: https://sites.google.com/corp/view/keypose.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019
989da5b9938789dc9462a6709774158bb7d601a9,https://www.semanticscholar.org/paper/989da5b9938789dc9462a6709774158bb7d601a9,PVN3D: A Deep Point-Wise 3D Keypoints Voting Network for 6DoF Pose Estimation,"In this work, we present a novel data-driven method for robust 6DoF object pose estimation from a single RGBD image. Unlike previous methods that directly regressing pose parameters, we tackle this challenging task with a keypoint-based approach. Specifically, we propose a deep Hough voting network to detect 3D keypoints of objects and then estimate the 6D pose parameters within a least-squares fitting manner. Our method is a natural extension of 2D-keypoint approaches that successfully work on RGB based 6DoF estimation. It allows us to fully utilize the geometric constraint of rigid objects with the extra depth information and is easy for a network to learn and optimize. Extensive experiments were conducted to demonstrate the effectiveness of 3D-keypoint detection in the 6D pose estimation task. Experimental results also show our method outperforms the state-of-the-art methods by large margins on several benchmarks. Code and video are available at https://github.com/ethnhe/PVN3D.git.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019
9ad33df42ef944660f4be81a25d535d4633ddbde,https://www.semanticscholar.org/paper/9ad33df42ef944660f4be81a25d535d4633ddbde,A Deep Learning Approach to Grasping the Invisible,"We study an emerging problem named “grasping the invisible” in robotic manipulation, in which a robot is tasked to grasp an initially invisible target object via a sequence of pushing and grasping actions. In this problem, pushes are needed to search for the target and rearrange cluttered objects around it to enable effective grasps. We propose to solve the problem by formulating a deep learning approach in a critic-policy format. The target-oriented motion critic, which maps both visual observations and target information to the expected future rewards of pushing and grasping motion primitives, is learned via deep Q-learning. We divide the problem into two subtasks, and two policies are proposed to tackle each of them, by combining the critic predictions and relevant domain knowledge. A Bayesian-based policy accounting for past action experience performs pushing to search for the target; once the target is found, a classifier-based policy coordinates target-oriented pushing and grasping to grasp the target in clutter. The motion critic and the classifier are trained in a self-supervised manner through robot-environment interactions. Our system achieves a 93% and 87% task success rate on each of the two subtasks in simulation and an 85% task success rate in real robot experiments on the whole problem, which outperforms several baselines by large margins. Supplementary material is available at https://sites.google.com/umn.edu/grasping-invisible.",IEEE Robotics and Automation Letters,2019
9b78759381447d913bb878b0faaae8f2d5072867,https://www.semanticscholar.org/paper/9b78759381447d913bb878b0faaae8f2d5072867,Learning 6D pose of textureless objects via multi-scale dense relation,"6D object pose estimation is a fundamental problem for many computer vision and robotics applications. Recent work has shown that data-driven approaches could enable accurate 6D pose estimation for objects with sufficient texture on the surface. However, few works have focused on estimation 6D pose for texture-less objects. In this paper, we present a network that estimating 6D pose for texture-less objects by using the multi-scale relational features. The proposed network, which leverages both the appearance and geometry features from multi-scale point groups, is able to extract distinctive features for texture-less region. In particular, the multi-scale features encode relational information of the point groups, are more informative compared to the feature comes from vanilla convolutional neural networks and PointNet. The proposed network is end-to-end trainable. Experiments on T-LESS dataset demonstrate our method achieves competitive results on 6D pose estimation task of texture-less objects.",Other Conferences,2020
9bff9d1a719630aa572ba2b7b1a5c36e4ab81fb0,https://www.semanticscholar.org/paper/9bff9d1a719630aa572ba2b7b1a5c36e4ab81fb0,Learning Orientation Distributions for Object Pose Estimation,"For robots to operate robustly in the real world, they should be aware of their uncertainty. However, most methods for object pose estimation return a single point estimate of the object’s pose. In this work, we propose two learned methods for estimating a distribution over an object’s orientation. Our methods take into account both the inaccuracies in the pose estimation as well as the object symmetries. Our first method, which regresses from deep learned features to an isotropic Bing-ham distribution, gives the best performance for orientation distribution estimation for non-symmetric objects. Our second method learns to compare deep features and generates a non-parameteric histogram distribution. This method gives the best performance on objects with unknown symmetries, accurately modeling both symmetric and non-symmetric objects, without any requirement of symmetry annotation. We show that both of these methods can be used to augment an existing pose estimator. Our evaluation compares our methods to a large number of baseline approaches for uncertainty estimation across a variety of different types of objects. Code available at https://bokorn.github.io/orientation-distributions/",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
9d25c592420c36c4493b9f10ed0a5c856cf58e8a,https://www.semanticscholar.org/paper/9d25c592420c36c4493b9f10ed0a5c856cf58e8a,Indirect Object-to-Robot Pose Estimation from an External Monocular RGB Camera,"We present a robotic grasping system that uses a single external monocular RGB camera as input. The object-to-robot pose is computed indirectly by combining the output of two neural networks: one that estimates the object-to-camera pose, and another that estimates the robot-to-camera pose. Both networks are trained entirely on synthetic data, relying on domain randomization to bridge the sim-to-real gap. Because the latter network performs online camera calibration, the camera can be moved freely during execution without affecting the quality of the grasp. Experimental results analyze the effect of camera placement, image resolution, and pose refinement in the context of grasping several household objects. We also present results on a new set of 28 textured household toy grocery objects, which have been selected to be accessible to other researchers. To aid reproducibility of the research, we offer 3D scanned textured models, along with pre-trained weights for pose estimation.1",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
9d6a5c68d84a1e397c7997fb426b325068671ef8,https://www.semanticscholar.org/paper/9d6a5c68d84a1e397c7997fb426b325068671ef8,Object Detection in the Context of Mobile Augmented Reality,"In the past few years, numerous Deep Neural Network (DNN) models and frameworks have been developed to tackle the problem of real-time object detection from RGB images. Ordinary object detection approaches process information from the images only, and they are oblivious to the camera pose with regard to the environment and the scale of the environment. On the other hand, mobile Augmented Reality (AR) frameworks can continuously track a camera’s pose within the scene and can estimate the correct scale of the environment by using Visual-Inertial Odometry (VIO). In this paper, we propose a novel approach that combines the geometric information from VIO with semantic information from object detectors to improve the performance of object detection on mobile devices. Our approach includes three components: (1) an image orientation correction method, (2) a scale-based filtering approach, and (3) an online semantic map. Each component takes advantage of the different characteristics of the VIO-based AR framework. We implemented the AR-enhanced features using ARCore and the SSD Mobilenet model on Android phones. To validate our approach, we manually labeled objects in image sequences taken from 12 room-scale AR sessions. The results show that our approach can improve on the accuracy of generic object detectors by 12% on our dataset.",2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),2020
9e7ef3d8d2f29d9aa2088a5e5c84b89ee9bf0758,https://www.semanticscholar.org/paper/9e7ef3d8d2f29d9aa2088a5e5c84b89ee9bf0758,Symmetry-Aware 6D Object Pose Estimation via Multitask Learning,"Although 6D object pose estimation has been intensively explored in the past decades, the performance is still not fully satisfactory, especially when it comes to symmetric objects. In this paper, we study the problem of 6D object pose estimation by leveraging the information of object symmetry. To this end, a network is proposed that predicts 6D object pose and object reflectional symmetry as well as the key points simultaneously via a multitask learning scheme. Consequently, the pose estimation is aware of and regulated by the symmetry axis and the key points of the to-be-estimated objects. Moreover, we devise an optimization function to refine the predicted 6D object pose by considering the predicted symmetry. Experiments on two datasets demonstrate that the proposed symmetry-aware approach outperforms the existing methods in terms of predicting 6D pose estimation of symmetric objects.",Complex.,2020
a0e7763eb743ec159222b04dde6e9cd95008e8b0,https://www.semanticscholar.org/paper/a0e7763eb743ec159222b04dde6e9cd95008e8b0,6-PACK: Category-level 6D Pose Tracker with Anchor-Based Keypoints,"We present 6-PACK, a deep learning approach to category-level 6D object pose tracking on RGB-D data. Our method tracks in real time novel object instances of known object categories such as bowls, laptops, and mugs. 6-PACK learns to compactly represent an object by a handful of 3D keypoints, based on which the interframe motion of an object instance can be estimated through keypoint matching. These keypoints are learned end-to-end without manual supervision in order to be most effective for tracking. Our experiments show that our method substantially outperforms existing methods on the NOCS category-level 6D pose estimation benchmark and supports a physical robot to perform simple vision-based closed-loop manipulation tasks. Our code and video are available at https://sites.google.com/view/6packtracking.",2020 IEEE International Conference on Robotics and Automation (ICRA),2019
a13ab1a19a30bf8d1cec0d0b0e39a4be651cc98d,https://www.semanticscholar.org/paper/a13ab1a19a30bf8d1cec0d0b0e39a4be651cc98d,Video Object Segmentation-based Visual Servo Control and Object Depth Estimation on a Mobile Robot,"To be useful in everyday environments, robots must be able to identify and locate real-world objects. In recent years, video object segmentation has made significant progress on densely separating such objects from background in real and challenging videos. Building off of this progress, this paper addresses the problem of identifying generic objects and locating them in 3D using a mobile robot with an RGB camera. We achieve this by, first, introducing a video object segmentation-based approach to visual servo control and active perception and, second, developing a new Hadamard-Broyden update formulation. Our segmentation-based methods are simple but effective, and our update formulation lets a robot quickly learn the relationship between actuators and visual features without any camera calibration. We validate our approach in experiments by learning a variety of actuator-camera configurations on a mobile HSR robot, which subsequently identifies, locates, and grasps objects from the YCB dataset and tracks people and other dynamic articulated objects in real-time.",2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2019
a1d002f1fc221c8b696261fe79745872f6fe0ab6,https://www.semanticscholar.org/paper/a1d002f1fc221c8b696261fe79745872f6fe0ab6,AutoSynPose: Automatic Generation of Synthetic Datasets for 6D Object Pose Estimation,"We present an automated pipeline for the generation of synthetic datasets for six-dimension (6D) object pose estimation. Therefore, a completely automated generation process based on predefined settings is developed, which enables the user to create large datasets with a minimum of interaction and which is feasible for applications with a high object variance. The pipeline is based on the Unreal 4 (UE4) game engine and provides a high variation for domain randomization, such as object appearance, ambient lighting, camera-object transformation and distractor density. In addition to the object pose and bounding box, the metadata includes all randomization parameters, which enables further studies on randomization parameter tuning. The developed workflow is adaptable to other 3D objects and UE4 environments. An exemplary dataset is provided including five objects of the YaleCMU-Berkeley (YCB) object set. The datasets consist of 6 million subsegments using 97 rendering locations in 12 different UE4 environments. Each dataset subsegment includes one RGB image, one depth image and one class segmentation image at pixel-level.",MLIS,2020
aa237d7876a32c9bb5249c767febc4dfc35ea03d,https://www.semanticscholar.org/paper/aa237d7876a32c9bb5249c767febc4dfc35ea03d,DronePose: Photorealistic UAV-Assistant Dataset Synthesis for 3D Pose Estimation via a Smooth Silhouette Loss,"In this work we consider UAVs as cooperative agents supporting human users in their operations. In this context, the 3D localisation of the UAV assistant is an important task that can facilitate the exchange of spatial information between the user and the UAV. To address this in a data-driven manner, we design a data synthesis pipeline to create a realistic multimodal dataset that includes both the exocentric user view, and the egocentric UAV view. We then exploit the joint availability of photorealistic and synthesized inputs to train a single-shot monocular pose estimation model. During training we leverage differentiable rendering to supplement a state-of-the-art direct regression objective with a novel smooth silhouette loss. Our results demonstrate its qualitative and quantitative performance gains over traditional silhouette objectives. Our data and code are available at this https URL",ECCV Workshops,2020
ac95ec8f7d53365e3a03d88d77cce81a02193f5b,https://www.semanticscholar.org/paper/ac95ec8f7d53365e3a03d88d77cce81a02193f5b,Hardware Acceleration of Monte-Carlo Sampling for Energy Efficient Robust Robot Manipulation,"Algorithms based on Monte-Carlo sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with tight energy constraints. In this paper, we investigate 6 degree-of-freedom (6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential Monte-Carlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we develop a novel hardware implementation of Monte-Carlo sampling on an FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we achieve real time performance without compromising accuracy.",2020 30th International Conference on Field-Programmable Logic and Applications (FPL),2020
ae7ef7299c201a5ad1b479a679a20e848dc55b7b,https://www.semanticscholar.org/paper/ae7ef7299c201a5ad1b479a679a20e848dc55b7b,3D Object Recognition and Pose Estimation From Point Cloud Using Stably Observed Point Pair Feature,"Recognition and pose estimation from 3D free-form objects is a key step for autonomous robotic manipulation. Recently, the point pair features (PPF) voting approach has been shown to be effective for simultaneous object recognition and pose estimation. However, the global model descriptor (e.g., PPF and its variants) that contained some unnecessary point pair features decreases the recognition performance and increases computational efficiency. To address this issue, in this paper, we introduce a novel strategy for building a global model descriptor using stably observed point pairs. The stably observed point pairs are calculated from the partial view point clouds which are rendered by the virtual camera from various viewpoints. The global model descriptor is extracted from the stably observed point pairs and then stored in a hash table. Experiments on several datasets show that our proposed method reduces redundant point pair features and achieves better compromise of speed vs accuracy.",IEEE Access,2020
b03e4551e61047e35fadca9147e47d0acc533bd7,https://www.semanticscholar.org/paper/b03e4551e61047e35fadca9147e47d0acc533bd7,Restock and straightening system for retail automation using compliant and mobile manipulation,"As the retail industry keeps expanding and shortage of workers increasing, there is a need for autonomous manipulation of products to support retail operations. The increasing amount of products and customers in establishments such as convenience stores requires the automation of restocking, disposing and straightening of products. The manipulation of products needs to be time-efficient, avoid damaging products and beautify the display of products. In this paper, we propose a robotic system to restock shelves, dispose expired products, and straighten products in retail environments. The proposed mobile manipulator features a custom-made end effector with compact and compliant design to safely and effectively manipulate products in retail stores. Through experiments in a convenience store scenario, we verify the effectiveness of our system to restock, dispose and rearrange items. GRAPHICAL ABSTRACT",Adv. Robotics,2020
b3c7b7a3e8cc09e74f3cd4ce4b68cdfa87c251ce,https://www.semanticscholar.org/paper/b3c7b7a3e8cc09e74f3cd4ce4b68cdfa87c251ce,Panoptic 3D Mapping and Object Pose Estimation Using Adaptively Weighted Semantic Information,"We present a system capable of reconstructing highly detailed object-level models and estimating the 6D pose of objects by means of an RGB-D camera. In this work, we integrate deep-learning-based semantic segmentation, instance segmentation, and 6D object pose estimation into a state of the art RGB-D mapping system. We leverage the pipeline of ElasticFusion as a backbone and propose modifications of the registration cost function to make full use of the semantic class labels in the process. The proposed objective function features tunable weights for the depth, appearance, and semantic information channels, which are learned from data. A fast semantic segmentation and registration weight prediction convolutional neural network (Fast-RGBD-SSWP) suited to efficient computation is introduced. In addition, our approach explores performing 6D object pose estimation from multiple viewpoints supported by the high-quality reconstruction system. The developed method has been verified through experimental validation on the YCB-Video dataset and a dataset of warehouse objects. Our results confirm that the proposed system performs favorably in terms of surface reconstruction, segmentation quality, and accurate object pose estimation in comparison to other state-of-the-art systems. Our code and video are available at https://sites.google.com/view/panoptic-mope.",IEEE Robotics and Automation Letters,2020
b4bd1c60731234a76ae699c89798c6ac8285d1db,https://www.semanticscholar.org/paper/b4bd1c60731234a76ae699c89798c6ac8285d1db,6DoF Pose Estimation of Transparent Object from a Single RGB-D Image,"6DoF object pose estimation is a foundation for many important applications, such as robotic grasping, automatic driving, and so on. However, it is very challenging to estimate 6DoF pose of transparent object which is commonly seen in our daily life, because the optical characteristics of transparent material lead to significant depth error which results in false estimation. To solve this problem, a two-stage approach is proposed to estimate 6DoF pose of transparent object from a single RGB-D image. In the first stage, the influence of the depth error is eliminated by transparent segmentation, surface normal recovering, and RANSAC plane estimation. In the second stage, an extended point-cloud representation is presented to accurately and efficiently estimate object pose. As far as we know, it is the first deep learning based approach which focuses on 6DoF pose estimation of transparent objects from a single RGB-D image. Experimental results show that the proposed approach can effectively estimate 6DoF pose of transparent object, and it out-performs the state-of-the-art baselines by a large margin.",Sensors,2020
b658f7b75056eee3e1061b2d8456aa60a56c44eb,https://www.semanticscholar.org/paper/b658f7b75056eee3e1061b2d8456aa60a56c44eb,Single-Stage 6D Object Pose Estimation,"Most recent 6D pose estimation frameworks first rely on a deep network to establish correspondences between 3D object keypoints and 2D image locations and then use a variant of a RANSAC-based Perspective-n-Point (PnP) algorithm. This two-stage process, however, is suboptimal: First, it is not end-to-end trainable. Second, training the deep network relies on a surrogate loss that does not directly reflect the final 6D pose estimation task. In this work, we introduce a deep architecture that directly regresses 6D poses from correspondences. It takes as input a group of candidate correspondences for each 3D keypoint and accounts for the fact that the order of the correspondences within each group is irrelevant, while the order of the groups, that is, of the 3D keypoints, is fixed. Our architecture is generic and can thus be exploited in conjunction with existing correspondence-extraction networks so as to yield single-stage 6D pose estimation frameworks. Our experiments demonstrate that these single-stage frameworks consistently outperform their two-stage counterparts in terms of both accuracy and speed.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019
b74c3a9370daee251a6bd3a24707f0077f18a343,https://www.semanticscholar.org/paper/b74c3a9370daee251a6bd3a24707f0077f18a343,An Efficient and Dynamical Way for Local Feature Extraction on Point Cloud,"This paper presents a flexible module that utilizes the 3D position attention mechanism to extract contextual features from local regions of point cloud. The key point is to create an effective representation of local features. Due to the irregularity of point cloud, previous algorithms for point cloud processing have not fully explored how to enhance the extraction of local features. Inspired by the position attention mechanism in the 2D image segmentation algorithm, we propose a Point Attention Graph (PAG) module that can be used to improve the fusion of local features and make it better and faster. The PAG module uses the point attention mechanism to adaptively calculate the interaction between all nodes of the local graph. It can efficiently definite the relations of local points to enhance the performance of feature extraction both in accuracy and time efficiency, especially compared with some related models like PointWEB. Experiments show that our method can be effectively applied to semantic segmentation datasets.",,2020
b9471a96b47736fcf142c1da53f927b51e59706f,https://www.semanticscholar.org/paper/b9471a96b47736fcf142c1da53f927b51e59706f,3D camera-based markerless navigation system for robotic osteotomies,"Abstract A markerless system for the registration of a bone’s pose is presented which reduces the setup time and the damage to the bone to a minimum. For the registration, a particle filter is implemented which is able to estimate a bone’s pose using depth images. In a phantom study, the pose of 3D-printed bones has been estimated at a rate of 90 Hz and with a precision of a few millimeters. The particle filter is stable under partial occlusions and only diverges when the bone is fully occluded. During a cadaver study, the preoperatively planned cutting edges have been projected as augmented reality (AR) templates onto the hip bones of five cadavers. By cutting manually along the AR templates, surgeons were able to extract ten transplants in the same time as with conventional osteotomy templates. Using the presented navigation system can save hours spent on the construction and production of conventional templates. In conclusion, this work represents one step towards a broader acceptance of robotic osteotomies.",Autom.,2020
b9b89b9990915b6566ef9bfa0e068e52ad3d0d01,https://www.semanticscholar.org/paper/b9b89b9990915b6566ef9bfa0e068e52ad3d0d01,PointPoseNet: Point Pose Network for Robust 6D Object Pose Estimation,"In this paper, we propose a novel pipeline to estimate 6D object pose from RGB-D images of known objects present in complex scenes. The pipeline directly operates on raw point clouds extracted from RGB-D scans. Specifically, our method takes the point cloud as input and regresses the point-wise unit vectors pointing to the 3D keypoints. We then use these vectors to generate keypoint hypotheses from which the 6D object pose hypotheses are computed. Finally, we select the best 6D object pose from the hypotheses based on a proposed scoring mechanism with geometry constraints. Extensive experiments show that the proposed method is robust against the variety in object shape and appearance as well as occlusions between objects, and that our method outperforms the state-of-the-art methods on the LINEMOD and Occlusion LINEMOD datasets.",2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2020
be99f4b9347dbe92d03234bac7da031ca5ed5bf6,https://www.semanticscholar.org/paper/be99f4b9347dbe92d03234bac7da031ca5ed5bf6,Cognitive Template-Clustering Improved LineMod for Efficient Multi-object Pose Estimation,"Various types of theoretical algorithms have been proposed for 6D pose estimation, e.g., the point pair method, template matching method, Hough forest method, and deep learning method. However, they are still far from the performance of our natural biological systems, which can undertake 6D pose estimation of multi-objects efficiently, especially with severe occlusion. With the inspiration of the Müller-Lyer illusion in the biological visual system, in this paper, we propose a cognitive template-clustering improved LineMod (CT-LineMod) model. The model uses a 7D cognitive feature vector to replace standard 3D spatial points in the clustering procedure of Patch-LineMod, in which the cognitive distance of different 3D spatial points will be further influenced by the additional 4D information related with direction and magnitude of features in the Müller-Lyer illusion. The 7D vector will be dimensionally reduced into the 3D vector by the gradient-descent method, and then further clustered by K-means to aggregately match templates and automatically eliminate superfluous clusters, which makes the template matching possible on both holistic and part-based scales. The model has been verified on the standard Doumanoglou dataset and demonstrates a state-of-the-art performance, which shows the accuracy and efficiency of the proposed model on cognitive feature distance measurement and template selection on multiple pose estimation under severe occlusion. The powerful feature representation in the biological visual system also includes characteristics of the Müller-Lyer illusion, which, to some extent, will provide guidance towards a biologically plausible algorithm for efficient 6D pose estimation under severe occlusion.",Cognitive Computation,2020
c2af5e7ef85e7346943ff8ab1a835341f824a1d5,https://www.semanticscholar.org/paper/c2af5e7ef85e7346943ff8ab1a835341f824a1d5,Domain-Translated 3D Object Pose Estimation,"Synthetic 3D object models have been proven crucial in object pose estimation, as they are utilized to generate a huge number of accurately annotated data. The object pose estimation problem is usually solved for images originating from the real data domain by employing synthetic images for training data enrichment, without fully exploiting the fact that synthetic and real images may have different data distributions. In this work, we argue that 3D object pose estimation problem is easier to solve for images originating from the synthetic domain, rather than the real data domain. To this end, we propose a 3D object pose estimation framework consisting of a two-step process, where a novel pose-oriented image-to-image translation step is first employed to translate noisy real images to clean synthetic ones and then, a 3D object pose estimation method is applied on the translated synthetic images to finally predict the 3D object poses. A novel pose-oriented objective function is employed for training the image-to-image translation network, which enforces that pose-related object image characteristics are preserved in the translated images. As a result, the pose estimation network does not require real data for training purposes. Experimental evaluation has shown that the proposed framework greatly improves the 3D object pose estimation performance, when compared to state-of-the-art methods.",IEEE Transactions on Image Processing,2020
c5eea45b62a9c35d976d878d73ca761c6377209d,https://www.semanticscholar.org/paper/c5eea45b62a9c35d976d878d73ca761c6377209d,Pointvotenet: Accurate Object Detection And 6 DOF Pose Estimation In Point Clouds,"We present a learning-based method for 6 DoF pose estimation of rigid objects in point cloud data. Many recent learning-based approaches use primarily RGB information for detecting objects, in some cases with an added refinement step using depth data. Our method consumes unordered point sets with/without RGB information, from initial detection to the final transformation estimation stage. This allows us to achieve accurate pose estimates, in some cases surpassing state of the art methods trained on the same data.",2020 IEEE International Conference on Image Processing (ICIP),2019
c8e31c5b63e68e30faef12c48399be5ff0fc55b0,https://www.semanticscholar.org/paper/c8e31c5b63e68e30faef12c48399be5ff0fc55b0,MoreFusion: Multi-object Reasoning for 6D Pose Estimation from Volumetric Fusion,"Robots and other smart devices need efficient object-based scene representations from their on-board vision systems to reason about contact, physics and occlusion. Recognized precise object models will play an important role alongside non-parametric reconstructions of unrecognized structures. We present a system which can estimate the accurate poses of multiple known objects in contact and occlusion from real-time, embodied multi-view vision. Our approach makes 3D object pose proposals from single RGB-D views, accumulates pose estimates and non-parametric occupancy information from multiple views as the camera moves, and performs joint optimization to estimate consistent, non-intersecting poses for multiple objects in contact. We verify the accuracy and robustness of our approach experimentally on 2 object datasets: YCB-Video, and our own challenging Cluttered YCB-Video. We demonstrate a real-time robotics application where a robot arm precisely and orderly disassembles complicated piles of objects, using only on-board RGB-D vision.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
c93949f74194eed629a394b6e68078e983663aaf,https://www.semanticscholar.org/paper/c93949f74194eed629a394b6e68078e983663aaf,Visuomotor Mechanical Search: Learning to Retrieve Target Objects in Clutter,"When searching for objects in cluttered environments, it is often necessary to perform complex interactions in order to move occluding objects out of the way and fully reveal the object of interest and make it graspable. Due to the complexity of the physics involved and the lack of accurate models of the clutter, planning and controlling precise predefined interactions with accurate outcome is extremely hard, when not impossible. In problems where accurate (forward) models are lacking, Deep Reinforcement Learning (RL) has shown to be a viable solution to map observations (e.g. images) to good interactions in the form of close-loop visuomotor policies. However, Deep RL is sample inefficient and fails when applied directly to the problem of unoccluding objects based on images. In this work we present a novel Deep RL procedure that combines i) teacher-aided exploration, ii) a critic with privileged information, and iii) mid-level representations, resulting in sample efficient and effective learning for the problem of uncovering a target object occluded by a heap of unknown objects. Our experiments show that our approach trains faster and converges to more efficient uncovering solutions than baselines and ablations, and that our uncovering policies lead to an average improvement in the graspability of the target object, facilitating downstream retrieval applications.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
d24d004b9e2f3c9e3a0be19cea1afeb5187011d9,https://www.semanticscholar.org/paper/d24d004b9e2f3c9e3a0be19cea1afeb5187011d9,Edge Enhanced Implicit Orientation Learning With Geometric Prior for 6D Pose Estimation,"Estimating 6D poses of rigid objects from RGB images is an important but challenging task. This is especially true for textureless objects with strong symmetry, since they have only sparse visual features to be leveraged for the task and their symmetry leads to pose ambiguity. The implicit encoding of orientations learned by autoencoders <xref ref-type=""bibr"" rid=""ref31"">[31]</xref>, <xref ref-type=""bibr"" rid=""ref32"">[32]</xref> has demonstrated its effectiveness in handling such objects without requiring explicit pose labeling. In this letter, we further improve this methodology with two key technical contributions. First, we use edge cues to complement the color images with more discriminative features and reduce the domain gap between the real images for testing and the synthetic ones for training. Second, we enhance the regularity of the implicitly learned pose representations by a self-supervision scheme to enforce the geometric prior that the latent representations of two images presenting nearby rotations should be close too. Our approach achieves the state-of-the-art performance on the T-LESS benchmark in the RGB domain; its evaluation on the LINEMOD dataset also outperforms other synthetically trained approaches. Extensive ablation tests demonstrate the improvements enabled by our technical designs. Our code is publicly available for research use.<xref ref-type=""fn"" rid=""fn1""><sup>*</sup></xref><fn id=""fn1""><label><sup>*</sup></label><p>The code is available at <uri>https://github.com/fylwen/EEGP-AAE</uri>.</p></fn>",IEEE Robotics and Automation Letters,2020
d3500ca140dca361866f5e2ede875ed0d38de15f,https://www.semanticscholar.org/paper/d3500ca140dca361866f5e2ede875ed0d38de15f,3DPVNet: Patch-level 3D Hough Voting Network for 6D Pose Estimation,"In this paper, we focus on estimating the 6D pose of objects in point clouds. Although the topic has been widely studied, pose estimation in point clouds remains a challenging problem due to the noise and occlusion. To address the problem, a novel 3DPVNet is presented in this work, which utilizes 3D local patches to vote for the object 6D poses. 3DPVNet is comprised of three modules. In particular, a Patch Unification (\textbf{PU}) module is first introduced to normalize the input patch, and also create a standard local coordinate frame on it to generate a reliable vote. We then devise a Weight-guided Neighboring Feature Fusion (\textbf{WNFF}) module in the network, which fuses the neighboring features to yield a semi-global feature for the center patch. WNFF module mines the neighboring information of a local patch, such that the representation capability to local geometric characteristics is significantly enhanced, making the method robust to a certain level of noise. Moreover, we present a Patch-level Voting (\textbf{PV}) module to regress transformations and generates pose votes. After the aggregation of all votes from patches and a refinement step, the final pose of the object can be obtained. Compared to recent voting-based methods, 3DPVNet is patch-level, and directly carried out on point clouds. Therefore, 3DPVNet achieves less computation than point/pixel-level voting scheme, and has robustness to partial data. Experiments on several datasets demonstrate that 3DPVNet achieves the state-of-the-art performance, and is also robust against noise and occlusions.",ArXiv,2020
d619bbbac79d330523128cc58a0a5542d56896c7,https://www.semanticscholar.org/paper/d619bbbac79d330523128cc58a0a5542d56896c7,PAM: Point-wise Attention Module for 6D Object Pose Estimation,"6D pose estimation refers to object recognition and estimation of 3D rotation and 3D translation. The key technology for estimating 6D pose is to estimate pose by extracting enough features to find pose in any environment. Previous methods utilized depth information in the refinement process or were designed as a heterogeneous architecture for each data space to extract feature. However, these methods are limited in that they cannot extract sufficient feature. Therefore, this paper proposes a Point Attention Module that can efficiently extract powerful feature from RGB-D. In our Module, attention map is formed through a Geometric Attention Path(GAP) and Channel Attention Path(CAP). In GAP, it is designed to pay attention to important information in geometric information, and CAP is designed to pay attention to important information in Channel information. We show that the attention module efficiently creates feature representations without significantly increasing computational complexity. Experimental results show that the proposed method outperforms the existing methods in benchmarks, YCB Video and LineMod. In addition, the attention module was applied to the classification task, and it was confirmed that the performance significantly improved compared to the existing model.",ArXiv,2020
d6913553c1d506b8e65103f0bf89ce5c00464287,https://www.semanticscholar.org/paper/d6913553c1d506b8e65103f0bf89ce5c00464287,2D-Key-Points-Localization-Driven 3D Aircraft Pose Estimation,"In this paper, we are interesting in inferring 3D pose estimation of aircraft object leveraging 2D key-points localization. Monocular vision based pose estimation for aircraft can be widely utilized in airspace tasks like flight control system, air traffic management, autonomous navigation and air defense system. Nonetheless, prior methods using directly regression or classification can not meet the requirements of high precision in aircraft pose estimation context, other approaches using PnP algorithms that need additional information such as template 3D model or depth as prior knowledge. These methods do not exploit to full advantage the correlation information between 2D key-points and 3D pose. In this paper, we present a multi-branch network, named AirPose network, using convolutional neural network to address 3D pose estimation based on 2D key-points information. In the meantime, a novel feature fusion method is explored to enable orientation estimation branch adequately exploit key-points information. Our feature fusion method significantly decreases 3D pose estimation error also avoids the involvement of RANSAC based PnP algorithms. To address the problem that there is no available dedicated aircraft 3D pose dataset for training and testing, we build a visual simulation platform on Unreal Engine 4 applying domain randomization (DR) skill, named AKO platform, which generates aircraft images automatically labeled with 3D orientation and key-points location. The dataset is called AKO dataset. We implement a series of ablation experiments to evaluate our framework for aircraft object detection, key-points localization and orientation estimation on AKO dataset. Experiments show that our proposed AirPose network leveraging AKO dataset can achieve convincing results for each of the tasks.",IEEE Access,2020
d95def2bf8305b77b4079ebc4a1f6fdf33b0e070,https://www.semanticscholar.org/paper/d95def2bf8305b77b4079ebc4a1f6fdf33b0e070,MaskedFusion: Mask-based 6D Object Pose Estimation,"MaskedFusion is a framework to estimate the 6D pose of objects using RGB-D data, with an architecture that leverages multiple sub-tasks in a pipeline to achieve accurate 6D poses. 6D pose estimation is an open challenge due to complex world objects and many possible problems when capturing data from the real world, e.g., occlusions, truncations, and noise in the data. Achieving accurate 6D poses will improve results in other open problems like robot grasping or positioning objects in augmented reality. MaskedFusion improves the state-of-the-art by using object masks to eliminate non-relevant data. With the inclusion of the masks on the neural network that estimates the 6D pose of an object we also have features that represent the object shape. MaskedFusion is a modular pipeline where each sub-task can have different methods that achieve the objective. MaskedFusion achieved 97.3% on average using the ADD metric on the LineMOD dataset and 93.3% using the ADD-S AUC metric on YCB-Video Dataset, which is an improvement, compared to the state-of-the-art methods.",2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),2019
db0c881fb56c76d71f0f473597a96b1f1e04c39e,https://www.semanticscholar.org/paper/db0c881fb56c76d71f0f473597a96b1f1e04c39e,"Robust, Occlusion-aware Pose Estimation for Objects Grasped by Adaptive Hands","Many manipulation tasks, such as placement or within-hand manipulation, require the object's pose relative to a robot hand. The task is difficult when the hand significantly occludes the object. It is especially hard for adaptive hands, for which it is not easy to detect the finger's configuration. In addition, RGB-only approaches face issues with texture-less objects or when the hand and the object look similar. This paper presents a depth-based framework, which aims for robust pose estimation and short response times. The approach detects the adaptive hand's state via efficient parallel search given the highest overlap between the hand's model and the point cloud. The hand's point cloud is pruned and robust global registration is performed to generate object pose hypotheses, which are clustered. False hypotheses are pruned via physical reasoning. The remaining poses' quality is evaluated given agreement with observed data. Extensive evaluation on synthetic and real data demonstrates the accuracy and computational efficiency of the framework when applied on challenging, highly-occluded scenarios for different object types. An ablation study identifies how the framework's components help in performance. This work also provides a dataset for in-hand 6D object pose estimation. Code and dataset are available at: https://github.com/wenbowen123/icra20-hand-object-pose",2020 IEEE International Conference on Robotics and Automation (ICRA),2020
dd306f0e55a4fd3d6468e28d4b13a8558680b51b,https://www.semanticscholar.org/paper/dd306f0e55a4fd3d6468e28d4b13a8558680b51b,Multi-View Shape Estimation of Transparent Containers,"The 3D localisation of an object and the estimation of its properties, such as shape and dimensions, are challenging under varying degrees of transparency and lighting conditions. In this paper, we propose a method for jointly localising container-like objects and estimating their dimensions using two wide-baseline, calibrated RGB cameras. Under the assumption of circular symmetry along the vertical axis, we estimate the dimensions of an object with a generative 3D sampling model of sparse circumferences, iterative shape fitting and image re-projection to verify the sampling hypotheses in each camera using semantic segmentation masks. We evaluate the proposed method on a novel dataset of objects with different degrees of transparency and captured under different backgrounds and illumination conditions. Our method, which is based on RGB images only, outperforms in terms of localisation success and dimension estimation accuracy a deep-learning based approach that uses depth maps.","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2019
ddb42aace56362ea9725a33815a64bb213d0329a,https://www.semanticscholar.org/paper/ddb42aace56362ea9725a33815a64bb213d0329a,ImVoteNet: Boosting 3D Object Detection in Point Clouds With Image Votes,"3D object detection has seen quick progress thanks to advances in deep learning on point clouds. A few recent works have even shown state-of-the-art performance with just point clouds input (e.g. VoteNet). However, point cloud data have inherent limitations. They are sparse, lack color information and often suffer from sensor noise. Images, on the other hand, have high resolution and rich texture. Thus they can complement the 3D geometry provided by point clouds. Yet how to effectively use image information to assist point cloud based detection is still an open question. In this work, we build on top of VoteNet and propose a 3D detection architecture called ImVoteNet specialized for RGB-D scenes. ImVoteNet is based on fusing 2D votes in images and 3D votes in point clouds. Compared to prior work on multi-modal detection, we explicitly extract both geometric and semantic features from the 2D images. We leverage camera parameters to lift these features to 3D. To improve the synergy of 2D-3D feature fusion, we also propose a multi-tower training scheme. We validate our model on the challenging SUN RGB-D dataset, advancing state-of-the-art results by 5.7 mAP. We also provide rich ablation studies to analyze the contribution of each design choice.",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020
e3fd91eb9b02e4b25a201b82fbf7aa513cfc6e80,https://www.semanticscholar.org/paper/e3fd91eb9b02e4b25a201b82fbf7aa513cfc6e80,"Scalable, physics-aware 6D pose estimation for robot manipulation","OF THE DISSERTATION Scalable, Physics-aware 6D Pose Estimation for Robot Manipulation by CHAITANYA MITASH Dissertation Director: Abdeslam Boularias, Kostas E. Bekris Robot Manipulation often depend on some form of pose estimation to represent the state of the world and allow decision making both at the task-level and for motion or grasp planning. Recent progress in deep learning gives hope for a pose estimation solution that could generalize over textured and texture-less objects, objects with or without distinctive shape properties, and under different lighting conditions and clutter scenarios. Nevertheless, it gives rise to a new set of challenges such as the painful task of acquiring large-scale labeled training datasets and of dealing with their stochastic output over unforeseen scenarios that are not captured by the training. This restricts the scalability of such pose estimation solutions in robot manipulation tasks that often deal with a variety of objects and changing environments. The thesis first describes an automatic data generation and learning framework to address the scalability challenge. Learning is bootstrapped by generating labeled data via physics simulation and rendering. Then it self-improves over time by acquiring and labeling real-world images via a search-based pose estimation process. The thesis proposes algorithms to generate and validate object poses online based on the objects’ geometry and based on the physical consistency of their scene-level interactions. These algorithms provide robustness even when there exists a domain gap between the synthetic training and the real test scenarios. Finally, the thesis proposes a manipulation planning framework that goes beyond model-based pose",,2020
e60118ac01da6f396d08dbdcd64f294c49a723bb,https://www.semanticscholar.org/paper/e60118ac01da6f396d08dbdcd64f294c49a723bb,Spatial-Related Correlation Network for 3D Point Clouds,"Due to the irregularity and inconsistency of 3D point clouds, it is difficult to extract features directly from them. Existing methods usually extract point features independently and then use the max-pooling operation to aggregate local features, which limits the feature representation capability of their models. In this work, we design a novel spatial-related correlation path, which considers both spatial information and point correlations, to preserve high dimensional features, thereby capturing fine-detail information and long-distance context of the point cloud. We further propose a new network to aggregate the spatial aware correlations with point-wise features and global features in a learnable way. The experimental results show that our method can achieve better performance than the state-of-the-art approaches on challenging datasets. We can achieve 0.934 accuracy on ModelNet40 dataset and 0.875 mean IoU (Intersection over Union) on ShapeNet dataset with only about 2.42 million parameters.",IEEE Access,2020
e6aca2e7c91b428205b7eafcdf627b51b8592783,https://www.semanticscholar.org/paper/e6aca2e7c91b428205b7eafcdf627b51b8592783,se(3)-TrackNet: Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic Domains,"Tracking the 6D pose of objects in video sequences is important for robot manipulation. This task, however, introduces multiple challenges: (i) robot manipulation involves significant occlusions; (ii) data and annotations are troublesome and difficult to collect for 6D poses, which complicates machine learning solutions, and (iii) incremental error drift often accumulates in long term tracking to necessitate re-initialization of the object’s pose. This work proposes a data-driven optimization approach for long-term, 6D pose tracking. It aims to identify the optimal relative pose given the current RGB-D observation and a synthetic image conditioned on the previous best estimate and the object’s model. The key contribution in this context is a novel neural network architecture, which appropriately disentangles the feature encoding to help reduce domain shift, and an effective 3D orientation representation via Lie Algebra. Consequently, even when the network is trained only with synthetic data can work effectively over real images. Comprehensive experiments over benchmarks - existing ones as well as a new dataset with significant occlusions related to object manipulation - show that the proposed approach achieves consistently robust estimates and outperforms alternatives, even though they have been trained with real images. The approach is also the most computationally efficient among the alternatives and achieves a tracking frequency of 90.9Hz. 1",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
e88e49445cca8bfbe4ab76d4326f8f988bed4417,https://www.semanticscholar.org/paper/e88e49445cca8bfbe4ab76d4326f8f988bed4417,Pose Ambiguity Elimination Algorithm for 3C Components Assembly Pose Estimation in Point Cloud,"Pose ambiguity is an inevitable problem in object pose estimation which means it is difficult or impossible to distinguish between several possible poses based on known observations and it is often caused by object symmetry, occlusion, less or repetitive textures. In 3C assembly, components often have plane symmetrical structure. When using traditional point cloud registration algorithms to estimate 6D pose of 3C components, an incorrect ambiguous pose is often obtained, which will cause assembly failure. In order to solve the pose ambiguity problem in 3C assembly, a pose ambiguity elimination algorithm based on PCA (Principal Component Analysis) and 2D image template matching is proposed. In elimination of ambiguity, Our method has higher accuracy than traditional methods and the efficiency meets our need. The reliability and effectiveness are verified by simulation and experiments.",,2020
e92f38e818ab755e836039a0774bfa9ebb5a4389,https://www.semanticscholar.org/paper/e92f38e818ab755e836039a0774bfa9ebb5a4389,Joint Pose and Shape Estimation of Vehicles from LiDAR Data,"We address the problem of estimating the pose and shape of vehicles from LiDAR scans, a common problem faced by the autonomous vehicle community. Recent work has tended to address pose and shape estimation separately in isolation, despite the inherent connection between the two. We investigate a method of jointly estimating shape and pose where a single encoding is learned from which shape and pose may be decoded in an efficient yet effective manner. We additionally introduce a novel joint pose and shape loss, and show that this joint training method produces better results than independently-trained pose and shape estimators. We evaluate our method on both synthetic data and real-world data, and show superior performance against a state-of-the-art baseline.",ArXiv,2020
e9fb229764f8bd27062764bba19cafef92358d96,https://www.semanticscholar.org/paper/e9fb229764f8bd27062764bba19cafef92358d96,Fast Object Pose Estimation Using Adaptive Threshold for Bin-Picking,"Robotic bin-picking is a common process in modern manufacturing, logistics, and warehousing that aims to pick-up known or unknown objects with random poses out of a bin by using a robot-camera system. Rapid and accurate object pose estimation pipelines have become an escalating issue for robot picking in recent years. In this paper, a fast 6-DoF (degrees of freedom) pose estimation pipeline for random bin-picking is proposed in which the pipeline is capable of recognizing different types of objects in various cluttered scenarios and uses an adaptive threshold segment strategy to accelerate estimation and matching for the robot picking task. Particularly, our proposed method can be effectively trained with fewer samples by introducing the geometric properties of objects such as contour, normal distribution, and curvature. An experimental setup is designed with a Kinova 6-Dof robot and an Ensenso industrial 3D camera for evaluating our proposed methods with respect to four different objects. The results indicate that our proposed method achieves a 91.25% average success rate and a 0.265s average estimation time, which sufficiently demonstrates that our approach provides competitive results for fast objects pose estimation and can be applied to robotic random bin-picking tasks.",IEEE Access,2020
eae25adb8ca5dcd0340a8d5fbd9c52ac628f5690,https://www.semanticscholar.org/paper/eae25adb8ca5dcd0340a8d5fbd9c52ac628f5690,Iterative Pose Refinement for Object Pose Estimation Based on RGBD Data,"Accurate estimation of 3D object pose is highly desirable in a wide range of applications, such as robotics and augmented reality. Although significant advancement has been made for pose estimation, there is room for further improvement. Recent pose estimation systems utilize an iterative refinement process to revise the predicted pose to obtain a better final output. However, such refinement process only takes account of geometric features for pose revision during the iteration. Motivated by this approach, this paper designs a novel iterative refinement process that deals with both color and geometric features for object pose refinement. Experiments show that the proposed method is able to reach 94.74% and 93.2% in ADD(-S) metric with only 2 iterations, outperforming the state-of-the-art methods on the LINEMOD and YCB-Video datasets, respectively.",Sensors,2020
f1425a876bb10febffc49dcad4d52c8f6706fee0,https://www.semanticscholar.org/paper/f1425a876bb10febffc49dcad4d52c8f6706fee0,Robust 6D Object Pose Estimation by Learning RGB-D Features,"Accurate 6D object pose estimation is fundamental to robotic manipulation and grasping. Previous methods follow a local optimization approach which minimizes the distance between closest point pairs to handle the rotation ambiguity of symmetric objects. In this work, we propose a novel discrete- continuous formulation for rotation regression to resolve this local-optimum problem. We uniformly sample rotation anchors in SO(3), and predict a constrained deviation from each anchor to the target, as well as uncertainty scores for selecting the best prediction. Additionally, the object location is detected by aggregating point-wise vectors pointing to the 3D center. Experiments on two benchmarks: LINEMOD and YCB-Video, show that the proposed method outperforms state-of-the-art approaches. Our code is available at https://github.com/mentian/object-posenet.",2020 IEEE International Conference on Robotics and Automation (ICRA),2020
f47d2bba0458de7953a58619cd4a51ce4cc19d9c,https://www.semanticscholar.org/paper/f47d2bba0458de7953a58619cd4a51ce4cc19d9c,Acceleration Techniques for Energy Efficient Sampling based Machine Learning,"Deep learning algorithms based on convolutional neural networks (CNNs) have led to major improvements in accuracy for such tasks as object recognition. However, CNNs may not have sufficient robustness when presented with challenging or new scenarios (e.g, from unstructured or changing environments). Alternatively, algorithms based on Monte-Carlo sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with tight energy constraints. In this paper, we investigate 6 degree-offreedom (6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential MonteCarlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we develop a novel hardware implementation of Monte-Carlo sampling on an FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we achieve real time performance without compromising accuracy.",,2020
f7bc7b21c1ea8e035ab278e55a0747734d941de2,https://www.semanticscholar.org/paper/f7bc7b21c1ea8e035ab278e55a0747734d941de2,6 DoF Pose Estimation of Textureless Objects from Multiple RGB Frames,"This paper addresses the problems of object detection and 6 DoF pose estimation from a sequence of RGB images. Our deep learningbased approach uses only synthetic non-textured 3D CAD models for training and has no access to the images from the target domain. The image sequence is used to obtain a sparse 3D reconstruction of the scene via Structure from Motion. The domain gap is closed by relying on the intuition that geometric edges are the only prominent features that can be extracted from both the 3D models and the sparse reconstructions. Based on this assumption, we have developed a domain-invariant data preparation scheme and 3DKeypointNet, which is a neural network for detecting of the 3D keypoints in sparse and noisy point clouds. The final pose is estimated with RANSAC and a scale-aware point cloud alignment method. The proposed method has been tested on the T-LESS dataset and compared to methods also trained on synthetic data. The results indicate the potential of our method despite the fact that the entire pipeline is solely trained on synthetic data.",ECCV Workshops,2020
faef63d9ecfe7e366dc167203f7c555df0a59dcb,https://www.semanticscholar.org/paper/faef63d9ecfe7e366dc167203f7c555df0a59dcb,PERCH 2.0 : Fast and Accurate GPU-based Perception via Search for Object Pose Estimation,"Pose estimation of known objects is fundamental to tasks such as robotic grasping and manipulation. The need for reliable grasping imposes stringent accuracy requirements on pose estimation in cluttered, occluded scenes in dynamic environments. Modern methods employ large sets of training data to learn features in order to find correspondence between 3D models and observed data. However these methods require extensive annotation of ground truth poses. An alternative is to use algorithms that search for the best explanation of the observed scene in a space of possible rendered scenes. A recently developed algorithm, PERCH (PErception Via SeaRCH) does so by using depth data to converge to a globally optimum solution using a search over a specially constructed tree. While PERCH offers strong guarantees on accuracy, the current formulation suffers from low scalability owing to its high runtime. In addition, the sole reliance on depth data for pose estimation restricts the algorithm to scenes where no two objects have the same shape. In this work, we propose PERCH 2.0, a novel perception via search strategy that takes advantage of GPU acceleration and RGB data. We show that our approach can achieve a speedup of 100x over PERCH, as well as better accuracy than the state-of-the-art data-driven approaches on 6-DoF pose estimation without the need for annotating ground truth poses in the training data. Our code and video are available at https://sbpl-cruz.github.io/perception/.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
fcb9e37a9447c6e1cc23110a17f331ee5052bdd8,https://www.semanticscholar.org/paper/fcb9e37a9447c6e1cc23110a17f331ee5052bdd8,A Review on Object Pose Recovery: from 3D Bounding Box Detectors to Full 6D Pose Estimators,"Object pose recovery has gained increasing attention in the computer vision field as it has become an important problem in rapidly evolving technological areas related to autonomous driving, robotics, and augmented reality. Existing review-related studies have addressed the problem at visual level in 2D, going through the methods which produce 2D bounding boxes of objects of interest in RGB images. The 2D search space is enlarged either using the geometry information available in the 3D space along with RGB (Mono/Stereo) images, or utilizing depth data from LIDAR sensors and/or RGB-D cameras. 3D bounding box detectors, producing category-level amodal 3D bounding boxes, are evaluated on gravity aligned images, while full 6D object pose estimators are mostly tested at instance-level on the images where the alignment constraint is removed. Recently, 6D object pose estimation is tackled at the level of categories. In this paper, we present the first comprehensive and most recent review of the methods on object pose recovery, from 3D bounding box detectors to full 6D pose estimators. The methods mathematically model the problem as a classification, regression, classification & regression, template matching, and point-pair feature matching task. Based on this, a mathematical-model-based categorization of the methods is established. Datasets used for evaluating the methods are investigated with respect to the challenges, and evaluation metrics are studied. Quantitative results of experiments in the literature are analyzed to show which category of methods best performs across what types of challenges. The analyses are further extended comparing two methods, which are our own implementations, so that the outcomes from the public results are further solidified. Current position of the field is summarized regarding object pose recovery, and possible research directions are identified.",Image Vis. Comput.,2020
fddcc5d3c2f66e7973974af55a2b3ad7a8de6e42,https://www.semanticscholar.org/paper/fddcc5d3c2f66e7973974af55a2b3ad7a8de6e42,Shape Prior Deformation for Categorical 6D Object Pose and Size Estimation,"We present a novel learning approach to recover the 6D poses and sizes of unseen object instances from an RGB-D image. To handle the intra-class shape variation, we propose a deep network to reconstruct the 3D object model by explicitly modeling the deformation from a pre-learned categorical shape prior. Additionally, our network infers the dense correspondences between the depth observation of the object instance and the reconstructed 3D model to jointly estimate the 6D object pose and size. We design an autoencoder that trains on a collection of object models and compute the mean latent embedding for each category to learn the categorical shape priors. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach significantly outperforms the state of the art. Our code is available at this https URL.",ECCV,2020
fe0d78bee79e9cfec145787e1e05779565cce6cc,https://www.semanticscholar.org/paper/fe0d78bee79e9cfec145787e1e05779565cce6cc,Feature Sensing and Robotic Grasping of Objects with Uncertain Information: A Review,"As there come to be more applications of intelligent robots, their task object is becoming more varied. However, it is still a challenge for a robot to handle unfamiliar objects. We review the recent work on the feature sensing and robotic grasping of objects with uncertain information. In particular, we focus on how the robot perceives the features of an object, so as to reduce the uncertainty of objects, and how the robot completes object grasping through the learning-based approach when the traditional approach fails. The uncertain information is classified into geometric information and physical information. Based on the type of uncertain information, the object is further classified into three categories, which are geometric-uncertain objects, physical-uncertain objects, and unknown objects. Furthermore, the approaches to the feature sensing and robotic grasping of these objects are presented based on the varied characteristics of each type of object. Finally, we summarize the reviewed approaches for uncertain objects and provide some interesting issues to be more investigated in the future. It is found that the object’s features, such as material and compactness, are difficult to be sensed, and the object grasping approach based on learning networks plays a more important role when the unknown degree of the task object increases.",Sensors,2020
fe6314c748985dca27cc509db20bd1b0bd95a220,https://www.semanticscholar.org/paper/fe6314c748985dca27cc509db20bd1b0bd95a220,YOLOff: You Only Learn Offsets for robust 6DoF object pose estimation,"Estimating the 3D translation and orientation of an object is a challenging task that can be considered within augmented reality or robotic applications. In this paper, we propose a novel approach to perform 6 DoF object pose estimation from a single RGB-D image in cluttered scenes. We adopt an hybrid pipeline in two stages: data-driven and geometric respectively. The first data-driven step consists of a classification CNN to estimate the object 2D location in the image from local patches, followed by a regression CNN trained to predict the 3D location of a set of keypoints in the camera coordinate system. We robustly perform local voting to recover the location of each keypoint in the camera coordinate system. To extract the pose information, the geometric step consists in aligning the 3D points in the camera coordinate system with the corresponding 3D points in world coordinate system by minimizing a registration error, thus computing the pose. Our experiments on the standard dataset LineMod show that our approach more robust and accurate than state-of-the-art methods.",ArXiv,2020
018d208a4067bd60db2ca4a16658f5280f6909dc,https://www.semanticscholar.org/paper/018d208a4067bd60db2ca4a16658f5280f6909dc,Object-RPE: Dense 3D Reconstruction and Pose Estimation with Convolutional Neural Networks for Warehouse Robots,"We present a system for accurate 3D instance-aware semantic reconstruction and 6D pose estimation, using an RGB-D camera. Our framework couples convolutional neural networks (CNNs) and a state-of-the-art dense Simultaneous Localisation and Mapping (SLAM) system, ElasticFusion, to achieve both high-quality semantic reconstruction as well as robust 6D pose estimation for relevant objects. The method presented in this paper extends a high-quality instance-aware semantic 3D Mapping system from previous work [1] by adding a 6D object pose estimator. While the main trend in CNN-based 6D pose estimation has been to infer object's position and orientation from single views of the scene, our approach explores performing pose estimation from multiple viewpoints, under the conjecture that combining multiple predictions can improve the robustness of an object detection system. The resulting system is capable of producing high-quality object-aware semantic reconstructions of room-sized environments, as well as accurately detecting objects and their 6D poses. The developed method has been verified through experimental validation on the YCB-Video dataset and a newly collected warehouse object dataset. Experimental results confirmed that the proposed system achieves improvements over state-of-the-art methods in terms of surface reconstruction and object pose prediction. Our code and video are available at https://sites.google.com/view/object-rpe.",2019 European Conference on Mobile Robots (ECMR),2019
04c9261b8b9da2d72db86f31a63685609eea8f7e,https://www.semanticscholar.org/paper/04c9261b8b9da2d72db86f31a63685609eea8f7e,Context-Aware Dynamic Feature Extraction for 3D Object Detection in Point Clouds,"Varying density of point clouds increases the difficulty of 3D detection. In this paper, we present a context-aware dynamic network (CADNet) to capture the variance of density by considering both point context and semantic context. Point-level contexts are generated from original point clouds to enlarge the effective receptive filed. They are extracted around the voxelized pillars based on our extended voxelization method and processed with the context encoder in parallel with the pillar features. With a large perception range, we are able to capture the variance of features for potential objects and generate attentive spatial guidance to help adjust the strengths for different regions. In the region proposal network, considering the limited representation ability of traditional convolution where same kernels are shared among different samples and positions, we propose a decomposable dynamic convolutional layer to adapt to the variance of input features by learning from local semantic context. It adaptively generates the position-dependent coefficients for multiple fixed kernels and combines them to convolve with local feature windows. Based on our dynamic convolution, we design a dual-path convolution block to further improve the representation ability. We conduct experiments with our Network on KITTI dataset and achieve good performance on 3D detection task for both precision and speed. Our one-stage detector outperforms SECOND and PointPillars by a large margin and achieves the speed of 30 FPS.",,2019
094e45b20438fea5263f5b50e384507a393af7fb,https://www.semanticscholar.org/paper/094e45b20438fea5263f5b50e384507a393af7fb,Active 3D Classification of Multiple Objects in Cluttered Scenes,"Autonomous agents that need to effectively move and interact in a realistic environment have to be endowed with robust perception skills. Among many, accurate object classification is an essential supporting element for assistive robotics. However, realistic scenarios often present scenes with severe clutter, that dramatically degrades the performance of current object classification methods. This paper presents an active vision approach that improves the accuracy of 3D object classification through a next-best-view (NBV) paradigm to perform this complex task with ease. The next camera motion is chosen with the criteria that aim to avoid object self-occlusions while exploring as much as possible the surrounding area. An online 3D reconstruction module is exploited in our system in order to obtain a better canonical 3D representation of the scene while moving the sensor. By reducing the impact of occlusions, we show with both synthetic and real-world data that in a few moves the approach can surpass a state-of-the-art method, PointNet with single view object classification from depth data. In addition, we demonstrate our system in a practical scenario where depth sensor moves to search and classify a set of objects in cluttered scenes.",2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),2019
0abd629cf22aa7b54051e907acb5526b89760de8,https://www.semanticscholar.org/paper/0abd629cf22aa7b54051e907acb5526b89760de8,GraspCNN: Real-Time Grasp Detection Using a New Oriented Diameter Circle Representation,"This paper proposes GraspCNN, an approach to grasp detection where a feasible robotic grasp is detected as an oriented diameter circle in RGB image, using a single convolutional neural network. By detecting robotic grasps as oriented diameter circles, grasp representation is thereby simplified. In addition to our novel grasp representation, a grasp pose localization algorithm is proposed to project an oriented diameter circle back to a 6D grasp pose in point cloud. GraspCNN predicts feasible grasping circles and grasp probabilities directly from RGB image. Experiments show that GraspCNN achieves a 96.5% accuracy on the Cornell Grasping Dataset, outperforming existing one-stage detectors for grasp detection. GraspCNN is fast and stable, which can process RGB image at 50 fps and meet the requirements of real-time applications. To detect objects and locate feasible grasps simultaneously, GraspCNN is executed in parallel with YOLO, which achieves outstanding performance on both object detection and grasp detection.",IEEE Access,2019
1466d4eec15fc02855710d1d807933b849dfbd21,https://www.semanticscholar.org/paper/1466d4eec15fc02855710d1d807933b849dfbd21,A Multi-task Learning Convolutional Neural Network for Object Pose Estimation⋆,"Estimating 6D poses of objects from RGB images is very crucial for robots to interact with the surrounding environment and to cooperate with humans. It is a challenging problem due to the various shapes of objects, the occlusions among objects, as well as the complexity of the scene. In this study, we present a new multi-task convolutional neural network for 6D object pose estimation, which also learns the object region in the image to further improve the estimation result. A weighted loss computed from the training samples is adopted to guarantee that the components of the estimated pose are equally accurate. Additionally, we sythesize new virtual data based on the existing training data so as to overcome the possible adverse situation caused by insufficiency of training data. Experiments on the YCB-video dataset are undertaken to validate the effectiveness of the proposed method.",2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),2019
17d077fb5f66263b08b06f5cc10da2a7e2b09c15,https://www.semanticscholar.org/paper/17d077fb5f66263b08b06f5cc10da2a7e2b09c15,6D Pose Estimation of Transparent Object from Single RGB Image,"Transparent objects are one of the most common objects in everyday life. Estimating pose of these objects are required to pick and manipulate such objects. However, due to the absorption and refraction of light, it is hard to capture depth image of transparent object. In this paper, we address this problem using synthetic dataset to train deep neural network and estimate pose of known transparent objects. Synthetic dataset contains depth map of transparent object which we created in realistic looking environment. Also combining domain randomized and photorealistic images, we create desired amount of annotated data in order to network operate successfully against real world data. We conducted experiment on 3D printed transparent objects in the real environment. For future work, we are planning to build random bin picking system for transparent object.",,2019
26cfc16bcbb7ec8dce6a3dc410d14cd2cf383623,https://www.semanticscholar.org/paper/26cfc16bcbb7ec8dce6a3dc410d14cd2cf383623,Contextual Reinforcement Learning of Visuo-tactile Multi-fingered Grasping Policies,"Using simulation to train robot manipulation policies holds the promise of an almost unlimited amount of training data, generated safely out of harm's way. One of the key challenges of using simulation, to date, has been to bridge the reality gap, so that policies trained in simulation can be deployed in the real world. We explore the reality gap in the context of learning a contextual policy for multi-fingered robotic grasping. We propose a Grasping Objects Approach for Tactile (GOAT) robotic hands, learning to overcome the reality gap problem. In our approach we use human hand motion demonstration to initialize and reduce the search space for learning. We contextualize our policy with the bounding cuboid dimensions of the object of interest, which allows the policy to work on a more flexible representation than directly using an image or point cloud. Leveraging fingertip touch sensors in the hand allows the policy to overcome the reduction in geometric information introduced by the coarse bounding box, as well as pose estimation uncertainty. We show our learned policy successfully runs on a real robot without any fine tuning, thus bridging the reality gap.",ArXiv,2019
381f25fe20580d65e8577603ea2d3e5c4cc3bb02,https://www.semanticscholar.org/paper/381f25fe20580d65e8577603ea2d3e5c4cc3bb02,One Framework to Register Them All: PointNet Encoding for Point Cloud Alignment,"PointNet has recently emerged as a popular representation for unstructured point cloud data, allowing application of deep learning to tasks such as object detection, segmentation and shape completion. However, recent works in literature have shown the sensitivity of the PointNet representation to pose misalignment. This paper presents a novel framework that uses PointNet encoding to align point clouds and perform registration for applications such as 3D reconstruction, tracking and pose estimation. We develop a framework that compares PointNet features of template and source point clouds to find the transformation that aligns them accurately. In doing so, we avoid computationally expensive correspondence finding steps, that are central to popular registration methods such as ICP and its variants. Depending on the prior information about the shape of the object formed by the point clouds, our framework can produce approaches that are shape specific or general to unseen shapes. Our framework produces approaches that are robust to noise and initial misalignment in data and work robustly with sparse as well as partial point clouds. We perform extensive simulation and real-world experiments to validate the efficacy of our approach and compare the performance with state-of-art approaches. Code is available at this https URL.",ArXiv,2019
430d032480867c5b95b31c598a360b041e950b36,https://www.semanticscholar.org/paper/430d032480867c5b95b31c598a360b041e950b36,ESKO6d - A Binocular and RGB-D Dataset of Stored Kitchen Objects with 6d Poses*,"We present a new dataset with the goal of advancing the state-of-the-art in object pose estimation especially for stored porcelain and glass crockery in kitchen scenes. Specifically the ESKO 6d (EASE Stored Kitchen Objects with 6d poses) dataset features texture-less, glossy or glassy ordinary used objects which were naturally stored in a cupboard, drawer or dishwasher. There is a large degree of occlusion being the specific challenge in these scenes. Each scene was recorded in video sequences by two cameras (RGB-D (Kinect) and binocular) within multiple setup stages. The dataset contains an RGB-D image or binocular RGB image plus stereo-matched depth image as well as 6d pose ground truth and instance segmentation. Our dataset contains twelve stored object scenes with a combined amount of 47 video sequences captured by each camera, resulting in over 17k annotated Kinect images and more than 42k annotated stereo images showing around 50 different objects. The ground truth annotation is precise to 3. 5mm ADD (details see paper). The dataset can be accessed under http://www.informatik.uni-bremen.de/esko6d-dataset. Besides the concrete dataset we propose a method of ground truth pose measurement based on an external 3d tracking system that allows on the one hand to precisely measure the object’s pose inside a tight packed storage and on the other hand to obtain the object pose in several images with just one manual measurement.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019
4946b12381f1d0bd3206ff27c3da24d01d6dad6a,https://www.semanticscholar.org/paper/4946b12381f1d0bd3206ff27c3da24d01d6dad6a,EnforceNet: Monocular Camera Localization in Large Scale Indoor Sparse LiDAR Point Cloud,"Pose estimation is a fundamental building block for robotic applications such as autonomous vehicles, UAV, and large scale augmented reality. It is also a prohibitive factor for those applications to be in mass production, since the state-of-the-art, centimeter-level pose estimation often requires long mapping procedures and expensive localization sensors, e.g. LiDAR and high precision GPS/IMU, etc. To overcome the cost barrier, we propose a neural network based solution to localize a consumer degree RGB camera within a prior sparse LiDAR map with comparable centimeter-level precision. We achieved it by introducing a novel network module, which we call resistor module, to enforce the network generalize better, predicts more accurately, and converge faster. Such results are benchmarked by several datasets we collected in the large scale indoor parking garage scenes. We plan to open both the data and the code for the community to join the effort to advance this field.",ArXiv,2019
4e5f0fb6d5b3ee785bb3f5a86a11b3f036cdfc55,https://www.semanticscholar.org/paper/4e5f0fb6d5b3ee785bb3f5a86a11b3f036cdfc55,Tigris: Architecture and Algorithms for 3D Perception in Point Clouds,"Machine perception applications are increasingly moving toward manipulating and processing 3D point cloud. This paper focuses on point cloud registration, a key primitive of 3D data processing widely used in high-level tasks such as odometry, simultaneous localization and mapping, and 3D reconstruction. As these applications are routinely deployed in energy-constrained environments, real-time and energy-efficient point cloud registration is critical. We present Tigris, an algorithm-architecture co-designed system specialized for point cloud registration. Through an extensive exploration of the registration pipeline design space, we find that, while different design points make vastly different trade-offs between accuracy and performance, KD-tree search is a common performance bottleneck, and thus is an ideal candidate for architectural specialization. While KD-tree search is inherently sequential, we propose an acceleration-amenable data structure and search algorithm that exposes different forms of parallelism of KD-tree search in the context of point cloud registration. The co-designed accelerator systematically exploits the parallelism while incorporating a set of architectural techniques that further improve the accelerator efficiency. Overall, Tigris achieves 77.2× speedup and 7.4× power reduction in KD-tree search over an RTX 2080 Ti GPU, which translates to a 41.7% registration performance improvements and 3.0× power reduction.",MICRO,2019
50909262f047b2d40b3a5a127a0e6963971db1a4,https://www.semanticscholar.org/paper/50909262f047b2d40b3a5a127a0e6963971db1a4,DeepIM: Deep Iterative Matching for 6D Pose Estimation,"Estimating 6D poses of objects from images is an important problem in various applications such as robot manipulation and virtual reality. While direct regression of images to object poses has limited accuracy, matching rendered images of an object against the input image can produce accurate results. In this work, we propose a novel deep neural network for 6D pose matching named DeepIM. Given an initial pose estimation, our network is able to iteratively refine the pose by matching the rendered image against the observed image. The network is trained to predict a relative pose transformation using a disentangled representation of 3D location and 3D orientation and an iterative training process. Experiments on two commonly used benchmarks for 6D pose estimation demonstrate that DeepIM achieves large improvements over state-of-the-art methods. We furthermore show that DeepIM is able to match previously unseen objects.",International Journal of Computer Vision,2018
57a7f7e408ed68c6bfc832f4f3ae761841bc738b,https://www.semanticscholar.org/paper/57a7f7e408ed68c6bfc832f4f3ae761841bc738b,Robust motion estimation for qualitative dynamic scene analysis,"Robust Motion Estimation for Qualitative Dynamic Scene Analysis Mr. Mahmoud Ali Ahmed Mohamed Dynamic scene analysis is the primary challenge for various applications such as Advanced Driver Assistance Systems (ADAS), and in any autonomous robot operation in dynamic environments. Autonomous robot/vehicle can carry out desired tasks without continuous human interaction. Distinctly, robust detection, tracking, and recognition of moving objects as well as an estimation of camera ego-motion in a scene are necessary expendables for many autonomous tasks. For instance, in mobile robotics, moving objects are possibly more insecure than stationary objects for safe navigation. In particular, rescue robot systems could increase their performance enormously if they were capable of interacting with moving victims. Robust detection/tracking of moving objects from a moving camera in an outdoor environment is a challenging task due to dynamically changing cluttered backgrounds,large motion, varying lighting conditions, less texture objects, partial object occlusion, and varying object viewpoints. The work presented in this thesis cops with the problem of robust estimation of 2D motion and tracking of moving objects with the problems mentioned above. Therefore, this work introduce a new approach to improve the accuracy of the 2D motion estimation, which called optical flow, in case of large motion using the coarse-to-fine technique. The proposed algorithm estimates the optical flow of fast as well as slow objects correctly and with less processing cost. Moreover, the presented work proposes a novel optimization model for the optical flow estimation base on the texture constraint. The texture constraint assumes that object textures such as edges, gradients, or orientation-of-image features remain constant in case of objects or camera motion. The optimization model uses an objective function to minimize dissimilarity between image texture using local descriptors. The proposed model is not limited to any local texture descriptors, for instance, the histogram of oriented gradient (HOG), the modified local directional pattern (MLDP), the census transform, and other descriptors are used. Furthermore, we present the usage of the monocular epipolar line constraint to improve the accuracy of the optical flow in the case of texture-less regions. The new model estimates the optical flow correctly in most cases when most state-of-the-art approaches that depend on the brightness constancy of a pixel fail. Besides, we propose a new approach for detecting and tracking all moving objects. The proposed algorithm works with a static as well as a moving camera, and the results show the successful detection, estimation, and tracking of moving objects in indoor and outdoor environments. Several experiments and applications have been conducted to test and evaluate the algorithms extensively. The results have shown that the proposed algorithms outperformed the state-of-the-art approaches based on the standard benchmark datasets.",,2019
58c4358a532c37dc3977d4e52513c9e8c05fe183,https://www.semanticscholar.org/paper/58c4358a532c37dc3977d4e52513c9e8c05fe183,Towards Industrial IoT-AR Systems using Deep Learning-Based Object Pose Estimation,"Augmented Reality (AR) is known to enhance user experience, however, it remains under-adopted in industry. We present an AR interaction system improving human-machine coordination in Internet of Things (IoT) and Industry 4.0 applications including manufacturing and assembly, maintenance and safety, and other highly-interactive functions. A driver of slow adoption is the computational complexity and inaccuracy in localization and rendering digital content. AR systems may render digital content close to the associated physical objects, but traditional object recognition and localization modules perform poorly when tracking texture-less objects and complex shapes, presenting a need for robust and efficient digital content rendering techniques. We propose a method of improving IoT-AR by integrating Deep Learning with AR to increase accuracy and robustness of the target object localization module, taking both color and depth images as input and outputting the target’s pose parameters. Quantitative and qualitative experiments prove this system’s efficacy and show potential for fusing these emerging technologies in real-world applications.",2019 IEEE 38th International Performance Computing and Communications Conference (IPCCC),2019
5a1434be9982f9a2cc356adf7ece4f11b3649d1d,https://www.semanticscholar.org/paper/5a1434be9982f9a2cc356adf7ece4f11b3649d1d,P2GNet: Pose-Guided Point Cloud Generating Networks for 6-DoF Object Pose Estimation,"Humans are able to perform fast and accurate object pose estimation even under severe occlusion by exploiting learned object model priors from everyday life. However, most recently proposed pose estimation algorithms neglect to utilize the information of object models, often end up with limited accuracy, and tend to fall short in cluttered scenes. In this paper, we present a novel learning-based model, \underline{P}ose-Guided \underline{P}oint Cloud \underline{G}enerating Networks for 6D Object Pose Estimation (P$^2$GNet), designed to effectively exploit object model priors to facilitate 6D object pose estimation. We achieve this with an end-to-end estimation-by-generation workflow that combines the appearance information from the RGB-D image and the structure knowledge from object point cloud to enable accurate and robust pose estimation. Experiments on two commonly used benchmarks for 6D pose estimation, YCB-Video dataset and LineMOD dataset, demonstrate that P$^2$GNet outperforms the state-of-the-art method by a large margin and shows marked robustness towards heavy occlusion, while achieving real-time inference.",ArXiv,2019
60c29430e40cdcd5e0bc6be18cade2ab6d570ae2,https://www.semanticscholar.org/paper/60c29430e40cdcd5e0bc6be18cade2ab6d570ae2,Unsupervised Joint 3D Object Model Learning and 6D Pose Estimation for Depth-Based Instance Segmentation,"In this work, we propose a novel unsupervised approach to jointly learn the 3D object model and estimate the 6D poses of multiple instances of a same object, with applications to depth-based instance segmentation. The inputs are depth images, and the learned object model is represented by a 3D point cloud. Traditional 6D pose estimation approaches are not sufficient to address this problem, where neither a CAD model of the object nor the ground-truth 6D poses of its instances are available during training. To solve this problem, we propose to jointly optimize the model learning and pose estimation in an end-to-end deep learning framework. Specifically, our network produces a 3D object model and a list of rigid transformations on this model to generate instances, which when rendered must match the observed point cloud to minimizing the Chamfer distance. To render the set of instance point clouds with occlusions, the network automatically removes the occluded points in a given camera view. Extensive experiments evaluate our technique on several object models and varying number of instances in 3D point clouds. We demonstrate the application of our method to instance segmentation of depth images of small bins of industrial parts. Compared with popular baselines for instance segmentation, our model not only demonstrates competitive performance, but also learns a 3D object model that is represented as a 3D point cloud.",2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),2019
6c5bb34621faaef103d80b31816731db4a8795ae,https://www.semanticscholar.org/paper/6c5bb34621faaef103d80b31816731db4a8795ae,W-PoseNet: Dense Correspondence Regularized Pixel Pair Pose Regression,"Solving 6D pose estimation is non-trivial to cope with intrinsic appearance and shape variation and severe inter-object occlusion, and is made more challenging in light of extrinsic large illumination changes and low quality of the acquired data under an uncontrolled environment. This paper introduces a novel pose estimation algorithm W-PoseNet, which densely regresses from input data to 6D pose and also 3D coordinates in model space. In other words, local features learned for pose regression in our deep network are regularized by explicitly learning pixel-wise correspondence mapping onto 3D pose-sensitive coordinates as an auxiliary task. Moreover, a sparse pair combination of pixel-wise features and soft voting on pixel-pair pose predictions are designed to improve robustness to inconsistent and sparse local features. Experiment results on the popular YCB-Video and LineMOD benchmarks show that the proposed W-PoseNet consistently achieves superior performance to the state-of-the-art algorithms.",ArXiv,2019
7533fd49ca2ff37964b5b7f9dfb5f0e45160ccc8,https://www.semanticscholar.org/paper/7533fd49ca2ff37964b5b7f9dfb5f0e45160ccc8,Optimization for Training Deep Models and Deep Learning Based Point Cloud Analysis and Image Classification,"Deep learning (DL) has dramatically improved the state-of-the-art performances in broad applications of computer vision, such as image recognition, object detection, segmentation, and point cloud analysis. However, the reasons for such huge empirical success of DL still keep elusive theoretically. In this dissertation, to understand DL and improve its efficiency, robustness, and interpretability, we theoretically investigate optimization algorithms for training deep models and empirically explore deep learning based point cloud analysis and image classification. 1). Optimization for Training Deep Models: Neural network training is one of the most difficult optimization problems involved in DL. Recently, it has been attracting more and more attention to understand the global optimality in DL. However, we observe that conventional DL solvers have not been developed intentionally to seek for such global optimality. In this dissertation, we propose a novel approximation algorithm, BPGrad, towards optimizing deep models globally via branch and pruning. The proposed BPGrad algorithm is based on the assumption of Lipschitz continuity in DL, and as a result, it can adaptively determine the step size for the current gradient given the history of previous updates, wherein theoretically no smaller steps can achieve the global optimality. Empirically an efficient solver based on BPGrad for DL is proposed as well, and it outperforms conventional DL solvers such as Adagrad, Adadelta, RMSProp, and Adam in the tasks of object recognition, detection, and segmentation. 2). Deep Learning Based Point Cloud Analysis and Image Classification: The network architecture is of central importance for many visual recognition tasks. In this dissertation, we focus on the emerging field of point clouds analysis and image classification. 2.1) Point cloud analysis: We observe that traditional 6D pose estimation approaches are not sufficient to address the problem where neither a CAD model of the object nor the ground-truth 6D poses of its instances are available during training. We propose a novel unsupervised approach to jointly learn the 3D object model and estimate the 6D poses of iii multiple instances of the same object in a single end-to-end deep neural network framework, with applications to depth-based instance segmentation. The inputs are depth images, and the learned object model is represented by a 3D point cloud. Specifically, our network produces a 3D object model and a list of rigid transformations on this model to generate instances, which when rendered must match the observed point cloud to minimizing the Chamfer distance. To render the set of instance point clouds with occlusions, the network automatically removes the occluded points in a given camera view. Extensive experiments evaluate our technique on several object models and a varying number of instances in 3D point clouds. Compared with popular baselines for instance segmentation, our model not only demonstrates competitive performance, but also learns a 3D object model that is represented as a 3D point cloud. 2.2) Low quality image classification: We propose a simple while effective unsupervised deep feature transfer network to address the degrading problem of the state-of-the-art classification algorithms on low-quality images. No fine-tuning is required in our method. We use a pre-trained deep model to extract features for both highresolution (HR) and low-resolution (LR) images, and feed them into a multilayer feature transfer network for knowledge transfer. An SVM classifier is learned directly using these transferred lowresolution features. Our network can be embedded into the state-of-the-art network models as a plug-in feature enhancement module. It preserves data structures in feature space for HR images, and transfers the distinguishing features from a well-structured source domain (HR features space) to a not well-organized target domain (LR features space). Extensive experiments show that the proposed transfer network achieves significant improvements over the baseline method.",,2019
761ef720206c4a2e557436e2904ebe01a0e87ee0,https://www.semanticscholar.org/paper/761ef720206c4a2e557436e2904ebe01a0e87ee0,Real Time and Robust 6D Pose Estimation of RGBD Data for Robotic Bin Picking,"In this paper, we propose a real time and robust method to address the issues of 6D pose estimation for robot bin picking utilizing a low cost 3D sensor. RGB-D data have been widely in industrial applications to deal with 6D pose estimation problems. Different from previous methods of registration-based with time-consuming and point cloud information only with poor accuracy, our approach uses a pinhole camera model and the geometric relationship to correlate the point cloud data and RGB pixels, which is faster and almost same accurate compared with registration based methods. Experimental results show that our method is computationally efficient and can reach an approximate centimeter accuracy. Furthermore, it is also much lower cost and easier to implement when Compared with anterior methods.",2019 Chinese Automation Congress (CAC),2019
7b8aec7cf6751ee9a43fde8c7bcfce353bd95ac1,https://www.semanticscholar.org/paper/7b8aec7cf6751ee9a43fde8c7bcfce353bd95ac1,6D Pose Estimation for Industrial Applications,"Object pose estimation is important for systems and robots to interact with the environment where the main challenge of this task is the complexity of the scene caused by occlusions and clutters. A key challenge is performing pose estimation leveraging on both RGB and depth information: prior works either extract information from the RGB image and depth separately or use costly post-processing steps, limiting their performances in highly cluttered scenes and real-time applications. Traditionally, the pose estimation problem is tackled by matching feature points between 3D models and images. However, these methods require rich textured models. In recent years, the raising of deep learning has offered an increasing number of methods based on neural networks, such as DSAC++, PoseCNN, DenseFusion and SingleShotPose. In this work, we present a comparison between two recent algorithms, DSAC++ and DenseFusion, focusing on computational cost, performance and applicability in the industry.",ICIAP Workshops,2019
856dd9a133a5c050398b31061e401644a06fd2e0,https://www.semanticscholar.org/paper/856dd9a133a5c050398b31061e401644a06fd2e0,Data-Efficient Learning for Sim-to-Real Robotic Grasping using Deep Point Cloud Prediction Networks,"Training a deep network policy for robot manipulation is notoriously costly and time consuming as it depends on collecting a significant amount of real world data. To work well in the real world, the policy needs to see many instances of the task, including various object arrangements in the scene as well as variations in object geometry, texture, material, and environmental illumination. In this paper, we propose a method that learns to perform table-top instance grasping of a wide variety of objects while using no real world grasping data, outperforming the baseline using 2.5D shape by 10%. Our method learns 3D point cloud of object, and use that to train a domain-invariant grasping policy. We formulate the learning process as a two-step procedure: 1) Learning a domain-invariant 3D shape representation of objects from about 76K episodes in simulation and about 530 episodes in the real world, where each episode lasts less than a minute and 2) Learning a critic grasping policy in simulation only based on the 3D shape representation from step 1. Our real world data collection in step 1 is both cheaper and faster compared to existing approaches as it only requires taking multiple snapshots of the scene using a RGBD camera. Finally, the learned 3D representation is not specific to grasping, and can potentially be used in other interaction tasks.",ArXiv,2019
87a3bee49e6a5ec127b449bd2d269529aa700193,https://www.semanticscholar.org/paper/87a3bee49e6a5ec127b449bd2d269529aa700193,MaskedFusion: Mask-based 6D Object Pose Detection,"MaskedFusion is a framework to estimate 6D pose of objects using RGB-D data, with an architecture that leverages multiple stages in a pipeline to achieve accurate 6D poses. 6D pose estimation is an open challenge due to complex world objects and many possible problems when capturing data from the real world, e.g., occlusions, truncations, and noise in the data. Achieving accurate 6D poses will improve results in other open problems like robot grasping or positioning objects in augmented reality. MaskedFusion improves upon DenseFusion where the key differences are in pre-processing data before it enters the Neural Network (NN), eliminating non-relevant data, and adding additional features extracted from the mask of the objects to the NN to improve its estimation. It achieved $5.9mm$ average error on the widely used LineMOD dataset, which is an improvement, of more than 20\%, compared to the state-of-the-art method, DenseFusion.",ArXiv,2019
888f9a6b620e8128bb55124466652cc1f89469c3,https://www.semanticscholar.org/paper/888f9a6b620e8128bb55124466652cc1f89469c3,Depth Camera Based Particle Filter for Robotic Osteotomy Navigation,"Active surgical robots lack acceptance in clinical practice, because they do not offer the flexibility and usability required for a versatile usage: the systems require a large installation space or a complicated registration step, where the preoperative plan is aligned to the patient and transformed to the base frame of the robot. In this paper, a navigation system for robotic osteotomies is designed, which uses the raw depth images from a camera mounted on the flange of a lightweight robot arm. Consequently, the system does not require any rigid attachment of the robot or fiducials to the bone and the time-consuming registration step is eliminated. Instead, only a coarse initialization is required which improves the usability in surgery. The full six dimensional pose of the iliac crest bone is estimated with a particle filter at a maximum rate of 90 Hz. The presented method is robust against changing lighting conditions, blood or tissue on the bone surface and partial occlusions caused by the surgeons. Proof of the usability in a clinical environment is successfully provided in a corpse study, where surgeons used an augmented reality osteotomy template, which was aligned to bone via the particle filters pose estimates for the resection of transplants from the iliac crest.",ArXiv,2019
8b6ec029eca6373351e5db332e40d58f1d6b0f93,https://www.semanticscholar.org/paper/8b6ec029eca6373351e5db332e40d58f1d6b0f93,Hybrid 6D Object Pose Estimation from the RGB Image,"In this research, we focus on the 6D pose estimation of known objects from the RGB image. In contrast to state of the art methods, which are based on the end-to-end neural network training, we proposed a hybrid approach. We use separate deep neural networks to: detect the object on the image, estimate the center of the object, and estimate the translation and ”in-place” rotation of the object. Then, we use geometrical relations on the image and the camera model to recover the full 6D object pose. As a result, we avoid the direct estimation of the object orientation defined in SO3 using a neural network. We propose the 4D-NET neural network to estimate translation and ”in-place” rotation of the object. Finally, we show results on the images generated from the Pascal VOC and ShapeNet datasets.",ICINCO,2019
9781f0212565f334484da0211734fdfde460ec6b,https://www.semanticscholar.org/paper/9781f0212565f334484da0211734fdfde460ec6b,"KOSNet : A Unified Keypoint , Orientation and Scale Network for Probabilistic 6 D Pose Estimation","We propose a novel method using a Convolutional Neural Network (CNN) for probabilistic 6D object pose estimation from color images. Unlike other methods that compute only one data point as the output, our network returns the information necessary to estimate the full probability distributions of 6D object poses. This not only captures the ambiguity of object appearance in the image in a principled manner, but also enables the results to be fused with other sensing modalities using well-established probabilistic inference techniques. One of the main challenges is to provide probabilistic ground truth labels for training the network. To this end, we introduce a way to approximate uncertainties of object poses related to rotational symmetry, occlusion, and how distinct an object is from the background. We demonstrate the unique capability of our network on both fully and partially rotationally symmetric objects while achieving comparable performance with a stateof-the-art method on publicly available datasets.",,2019
9acfcc4c84307b133df9c722a36eb2d71bbfbd3b,https://www.semanticscholar.org/paper/9acfcc4c84307b133df9c722a36eb2d71bbfbd3b,Scene-level Pose Estimation for Multiple Instances of Densely Packed Objects,"This paper introduces key machine learning operations that allow the realization of robust, joint 6D pose estimation of multiple instances of objects either densely packed or in unstructured piles from RGB-D data. The first objective is to learn semantic and instance-boundary detectors without manual labeling. An adversarial training framework in conjunction with physics-based simulation is used to achieve detectors that behave similarly in synthetic and real data. Given the stochastic output of such detectors, candidates for object poses are sampled. The second objective is to automatically learn a single score for each pose candidate that represents its quality in terms of explaining the entire scene via a gradient boosted tree. The proposed method uses features derived from surface and boundary alignment between the observed scene and the object model placed at hypothesized poses. Scene-level, multi-instance pose estimation is then achieved by an integer linear programming process that selects hypotheses that maximize the sum of the learned individual scores, while respecting constraints, such as avoiding collisions. To evaluate this method, a dataset of densely packed objects with challenging setups for state-of-the-art approaches is collected. Experiments on this dataset and a public one show that the method significantly outperforms alternatives in terms of 6D pose accuracy while trained only with synthetic datasets.",CoRL,2019
9d42b6f92e60becf53b9b05cffa85a72b0167105,https://www.semanticscholar.org/paper/9d42b6f92e60becf53b9b05cffa85a72b0167105,Weakly Aligned Cross-Modal Learning for Multispectral Pedestrian Detection,"Multispectral pedestrian detection has shown great advantages under poor illumination conditions, since the thermal modality provides complementary information for the color image. However, real multispectral data suffers from the position shift problem, i.e. the color-thermal image pairs are not strictly aligned, making one object has different positions in different modalities. In deep learning based methods, this problem makes it difficult to fuse the feature maps from both modalities and puzzles the CNN training. In this paper, we propose a novel Aligned Region CNN (AR-CNN) to handle the weakly aligned multispectral data in an end-to-end way. Firstly, we design a Region Feature Alignment (RFA) module to capture the position shift and adaptively align the region features of the two modalities. Secondly, we present a new multimodal fusion method, which performs feature re-weighting to select more reliable features and suppress the useless ones. Besides, we propose a novel RoI jitter strategy to improve the robustness to unexpected shift patterns of different devices and system settings. Finally, since our method depends on a new kind of labelling: bounding boxes that match each modality, we manually relabel the KAIST dataset by locating bounding boxes in both modalities and building their relationships, providing a new KAIST-Paired Annotation. Extensive experimental validations on existing datasets are performed, demonstrating the effectiveness and robustness of the proposed method. Code and data are available at https://github.com/luzhang16/AR-CNN.",2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019
9fea48dc58280776c87ff8b53c62126b178907b2,https://www.semanticscholar.org/paper/9fea48dc58280776c87ff8b53c62126b178907b2,6DoF Pose-Estimation Pipeline for Texture-less Industrial Components in Bin Picking Applications,"Over the next few years, autonomous robots and functionalities are expected to gain increased importance for the shop floor. Perception and the derivation of autonomous behavior is of crucial importance in this context. We present a combined object recognition and pose estimation pipeline to generate pose estimates with six degrees of freedom (6DoF) for bin picking, specifically targeting the suitability for challenging scenarios with texture-less, metallic parts in industrial environments. The pipeline is based on open source algorithms, combining Convolutional Neural Networks (CNNs) and feature-matching methods to create an effective 6DoF pose estimate. We evaluate our approach on several industrial components using a articulated arm robot to guarantee a high level of comparability during the different measurement runs. We further quantify the results using known error metrics for pose estimation, compare the results to established approaches and provide statistical insight into the achieved outcomes to assess the robustness and reliability.",2019 European Conference on Mobile Robots (ECMR),2019
a95d2d685ab4570b7d352dd3f4eb8c15581fe07f,https://www.semanticscholar.org/paper/a95d2d685ab4570b7d352dd3f4eb8c15581fe07f,VeREFINE: Integrating Object Pose Verification with Iterative Physics-guided Refinement,"Precise object pose estimation for robotics applications and augmented reality relies on final refinement and verification steps. However, interactions between objects and interactions with the supporting structures in the observed scene are typically not considered. In this work, we propose to integrate scene-level hypotheses verification with object-level object pose refinement guided by physics simulation. This allows the physical plausibility of individual object pose estimates and the stability of the estimated scene to be consider in a unified search-based optimization. The proposed method is able to adapt to scenes of multiple objects and efficiently focuses on refining the most promising object poses in multi-hypotheses scenarios. We call this integrated approach VeREFINE and evaluate it on two datasets with varying scene complexity. The generality of the approach is shown by using two different pose estimators and two different baseline refiners. Results show improvements over all baselines and on all datasets with the inclusion of our proposed VeREFINE approach.",ArXiv,2019
ab33cb05d10420127fbca804538878bd6290efe0,https://www.semanticscholar.org/paper/ab33cb05d10420127fbca804538878bd6290efe0,PoseRBPF: A Rao-Blackwellized Particle Filter for6D Object Pose Estimation,"Tracking 6D poses of objects from videos provides rich information to a robot in performing different tasks such as manipulation and navigation. In this work, we formulate the 6D object pose tracking problem in the Rao-Blackwellized particle filtering framework, where the 3D rotation and the 3D translation of an object are decoupled. This factorization allows our approach, called PoseRBPF to efficiently estimate the 3D translation of an object along with the full distribution over the 3D rotation. This is achieved by discretizing the rotation space in a fine-grained manner, and training an auto-encoder network to construct a codebook of feature embeddings for the discretized rotations. As a result, PoseRBPF can track objects with arbitrary symmetries while still maintaining adequate posterior distributions. Our approach achieves state-of-the-art results on two 6D pose estimation benchmarks.",Robotics: Science and Systems,2019
aba7b3fbbbb87ca37b0df1f7e6c28dec185f7905,https://www.semanticscholar.org/paper/aba7b3fbbbb87ca37b0df1f7e6c28dec185f7905,Pose Estimation for Texture-less Shiny Objects in a Single RGB Image Using Synthetic Training Data,"In the industrial domain, the pose estimation of multiple texture-less shiny parts is a valuable but challenging task. In this particular scenario, it is impractical to utilize keypoints or other texture information because most of them are not actual features of the target but the reflections of surroundings. Moreover, the similarity of color also poses a challenge in segmentation. In this article, we propose to divide the pose estimation process into three stages: object detection, features detection and pose optimization. A convolutional neural network was utilized to perform object detection. Concerning the reliability of surface texture, we leveraged the contour information for estimating pose. Since conventional contour-based methods are inapplicable to clustered metal parts due to the difficulties in segmentation, we use the dense discrete points along the metal part edges as semantic keypoints for contour detection. Afterward, we exploit both keypoint information and CAD model to calculate the 6D pose of each object in view. A typical implementation of deep learning methods not only requires a large amount of training data, but also relies on intensive human labor for labeling the datasets. Therefore, we propose an approach to generate datasets and label them automatically. Despite not using any real-world photos for training, a series of experiments showed that the algorithm built on synthetic data perform well in the real environment.",ArXiv,2019
b3caa86c7b5af9705881b92c957890ddfa712d31,https://www.semanticscholar.org/paper/b3caa86c7b5af9705881b92c957890ddfa712d31,Probabilistic Online Learning of Appearance and Structure for Robotics,"A robotic system can be characterized by its interactions with environments. With growing demand for robots deployed in various scenarios, the ability to perform physical interaction in uncontrolled environments has become of great interest. While a robot performs interactive tasks, its visual and spatial sensing plays a critical role. Being a major source of learning, vision not only guides immediate actions, but also indirectly improves future actions and decisions. How visual information is gathered and represented will significantly influence how a robot can plan and act. Although recent advances in machine perception have presented unprecedented performance in some areas, there still exist challenges in various aspects. In this dissertation, I will address two such issues and suggest an online probabilistic approach to each problem. Most successful approaches in visual learning depend on fragments of exemplars prepared by humans. It is simply unaffordable to provide constant human supervision to a robotic system that would receive tens of new image frames per second. Ideally, a robotic system is required to gather information from its unique experience and keep growing knowledge on the fly without such external aids. One way to implement the self-learning is to take advantage of the naturally correlated sensations of different sensory modalities. The first part of this talk presents a probabilistic online self-learning framework to alleviate the dependency in robotic visual learning by leveraging structural priors. Another challenge in robotics is its spatial understanding. Aside from planning and performing actions, spatial representation itself still largely requires more research. While point or grid-based representations are currently being employed for practical conveniences, these methods suffer from discretization and disconnected spatial information. On the other hand, Gaussian Processes (GP) have recently gained attention as an alternative to represent the distance field of structures continuously and probabilistically. It is not only the seamless expression of structures, but also direct access to the distance and direction to obstacles that make the representation invaluable. The second part of the talk presents an online framework for continuous spatial mapping using GP. Degree Type Dissertation Degree Name Doctor of Philosophy (PhD) Graduate Group Electrical & Systems Engineering First Advisor Daniel Lee",,2019
cba8a3db2a4022f2229a741ec150e763a9f5f1b0,https://www.semanticscholar.org/paper/cba8a3db2a4022f2229a741ec150e763a9f5f1b0,Learning Joint 2D-3D Representations for Depth Completion,"In this paper, we tackle the problem of depth completion from RGBD data. Towards this goal, we design a simple yet effective neural network block that learns to extract joint 2D and 3D features. Specifically, the block consists of two domain-specific sub-networks that apply 2D convolution on image pixels and continuous convolution on 3D points, with their output features fused in image space. We build the depth completion network simply by stacking the proposed block, which has the advantage of learning hierarchical representations that are fully fused between 2D and 3D spaces at multiple levels. We demonstrate the effectiveness of our approach on the challenging KITTI depth completion benchmark and show that our approach outperforms the state-of-the-art.",2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019
cbc3d7d92635430b8f1704bdc76d61237c8790c0,https://www.semanticscholar.org/paper/cbc3d7d92635430b8f1704bdc76d61237c8790c0,6D Object Pose Verification via Confidence-based Monte Carlo Tree Search and Constrained Physics Simulation,"Precise object pose estimation is required for robots to manipulate objects in their environment. However, the quality of object pose estimation deteriorates in cluttered scenes due to occlusions and detection errors. The estimates only partially fit the observed scene, or are physically implausible. As a result, robotic grasps based on these poses may be unsuccessful and derived scene descriptions may be unintelligible for a human observer. We propose a hypotheses verification approach that detects such outliers while, at the same time, enforces physical plausibility. On one hand, this is achieved by a tight coupling of hypotheses generation with the verification stage to guide the search for a solution. On the other hand, we integrate a constrained physics simulation into the verification stage to constantly enforce physical plausibility. By constraining the simulated objects to the most confident point correspondences, we prevent the estimated poses from erroneously diverging from the initial predictions. We thereby generate a plausible description of the observed scene. We evaluate our method on the LINEMOD and YCB-VIDEO datasets, and achieve state-ofthe-art performance.",,2019
d53121dafa8d9ffa56571adb36f844a1995a814c,https://www.semanticscholar.org/paper/d53121dafa8d9ffa56571adb36f844a1995a814c,Deep Gated Multi-modal Learning: In-hand Object Pose Estimation with Tactile and Image,"In robot manipulation tasks, especially in-hand manipulation, estimation of the position and orientation of an object is an essential skill to manipulate objects freely. However, since in-hand manipulation tends to cause occlusion by the hand itself, image information only is not sufficient. For the challenge, combining tactile sensors is one of the approaches. The advantage of using multiple sensors (modals) is that the other modals can compensate for occlusion, noise, and sensor malfunctions. Even though the decision making of each modal reliability corresponding to the situations is important, the manual design of the model is difficult to deal with various situations. Therefore, in this study, we propose deep gated multi-modal learning using end-to-end deep learning in which the network self-determines the reliability of each modal. As experiments, an RGB camera and a GelSight tactile sensor were attached to the gripper of the Sawyer robot, and the poses were estimated during grasping. A total of 15 objects were used in the experiments. In the proposed model, the reliability of the modal was determined according to the noise and failure of each modal, and it was confirmed that the pose was estimated even for unknown objects.",ArXiv,2019
d9043c07e2cbbf894cf5f1cd6919b45448085c49,https://www.semanticscholar.org/paper/d9043c07e2cbbf894cf5f1cd6919b45448085c49,Monte Carlo Tree Search on Directed Acyclic Graphs for Object Pose Verification,"Reliable object pose estimation is an integral part of robotic vision systems as it enables robots to manipulate their surroundings. Powerful methods exist that estimate object poses from RGB and RGB-D images, yielding a set of hypotheses per object. However, determining the best hypotheses from the set of possible combinations is a challenging task. We apply MCTS to this problem to find an optimal solution in limited time and propose to share information between equivalent object combinations that emerge during the tree search, so-called transpositions. Thereby, the number of combinations that need to be considered is reduced and the search gathers information on these transpositions in a single statistic. We evaluate the resulting verification method on the YCB-VIDEO dataset and show more reliable detection of the best solution as compared to state of the art. In addition, we report a significant speed-up compared to previous MCTS-based methods for object pose verification.",ICVS,2019
d989a64151cf803a99c574d203434f09e81a88cd,https://www.semanticscholar.org/paper/d989a64151cf803a99c574d203434f09e81a88cd,Using PCL Gobal Descriptors in a DenseFusion Architecture,"In this paper, we present an alternative architecture to the state-of-the-art in 6D pose DenseFusion. We changed the architecture of the method in the depth feature extraction phase. Instead of using the PointNet, as used in the original DenseFusion, we used global descriptors from the Point Cloud Library (PCL) to extract features. We made a comparison in terms of average accuracy between the Ensemble of Shape Functions (ESF), Viewpoint Feature Histogram (VHF) and the original PointNet.",,2019
da3fd3c3649b371ae88c5e9aa8cce2e251f88782,https://www.semanticscholar.org/paper/da3fd3c3649b371ae88c5e9aa8cce2e251f88782,Predicting Grasping Order in Clutter Environment by Using Both Color Image and Points Cloud,"Grasping selection for a individual object has been developed many years, and there many feasible proposals have been presented. However, for a robot serving in daily life, this capacity is far from enough. Because the scene in our common life is usually chaotic, where objects are often mutual influences, front and back occlusion, stack up and down. In this paper, we mainly focus on grasping plan and selection in this clutter scene. The first step of this work is to segment the objects from the input picture which are going to manipulate. We use the Faster R-CNN model to segment objects based on the color image for this model have a fine ability to detect multi-objects. For planning the correct grasping order in a chaotic scene, however, it is not enough only using the color information. So, we should combine the geometry information of point cloud together. In this process, we use the extrinsic parameters to transform the bounding-box of objects in color image to point cloud. Then, we calculate the grasping order whit the geometry information of point cloud. In experiment, we demonstrate the whole process of our proposal. And we actually grasping common objects in a clutter environment with the KINOVA ARM and an underactuated hand designed by ourselves.",2019 WRC Symposium on Advanced Robotics and Automation (WRC SARA),2019
dab99d5b7b20215307f5db85daee654617977bcf,https://www.semanticscholar.org/paper/dab99d5b7b20215307f5db85daee654617977bcf,A System Framework for Localization and Mapping using High Resolution Cameras of Mobile Devices,"We propose a hierarchical framework for processing high-resolution images on mobile devices for visual SLAM. It is based on the insights from analysis of new progress in primary features' detection, object detection and pose estimation. A rectification/unwarping operation is applied in regions of interest (ROIs) to improve the object/parts classification/detection performance; the object-part spatial relationships are created and contribute in map building, object detection, and localization; and a geometric constraints based pose refinement is followed to further improve the localization accuracy. Our design facilitates the more accurate pose estimating and localization using mobile devices for SLAM, and Augmented Reality/Mixed Reality applications.",2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),2019
e3bda3355d9d823194c95302969b8c8dea225625,https://www.semanticscholar.org/paper/e3bda3355d9d823194c95302969b8c8dea225625,Improving the Accuracy and Runtime of Probablistic and Deep Learning-Based Pose Estimation,"Many applications in robotics require estimating pose, consisting of translation and orientation, between a model frame and a sensor frame. One popular application is robot grasping, where the object pose is used for determining the optimal placement of the robot gripper. This thesis consists of a survey on three methods aimed at improving pose estimation accuracy and runtime. The first method models uncertainty using various distributions and examines their ability to improve the accuracy of the resulting output, when compared to current methods that do not consider uncertainty in their models. The second method searches for the relationship between common system variables and the performance of neural networks with different configurations, in order to accelerate computation by developing a guideline to select the optimal parallel model given certain problem characteristics and hardware resources. The third method improves both accuracy and runtime by mapping the original non-linear and non-convex pose estimation problem into an alternative parameter space where the original problem can become truly linear. The lack of linearization or other approximations avoids high sensitivity to initial estimation error and high computation time.",,2019
e788b979e92cb86ee0c8e51a5a7cce5018b9c274,https://www.semanticscholar.org/paper/e788b979e92cb86ee0c8e51a5a7cce5018b9c274,GRIP: Generative Robust Inference and Perception for Semantic Robot Manipulation in Adversarial Environments,"Recent advancements have led to a proliferation of machine learning systems used to assist humans in a wide range of tasks. However, we are still far from accurate, reliable, and resource-efficient operations of these systems. For robot perception, convolutional neural networks (CNNs) for object detection and pose estimation are recently coming into widespread use. However, neural networks are known to suffer from overfitting during the training process and are less robust under unforeseen conditions (which makes them especially vulnerable to adversarial scenarios). In this work, we propose Generative Robust Inference and Perception (GRIP) as a two-stage object detection and pose estimation system that aims to combine the relative strengths of discriminative CNNs and generative inference methods to achieve robust estimation. Our results show that a second stage of sample-based generative inference is able to recover from false object detections by CNNs, and produce robust estimations in adversarial conditions. We demonstrate the efficacy of GRIP robustness through comparison with state-of-the-art learning-based pose estimators and pick-and-place manipulation in dark and cluttered environments.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019
eb52a36e02cd97c606722e3556b29c03f1ffe02b,https://www.semanticscholar.org/paper/eb52a36e02cd97c606722e3556b29c03f1ffe02b,A Deep 3D Object Pose Estimation Framework for Robots with RGB-D Sensors,"The task of object detection and pose estimation has widely been done using template matching techniques. However, these algorithms are sensitive to outliers and occlusions, and have high latency due to their iterative nature. Recent research in computer vision and deep learning has shown great improvements in the robustness of these algorithms. However, one of the major drawbacks of these algorithms is that they are specific to the objects. Moreover, the estimation of pose depends significantly on their RGB image features. As these algorithms are trained on meticulously labeled large datasets for object’s ground truth pose, it is difficult to re-train these for real-world applications. To overcome this problem, we propose a two-stage pipeline of convolutional neural networks which uses RGB images to localize objects in 2D space and depth images to estimate a 6DoF pose. Thus the pose estimation network learns only the geometric features of the object and is not biased by its color features. We evaluate the performance of this framework on LINEMOD dataset, which is widely used to benchmark object pose estimation frameworks. We found the results to be comparable with the state of the art algorithms using RGB-D images. Secondly, to show the transferability of the proposed pipeline, we implement this on ATLAS robot for a pick and place experiment. As the distribution of images in LINEMOD dataset and the images captured by the MultiSense sensor on ATLAS are different, we generate a synthetic dataset out of very few real-world images captured from the MultiSense sensor. We use this dataset to train just the object detection networks used in the ATLAS Robot experiment.",,2019
ee7dd12eecc06c25fbd0ca356766bcc6f01a487e,https://www.semanticscholar.org/paper/ee7dd12eecc06c25fbd0ca356766bcc6f01a487e,A Survey of Simultaneous Localization and Mapping,"Simultaneous Localization and Mapping (SLAM) achieves the purpose of simultaneous positioning and map construction based on self-perception. The paper makes an overview in SLAM including Lidar SLAM, visual SLAM, and their fusion. For Lidar or visual SLAM, the survey illustrates the basic type and product of sensors, open source system in sort and history, deep learning embedded, the challenge and future. Additionally, visual inertial odometry is supplemented. For Lidar and visual fused SLAM, the paper highlights the multi-sensors calibration, the fusion in hardware, data, task layer. The open question and forward thinking end the paper. The contributions of this paper can be summarized as follows: the paper provides a high quality and full-scale overview in SLAM. It's very friendly for new researchers to hold the development of SLAM and learn it very obviously. Also, the paper can be considered as dictionary for experienced researchers to search and find new interested orientation.",ArXiv,2019
eea3789a54807d998401c7d5f3501511f1960432,https://www.semanticscholar.org/paper/eea3789a54807d998401c7d5f3501511f1960432,A Survey of Simultaneous Localization and Mapping with an Envision in 6G Wireless Networks,"Simultaneous Localization and Mapping (SLAM) achieves the purpose of simultaneous positioning and map construction based on self-perception. The paper makes an overview in SLAM including Lidar SLAM, visual SLAM, and their fusion. For Lidar or visual SLAM, the survey illustrates the basic type and product of sensors, open source system in sort and history, deep learning embedded, the challenge and future. Additionally, visual inertial odometry is supplemented. For Lidar and visual fused SLAM, the paper highlights the multi-sensors calibration, the fusion in hardware, data, task layer. The open question and forward thinking with an envision in 6G wireless networks end the paper. The contributions of this paper can be summarized as follows: the paper provides a high quality and full-scale overview in SLAM. It's very friendly for new researchers to hold the development of SLAM and learn it very obviously. Also, the paper can be considered as a dictionary for experienced researchers to search and find new interesting orientation.",,2019
f34e74550eaf737c246cbea30c8e3e4c27644556,https://www.semanticscholar.org/paper/f34e74550eaf737c246cbea30c8e3e4c27644556,Pillar in Pillar: Multi-Scale and Dynamic Feature Extraction for 3D Object Detection in Point Clouds,"Sparsity and varied density are two of the main obstacles for 3D detection networks with point clouds. In this paper, we present a multi-scale voxelization method and a decomposable dynamic convolution to solve them. We consider the misalignment problem between voxel representation with different scales and present a center-aligned voxelization strategy. Instead of separating points into individual groups, we use an overlapped partition mechanism to avoid the perception deficiency of edge points in each voxel. Based on this multi-scale voxelization, we are able to build an effective fusion network by one-iteration top-down forward. To handle the variation of density in point cloud data, we propose a decomposable dynamic convolutional layer that considers the shared and dynamic components when applying convolutional filters at different positions of feature maps. By modeling bases in the kernel space, the number of parameters for generating dynamic filters is greatly reduced. With a self-learning network, we can apply dynamic convolutions to input features and deal with the variation in the feature space. We conduct experiments with our PiPNet on KITTI dataset and achieve better results than other voxelization-based methods on 3D detection task.",ArXiv,2019
fd577c0b62d4d2d2d088566ab7e87bfd2d5a43f1,https://www.semanticscholar.org/paper/fd577c0b62d4d2d2d088566ab7e87bfd2d5a43f1,DeepIM: Deep Iterative Matching for 6D Pose Estimation,"Estimating the 6D pose of objects from images is an important problem in various applications such as robot manipulation and virtual reality. While direct regression of images to object poses has limited accuracy, matching rendered images of an object against the observed image can produce accurate results. In this work, we propose a novel deep neural network for 6D pose matching named DeepIM. Given an initial pose estimation, our network is able to iteratively refine the pose by matching the rendered image against the observed image. The network is trained to predict a relative pose transformation using an untangled representation of 3D location and 3D orientation and an iterative training process. Experiments on two commonly used benchmarks for 6D pose estimation demonstrate that DeepIM achieves large improvements over state-of-the-art methods. We furthermore show that DeepIM is able to match previously unseen objects.",ECCV,2020
337c235f57f8326db4793555c9a86615115ff4e5,https://www.semanticscholar.org/paper/337c235f57f8326db4793555c9a86615115ff4e5,RFNet: Region-aware Fusion Network for Incomplete Multi-modal Brain Tumor Segmentation,"Most existing brain tumor segmentation methods usually exploit multi-modal magnetic resonance imaging (MRI) images to achieve high segmentation performance. However, the problem of missing certain modality images often happens in clinical practice, thus leading to severe segmentation performance degradation. In this work, we propose a Region-aware Fusion Network (RFNet) that is able to exploit different combinations of multi-modal data adaptively and effectively for tumor segmentation. Considering different modalities are sensitive to different brain tumor regions, we design a Region-aware Fusion Module (RFM) in RFNet to conduct modal feature fusion from available image modalities according to disparate regions. Benefiting from RFM, RFNet can adaptively segment tumor regions from an incomplete set of multi-modal images by effectively aggregating modal features. Furthermore, we also develop a segmentation-based regularizer to prevent RFNet from the insufficient and unbalanced training caused by the incomplete multi-modal data. Specifically, apart from obtaining segmentation results from fused modal features, we also segment each image modality individually from the corresponding encoded features. In this manner, each modal encoder is forced to learn discriminative features, thus improving the representation ability of the fused features. Remarkably, extensive experiments on BRATS2020, BRATS2018 and BRATS2015 datasets demonstrate that our RFNet outperforms the state-of-the-art significantly.",,
0746f6f44710e164cb4dac0ae580005d26f28cb7,https://www.semanticscholar.org/paper/0746f6f44710e164cb4dac0ae580005d26f28cb7,Strategic-level performance enhancement of a 660 MWe supercritical power plant and emissions reduction by AI approach,,Energy Conversion and Management,2021
17102c28ab1c15345cae87388390a1a426c5839f,https://www.semanticscholar.org/paper/17102c28ab1c15345cae87388390a1a426c5839f,An improved stochastic model predictive control operation strategy of integrated energy system based on a single-layer multi-timescale framework,"Abstract Economy, robustness and computational efficiency are of paramount metrics for an operation strategy of an integrated energy system (IES). To achieve the trade-off of the three metrics, a multi-layer framework is extensively exploited in existing operation strategies. This work, however, proposes a single-layer multi-timescale framework which can coordinate different operation performances associated with various timescales simultaneously. Based on the framework, an improved stochastic model predictive control (SMPC) operation strategy is further developed by embedding the proposed framework into its prediction horizon. To solve the multi-timescale optimization of the improved SMPC, the constraints and cost function are presented in the multi-timescale form, and the supplied and demands are forecast by the least square support vector machine. A simulator of an IES is thereafter constructed to mimic real system and used to evaluate the performance of the proposed strategy by operation cost, accumulative error and computation time with respect to economy, robustness and computational efficiency, respectively. Finally, the improved SMPC strategy is compared with a traditional single-layer and a hierarchical strategy by a case study. The results show that the improved strategy has the best tradeoff performance aforementioned. The multi-timescale framework can be also integrated into other operation strategies.",,2021
176650beb4b465551fe5d74dd11b91fbd56f2ab7,https://www.semanticscholar.org/paper/176650beb4b465551fe5d74dd11b91fbd56f2ab7,Operation optimization of Shell coal gasification process based on convolutional neural network models,"Abstract Coal gasification technology has gained increasing popularity in recent years, but the optimization of operating conditions remains inefficient. The operation optimization of the Shell coal gasification process (SCGP) is investigated in this paper using an operation optimization model integrating data analytics and mechanism analysis. The objective function contains two important indicators. One is effective syngas productivity and the other one is specific oxygen consumption. The optimization is subject to constraints on gasifier temperature and syngas yield. The objective function and the constraints can be calculated by six key operating parameters through three convolutional neural network (CNN) models, which can additionally utilize the correlations between process variables. Prior physical knowledge and a simplified mechanistic model of SCGP are integrated with the development of CNN models. The effectiveness of the proposed model is validated by an industrial case study. After the operation optimization, the objective function decreases by 28.3306% compared with its minimum value on historical process operation data, which outperforms the operation optimization model developed by artificial neural network models. The sensitivities of the objective function and effective syngas yield are analyzed. The operating condition of SCGP can be optimized by the proposed model.",,2021
1dfb275b60cca284f4cf45e0c4dcfed089882f94,https://www.semanticscholar.org/paper/1dfb275b60cca284f4cf45e0c4dcfed089882f94,Theoretical Analysis on Absorption of Carbon Dioxide (CO2) into Solutions of Phenyl Glycidyl Ether (PGE) Using Nonlinear Autoregressive Exogenous Neural Networks,"In this paper, we analyzed the mass transfer model with chemical reactions during the absorption of carbon dioxide (CO2) into phenyl glycidyl ether (PGE) solution. The mathematical model of the phenomenon is governed by a coupled nonlinear differential equation that corresponds to the reaction kinetics and diffusion. The system of differential equations is subjected to Dirichlet boundary conditions and a mixed set of Neumann and Dirichlet boundary conditions. Further, to calculate the concentration of CO2, PGE, and the flux in terms of reaction rate constants, we adopt the supervised learning strategy of a nonlinear autoregressive exogenous (NARX) neural network model with two activation functions (Log-sigmoid and Hyperbolic tangent). The reference data set for the possible outcomes of different scenarios based on variations in normalized parameters (α1, α2, β1, β2, k) are obtained using the MATLAB solver “pdex4”. The dataset is further interpreted by the Levenberg–Marquardt (LM) backpropagation algorithm for validation, testing, and training. The results obtained by the NARX-LM algorithm are compared with the Adomian decomposition method and residual method. The rapid convergence of solutions, smooth implementation, computational complexity, absolute errors, and statistics of the mean square error further validate the design scheme’s worth and efficiency.",Molecules,2021
506c743878d1eec865dc64a48cb195939701c31f,https://www.semanticscholar.org/paper/506c743878d1eec865dc64a48cb195939701c31f,Power-carbon coordinated control of BFG-fired CCGT power plant integrated with solvent-based post-combustion CO2 capture,"Abstract Decarbonizing the energy intensive iron and steel industry is in urgent need to meet the ambitious environmental goal. Efficient and clean use of the blast furnace gas (BFG) through combined-cycle gas turbine (CCGT) power plant provides feasible pathway to realize a near-term CO2 reduction when integrated with carbon capture. This paper presents effective control strategies to coordinate the operation of BFG-fired CCGT plant and solvent-based post-combustion CO2 capture (PCC) process based on the in-depth understanding of the interactions among process dynamics in different time-scales for carbon, heat and electricity. The energy storage capability of the PCC process is explored in addition to the CO2 capture and the reboiler steam flowrate used for solvent regeneration is incorporated into the BFG-fired CCGT control loop. Considering this, two coordinated control strategies are developed for the BFG-fired CCGT-PCC, first based on the conventional PI control and then with advanced model predictive control (MPC) approaches. The coordinated strategies are demonstrated to improve the power ramping performance of the CCGT with little degradation on the PCC operation, thus providing better support for the reliability of the power system in the context of increasing penetration of renewable energy resources. Moreover, by considering the impact of disturbances into the predictive models, the MPC-based coordinated control can well alleviate the influence of BFG fluctuations, guaranteeing a stable operation of the integrated plant. This paper points to the new direction of using PCC for more flexible power regulation of adjustable sources in low-carbon energy systems with penetration of intermittent renewable powers.",Energy,2021
51cb9d4bba823cfc512290f2953090e997302e27,https://www.semanticscholar.org/paper/51cb9d4bba823cfc512290f2953090e997302e27,The Review of Carbon Capture-Storage Technologies and Developing Fuel Cells for Enhancing Utilization,"The amount of CO2 released in the atmosphere has been at a continuous surge in the last decade, and in order to protect the environment from global warming, it is necessary to employ techniques like carbon capture. Developing technologies like Carbon Capture Utilization and Storage aims at mitigating the CO2 content from the air we breathe and has garnered immense research attention. In this review, the authors have aimed to discuss the various technologies that are being used to capture the CO2 from the atmosphere, store it and further utilize it. For utilization, researchers have developed alternatives to make profits from CO2 by converting it into an asset. The development of newer fuel cells that consume CO2 in exchange for electrical power to drive the industries and produce valuable hydrocarbons in the form of fuel has paved the path for more research in the field of carbon utilization. The primary focus on the article is to inspect the environmental and economic feasibility of novel technologies such as fuel cells, different electrochemical processes, and the integration of artificial intelligence and data science in them, which are designed for mitigating the percentage of CO2 in the air.",Energies,2021
92814535c2516df0b32a32960691aecd47e92c20,https://www.semanticscholar.org/paper/92814535c2516df0b32a32960691aecd47e92c20,Artificial intelligent based energy scheduling of steel mill gas utilization system towards carbon neutrality,"Abstract Steel industry contributes significantly to the world economy, but is highly energy intensive and CO2 intensive since the coal-based blast furnace route is dominant in steelmaking. Besides efficient utilization of the steel mill gases for power and heat supply, deploying technologies of carbon capture, utilization and renewable power is in urgent need for the transition of the steel industry towards carbon neutrality. To attain this goal, this paper develops a low-carbon steel mill gas utilization system with the integration of solvent-based carbon capture, methanol production based carbon utilization and renewable power. An artificial intelligent based optimal scheduling is then proposed to coordinate the interactions among gas, heat, electricity and carbon under variant weather and load conditions. Gradient boosted regression trees with Bayesian optimization is exploited to identify efficient surrogate models for the complex devices within the system. Heuristic search algorithm of particle swarm optimization is applied to find the low-carbon and economical scheduling within the entire scheduling period. Case studies show that the optimal scheduling can unlock complementary advantages among renewable energy, carbon capture and utilization, leading to 97% renewable energy curtailment reduction, 62% CO2 emission reduction and 126 tons of methanol production in 24 h. Sensitivity analyses are carried out to investigate the effects of additional coal consumption, renewable power installed capacity, CO2 emission penalty coefficient and CO2 capture constraint mode, providing broader insight into the operation of the steel mill gas utilization system towards carbon neutrality.",,2021
b1d8600e9f52be0f4c159333f8b8654c5589f61c,https://www.semanticscholar.org/paper/b1d8600e9f52be0f4c159333f8b8654c5589f61c,Power prediction of a wind farm cluster based on spatiotemporal correlations,"Abstract Accurate power prediction of wind farm clusters is important for safe and economic operation of power systems with high wind power penetration. Current superposition and statistical scaling methods used in wind power prediction systems do not fully consider the relationships among wind farms in a cluster, thereby leading to insufficient power prediction accuracies. To improve the power prediction accuracy of wind farm clusters, a new method based on spatiotemporal correlations is proposed herein. First, three correlation coefficients are used to represent spatiotemporal correlation characteristics of wind farms in a wind cluster. The Shapley value method is used to weight these coefficients, and a standard wind farm is found by combining the nominal capacities of the wind farms. Then, considering the spatiotemporal factors that affect wind power generation, a characteristic matrix of the wind farm cluster is constructed, and the key characteristics are extracted using a convolutional neural network (CNN). Considering the time series characteristics of wind power generation, a long and short term memory (LSTM) neural network is used to establish the mapping relationship between key characteristics and power generation, and power prediction of a wind farm cluster is performed. Finally, by utilizing the actual operating data of wind farm clusters in North China as an example, feasibility and effectiveness of the proposed method are verified. The proposed system provides a new high-precision method for future wind farm cluster power predictions.",,2021
e18e1b404b12cae23671f3ffd0a1d503ea63d440,https://www.semanticscholar.org/paper/e18e1b404b12cae23671f3ffd0a1d503ea63d440,Process control strategies for solar-powered carbon capture under transient solar conditions,,Energy,2021
6a70b346a51aa0632bb79724eb732f6ffe25d138,https://www.semanticscholar.org/paper/6a70b346a51aa0632bb79724eb732f6ffe25d138,Home-based telerehabilitation: A review of remote therapy frameworks,"Remote therapy frameworks play the main role in home-based telerehabilitation. These remote therapies are exergames that help in the physical and cognitive rehabilitation of the patient. The objective of this review is to present the frameworks of home-based therapies using exergames and to identify the points that can be improved in the development of future systems. To carry out this research, the criteria of the PRISMA were adopted.  Literature searches were conducted up to April 2021 in the Web of Sicence, Pubmed, Cochrane, Embase and Scopus databases. The search query was: ((""game*"" OR ""exergame*"") AND  (""rehabilitation"") AND (""remote"" OR ""telerehabilitation"" OR ""telemedicine"")). We have selected a total of  fourteen  studies. We found five types of frameworks: Client-Server, Web-Based, Layers,  Cloud Based and  Multi users. We identified that it may be advantageous to mix the features of these frameworks to have a cheaper home-based system and prevent the patient from having to purchase more powerful computers. In addition, there are some challenges that need to be studied that will also help reduce costs for the patient:  1) Reduce the need for high processing of exergames on the patient's computer; 2) Prevent the patient from having to purchase expensive external devices for motion tracking.",,2021
7e26eed860fb44af04dc4c8508dd0a284c1bc661,https://www.semanticscholar.org/paper/7e26eed860fb44af04dc4c8508dd0a284c1bc661,Tele-Rehabilitation platform ePHoRt as Serious Game: Usability evaluation,"In recent years, the development of serious games is growing among the different application fields, especially in education. Nevertheless, the concept of learning through a game could be applied even in fields like Tele-Rehabilitation, where the patient could perform a rehabilitation routine in a motivating way due to improve its performance without the need of a doctor’s presence. ePHoRt is a platform developed by our team that allows hip surgery patients to perform their hip movement exercises effectively at home. At the same time, the platform allowed data collection useful for the physiotherapist in order to evaluate patient’s progress. One of the main features in this setting is that the user can personalize their avatar, objects and scenes that interact directly with different therapeutic exercises. At the same time, the platform includes several modules helping the physiotherapist and the patient to be informed about relative pain in the various parts of the body. The aim of this work is presenting the results of the usability evaluation in terms of effectiveness, efficiency and satisfaction of the final users related with the serious game module in the ePHoRt web application. In order to perform this evaluation, several instruments are applied such as: IBM Questionnaire for the Satisfaction of the User Interface (IBM-CSUQ) and Microsoft’s Reaction Cards model. The results indicate that users rate serious games positively.",2021 Second International Conference on Information Systems and Software Technologies (ICI2ST),2021
fd0ab98e4f1058074c64325b980efdcfb0e0be00,https://www.semanticscholar.org/paper/fd0ab98e4f1058074c64325b980efdcfb0e0be00,Challenges in Smart Healthcare for Physical Rehabilitation,,,2021
98a1d22da2672b075dcba05c802d5ff36f7e2b03,https://www.semanticscholar.org/paper/98a1d22da2672b075dcba05c802d5ff36f7e2b03,Serious-Games-Based Exercises for Arthroplasty Rehabilitation,A usability study between a simple and a gamified serious game environment is presented to supports therapeutic exercises for patients with hip replacement. The first one was developed in JavaScript and the second one in Unity 3D. The level of realism of the games is higher in the latter than in the former implementation. Both use a motion detection device to capture the flexion points of each body articulation. 30 subjects tested the usability of the environments while patients perform the hip abduction exercise through the System Usability Scale. Results showed a good appreciation for the first environment and an excellent appreciation for the second environment. It suggests that a realistic game-based implementation of therapeutic exercises increases the engagement of the patients.,AHFE,2020
d5765a47fc089a7a463119dd8f7a00a1d442df1a,https://www.semanticscholar.org/paper/d5765a47fc089a7a463119dd8f7a00a1d442df1a,End-user adaptable technologies for rehabilitation: a systematic literature review,"Studies on end-user adaptable applications for rehabilitation aim to offer exercises to patients based on their therapeutic goals and individual advances. The process of adapting the applications is usually done by therapists, who have the clinical knowledge necessary for the effective design of the exercises; thus, their participation is essential in this process. In this sense, it is crucial that studies on adaptable applications consider their relevance for various users: patients who use an application (potential end users) and therapists who perform the process of adapting the application (end users). This study aims, through a systematic review, to identify how the use of adaptable applications has contributed, in the context of rehabilitation, not only to the treatment of patients but also to therapists in their work, in addition to identifying how they have addressed the process of adaptation and extension of the applications. A total of 28 studies from four electronic databases were considered and analyzed. The results indicate promising benefits for patients and some benefits that support the therapist’s work. However, there are some difficulties faced by therapists in the use and adoption of the applications. Further studies on the impact of adaptable applications in view of the end users (therapists adapting the applications) are needed. A longer-term follow-up is required to evaluate the treatment outcomes in the patients and improve the required aspects according to therapeutic contexts.",Universal Access in the Information Society,2020
c9bd5934e3a5f4d9bf6823d18488cc463f9f56d2,https://www.semanticscholar.org/paper/c9bd5934e3a5f4d9bf6823d18488cc463f9f56d2,Raptor: A Design of a Drain Inspection Robot,"Frequent inspections are essential for drains to maintain proper function to ensure public health and safety. Robots have been developed to aid the drain inspection process. However, existing robots designed for drain inspection require improvements in their design and autonomy. This paper proposes a novel design of a drain inspection robot named Raptor. The robot has been designed with a manually reconfigurable wheel axle mechanism, which allows the change of ground clearance height. Design aspects of the robot, such as mechanical design, control architecture and autonomy functions, are comprehensively described in the paper, and insights are included. Maintaining the robot’s position in the middle of a drain when moving along the drain is essential for the inspection process. Thus, a fuzzy logic controller has been introduced to the robot to cater to this demand. Experiments have been conducted by deploying a prototype of the design to drain environments considering a set of diverse test scenarios. Experiment results show that the proposed controller effectively maintains the robot in the middle of a drain while moving along the drain. Therefore, the proposed robot design and the controller would be helpful in improving the productivity of robot-aided inspection of drains.",Sensors,2021
e089c880d56950c0fffa04db8e07ab609e495f62,https://www.semanticscholar.org/paper/e089c880d56950c0fffa04db8e07ab609e495f62,Drain Structural Defect Detection and Mapping Using AI-Enabled Reconfigurable Robot Raptor and IoRT Framework,"Human visual inspection of drains is laborious, time-consuming, and prone to accidents. This work presents an AI-enabled robot-assisted remote drain inspection and mapping framework using our in-house developed reconfigurable robot Raptor. The four-layer IoRT serves as a bridge between the users and the robots, through which seamless information sharing takes place. The Faster RCNN ResNet50, Faster RCNN ResNet101, and Faster RCNN Inception-ResNet-v2 deep learning frameworks were trained using a transfer learning scheme with six typical concrete defect classes and deployed in an IoRT framework remote defect detection task. The efficiency of the trained CNN algorithm and drain inspection robot Raptor was evaluated through various real-time drain inspection field trials using the SLAM technique. The experimental results indicate that robot’s maneuverability was stable, and its mapping and localization were also accurate in different drain types. Finally, for effective drain maintenance, the SLAM-based defect map was generated by fusing defect detection results in the lidar-SLAM map.",Sensors,2021
f09ce81d075d842c84dd521b4d2aa104c990313e,https://www.semanticscholar.org/paper/f09ce81d075d842c84dd521b4d2aa104c990313e,Remote drain inspection framework using the convolutional neural network and re-configurable robot Raptor,"Drain blockage is a crucial problem in the urban environment. It heavily affects the ecosystem and human health. Hence, routine drain inspection is essential for urban environment. Manual drain inspection is a tedious task and prone to accidents and water-borne diseases. This work presents a drain inspection framework using convolutional neural network (CNN) based object detection algorithm and in house developed reconfigurable teleoperated robot called ‘Raptor’. The CNN based object detection model was trained using a transfer learning scheme with our custom drain-blocking objects data-set. The efficiency of the trained CNN algorithm and drain inspection robot Raptor was evaluated through various real-time drain inspection field trial. The experimental results indicate that our trained object detection algorithm has detect and classified the drain blocking objects with 91.42% accuracy for both offline and online test images and is able to process 18 frames per second (FPS). Further, the maneuverability of the robot was evaluated from various open and closed drain environment. The field trial results ensure that the robot maneuverability was stable, and its mapping and localization is also accurate in a complex drain environment.",Scientific reports,2021
f1fa5e56e7162178198ad1399a96cff86a52e1d9,https://www.semanticscholar.org/paper/f1fa5e56e7162178198ad1399a96cff86a52e1d9,Automatic Compensation of the Positional Error Utilizing Localization Method in Pipe,"151 Published By: Blue Eyes Intelligence Engineering and Sciences Publication Retrieval Number: 100.1/ijrte.F5529039621 DOI:10.35940/ijrte.F5529.039621 Abstract: Since 1965, a numerous number of cities implementing sewerage systems have increased rapidly throughout Japan, and sewerage development is considered to be becoming more widespread in various regions. However, with the increase of management facilities, the aging of facilities for long-term use is becoming more and more apparent. The standard expected durability of these pipes is approximately 50 years, but there is a tendency and a risk that the number of collapsed roads will increase rapidly 30 years after the pipes are laid. Against this background, maintenance of drainage and sewage pipes is critical and must be carried out continuously. Therefore, in recent years, investigation using robots have been actively conducted in order to reduce manual workload of the workers. However, these robots have a large-scale system as a whole, and as a result, they are poorly maintainable and expensive. Therefore, in this research, I have developed an autonomous and portable pipe inspection robot through the know-how on rescue robots which I have studied so far. However, for inspections using a pipe inspection robot, there is always the risk that the robot itself will tip over due to steps or small gaps at the joints of the pipes or slips caused by sludge. Therefore, to prevent tumbles and rollovers of the robot, I propose a localization method only by straight-driving control without relying on hardware. In addition, taking possible slips inside pipes into account, this method utilizes only acceleration sensor. In this study, localization method using only accelerometer mounted on the robot, which focuses on the relation between the pipe and the contact point of the tires, was shown as well as presenting a method using numerical analysis to derive the estimated values. Furthermore, it was confirmed that the estimation was stable as a result of an estimation experiment using autonomous small pipe inspection robot with and without a gradient (approx. 4/100) of a pipe, with a diameter of 189mm.",,2021
ba6b41f7587efeb018376e2b695552863d21afc7,https://www.semanticscholar.org/paper/ba6b41f7587efeb018376e2b695552863d21afc7,Development of a folding arm on an articulated mobile robot for plant disaster prevention,"Abstract In this work, we develop a folding arm on an articulated mobile robot to inspect an industrial plant. The design targets of the arm, its operations, measurement ability, and mobility, were set for the task of inspecting an industrial plant. To accomplish the targets, we designed the folding arm considering both accessibility to high locations and the mobility of the articulated mobile robot to which it is attached. The arm has links, joints, dummy wheels, and sensors and enables the robot to which it is attached to manipulate objects, e.g. rotating valves, opening a door, or inspecting by accessing high locations. In addition, changing the posture of the arm and touching the dummy wheel in the arm to the surrounding terrain can reduce any negative effect of the arm on the robot's mobility when it encounters narrow spaces, stairs, steps, and trenches. The arm is controlled as a six degrees-of-freedom manipulator without redundancy by an operator who directly sets two joint angles. The effectiveness of the developed arm was demonstrated not only through experiments in a laboratory but also in a field test at the Plant Disaster Prevention Challenge of the World Robot Summit 2018. GRAPHICAL ABSTRACT",Adv. Robotics,2020
4f8a7b4ed38688a41d1c28e465025f703d7b19cb,https://www.semanticscholar.org/paper/4f8a7b4ed38688a41d1c28e465025f703d7b19cb,TOWARDS AUTONOMOUS MOTION OF THE PIRATE THROUGH CLOSED PIPE STRUCTURES D.M.G,,,2019
5ad8f34c2d873bd434c67bf092781e1b190c9eba,https://www.semanticscholar.org/paper/5ad8f34c2d873bd434c67bf092781e1b190c9eba,A Spiral Curve Gait Design for a Modular Snake Robot Moving on a Pipe,"Modular snake robot has the ability to maneuver narrow, complex, and unstructured environments. In recent years, Snake robot with 3-D locomotion has been studied by researchers for inspection of pipes, and stairs climbing etc. One of the effective approaches to accomplishing such complex tasks is by designing gaits for modular snake robot. In this paper, A Spiral curve gait along with rolling motion is proposed to adapt to the changes in the pipe diameter while moving on the pipe, which cannot be overcome by a simple helical rolling motion. The joint angles are calculated using Bellow’s model, based on the curvature and torsion of the backbone curve. We validated the proposed gait by simulating thirty degrees of freedom modular snake robot in Open Dynamics Engine simulator.","International Journal of Control, Automation and Systems",2019
9534c8c62e7ec5ab9acfa902d409cd5ba8b3bfbb,https://www.semanticscholar.org/paper/9534c8c62e7ec5ab9acfa902d409cd5ba8b3bfbb,Task-Space Control of Articulated Mobile Robots With a Soft Gripper for Operations,"A task-space method is presented for the control of a head-raising articulated mobile robot, allowing the trajectory tracking of a tip of a gripper located on the head of the robot in various operations, e.g., picking up an object and rotating a valve. If the robot cannot continue moving because it reaches a joint angle limit, the robot moves away from the joint limit and changes posture by switching the allocation of lifted/grounded wheels. An articulated mobile robot with a gripper that can grasp objects using jamming transition was developed, and experiments were conducted to demonstrate the effectiveness of the proposed controller in operations.",IEEE Transactions on Robotics,2019
1123c9fde6041659a02950ac230752cc83815e2f,https://www.semanticscholar.org/paper/1123c9fde6041659a02950ac230752cc83815e2f,Development and Control of Articulated Mobile Robot for Climbing Steep Stairs,"In this paper, we develop an articulated mobile robot that can climb stairs, and also move in narrow spaces and on 3-D terrain. This paper presents two control methods for this robot. The first is a 3-D steering method that is used to adapt the robot to the surrounding terrain. In this method, the robot relaxes its joints, allowing it to adapt to the terrain using its own weight, and then, resumes its motion employing the follow-the-leader method. The second control method is the semi-autonomous stair climbing method. In this method, the robot connects with the treads of the stairs using a body called a connecting part, and then shifts the connecting part from its head to its tail. The robot then uses the sensor information to shift the connecting part with appropriate timing. The robot can climb stairs using this method even if the stairs are steep, and the sizes of the riser and the tread of the stairs are unknown. Experiments are performed to demonstrate the effectiveness of the proposed methods and the developed robot.",IEEE/ASME Transactions on Mechatronics,2018
a2014bb1b67f61c7bd20cf2cda494b44f1894a26,https://www.semanticscholar.org/paper/a2014bb1b67f61c7bd20cf2cda494b44f1894a26,"Tarantula: Design, Modeling, and Kinematic Identification of a Quadruped Wheeled Robot",This paper firstly presents the design and modeling of a quadruped wheeled robot named Tarantula. It has four legs each having four degrees of freedom with a proximal end attached to the trunk and the wheels for locomotion connected at the distal end. The two legs in the front and two at the back are actuated using two motors which are placed inside the trunk for simultaneous abduction or adduction. It is designed to manually reconfigure its topology as per the cross-sections of the drainage system. The bi-directional suspension system is designed using a single damper to prevent the trunk and inside components from shock. Formulation for kinematics of the wheels that is coupled with the kinematics of each leg is presented. We proposed the cost-effective method which is also an on-site approach to estimate the kinematic parameters and the effective trunk dimension after assembly of the quadruped robot using the monocular camera and ArUco markers instead of high-end devices like a laser tracker or coordinate measurement machine. The measurement technique is evaluated experimentally and the same set up was used for trajectory tracking of the Tarantula. The experimental method for the kinematic identification presented here can be easily extended to the other mobile robots with serial architecture designed legs.,Applied Sciences,2018
a7aadf240e45118108d2be5afff39408ce07af51,https://www.semanticscholar.org/paper/a7aadf240e45118108d2be5afff39408ce07af51,Design of a multilink-articulated wheeled pipeline inspection robot using only passive elastic joints,"Abstract This paper presents a multilink-articulated robot with omni and hemispherical wheels (AIRo-2.1) for inspecting and exploring pipelines. To quickly adapt to winding pipes, holonomic rolling movement without moving forward and backward is useful. However, this requires the rolling actuators to replace the driving actuators at the expense of the driving force. Furthermore, so far the number of driving wheels and torsion springs, magnitude of driving forces, stiffness and natural angle of the spring that are required to adapt to various pipelines have not been clarified. In this paper, we investigate the possibility of high maneuverability of multilink-articulated robots in winding pipes with as few driving actuators as possible and only elastic joints (torsion springs) for body bending. We further validate its effectiveness by experimental verification. Graphical Abstract",Adv. Robotics,2018
be3ab5ee0f5deb16139a8244733d636f69d32f69,https://www.semanticscholar.org/paper/be3ab5ee0f5deb16139a8244733d636f69d32f69,"Robots Hiper-Redundantes: Clasificación, Estado del Arte y Problemática","Los robots hiper-redundantes son aquellos que tienen un número muy elevado de grados de libertad. En su uso cotidiano, la redundancia es referida para indicar una repetición o un uso excesivo de un concepto. En el campo de la robótica, la redundancia puede ofrecer numerosos beneficios frente a los robots convencionales. Los robots hiper-redundantes poseen una mayor habilidad para sortear obstáculos, son tolerantes a fallos en algunas de sus articulaciones y también pueden ofrecer ventajas cinemáticas. En este artículo se presentan los conceptos generales para entender este tipo de robots, así como una clasificación de los mismos, su potencial, su problemática y su evolución a lo largo de la historia.",Revista Iberoamericana de Automática e Informática industrial,2018
3ba357e5c449bc2a633bac7054c47368e0ee5e22,https://www.semanticscholar.org/paper/3ba357e5c449bc2a633bac7054c47368e0ee5e22,Development of a small autonomous pipe inspection robot (Modularization of hardware using the technique of wooden mosaic work),,,2016
7f3155950c5440a6a203e4ef0bf2c7e1d0cdc48c,https://www.semanticscholar.org/paper/7f3155950c5440a6a203e4ef0bf2c7e1d0cdc48c,Sensors in modular robotics for pipeline inspection : design and test of erekobot- σ module,"Pipelines still are the most efficient, safe, ecological and economical environmental to transport crude oil over long distances. However, the transported oil and the environment in which the pipeline is located may corrode the metal to the point of failure, affecting not only production but also the environment. In addition, activities such as inspection and maintenance are more complex due to difficult access – exposure to toxins, a wide variety of terrains and the special cloths are just some of the challenges. Therefore, pipelines require processes recurrent and autonomous, which motivates the development of new technologies: the machinery of inspection should be cheap, robust and versatile for maintenance, cleaning, removal of fluids, product separation and inspection. The reconfigurable modular robots are autonomous machines with variable morphology and, with the reorganization of the connectivity of parts (called modules), this architecture offers a greater degree of flexibility and fault tolerance at a lower cost. Because of its low cost, robustness and versatility reconfigurable modular robots can perform inspection tasks and reduce production costs in the Oil and Oil Industry. The objective of this work is to design, build and test a module of a reconfigurable modular robot with sensors for inspection in pipelines, called ErekoBot. Each module must have the ability to estimate its own pose, detect an obstacle and align yourself with a plan (simulating a pipe). In this work, the most suitable sensors for ErekoBot were chosen: four infrared sensors and an inertial measurement unit. After the definition of the sensors, the complete module was designed and its prototype was built, considering shape, size, weight, electronic circuit, position of components and material. Tests with the prototype has shown that the module is capable of (1) to estimate its own orientation, (2) detecting the presence of obstacles and (3) align with a plane. These abilities are sufficient to allow a situation where the robot must move moved through a pipeline, avoid obstacles and stop at a specific position to perform an inspection inside the tube.",,2015
14b23dfc7cf552bd4bd0e35e929afce6174e808a,https://www.semanticscholar.org/paper/14b23dfc7cf552bd4bd0e35e929afce6174e808a,Mechanism Design and Manipulating Algorithm for Orientation Changing Module with Three Flexible Links,"This paper presents mechanism and control algorithm for inch worm type in-pipe robot using three helical springs. Control algorithm is based on experiment result and length of three spring are derived from desired position of top module. A feasibility of proposed mechanism is verified by comparing between ellipse model and position of top module, and it shows that proposed mechanism can steer properly.",,2014
678dc38e55f375f3a97db70b664e61776ecf8b3f,https://www.semanticscholar.org/paper/678dc38e55f375f3a97db70b664e61776ecf8b3f,Hypermobile Robots – the Survey,"This article presents a survey on hypermobile robots – a group of articulated mobile robots that typically comprise of several segments with powered wheels, tracks, or legs to propel the vehicle forward. Segments are connected by 2- or 3-degree-of-freedom (DOF) joints that may or may not be powered and provide better mobility as compared with regular mobile robots. The origins are analyzed and over 14 projects are compared in order to find the best methodology of designing and developing hypermobile robots.",J. Intell. Robotic Syst.,2014
810a619491d068d00c9a5678b8dafd30ffeb77c7,https://www.semanticscholar.org/paper/810a619491d068d00c9a5678b8dafd30ffeb77c7,Sensors in Reconfigurable Modular Robot for Pipeline Inspection: Design and Tests of a Prototype,"Pipeline inspections are essential for an updated diagnosis in Oil and Gas Industry, but manual inspection in remote areas implies great expenses in the long term. Therefore, this process optimization requires autonomous and versatile systems, such as Self-reconfigurable Modular Robots (SMR). The SMR are autonomous machines with variable morphology, therefore they have the potential to deal with this kind of problem. Reorganizing its parts connectivities, SMR offer major flexibility and tolerance to failure with a low cost. This work aims to present a review of the most recent SMR and design a low cost Reconfigurable Modular Robot with embedded sensors suitable for pipelines inspection, which reports the presence of obstacles and the position/orientation of each robot in the system. At a typical scenario of leakage in pipelines, a self-reconfigurable modular robot reduces costs such as production loss, manual inspections, repairs and maintenance at pipelines. This area of robotics promises such a versatile system that in a near future it can change the processes automation of inspection, repair and maintenance at remote environments, as pipelines.",2014 Joint Conference on Robotics: SBR-LARS Robotics Symposium and Robocontrol,2014
91049f8cfc9c326b1c3c3c29b4a5f1b972d8150b,https://www.semanticscholar.org/paper/91049f8cfc9c326b1c3c3c29b4a5f1b972d8150b,Design of an inspection robot for small diameter gas distribution mains,"The gas distribution network in the Netherlands has a length of roughly 100.000 km in urban areas. This network needs to be monitored constantly and segments need to be replaced when the risks of leaks increase. Since no information can be obtained from inse the network, in this thesis the design of a robot which can move (autonomously) through the gas distribution network for inspection is investigated. Three prototypes have been realised. The design of a propulsion mechanism depends strongly on the layout of the gas distribution network. The most important aspects are long stretches of pipe (tens of metres), a diameter range of 63 mm to 125 mm, (mitre) bends, T-joints and inclinations up to 30◦. The design consists of a wheeled robot ‘snake’ consisting of a number of modules which can be used as two clamping V-shapes. The central module is a rotation joint which can be used to change the orientation of the robot in a pipe. To reduce the amount of wiring, the electronic system has been distributed over the robot segments. A master controller is added which communicates to these distributed ’slave nodes’ via a serial bus. Also energy for propulsion is provided through this bus. A camera system has been developed which can be used for both pipe assessment and navigation. The camera system uses a laser projector which projects a cone (circle) on the inside of the pipe. Deformations of the pipe and obstacles such as bends and T-joints show up as deviations of the captured circle shape. The first prototype has been designed and produced in a ‘conventional’ way which took a long time and missed some crucial steps in integration. The second and third prototype have been designed and produced using `digital fabrication' tools (3D printing, laser cutting). The differences in design and production between the first prototype and the subsequent prototypes can be used to describe the importance of accessibility, visibility and availability of these fabrication tools as condition for fruitful usage.",,2014
aeb29888db6a3bed5d6c40beb989712715d7c381,https://www.semanticscholar.org/paper/aeb29888db6a3bed5d6c40beb989712715d7c381,Region-Guarding Problem in 3-D Areas,"This chapter studies the optimal inspection of autonomous robots in a complex pipeline system. We solve a 3-D region-guarding problem to suggest the necessary inspection spots. The proposed hierarchical integer linear programming (HILP) optimization algorithm seeks the fewest spots necessary to cover the entire given 3-D region. Unlike most existing pipeline inspection systems that focus on designing mobility and control of the explore robots, this chapter focuses on global planning of the thorough and automatic inspection of a complex environment. We demonstrate the efficacy of the computation framework using a simulated environment, where scanned pipelines and existing leaks, clogs, and deformation can be thoroughly detected by an autonomous prototype robot.",,2014
cd2ee38dfbb871764d643f96a9aba53a42611a1e,https://www.semanticscholar.org/paper/cd2ee38dfbb871764d643f96a9aba53a42611a1e,Sensors in Reconfigurable Modular Robot for Pipeline Inspection: Design and Tests of a Prototype,"Pipeline inspections are essential for an updated diagnosis in Oil and Gas Industry, but manual inspection in remote areas implies great expenses in the long term. Therefore, this process optimization requires autonomous and versatile systems, such as Self-reconfigurable Modular Robots (SMR). The SMR are autonomous machines with variable morphology, therefore they have the potential to deal with this kind of problem. Reorganizing its parts connectivities, SMR offer major flexibility and tolerance to failure with a low cost. This work aims to present a review of the most recent SMR and design a low cost Reconfigurable Modular Robot with embedded sensors suitable for pipelines inspection, which reports the presence of obstacles and the position/orientation of each robot in the system. At a typical scenario of leakage in pipelines, a self-reconfigurable modular robot reduces costs such as production loss, manual inspections, repairs and maintenance at pipelines. This area of robotics promises such a versatile system that in a near future it can change the processes automation of inspection, repair and maintenance at remote environments, as pipelines.",,2014
7eec7eedde7a9c4cfe33a1869d39510f6d371b64,https://www.semanticscholar.org/paper/7eec7eedde7a9c4cfe33a1869d39510f6d371b64,Optimizing pyramid visibiliy coverage for autonomous robots in 3D environment,"This paper studies the optimal visibility coverage for autonomous robots in complex 3D environments. The perception sensor equipped on an inspection robot usually has a pyramid shaped visible range with limited distance and angle. Finding the optimal pyramid visibility coverage for a given 3D region is NP hard; this paper presents an effective progressive integer linear programming algorithm to compute an approximate solution. Our framework allows the user to specify a coverage rate parameter to balance the percentage of visibility and the required guarding points for the given region. The algorithm is assessed in a simulated 3D pipeline environment and demonstrated promising for detecting leaks, clogs, and deformation of the pipes.",2013 8th International Conference on Computer Science & Education,2013
ae58328f79b3d9599d01dc09b93588f1d54272f7,https://www.semanticscholar.org/paper/ae58328f79b3d9599d01dc09b93588f1d54272f7,Optimizing pyramid visibiliy coverage for autonomous robots in 3D environment,"This paper studies the optimal visibility coverage for autonomous robots in complex 3D environments. The perception sensor equipped on an inspection robot usually has a pyramid shaped visible range with limited distance and angle. Finding the optimal pyramid visibility coverage for a given 3D region is NP hard; this paper presents an effective progressive integer linear programming algorithm to compute an approximate solution. Our framework allows the user to specify a coverage rate parameter to balance the percentage of visibility and the required guarding points for the given region. The algorithm is assessed in a simulated 3D pipeline environment and demonstrated promising for detecting leaks, clogs, and deformation of the pipes.",ICCSE 2013,2013
b00b0360db4d367896a047c91c5569afc2b5c09b,https://www.semanticscholar.org/paper/b00b0360db4d367896a047c91c5569afc2b5c09b,Design and control method for a high-mobility in-pipe robot with flexible links,"Purpose – The purpose of this paper is to propose a high‐mobility in‐pipe robot platform and its navigation strategy for navigating in T‐branch pipes efficiently.Design/methodology/approach – For high mobility, this robot is developed based on inchworm locomotion. An extensor mechanism with flexible links and clamper mechanisms enable the robot to conduct both steering and inchworm locomotion. The locomotion of the robot is modeled based on a pseudo‐rigid‐body model. From the developed model, this paper introduces a navigation strategy based on defining relay points and generating a path from a main pipe to a T‐branch pipe.Findings – With this navigation strategy, the robot can avoid collisions and enter T‐branch pipes effectively. The path generation algorithm is verified by experiment. In addition, both the navigation strategy and mobility of the robot are demonstrated by experiments conducted in a commercial pipe configuration.Originality/value – This paper describes the mechanism of an inchworm‐type i...",Ind. Robot,2013
b18a142ca5d03f4085282814878aa30541a2a5c9,https://www.semanticscholar.org/paper/b18a142ca5d03f4085282814878aa30541a2a5c9,Hierarchical Control of Limbless Locomotion Using a Bio-inspired CPG Model,"Limbless robots have the potential ability to perform various highly efficient movements in different environments, taking advantage of the features of limbless locomotion, such as a low center of gravity, a large contact area and a distributed mass. This thesis deals with the locomotion control of limbless robots, concentrating specifically on the study of a hierarchical control architecture as steps toward developing limbless robots capable of 3D locomotion, fast reflex responses and sophisticated responses to environmental stimuli. First, an overview of limbless robots is presented. Various limbless robots found in the literature are investigated. The survey not only introduces some potential applications for limbless robots, but also establishes a classification of limbless locomotion according to the limbless robots\\\' configurations and auxiliary equipment. Moreover, different approaches to autonomously generate motion patterns for limbless robots are discussed. One type of control approaches based on Central Pattern Generators (CPGs) is emphasized, since it is ideally suited to being applied to a hierarchical control architecture. Then, a bio-inspired CPG model is proposed. The key problem for developing such a hierarchical control architecture is how to design a CPG based controller that can not only generate various gaits, but also provide a solution for realizing reflex mechanisms as well as integrating sensory feedback. To this end, a CPG model inspired by the neuronal circuit diagram in the spinal cord of swimming lampreys is designed. A set of interneurons described with sigmoid functions and leaky integrators is incorporated into the design of the neural oscillator for rhythmic signal generation. Furthermore, according to the connection between neural oscillators, a chained type and a cyclic type of CPG circuits are developed. The chained type CPG circuit is used for generating traveling waves between oscillators, while the cyclic type CPG circuit is used for producing synchronization and maintenance activities. Through numerical simulations, the control parameters over relevant characteristics of the two types of CPG circuits are studied in detail. Next, the proposed CPG model is further designed for limbless gait implementation. Considering the configuration of limbless robots with pitch modules and yaw modules connected alternatively, two CPG circuits are applied to the pitch grouped modules and the yaw grouped modules, respectively. Both the necessary conditions for cooperation between the two CPG circuits and the control parameters for fast limbless locomotion are investigated. Four types of limbless gaits, i.e. side winding, rolling, turning and flapping are realized. Results of simulations and experiments show the effectiveness of the proposed CPG circuits in generating limbless locomotion. After that, in order to realize fast sensory reflex responses, the concept of both sensory neurons and reflex arcs are utilized. Since the proposed CPG model is derived from neural circuit in the spinal cord of lampreys and the existence of sensory neurons in lampreys has been proven, it is simple and natural to add sensory neurons into the proposed CPG model at the neuronal level. Based on the design of the sensory neurons, a reflex mechanism taking advantage of reflex arcs forms short pathways to bridge external stimuli and the CPG model. Thus fast responses can be made when the external stimuli are afferent to the CPG model. A ball hitting experiment and a corridor passing experiment confirm the feasibility of the reflex mechanism. Finally, the development of sophisticated responses to environmental stimuli is presented. A framework that combines the CPG model with a learning method is proposed for achieving adaptive limbless locomotion. The key issue of the framework is to find a mapping that converts external stimuli to proper sensory input, so as to modify the output of the CPG model and thus enable the limbless robot to adapt to environments. Two types of learning methods, i.e. a genetic algorithm (GA) based method and a reinforcement learning (RL) based method are applied to the framework, respectively. Through a slope climbing experiment, it is verified that both of them can achieve adaptive limbless locomotion. Furthermore, the performance of adaptive limbless locomotion under the two methods is compared and analyzed, which provides future work with the possible solutions for promoting the performance of adaptive limbless locomotion. From the results of simulations and experiments, the hierarchical control architecture is confirmed to be a solid platform for improving the locomotive behaviors of limbless robots.",,2013
c6a6a06bed0f1de986fa5886a613023205a5e124,https://www.semanticscholar.org/paper/c6a6a06bed0f1de986fa5886a613023205a5e124,A snake-like robot for real-world inspection applications (the design and control of a practical active cord mechanism),"In order to inspect narrow and unstructured environments such as disaster sites, snake-like robots should have rugged construction, but at the same time be sufficiently sensitive to detect contact with their environments. In addition, control which allows the robot to adapt to its environment is also essential. Thus, we studied both design and control of snake-like robots for real-world inspection application, and through this developed our new prototype named ‘ACM-R4.1’. The ACM-R4.1 integrated a torque sensing function, a camera system, dust- and water-proofing, a mechanical torque limiter, and terrain adaptive control into its compact body. Particularly, the torque sensing system and the terrain adaptive control based on that allows us to operate the robot in challenging environment without observing the robot directly. We also showed the feasibility of our concept through the testing of the ACM-R4.1. In this paper, we describe the concept design of a snake-like robot for real-world inspection application and detailed design and experiments of the ACM-R4.1.",Adv. Robotics,2013
71134cbb04f4a71b981f987c10b5f108fa548962,https://www.semanticscholar.org/paper/71134cbb04f4a71b981f987c10b5f108fa548962,Design considerations of robotic system for cleaning and inspection of large-diameter sewers,"On behalf of the Emschergenossenschaft, a public wastewater utility based in Essen, Germany, the Fraunhofer Institute for Factory Operation and Automation (IFF) in Magdeburg has developed a novel robotic system, the damage measuring and cleaning system (SVM-RS), for cleaning and inspecting large-diameter sewers that are partially filled and in normal operation. The SVM-RS was specifically designed and built for use in the Emscher sewer system and employs a multisensor approach for a high-resolution inspection of the pipe, both above and below the water. Furthermore, robotics technologies are used in combination with traditional high-pressure cleaning techniques to achieve high-quality cleaning results. In addition to the hardware design, a number of software developments in the areas of software architecture, image processing, and data fusion for understanding and presenting the data, as well as teleoperation techniques, have been carried out in the course of the project. Here automatic detection of damage as well as other features present in the environment has proven to be of importance. Design considerations and solutions for individual components of the cleaning and inspection are described within the context of the whole system, and the results of specific tests and experiments are presented. © 2011 Wiley Periodicals, Inc.",J. Field Robotics,2012
887529bc33e3334d63548c55237fff7909eab7ef,https://www.semanticscholar.org/paper/887529bc33e3334d63548c55237fff7909eab7ef,On Optimizing Autonomous Pipeline Inspection,"This paper studies the optimal inspection of autonomous robots in a complex pipeline system. We solve a 3-D region-guarding problem to suggest the necessary inspection spots. The proposed hierarchical integer linear programming optimization algorithm seeks the fewest spots necessary to cover the entire given 3-D region. Unlike most existing pipeline inspection systems that focus on designing mobility and control of the explore robots, this paper focuses on global planning of the thorough and automatic inspection of a complex environment. We demonstrate the efficacy of the computation framework using a simulated environment, where scanned pipelines and existing leaks, clogs, and deformation can be thoroughly detected by an autonomous prototype robot.",IEEE Transactions on Robotics,2012
904d9b1baf3304b22d6f7f95d6dcd27327853f54,https://www.semanticscholar.org/paper/904d9b1baf3304b22d6f7f95d6dcd27327853f54,A Review: Hybrid Locomotion of In-pipe Inspection Robot,"Abstract In the past five years, researchers have improvised the existing in-pipe inspection robots by developing hybrid locomotion by combining two or more propulsion mechanism in achieving robust but yet flexible robot platform. In this paper, several hybrid robots have been reviewed and categorized according to their implemented locomotion system. The hybrid locomotion systems are caterpillar wall-pressed type, wheeled wall-pressed type and wheeled wall-pressing screw type. Each hybrid locomotion system is developed according to distinct design requirements for specific environment and might be not suitable for other application. The aim of this review is to highlight the current innovation of in-pipe robot for inspection. Based on the study, wall pressed type is the most popular main locomotion system in in-pipe robot development. Most of the prototypes are able to travel into branches with the same diameter as the pipe. Integration of caterpillar wheel gives more advantage in preventing motion singularity problem while surpassing branches. On the other hand, wheeled wall-pressed type provides advantage in high speed mobility. Wheeled wall pressing screw type gives the best navigation in curved pipe. None of these inventions show their ability in navigating bigger pipe to smaller branches.",ISR 2012,2012
b096cbc1df3b86038d87c0d24774784ee93568f5,https://www.semanticscholar.org/paper/b096cbc1df3b86038d87c0d24774784ee93568f5,17 Hypermobile Robots,"Active joints Hypermobile robots: • Koryu-I and Koryu-II (Hirose, 1993) • Snake 2 (Klaassen and Paap, 1999) • Soryu (Takayama and Hirose, 2000) • Millibot Train (Brown et al., 2002) • Moira (Osuka & Kitajima, 2003) • Pipeline Explorer (Schempf et al., 2003) • Omnis family (Granosik et al., 2005) • MAKRO plus (Streich & Adria, 2004) • KOHGA (Kamegawa et al., 2004) • JL-I (Zhang et al., 2006) • Wheeeler (Pytasz & Granosik, 2006) Snake-like robots: • Active Cord Mechanism whole family of robots (Hirose, 1993) • Slim Slime Robot (Ohno & Hirose, 2000) • Snake robots by Dr. Gavin Miller (snakerobots.com) • Perambulator-II (Ye et al., 2007)",,2012
f0f2ae349c9aef613d7e75eb6d3e786c7d8c426f,https://www.semanticscholar.org/paper/f0f2ae349c9aef613d7e75eb6d3e786c7d8c426f,Control Methods for Wheeeler – The Hypermobile Robot,"In this paper we compare two methods for synchronizing movements of segments of the hypermobile robot Wheeeler. Hypermobile robots are a subset of articulated mobile machines and one of the most important problems with controlling them is appropriate coordination of multiple actuators. One of the most popular methods to do this job is the follow-the-leader approach; another possible method is adaptation of the n-trailer kinematics. We present some details of the latter approach and then show a few tests realized in a simulation environment. Unlike in other papers, our robot is controlled in the teleoperation mode instead of following a predefined trajectory. Nevertheless, we propose appropriate measures to compare the results of several simulation tests.",,2012
0ce472098e85b700d68179762f98cbdbd1f17e8b,https://www.semanticscholar.org/paper/0ce472098e85b700d68179762f98cbdbd1f17e8b,Snake-like active wheel robot ACM-R4.1 with joint torque sensor and limiter,"In order to inspect inside narrow and unstructured environments, the snake-like robots should have ruggedness of the structure and at the same time function to detect the contact of the body to the environments. This paper proposes a snake-like active wheel robot named “ACM-R4.1” with torque sensor and torque limiter on each of the joints. Introduced torque sensor is composed of 2 thin ring plates holding steel balls in the oval cavities in between and a rubber ring producing compressing force of the thin ring plates in the narrow gap of a joint. Applied torque of the joint produces small sliding motion of the ball inside oval cavities and thus measurement of the small displacement of these plates enable to detect the applied torque. Overload-protection to the joint actuator is made by the sliding motion of the rubber which acts after the ball motion in the cavities and they hit the end of cavities. We made theoretical consideration of design of the torque sensor and did torque measurement experiments by using constructed snake-like active wheel robot ACM-R4.1. We also demonstrated the terrain adaptive motion of ACM-R4.1 by using the torque sensors.",2011 IEEE/RSJ International Conference on Intelligent Robots and Systems,2011
2cdb55252b9a55339248acf3a32259661a05e1a2,https://www.semanticscholar.org/paper/2cdb55252b9a55339248acf3a32259661a05e1a2,Robotlæring for slangeroboter,Developing a control strategy for a wheeled snake robot can be difficult given the number of parameters involved. In this thesis we have studied the use of a reinforcement learning framework to develop a control strategy that allows a wheeled snake to lift its head as much as possible. The learning process has been done using a simulator developed for SINTEF’s pipe inspection robot PIKo. The reinforcement learning methodology used has been CACLA with an RBF network as function approximator. Various alternatives have been proposed and used for the action space in simulations showing positive results. Issues with the simulator have been detected and workarounds proposed for them.,,2011
6ced25779751ecf90cbaff6ed9bdecf66e31b4dc,https://www.semanticscholar.org/paper/6ced25779751ecf90cbaff6ed9bdecf66e31b4dc,Development of an inspection robot for small diameter gas distribution mains,"This paper discusses the design of a mechanical structure of a miniature pipe inspection robot capable of moving through very small pipes (down to 41 mm inner diameter). The requirement to negotiate bends, T-joints and steep inclinations pose another set of strict design constraints. The proposed robot consists of a modular design (7 modules) with a relatively low number of active degrees of freedom. The system is using a novel clamping mechanism with a series-elastic drive. The design of this mechanism has resulted in a high spreading factor allowing the system to operate in a wide diameter range (63 mm to 125 mm outer diameter). In this paper the mechanical design requirements and control system will be discussed. Preliminary test results will be given.",2011 IEEE International Conference on Robotics and Automation,2011
a2dfcbce5f142fe2a0a9a7ea0e24f7242a88ab08,https://www.semanticscholar.org/paper/a2dfcbce5f142fe2a0a9a7ea0e24f7242a88ab08,Development of high mobility in-pipe inspection robot,"In this paper, we propose a steerable inchworm type in-pipe inspection robot. An extensor mechanism using continuum links makes the robot possible for both steering and inchworm locomotion. The robot has two clamper modules which are composed of a crank-slider mechanism. The mechanism makes the robot compact and adaptable to pipe diameter change from 205mm to 305mm. We also analyzed steering locomotion of the robot and propose a simple strategy for navigating in a T-branch pipe. The mechanisms and strategy are demonstrated by experiment.",2011 IEEE/SICE International Symposium on System Integration (SII),2011
ced24304f28c5cae926d08486f8eb252eb81bb80,https://www.semanticscholar.org/paper/ced24304f28c5cae926d08486f8eb252eb81bb80,An Optimization Algorithm for the NP-hard 3 D Gallery Guarding Problem and its Application on Autonomous Pipeline Inspection,"This paper introduces a hierarchical optimization algorithm to an open NP-hard 3D guarding problem for massive data sets. The proposed hierarchical integer linear programming (HILP) algorithm can find the fewest spots necessary to cover an entire given 3D region. Efficiently solving this problem can greatly benefit autonomous pipeline monitoring and inspections. Unlike most existing pipeline inspection systems that focus on designing mobility and control of the explore robots, this framework focuses on planning automatic and thorough inspection in a complex environment. We demonstrate its efficacy on a simulated system built upon scanned pipelines environments using our prototype robots, in which leaks, clogs, and deformation can be detected thoroughly.",,2011
ead4a35ce2b3f83ad8f23208e5f4d2cb509aa1eb,https://www.semanticscholar.org/paper/ead4a35ce2b3f83ad8f23208e5f4d2cb509aa1eb,"Hypermobile robots: concept,construction and control",,,2011
514021c79e5bbbbcbd82c96f10193aa94be81233,https://www.semanticscholar.org/paper/514021c79e5bbbbcbd82c96f10193aa94be81233,Modular Robotics and Locomotion: Application to Limbless Robots,"This dissertation discusses the locomotion of modular robots. It is focused specifically on the study of 1D topology configurations (called snakes or limbless robots). The problem to solve is how to coordinate the joint's movement so that modular robots can move both in one and two dimensions. A big challenge in robotics is the development of a very versatile robot with the full capability of moving on different terrains. This is especially important in applications where the environment is unknown in advance, such as the exploration of other planet's surfaces, navigation in hostile environments and search and rescue operations. Modular robotics offers the promise of increasing the versatility in locomotion by means of building robots from basic modules. Each configuration has its own locomotive characteristics that should be studied. If the robots have the ability to be self-reconfigurable, then they will be able to change their shapes and topology in order to select the best gait for every terrain and negotiate with different tasks. One kind of bio-inspired controllers for mobile robots used in the last decade are based on CPG (Central pattern generators), which are a specialized neurons that produce rhythms for controlling the muscle activities of animals. In the steady state CPG behave like fixed-frequency oscillators. For that reason, they can be replaced by a simplified model like sinusoidal generators. The main advantage is that they are extremely simple to implement and requires very few computing resources. Therefore, they can be implemented in low-end inexpensive microcontrollers. Moreover, the generators can also be realized directly as hardware components using either digital or analog electronics. In this dissertation a general classification of modular robots is established based on their topologies and types of connection. The hypothesis of using sinusoidal generators for controlling the locomotion of 1D pitch-pitch and pitch-yaw modular robots of any length is raised. The results show that this simple model is efficient and the gaits obtained are natural and smooth. It is shown that at least they can move in five different movements. Some of them are totally new and have not been previously studied or implemented by other researchers, from the best of our knowledge. In addition, the relationships between the generator's parameters and the robot kinematics have been obtained. Another problem is to find the minimal configurations for locomotion, which are the modular robots within the studied groups that have the minimum number of modules and are still capable of moving in one and two dimensions. This problem has been solved and the two minimal configurations are presented. Their kinematics models are studied throughout too. The experiments confirm that the solutions found to the coordination problem are valid for the locomotion of real mobile modular robots. Four kinds of modular robotic prototypes have been built using the identical Y1 modules, which have been designed specifically for this thesis. Finally the knowledge about the locomotion of pitch-pitch and pitch-yaw connecting modular robots has been summarized in 27 key principles.",,2008
d0ee48da308177d90666b2b3bdec2cfc884907e1,https://www.semanticscholar.org/paper/d0ee48da308177d90666b2b3bdec2cfc884907e1,Wheeeler - Hypermobile Robot,"We have designed and built the prototype of hyper redundant, articulated mobile robot propelled on wheels and therefore called - Wheeeler. In this paper we present progress in our project, focusing on modeling and prototyping phase. We show model of the robot built and verified in 3D simulator and proof-of-concept 3-segment device. Wheeeler is designed to operate in a rough terrain and fulfill tasks such as climbing up or down the stairs, going through trenches, avoiding or climbing over obstacles, operating in narrow, limited spaces like ventilation shafts. The major difficulty of control of hypermobile robots is synchronization of multiple actuators. Design of the high level control system, which can help human operator to intuitively steer this robot is the main goal of our project. In the further part of this paper we introduce communication and control architecture.",Eurobot Conference,2008
d9f7bdd804aa16699dc88f273f9bf1485b3a570a,https://www.semanticscholar.org/paper/d9f7bdd804aa16699dc88f273f9bf1485b3a570a,MODULAR ROBOTICS AND LOCOMOTION: APPLICATION TO LIMBLESS ROBOTS,,,2008
6e6ae08259b22ac769c9a81a62f9752eb2b9e732,https://www.semanticscholar.org/paper/6e6ae08259b22ac769c9a81a62f9752eb2b9e732,Applying CORBA Technology for the Teleoperation of Wheeeler,"In this paper, we present development of Wheeeler - the hyper mobile robot. Hyper mobile robots belong to the group of highly articulated robots, sometimes called “snake-like” or serpentine robots. Wheeeler has 7 segments driven by wheels and interconnected by 2 degrees- of-freedom joints (Fig. 28.1). This machine is expected to operate in rough terrain, traverse stairs and trenches, avoid obstacles, or climb over them, and also pass through tight spaces. Our project is in the simulation stage and currently we focus on the communication issues. Although, modeling and tests are performed in simulator (Webots 5 PRO) now, the same control software will work with real robot soon. In this paper, we shortly present the actual version of model; introduce the sensory suite and local controllers’ configuration. In the main paragraph we present the implementation of CORBA technology in client-server communication.",RoMoCo,2007
6ead6afb82e1289ec1d9abded475e92509a74060,https://www.semanticscholar.org/paper/6ead6afb82e1289ec1d9abded475e92509a74060,In-pipe robot for inspection and sampling tasks,"Purpose – To develop an in‐pipe robot to be used for inspecting pipes that are laid underneath a waste disposal site and for sampling sewage water leaking from holes around the pipe.Design/methodology/approach – The paper presents a compact design of the robot's mechanical and electronic systems, and develops a simple and practical method for determining the hole position using some characteristics of this in‐pipe robot.Findings – Development of a multi‐functional in‐pipe robot with elaborate design is feasible, and multiple trapezoidal‐shaped wheels have good capabilities of providing the robot large traction force and keeping the robot horizontal in pipeline. A good mechanical structure design can greatly reduce control and computation cost by using some specific features of the object system.Research limitations/implications – This study provides guidance for future design of multi‐functional in‐pipe robots.Practical implications – The combination of a vision system and a manipulator can perform in‐pip...",Ind. Robot,2007
96592e477bb29b3f8848cbcf08a8204bf42d8c40,https://www.semanticscholar.org/paper/96592e477bb29b3f8848cbcf08a8204bf42d8c40,A Historical Perspective of Legged Robots,"The objective of this paper is to present the evolution and the state-of-the-art in the area of legged locomotion systems. In a first phase different possibilities for implementing mobile robots are discussed, namely the case of artificial legged locomotion systems, while emphasizing their advantages and limitations. In a second phase a historical overview of the evolution of these systems is presented, bearing in mind several particular cases often considered as milestones of technological and scientific progress. After this historical timeline, some of the present-day systems are examined and their performance is analyzed. In a third phase the major areas of research and development that are presently being followed in the construction of legged robots are pointed out. Finally, some still unsolved problems that remain defying robotics research, are also addressed.",,2007
97158f289481e54a9b29216ac54e19024dac30f0,https://www.semanticscholar.org/paper/97158f289481e54a9b29216ac54e19024dac30f0,Serpentine Robots for Industrial Inspection and Surveillance,"¶ Urban search and rescue, industrial inspections, and military intelligence have one need in common: smallsized mobile robots that can travel across the rubble of a collapsed building, squeeze through small crawl-spaces to take measurements or perform visual inspections, and slither into the shelter of insurgents to gather intelligence. Some of these areas are not only difficult to reach, but may also present safety and health hazards to human inspectors. One species of mobile robots that promises to deliver such hypermobility is the so-called serpentine or snake robot (see Figure 1). Serpentine robots typically comprise of three or more rigid segments that are connected by 2or 3-degree-of-freedom (DOF) joints. The segments typically have powered wheels, tracks, or legs to propel the vehicle forward, while the joints may be powered or unpowered. Desired capabilities for such a robot are: • ability to traverse rugged terrain, such as concrete floors cluttered with debris, or unfinished floors such as those found on constructions sites; • ability to fit through small openings; • ability to climb up and over tall vertical steps;",,2006
df5a34d4900b24c31c55fe706805663188368fa4,https://www.semanticscholar.org/paper/df5a34d4900b24c31c55fe706805663188368fa4,An Overview of Legged Robots,"The objective of this paper is to present the evolution and the state-of-theart in the area of legged locomotion systems. In a first phase different possibilities for mobile robots are discussed, namely the case of artificial legged locomotion systems, while emphasizing their advantages and limitations. In a second phase an historical overview of the evolution of these systems is presented, bearing in mind several particular cases often considered as milestones on the technological and scientific progress. After this historical timeline, some of the present day systems are examined and their performance is analyzed. In a third phase are pointed out the major areas for research and development that are presently being followed in the construction of legged robots. Finally, some of the problems still unsolved, that remain defying robotics research, are also addressed.",,2006
7f47a51a51407401a586927b1865675dd83e4158,https://www.semanticscholar.org/paper/7f47a51a51407401a586927b1865675dd83e4158,Compliant motion of a multi-segmented inspection robot,"This paper presents a method to potentate the multi-segmented inspection robot Kairo-II to navigate in unstructured and dynamic environment. Previous methods for motion planning for such robots come from driving scenarios in highly structured areas. The virtual tube algorithm is introduced which enables a multi-segmented robot to range in such complex environment. Precise force feedback is required. Therefore, we present a sensor system which is based on strain-gauges technology. Information extracted by this sensor enables the trajectory planning algorithm to adapt its curve. Thus, the proposed system provides and evaluates key functions for compliant motion of a multi-segmented robot within unstructured environment.",2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2005
89fbaa0cacab3c7bbcd7e502be1fc19d6751194f,https://www.semanticscholar.org/paper/89fbaa0cacab3c7bbcd7e502be1fc19d6751194f,The OmniTread serpentine robot with pneumatic joint actuation,"This paper describes the design of a pneumatic joint actuation system for the OmniTread serpentine robot, developed at the University of Michigan. Serpentine robots are mobile robots with one unique characteristic: they have a very large ratio of length to diameter. To implement this unique shape, they usually have multiple segments connected by joints. Some serpentine robots provide legged, wheeled, or tracked propulsion, and, in addition, actuation for the joints. In this paper we present a detailed analysis of pneumatic integrated joint actuators (IJA) invented and built especially for serpentine robots. The IJA combines advantages of pneumatic bellows-like actuators with our proportional position and stiffness (PPS) control algorithm. Controllable stiffness is of crucial importance in serpentine robots, which require stiff joints to cross gaps and compliant joints to conform to rough terrain for effective propulsion. The paper also includes results of tests performed at the Southwest Research Institute.","Proceedings of the Fifth International Workshop on Robot Motion and Control, 2005. RoMoCo '05.",2005
185ae4eb08b9999a23e22e51da3d2ba4b082d17c,https://www.semanticscholar.org/paper/185ae4eb08b9999a23e22e51da3d2ba4b082d17c,AutoPhoto: Aesthetic Photo Capture using Reinforcement Learning,"The process of capturing a well-composed photo is difficult and it takes years of experience to master. We propose a novel pipeline for an autonomous agent to automatically capture an aesthetic photograph by navigating within a local region in a scene. Instead of classical optimization over heuristics such as the rule-of-thirds, we adopt a data-driven aesthetics estimator to assess photo quality. A reinforcement learning framework is used to optimize the model with respect to the learned aesthetics metric. We train our model in simulation with indoor scenes, and we demonstrate that our system can capture aesthetic photos in both simulation and real world environments on a ground robot. To our knowledge, this is the first system that can automatically explore an environment to capture an aesthetic photo with respect to a learned aesthetic estimator. Source code is at https://github.com/HadiZayer/AutoPhoto",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
667602368042dde787af25e9158a7ee05ea2e8a2,https://www.semanticscholar.org/paper/667602368042dde787af25e9158a7ee05ea2e8a2,Virtual Camera Layout Generation using a Reference Video,"We propose a method that generates a virtual camera layout of a 3D animation scene by following the cinematic intention of a reference video. From a reference video, cinematic features such as the start frame, end frame, framing, camera movement, and the visual features of the subjects are extracted automatically. The extracted information is used to generate the virtual camera layout, which resembles the camera layout of the reference video. Our method handles stylized as well as human characters with body proportions different from those of humans. We demonstrate the effectiveness of our approach with various reference videos and 3D animation scenes. The user evaluation results show that the generated layouts are comparable to layouts created by the artist, allowing us to assert that our method can provide effective assistance to both novice and professional users when positioning a virtual camera.",CHI,2021
b63ff071b3e954b4e009a09b05a2664cf344f867,https://www.semanticscholar.org/paper/b63ff071b3e954b4e009a09b05a2664cf344f867,Example-driven virtual cinematography by learning camera behaviors,"Designing a camera motion controller that has the capacity to move a virtual camera automatically in relation with contents of a 3D animation, in a cinematographic and principled way, is a complex and challenging task. Many cinematographic rules exist, yet practice shows there are significant stylistic variations in how these can be applied. In this paper, we propose an example-driven camera controller which can extract camera behaviors from an example film clip and re-apply the extracted behaviors to a 3D animation, through learning from a collection of camera motions. Our first technical contribution is the design of a low-dimensional cinematic feature space that captures the essence of a film's cinematic characteristics (camera angle and distance, screen composition and character configurations) and which is coupled with a neural network to automatically extract these cinematic characteristics from real film clips. Our second technical contribution is the design of a cascaded deep-learning architecture trained to (i) recognize a variety of camera motion behaviors from the extracted cinematic features, and (ii) predict the future motion of a virtual camera given a character 3D animation. We propose to rely on a Mixture of Experts (MoE) gating+prediction mechanism to ensure that distinct camera behaviors can be learned while ensuring generalization. We demonstrate the features of our approach through experiments that highlight (i) the quality of our cinematic feature extractor (ii) the capacity to learn a range of behaviors through the gating mechanism, and (iii) the ability to generate a variety of camera motions by applying different behaviors extracted from film clips. Such an example-driven approach offers a high level of controllability which opens new possibilities toward a deeper understanding of cinematographic style and enhanced possibilities in exploiting real film data in virtual environments.",ACM Trans. Graph.,2020
ce0f4ddecf693b023cba389d82b0be1d57af15d1,https://www.semanticscholar.org/paper/ce0f4ddecf693b023cba389d82b0be1d57af15d1,Can We Enable the Drone to be a Filmmaker?,"Drones are enabling new forms of cinematography. However, quadrotor cinematography requires accurate comprehension of the scene, technical skill of flying, artistic skill of composition and simultaneous realization of all the requirements in real time. These requirements could pose real challenge to drone amateurs because unsuitable camera viewpoint and motion could result in unpleasing visual composition and affect the target's visibility. In this paper, we propose a novel autonomous drone camera system which captures action scenes using proper camera viewpoint and motion. The key novelty is that our system can dynamically generate smooth drone camera trajectory associated with human movement while obeying visual composition principles. We evaluate the performance of our cinematography system on simulation and real scenario. The experimental results demonstrate that our system can capture more expressive video footage of human action than that of the state-of-the-art drone camera system. To the best of our knowledge, this is the first cinematography system that enables people to leverage the mobility of quadrotor to autonomously capture high-quality footage of action scene based on subject's movements.",ArXiv,2020
fc65a1a6306fc9734a54e0f5b67d551b33dae731,https://www.semanticscholar.org/paper/fc65a1a6306fc9734a54e0f5b67d551b33dae731,LookOut! Interactive Camera Gimbal Controller for Filming Long Takes,"The job of a camera operator is more challenging, and potentially dangerous, when filming long moving camera shots. Broadly, the operator must keep the actors in-frame while safely navigating around obstacles, and while fulfilling an artistic vision. We propose a unified hardware and software system that distributes some of the camera operator's burden, freeing them up to focus on safety and aesthetics during a take. Our real-time system provides a solo operator with end-to-end control, so they can balance on-set responsiveness to action vs planned storyboards and framing, while looking where they're going. By default, we film without a field monitor. Our LookOut system is built around a lightweight commodity camera gimbal mechanism, with heavy modifications to the controller, which would normally just provide active stabilization. Our control algorithm reacts to speech commands, video, and a pre-made script. Specifically, our automatic monitoring of the live video feed saves the operator from distractions. In pre-production, an artist uses our GUI to design a sequence of high-level camera ""behaviors."" Those can be specific, based on a storyboard, or looser objectives, such as ""frame both actors."" Then during filming, a machine-readable script, exported from the GUI, ties together with the sensor readings to drive the gimbal. To validate our algorithm, we compared tracking strategies, interfaces, and hardware protocols, and collected impressions from a) film-makers who used all aspects of our system, and b) film-makers who watched footage filmed using LookOut.",ArXiv,2020
1abdeafe4b6e36e2566ffc0054b2357c3929baae,https://www.semanticscholar.org/paper/1abdeafe4b6e36e2566ffc0054b2357c3929baae,One-Shot Imitation Filming of Human Motion Videos,"Imitation learning has been applied to mimic the operation of a human cameraman in several autonomous cinematography systems. To imitate different filming styles, existing methods train multiple models, where each model handles a particular style and requires a significant number of training samples. As a result, existing methods can hardly generalize to unseen styles. In this paper, we propose a framework, which can imitate a filming style by ""seeing"" only a single demonstration video of the same style, i.e., one-shot imitation filming. This is done by two key enabling techniques: 1) feature extraction of the filming style from the demo video, and 2) filming style transfer from the demo video to the new situation. We implement the approach with deep neural network and deploy it to a 6 degrees of freedom (DOF) real drone cinematography system by first predicting the future camera motions, and then converting them to the drone's control commands via an odometer. Our experimental results on extensive datasets and showcases exhibit significant improvements in our approach over conventional baselines and our approach can successfully mimic the footage with an unseen style.",ArXiv,2019
8acd1430287b63af6a3c17903fe01bef99991dc9,https://www.semanticscholar.org/paper/8acd1430287b63af6a3c17903fe01bef99991dc9,Third-Person Piloting: Increasing Situational Awareness using a Spatially Coupled Second Drone,"We propose Third-Person Piloting, a novel drone manipulation interface that increases situational awareness using an interactive third-person perspective from a second, spatially coupled drone. The pilot uses a controller with a manipulatable miniature drone. Our algorithm understands the relationship between the pilot's eye position and the miniature drone and ensures that the same spatial relationship is maintained between the two real drones in the sky. This allows the pilot to obtain various third-person perspectives by changing the orientation of the miniature drone while maintaining standard primary drone control using the conventional controller. We design and implement a working prototype with programmable drones and propose several representative operation scenarios. We gather user feedback to obtain the initial insights of our interface design from novices, advanced beginners, and experts. Our result suggests that the interactive third-person perspective provided by the second drone offers sufficient potential for increasing situational awareness and supporting their primary drone operations.",UIST,2019
e6debe8731daadf256ba4005fd291f85792885b4,https://www.semanticscholar.org/paper/e6debe8731daadf256ba4005fd291f85792885b4,Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography,"Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019
356fed2bd639ef4bb367cf994465b44d5bb4b2ed,https://www.semanticscholar.org/paper/356fed2bd639ef4bb367cf994465b44d5bb4b2ed,Complex system health analysis by the Graphical Evolutionary Hybrid Neuro-Observer (GNeuroObs),"Obtaining methodologies that enable predictive health monitoring of components degradation and the propagation of related effects across the overall system is a need when designing complex systems (such as autonomous vehicles, robotic systems, and aerospace platforms). In this paper, a current software development is presented for workflow generation and visualization to evaluate how component degradation impacts an entire system. Relevant technical aspects of this “Graphical Evolutionary Hybrid Neuro-Observer” (GNeuroObs) include: (a) highly accurate system modeling; (b) techniques for system level analysis; and (c) low level entity instantiations that builds on health monitoring and root cause analysis. The GNeuroObs is described with the application of a fuel subsystem. In that system, the methodology allows for describing interrelations among a set of heterogeneous sensors, where Health Monitoring algorithms are used to analyze failures in entities and propagation of effects across the system.",2016 IEEE AUTOTESTCON,2016
f57dfb53d3a7d49950665bf4aa68db1cf2675dc3,https://www.semanticscholar.org/paper/f57dfb53d3a7d49950665bf4aa68db1cf2675dc3,Validation Techniques for Sensor Data in Mobile Health Applications,"Mobile applications have become a must in every user’s smart device, and many of these applications make use of the device sensors’ to achieve its goal. Nevertheless, it remains fairly unknown to the user to which extent the data the applications use can be relied upon and, therefore, to which extent the output of a given application is trustworthy or not. To help developers and researchers and to provide a common ground of data validation algorithms and techniques, this paper presents a review of the most commonly used data validation algorithms, along with its usage scenarios, and proposes a classification for these algorithms. This paper also discusses the process of achieving statistical significance and trust for the desired output.",J. Sensors,2016
ecd853875e35c705250b3cebe261aa6358a405ea,https://www.semanticscholar.org/paper/ecd853875e35c705250b3cebe261aa6358a405ea,SOM with neighborhood step decay for motor current based diagnostics,"Embedded self-learning is a desired capability that can enhance autonomy in different types of unmanned systems. Autonomous diagnostics is an area of opportunity to deploy this capability, which allows for vehicle failure awareness and enables for other advantageous schemes such as fault tolerant control. In this paper, we present one subsystem of an ensemble of schemes that form the Enhanced Autonomous Health Monitoring System (EAHMS) designed to support NASA's Robotics, Tele-Robotics and Autonomous Systems Roadmap. The EAHMS is aimed to provide an integral framework to determine the operational condition of on-board sensors (odometry), actuators, and power systems. Within the EAHMS context, this paper outlines a method for diagnostics of a robotic vehicle mechanical mobility subsystem by motor current and vibration signature analysis based upon Self Organizing Maps (SOM) using an enhanced neighborhood step decay algorithm. The learning algorithm was tested for different learning rate functions and was applied to different training set cases. The resulting algorithm was used for conducting failure diagnostics in a testbed, where three types of transmission/motor mechanical failures were considered: (a) damaged chain link; (b) motor gearbox damage; and (c) damaged sprocket. A core goal of this diagnostic approach is to enhance a novel methodology called the embedded Collaborative Learning Engine (eCLE), which combines supervised and unsupervised learning synergistically to process new emerging data signatures. This technique for system enhancement and application results are described in this paper.","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",2014
771307f49e89e3977d5fe62c9a57baea15891c47,https://www.semanticscholar.org/paper/771307f49e89e3977d5fe62c9a57baea15891c47,Intelligent Distributed and Ubiquitous Health Management System: Data Storage and Processing,"We present here recent developments and results in data storage and processing for an Intelligent Distributed and Ubiquitous Health Management System. The system is designed to store and present data related to faults that may occur in distributed sensor and actuator networked systems. Such systems are common at NASA centers, industrial plants, and other distributed electro-mechanical systems. We show how sensor and actuator fault information can be stored and processed. We describe database development, communication with a Network Capable Application Processor (NCAP), and interfacing with a smart phone including smart phone application developed specifically for this purpose. An experimental setup is described which is used to test, debug, and evaluate the overall system design.",,2013
8a3dbb9366d2f6e4b839cab9aeec31e29cc87898,https://www.semanticscholar.org/paper/8a3dbb9366d2f6e4b839cab9aeec31e29cc87898,Self-learning and neural network adaptation by embedded collaborative learning engine (eCLE) — An overview,"This paper provides an overview of a novel scheme for constructing machine evolutionary behavior within systems. Specifically, evolving learning for the autonomous recognition of both known as well as newly emerging behaviors is provided. The paper is related with several open research problems such as cognition, incremental learning, and self-learning within the context of health monitoring systems (fault diagnosis and prognosis). Also, it is addressed the need for a formal methodology and its implementation for adding new knowledge, thus enabling the automated recognition of new patterns (e.g. behaviors) within systems. A key feature of the resulting embedded Collaborative Learning Engine (eCLE) when generating machine evolutionary behavior consists of operating with an ensemble of learning paradigms, which when instantiated work in a collaborative way. The resulting framework not only compiles the inherent advantages of the involved methods, but also enables synergistic behavior by working in a collaborative fashion.",The 2013 International Joint Conference on Neural Networks (IJCNN),2013
307bccaee7e7eda278b9cad46522e315b0a638de,https://www.semanticscholar.org/paper/307bccaee7e7eda278b9cad46522e315b0a638de,Formal verification of neural networks for safety-critical tasks in deep reinforcement learning,"In the last years, neural networks achieved groundbreaking successes in a wide variety of applications. However, for safety critical tasks, such as robotics and healthcare, it is necessary to provide some specific guarantees before the deployment in a real world context. Even in these scenarios, where high cost equipment and human safety are involved, the evaluation of the models is usually performed with the standard metrics (i.e., cumulative reward or success rate). In this paper, we introduce a novel metric for the evaluation of models in safety critical tasks, the violation rate. We build our work upon the concept of formal verification for neural networks, providing a new formulation for the safety properties that aims to ensure that the agent always makes rational decisions. To perform this evaluation, we present ProVe (Property Verifier), a novel approach based on the interval algebra, designed for the analysis of our novel behavioral properties. We apply our method to different domains (i.e., mapless navigation for mobile robots, trajectory generation for manipulators, and the standard ACAS benchmark). Results show that the violation rate computed by ProVe provides a good evaluation for the safety of trained models.",UAI,2021
880afccf453185e5ea5546f4730b840b85be9fad,https://www.semanticscholar.org/paper/880afccf453185e5ea5546f4730b840b85be9fad,Towards Multi-Modal Perception-Based Navigation: A Deep Reinforcement Learning Method,"In this letter, we present a novel navigation system of unmanned ground vehicle (UGV) for local path planning based on deep reinforcement learning. The navigation system decouples perception from control and takes advantage of multi-modal perception for a reliable online interaction with the surrounding environment of the UGV, which enables a direct policy learning for generating flexible actions to avoid collisions with obstacles in the navigation. By replacing the raw RGB images with their semantic segmentation maps as the input and applying a multi-modal fusion scheme, our system trained only in simulation can handle real-world scenes containing dynamic obstacles such as vehicles and pedestrians. We also introduce a modal separation learning to accelerate the training and further boost the performance. Extensive experiments demonstrate that our method closes the gap between simulated and real environments, exhibiting the superiority over state-of-the-art approaches. Please refer to https://vsislab.github.io/mmpbnv1/ for the supplementary video demonstration of UGV navigation in both simulated and real-world environments.",IEEE Robotics and Automation Letters,2021
9956e3ea2b894f45ca9070ee1984caadb74edbf7,https://www.semanticscholar.org/paper/9956e3ea2b894f45ca9070ee1984caadb74edbf7,Learning Composable Behavior Embeddings for Long-Horizon Visual Navigation,"Learning high-level navigation behaviors has important implications: it enables robots to build compact visual memory for repeating demonstrations and to build sparse topological maps for planning in novel environments. Existing approaches only learn discrete, short-horizon behaviors. These standalone behaviors usually assume a discrete action space with simple robot dynamics, thus they cannot capture the intricacy and complexity of real-world trajectories. To this end, we propose Composable Behavior Embedding (CBE), a continuous behavior representation for long-horizon visual navigation. CBE is learned in an end-to-end fashion; it effectively captures path geometry and is robust to unseen obstacles. We show that CBE can be used to performing memory-efficient path following and topological mapping, saving more than an order of magnitude of memory than behavior-less approaches.",IEEE Robotics and Automation Letters,2021
f667c3a0c904db9d55c225c0411833abbc38a561,https://www.semanticscholar.org/paper/f667c3a0c904db9d55c225c0411833abbc38a561,Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning,"The combination of Evolutionary Algorithms (EAs) and Deep Reinforcement Learning (DRL) has been recently proposed to merge the benefits of both solutions. Existing mixed approaches, however, have been successfully applied only to actor-critic methods and present significant overhead. We address these issues by introducing a novel mixed framework that exploits a periodical genetic evaluation to soft update the weights of a DRL agent. The resulting approach is applicable with any DRL method and, in a worst-case scenario, it does not exhibit detrimental behaviours. Experiments in robotic applications and continuous control benchmarks demonstrate the versatility of our approach that significantly outperforms prior DRL, EAs, and mixed approaches. Finally, we employ formal verification to confirm the policy improvement, mitigating the inefficient exploration and hyper-parameter sensitivity of DRL.",ICLR,2021
61ba1972dba0e6a7ca97753c5c3b34e1bdfef773,https://www.semanticscholar.org/paper/61ba1972dba0e6a7ca97753c5c3b34e1bdfef773,Model-based Reinforcement Learning for Decentralized Multiagent Rendezvous,"Collaboration requires agents to align their goals on the fly. Underlying the human ability to align goals with other agents is their ability to predict the intentions of others and actively update their own plans. We propose hierarchical predictive planning (HPP), a model-based reinforcement learning method for decentralized multiagent rendezvous. Starting with pretrained, single-agent point to point navigation policies and using noisy, high-dimensional sensor inputs like lidar, we first learn via self-supervision motion predictions of all agents on the team. Next, HPP uses the prediction models to propose and evaluate navigation subgoals for completing the rendezvous task without explicit communication among agents. We evaluate HPP in a suite of unseen environments, with increasing complexity and numbers of obstacles. We show that HPP outperforms alternative reinforcement learning, path planning, and heuristic-based baselines on challenging, unseen environments. Experiments in the real world demonstrate successful transfer of the prediction models from sim to real world without any additional fine-tuning. Altogether, HPP removes the need for a centralized operator in multiagent systems by combining model-based RL and inference methods, enabling agents to dynamically align plans.",CoRL,2020
76a91900d72ded9d3d8ba019e54ca115aae904ba,https://www.semanticscholar.org/paper/76a91900d72ded9d3d8ba019e54ca115aae904ba,Discrete Deep Reinforcement Learning for Mapless Navigation,"Our goal is to investigate whether discrete state space algorithms are a viable solution to continuous alternatives for mapless navigation. To this end we present an approach based on Double Deep Q-Network and employ parallel asynchronous training and a multi-batch Priority Experience Replay to reduce the training time. Experiments show that our method trains faster and outperforms both the continuous Deep Deterministic Policy Gradient and Proximal Policy Optimization algorithms. Moreover, we train the models in a custom environment built on the recent Unity learning toolkit and show that they can be exported on the TurtleBot3 simulator and to the real robot without further training. Overall our optimized method is 40% faster compared to the original discrete algorithm. This setting significantly reduces the training times with respect to the continuous algorithms, maintaining a similar level of success rate hence being a viable alternative for mapless navigation.",2020 IEEE International Conference on Robotics and Automation (ICRA),2020
7db4988899e3f8a3a68d6ff56106942329106c4c,https://www.semanticscholar.org/paper/7db4988899e3f8a3a68d6ff56106942329106c4c,Genetic Deep Reinforcement Learning for Mapless Navigation,We consider Deep Reinforcement Learning (DRL) approaches to devise mapless navigation strategies for mobile platforms. We propose a Genetic Deep Reinforcement Learning (GDRL) method that combines Genetic Algorithms (GA) with discrete and continuous action space DRL approaches. The goal of GDRL is to reduce the sensitivity of DRL approaches to their hyper-parameter tuning and to provide robust exploration strategies. We evaluate GDRL in combination with Rainbow and Proximal Policy Optimization (PPO) in two navigation scenarios: i) a wheeled robot avoiding obstacles in an indoor environment and ii) a water drone that must reach a predefined location in presence of waves. Our empirical evaluation demonstrates that GDRL outperforms state-of-the-art DRL and GA methods as well as a previous hybrid approach.,AAMAS,2020
b36679a4543f98c81fb80ee37352a89ca057a801,https://www.semanticscholar.org/paper/b36679a4543f98c81fb80ee37352a89ca057a801,Long-Range Indoor Navigation With PRM-RL,"Long-range indoor navigation requires guiding robots with noisy sensors and controls through cluttered environments along paths that span a variety of buildings. We achieve this with PRM-RL, a hierarchical robot navigation method in which reinforcement learning (RL) agents that map noisy sensors to robot controls learn to solve short-range obstacle avoidance tasks, and then sampling-based planners map where these agents can reliably navigate in simulation; these roadmaps and agents are then deployed on robots, guiding them along the shortest path where the agents are likely to succeed. In this article, we use probabilistic roadmaps (PRMs) as the sampling-based planner, and AutoRL as the RL method in the indoor navigation context. We evaluate the method with a simulation for kinematic differential drive and kinodynamic car-like robots in several environments, and on differential-drive robots at three physical sites. Our results show that PRM-RL with AutoRL is more successful than several baselines, is robust to noise, and can guide robots over hundreds of meters in the face of noise and obstacles in both simulation and on robots, including over 5.8 km of physical robot navigation.",IEEE Transactions on Robotics,2019
cbbc79f797647fa2bfd6c838b0c2e51365185b9a,https://www.semanticscholar.org/paper/cbbc79f797647fa2bfd6c838b0c2e51365185b9a,Evaluating the Safety of Deep Reinforcement Learning Models using Semi-Formal Verification,"Groundbreaking successes have been achieved by Deep Reinforcement Learning (DRL) in solving practical decision-making problems. Robotics, in particular, can involve high-cost hardware and human interactions. Hence, scrupulous evaluations of trained models are required to avoid unsafe behaviours in the operational environment. However, designing metrics to measure the safety of a neural network is an open problem, since standard evaluation parameters (e.g., total reward) are not informative enough. In this paper, we present a semi-formal verification approach for decision-making tasks, based on interval analysis, that addresses the computational demanding of previous verification frameworks and design metrics to measure the safety of the models. Our method obtains comparable results over standard benchmarks with respect to formal verifiers, while drastically reducing the computation time. Moreover, our approach allows to efficiently evaluate safety properties for decision-making models in practical applications such as mapless navigation for mobile robots and trajectory generation for manipulators.",ArXiv,2020
f22d1a958c5fe235d454469a82f2e4d61d2aaeac,https://www.semanticscholar.org/paper/f22d1a958c5fe235d454469a82f2e4d61d2aaeac,Robust RL-Based Map-Less Local Planning: Using 2D Point Clouds as Observations,"In this letter, we propose a robust approach to train map-less navigation policies that rely on variable size 2D point clouds, using Deep Reinforcement Learning (Deep RL). The navigation policies are trained in simulations using the DDPG algorithm. Through experimental evaluations in simulated and real-world environments, we showcase the benefits of our approach when compared to more classical RL-based formulations: better performance, the possibility to interchange sensors at deployment time, and to easily augment the environment observability through sensor preprocessing and/or sensor fusion. Videos showing trajectories traversed by agents trained with the proposed approach can be found in https://youtu.be/AzvRJyN6rwQ.",IEEE Robotics and Automation Letters,2020
6c3f07521d5399ab5157c39dd20f8570eb8b0e10,https://www.semanticscholar.org/paper/6c3f07521d5399ab5157c39dd20f8570eb8b0e10,A Data Quality Assessment Approach in the SmartWork Project's Time-series Data Imputation Paradigm,"The plethora of collected data streams of the SmartWork project’s sensing system is often accompanied by missing values, yielding the need for estimating these missing values through imputation, which may prove unnecessary or computationally expensive in relation to the outcome. This work introduces a data quality assessment approach that allows for decision making regarding the need/efficiency of data completion in order to save system computational resources and ensure quality of imputed data. Preliminary validation of the proposed approach is performed by assessing the correlation between the proposed data quality assessment scores and the normalized mean square error of the imputation on various simulated missing patterns. The results reinforce our initial hypothesis that the suggested score is a suitable data quality indicator, correlating well with the potential errors introduced by imputation in the case of a given batch of input data.",IJCCI,2021
063c809036f81c920845daa815d944972a19e2e6,https://www.semanticscholar.org/paper/063c809036f81c920845daa815d944972a19e2e6,A Systematic Mapping Study on Edge Computing and Analytics,"The vast amount of data provided by the Internet of Things and sensors, have given rise to edge computing and analytics. In edge computing and analytics, data processing and analysis on sensor input is performed in edge devices prior to sending the results to the cloud. This reduces required processing in the cloud while minimizing communication network utilization and allows cloud resources to be used for other tasks such as decision making. In this paper, we present a comprehensive, unbiased overview of state-of-the-art research on edge computing and analytics. Of the 47 identified papers, several have targeted task scheduling and power optimisation, while data management and engineering, image and facial recognition as well as anomaly detection were not well studied. Simulation remains the most used approach for validation, and research results based on implementations of edge systems in real life environments are still sparse. Keywords-edge; analytics; systematic mapping study.",,2020
3223749e448b1899347a6b5d9fcdeb48b3076078,https://www.semanticscholar.org/paper/3223749e448b1899347a6b5d9fcdeb48b3076078,Sparse modeling and optimization tools for energy efficient and reliable IoT,"The continuous expansion of the Internet of Things, with even more devices expected to connect in the following years, leads to a great increase in the amount of data required to be transmitted and stored, identifying the need for robust, reliable and energy efficient data flow in the context of an ever-growing network. This study presents a matrix completion based approach for big data and large matrices facilitating local smoothness constraints combined with active subspace computing. We demonstrate that the presented approaches exhibit lower reconstruction error with respect to relevant literature for the specific problem. We also examine the effect of matrix size on the reconstruction accuracy so as to investigate the suitability of the proposed approaches for big data.",2019 First International Conference on Societal Automation (SA),2019
466d3d0990f78147e700a5f338e59759a10da156,https://www.semanticscholar.org/paper/466d3d0990f78147e700a5f338e59759a10da156,Coping with missing data in an unobtrusive monitoring system for office workers,"Current trend of population ageing at global level is accompanied by increased prevalence of chronic diseases and higher rates of early retirement and labor market exit. In particular, the lifestyle of office workers is characterized by prolonged sitting and overall sedentary life, which alone is a high risk factor for cardiometabolic diseases, obesity and other related chronic diseases. The SmartWork unobtrusive monitoring system allows for continuous monitoring of various lifestyle, health, behavioural and work related parameters of office workers targeting to empower work ability sustainability. The large amounts of collected data in such systems are often characterized by the presence of missing entries. This work is an exploratory study on the potential of a Laplacian matrix completion variant for data imputation on the multi-channel time-series data collected with wearable or work devices in the SmartWork system.",2019 International Conference on Biomedical Innovations and Applications (BIA),2019
6a5e084c23c01a589b90458f5f54aab900e6e87b,https://www.semanticscholar.org/paper/6a5e084c23c01a589b90458f5f54aab900e6e87b,Identifying Eco-driving Behavior and Estimating CO2 Emissions with Machine Learning,"Transport is responsible for nearly 30% of the EU’s total CO2 emissions, of which 72% comes from road transportation. The European Union, for the past few years, has set a goal of reducing emissions from transport by 60% by 2050 in comparison to the levels in the previous century. One way to reduce CO2 emission implemented by the EU the past few years was to promote the idea of Eco-driving to the general population. In this paper, with the data and experiments provided by GAMECAR, we will analyze the effects of Eco-driving on car fuel consumption, identify 10 Ecodriving behaviors before estimating the impact of those driving behaviors on CO2 emission with machine learning.",,2019
c35cc359bc90d02f92771baec2edee2d7ef94bf2,https://www.semanticscholar.org/paper/c35cc359bc90d02f92771baec2edee2d7ef94bf2,Utilising fog computing for developing a person-centric heart monitoring system,,J. Ambient Intell. Smart Environ.,2019
d8022d5af30d639493e4d3aec2422a16c4073e40,https://www.semanticscholar.org/paper/d8022d5af30d639493e4d3aec2422a16c4073e40,"Field Research Cooperative Wearable Systems: Challenges in Requirements, Design and Validation","The widespread availability of wearable devices is evolving them into cooperative systems. Communication and distribution aspects such as the Internet of Things, Wireless Body Area Networks, and Local Wireless Networks provide the means to develop multi-device platforms. Nevertheless, the field research environment presents a specific feature set, which increases the difficulty in the adoption of this technology. In this text, we review the main aspects of Field Research Gears and Wearable Devices. This review is made aiming to understand how to create cooperative systems based on wearable devices directed to the Field Research Context. For a better understanding, we developed a case study in which we propose a cooperative system architecture and provide validation aspects. For this matter, we provide an overview of a previous device architecture and study an integration proposal.",Sensors,2019
fd3bbafdefd4e9863c37ed22fe2706f3b7925488,https://www.semanticscholar.org/paper/fd3bbafdefd4e9863c37ed22fe2706f3b7925488,"On the Design of a Fog Computing-Based, Driving Behaviour Monitoring Framework","Recent technological improvements in vehicle manufacturing may greatly improve safety however, the individuals' driving behaviour still remains a factor of paramount importance with aggressiveness, lack of focus and carelessness being the main cause of the majority of traffic incidents. The imminent deployment of 5G networking infrastructure, paired with the advent of Fog computing and the establishment of the Internet of Things (IoT) as a reliable and cost-effective service delivery framework may provide the means for the deployment of an accurate driving monitoring solution which could be utilized to further understand the underlying reasons of peculiar road behaviour, as well as its correlation to the driver's physiological state, the vehicle condition and certain environmental parameters. This paper presents some of the fundamental attributes of Fog computing along with the functional requirements of a driving behaviour monitoring framework, followed by its high level architecture blueprint and the description of the prototype implementation process.",2019 IEEE 24th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD),2019
30718c357cced0388bb4bf2f879edbe829871cdf,https://www.semanticscholar.org/paper/30718c357cced0388bb4bf2f879edbe829871cdf,A Consecutive Hybrid Spiking-Convolutional (CHSC) Neural Controller for Sequential Decision Making in Robots,,Neurocomputing,2021
376032f2d168cc46c34fc28f3029fd9c94506fcb,https://www.semanticscholar.org/paper/376032f2d168cc46c34fc28f3029fd9c94506fcb,A Brain-Inspired Framework for Evolutionary Artificial General Intelligence,"From the medical field to agriculture, from energy to transportation, every industry is going through a revolution by embracing artificial intelligence (AI); nevertheless, AI is still in its infancy. Inspired by the evolution of the human brain, this paper demonstrates a novel method and framework to synthesize an artificial brain with cognitive abilities by taking advantage of the same process responsible for the growth of the biological brain called ""neuroembryogenesis."" This framework shares some of the key behavioral aspects of the biological brain such as spiking neurons, neuroplasticity, neuronal pruning, and excitatory and inhibitory interactions between neurons, together making it capable of learning and memorizing. One of the highlights of the proposed design is its potential to incrementally improve itself over generations based on system performance, using genetic algorithms. A proof of concept at the end of the paper demonstrates how a simplified implementation of the human visual cortex using the proposed framework is capable of character recognition. Our framework is open-source and the code is shared with the scientific community at www.feagi.org.",2020 Information Theory and Applications Workshop (ITA),2020
3dc5b8f751d2497850874a5d5bad5161bfab52b6,https://www.semanticscholar.org/paper/3dc5b8f751d2497850874a5d5bad5161bfab52b6,Digital neuromorphic real-time platform,"Abstract Hardware implementations of spiking neural networks in portable devices can improve many applications of robotics, neurorobotics or prosthetic fields in terms of power consumption, high-speed processing and learning mechanisms. Analog and digital platforms have been previously proposed to run these networks. Analog designs are closer to biology since they implement the original mathematical model. However, digital platforms are, to some extent, abstractions of this model so far. In this paper, a full digital platform to design, implement and run real-time analog-like spiking neural networks is presented. Specifically, we present the design and implementation of digital circuits to run real-time biologically plausible spiking neural networks on a Field Programmable Gate Array (FPGA). The circuit designed for the neuron implements the Leaky Integrate and Fire (LIF) model. The synapsis implemented is a bi-exponential current-based one. The synaptic circuit design consists of one static memory with the baseline current and a dynamic memory which stores the updated contribution over time of each pre-synaptic connection. All the parameters of both the neuron and the synapse are configurable. The results of the circuits are validated by running the same experiments on the Brian simulator. The circuits, which are totally original and independent of the technology, use only 136 slice registers of hardware resources. Thus, these designs allow the scale of the network. These circuits aim to be the basis of the spiking neural networks on digital devices. This platform allows the user to first simulate their network within the Brian simulator and then, confidently, move to the hardware platform replicating the same performance or even replace their analog platform with the digital one.",Neurocomputing,2020
476174518e18575346c0f6545635fd240e6cfb2d,https://www.semanticscholar.org/paper/476174518e18575346c0f6545635fd240e6cfb2d,Computational Modeling of Prefrontal Cortex for Meta-Cognition of a Humanoid Robot,"For robot intelligence and human-robot interaction (HRI), complex decision-making, interpretation, and adaptive planning processes are great challenges. These require recursive task processing and meta-cognitive reasoning mechanism. Naturally, the human brain realizes these cognitive skills by prefrontal cortex which is a part of the neocortex. Previous studies about neurocognitive robotics would not meet these requirements. Thus, it is aimed at developing a brain-inspired robot control architecture that performs spatial-temporal and emotional reasoning. In this study, we present a novel solution that covers a computational model of the prefrontal cortex for humanoid robots. Computational mechanisms are mainly placed on the bio-physical plausible neural structures embodied in different dynamics. The main components of the system are composed of several computational modules including dorsolateral, ventrolateral, anterior, and medial prefrontal regions. Also, it is responsible for organizing the working memory. A reinforcement meta-learning based explainable artificial intelligence (xAI) procedure is applied to the working memory regions of the computational prefrontal cortex model. Experimental evaluation and verification tests are processed by the developed software framework embodied in the humanoid robot platform. The humanoid robots’ perceptual states and cognitive processes including emotion, attention, and intention-based reasoning skills can be observed and controlled via the developed software. Several interaction scenarios are implemented to monitor and evaluate the model’s performance.",IEEE Access,2020
ee2fc396cd45419836e7645264ddd8b67a4f054d,https://www.semanticscholar.org/paper/ee2fc396cd45419836e7645264ddd8b67a4f054d,A self-organizing developmental cognitive architecture with interactive reinforcement learning,"Abstract Developmental cognitive systems can endow robots with the abilities to incrementally learn knowledge and autonomously adapt to complex environments. Conventional cognitive methods often acquire knowledge through passive perception, such as observing and listening. However, this learning way may generate incorrect representations inevitably and cannot correct them online without any feedback. To tackle this problem, we propose a biologically-inspired hierarchical cognitive system called Self-Organizing Developmental Cognitive Architecture with Interactive Reinforcement Learning (SODCA-IRL). The architecture introduces interactive reinforcement learning into hierarchical self-organizing incremental neural networks to simultaneously learn object concepts and fine-tune the learned knowledge by interacting with humans. In order to realize the integration, we equip individual neural networks with a memory model, which is designed as an exponential function controlled by two forgetting factors to simulate the consolidation and forgetting processes of humans. Besides, an interactive reinforcement strategy is designed to provide appropriate rewards and execute mistake correction. The feedback acts on the forgetting factors to reinforce or weaken the memory of neurons. Therefore, correct knowledge is preserved while incorrect representations are forgotten. Experimental results show that the proposed method can make effective use of the feedback from humans to improve the learning effectiveness significantly and reduce the model redundancy.",Neurocomputing,2020
efbb166e3c9227870b06dd320ab650c4d312e3a5,https://www.semanticscholar.org/paper/efbb166e3c9227870b06dd320ab650c4d312e3a5,A Brain-Inspired Framework for Evolutionary Artificial General Intelligence,"From the medical field to agriculture, from energy to transportation, every industry is going through a revolution by embracing artificial intelligence (AI); nevertheless, AI is still in its infancy. Inspired by the evolution of the human brain, this article demonstrates a novel method and framework to synthesize an artificial brain with cognitive abilities by taking advantage of the same process responsible for the growth of the biological brain called “neuroembryogenesis.” This framework shares some of the key behavioral aspects of the biological brain, such as spiking neurons, neuroplasticity, neuronal pruning, and excitatory and inhibitory interactions between neurons, together making it capable of learning and memorizing. One of the highlights of the proposed design is its potential to incrementally improve itself over generations based on system performance, using genetic algorithms. A proof of concept at the end of this article demonstrates how a simplified implementation of the human visual cortex using the proposed framework is capable of character recognition. Our framework is open source, and the code is shared with the scientific community at http://www.feagi.org.",IEEE Transactions on Neural Networks and Learning Systems,2020
d0874fa2a4043fc402b19fb26299ed73b5b81230,https://www.semanticscholar.org/paper/d0874fa2a4043fc402b19fb26299ed73b5b81230,Semantic Flexibility and Grounded Language Learning,"We explore the way that the flexibility inherent in the lexicon might be incorporated into the process by which an environmentally grounded artificial agent – a robot – acquires language. We take flexibility to indicate not only many-to-many mappings between words and extensions, but also the way that word meaning is specified in the context of a particular situation in the world. Our hypothesis is that embodiment and embededness are necessary conditions for the development of semantic representations that exhibit this flexibility. We examine this hypothesis by first very briefly reviewing work to date in the domain of grounded language learning, and then proposing two research objectives: 1) the incorporation of highdimensional semantic representations that permit context-specific projections, and 2) an exploration of ways in which non-humanoid robots might exhibit language-learning capacities. We suggest that the experimental programme implicated by this theoretical investigation could be situated broadly within the enactivist paradigm, which approaches cognition from the perspective of agents emerging in the course of dynamic entanglements within an environment.",,2019
f11d40dc6c61ffa42ad132f6841f19b21ad24118,https://www.semanticscholar.org/paper/f11d40dc6c61ffa42ad132f6841f19b21ad24118,Innovative Internet of Things-reinforced Human Recognition for Human-Machine Interaction Purposes,"Abstract Accurate and reliable human recognition and parametrisation have always been an important challenge in efficient Man-Machine Interaction. A humanoid robot is able to offer a much richer and more natural behaviour and human-like communication, but only if the robot possesses sufficient knowledge about the interlocutor, such as inter alia: gender, age, mood, behaviour data, interaction history. In this paper authors introduced an innovative conception in Human-Machine Interaction, where instead of thinking about an interaction as an event (which uses and produces information) an innovative point of view was proposed, where the interaction is just an event in a continuous flow of information. The difference, once perceived, results in an astounding change of conception, as well as a whole new set of ideas. The human detection, information acquisition, human recognition – can be performed earlier, before a human reaches the humanoid robot, also the history of interactions and possible interests of the interlocutor can be predicted before they would even start the conversation. This paper contains a detailed analysis of the proposed environment-based approach to interaction, as well as the Internet of Things-reinforced information acquisition.",,2018
30718c357cced0388bb4bf2f879edbe829871cdf,https://www.semanticscholar.org/paper/30718c357cced0388bb4bf2f879edbe829871cdf,A Consecutive Hybrid Spiking-Convolutional (CHSC) Neural Controller for Sequential Decision Making in Robots,,Neurocomputing,2021
812c68184291a780481eb9b9663c19a3b6fdbda7,https://www.semanticscholar.org/paper/812c68184291a780481eb9b9663c19a3b6fdbda7,Stochastic Genetic Algorithm-Assisted Fuzzy Q-Learning for Robotic Manipulators,"This work proposes stochastic genetic algorithm-assisted Fuzzy Q-Learning-based robotic manipulator control. Specifically, the aim is to redefine the action choosing mechanism in Fuzzy Q-Learning for robotic manipulator control. Conventionally, a Fuzzy Q-Learning-based controller selects a deterministic action from available actions using fuzzy Q values. This deterministic Fuzzy Q-Learning is not an efficient approach, especially in dealing with highly coupled nonlinear systems such as robotic manipulators. Restricting the search for optimal action to the agent’s action set or a restricted set of Q values (deterministic) is a myopic idea. Herein, the proposal is to employ genetic algorithm as stochastic optimizer for action selection at each stage of Fuzzy Q-Learning-based controller. This turns out to be a highly effective way for robotic manipulator control rather than choosing an algebraic minimal action. As case studies, present work implements the proposed approach on two manipulators: (a) two-link arm manipulator and (b) selective compliance assembly robotic arm. Scheme is compared with baseline Fuzzy Q-Learning controller, Lyapunov Markov game-based controller and Linguistic Lyapunov Reinforcement Learning controller. Simulation results show that our stochastic genetic algorithm-assisted Fuzzy Q-Learning controller outperforms the above-mentioned controllers in terms of tracking errors along with lower torque requirements.",,2021
ddaa52c98c898bcf2bb1579b7d834755d32aff70,https://www.semanticscholar.org/paper/ddaa52c98c898bcf2bb1579b7d834755d32aff70,A fuzzy-based potential field hierarchical reinforcement learning approach for target hunting by multi-AUV in 3-D underwater environments,"ABSTRACT In order to accomplish the target hunting by multi-AUV in 3-D underwater environments, the AUVs need to cooperate in the process of pursuing targets. To improve the efficiency of target hunting and the smoothness of AUV’s trajectory, a fuzzy-based potential field hierarchical reinforcement learning approach is proposed. Unlike other algorithms that need repeated training in the choice of parameters, the proposed approach automatically acquires all the required parameters by learning. The potential field hierarchy is established by combining the segmental options with the traditional hierarchy reinforcement learning algorithm. The potential field is applied in the parameters of the HRL, which provides a reasonable path for target hunting in an undeveloped environments. In the meantime, fuzzy algorithm is introduced to improve the smoothness of AUV trajectory. The simulation results show that the proposed method can control multi-AUV to achieve multi-target hunting task, and has higher efficiency and adaptability than other algorithm.",Int. J. Control,2019
fe890530df063804ce219ba9c4fd1f16401440ec,https://www.semanticscholar.org/paper/fe890530df063804ce219ba9c4fd1f16401440ec,Q-Learning-Based Target Selection for Bearings-Only Autonomous Navigation,"This paper presents a Q-learning-based target selection algorithm for spacecraft autonomous navigation using bearing observations of known visible targets. For the considered navigation system, the position and velocity of the spacecraft are estimated using an extended Kalman filter (EKF) with the measurements of inter-satellite line-of-sight (LOS) vectors obtained via an onboard star camera. This paper focuses on the selection of the appropriate target at each observation period for the star camera adaptively, such that the performance of the EKF is enhanced. To derive an effective algorithm, a Q-function is designed to select a proper observation region, while a U-function is introduced to rank the targets in the selected region. Both the Q-function and the U-function are constructed based on the sequence of innovations obtained from the EKF. The efficiency of the Q-learning-based target selection algorithm is illustrated via numerical simulations, which show that the presented algorithm outperforms the traditional target selection strategy based on a Cramer-Rao bound (CRB) in the case that the prior knowledge about the target location is inaccurate.",J. Syst. Sci. Complex.,2021
1547b5d116d888b8777584a61f537d8b1aba3415,https://www.semanticscholar.org/paper/1547b5d116d888b8777584a61f537d8b1aba3415,Sample-Efficient Training of Robotic Guide Using Human Path Prediction Network.,"Training a robot that engages with people is challenging, because it is expensive to involve people in a robot training process requiring numerous data samples. This paper proposes a human path prediction network (HPPN) and an evolution strategy-based robot training method using virtual human movements generated by the HPPN, which compensates for this sample inefficiency problem. We applied the proposed method to the training of a robotic guide for visually impaired people, which was designed to collect multimodal human response data and reflect such data when selecting the robot's actions. We collected 1,507 real-world episodes for training the HPPN and then generated over 100,000 virtual episodes for training the robot policy. User test results indicate that our trained robot accurately guides blindfolded participants along a goal path. In addition, by the designed reward to pursue both guidance accuracy and human comfort during the robot policy training process, our robot leads to improved smoothness in human motion while maintaining the accuracy of the guidance. This sample-efficient training method is expected to be widely applicable to all robots and computing machinery that physically interact with humans.",,2020
40f85c3f1223286e8b1ef988ecea614b6c312dec,https://www.semanticscholar.org/paper/40f85c3f1223286e8b1ef988ecea614b6c312dec,COLREG-Compliant Collision Avoidance for Unmanned Surface Vehicle Using Deep Reinforcement Learning,"Path Following and Collision Avoidance, be it for unmanned surface vessels or other autonomous vehicles, are two fundamental guidance problems in robotics. For many decades, they have been subject to academic study, leading to a vast number of proposed approaches. However, they have mostly been treated as separate problems, and have typically relied on non-linear first-principles models with parameters that can only be determined experimentally. The rise of deep reinforcement learning in recent years suggests an alternative approach: end-to-end learning of the optimal guidance policy from scratch by means of a trial-and-error based approach. In this article, we explore the potential of Proximal Policy Optimization, a deep reinforcement learning algorithm with demonstrated state-of-the-art performance on Continuous Control tasks, when applied to the dual-objective problem of controlling an autonomous surface vehicle in a COLREGs compliant manner such that it follows an a priori known desired path while avoiding collisions with other vessels along the way. Based on high-fidelity elevation and AIS tracking data from the Trondheim Fjord, an inlet of the Norwegian sea, we evaluate the trained agent’s performance in challenging, dynamic real-world scenarios where the ultimate success of the agent rests upon its ability to navigate non-uniform marine terrain while handling challenging, but realistic vessel encounters.",IEEE Access,2020
6655c61f81ceed65384cbb11fa60f7546a7ecc34,https://www.semanticscholar.org/paper/6655c61f81ceed65384cbb11fa60f7546a7ecc34,Q‐learning for noise covariance adaptation in extended KALMAN filter,,,2020
7c7d26a5d3f7d546062150aa8d0a97d8a71802ed,https://www.semanticscholar.org/paper/7c7d26a5d3f7d546062150aa8d0a97d8a71802ed,Deep imitation learning for autonomous vehicles based on convolutional neural networks,"Providing autonomous systems with an effective quantity and quality of information from a desired task is challenging. In particular, autonomous vehicles, must have a reliable vision of their workspace to robustly accomplish driving functions. Speaking of machine vision, deep learning techniques, and specifically convolutional neural networks, have been proven to be the state of the art technology in the field. As these networks typically involve millions of parameters and elements, designing an optimal architecture for deep learning structures is a difficult task which is globally under investigation by researchers. This study experimentally evaluates the impact of three major architectural properties of convolutional networks, including the number of layers, filters, and filter size on their performance. In this study, several models with different properties are developed, equally trained, and then applied to an autonomous car in a realistic simulation environment. A new ensemble approach is also proposed to calculate and update weights for the models regarding their mean squared error values. Based on design properties, performance results are reported and compared for further investigations. Surprisingly, the number of filters itself does not largely affect the performance efficiency. As a result, proper allocation of filters with different kernel sizes through the layers introduces a considerable improvement in the performance. Achievements of this study will provide the researchers with a clear clue and direction in designing optimal network architectures for deep learning purposes.",IEEE/CAA Journal of Automatica Sinica,2020
9e06e4529dc5cf060b934a081f0742aa6fb9012f,https://www.semanticscholar.org/paper/9e06e4529dc5cf060b934a081f0742aa6fb9012f,MRCDRL: Multi-robot coordination with deep reinforcement learning,"Abstract This paper proposes a multi-robot cooperative algorithm based on deep reinforcement learning (MRCDRL). We use end-to-end methods to train directly from each robot-centered, relative perspective-generated image, and each robot’s reward as the input. During training, it is not necessary to specify the target position and movement path of each robot. MRCDRL learns the actions of each robot by training the neural network. MRCDRL uses the neural network structure that was modified from the Duel neural network structure. In the Duel network structure, there are two streams that each represents the state value function and the state-dependent action advantage function, and the results of the two streams are merged. The proposed method can solve the resource competition problem on the one hand and can solve the static and dynamic obstacle avoidance problems between multi-robot in real time on the other hand. Our new MRCDRL algorithm has higher accuracy and robustness than DQN and DDQN and can be effectively applied to multi-robot collaboration.",Neurocomputing,2020
a14630721114759e1fbdc7b4324eed18ece8364e,https://www.semanticscholar.org/paper/a14630721114759e1fbdc7b4324eed18ece8364e,Distributed evolutionary learning control for mobile robot navigation based on virtual and physical agents,"Abstract This paper presents a distributed evolutionary learning control based on social wound treatment for mobile robot navigation using an integrated multi-robot system comprised of simulated and physical robots. To do so, this work proposes an extension of the population-based metaheuristic wound treatment optimization (WTO) method into a distributed scheme. In addition, this distributed WTO method is implemented on the multi-robot system allowing them to experience the environment in their own and communicate their findings, resulting in an emergence intelligence. We implemented our proposal using the combination of five simulated robots with one physical robot for tuning a navigation controller to move freely in a workspace. Results showed that the solution found by this multi-robot system aims using the output controller in the physical robot for successfully achieving the goal to move the robot around a U-maze, without applying any transfer learning approach. We consider this proposal useful in evolutionary robotics, and of great importance to decrease the gap related to transfer knowledge in robotics from simulation to reality.",Simul. Model. Pract. Theory,2020
c7ff5fed4f883e7da1cc5a51273155b0fa969330,https://www.semanticscholar.org/paper/c7ff5fed4f883e7da1cc5a51273155b0fa969330,Temporal Difference Learning for Noise Covariance Adaptation,"When the noise covariance matrices in the filtering algorithm are not match with the practical system, the filtering performance may be degraded. To address this problem, a temporal difference learning Kalman filter (TDLKF) algorithm is presented for systems with noise covariance uncertainty. The key idea is to select appropriate noise parameters adaptively via trial-and-error interactions in an operational environment, such that the filtering performance is improved gradually. The adaptation scheme is implemented via temporal difference (TD) learning, which is an optimization-searching algorithm based on a value function updated iteratively as episode increases. The TDLKF is applied for an autonomous satellite constellation navigation system. The high performance of the algorithm is illustrated via simulation in comparison with the multiple-model adaptive estimation (MMAE) and the adaptive Kalman filter (AKF).",,2020
0f48eaf59a5099fe0222a659b04cde2c1780dbd9,https://www.semanticscholar.org/paper/0f48eaf59a5099fe0222a659b04cde2c1780dbd9,A Novel Motion-Intelligence-Based Control Algorithm for Object Tracking by Controlling PAN-Tilt Automatically,"As computer vision develops, pan-tilt platform visual systems are able to track moving target over static camera systems. In this paper, a novel motion-intelligence-based control algorithm for object tracking by controlling pan-tilt platform has been proposed. The algorithm includes the motion control model based on angular speed and the intelligent control algorithm based on reinforcement learning (RL). The motion control model converts deviation between the center point of the tracked target and the center point of the frame to angular speed of pan-tilt platform. It can keep position of the tracked object in the center of the frame automatically. The intelligent control algorithm based on reinforcement learning can reduce the error between the ideal value and the actual value when the pan-tilt platform moves. The two blocks work together to make the pan-tilt platform track a dynamic object more stably and the experiment result shows that both the tracking accuracy and robustness are improved.",Mathematical Problems in Engineering,2019
2e38ab6bbb6c7929967aa7e453aec53ff9d895dc,https://www.semanticscholar.org/paper/2e38ab6bbb6c7929967aa7e453aec53ff9d895dc,Attitude Control of Quad-copter using Deterministic Policy Gradient Algorithms (DPGA),"In aerial robotics, intelligent control has been a buzz for the past few years. Extensive research efforts can be witnessed to produce control algorithms for stable flight operation of aerial robots using machine learning. Supervised learning has the tendency but training an agent using supervised learning can be a tedious task. Moreover, the data gathering could be expensive and always prone to inaccuracies due to parametric variations and system dynamics. An alternative approach is to ensure the stability of the aerial robots with the help of Deep Re-inforcement Learning (DRL). This paper deals with the intelligent control of quad-copter using deterministic policy gradient algorithms. In this research, state of the art Deep Deterministic Policy Gradient (DDPG) and Distributed Distributional Deep Deterministic Policy Gradient (D4PG) algorithms are employed for attitude control of quad-copter. An open source simulation environment GymFC is used for training of quad-copter. The results for comparative analysis of DDPG & D4PG algorithms are also presented, highlighting the attitude control performance.","2019 2nd International Conference on Communication, Computing and Digital systems (C-CODE)",2019
41577ab11ea39ef9bc0f6b6bbfad3ec7e36a3c9f,https://www.semanticscholar.org/paper/41577ab11ea39ef9bc0f6b6bbfad3ec7e36a3c9f,"A particle swarm optimization approach using adaptive entropy-based fitness quantification of expert knowledge for high-level, real-time cognitive robotic control","High-level, real-time mission control of semi-autonomous robots, deployed in remote and dynamic environments, remains a challenge. Control models, learnt from a knowledgebase, quickly become obsolete when the environment or the knowledgebase changes. This research study introduces a cognitive reasoning process, to select the optimal action, using the most relevant knowledge from the knowledgebase, subject to observed evidence. The approach in this study introduces an adaptive entropy-based set-based particle swarm algorithm (AE-SPSO) and a novel, adaptive entropy-based fitness quantification (AEFQ) algorithm for evidence-based optimization of the knowledge. The performance of the AE-SPSO and AEFQ algorithms are experimentally evaluated with two unmanned aerial vehicle (UAV) benchmark missions: (1) relocating the UAV to a charging station and (2) collecting and delivering a package. Performance is measured by inspecting the success and completeness of the mission and the accuracy of autonomous flight control. The results show that the AE-SPSO/AEFQ approach successfully finds the optimal state-transition for each mission task and that autonomous flight control is successfully achieved.",,2019
99cee1e379e9260e575b1e97157030908e92b893,https://www.semanticscholar.org/paper/99cee1e379e9260e575b1e97157030908e92b893,Mobile Robot Navigation Using Reinforcement Learning in Unknown Environments,"In mobile robotics, navigation is considered as one of the most primary tasks, which becomes more challenging during local navigation when the environment is unknown. Therefore, the robot has to explore utilizing the sensory information. Reinforcement learning (RL), a biologically-inspired learning paradigm, has caught the attention of many as it has the capability to learn autonomously in an unknown environment. However, the randomized behavior of exploration, common in RL, increases computation time and cost, hence making it less appealing for real-world scenarios. This paper proposes an informed-biased softmax regression (iBSR) learning process that introduce a heuristic-based cost function to ensure faster convergence. Here, the action-selection is not considered as a random process, rather, is based on the maximum probability function calculated using softmax regression. Through experimental simulation scenario for navigation, the strength of the proposed approach is tested and, for comparison and analysis purposes, the iBSR learning process is evaluated against two benchmark algorithms.",Balkan Journal of Electrical and Computer Engineering,2019
eed4725470ea54159b155f23aaa3ac1cb6909023,https://www.semanticscholar.org/paper/eed4725470ea54159b155f23aaa3ac1cb6909023,Teaching machine learning in robotics interactively: the case of reinforcement learning with Lego® Mindstorms,"ABSTRACT Preparing students for dealing with a world more and more densely populated with physical machines that possess learning capabilities, e.g. intelligent robots, is of the utmost importance in engineering. In this paper, we describe and analyse a design of interactive sessions devoted to the application of some machine learning (ML) methods within a master degree subject named “Cognitive Robotics”, in particular, reinforcement learning (RL), a technique that allows the machine to autonomously learn decision-making in a physical environment. The paper contains a complete depiction of the interactive teaching sessions, implemented with reasonable cost and resources thanks to a suitable mixture of the constructivist and instructivist paradigms. It also gathers the experiences of students and teachers through both qualitative and quantitatively indicators. GRAPHICAL ABSTRACT Video abstract Watch the video on Vimeo",Interact. Learn. Environ.,2018
f2f331d9b6a6325dc67a40336f4b6843eadc7a54,https://www.semanticscholar.org/paper/f2f331d9b6a6325dc67a40336f4b6843eadc7a54,An aero-engine life-cycle maintenance policy optimization algorithm: Reinforcement learning approach,"Abstract An aero-engine maintenance policy plays a crucial role in reasonably reducing maintenance cost. An aero-engine is a type of complex equipment with long service-life. In engineering, a hybrid maintenance strategy is adopted to improve the aero-engine operational reliability. Thus, the long service-life and the hybrid maintenance strategy should be considered synchronously in aero-engine maintenance policy optimization. This paper proposes an aero-engine life-cycle maintenance policy optimization algorithm that synchronously considers the long service-life and the hybrid maintenance strategy. The reinforcement learning approach was adopted to illustrate the optimization framework, in which maintenance policy optimization was formulated as a Markov decision process. In the reinforcement learning framework, the Gauss–Seidel value iteration algorithm was adopted to optimize the maintenance policy. Compared with traditional aero-engine maintenance policy optimization methods, the long service-life and the hybrid maintenance strategy could be addressed synchronously by the proposed algorithm. Two numerical experiments and algorithm analyses were performed to illustrate the optimization algorithm in detail.",Chinese Journal of Aeronautics,2019
5bbd6d6657b7461828e528b257106d5f0af78746,https://www.semanticscholar.org/paper/5bbd6d6657b7461828e528b257106d5f0af78746,Applied Robot Coverage Path Planning with Multiple Decision Making Capability under Uncertainty using Knowledge Inference with Hedge Algebras,"Robotic decision-support systems must facilitate a robots interactions with their environment, this demands adaptability. Adaptability relates to awareness of the environment and `self-awareness', human behaviour exemplifies the concept of awareness to arrive at an optimal choice of action or decision based on reasoning and inference with learned preferences. A similar conceptual approach is required to implement awareness in autonomous robotic systems which must adapt to the current dynamic environment (the context of use). By incorporating `self-awareness' with knowledge of a Robot's preferences (in decision making) the decision maker interface should adapt to the current context of use. This paper proposes a novel approach to enable an autonomous robotics which implements path planning combining adaptation with knowledge reasoning techniques and hedge algebra to enable an autonomous robot to realise optimal coverage path planning under dynamic uncertainty. The results for a cleaning robot show that using our proposed approach demonstrated the capability to avoid both static and dynamic obstacles while achieving optimal path planning with increased efficiency. The proposed approach achieves the multiple decision-making objectives (path planning) with a high-coverage and low repetition rates. Compared to other current approaches, the proposed approach has demonstrated improved performance over the conventional robot control algorithms.",,2018
776f7c7fc12221dd0a51e26a5449089dc863e75b,https://www.semanticscholar.org/paper/776f7c7fc12221dd0a51e26a5449089dc863e75b,Robot Arm Dynamics Control Based on Deep Learning and Physical Simulation,"General robot arm dynamics is calculated by building robot arm physical model and calculating Newton-Euler formula. In the process of dynamic modeling, the accuracy of robot dynamic control will be affected by many factors, such as estimation of dynamic parameters, simplification of robot model, inaccurate parameters of friction model. In this paper, we proposal a method of calculating robot dynamics using deep learning networks and physical simulation. The deep learning network implement an end-to-end method to calculate robot dynamics. It means that the robot arm modeling process is not required. The robot arm physical simulation based on physical engine is carried out, and the deep learning network online training system is constructed by simultaneously communicating with the physical simulation through Socket communication. The experimental data shows that the maximum error of the joint torque calculation is 15.8% and 94.7% of the joint torque error is less than 10%. The calculation results of this method are approximately the same as those traditional dynamic method. However, the work presented in this paper is a first step towards combining robot dynamics and deep learning. It focuses on using a new method to solve the traditional problem.",2018 37th Chinese Control Conference (CCC),2018
9d589375de93370b2834acead9919a5184b0728a,https://www.semanticscholar.org/paper/9d589375de93370b2834acead9919a5184b0728a,Making a robot stop a penalty Using Q Learning and Transfer Learning,"This thesis addresses the problem of decision making for an autonomous goalkeeping robot in a penalty shootout. A solution to this problem would be an advancement in the ability of autonomous decision making and learning in robots, and would contribute to the goal of having robot soccer players outperform human soccer players by 2050. The problem is complex as the amount of information the goalkeeper has is limited and the goalkeeper only has a limited time frame within it has to make a decision. Previous approaches often involved a human coding complex behavioral rules for the robots, which is very inflexible and the process of constructing behavioral rules and discovering the right parameters can be very time consuming. By using reinforcement learning, the goalkeeper in this thesis was able to stop a penalty without hand coded rules, learning from its own experience. The approach presented in this thesis uses Q learning combined with a deep neural network applied to discrete state and actions spaces and transfer learning to learn a behavioral policy. With intermediate rewards the algorithm is able to successfully stop a penalty in approx. 96% of the trials, with an average training length of 813 trials. Without intermediate rewards and using transfer learning, the agent was able to stop a penalty with an accuracy of approx. 64.5% after an average of 7476 trials.",,2018
e12b0d74bc91ac49203ec46f4fa7f829532585c0,https://www.semanticscholar.org/paper/e12b0d74bc91ac49203ec46f4fa7f829532585c0,Robot Coverage Path Planning under Uncertainty Using Knowledge Inference and Hedge Algebras,"Human behaviour demonstrates environmental awareness and self-awareness which is used to arrive at decisions and actions or reach conclusions based on reasoning and inference. Environmental awareness and self-awareness are traits which autonomous robotic systems must have to effectively plan an optimal route and operate in dynamic operating environments. This paper proposes a novel approach to enable autonomous robotic systems to achieve efficient coverage path planning, which combines adaptation with knowledge reasoning techniques and hedge algebras to achieve optimal coverage path planning in multiple decision-making under dynamic operating environments. To evaluate the proposed approach we have implemented it in a mobile cleaning robot. The results demonstrate the ability to avoid static and dynamic (moving) obstacles while achieving efficient coverage path planning with low repetition rates. While alternative current coverage path planning algorithms have achieved acceptable results, our reported results have demonstrated a significant performance improvement over the alternative coverage path planning algorithms.",Machines,2018
8175081d2669b6b3597b49407c5f4d29ee172403,https://www.semanticscholar.org/paper/8175081d2669b6b3597b49407c5f4d29ee172403,A deep Q-Learning based Path Planning and Navigation System for Firefighting Environments,"Live fire creates a dynamic, rapidly changing environment that presents a worthy challenge for deep learning and artificial intelligence methodologies to assist firefighters with scene comprehension in maintaining their situational awareness, tracking and relay of important features necessary for key decisions as they tackle these catastrophic events. We propose a deep Q-learning based agent who is immune to stress induced disorientation and anxiety and thus able to make clear decisions for navigation based on the observed and stored facts in live fire environments. As a proof of concept, we imitate structural fire in a gaming engine called Unreal Engine which enables the interaction of the agent with the environment. The agent is trained with a deep Q-learning algorithm based on a set of rewards and penalties as per its actions on the environment. We exploit experience replay to accelerate the learning process and augment the learning of the agent with human-derived experiences. The agent trained under this deep Q-learning approach outperforms agents trained through alternative path planning systems and demonstrates this methodology as a promising foundation on which to build a path planning navigation assistant capable of safely guiding fire fighters through live fire environments.",ICAART,2020
c138133577e40f56f64be95ab493a678bc6ee325,https://www.semanticscholar.org/paper/c138133577e40f56f64be95ab493a678bc6ee325,"Measuring User Experience, Usability and Interactivity of a Personalized Mobile Augmented Reality Training System","Innovative technology has been an important part of firefighting, as it advances firefighters’ safety and effectiveness. Prior research has examined the implementation of training systems using augmented reality (AR) in other domains, such as welding, aviation, army, and mathematics, offering significant pedagogical affordances. Nevertheless, firefighting training systems using AR are still an under-researched area. The increasing penetration of AR for training is the driving force behind this study, and the scope is to analyze the main aspects affecting the acceptance of AR by firefighters. The current research uses a technology acceptance model, extended by the external constructs of perceived interactivity and personalization, to consider both the system and individual level. The proposed model was evaluated by a sample of 200 users, and the results show that both the external variables of perceived interactivity and perceived personalization are prerequisite factors in extending the TAM model. The findings reveal that the usability is the strongest predictor of firefighters’ behavioral intentions to use the AR system, followed by the ease of use with smaller, yet meaningful, direct and indirect effects on firefighters’ intentions. The identified acceptance factors help AR developers enhance the firefighters’ experience in training operations.",Sensors,2021
7b578c21204f8400607218213872e5dd6aab1e70,https://www.semanticscholar.org/paper/7b578c21204f8400607218213872e5dd6aab1e70,A multi-constrained zeroing neural network for time-dependent nonlinear optimization with application to mobile robot tracking control,"Abstract Because of the strong dynamic behavior and computing power, zeroing neural networks (ZNNs) have been dee different time-dependent issues. However, due to the high nonlinearity and complexity, the research on finding a feasible ZNN to address time-dependent nonlinear optimization with multiple types of constraints still remains stagnant. To simultaneously handle multiple types of constraints for the time-dependent nonlinear optimization, this paper proposes a novel neural-network based model in a unified framework of ZNN. By using leveraging the Lagrange method, the time-dependent nonlinear optimization problem with multiple types of constraints is converted to a time-dependent equality system. The proposed multi-constrained ZNN (termed MZNN) inherently possesses the effectiveness of exponential convergence property by utilizing the time-derivative information. Theoretical analyses on the global stability and exponential convergence property are rigorously provided. Then, three general numerical examples in time-independent and time-dependent cases verify the computational performance of the proposed MZNN. An application based on the mobile robot for nonlinear optimization control sufficiently demonstrates the physical effectiveness of the proposed MZNN for the control of mobile robot with both performance-index optimization and multiple physical-limit constraints. Finally, comparisons with existing neural networks such as gradient neural network (GNN), and performance tests with investigation on computational complexity substantiate the superiority of the MZNN for the time-dependent nonlinear optimization subject to multiple types of constraints.",Neurocomputing,2021
b2d78c896c2f004317c9e7f20952eeaca5a6c9d4,https://www.semanticscholar.org/paper/b2d78c896c2f004317c9e7f20952eeaca5a6c9d4,A deep survey on supervised learning based human detection and activity classification methods,"Human detection and activity recognition is very important research area in the healthcare, video surveillance, pedestrian detection, intelligent vehicle system and home care center. Among the various human activity detection frameworks, the statistical based approach were most intensively studied and used in practice in which pattern recognition was traditionally formulated. More recently, supervised learning based techniques and methods imported from statistical learning theory have deserved increasing attention. Many new supervised learning methods such as transfer learning, multi-instance learning, and the new trends in deep learning techniques have used for the formulation of solutions to the human activity detection. This paper reviews the automatic human detection and their activity recognition in the video sequences and static images. We explain several problems of human detection and activity recognition in different steps such as processing, segmentation of human features extraction and classification. Moreover, discuss the problems in each step and provide the recent state- of-the-art methods, gaps between recent methods, technical difficulties, applications and their challenges. Several features extraction techniques and corresponding problems for human classification have been discussed in details. Special emphasis have been given on convolution neural network that solves the problem of human segmentation, efficient classification and activity recognition. The objective of this review paper is to summarize and review related of the established and recent methods used in various stages of a human detection and activity classification system and identify research topics and applications that are at the forefront of this exciting and challenging field. Further, the evaluation protocols (i.e. datasets and simulation tools) and possible solution of current limitation have been discussed briefly in this survey.",Multim. Tools Appl.,2021
be45fc6b9796ebaad59f3fabd88adfee1f65b242,https://www.semanticscholar.org/paper/be45fc6b9796ebaad59f3fabd88adfee1f65b242,Smart Video Surveillance System Based on Edge Computing,"New processing methods based on artificial intelligence (AI) and deep learning are replacing traditional computer vision algorithms. The more advanced systems can process huge amounts of data in large computing facilities. In contrast, this paper presents a smart video surveillance system executing AI algorithms in low power consumption embedded devices. The computer vision algorithm, typical for surveillance applications, aims to detect, count and track people’s movements in the area. This application requires a distributed smart camera system. The proposed AI application allows detecting people in the surveillance area using a MobileNet-SSD architecture. In addition, using a robust Kalman filter bank, the algorithm can keep track of people in the video also providing people counting information. The detection results are excellent considering the constraints imposed on the process. The selected architecture for the edge node is based on a UpSquared2 device that includes a vision processor unit (VPU) capable of accelerating the AI CNN inference. The results section provides information about the image processing time when multiple video cameras are connected to the same edge node, people detection precision and recall curves, and the energy consumption of the system. The discussion of results shows the usefulness of deploying this smart camera node throughout a distributed surveillance system.",Sensors,2021
8bc9957070741784b943be71a461212a9226d041,https://www.semanticscholar.org/paper/8bc9957070741784b943be71a461212a9226d041,Performing predefined tasks using the human-robot interaction on speech recognition for an industrial robot,"Abstract People who are not experts in robotics can easily implement complex robotic applications by using human–robot interaction (HRI). HRI systems require many complex operations such as robot control, image processing, natural speech recognition, and decision making. In this study, interactive control with an industrial robot was performed by using speech recognition software in the Turkish language. The collected voice data were converted to text data by using automatic speech recognition module based on deep neural networks (DNN). The proposed DNN (p-DNN) was compared to classic classification algorithms. Converted text data was improved in another module to select the process to be applied. According to selected process, position data were defined using image processing. The determined position information was sent to the robot using a fuzzy controller. The developed HRI system was implemented on a KUKA KR Agilus KR6 R900 sixx robot manipulator. The word accuracy rate of the p-DNN model was measured as 90.37%. The developed image processing module and fuzzy controller worked with minimal errors. The contribution of this study is that an industrial robot is easily programming using this software by people who are not experts in robotics and know Turkish.",Eng. Appl. Artif. Intell.,2020
a238000b334d2e9207c453edbf71e66a23cf2aa4,https://www.semanticscholar.org/paper/a238000b334d2e9207c453edbf71e66a23cf2aa4,Collision-Free Speed Alteration Strategy for Human Safety in Human-Robot Coexistence Environments,"This paper presents a novel real-time collision-free speed alteration strategy using a danger index and an elite real-coded genetic algorithm (ERGA) for environments in which humans and robots coexist or cooperate, in order to guarantee the safety of an operator who works with a collaborative robot. A danger index based on ellipsoid modeling of the operator and robot describes the degree of safety during human–robot interactions. The ERGA and a penalty function are used to solve the constrained nonlinear optimization problem to change the handling speed of the robot. Comparative simulation results show the superiority of the proposed method by comparing to two existing methods. The applicability of the proposed method is verified using two experiments involving a 6-DoF industrial manipulator with an EtherCAT network protocol, an RGB-D sensor and a real-time operation system.",IEEE Access,2020
e1529c1e71afe9a6525a506485064e4473fcae31,https://www.semanticscholar.org/paper/e1529c1e71afe9a6525a506485064e4473fcae31,Ground-penetrating radar-based underground environmental perception radar for robotic system,"In recent years, the environmental perception technology for robotic system has attracted a lot of attention from researchers, but only a little of studies on environmental perception technology are focused on the space underground. Meanwhile, in the field of mobile robotic systems, with the development of research on underground emergency hedging and buried targets’ high-resolution fault imaging, more and more attention has also been paid to underground environmental detection and perception. This article proposes a ground-penetrating radar-based underground environmental perception radar (UEPR) for mobile robotic system indoors. The underground environmental perception radar can achieve noncontact and real-time perception, which helps people detect buried targets and get the image of targets more conveniently and precisely. Major contributions of this work are threefold. Firstly, a stepped frequency continuous wave modulation and demodulation scheme is proposed; secondly, a switch device for a six-channel antenna array is designed and contributed; thirdly, based on a linear antenna array and a signal processing platform, the underground environmental perception radar is supposed to achieve three-dimensional imaging in underground space indoors with its low power consumption. For the experiment of three-dimensional imaging on the copper box and underground environment indoors, the process of imaging is successful, although the size of them is a little bigger than the real size. In addition, the comparison experiment shows that the resolution of underground environmental perception radar system is similar with that of sound wave methods, and the working range of underground environmental perception radar system is deeper than the others. It can be concluded that the underground environmental perception radar can detect the copper box underground and perceive something special within 1.5 m depth.",,2020
fc099e2d0a8236ce198d7eadd6abb183aa6847b0,https://www.semanticscholar.org/paper/fc099e2d0a8236ce198d7eadd6abb183aa6847b0,Macro workstep detection for assembly manufacturing,"In this paper, we introduce a detection system for macro worksteps in a manufacturing assembly line using depth images. The sensor is mounted on the ceiling with a top-down angle. The system was deployed in a real life industrial process where workers had to assemble an ATM machine. Experimental results show the effectiveness of three identification approaches that were used: (1) template matching using a single template per macro workstep, (2) multiple templates for macro worksteps and (3) template matching and motion detection in order to detect the transition between each two consecutive macro worksteps. Each approach has its own benefits in terms of processing speed, accuracy and precision and we discuss them in details along with the challenges the system had, in the discussion section. The results are also investigated in details and we present the future plans for the proposed detection system.",PETRA,2020
fc1f4a94c542381611b78fc2d55d580f306b93c3,https://www.semanticscholar.org/paper/fc1f4a94c542381611b78fc2d55d580f306b93c3,Collision-free path planning based on new navigation function for an industrial robotic manipulator in human-robot coexistence environments,"ABSTRACT This paper presents a method for real-time collision-free path planning that uses a new navigation function for environments in which humans and robots cooperate or coexist, which guarantees the safety of a human operator who works with a collaborative robot. This method follows 10 skeletal joints in a human operator, which are detected using an RGB-D sensor, in order to detect humans. A new navigation function ensures collision-free planning for a robotic manipulator that avoids local minima and generates a shorter path. Simulation results show the effectiveness of the proposed method in comparison to two existing methods. The applicability and practicability of the proposed method are demonstrated by experiments using a 6-DoF industrial manipulator HIWIN RA605 with an RGB-D vision sensor (Kinect V1), a real-time operation system extension (RTX64) and an EtherCAT network protocol.",,2020
043b35d5a9e3fdf67073220c15f80f31595fb84b,https://www.semanticscholar.org/paper/043b35d5a9e3fdf67073220c15f80f31595fb84b,Development of a human metabolic rate prediction model based on the use of Kinect-camera generated visual data-driven approaches,"Abstract Predicting thermal comfort is one of the primary building research domains due to its technical and environmental significance. A metabolic rate, one of the significant variables for predicting an individual's thermal comfort, is primarily based on the human body's activity level. While other human and environmental factors, such as air temperature and relative humidity are easily measured and collected, with the help of sensory devices, a metabolic rate varies with time, and is not easy to measure to determine an accurate thermal comfort estimation in reality. Therefore, this study investigated the potential use of Deep Learning algorithm to accurately estimate the metabolic rate for a better thermal comfort estimation. A series of chamber tests were conducted with 23 test participants. The Kinect sensor was adopted to detect a user's physical motion, by capturing the motion images. With the help of a wearable sensor, a user's heart rate was also measured to estimate a metabolic rate. This study found that males showed higher MET than females, and the high BMI group generated higher MET than the low BMI group. The result also indicated that an estimated accurate range of 77%–89% was reasonably acceptable in the self-MET prediction modeling, while it was 65% in the third-party MET prediction. Therefore, the outcome of this research confirms that it is possible to use the Kinect sensor as a remote sensing device to estimate a user's metabolic rate, based on the use of a Deep Learning algorithm developed per individual.",Building and Environment,2019
4ffed783cd3f56dadc447406ab9b41e6683a7574,https://www.semanticscholar.org/paper/4ffed783cd3f56dadc447406ab9b41e6683a7574,Deep 3D perception of people and their mobility aids,"Abstract Robots operating in populated environments, such as hospitals, office environments or airports, encounter a large variety of people with some of them having an advanced need for cautious interaction because of their advanced age or motion impairments. To provide appropriate assistance and support robot helpers require the ability to recognize people and their potential requirements. In this article, we present a people detection framework that distinguishes people according to the mobility aids they use. Our framework uses a deep convolutional neural network for detecting people in image data. For human-aware robots it is necessary to know where people are in a 3D world reference frame instead of only locating them in a 2D image, therefore we add a 3D centroid regression output to the network to predict the Cartesian position of people. We further use a probabilistic class, position and velocity tracker to account for false detections and occlusions. Our framework comes in two variants: The depth only variant targets high privacy demands, while the RGB only framework provides improved detection performance for non-critical applications. Both variants do not require additional geometric information about the environment. We demonstrate our approach using a dedicated dataset acquired with the support of a mobile robotic platform. The dataset contains five classes: pedestrian, person in wheelchair, pedestrian pushing a person in a wheelchair, person using crutches and person using a walking frame. Our framework achieves an mAP of 0.87 for RGB and 0.79 for depth images at a detection distance threshold of 0.5 m on our dataset, with a runtime of 53 ms per image. The annotated dataset is publicly available and our framework is made open source as a ROS people detector.",Robotics Auton. Syst.,2019
715b22c6f8286b7dbf05e08217db3d7b51c93091,https://www.semanticscholar.org/paper/715b22c6f8286b7dbf05e08217db3d7b51c93091,A Simple Geometrical-Based Calibration Technique for 3D Scanners with Rotating Platform,"Active three-dimensional (3D) scanning techniques usually create 3D models of real scenes by using known light patterns reflected by surfaces and captured by cameras. Each scanning technique has its own implementation issues, which can impact on its complexity, processing time and data precision. This paper proposes a simple geometrical-based calibration technique for 3D scanners with rotating platform. As we focus on low-cost and accessibility, the scanning system was implemented using offthe-shelf components. Also its structure was designed to be 3D printed. Two objects are scanned and their point clouds are used to assess the system performance. Results show that the proposed model presents a good trade-off between accuracy and implementation complexity with an average accuracy error equals to 0.196 mm and a mean squared error (MSE) smaller than 4.65%.","International journal of simulation: systems, science & technology",2019
9bc62e06f414e239f461ee0ee9318e5bbfe2e33a,https://www.semanticscholar.org/paper/9bc62e06f414e239f461ee0ee9318e5bbfe2e33a,From person to group re-identification via unsupervised transfer of sparse features,"Abstract The visual association of a person appearing in the field of view of different cameras is today well known as Person Re-Identification. Current approaches find a solution to such a problem by considering persons as individuals, hence avoiding the fact that frequently they form groups or move in crowds. In such cases, the information acquired by neighboring individuals can provide relevant visual context to boost the performance in re-identifying persons within the group. In light of enriched information, groups re-identification encompasses additional problems to the common person re-identification ones, such as severe occlusions and changes in the relative position of people within the group. In this paper, the single person re-identification knowledge is transferred by means of a sparse dictionary learning to group re-identification. First, patches extracted from single person images are used to learn a dictionary of sparse atoms. This is used to obtain a sparsity-driven residual group representation that is exploited to perform group re-identification. To evaluate the performance of the proposed approach, we considered the i-LIDS groups dataset that is the only group re-identification publicly available dataset. The benchmark datasets for single person re-identification evaluation do not include group information, hence we collected two additional datasets under challenging scenarios and used them to validate our solution.",Image Vis. Comput.,2019
a0931bca565826c7d9828298389bd71c709f9034,https://www.semanticscholar.org/paper/a0931bca565826c7d9828298389bd71c709f9034,Deep Learning Fusion of RGB and Depth Images for Pedestrian Detection,"In this paper, we propose an effective method based on the Faster-RCNN structureto combine RGB and depth images for pedestrian detection. During the training stage,we generate a semantic segmentation map from the depth image and use it to refine theconvolutional features extracted from the RGB images. In addition, we acquire moreaccurate region proposals by exploring the perspective projection with the help of depthinformation. Experimental results demonstrate that our proposed method achieves thestate-of-the-art RGBD pedestrian detection performance on KITTI [12] datase",BMVC,2019
aae061614b380c84ea29399ecd375bd682987a81,https://www.semanticscholar.org/paper/aae061614b380c84ea29399ecd375bd682987a81,Enhancement of Missing Face Prediction Algorithm with Kalman Filter and DCF-CSR,"Detection and tracking of moving objects in sequence videos has wide applications in security surveillance, and becomes concern to many researchers. In actual environmental conditions, with various lighting conditions, object tracking faces a number of challenges including partial or severe occlusion which causes some systems to lose information so that it is difficult to estimate object trajectory. In the domain of surveillance, human tracking should not only be based on face, but also based on other characteristics, so that wherever the person facing towards, the system is always able to do the tracking correctly. In this study the detection and alignment process employed Multi-task Cascaded Convolutional Networks and Kalman Filters to predict facial position. Then, at the times the face is not facing towards the camera, the system saves the color of the bounding box that was last seen and tracks by color using the Discriminative Correlation Filter with Channel and Spatial Reliability (DCF-CSR). The proposed method resulting in increasing a person's detection rate when facing away from the camera.",2019 International Conference on Electrical Engineering and Informatics (ICEEI),2019
bafa74ff81e5de7d33bce36106de38d5ba585baf,https://www.semanticscholar.org/paper/bafa74ff81e5de7d33bce36106de38d5ba585baf,Real-Time Person Re-Identification for Mobile Robots to Improve Human-Robot Interaction,"Mobile robots operating in seniors’ homes can serve as social companions and assist with daily tasks, thus enhancing the seniors’ quality of life [104]. In order for robots to assist seniors, it is crucial that they are equipped with sets of social and interactive skills to enable them to have natural and personalized interactions. Personalized interactions, such as using patients’ proper names or remembering personal preferences, is necessary to establish strong social relationships [4, 45], and is a key factor to improve trust in human-robot interaction [37]. A prerequisite for robots to achieve personalized interactions, however, is the ability to automatically recognize and re-identify people around them [4]. Existing person re-identification systems for mobile robots are highly restricted in terms of where robots can operate, and do not stimulate natural and personalized interactions because they need preliminary knowledge about the robot’s users [12, 18], rely on facial cues [113, 115], or use data collected from external sensors [45]. This thesis introduces two lightweight Siamese convolutional neural networks, LuNet Light and LuNet Lightest, designed for the problem of person re-identification in a robotic setting without relying on the aforementioned restrictions. Despite being significantly more lightweight than other person re-identification systems [3, 120], LuNet Lightest achieves near state-ofthe-art results on the MARS dataset evaluation protocols [135]. This thesis additionally presents a set of evaluation measures tailored to evaluate reidentification systems for robots operating in various environments. When simulating crowded environments, LuNet Lightest reaches 92.4% balanced accuracy on the proposed evaluation protocol. As a result of the lightweight architecture, LuNet Lightest achieves real-time frame-rates of 71.6 frames per second when using a GPU, 33.9 frames per second when using a CPU without GPU, and 15.7 frames per second when using only one core of the same CPU, rendering the proposed system highly suitable for low-cost, hardware-constrained robots. The proposed person re-identification system will enable assistive mobile robots to robustly and accurately identify their users, and is a preliminary step to improve trust and attain natural and personalized interaction between robots and patients.",,2019
bbed0501a7a3e0033c41cd89b21dbd97c25059e8,https://www.semanticscholar.org/paper/bbed0501a7a3e0033c41cd89b21dbd97c25059e8,Fast and Robust RGB-D Multiple Human Tracking Based on Part Model for Mobile Robots,"In this paper, we address the problem of multiple human tracking for mobile robots and proposed a fast and robust RGB-D multiple human tracking approach based on part model. Firstly, a simplified deformable part model method is used for fast human detection using RGB-D information. Then the partial occlusion is detected with depth information. Finally, part model and partial occlusion information are combined into data association process and an on-line appearance classification method with dynamic occlusion handling is proposed for robust tracking. The performance of the proposed method is evaluated on the public dataset, and experiment results have demonstrated the effectiveness of the proposed method.",2019 Chinese Control Conference (CCC),2019
e989286d575431d0c21d4e28a87c4d75ef99cb7a,https://www.semanticscholar.org/paper/e989286d575431d0c21d4e28a87c4d75ef99cb7a,Behavioral Pedestrian Tracking Using a Camera and LiDAR Sensors on a Moving Vehicle,"In this paper, we present a novel 2D–3D pedestrian tracker designed for applications in autonomous vehicles. The system operates on a tracking by detection principle and can track multiple pedestrians in complex urban traffic situations. By using a behavioral motion model and a non-parametric distribution as state model, we are able to accurately track unpredictable pedestrian motion in the presence of heavy occlusion. Tracking is performed independently, on the image and ground plane, in global, motion compensated coordinates. We employ Camera and LiDAR data fusion to solve the association problem where the optimal solution is found by matching 2D and 3D detections to tracks using a joint log-likelihood observation model. Each 2D–3D particle filter then updates their state from associated observations and a behavioral motion model. Each particle moves independently following the pedestrian motion parameters which we learned offline from an annotated training dataset. Temporal stability of the state variables is achieved by modeling each track as a Markov Decision Process with probabilistic state transition properties. A novel track management system then handles high level actions such as track creation, deletion and interaction. Using a probabilistic track score the track manager can cull false and ambiguous detections while updating tracks with detections from actual pedestrians. Our system is implemented on a GPU and exploits the massively parallelizable nature of particle filters. Due to the Markovian nature of our track representation, the system achieves real-time performance operating with a minimal memory footprint. Exhaustive and independent evaluation of our tracker was performed by the KITTI benchmark server, where it was tested against a wide variety of unknown pedestrian tracking situations. On this realistic benchmark, we outperform all published pedestrian trackers in a multitude of tracking metrics.",Sensors,2019
32500e24ba7728ee1d7e48df07a88ab20124317b,https://www.semanticscholar.org/paper/32500e24ba7728ee1d7e48df07a88ab20124317b,Skeleton-based bio-inspired human activity prediction for real-time human–robot interaction,"Activity prediction is an essential task in practical human-centered robotics applications, such as security, assisted living, etc., which is targeted at inferring ongoing human activities based on incomplete observations. To address this challenging problem, we introduce a novel bio-inspired predictive orientation decomposition (BIPOD) approach to construct representations of people from 3D skeleton trajectories. BIPOD is invariant to scales and viewpoints, runs in real-time on basic computer systems, and is able to recognize and predict activities in an online fashion. Our approach is inspired by biological research in human anatomy. To capture spatio-temporal information of human motions, we spatially decompose 3D human skeleton trajectories and project them onto three anatomical planes (i.e., coronal, transverse and sagittal planes); then, we describe short-term time information of joint motions and encode high-order temporal dependencies. By using Extended Kalman Filters to estimate future skeleton trajectories, we endow our BIPOD representation with the critical capabilities to reduce noisy skeleton observation data and predict the ongoing activities. Experiments on benchmark datasets have shown that our BIPOD representation significantly outperforms previous methods for real-time human activity classification and prediction from 3D skeleton trajectories. Empirical studies using TurtleBot2 and Baxter humanoid robots have also validated that our BIPOD method obtains promising performance, in terms of both accuracy and efficiency, making BIPOD a fast, simple, yet powerful representation for low-latency online activity prediction in human–robot interaction applications.",Auton. Robots,2018
44913843f0566a46303ecf681321c3e1b11e05da,https://www.semanticscholar.org/paper/44913843f0566a46303ecf681321c3e1b11e05da,Depth perception based on omnidirectional ring structured light,"Abstract A depth perception method based on omnidirectional image and ring structured light is proposed. Firstly, a new omnidirectional ring structured light pattern (ORSL) was presented. ORSL can simplify feature point extraction and locate the scene position more robust and fast. Secondly, a new sensor is proposed, which including an omnidirectional camera, laser projector and control circuit system. Thirdly, measurement accuracy was improved on error correction methods. Finally, a pose estimation method is designed to compute the location and direction of the imaging system. The experimental results demonstrated that the proposed method can acquire omnidirectional depth information about large-scale scene. The error analysis of multiple sets of depth data show the effectiveness of the method.",Optics & Laser Technology,2018
55b53602d4956b75c0007f283d0c53d04112b381,https://www.semanticscholar.org/paper/55b53602d4956b75c0007f283d0c53d04112b381,Protective Clothing Detection of Substation Workers Using S-HOG+C Operator,"This paper focuses on the application of the protective clothing detection system by using S-HOG+C operator for substation workers in order to meet the practical needs in a complex environment. An image is firstly divided into three cells including a helmet, upper and lower part of a body according to the characteristics of objects. The HOG and HOC features of the three cells are extracted individually to train a classifier. A linear Support Vector Machine is used in our study. The S-HOG+C operator is used to improve the detection accuracy on the protective clothing of substation workers. Three evaluation indicators are used to analyze the performance of the S-HOG+C operator. The experimental results suggest that the S-HOG+C operator perform better than the HOG+C operator in the protective clothing detection for substation workers. This work is supported by Science and Technology Project of Guangdong Power Grid Co., Ltd. (GDKJXM20162351).",2018 International Conference on Power System Technology (POWERCON),2018
b87a7d18ac97b10eb823827567f456321dc0254c,https://www.semanticscholar.org/paper/b87a7d18ac97b10eb823827567f456321dc0254c,ExTCKNN: Expanding Tree-Based Continuous K Nearest Neighbor Query in Road Networks With Traffic Rules,"The existing continuous nearest neighbor query algorithms of moving objects in road networks do not consider any traffic rule and assume that the speed of moving objects is constant and the topology of road networks never change. However, in real road networks, the object’s speed and the road network’s structure change frequently Hence, these would make the existing methods ineffective when applying to the real-world road network environment To overcome the aforementioned disadvantages, we propose a Data Modeling approach of Road Networks with traffic rules (called DMRNR) and design a novel Expanding Tree-based Continuous k Nearest Neighbors algorithm (abbreviate for ExTCKNN) that can be well adopted to the actual road network environment. The algorithm consists of three steps: 1) it obtains the query results to store using DMRNR in the initial phase; 2) it maintains the data model of road networks by monitoring the real-time change information; and 3) the results are generated according to the submitted query with the updated data model and the latest state of moving objects The merit of the proposed algorithm lies in that it queries the nearest neighbors by taking the movements of the moving object and the variety of the road networks into consideration Extensive experiments are conducted and the experimental results demonstrate a significant improvement of the proposed method when compared with conventional solutions.",IEEE Access,2018
d615fcff9b6c2bc1fc5fd2d52f746b3dffcb60a4,https://www.semanticscholar.org/paper/d615fcff9b6c2bc1fc5fd2d52f746b3dffcb60a4,Robust Algorithm for Dress Recognition of Substation Operators Based on Sensitivity Radial Basis Function Neural Network,"At the substation job site, the use of intelligent video surveillance technology can greatly reduce the supervision burden on safety inspectors for irregular operations of operators. However, in the outdoor complex working environment, the identification accuracy of recognition algorithm based on the traditional radial basis function neural Network (RBFNN) is not high enough and the missing alarm rate is high. In order to solve this problem, this paper proposes the RBFNN robust algorithm for dress recognition based on classifier output sensitivity. The algorithm firstly extracts the shape and color feature vector of the helmet, the top and the bottom of the operator image. Then, the Monte Carlo method is used to randomly sample the points in the neighborhood of training samples to expand the number of samples and reduce the volatility of the classifier output. And then, the loss function that considers the sensitivity of the sample neighborhood is established. Finally, the weights from the hidden layer to the output layer are solved by Gauss-Newton method. The RBFNN classifier based on Gaussian function is established. The simulation results show that the recognition algorithm based on sensitivity RBFNN (S-RBFNN) can effectively reduce the missing alarm rate, which is more robust in practical applications.",2018 International Conference on Power System Technology (POWERCON),2018
1c38185bdfb9a3414d0f37afb966bd5470141541,https://www.semanticscholar.org/paper/1c38185bdfb9a3414d0f37afb966bd5470141541,Fast k-Nearest Neighbor Searching in Static Objects,"The k-nearest neighbor searching is a classical problem that has been seriously studied, due to its many important applications. The paper proposes an efficient algorithm to search the k-nearest neighbors for static objects. Since locations of static objects are known in advance and not changed, most of existing solutions build a kd-tree as a preprocessing and search the k- nearest neighbors by using it. We propose a completely different preprocessing with kd-trees. The core idea of this paper is to build in advance the k-nearest neighbors of each static object as a preprocessing. If a querying point q is given, the nearest object p of q is firstly searched and then the k-nearest neighbors of q are found by using the k-nearest neighbors of p. It is to use the feature that two objects may share many neighbors if they are spatially close to each other. In order to measure the performance of the proposed algorithm, we have a number of experiments. The results of experiments showed that the proposed algorithm is 2–3 times quicker than the method using kd-tree in the Point Cloud Library(PCL).",Wirel. Pers. Commun.,2017
2c85c3f3ed586e841ad9fce95dd6c97437c1bf68,https://www.semanticscholar.org/paper/2c85c3f3ed586e841ad9fce95dd6c97437c1bf68,Multiple camera based multiple object tracking under occlusion: A survey,"In recent years, vision based technologies have gained immense attention across academia-industries to enable optimal surveillance solution for event monitoring, analysis and control. However, the complexities of real time environment and expected functional characteristics often put question over existing approaches and their efficacy. In this paper, a number of the existing approaches for vision based object detection and tracking have been discussed. One of the important issues which come across in the object tracking is Occlusion. However, a very few efforts have been done to alleviate occlusion issues so as to enable optimal moving object detection and tracking. This review paper reveals that to enable efficient multiple object detection and tracking under occlusion conditions, the combination of different features such as depth data, geometry, textural, color feature metrics, speed, etc can be taken into consideration. With multiple synchronized cameras set up, 3D techniques including depth estimation, azimuth, texture, color, geometric information and speed etc, in conjunction with optimal trajectory estimation model can be vital for multiple objects tracking under occlusions. In addition, efficient region of interest (ROI) feature extraction, trajectory estimation and feature fusion across synchronized cameras can be explored to track multiple objects under occlusions. Synchronizing multiple cameras with best feature training, association, continuous object skeletal tracking using stochastic trajectory prediction and classification; can be an effective solution, especially for traffic surveillance or outdoor surveillance applications.",2017 International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),2017
2dcbebebd2ee884f04341e27e630226eb21389d4,https://www.semanticscholar.org/paper/2dcbebebd2ee884f04341e27e630226eb21389d4,Real-time gymnast detection and performance analysis with a portable 3D camera,"Abstract Sports analysis is a useful application of technology, providing value to athletes, coaches, and sports fans by producing quantitative evaluations of performance. To address this field in the context of men’s gymnastics, we introduce a system that utilizes a Microsoft Kinect 2 camera to automatically evaluate the performance of a gymnast on the pommel horse apparatus, specifically in regards to the consistency of the gymnast’s timing and body angle. The Kinect’s ability to determine the depth at each pixel provides information not available to typical sports analysis approaches based solely on RGB data. Our approach consists of a three stage pipeline that automatically identifies a depth of interest, localizes the gymnast, detects when the gymnast is performing a certain routine, and finally provides an analysis of that routine. We demonstrate that each stage of the pipeline produces effective results: our depth of interest approach identifies the gymnast 97.8% of the time and removes over 60% of extraneous data; our activity recognition approach is highly efficient and identifies ‘spinning’ by the gymnast with 94.8% accuracy; and our performance analysis method evaluates the gymnast’s timing with accuracy only limited by the frame rate of the Kinect. Additionally, we validate our system and the proposed methods with a real-world online application, used by actual gymnastics coaches and viewed as a highly effective training tool.",Comput. Vis. Image Underst.,2017
3555784fbbf7ba81b8d713a4d157999fa0b2261a,https://www.semanticscholar.org/paper/3555784fbbf7ba81b8d713a4d157999fa0b2261a,Mobile Robot Moving Target Detection and Tracking System,"In order to solve the problem that the robot can coexist harmoniously with human beings and provide better service in the human settlement environment. Based on the Mecanum wheel mobile robot platform, by introducing the pyramid optical flow algorithm and CamShift algorithm, empirical results show that the robot can quickly predict the movement tendency and speed of the moving object according to the moving characteristics and color characteristic information of the moving object as well as accurate identification of tracking. Based on the above algorithm research, it can effectively improve the ability of robot motion planning and executing tasks in complex environment.",,2017
398246ac90a7abc2c0f319f604017062c4593e58,https://www.semanticscholar.org/paper/398246ac90a7abc2c0f319f604017062c4593e58,Machine-Vision-Based Human-Oriented Mobile Robots: A Review,"In this paper we present a study of vision-based, human-recognition solutions in human-oriented, mobile-robot applications. Human recognition is composed of detection, tracking and identification. Here, we provide an analysis of each step. The applied vision systems can be conventional 2D, stereo or omnidirectional. The camera sensor can be designed to detect light in the visible or infrared parts of the electromagnetic spectrum. Regardless of the method or the type of sensor chosen, the best results in human recognition can be obtained by using a multimodal solution. In this case, the vision system is enhanced with other forms of sensory information. The most common sensors are laser range finders, microphones and sonars. As medicine is expected to be one of the main fields of application for mobile robots, we give it special emphasis. An overview of current applications and proposal of potential future applications are given. Without doubt, properly controlled mobile robots will play an ever-increasing role in the future of medicine.",,2017
3fbf32a428db505e0bb45177016e8851d9b31e97,https://www.semanticscholar.org/paper/3fbf32a428db505e0bb45177016e8851d9b31e97,Multiple human tracking in RGB-depth data: a survey,"Multiple human tracking (MHT) is a fundamental task in many computer vision applications. Appearance-based approaches, primarily formulated on RGB data, are constrained and affected by problems arising from occlusions and/or illumination variations. In recent years, the arrival of cheap RGB-depth devices has led to many new approaches to MHT, and many of these integrate colour and depth cues to improve each and every stage of the process. In this survey, the authors present the common processing pipeline of these methods and review their methodology based (a) on how they implement this pipeline and (b) on what role depth plays within each stage of it. They identify and introduce existing, publicly available, benchmark datasets and software resources that fuse colour and depth data for MHT. Finally, they present a brief comparative evaluation of the performance of those works that have applied their methods to these datasets.",IET Comput. Vis.,2017
410f9d063d09659745d04425d217fde72eafa9e1,https://www.semanticscholar.org/paper/410f9d063d09659745d04425d217fde72eafa9e1,Occlusion handling of visual tracking by fusing multiple visual clues,"In this paper, a robust visual tracking system with occlusion handling is proposed to track the target with real-time performance. The thermal camera, which can observe the heat originated from the target such as the human body or vehicle, can collaborate with the color camera to track the target in the cluttered environment or under occlusion. Unlike the general tracking by using the color camera and the thermal camera, which simply verifies the target hypotheses in these two kinds of image domains, a sampling multiple importance resampling scheme is proposed here to efficiently generate the hypotheses and verify them. The better hypotheses in the color and thermal images are selected to evaluate the sparse appearance representation such that the target under severe occlusion can be identified with real-time performance. Using this resampling scheme, the diversity and the convergency are simultaneously considered by adaptively fusing the hypotheses in the color and thermal images. Moreover, the updating strategy of target image model is designed by estimating the occlusion ratio and the environmental similarity such that the robustness of tracking can be greatly increased. Finally, the proposed approaches have been validated in several scenes to present the tracking performance.","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",2017
49bed15812b6cea708a6b114956f41034b8bcbfe,https://www.semanticscholar.org/paper/49bed15812b6cea708a6b114956f41034b8bcbfe,Detecting humans in RGB-D data with CNNs,"We address the problem of people detection in RGB-D data where we leverage depth information to develop a region-of-interest (ROI) selection method that provides proposals to two color and depth CNNs. To combine the detections produced by the two CNNs, we propose a novel fusion approach based on the characteristics of depth images. We also present a new depth-encoding scheme, which not only encodes depth images into three channels but also enhances the information for classification. We conduct experiments on a publicly available RGB-D people dataset and show that our approach outperforms the baseline models that only use RGB data.",2017 Fifteenth IAPR International Conference on Machine Vision Applications (MVA),2017
5150c6748efa633f1a5f86e1105c01a4a27d8e5e,https://www.semanticscholar.org/paper/5150c6748efa633f1a5f86e1105c01a4a27d8e5e,Fast Motion Object Detection Algorithm Using Complementary Depth Image on an RGB-D Camera,"Stereo vision has become a popular topic in recent years, especially in-depth images from stereo vision. Depth information can be extracted either from a dual camera or RGB-D camera. In image processing, the realization of object detection is only based on the color information or depth images separately; however, both have advantages and disadvantages. Therefore, many researchers have combined them together to achieve better results. A new fast motion object-detection algorithm is presented based on the complementary depth images and color information, which is able to detect motion objects without background noise. The experiment results show that the proposed fast object detection algorithm can achieve 84.4% of the segmentation accuracy rate on average with a 45 FPS computation speed on an embedded platform.",IEEE Sensors Journal,2017
56a74f0f8f18895b114839ee53c2f6e36950a5c5,https://www.semanticscholar.org/paper/56a74f0f8f18895b114839ee53c2f6e36950a5c5,Template Deformation-Based 3-D Reconstruction of Full Human Body Scans From Low-Cost Depth Cameras,"Full human body shape scans provide valuable data for a variety of applications including anthropometric surveying, clothing design, human-factors engineering, health, and entertainment. However, the high price, large volume, and difficulty of operating professional 3-D scanners preclude their use in home entertainment. Recently, portable low-cost red green blue-depth cameras such as the Kinect have become popular for computer vision tasks. However, the infrared mechanism of this type of camera leads to noisy and incomplete depth images. We construct a stereo full-body scanning environment composed of multiple depth cameras and propose a novel registration algorithm. Our algorithm determines a segment constrained correspondence for two neighboring views, integrating them using rigid transformation. Furthermore, it aligns all of the views based on uniform error distribution. The generated 3-D mesh model is typically sparse, noisy, and even with holes, which makes it lose surface details. To address this, we introduce a geometric and topological fitting prior in the form of a professionally designed high-resolution template model. We formulate a template deformation optimization problem to fit the high-resolution model to the low-quality scan. Its solution overcomes the obstacles posed by different poses, varying body details, and surface noise. The entire process is free of body and template markers, fully automatic, and achieves satisfactory reconstruction results.",IEEE Transactions on Cybernetics,2017
6475c1e95da0a3bd36786a32d00a893d85460e9e,https://www.semanticscholar.org/paper/6475c1e95da0a3bd36786a32d00a893d85460e9e,Combined image- and world-space tracking in traffic scenes,"Tracking in urban street scenes plays a central role in autonomous systems such as self-driving cars. Most of the current vision-based tracking methods perform tracking in the image domain. Other approaches, e.g. based on LIDAR and radar, track purely in 3D. While some vision-based tracking methods invoke 3D information in parts of their pipeline, and some 3D-based methods utilize image-based information in components of their approach, we propose to use image- and world-space information jointly throughout our method. We present our tracking pipeline as a 3D extension of image-based tracking. From enhancing the detections with 3D measurements to the reported positions of every tracked object, we use world-space 3D information at every stage of processing. We accomplish this by our novel coupled 2D-3D Kalman filter, combined with a conceptually clean and extendable hypothesize-and-select framework. Our approach matches the current state-of-the-art on the official KITTI benchmark, which performs evaluation in the 2D image domain only. Further experiments show significant improvements in 3D localization precision by enabling our coupled 2D-3D tracking.",2017 IEEE International Conference on Robotics and Automation (ICRA),2017
98497eb9268cd9cdb8acb24631408769dedfcb5a,https://www.semanticscholar.org/paper/98497eb9268cd9cdb8acb24631408769dedfcb5a,Design and implementation of an omnidirectional vision system for robot perception,"Abstract To meet the demand of surrounding detection of a humanoid robot, we developed an omnidirectional vision system for robot perception (OVROP) with 5 Degrees of Freedom (DOFs). OVROP has a modular design and mainly consists of three parts: hardware, control architecture and visual processing part (omnidirectional vision and stereovision). As OVROP is equipped with universal hardware and software interfaces it can be applied to various types of robots. Our performance evaluation proves that OVROP can accurately detect and track an object with 360° field of view (FOV). Besides, undistorted omnidirectional perception of surroundings can be achieved through calibrations of both monocular and stereo cameras. Furthermore, our preliminary experimental results show that OVROP can perceive a desired object within 160 ms in most cases. As a result, OVROP can provide detailed information on surrounding environment for full-scope and real-time robot perception.",,2017
b507ce8ff842c48ef1cd328cf40b9993ce85d245,https://www.semanticscholar.org/paper/b507ce8ff842c48ef1cd328cf40b9993ce85d245,Hand Gesture Recognition for Sign Language Transcription,"Sign Language is a language which allows mute people to communicate. The ease of communication offered by this language, however, disappears when one of the interlocutors, who may or not be mute, does not know Sign Language and a conversation starts using that language. In this document, I discuss research efforts that resulted in a system that takes advantage of Convolutional Neural Networks to recognize hand letter and number gestures from American Sign Language based on depth images captured by the Kinect camera. As a byproduct of these research efforts, I created a new dataset which consists of depth images of American Sign Language letters and numbers, I conducted an empirical assessment and I compared the presented method for image recognition against a similar dataset but for Vietnamese Sign Language. Finally, I present how this work supports my ideas for the future work on a complete system for Sign Language transcription.",,2017
ba4a9062c350800c36c62704b33ae0cf8a1d93b8,https://www.semanticscholar.org/paper/ba4a9062c350800c36c62704b33ae0cf8a1d93b8,Object Recognition and Positioning with the Kinect Camera,"Robocup Middle Size League (MSL) is an international robot competition, in which 5 robots play soccer like human beings. This project is based on the hardware platform (TURTLE) which is currently used by Tech United MSL team. Before this project, the Kinect camera from Microsoft was used solely for detection of a standard yellow ball, and this was done using color segmentation and blob detection techniques. The intention for this project is to develop a new algorithm to improve the performance and functionality of the Kinect camera. A framework of object recognition and positioning is proposed in this report, with combining the color image and the depth image in a proper designed way, to achieve real-time object recognition and positioning task. The algorithm designed in this project focuses on peer robot detection and positioning, but if needed, in principle any object can be added into this framework. This algorithm first detects candidate objects in the depth image, after which they are mapped onto the corresponding color image, where high quality texture information exists. On the extracted color image, a trained Cascade AdaBoost classifier is applied to verify the candidate objects. This algorithm can run in a efficient way. On NVidia Jetson TK1 board, it can obtain the frequency of 28 Hz (the highest record, with detecting arbitrarily number of peer robots). Object Recognition and Positioning with the Kinect Camera iii",,2017
c6eb9525be65d9a5ef823020135fdea08d025928,https://www.semanticscholar.org/paper/c6eb9525be65d9a5ef823020135fdea08d025928,A Hybrid Multi-Objective Scheme Applied to Redundant Robot Manipulators,"In this paper, a hybrid multi-objective scheme is proposed to complete simultaneously four objectives, i.e., the specified primary task for the end-effector, obstacle avoidance, joint-physical limits avoidance, and repetitive motion of redundant robot manipulators. In addition, corresponding theoretical analysis is given, which guarantees the validity of the proposed scheme. Then, the proposed hybrid multi-objective scheme is reformulated as a dynamical quadratic program (DQP) problem. The optimal solution of the DQP problem is found by the PLPE (piecewise-linear projection equation) neural network, i.e., PLPENN, and also by the corresponding numerical algorithm implemented on the computer. Furthermore, simulation and comparison based on a six-link planar redundant robot manipulator substantiate the effectiveness and accuracy of the proposed scheme. At last, a hardware experiment is conducted on a six-link physical robot manipulator system, which substantiates the physical realizability, operational stability, and safety of the proposed hybrid multi-objective scheme.",IEEE Transactions on Automation Science and Engineering,2017
d21a971631dccb379bd9db1755fe462223739462,https://www.semanticscholar.org/paper/d21a971631dccb379bd9db1755fe462223739462,Shape matching based leader tracking for a mobile robot with night vision ability,"Görsel kılavuzlanan bir mobil robotun baş etmesi gereken sorunlarından biri gece görüştür. Mobil robotların diğer bir uygulama alanı ise lider takibidir. Bu çalışmada bu amaçlara yönelik tasarlanmış Bilecik Mobil Robot (BLMρ) tanıtılmaktadır. Çalışmada gece görüş IRLED kamera ile sağlanırken şekil taşıyan lideri bulma ve takip etme bölgesel tanımlayıcılar, 2B çapraz korelasyon ve şekil betimleyici ile başarılmıştır. Kalman filtresi ile hesapsal yük azaltılarak daha etkin bir takip algoritması oluşturulmuştur. BLMρ lider üzerindeki şeklin görsel geribesleme ile elde edilen merkezinin görüntüdeki konumunu ve BLMρ’ya uzaklığını belirten görüntüdeki alanını giriş olarak almaktadır. Bu girişleri kullanan bulanık mantık birimi sağ ve sol tekerler için kontrol işaretleri üretmektedir. Çalışmada belirtilen aşamalar ayrıntılarıyla verilmiş, lider takibi için kullanılan yöntemler karşılaştırılmış ve deneysel sonuçlar sunulmuştur. One of the problems that a visually guided mobile robot has to deal with is night vision. Another application field of mobile robots is leader tracking. In this study, Bilecik Mobile Robot (BLMρ) which is designed for these purposes is introduced. While night vision is provided by an IRLED camera, shape carrying leader detection and following is achieved with regional descriptors, 2D cross-correlation and shape context. A more efficient following algorithm is obtained by decreasing computational cost with Kalman filtering. BLMρ takes the position of the center of the shape on the leader obtained from visual feedback and the shape area defining the distance between BLMρ and the leader as inputs. A fuzzy logic unit uses these inputs to generate control signals for left and right wheels. In the study, these stages are given in details, the methods used for leader tracking are compared and experimental results are presented.",,2017
ea6379f6f58ce2a554475856e6183d04f207f4ad,https://www.semanticscholar.org/paper/ea6379f6f58ce2a554475856e6183d04f207f4ad,"Robot Learning from Human Demonstration: Interpretation, Adaptation, and Interaction","Robot Learning from Demonstration (LfD) is a research area that focuses on how robots can learn new skills by observing how people perform various activities. As humans, we have a remarkable ability to imitate other human’s behaviors and adapt to new situations. Endowing robots with these critical capabilities is a significant but very challenging problem considering the complexity and variation of human activities in highly dynamic environments. This research focuses on how robots can learn new skills by interpreting human activities, adapting the learned skills to new situations, and naturally interacting with humans. This dissertation begins with a discussion of challenges in each of these three problems. A new unified representation approach is introduced to enable robots to simultaneously interpret the high-level semantic meanings and generalize the low-level trajectories of a broad range of human activities. An adaptive framework based on feature space decomposition is then presented for robots to not only reproduce skills, but also autonomously and e ciently adjust the learned skills to new environments that are significantly di↵erent from demonstrations. To achieve natural Human Robot Interaction (HRI), this dissertation presents a Recurrent Neural Network based deep perceptual control approach, which is capable of integrating multi-modal perception sequences with actions for robots to interact with humans in long-term tasks. Overall, by combining the above approaches, an autonomous system is created for robots to acquire important skills that can be applied to human-centered applications. Finally, this dissertation concludes with a discussion of future directions that could",,2017
26c46bcffaeebb8e0543f042aacd24a9c6146599,https://www.semanticscholar.org/paper/26c46bcffaeebb8e0543f042aacd24a9c6146599,Detection of humans from depth images,"With the development of consumer depth sensors, research on human detection and tracking from depth images has gained momentum. Depth information facilitates the extraction of objects from the background, and enables localization of these objects in 3D space. In this work, we present a new dataset of depth images acquired from indoor environments, such as home, office, coffee shop, where people are present in a variety of poses. We propose a new method for detection of unmoving humans, and test our algorithm on our new dataset.",2016 24th Signal Processing and Communication Application Conference (SIU),2016
4ee4a540b3a2bbfe263573852d2a5f6231002145,https://www.semanticscholar.org/paper/4ee4a540b3a2bbfe263573852d2a5f6231002145,Human activity recognition and gymnastics analysis through depth imagery,"Depth imagery is transforming many areas of computer vision, such as object recognition, human detection, human activity recognition, and sports analysis. The goal of my work is twofold: (1) use depth imagery to effectively analyze the pommel horse event in men’s gymnastics, and (2) explore and build upon the use of depth imagery to recognize human activities through skeleton representation. I show that my gymnastics analysis system can accurately segment a scene based on depth to identify a ‘depth of interest’, ably recognize activities on the pommel horse using only the gymnast’s silhouette, and provide an informative analysis of the gymnast’s performance. This system runs in real-time on an inexpensive laptop, and has been built into an application in use by elite gymnastics coaches. Furthermore, I present my work expanding on a bio-inspired skeleton representation obtained through depth data. This representation outperforms existing methods in classification accuracy on benchmark datasets. I then show that it can be used to interact in real-time with a Baxter humanoid robot, and is more accurate at recognizing both complete and ongoing interactions than current state-of-the-art methods.",,2016
62b5fc7fde246e52580836f7ae939ac161e4ba37,https://www.semanticscholar.org/paper/62b5fc7fde246e52580836f7ae939ac161e4ba37,Robust Multimodal Sequence-Based Loop Closure Detection via Structured Sparsity,"Loop closure detection is an essential component for simultaneously localization and mapping in a variety of robotics applications. One of the most challenging problems is to perform long-term place recognition with strong perceptual aliasing and appearance variations due to changes of illumination, vegetation, weather, etc. To address this challenge, we propose a novel Robust Multimodal Sequence-based (ROMS) method for long-term loop closure detection, by formulating image sequence matching as an optimization problem regularized by structured sparsity-inducing norms. Our method is able to model the sparsity nature of place recognition, i.e., the current location should match only a small subset of previously visited places, as well as to model underlying structures of image sequences and incorporate multiple feature modalities to construct a discriminative scene representation. In addition, a new optimization algorithm is developed to efficiently solve the formulated problem, which has a theoretical guarantee to converge to the global optimal solution. To evaluate the ROMS algorithm, extensive experiments are performed using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have validated that our algorithm outperforms previous loop closure detection methods, and obtains the state-of-the-art performance on long-term place recognition.",Robotics: Science and Systems,2016
6cd79845f22c6c8b6b86e5e206bc723daf4e5074,https://www.semanticscholar.org/paper/6cd79845f22c6c8b6b86e5e206bc723daf4e5074,Depth and Thermal Image Fusion for Human Detection with Occlusion Handling Under Poor Illumination from Mobile Robot,"In this paper we present a vision-based approach to detect multiple persons with occlusion handling from a mobile robot in real-world scenarios under two lighting conditions, good illumination (lighted) and poor illumination (dark). We use depth and thermal information that are fused for occlusion handling. First, a classifier is trained using thermal images of the human upper-body. This classifier is used to obtain the bounding box coordinates of human. The depth image is later fused with the region of interest obtained from the thermal image. Using the initial bounding box, occlusion handling is performed to determine the final position of human in the image. The proposed method significantly improves human detection even in crowded scene and poor illumination.",,2016
6f207e5ea798c2f460d4ed7b191c55bea97ee251,https://www.semanticscholar.org/paper/6f207e5ea798c2f460d4ed7b191c55bea97ee251,People detection and tracking using RGB-D cameras for mobile robots,"People detection and tracking is an essential capability for mobile robots in order to achieve natural human–robot interaction. In this article, a human detection and tracking system is designed and validated for mobile robots using color data with depth information RGB-depth (RGB-D) cameras. The whole framework is composed of human detection, tracking and re-identification. Firstly, ground points and ceiling planes are removed to reduce computation effort. A prior-knowledge guided random sample consensus fitting algorithm is used to detect the ground plane and ceiling points. All left points are projected onto the ground plane and subclusters are segmented for candidate detection. Meanshift clustering with an Epanechnikov kernel is conducted to partition different points into subclusters. We propose the new idea of spatial region of interest plan view maps which are employed to identify human candidates from point cloud subclusters. Here, a depth-weighted histogram is extracted online to feature a human candidate. Then, a particle filter algorithm is adopted to track the human’s motion. The integration of the depth-weighted histogram and particle filter provides a precise tool to track the motion of human objects. Finally, data association is set up to re-identify humans who are tracked. Extensive experiments are conducted to demonstrate the effectiveness and robustness of our human detection and tracking system.",,2016
949c01d0e00c22bb30b5590ca2adb09e02783232,https://www.semanticscholar.org/paper/949c01d0e00c22bb30b5590ca2adb09e02783232,CoDe4D: Color-Depth Local Spatio-Temporal Features for Human Activity Recognition From RGB-D Videos,"Human activity recognition has a variety of important real-world applications, such as video analysis, surveillance, and human-robot interaction. As a promising video representation method, local spatio-temporal (LST) features have received increasing attention from computer vision, machine learning, and robotics communities. However, approaches based on traditional LST features only use color information, which face several challenges, such as illumination changes and dynamic backgrounds. The recent availability of commercial color-depth cameras makes it much cheaper, faster, and easier to acquire depth information, which provides a potential to implement more discriminative and robust LST features. In this paper, we introduce the new 4-D color-depth (CoDe4D) LST feature that incorporates both intensity and depth information acquired from RGB-D cameras. Our feature detector constructs a saliency map through applying independent filters in xyzt dimension to represent texture, shape and pose variations, and selects its local maxima as interest points. Our multichannel orientation histogram descriptor applies a 4-D support region, which is adaptive to linear perspective view changes, on each interest point. Then, image gradients of color-depth patches within the support region are computed and quantized using a spherical coordinate-based method to form a final feature vector. We build a complete activity recognition system by combining our features with bag-of-features representations and support vector machines. To evaluate the performance of our CoDe4D LST features and the complete system, we conduct experiments using four benchmark color-depth human activity data sets, including UTK Action3-D, Berkeley MHAD, ACT42, and MSR daily activity 3-D data sets. Experimental results demonstrate the promising representative power of our CoDe4D features, which obtain the state-of-the-art performance on activity recognition from RGB-D visual data.",IEEE Transactions on Circuits and Systems for Video Technology,2016
aba8008b8c2f3149260b596b1d16549cf2e772f7,https://www.semanticscholar.org/paper/aba8008b8c2f3149260b596b1d16549cf2e772f7,Enforcing Template Representability and Temporal Consistency for Adaptive Sparse Tracking,"Sparse representation has been widely studied in visual tracking, which has shown promising tracking performance. Despite a lot of progress, the visual tracking problem is still a challenging task due to appearance variations over time. In this paper, we propose a novel sparse tracking algorithm that well addresses temporal appearance changes, by enforcing template representability and temporal consistency (TRAC). By modeling temporal consistency, our algorithm addresses the issue of drifting away from a tracking target. By exploring the templates' long-term-short-term representability, the proposed method adaptively updates the dictionary using the most descriptive templates, which significantly improves the robustness to target appearance changes. We compare our TRAC algorithm against the state-of-the-art approaches on 12 challenging benchmark image sequences. Both qualitative and quantitative results demonstrate that our algorithm significantly outperforms previous state-of-the-art trackers.",IJCAI,2016
abe4440713b5c51e76b44315916fcdb684bd5a79,https://www.semanticscholar.org/paper/abe4440713b5c51e76b44315916fcdb684bd5a79,Scene Depth Perception Based on Omnidirectional Structured Light,"A depth perception method combining omnidirectional images and encoding structured light was proposed. First, a new structured light pattern was presented by using monochromatic light. The primitive of the pattern consists of four-direction sand clock-like (FDSC) image. FDSC can provide more robust and accurate position compared with conventional pattern primitive. Second, on the basis of multiple reference planes, a calibration method of projector was proposed to significantly simplify projector calibration in the constructed omnidirectional imaging system. Third, a depth point cloud matching algorithm based on the principle of prior constraint iterative closest point under mobile condition was proposed to avoid the effect of occlusion. The experimental results demonstrated that the proposed method can acquire omnidirectional depth information about large-scale scenes. The error analysis of 16 groups of depth data reported a maximum measuring error of 0.53 mm and an average measuring error of 0.25 mm.",IEEE Transactions on Image Processing,2016
ad783c47ab14e48c30337cf126667817e116514e,https://www.semanticscholar.org/paper/ad783c47ab14e48c30337cf126667817e116514e,Multiple Human Tracking in RGB-D Data: A Survey,"Multiple human tracking (MHT) is a fundamental task in many computer vision applications. Appearance-based approaches, primarily formulated on RGB data, are constrained and affected by problems arising from occlusions and/or illumination variations. In recent years, the arrival of cheap RGB-Depth (RGB-D) devices has {led} to many new approaches to MHT, and many of these integrate color and depth cues to improve each and every stage of the process. In this survey, we present the common processing pipeline of these methods and review their methodology based (a) on how they implement this pipeline and (b) on what role depth plays within each stage of it. We identify and introduce existing, publicly available, benchmark datasets and software resources that fuse color and depth data for MHT. Finally, we present a brief comparative evaluation of the performance of those works that have applied their methods to these datasets.",ArXiv,2016
c19776b78d4e4d521e8af5c49f70be820f611374,https://www.semanticscholar.org/paper/c19776b78d4e4d521e8af5c49f70be820f611374,Evolution Strategy Sampling Consensus for Robust Estimator,,J. Adv. Comput. Intell. Intell. Informatics,2016
e4ebbca30f6a1f28b02544c9b4b55677f1a0849a,https://www.semanticscholar.org/paper/e4ebbca30f6a1f28b02544c9b4b55677f1a0849a,ROBUST HUMAN DETECTION WITH OCCLUSION HANDLING BY FUSION OF THERMAL AND DEPTH IMAGES FROM MOBILE ROBOT,"In this paper, a robust surveillance system to enable robots to detect humans in indoor environments is proposed. The proposed method is based on fusing information from thermal and depth images which allows the detection of human even under occlusion. The proposed method consists of three stages; pre-processing, ROI generation and object classification. A new dataset was developed to evaluate the performance of the proposed method. The experimental results show that the proposed method is able to detect multiple humans under occlusions and illumination variations.",,2016
516a014f4654c90a22ae3d363b6e80bda68a084d,https://www.semanticscholar.org/paper/516a014f4654c90a22ae3d363b6e80bda68a084d,Adaptive human-centered representation for activity recognition of multiple individuals from 3D point cloud sequences,"Activity recognition of multi-individuals (ARMI) within a group, which is essential to practical human-centered robotics applications such as childhood education, is a particularly challenging and previously not well studied problem. We present a novel adaptive human-centered (AdHuC) representation based on local spatio-temporal features (LST) to address ARMI in a sequence of 3D point clouds. Our human-centered detector constructs affiliation regions to associate LST features with humans by mining depth data and using a cascade of rejectors to localize humans in 3D space. Then, features are detected within each affiliation region, which avoids extracting irrelevant features from dynamic background clutter and addresses moving cameras on mobile robots. Our feature descriptor is able to adapt its support region to linear perspective view variations and encode multi-channel information (i.e., color and depth) to construct the final representation. Empirical studies validate that the AdHuC representation obtains promising performance on ARMI using a Meka humanoid robot to play multi-people Simon Says games. Experiments on benchmark datasets further demonstrate that our adaptive human-centered representation outperforms previous approaches for activity recognition from color-depth data.",2015 IEEE International Conference on Robotics and Automation (ICRA),2015
5b712609db31bd51b320e7371a0595a60e74f0ba,https://www.semanticscholar.org/paper/5b712609db31bd51b320e7371a0595a60e74f0ba,Embedded human-following mobile-robot with an RGB-D camera,"Embedded device recently becomes more crucial in some real-life applications, such as the entertainment, health care, and industrial application. Given the development of embedded devices, the mobile robot becomes not only cheaper, but also more highly practical to produce. However, the embedded device still has some limitation from the hardware capability, therefore the implemented method has to be robust and low computational complexity. In this research, we introduce an embedded human following mobile robot application with an RGB-D camera, which can help us detect human position based on the human geometry, compatible into the ARM-based embedded device. The Human Depth of Interest (HDOI) is proposed to cooperate with CAM-shift algorithm for the human detection and tracking. The virtual spring model with the safe region and active region is chosen to carry out the smoothing navigation and easy implementation. The performance of our approach is enhanced more accuracy than the original CAM-shift algorithm and more feasible than the stereo vision system.",2015 14th IAPR International Conference on Machine Vision Applications (MVA),2015
5b82242f57965687cc608e556b214c685ad9e1b9,https://www.semanticscholar.org/paper/5b82242f57965687cc608e556b214c685ad9e1b9,Bio-inspired predictive orientation decomposition of skeleton trajectories for real-time human activity prediction,"Activity prediction is an essential task in practical human-centered robotics applications, such as security, assisted living, etc., which targets at inferring ongoing human activities based on incomplete observations. To address this challenging problem, we introduce a novel bio-inspired predictive orientation decomposition (BIPOD) approach to construct representations of people from 3D skeleton trajectories. Our approach is inspired by biological research in human anatomy. In order to capture spatio-temporal information of human motions, we spatially decompose 3D human skeleton trajectories and project them onto three anatomical planes (i.e., coronal, transverse and sagittal planes); then, we describe short-term time information of joint motions and encode high-order temporal dependencies. By estimating future skeleton trajectories that are not currently observed, we endow our BIPOD representation with the critical predictive capability. Empirical studies validate that our BIPOD approach obtains promising performance, in terms of accuracy and efficiency, using a physical TurtleBot2 robotic platform to recognize ongoing human activities. Experiments on benchmark datasets further demonstrate that our new BIPOD representation significantly outperforms previous approaches for real-time activity classification and prediction from 3D human skeleton trajectories.",2015 IEEE International Conference on Robotics and Automation (ICRA),2015
626197f9be088d84177504de20fa0a46a4d4d961,https://www.semanticscholar.org/paper/626197f9be088d84177504de20fa0a46a4d4d961,A Robust Visual Human Detection Approach With UKF-Based Motion Tracking for a Mobile Robot,"Robust tracking of a human in a video sequence is an essential prerequisite to an increasing number of applications, where a robot needs to interact with a human user or operates in a human-inhabited environment. This paper presents a robust approach that enables a mobile robot to detect and track a human using an onboard RGB-D sensor. Such robots could be used for security, surveillance, and assistive robotics applications. The proposed approach has real-time computation power through a unique combination of new ideas and well-established techniques. In the proposed method, background subtraction is combined with depth segmentation detector and template matching method to initialize the human tracking automatically. A novel concept of head and hand creation based on depth of interest is introduced in this paper to track the human silhouette in a dynamic environment, when the robot is moving. To make the algorithm robust, a series of detectors (e.g., height, size, and shape) is utilized to distinguish target human from other objects. Because of the relatively high computation time of the silhouette-matching-based method, a confidence level is defined, which allows using the matching-based method only where it is imperative. An unscented Kalman filter is used to predict the human location in the image frame to maintain the continuity of the robot motion. The efficacy of the approach is demonstrated through a real experiment on a mobile robot navigating in an indoor environment.",IEEE Systems Journal,2015
77e7b12fe4a0ff50acb47a525df95216dbcc9e31,https://www.semanticscholar.org/paper/77e7b12fe4a0ff50acb47a525df95216dbcc9e31,An ultra-fast human detection method for color-depth camera,"An extremely fast technique to locate positions that are plausibly humans is proposed to quickly reduce searching space.A novel knowledge based human locator which can deal with partial occlusion and incomplete depth data is proposed.A stepwise filtering framework enables the system to perform very quickly (80-140fps). Real-time human detection is important for a wide range of applications. The task is highly challenging due to occlusions, complex backgrounds, and variation of human poses. We propose a cascade-structured approach to real-time human detection in cluttered and dynamic environments with both color and depth data seamlessly incorporated. The first stage efficiently exploits depth data which generates a set of physically plausible yet over-detected candidates. These candidates are then purified by another two filters: a knowledge based human upper portion locator and a data-driven learning based filter. Experimental results show high detection accuracy achieved by the proposed method at 80-140fps on a single CPU core (without GPU acceleration).",J. Vis. Commun. Image Represent.,2015
9d4519a1fd223b6ab511246afbd032d6dfbc0e56,https://www.semanticscholar.org/paper/9d4519a1fd223b6ab511246afbd032d6dfbc0e56,Detecting and tracking people in real time with RGB-D camera,"A PEI representation is proposed to alleviate overlapping in original image domain while preserving information of all pixels.A human plausible candidates locating technique is proposed to quickly reduce search space of the detector.Two novel features are proposed to characterize human shape and appearance in 3D space.A single-pass, progressive refinement framework enables the system to achieve high accuracy at real time. We propose a novel approach to automatic detection and tracking of people taking different poses in cluttered and dynamic environments using a single RGB-D camera. The original RGB-D pixels are transformed to a novel point ensemble image (PEI), and we demonstrate that human detection and tracking in 3D space can be performed very effectively with this new representation. The detector in the first phase quickly locates human physiquewise plausible candidates, which are then further carefully filtered in a supervised learning and classification second phase. Joint statistics of color and height are computed for data association to generate final 3D motion trajectories of tracked individuals. Qualitative and quantitative experimental results obtained on the publicly available office dataset, mobile camera dataset and the real-world clothing store dataset we created show very promising results.",Pattern Recognit. Lett.,2015
ba6aec7f1b17833e7983809926a90951469f5520,https://www.semanticscholar.org/paper/ba6aec7f1b17833e7983809926a90951469f5520,People perception from RGB-D cameras for mobile robots,"Understanding how humans move through the scene is a key issue of decision-making for an autonomous mobile robot in crown people zones. So accurately detecting and tracking people from a mobile platform can help improve interaction effective and efficient. In this paper, we proposed a people detection and tracking system using combination of a several new techniques for mobile robots, plan-view maps, depth weighted histograms, and GNN data association. We proposed a spatial region of interest based plan-view maps to detect human candidates. Firstly, point cloud sub-clusters were segmented for candidate detection. Two different plan-view maps, named occupancy map and height map, were employed to identify human candidates from point cloud sub-clusters. Meanwhile, a depth weighted histogram was extracted to feature a human candidate. Then, a particle filter algorithm was adopted to track human's motion. Finally, data association was set up to re-identify humans which were tracked. Extensive experiments demonstrated the effectiveness and robustness of our human detection and tracking system.",2015 IEEE International Conference on Robotics and Biomimetics (ROBIO),2015
dffa5cc1ecf7d1f39d9a3b610d98c3eac844f649,https://www.semanticscholar.org/paper/dffa5cc1ecf7d1f39d9a3b610d98c3eac844f649,Fusion of thermal and depth images for occlusion handling for human detection from mobile robot,"In this paper we present a vision-based approach to detect multiple persons from a mobile robot in real world scenarios using thermal and depth images. First, human upper-body is detected from thermal image to obtain the bounding box coordinates (BBC). This is used as an initial estimate of the position of a person. Then, depth image is fused with the region of interest obtained from the thermal image. Occlusion detection is then performed using the BBC to obtain the actual position of detected persons. The proposed method is able to detect persons and is able to resolve occlusions during the detection process to correctly obtain all the persons in the view.",2015 10th Asian Control Conference (ASCC),2015
fb62b9f4287ff249df2948fe2f9fe4cea524e8e6,https://www.semanticscholar.org/paper/fb62b9f4287ff249df2948fe2f9fe4cea524e8e6,Multisensor Information Fusion for People Tracking With a Mobile Robot: A Particle Filtering Approach,"People tracking based on multisensor information fusion is addressed. A framework is presented for fusing the laser range finder (LRF) data and the monocular camera data. Based on this framework, an LRF-based detection algorithm is proposed to identify the pairs of human legs, by combining motion information and metric features. Moreover, a geometric observation model is developed for the camera to extract both the range and bearing measurements of the target person by focusing the target's shoes with the camera. Then, a near-optimal particle filter is designed to fuse the measurements from the LRF and the camera. To prevent the sample impoverishment, a procedure of sample diversity improvement is used after the resampling step. The full occlusion problem is solved using image matching based on speeded up robust feature. Note that either of the LRF and the camera can work independently, since both the range and bearing are simultaneously acquired from the LRF or the camera. As a result, flexible and robust tracking can be achieved. Extensive experiments demonstrate that the proposed approach achieves high tracking accuracy and robustness. Especially, only a very small number of particles suffice to maintain good tracking performance.",IEEE Transactions on Instrumentation and Measurement,2015
6028f819adb0e79e8b846f4ff52fc7f1d4ee5711,https://www.semanticscholar.org/paper/6028f819adb0e79e8b846f4ff52fc7f1d4ee5711,RGB-D Human Detection and Tracking for Industrial Environments,"Reliably detecting and tracking movements of nearby workers on the factory floor are crucial to the safety of advanced manufacturing automation in which humans and robots share the same workspace. In this work, we address the problem of multiple people detection and tracking in industrial environments by proposing algorithms which exploit both color and depth data to robustly track people in real time. For people detection, a cascade organization of these algorithms is proposed, while tracking is performed based on a particle filter which can interpolate sparse detection results by exploiting color histograms of people. Tracking results of different combinations of the proposed methods are evaluated on a novel dataset collected with a consumer RGB-D sensor in an industrial-like environment. Our techniques obtain good tracking performances even in an industrial setting and reach more than 30 Hz update rate. All these algorithms have been released as open source as part of the ROS-Industrial project.",IAS,2014
9ef9d2f9915a858e8e9cdccffdea4205f5ec72ae,https://www.semanticscholar.org/paper/9ef9d2f9915a858e8e9cdccffdea4205f5ec72ae,Visual Mapping in Light-Crowded Indoor Environments,"Due to the recent success of affordable RGBD cameras, solutions to the Visual Simultaneous Localization and Mapping (VSLAM) problem has experienced a huge leap. To enable accurate mapping solutions, most of the proposed solutions expect static environments. Thinking of industrial applications, there is no guarantee for static environments. The SLAM algorithm has to cope with moving objects like human beings. We present an approach to detect moving objects in RGBD camera images. The approach is based on point cloud and image filtering techniques. We present test results using publicly available datasets. We further show the performance and influence of the algorithm on mapping and on the accuracy of a visual SLAM system.",IAS,2014
c1a35c25139e4eb94c34cbcca4eabe574c4466e8,https://www.semanticscholar.org/paper/c1a35c25139e4eb94c34cbcca4eabe574c4466e8,"3D Robotic Sensing of People: Human Perception, Representation and Activity Recognition","The robots are coming. Their presence will eventually bridge the digital-physical gap and dramatically impact human life by taking over tasks where our current society has shortcomings (e.g., search and rescue, elderly care, and child education). Humancentered robotics (HCR) is a vision to address how robots can coexist with humans and help people live safer, simpler and more independent lives. As humans, we have a remarkable ability to perceive the world around us, perceive people, and interpret their behaviors. Endowing robots with these critical capabilities in highly dynamic human social environments is a significant but very challenging problem in practical human-centered robotics applications. This research focuses on robotic sensing of people, that is, how robots can perceive and represent humans and understand their behaviors, primarily through 3D robotic vision. In this dissertation, I begin with a broad perspective on human-centered robotics by discussing its real-world applications and significant challenges. Then, I will introduce a real-time perception system, based on the novel concept of Depth of Interest, to detect and track multiple individuals using a color-depth camera that is installed on intelligent mobile robotic platforms. In addition, I will discuss human representation approaches, based on local spatio-temporal features, including new CoDe4D features that incorporate both color and depth information, a new SOD descriptor to efficiently quantize 3D visual features, and the novel AdHuC features, which are capable of representing the activities of multiple individuals. Several new algorithms to recognize human activities are also discussed, including the RG-PLSA model, which allows us to discover activity patterns without supervision, the MCHCRF model, which can explicitly investigate certainty in latent temporal patterns, and the FuzzySR model, which is used to segment continuous data into events and probabilistically recognize human activities. Cognition models based on recognition results are also implemented for decision making that allow robotic systems to react to human activities. Finally, I will conclude with a discussion of future directions that will accelerate the upcoming technological revolution of human-centered robotics.",,2014
0f7b762385171ea3d7a53a3405bdb68ac65a0302,https://www.semanticscholar.org/paper/0f7b762385171ea3d7a53a3405bdb68ac65a0302,Review of Intellectual Video Surveillance Through Internet of Things,"Abstract Surveillance is a vital utility in all places to enable the provision of a secure environment for the well-being of living folks and can be effectively achieved with the help of a video. Industries, along with researchers, are endeavoring hard to overcome the difficulties seen in the implementation of a mature Internet of Things (IoT) framework for a video surveillance application. Video surveillance and the IoT are converged for ensuring compactness for the nodes of video surveillance, ease of time, and high efficiency, and for providing video surveillance over Internet of Things (VS-IoT). This chapter highlights the analysis of VS-IoT and articulates the important stages of enactment. Added to that, it also depicts the contemporary technologies and challenges present in each stage, so that it could lead the research of successful intelligent video surveillance enactment.",,2020
1d103943d69a3e7ccb6f5d98666443a9b23a4b0d,https://www.semanticscholar.org/paper/1d103943d69a3e7ccb6f5d98666443a9b23a4b0d,Deep learning for the internet of things: Potential benefits and use-cases,"Abstract The massive number of sensors deployed in the Internet of Things (IoT) produce gigantic amounts of data for facilitating a wide range of applications. Deep Learning (DL) would certainly play a role in generating valuable inferences from this massive volume of data and hence will assist in creating smarter IoT. In this regard, exploring the potential of DL for IoT data analytics becomes highly crucial. This paper begins with a concise discussion on the Deep Neural Network (DNN) and its different architectures. The potential benefits that DL will bring to the IoT are also discussed. Then, a detailed review of DL-driven IoT use-cases is presented. Moreover, this paper formulates a DL-based model for Human Activity Recognition (HAR) and carries out a performance comparison of the proposed model with other machine learning techniques to delineate the superiority of the DL model over other techniques. Apart from enlightening the potential of DL in IoT applications, this paper will serve as an impetus to encourage advanced research in the realm of DL-driven IoT applications.",,2020
666a88b8198e0ef9e647e3dbde096f65379579f9,https://www.semanticscholar.org/paper/666a88b8198e0ef9e647e3dbde096f65379579f9,Compiler compatible 5.66 Mb/mm2 8T 1R1W register file in 14 nm FinFET technology,"Abstract 1-read/1-write (1R1W) register file (RF) is a popular memory configuration in modern feature rich SoCs requiring significant amount of embedded memory. A memory compiler is constructed using the 8T RF bitcell spanning a range of instances from 32 b to 72 Kb. An 8T low-leakage bitcell of 0.106 μm2 is used in a 14 nm FinFET technology with a 70 nm contacted gate pitch for high-density (HD) two-port (TP) RF memory compiler which achieves 5.66 Mb/mm2 array density for a 72 Kb array which is the highest reported density in 14 nm FinFET technology. The density improvement is achieved by using techniques such as leaf-cell optimization (eliminating transistors), better architectural planning, top level connectivity through leaf-cell abutment and minimizing the number of unique leaf-cells. These techniques are fully compatible with memory compiler usage over the required span. Leakage power is minimized by using power-switches without degrading the density mentioned above. Self-induced supply voltage collapse technique is applied for write and a four stack static keeper is used for read Vmin improvement. Fabricated test chips using 14 nm process have demonstrated 2.33 GHz performance at 1.1 V/25 °C operation. Overall Vmin of 550 mV is achieved with this design at 25 °C. The inbuilt power-switch improves leakage power by 12x in simulation. Approximately 8% die area of a leading 14 nm SoC in commercialization is occupied by these compiled RF instances.",Integr.,2020
e151016f18d1309eff39a454b55d244b6a60dd21,https://www.semanticscholar.org/paper/e151016f18d1309eff39a454b55d244b6a60dd21,The Socioethical Implications of Body Worn Computers: An Ethnographic Study,"This thesis explores the socioethical implications of body worn computers (BWC) using an ethnographic approach. Furthermore, a subset, body worn cameras (BWCs), combines data with value added constancy through Location Based Services (LBS) over wireless network connections. The aim of this investigation was to engage global leaders from transdisciplinary stakeholder groups in semi-structured interviews, conversations and events, situating a review of the social impact and ethical implications of BWCs. A critical discourse analysis using a Foucauldian approach reveals power relations, which are then infused through narrative with unique intercultural perspectives, differentiating ‘location’ from ‘place’. The author of this study has subsequently identified through Grounded Theory that BWCs are causal agency for disconnect from proper culture which can be addressed through the application of Ngikalikarra, a unique framework for empathetic understanding of place and community engagement.",,2020
ebf460f03eac179bf0ca216a69613e2b5386af81,https://www.semanticscholar.org/paper/ebf460f03eac179bf0ca216a69613e2b5386af81,Image monitoring and recognition processing based on neural network,"Abstract With the development of economy and the abundance of material, people tend to travel. In the peak season of tourism, the scenic spots are crowded and easy to cause trample and safety problems. The traditional monitoring methods are rigid and have low recognition accuracy. This paper briefly introduced the image monitoring and recognition system and the back-propagation (BP) neural network used for identifying the trampling risk areas in the monitoring images. After that, the image monitoring and recognition system was simulated by using MATLAB software, and it was compared with the traditional entropy method and state-of-the-art CNN. The results showed that the three methods could identify the area with trampling risk in the image, but the image monitoring and recognition system designed in this study was more comprehensive and had lower false alarm rate and shorter recognition time than the traditional information entropy method and state-of-the-art CNN. In summary, the image monitoring and recognition system designed in this study can efficiently and accurately identify the trampling risk areas in the monitoring images.",,2020
015231c19f196e3bc51496c6036a52bdaa7a3d84,https://www.semanticscholar.org/paper/015231c19f196e3bc51496c6036a52bdaa7a3d84,A Survey of Motion Detection in Image Sequences,"Detection of motion is an essential and important step in many applications such as in the use of video surveliance in security systems, anomaly detection, traffic monitoring, people tracking. Detection of the moving object is a growing research area because of its extensive applications in real life. This paper emphasizes on survey of different algorithms for detection of motion. The most commonly used strategy of subtraction of background is described in detail. A survey of different techniques of motion detection is presented in this paper. The novel method of detection of motion for the pedestrian (indoor) without the need of finger printing of location proposed by Zohuis explained in detail. The advantages of schemes presented are also mentioned. The novel technique of detecting both global and local motion which is coherent, proposed by Yunpeng Wu is described in detail with its advantages and comparison with the previous related works. The applications of detection of motion are presented in this paper. A detailed description of widely used datasets along with the examples of frames of the datasets is given in this paper.",2019 6th International Conference on Computing for Sustainable Global Development (INDIACom),2019
69db4587911b481261a9f70c6873d63058b4b5fc,https://www.semanticscholar.org/paper/69db4587911b481261a9f70c6873d63058b4b5fc,A Laterally Driven MEMS Inertial Switch With Double-Layer Suspended Springs for Improving Single-Axis Sensitivity,"A novel laterally driven inertial switch with double-layer springs has been proposed and fabricated by surface micromachining technology for improving single-axial sensitivity. The symmetrical distribution of double-layer suspended springs and the constraint structures limits the displacement of the proof mass in the off-axis sensitive direction under an acceleration disturbance. The ANSYS simulation results reveal that compared with the inertial switch with one layer springs, the symmetrical distribution of double-layer serpentine springs effectively reduces the displacement of the proof mass in the off-axis direction. The design of symmetrical distribution of double-layer serpentine springs plays an important role in resisting small acceleration disturbance from the off-axis sensitive  $z$ -direction, and the constraint structures can resist the large acceleration disturbance. The modal analysis, contact time, and the collision response in the inertial switch have also been simulated and discussed. Finally, the proposed inertial switch has been fabricated successfully, and the prototype is tested by a dropping hammer system. The test results show that the threshold level of the fabricated inertial switch is 272 g with 20- $\mu \text{s}$  contact time. The combined efforts of double-layer suspended springs and constraint structures effectively lower off-axis sensitivity and improve the single-axis sensitivity of the microelectromechanical system inertial switch.","IEEE Transactions on Components, Packaging and Manufacturing Technology",2018
a1ab94437ccf46d60ee47f121c72274404072e16,https://www.semanticscholar.org/paper/a1ab94437ccf46d60ee47f121c72274404072e16,A Light-Powered Smart Camera With Compressed Domain Gesture Detection,"This paper presents an ultralow power smart camera with gesture detection. Low power is achieved by directly extracting gesture features from the compressed measurements, which are the block averages and the linear combinations of the image sensor’s pixel values. We present two classifier techniques to allow low computational and storage requirements. The system has been implemented on an analog devices BlackFin ULP vision processor. By enabling ultralow energy consumption, we demonstrate that the system is powered by ambient light harvested through photovoltaic cells whose output is regulated by TI’s dc–dc buck converter with maximum power point tracking. Measured data reveals that with only 400 compressed measurements (<inline-formula> <tex-math notation=""LaTeX"">$768\times $ </tex-math></inline-formula> compression ratio) per frame, the system is able to recognize key wake-up gestures with greater than 80% accuracy and only <inline-formula> <tex-math notation=""LaTeX"">$95mJ$ </tex-math></inline-formula> of energy per frame. Owing to its fully self-powered operation, the proposed system can find wide applications in “always-on” vision systems, such as in surveillance, robotics, and consumer electronics with touch-less operation.",IEEE Transactions on Circuits and Systems for Video Technology,2018
1b09317646cdd377fbaa19a62f0281590d6a96a1,https://www.semanticscholar.org/paper/1b09317646cdd377fbaa19a62f0281590d6a96a1,A real-time embedded system for human action recognition using template matching,Human action recognition system proposed here recognizes the behavior of a person in real-time. The system aims at communicating the recognized gestures with the camera system. The proposed system initiates on identifying the human action provided in the database and it sends the trigger signals to the camera system so as to record and store the video stream within the system. The video stream is then transmitted to through web page with the aid of IoT. The system is also provided with a buzzer that activates on recognizing the human action. Template matching algorithm is used to recognize and identify actions from the captured video frame directly. The system is realized using Beaglebone board with ARM CORTEX A8 processor and OpenCV is used as the software tool to implement the system.,"2017 IEEE International Conference on Electrical, Instrumentation and Communication Engineering (ICEICE)",2017
429cbf14676bc561e58a1c0c3040271dc2deda6e,https://www.semanticscholar.org/paper/429cbf14676bc561e58a1c0c3040271dc2deda6e,A novel IOT based approach to establish an ultra-low power self security system,"Rape cases and similar violation are nowadays a leading menace to women and children. An important step to eradicate this problem is to monitor and support them in the case of a crisis. To endure with this situation, an intelligent camera system is introduced to capture and transmit the video of unlawful activities. The system acts as an alert system and also as a location tracker. The embedded system implemented here is adopted to provide the system with fast processing rate, accuracy and low power. The proposed system adopts a hidden camera system that makes smart decisions and becomes active on recognizing human postures and hand gestures maintained in the database. On processing and recognizing gestures by the frontend of the camera system, the system starts recording the video and sends an alert message to the authorized officials. As the self security system is supported with IOT environment, it enables the system to transmit the video to the cloud platform. And the anti-social activities could be monitored through smartphone/PC. Moreover, the hidden Markov and Baum-Welch algorithm is adopted to classify, train and test the system. In order to enable an ultra-low power operation, the system is implemented using ARM cortex A8 processor with optimized algorithm.","2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)",2017
7816db3e38dc73b8e8fbcbe7e21c05bff21610ce,https://www.semanticscholar.org/paper/7816db3e38dc73b8e8fbcbe7e21c05bff21610ce,Human Posture Detection in Always-on Body Worn Cameras,"Internet of Things (IoTs) is the emerging Technology as the third wave in the development of the internet. IOT is accepted to have massive impact sensors, surveillance devices; wearable’s and body area networks with advanced interface technique. This leads to the need for a hardware-software co-design approach. We present a highly parameterized hardware design allowing configurability and the ability to evaluate different design choices in a short amount of time. This paper aims to analyze the use of Deep learning algorithm for building such reconfigurable low power devices. We develop the hardware architecture for such a system and provide experimental results obtained for the case study of Posture detection for body worn cameras used for law enforcement. Our proposed system, implemented on a Raspberry picamera platform uses minimal power consumption with an accuracy of more than 90% for the selected case study of Posture Detection. ",,2017
063f9fd699c3b014a74ccd5c0437a53cd6c3100d,https://www.semanticscholar.org/paper/063f9fd699c3b014a74ccd5c0437a53cd6c3100d,A MEMS inertial switch with compact constraint structures for lowering off-axis sensitivity,"This paper proposes two novel laterally-driven inertial switches with multi-directional constraint structures for lowering off-axis sensitivity. First one is the inertial switch with one layer of serpentine springs. The second is the inertial switch with two layers of serpentine springs. ANSYS software was used to simulate the dynamic contact process of inertial switch, and the simulation results reveal that the design of symmetrical distribution of double layers serpentine springs plays an important role in resisting small acceleration disturbance from off-axis sensitive z-direction, and the constraint structures can resist large acceleration disturbance. The fabricated inertial switch by surface micromachining technology has been evaluated using a drop hammer system. The test results show that the symmetrical distribution of double layers serpentine springs reduce the displacement of proof mass in the off-axis sensitive direction under a small acceleration disturbance. Therefore, The combined efforts of double layers suspended springs and constraint structures effectively lower the off-axis sensitivity of the MEMS inertial switch.",2016 IEEE SENSORS,2016
58bf7814ecb6842184251743c43819724c0f9c61,https://www.semanticscholar.org/paper/58bf7814ecb6842184251743c43819724c0f9c61,"A Light-powered, ""Always-On"", Smart Camera with Compressed Domain Gesture Detection","In this paper we propose an energy-efficient camera-based gesture recognition system powered by light energy for ""always on"" applications. Low energy consumption is achieved by directly extracting gesture features from the compressed measurements, which are the block averages and the linear combinations of the image sensor's pixel values. The gestures are recognized using a nearest-neighbour (NN) classifier followed by Dynamic Time Warping (DTW). The system has been implemented on an Analog Devices Black Fin ULP vision processor and powered by PV cells whose output is regulated by TI's DC-DC buck converter with Maximum Power Point Tracking (MPPT). Measured data reveals that with only 400 compressed measurements (768x compression ratio) per frame, the system is able to recognize key wake-up gestures with greater than 80% accuracy and only 95mJ of energy per frame. Owing to its fully self-powered operation, the proposed system can find wide applications in ""always-on"" vision systems such as in surveillance, robotics and consumer electronics with touch-less operation.",ISLPED,2016
abe6e61a07cfa657cc35844c937b8b6061bd91fd,https://www.semanticscholar.org/paper/abe6e61a07cfa657cc35844c937b8b6061bd91fd,Voice-controlled Assistance for Robot Navigation Using Android-based Mobile Devices,"Mobile robotics is an interesting area in which movable objects handle different pre-specified tasks such as line following, object relocation, etc. The advancements in the field of Automatic Speech Recognition (ASR) enable systems to support speech processing capability. This also gives scope to IoT devices that interact with speech dialogue systems. Designing such interfaces is not a straight forward job because of the challenges involved in handling spoken languages. The complexity will increase even more in the context of low resource languages. Adapting language specific features can help in developing such interfaces in IoT environments. In this paper, a speech dialog system is developed for Indian English language to operate robot movements. The system was developed using NXT Lego and Raspberry Pi. The architecture of the system with implementation details are discussed in the paper.","2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)",2021
3267a0747e3aa60c4fefe73ea0ae81d9eb2615e6,https://www.semanticscholar.org/paper/3267a0747e3aa60c4fefe73ea0ae81d9eb2615e6,RD-CNN: A Compact and Efficient Convolutional Neural Net for Sound Classification,"Classification of signals (sounds, biomedical, etc.) occurs in various circumstances, often requiring low-complexity implementations for various resources-constrained platforms such as mobile or embedded systems within the IoT framework. Herein we describe preliminary results for a novel recognition system where a compact and fast transform, the reaction-diffusion transform (RDT), is used to generate spectral images. Such images are then processed into a novel type of compact convolution neural network (called NL-CNN) where nonlinear convolution is emulated. The ESC-50 environmental sound database with 50 sound categories was considered for parameter tuning and performance evaluation. Despite its low complexity, a reasonable well accuracy is demonstrated (up to 76.5%) close to the human accuracy reported on the same dataset and better in both accuracy and complexity when compared to similar approaches reported in the literature and based on mel-cepstrum. These results provide a basis for a novel and effective method for time-series recognition in general.",2020 International Symposium on Electronics and Telecommunications (ISETC),2020
d93bf3cc4c544a105f29175bd2751e09f5add35a,https://www.semanticscholar.org/paper/d93bf3cc4c544a105f29175bd2751e09f5add35a,Comparative Study of Extreme Learning Machine using Various Computing Platforms,"This paper focuses on testing the performance of an optimized extreme learning machine (ELM) algorithm using various resources-constrained computational platforms, to be used in autonomous intelligent vehicles. The purpose of this comparative study is to find the best suited embedded computational platform for future use in an experimental autonomous mobile robot, where computing power, responsiveness and power consumption are key to further development. The aforementioned algorithm was used as a benchmarking tool in this performance review, but also as an important starting point for processing large amounts of different data types from the robots' sensorial units. For now, the conducted experiments are limited to pre-trained datasets, to have a precise output of the very same data type.",2019 6th International Symposium on Electrical and Electronics Engineering (ISEEE),2019
645e45503a7f5fdbedafc5827e2dec3e1630d00f,https://www.semanticscholar.org/paper/645e45503a7f5fdbedafc5827e2dec3e1630d00f,Anomaly Detection using Edge Computing in Video Surveillance System: Review,"The current concept of Smart Cities influences urban planners and researchers to provide modern, secured and sustainable infrastructure and give a decent quality of life to its residents. To fulfill this need video surveillance cameras have been deployed to enhance the safety and well-being of the citizens. Despite technical developments in modern science, abnormal event detection in surveillance video systems is challenging and requires exhaustive human efforts. In this paper, we surveyed various methodologies developed to detect anomalies in intelligent video surveillance. Firstly, we revisit the surveys on anomaly detection in the last decade. We then present a systematic categorization of methodologies developed for ease of understanding. Considering the notion of anomaly depends on context, we identify different objects-of-interest and publicly available datasets in anomaly detection. Since anomaly detection is considered a time-critical application of computer vision, our emphasis is on anomaly detection using edge devices and approaches explicitly designed for them. Further, we discuss the challenges and opportunities involved in anomaly detection at the edge. KeywordsVideo Surveillance, Anomaly Detection, Edge Computing, Machine Learning",ArXiv,2021
2c8d988b1563a31b1e0e9f07cd58b8c10158df28,https://www.semanticscholar.org/paper/2c8d988b1563a31b1e0e9f07cd58b8c10158df28,Quality estimation for DASH clients by using Deep Recurrent Neural Networks,"Dynamic Adaptive Streaming over HTTP (DASH) is a technology designed to deliver video to the end-users in the most efficient way possible by providing the users to adapt their quality during streaming. In DASH architecture, the original content encoded into video streams in different qualities. As a protocol running over HTTP, the caches play an important role in DASH environment. Utilizing the cache capacity in these systems is an important problem where there are more than one encoded video files generated for each video content. In this paper, we propose a caching approach for DASH systems by predicting the future qualities of DASH clients. For the prediction, we use learning model, and the qualities that will be cached are determined by using this model. The learning model is designed using Recurrent Neural Networks (RNNs) and also Long Short Term Memory (LSTM) which is a special type of RNNs with default behavior of remembering information for long periods of time. We also utilize SDN technology to get some of the outputs for the learning algorithm. The simulation results show that predicting future qualities helps to reduce the underruns of the clients when cache storage is utilized.",2020 16th International Conference on Network and Service Management (CNSM),2020
d2263e52e2aec0cf07804e4c851dc42c79401fbb,https://www.semanticscholar.org/paper/d2263e52e2aec0cf07804e4c851dc42c79401fbb,A QoE-based 360° Video Adaptive Bitrate Delivery and Caching Scheme for C-RAN,"With the development of Virtual Reality (VR) technology, the growing number of VR users puts tremendous pressure on network bandwidth. The tile-based scheme is proposed to reduce the transmission size of 360° video and improve bandwidth utilization. However, when the Field of View (FoV) of the user changes unexpectedly, the tile-based scheme will cause video distortion and quality switching by unacceptable delay. Therefore, many methods are proposed to cache the tiles that users are most likely to playback in Cloud/Edge to decrease delay. However, the dynamic adaptive bitrate delivery and the caching decision is a complex joint optimization problem, which will be a dimensional explosion problem when the scale of users and videos is large. In this paper, we design a QoE-based 360° video adaptive bitrate delivery and caching scheme aiming to maximize the quality of experience (QoE) of multi-user and ensure the fairness of users. To solve this optimization problem which is proved to be NP-Hard, we propose a bitrate selection and caching decision algorithm by greedy strategy. Numerical simulation results demonstrate that our algorithm significantly improves cache hit rate and QoE performance compared with other algorithms with fairness guaranteed.","2020 16th International Conference on Mobility, Sensing and Networking (MSN)",2020
a996143df868fa057300f01039fc94e385ff7ec2,https://www.semanticscholar.org/paper/a996143df868fa057300f01039fc94e385ff7ec2,Chunk-level Request-Grant-Transfer Mode for QoE-Sensitive Video Delivery in CDN,"Remote Direct Memory Access (RDMA) can be deployed in Content Delivery Networks (CDN) Points of Presence (PoPs) to avoid the high CPU overheads caused by traditional TCP/IP stacks. However, RDMA cannot surmount the drawbacks of the window-based conservative of TCP and is insensitive to Quality of Experience (QoE). Moreover, the requirement of lossless networks hinders the widespread application of RDMA. In this paper, we introduce the parallel multipoint-to-multipoint Request-Grant-Transfer (RGT) mode into RDMA to solve the aforementioned problems. Compared with traditional RGT mode, our scheme supports parallel Dynamic Adaptive Streaming over HTTP (DASH) chunk delivery, thereby improving throughput and reducing initial delays. We differentiate the importance of DASH chunks according to QoE-related properties. In this way, we reduce the response time of specific DASH chunks. We provide an efficient approach to select the optimal number of requests for partially traversing pending requests to reduce the overheads of Request stages. We perform comprehensive experiments to demonstrate that our scheme improves the throughput of CDN PoPs and enhances client QoE.",2019 IEEE/ACM 27th International Symposium on Quality of Service (IWQoS),2019
cb4b60b2efdfe22ec9162a633cfb27894c919721,https://www.semanticscholar.org/paper/cb4b60b2efdfe22ec9162a633cfb27894c919721,Intelligent transportation systems: A survey on modern hardware devices for the era of machine learning,"Abstract The increasing complexity of Intelligent Transportation Systems (ITS), that comprise a wide variety of applications and services, has imposed a necessity for high-performance Modern Hardware Devices (MHDs). The performance challenge has become more noticeable with the integration of Machine Learning (ML) techniques deployed in large-scale settings. ML has effectively supported the field of ITS by providing efficient and optimized solutions to problems that were otherwise tackled using traditional statistical and analytical approaches. Addressing the hardware deployment needs of ITS in the era of ML is a challenging problem that involves temporal, spatial, environmental, and economical factors. This survey reviews the recent literature of ML-driven ITS, in which MHDs were utilized, with a focus on performance indicators. A taxonomy is then synthesized, giving a complete representation of what the current capabilities of the surveyed ITS rely on in terms of ML techniques and technological infrastructure. To alleviate the difficulties faced in the non-trivial task of selecting suitable ML techniques and MHDs for an ITS with a specific complexity level, a performance evaluation framework is proposed. The presented survey sets the basis for developing suitable hardware, facilitating the integration of ML within ITS, and bridging the gap between research and real-world deployments.",Journal of King Saud University - Computer and Information Sciences,2021
1eb6a3039e3c0457166b306e57844e5e43818fda,https://www.semanticscholar.org/paper/1eb6a3039e3c0457166b306e57844e5e43818fda,"Application, adoption and opportunities for improving decision support systems in irrigated agriculture: A review",,Agricultural Water Management,2021
3ea0976d1f6976f12a68910e5dbfa079909cbe60,https://www.semanticscholar.org/paper/3ea0976d1f6976f12a68910e5dbfa079909cbe60,Operations research for environmental assessment of crop-livestock production systems,"Abstract CONTEXT Agricultural crop and livestock production systems are complex, essential to human well-being, and fraught with sustainability challenges. In light of intrinsic variability in agricultural production systems and the high number of decision variables, decision support for optimization of sustainability outcomes should be supported by rigorous operations research. OBJECTIVE Several operations research (OR) methods such as evolutionary algorithms, multi-objective optimization, and data envelopment analysis (DEA) have been applied to optimization in agricultural contexts, taking into account different objective functions and decision variables, and life cycle-based evaluation of environmental outcomes in agriculture have become widespread. The current review evaluates the methods used for optimization of agricultural and livestock systems for life cycle-based environmental sustainability goals. METHODS A Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) systematic review method and three complementary search strategies were used to identify relevant articles. Strengths, weaknesses, and performance issues for each method are considered and compared. RESULTS AND CONCLUSIONS Farm benchmarking, output prediction and resource use management are the three most commonly considered decision types in crop-livestock production systems. To guide selection and implementation of appropriate OR methods, a framework (decision tree) is proposed. SIGNIFICANCE The proposed decision tree provides an indication of necessary method-specific methodological choices. Methodological choices with respect to each method are discussed.",,2021
4bcb1fb5772c465a3c54e6852773f39b08e01d4e,https://www.semanticscholar.org/paper/4bcb1fb5772c465a3c54e6852773f39b08e01d4e,A Review of the Water–Energy–Food Nexus Research in Africa,"Notwithstanding the dispersed nature of the water, energy and food (WEF) nexus scholarship in the African continent, its strategic importance to the African agenda has gained widespread attention in research and planning circles. In this regard, the bibliometric science mapping and content analysis of the WEF nexus scientific publication trends, the conceptual, intellectual and social structures, as well as the inherent paradigmatic shifts in the WEF nexus body of knowledge in the African continent have been undertaken, using the nexus body of literature accessed from the Web of Science and Scopus core collection databases. The review results confirmed that, whilst the WEF nexus scholarship has expanded since 2013, there is also evidence of growth in the conceptual, intellectual and social structures of the WEF nexus in the African continent. These shifts have resulted in the emergence of hot topics (subfields) including modelling and optimization, climate variability and change, environmental ecosystem services sustainability, and sustainable development and livelihoods. The review further determined that these structures have evolved along two main perspectives of WEF nexus research development, i.e., the interdisciplinary and transdisciplinary domains. In support of the interpretation of the visual analytics of the intellectual structure and changing patterns of the WEF nexus research, the shifts in positivist, interpretivist and pragmatic paradigmatic perspectives (these are underpinned by the ontology, epistemology, and methodology and methods) are considered when explaining WEF nexus research shifts: (a) From the unconnected silo paradigms that focus on water, energy and food (security concerns) to interconnected (and sometimes interdependent or nested) linkages or systems incorporating environmental, social-economic and political drivers (also viewed as subfields) in a bid to holistically support the Sustainable Development Goals (SDGs) across the African continent; and (b) in the evaluation of the WEF nexus scholarship based on novel analytical approaches. We contend that whilst the theories of science change underpin this apparent expansion, the macro-economic theory will find use in explaining how the WEF nexus research agenda is negotiated and the Integrative Environmental Governance (IEG) is the duly suited governance theory to bridge the inherent disconnect between WEF nexus output and governance processes uncovered in the literature. Overall, operational challenges and opportunities of the WEF nexus abound, transitioning the WEF nexus research to practice in Africa, motivating the need to take advantage of the scholar–practitioner research underpinnings, as contemplated in the transdisciplinary research approach, which is characterised by the dual quest for new knowledge and considerations of use. Yet, there is need for more coordinated and collaborative research to achieve impact and transition from WEF nexus thinking to WEF nexus practice.",,2021
642e3dd59e84d90e4db2e02eff44cda1027425e0,https://www.semanticscholar.org/paper/642e3dd59e84d90e4db2e02eff44cda1027425e0,Development of Decision Support System Based on the Bayes ARD Algorithm for Irrigation of Cotton,"Cotton is a plant, which is mainly cultivated in regions where the irrigation is necessary as rainwater is not adequate. Researches in the recent years have showed that the irrigation water used could be declined. Improvements in the technological field has made Decision Support Systems combined with Neural Networks and data analysis, an important tool of sustainable agriculture. Cotton producers need to reduce irrigation water needs and that can be achieved by using new technologies. The development Decision Support System was conducted, having 3 different types of input. Data derived from a variety of IoT sensors, weather stations, and on-site measurements (yield and ΕΜ38) derived from 3 fields in Greece, creating a dataset of 9 different inputs. A total of 13 different algorithms were tested and evaluated in order to determine which one is the ideal for our dataset. The adoption of this technology in real data predicted the reduction of the irrigation times, ensuring that there will be no losses in the final yield.",Bulletin of University of Agricultural Sciences and Veterinary Medicine Cluj-Napoca. Horticulture,2021
861dc44a78e4bc1e8a6359ebf79118f549d6b291,https://www.semanticscholar.org/paper/861dc44a78e4bc1e8a6359ebf79118f549d6b291,Smart farming for improving agricultural management,,The Egyptian Journal of Remote Sensing and Space Science,2021
9e7de07e1b3868e097b3405da243a4c8b65b4994,https://www.semanticscholar.org/paper/9e7de07e1b3868e097b3405da243a4c8b65b4994,Characterizing Prediction Uncertainty in Agricultural Modeling via a Coupled Statistical–Physical Framework,"Multiple factors, many of them environmental, coalesce to inform agricultural decisions. Farm planning is often done months in advance. These decisions have to be made with the information available at the time, including current trends, historical data, or predictions of what future weather patterns may be. The effort described in this work is geared towards a flexible mathematical and software framework for simulating the impact of meteorological variability on future crop yield. Our framework is data driven and can easily be applied to any location with suitable historical observations. This will enable site-specific studies that are needed for rigorous risk assessments and climate adaptation planning. The framework combines a physics-based model of crop yield with stochastic process models for meteorological inputs. Combined with techniques from uncertainty quantification, global sensitivity analysis, and machine learning, this hybrid statistical–physical framework allows studying the potential impacts of meteorological uncertainty on future agricultural yields and identify the environmental variables that contribute the most to prediction uncertainty. To highlight the utility of our general approach, we studied the predicted yields of multiple crops in multiple scenarios constructed from historical data. Using global sensitivity analysis, we then identified the key environmental factors contributing to uncertainty in these scenarios’ predictions.",Modelling,2021
b69d0d2b3dc4d37841e52e820f7627f775b38a3b,https://www.semanticscholar.org/paper/b69d0d2b3dc4d37841e52e820f7627f775b38a3b,Framework design of decision support system: Improving decision making in fishery supply chain for coastal communities,"The focus of researchers in the field of decision making which related to designing a decision support system to assist in the decision-making process, so far is very limited to the fisheries sector, especially at the small and micro business scale. On the other hand, the SME-scale fisheries sector is a major driver of regional and country performance because it has a very significant multiplier effect on the economic development of the region. Specifically, for coastal areas, the main problem faced is the consistency of the results obtained, one of the main causes is a distorted supply chain. In this study, we are trying to design a conceptual framework for decision support systems in order to assist the decision-making process of fisheries business operators in coastal areas in the Kei Islands, Indonesia. With the main objective of expediting the supply chain of fisheries in this region. The design of the DSS that was built was adjusted to the needs of every fishery businessman in this region. So, in addition to web-based DSS framework design, we also conducted surveys on fisheries supply chain processes from capture fishermen and aquaculture farmers to adjust the conditions of needs and empirical problems to design DSS concepts that can help overcome supply chain problems in the fisheries sector in the region.",,2021
eb074db782ace56da662106dac5bf9b06cadd5db,https://www.semanticscholar.org/paper/eb074db782ace56da662106dac5bf9b06cadd5db,Emerging role of artificial intelligence in waste management practices,"Sustainable development goals target to achieve better living condition in all countries by 2030 and this paves the need for ecological assessment and management. Accelerating environmental deterioration triggers the scientific community to invest and formulate policies and strategies for environmental management, which will lead to sustainable development. Among all environmental issues solid waste management pose serious threat considering the increase in amount of generation of waste in all economies. Better management strategies and policies are required to ensure better living conditions. Incorporation of AI based models to assist the human efforts not only ensure better management of waste but also aid in reduced carbon emissions. Various models and algorithms have been evaluated to assess their potential in better management of solid waste. Algorithms are available in various domains. In thisreview article, role of various AI based techniques in waste management is discussed.",IOP Conference Series: Earth and Environmental Science,2021
f987db348f6f1120fe07211b84d52640bec7706e,https://www.semanticscholar.org/paper/f987db348f6f1120fe07211b84d52640bec7706e,Bioenergy Potential of Crop Residues in the Senegal River Basin: A Cropland–Energy–Water-Environment Nexus Approach,"Access to energy services is a priority for sustainable economic development, especially in rural areas, where small- and medium-sized enterprises have many difficulties in accessing reliable and affordable electricity. Western African countries are highly dependent on biomass resources; therefore, understanding the potential of bioenergy from crop residues is crucial to designing effective land-management practices. The assessment of the capability to use crop residues for electricity production is particularly important in those regions where agriculture is the dominant productive sector and where electrification through grid extension might be challenging. The objective of this work was to guide the development of sustainable strategies for rural areas that support energy development by simultaneously favouring food self-sufficiency capacity and environmental benefits. These complex interlinkages have been jointly assessed in the Senegal river basin by an integrated optimization system using a cropland–energy–water-environment nexus approach. The use of the nexus approach, which integrates various environmental factors, is instrumental to identify optimal land-energy strategies and provide decision makers with greater knowledge of the potential multiple benefits while minimizing trade-offs of the new solutions such as those connected to farmers’ needs, local energy demand, and food and land aspects. By a context-specific analysis, we estimated that, in 2016, 7 million tons of crop residues were generated, resulting in an electricity potential of 4.4 million MWh/year. Several sustainable land-energy management strategies were explored and compared with the current management strategy. Our results indicate that bioenergy production from crop residues can increase with significant variability from 5% to +50% depending on the strategy constraints considered. An example analysis of alternative irrigation in the Guinea region clearly illustrates the existing conflict between water, energy, and food: strategies optimizing bioenergy achieved increases both for energy and food production (+6%) but at the expense of increasing water demand by a factor of nine. The same water demand increase can be used to boost food production (+10%) if a modest decrease in bioenergy production is accepted (−13%).",Sustainability,2021
4bd75cf9c7b6a0bdadf2ed2f3bc4c3857f179b03,https://www.semanticscholar.org/paper/4bd75cf9c7b6a0bdadf2ed2f3bc4c3857f179b03,Crop Knowledge Discovery Based on Agricultural Big Data Integration,"Nowadays, the agricultural data can be generated through various sources, such as: Internet of Thing (IoT), sensors, satellites, weather stations, robots, farm equipment, agricultural laboratories, farmers, government agencies and agribusinesses. The analysis of this big data enables farmers, companies and agronomists to extract high business and scientific knowledge, improving their operational processes and product quality. However, before analysing this data, different data sources need to be normalised, homogenised and integrated into a unified data representation. In this paper, we propose an agricultural data integration method using a constellation schema which is designed to be flexible enough to incorporate other datasets and big data models. We also apply some methods to extract knowledge with the view to improve crop yield; these include finding suitable quantities of soil properties, herbicides and insecticides for both increasing crop yield and protecting the environment.",ICMLSC,2020
52acb53bac559ea73b68edf598cab021f383fa35,https://www.semanticscholar.org/paper/52acb53bac559ea73b68edf598cab021f383fa35,Data Warehouse and Decision Support on Integrated Crop Big Data,"In recent years, precision agriculture is becoming very popular. The introduction of modern information and communication technologies for collecting and processing Agricultural data revolutionise the agriculture practises. This has started a while ago (early 20th century) and it is driven by the low cost of collecting data about everything; from information on fields such as seed, soil, fertiliser, pest, to weather data, drones and satellites images. Specially, the agricultural data mining today is considered as Big Data application in terms of volume, variety, velocity and veracity. Hence it leads to challenges in processing vast amounts of complex and diverse information to extract useful knowledge for the farmer, agronomist, and other businesses. It is a key foundation to establishing a crop intelligence platform, which will enable efficient resource management and high quality agronomy decision making and recommendations. In this paper, we designed and implemented a continental level agricultural data warehouse (ADW). ADW is characterised by its (1) flexible schema; (2) data integration from real agricultural multi datasets; (3) data science and business intelligent support; (4) high performance; (5) high storage; (6) security; (7) governance and monitoring; (8) consistency, availability and partition tolerant; (9) cloud compatibility. We also evaluate the performance of ADW and present some complex queries to extract and return necessary knowledge about crop management.",Int. J. Bus. Process. Integr. Manag.,2020
8791c7fecfa5e2ef557036abb2b26af63a9abde4,https://www.semanticscholar.org/paper/8791c7fecfa5e2ef557036abb2b26af63a9abde4,Using LEL and scenarios to derive mathematical programming models. Application in a fresh tomato packing problem,"Abstract Mathematical programming models are invaluable tools at decision making, assisting managers to uncover otherwise unattainable means to optimize their processes. However, the value they provide is only as good as their capacity to capture the process domain. This information can only be obtained from stakeholders, i.e., clients or users, who can hardly communicate the requirements clearly and completely. Besides, existing conceptual models of mathematical programming models are not standardized, nor is the process of deriving the mathematical programming model from the concept model, which remains ad hoc. In this paper, we propose an agile methodology to construct mathematical programming models based on two techniques from requirements engineering that have been proven effective at requirements elicitation: the language extended lexicon (LEL) and scenarios. Using the pair of LEL + scenarios allows to create a conceptual model that is clear and complete enough to derive a mathematical programming model that effectively captures the business domain. We also define an ontology to describe the pair LEL + scenarios, which has been implemented with a semantic mediawiki and allows the collaborative construction of the conceptual model and the semi-automatic derivation of mathematical programming model elements. The process is applied and validated in a known fresh tomato packing optimization problem. This proposal can be of high relevance for the development and implementation of mathematical programming models for optimizing agriculture and supply chain management related processes in order to fill the current gap between mathematical programming models in the theory and the practice.",Comput. Electron. Agric.,2020
9b110945943b61fdf84f33ada8f8075d1795e091,https://www.semanticscholar.org/paper/9b110945943b61fdf84f33ada8f8075d1795e091,"Development of a decision support system at the stages of pre‐design studies and design of irrigation systems based on IDEFo functional modelling methodology*",,,2020
b770280818ef9fa8265f9592716f823657b434ed,https://www.semanticscholar.org/paper/b770280818ef9fa8265f9592716f823657b434ed,Systemic Design for Food Self-Sufficiency in Urban Areas,"This article adopts a systemic approach to address the problem of the operationalization of relationships between actors conducive to food self-sufficiency in urban areas. Through the use of Social Network Analysis (SNA), the literature on urban agriculture was analyzed, detecting eight key trends and topic areas. This information was used to design a generic recursive organizational structure with the identification of the key roles and functions for management and governance in the multi-level and multi-stakeholder relationships of a sustainable urban self-sufficient food production system, inspired by the principles of complexity management and organizational cybernetics. Methodologically, this is the first application that combines the exploratory capability of SNA and the recursive structure of the Viable System Model (VSM) to propose applicable organizational structures in any urban area, suggesting a new route for the study and application of systemic thinking in the development of urban agriculture schemes. However, due to the conceptual nature of this work, this study opens a discussion on how we can rethink interactions to seek continuous adaptation in food self-sufficiency, provide tools that foster inclusion, and adapt to every context to support the relevant actors and academics in urban agriculture.",,2020
b95402732603d83b62419c7c1cfc5a68755ef2f5,https://www.semanticscholar.org/paper/b95402732603d83b62419c7c1cfc5a68755ef2f5,A decision support framework for the design and operation of sustainable urban farming systems,"Abstract The increasing population and continuous urbanization make food security prominent in sustainable development. It is important to develop economic and resource-efficient farming solutions to meet food demand. Renewable energy and waste valorization may bring benefits to build sustainable food production systems and facilitate circular economy. This work aims to develop a decision support framework for the stakeholders to quantitatively assess and optimize their urban farming systems for efficient investment and operation. The proposed framework is based on a holistic system model that considers the energy and material consumption in vegetable production processes and the economic and environmental performance of urban farming systems. In the multi-dimensional assessment model, the net present value and cradle-to-gate CO2 emission, water consumption, and land occupation of different configurations of urban farming systems were assessed. In a further development, the assessment model was embedded in an optimization framework to identify the optimal system design and operation. The optimal crop mix and the corresponding cultivation set points (such as temperature, humidity, irradiance, illumination time, and CO2 concentration) for the farming modules were determined via optimization. To demonstrate the proposed framework, a case study on the design and operation of a vertical farm in Singapore was carried out. The case study examined alternative farming systems with glass-enclosed vs window-free structural design, grid vs solar photovoltaic (PV) energy supply, and traditional chemical fertilizers vs food waste compost fertilization. Results showed that plant-factory farming systems integrated with solar PV and beer-residue-derived fertilizer could be a promising and sustainable farming solution for Singapore as a tropical megacity.",,2020
c4784652b900a9df26ac9247a232dca1b901dfe1,https://www.semanticscholar.org/paper/c4784652b900a9df26ac9247a232dca1b901dfe1,Operations Research Problems and Data Envelopment Analysis in Agricultural Land Processing – A Review,"Research Question: This paper aims at specifying the contribution of operations research (OR) methods and techniques to agricultural land processing. Motivation: Agricultural production is performed on an agricultural land, which has to be exploited in the best possible way, given the increasing human population and the limited availability of the land. Considering the importance of this issue, a large number of research studies dealing with problems in agriculture can be found in the literature, and many of these problems are solved by OR methods and techniques. However, to our knowledge, there are no review papers that deal with this specific area, so the main motivation is to provide a detailed review of selected OR methods application in the agricultural land processing area. Idea: The core idea behind this research is to perceive a real impact of OR methods and techniques implementation in the agricultural land processing. The research is based on detailed literature review for the period 2014-2019 and performed statistics involving publication by year, publication by journal and statistics involving keywords in articles. Data: The review was conducted using online repositories of the papers published in SCI and SCIe journals with impact factors in the period from 2014-2019. Tools: Analyzed papers are divided into three groups according to the OR method applied: linear optimization problems, DEA method and other OR methods (non linear, multicriteria, mixed integer programming, dynamic programming). Papers within the groups are analyzed according to the type of problems solved. Statistical analyses of all collected data were used to get a good insight into the applications of operations research problems and data envelopment analysis in agricultural land processing. Findings: The number of published papers in this specific area has a growing trend over the observed years (with some minor decrease in 2016 and 2019 in comparison with the previous year). All of the articles are related to specific application of the given methods to solving problems in the agricultural land processing, and this is the reason for many different keywords appearing in the articles. Some very important keywords such as “operations research” or “OR” does not appear in any article as a keyword. Inclusion of such common keywords may result in a faster search in repositories of all articles. Contribution: The primary contribution of this paper is a detailed review of application of linear optimization, data envelopment analysis and other OR methods in agricultural land processing in the period 2014-2019.",,2020
ce99117aebe0d31e9cb40b1d751b19141ac044d7,https://www.semanticscholar.org/paper/ce99117aebe0d31e9cb40b1d751b19141ac044d7,Decision support systems for agriculture 4.0: Survey and challenges,"Abstract Undoubtedly, high demands for food from the world-wide growing population are impacting the environment and putting many pressures on agricultural productivity. Agriculture 4.0, as the fourth evolution in the farming technology, puts forward four essential requirements: increasing productivity, allocating resources reasonably, adapting to climate change, and avoiding food waste. As advanced information systems and Internet technologies are adopted in Agriculture 4.0, enormous farming data, such as meteorological information, soil conditions, marketing demands, and land uses, can be collected, analyzed, and processed for assisting farmers in making appropriate decisions and obtaining higher profits. Therefore, agricultural decision support systems for Agriculture 4.0 has become a very attractive topic for the research community. The objective of this paper aims at exploring the upcoming challenges of employing agricultural decision support systems in Agriculture 4.0. Future researchers may improve the decision support systems by overcoming these detected challenges. In this paper, the systematic literature review technique is used to survey thirteen representative decision support systems, including their applications for agricultural mission planning, water resources management, climate change adaptation, and food waste control. Each decision support system is analyzed under a systematic manner. A comprehensive evaluation is conducted from the aspects of interoperability, scalability, accessibility, usability, etc. Based on the evaluation result, upcoming challenges are detected and summarized, suggesting the development trends and demonstrating potential improvements for future research.",Comput. Electron. Agric.,2020
e58188cd3520f8f27075d1c848257fa07f504f7a,https://www.semanticscholar.org/paper/e58188cd3520f8f27075d1c848257fa07f504f7a,GIS-based agro-ecological zoning for crop suitability using fuzzy inference system in semi-arid regions,"Abstract Agro-ecological zoning (AEZ) is one of the most useful tools for recognizing land capabilities to be allocated for the best and most profitable types of productivity. AEZ, as applied in FAO studies, defines zones based on combinations of topography, soil, land use, and climatic characteristics. In this research, data preparation in Geographic Information System (GIS) environment and membership function defined in fuzzy inference system (FIS) then used weighted linear combination (WLC) for determining parameters weight for agro-ecological zoning of chickpea in semi-arid regions of Iran that includes climatic, topography, soil, and land use parameters. At first, a climatic zoning map was developed based on rainfall, temperature, absolute minimum temperature, and evapotranspiration maps. The topography zoning map was made based on slope, aspect, and hypsometry. Soil zoning map was developed based on soil texture and soil erosion maps. Moreover, the land use map was developed by land type and land cover maps. The results showed that significant parts of the studied area were classified as unsuitable 52.59% (1.388.731 ha), 27.84% (734.881 ha) and marginal with 27.53% (727.535 ha), 17.96% (474.566 ha) while the optimal zones were only 4.15% (109.697 ha) and 8.44% (223.210 ha) for rain-fed chickpea cultivation and irrigated chickpea cultivation, respectively. The results also showed that agro-climatic zoning and agro-land use zoning have an essential role in determining the optimal areas for chickpea production in rain-fed and irrigated conditions. The use of GIS and fuzzy inference system improved the accuracy of spatial data, more productive analysis, and enhanced data access.",,2020
aabac36fae0a8f58f17f108f0a40cb06835f4a26,https://www.semanticscholar.org/paper/aabac36fae0a8f58f17f108f0a40cb06835f4a26,Optimization model for enhancing water-use efficiency from the perspective of water-energy-food nexus,"The water-energy-food (WEF) nexus, which is essential for supporting regional sustainable development, has become a popular research topic. This study proposed an optimization programming framework for improving water-use efficiency from a WEF nexus perspective. Through the incorporation of water rights transfer mechanism, water resources can be flexibly allocated between food and energy sectors. The proposed model could help decision makers to identify the optimal production scales of food and energy production, the potential of water conservation of food production, as well as the investment portfolio of water-saving engineering. The capability of proposed model was illustrated through a case study in Yellow River Basin, north China. Based on the proposed optimization model, the optimal allocation scheme of water resources between food and energy sectors were obtained. A total of 2.34 × 107 m3 of water would be transferred from food production to energy sector. Compared with state quo, production scales of energy sector, as well as profits of both food and energy sectors would increase rapidly. Optimization results reveal that designed energy production scales proposed by local government and enterprises are attainable as long as there are sufficient water resources available for energy sector.",IOP Conference Series: Earth and Environmental Science,2019
bb1711fc5a306a7759de9b95a1277eaf0c55afe5,https://www.semanticscholar.org/paper/bb1711fc5a306a7759de9b95a1277eaf0c55afe5,A Literature Review to Propose a Systematic Procedure to Develop “Nexus Thinking” Considering the Water–Energy–Food Nexus,"There is a growing interest in the literature on the theme of the water–energy–food nexus, as there is growing recognition that sectors that share natural resources have interdependent and interconnected systems. Despite the widespread popularity of nexus thinking, it still lacks standardized procedures and methodologies to assist in its development. Therefore, this paper proposes, from a literature review, a systematic procedure to assist in the development of management models based on nexus thinking. To this end, 304 papers were analyzed using the following criteria: nexus concept, type of approach, geographic scale, elements in the nexus system, application context, and types of assessment methods and tools. The results of the review served as the basis for determining the procedure, which consisted of four steps: (a) understanding nexus thinking, (b) identification of composing variables, (c) evaluation (diagnosis and prognosis), and (d) decision-making. In addition to the standardization of these steps, the main information used to compose the procedure was organized and synthesized with a mind map.",,2019
d6edbdf742104c71418a4f7924e328c2bc891429,https://www.semanticscholar.org/paper/d6edbdf742104c71418a4f7924e328c2bc891429,Identification of Optimal Agricultural Development Strategies in the West African Sahel Mékrou Transboundary River Basin,"Mekrou is a transboundary river basin across Benin, Burkina Faso, and Niger. In this area, agricultural production plays a major strategic role in guaranteeing household food security for the sustainable development of the basin. Increasing agricultural productivity is crucial for meeting the growing population demands. Climate change (CC) is already affecting agricultural production due to increased frequency and intensity of extreme weather events. In this paper, a systematic approach to identify the main factors that influence observed yield gaps and to evaluate the impacts of agricultural intensification on the environment and support local development plans is presented. By using a newly developed decision support system tool (E-Water) linking a geographic information system with the biophysical model EPIC, we demonstrate that the agricultural sector has a growing potential by adopting more integrated and efficient agricultural production systems. The analysis of the crop yield gap shows that the main limiting factor for crop production is low soil fertility, while water is limiting during dry years. We predict that the adoption of more intensive farming techniques and sustainable irrigation practices can increase the capacity of agriculture to efficiently mitigate the impacts of climate change and other external environmental stress factors. We confirm that irrigation can substantially increase yield and that it will be required to adapt to expected climate and increase of rainfall variability.",Climate Change Management,2019
07c01e9ca8f627e7d9bdca873378a5c699dfe74c,https://www.semanticscholar.org/paper/07c01e9ca8f627e7d9bdca873378a5c699dfe74c,"A survey of recommender systems for energy efficiency in buildings: Principles, challenges and prospects","Abstract Recommender systems have significantly developed in recent years in parallel with the witnessed advancements in both internet of things (IoT) and artificial intelligence (AI) technologies. Accordingly, as a consequence of IoT and AI, multiple forms of data are incorporated in these systems, e.g. social, implicit, local and personal information, which can help in improving recommender systems’ performance and widen their applicability to traverse different disciplines. On the other side, energy efficiency in the building sector is becoming a hot research topic, in which recommender systems play a major role by promoting energy saving behavior and reducing carbon emissions. However, the deployment of the recommendation frameworks in buildings still needs more investigations to identify the current challenges and issues, where their solutions are the keys to enable the pervasiveness of research findings, and therefore, ensure a large-scale adoption of this technology. Accordingly, this paper presents, to the best of the authors’ knowledge, the first timely and comprehensive reference for energy-efficiency recommendation systems through (i) surveying existing recommender systems for energy saving in buildings; (ii) discussing their evolution; (iii) providing an original taxonomy of these systems based on specified criteria, including the nature of the recommender engine, its objective, computing platforms, evaluation metrics and incentive measures; and (iv) conducting an in-depth, critical analysis to identify their limitations and unsolved issues. The derived challenges and areas of future implementation could effectively guide the energy research community to improve the energy-efficiency in buildings and reduce the cost of developed recommender systems-based solutions.",Inf. Fusion,2021
a0cefdc1f9863ff2a671feb9108bb5cc5fab88f8,https://www.semanticscholar.org/paper/a0cefdc1f9863ff2a671feb9108bb5cc5fab88f8,Arquitectura de referencia para el diseño y desarrollo de aplicaciones para la Industria 4.0,"La implementación práctica de la Industria 4.0 requiere la reformulación y coordinación de los procesos industriales. Para ello se requiere disponer de una plataforma digital que integre y facilite la comunicación e interacción entre los elementos implicados en la cadena de valor. Actualmente no existe una arquitectura de referencia (modelo) que ayude a las organizaciones a concebir, diseñar e implantar esta plataforma digital. Este trabajo proporciona ese marco e incluye un metamodelo que recoge la descripción de todos los elementos involucrados en la plataforma digital (datos, recursos, aplicaciones y monitorización), así como la información necesaria para configurar, desplegar y ejecutar aplicaciones en ella. Asimismo, se proporciona una herramienta compatible con el metamodelo que automatiza la generación de archivos de configuración y lanzamiento y su correspondiente transferencia y ejecución en los nodos de la plataforma. Por último, se muestra la flexibilidad, extensibilidad y validez de la arquitectura y artefactos software construidos a través de su aplicación en un caso de estudio.",Revista Iberoamericana de Automática e Informática industrial,2021
378cd1bcb5ff3f329d21415cdcbcb18457055a50,https://www.semanticscholar.org/paper/378cd1bcb5ff3f329d21415cdcbcb18457055a50,A microgrid energy management system based on chance-constrained stochastic optimization and big data analytics,"Abstract A Microgrid (MG) is a promising distributed technology to solve todays energy challenges. They are changing how electricity is produced, transmitted, and distributed, enabling to capture massive amounts of data from sensors, and other electrical infrastructures. However, recent advances in modeling and optimization of MG neither integrate the use of big data technologies aggressively nor focus on developing an optimal operational strategy for a single building. To bridge this gap, this research proposes to use Apache Spark to enhance the performance of a scalable stochastic optimization model for an MG for multiple buildings, and to ensure that a significant portion of the wind power output will be utilized. The decision model is formulated as a chance constraint two-stage optimization problem to obtain operation decisions for a behind-the-meter topology. The comparison between the current practice of using historical data and integrating Apache Spark technologies demonstrates the superiority of the streaming data as energy management strategy. Experiments under different settings show that using big data strategy, the model can (1) achieve more cost savings of the total system, (2) increase resiliency to power disturbances, and (3) build a data analytics framework to enhance the decision-making process.",Comput. Ind. Eng.,2020
9169cf00b90e536731648129902b568b801c1584,https://www.semanticscholar.org/paper/9169cf00b90e536731648129902b568b801c1584,The programmable CPG model based on Matsuoka oscillator and its application to robot locomotion,"The central pattern generator (CPG) is an important functional unit in the spinal cord which can produce rhythmic signals to control locomotion. Recently, there has been a growing interest in progr...",Int. J. Model. Simul. Sci. Comput.,2020
ef6b1cfb1d91abc75f3f5621dfbd94389f633e48,https://www.semanticscholar.org/paper/ef6b1cfb1d91abc75f3f5621dfbd94389f633e48,Motion Planning of Upper-Limb Exoskeleton Robots: A Review,"(1) Background: Motion planning is an important part of exoskeleton control that improves the wearer’s safety and comfort. However, its usage introduces the problem of trajectory planning. The objective of trajectory planning is to generate the reference input for the motion-control system. This review explores the methods of trajectory planning for exoskeleton control. In order to reduce the number of surveyed papers, this review focuses on the upper limbs, which require refined three-dimensional motion planning. (2) Methods: A systematic search covering the last 20 years was conducted in Ei Compendex, Inspect-IET, Web of Science, PubMed, ProQuest, and Science-Direct. The search strategy was to use and combine terms “trajectory planning”, “upper limb”, and ”exoskeleton” as high-level keywords. “Trajectory planning” and “motion planning” were also combined with the following keywords: “rehabilitation”, “humanlike motion“, “upper extremity“, “inverse kinematic“, and “learning machine “. (3) Results: A total of 67 relevant papers were discovered. Results were then classified into two main categories of methods to plan trajectory: (i) Approaches based on Cartesian motion planning, and inverse kinematics using polynomial-interpolation or optimization-based methods such as minimum-jerk, minimum-torque-change, and inertia-like models; and (ii) approaches based on “learning by demonstration” using machine-learning techniques such as supervised learning based on neural networks, and learning methods based on hidden Markov models, Gaussian mixture models, and dynamic motion primitives. (4) Conclusions: Various methods have been proposed to plan the trajectories for upper-limb exoskeleton robots, but most of them plan the trajectory offline. The review approach is general and could be extended to lower limbs. Trajectory planning has the advantage of extending the applicability of therapy robots to home usage (assistive exoskeletons); it also makes it possible to mitigate the shortages of medical caregivers and therapists, and therapy costs. In this paper, we also discuss challenges associated with trajectory planning: kinematic redundancy and incompatibility, and the trajectory-optimization problem. Commonly, methods based on the computation of swivel angles and other methods rely on the relationship (e.g., coordinated or synergistic) between the degrees of freedom used to resolve kinematic redundancy for exoskeletons. Moreover, two general solutions, namely, the self-tracing configuration of the joint axis and the alignment-free configuration of the joint axis, which add the appropriate number of extra degrees of freedom to the mechanism, were employed to improve the kinematic incompatibility between human and exoskeleton. Future work will focus on online trajectory planning and optimal control. This will be done because very few online methods were found in the scope of this study.",,2020
1b8d13362b8c3130a8b5c2b7b3d69ddf5ec37e97,https://www.semanticscholar.org/paper/1b8d13362b8c3130a8b5c2b7b3d69ddf5ec37e97,Detecting the presence of anterior cruciate ligament injury based on gait dynamics disparity and neural networks,"The aim of this study is to develop a new pattern recognition-based method to model and discriminate gait dynamics disparity between anterior cruciate ligament (ACL) deficient (ACL-D) knee and contralateral ACL-intact (ACL-I) knee in patients with unilateral ACL deficiency by using kinematic features and neural networks. Thereby the capabilities of these features to detect the presence of injury can be assessed. The proposed method consists of two stages. In the first (training) stage, gait analysis is performed. A two-dimensional five-link biped model used for imitating human gait locomotion is employed to demonstrate that functions containing kinematic data of lower extremities, including knee and hip flexion/extension angles and angular velocities, characterize the gait system dynamics. Knee angle-hip angle cyclograms, knee and hip angle-angular velocity phase portraits visually demonstrate the significant disparity of gait dynamics between the lower extremities of patients with unilateral ACL deficiency. Gait dynamics underlying gait patterns of ACL-D and ACL-I knees are locally accurately modeled and approximated by radial basis function (RBF) neural networks via deterministic learning theory. The derived knowledge of approximated gait dynamics is preserved in constant RBF networks. In the second (classification) stage, a bank of dynamical estimators is constructed using the preserved constant RBF networks to represent the learned training gait patterns. By comparing the set of estimators with a test gait pattern, the generated average $$L_1$$ L 1 norms of errors are taken as the disparity and classification measure between the training and test gait patterns to differentiate between ACL-D and ACL-I knees. Finally, experiments are carried out on forty-three patients to assess the effectiveness of the proposed method. By using the leave-one-out cross-validation style under normal and fast walking speed conditions, the correct classification rates for discriminating between ACL-D and ACL-I knees are reported to be 95.61 $$\%$$ % and 93.03 $$\%$$ % , respectively. Compared with other state-of-the-art methods, the results demonstrate that gait alterations in the presence of chronic ACL deficiency can be visualized through cyclograms and phase portraits, and can be detected with superior performance.",Artificial Intelligence Review,2019
d1a9a147cc47d2ed8cab89849190cddb21d81670,https://www.semanticscholar.org/paper/d1a9a147cc47d2ed8cab89849190cddb21d81670,Modulation of Central Pattern Generators (CPG) for the Locomotion Planning of an Articulated Robot,"The present paper proposes the approach of locomotion in mammals to be applied in articulated robotics. This is achieved using Central Pattern Generators by amplitude modulation of oscillatory signals to communicate the angle of rotation of each of the joints that are involved in a specific type of locomotion. Performing simulations to determine viability by frequency and amplitude, a better response was found in the amplitude modulation. A series of locomotion data with dogs were compiled and used as a reference for the amplitude modulation of the differential equation systems that replicate the Central Pattern Generators of the articulations of the quadrupedal robot. Recurrent neural networks in continuous time were used to represent the CPG. The angle was modulated as a function of the amplitude of the cyclic signal produced by the Central Pattern Generators allowing to manage the setpoints (angles) for a given articulation, between 0° and 90°. Other works, although related to Central Pattern Generators, and some focused on reproducing the model, none of them deals with the construction of modulated signals that represent joint angles based on data obtained from biomechanical studies of locomotion by quadrupeds. A distributed autonomous control architecture based on modular and hierarchical Central Pattern Generators, organized in two layers, that simultaneously synchronizes and executes the movement of each joint from each leg, and for the total movement production is proposed.",ICAI,2018
bb8a970abb2f6098b8229a079042e92d7dfecaaf,https://www.semanticscholar.org/paper/bb8a970abb2f6098b8229a079042e92d7dfecaaf,System Modes - Digestible System (Re-)Configuration for Robotics,"High-level deliberation in robotic systems has to handle three different but closely interwoven aspects simultaneously: intended tasks, contingencies, and system-level errors. To reduce the complexity, we propose the system modes concept, to abstract runtime state information and reconfiguration of the software components of the underlying layers by a model-based approach. The proposed concept introduces a notion of hierarchically composed, virtual subsystems as well as a notion of modes that determine their configuration. It features an inference engine to deduce the modes of the subsystems from the components and top-down reconfiguration mechanisms. Repetitive and fine-grained communication between high-level deliberation and underlying software components can thereby be reduced, decreasing unwanted coupling between system parts.",2021 IEEE/ACM 3rd International Workshop on Robotics Software Engineering (RoSE),2021
0360865388be28fd7b994c0afa07369a20fe6394,https://www.semanticscholar.org/paper/0360865388be28fd7b994c0afa07369a20fe6394,Solving the Real Robot Challenge using Deep Reinforcement Learning,"This paper details our winning submission to Phase 1 of the 2021 Real Robot Challenge; a challenge in which a three fingered robot must carry a cube along specified goal trajectories. To solve Phase 1, we use a pure reinforcement learning approach which requires minimal expert knowledge of the robotic system or of robotic grasping in general. A sparse, goal-based reward is employed in conjunction with Hindsight Experience Replay to teach the control policy to move the cube to the desired x and y coordinates. Simultaneously, a dense distance-based reward is employed to teach the policy to lift the cube to the desired z coordinate. The policy is trained in simulation with domain randomisation before being transferred to the real robot for evaluation. Although performance tends to worsen after this transfer, our best trained policy can successfully lift the real cube along goal trajectories via the use of an effective pinching grasp. Our approach outperforms all other submissions, including those leveraging more traditional robotic control techniques, and is the first learning-based approach to solve this challenge.",,2021
0927845f14277f2bae17813fe330554ac96a7fce,https://www.semanticscholar.org/paper/0927845f14277f2bae17813fe330554ac96a7fce,A Domain Data Pattern Randomization based Deep Reinforcement Learning method for Sim-to-Real transfer,"Transferring reinforcement learning policies trained in a physical simulator to the real world is a highly challenging problem, because the gap between the simulation and reality, usually causes the transferred model to perform poorly in the real world. Many algorithms including domain randomization, have been proposed to try to bridge the gap between simulation and reality. However, most of them are to change the value of the corresponding data by superimposing gaussian noise on robot dynamics parameters or environmental data. Such policies often fail to solve the problem of long-term/intermittent missing data patterns caused by sensor failures in the actual operation of the robot. Faced with this problem, we proposed a memory-enhanced domain data pattern randomization method. This method achieves data enhancement by randomizing the distribution pattern of data connection, at the same time, the memory mechanism based on recurrent neural network is introduced into the decision model, to alleviate the jitter of environmental distribution caused by data pattern changes, so as to improve the decision-making ability of the robot in some observable scenes triggered by the change of data pattern.",ICIAI,2021
14a0bee8e9574df6cc8bf5662812924f3d21f476,https://www.semanticscholar.org/paper/14a0bee8e9574df6cc8bf5662812924f3d21f476,Active Sensing for Search and Tracking: A Review,"Active Position Estimation (APE) is the task of localizing one or more targets using one or more sensing platforms. APE is a key task for search and rescue missions, wildlife monitoring, source term estimation, and collaborative mobile robotics. Success in APE depends on the level of cooperation of the sensing platforms, their number, their degrees of freedom and the quality of the information gathered. APE control laws enable active sensing by satisfying either pure-exploitative or pure-explorative criteria. The former minimizes the uncertainty on position estimation; whereas the latter drives the platform closer to its task completion. In this paper, we define the main elements of APE to systematically classify and critically discuss the state of the art in this domain. We also propose a reference framework as a formalism to classify APE-related solutions. Overall, this survey explores the principal challenges and envisages the main research directions in the field of autonomous perception systems for localization tasks. It is also beneficial to promote the development of robust active sensing methods for search and tracking applications.",ArXiv,2021
182218526c7c4453aca4f979cb8ec914e2d0846f,https://www.semanticscholar.org/paper/182218526c7c4453aca4f979cb8ec914e2d0846f,Learning meta-knowledge for few-shot image emotion recognition,"Abstract Previous studies have demonstrated that images are of great importance in attracting people’s attention and motivating them to take action. Various attributes (e.g., colors, aesthetics, and embedded objects) related to images are considered driving factors. Among which emotions in images, in particular, play a critical role in stimulating individuals, based on the Stimulus–Organism–Response theory. Consequently, many researchers put great efforts to understand image emotions, ranging from developing theoretical models to a broad spectrum of applications. Due to the complex and unstructured characteristics of images, identifying image emotions is challenging. Although some significant progress in image emotion classification has been achieved, inherent constraints still remain unaddressed. For example, acquiring a sufficiently large amount of labeled data to train a good model is costly and inevitably requires lots of human efforts. Besides, building a generalized model applicable to different datasets still needs a deep exploration. Image emotions are very subjective, which also makes such a classification task difficult. This paper proposes a general meta-learning framework for the few-shot image emotion classification, called Meta-IEC. Meta-IEC provides the capability of: (i) adapting to a similar dataset but new classes that have not been encountered before, and (ii) generalizing to a completely different dataset where emotion classes are unseen in the training dataset and only very few labeled images are available. Meta-IEC is also able to capture the uncertainty and ambiguity during the meta-testing, where we implement a hierarchical Bayesian graphical model to understand latent relationships among various parameters between meta-training and meta-testing. Extensive experiments on three commonly used datasets empirically demonstrate the superiority of our method over several state-of-the-art baselines. For example, our meta-learning based model can achieve performance improvement up to 5+%. We also provide some managerial implications on parameter sensitivity and label selection of meta-training and meta-testing.",Expert Syst. Appl.,2020
30b1e0a54817d77251e234270f6b45c700e46d43,https://www.semanticscholar.org/paper/30b1e0a54817d77251e234270f6b45c700e46d43,Real Robot Challenge using Deep Reinforcement Learning,"This paper details our winning submission to Phase 1 of the 2021 Real Robot Challenge, a challenge in which a three fingered robot must carry a cube along specified goal trajectories. To solve Phase 1, we use a pure reinforcement learning approach which requires minimal expert knowledge of the robotic system or of robotic grasping in general. A sparse goal-based reward is employed in conjunction with Hindsight Experience Replay to teach the control policy to move the cube to the desired x and y coordinates. Simultaneously, a dense distance-based reward is employed to teach the policy to lift the cube to the desired z coordinate. The policy is trained in simulation with domain randomisation before being transferred to the real robot for evaluation. Although performance tends to worsen after this transfer, our best trained policy can successfully lift the real cube along goal trajectories via the use of an effective pinching grasp. Our approach outperforms all other submissions, including those leveraging more traditional robotic control techniques, and is the first learning-based approach to solve this challenge. (a) Pushing (b) Cradling (c) Pinching Figure 1: The various manipulation strategies learned by our approach. 1 Real Robot Challenge Phase 1 Dexterous robotic manipulation is applicable in various industrial and domestic settings. However, current state-of-the-art control strategies generally struggle when faced with unstructured tasks which require high degrees of dexterity. Data-driven learning methods are promising for these challenging manipulation tasks, yet related research has been limited by the costly nature of real robot experimentation. In light of these issues, the Real Robot Challenge (RRC) aims to advance the state-of-the-art in robotic manipulation by providing participants with remote access to well maintained robotic platforms, allowing for cheap and easy real robot experimentation. To further support easy experimentation, users are also provided a simulated recreation of the robotic setup. After an initial RRC qualifying phase, successful participants are entered into Phase 1 where they must solve the challenging ‘Move Cube on Trajectory’ task. In this task, a cube must be carried along a goal trajectory, which specifies the coordinates at which the cube should be positioned at each time-step, using the provided TriFinger robotic platform [3]. For final Phase 1 evaluation, participants submit their developed control policy and receive a score based on how closely it can bring the cube to a number of randomly sampled goal trajectories. ∗University College Dublin, †Dublin City University, ‡ SFI Insight Centre for Data Analytics, Ireland 1Videos of our policies in action can be found at https://www.youtube.com/playlist?list= PLLJoWXUn8XplFszi16-VZMTDBhMQFuc5o. 1 ar X iv :2 10 9. 15 23 3v 1 [ cs .R O ] 3 0 Se p 20 21 ‘Move Cube on Trajectory’ requires a dexterous policy that can adapt to the various different cube and goal positions that may encountered during a single evaluation run. In the 2020 Real Robot Challenge, solutions to this task consisted of structured policies which relied heavily on inductive biases and task specific engineering [5, 6]. We take an alternative approach by formulating the task as a pure reinforcement learning (RL) problem, using RL to learn our control policy entirely in simulation before transferring it to the real robot for final evaluation. Upon this evaluation, our learned policy outperformed all other competing submissions.",ArXiv,2021
40a0d55b6de6749bf2ec3313d8ed6ca5c0ddd7c6,https://www.semanticscholar.org/paper/40a0d55b6de6749bf2ec3313d8ed6ca5c0ddd7c6,Deep Reinforcement Learning Versus Evolution Strategies: A Comparative Survey,"Deep Reinforcement Learning (DRL) has the potential to surpass human-level control in sequential decision-making problems. Evolution Strategies (ESs) have different characteristics than DRL, yet they are promoted as a scalable alternative. To get insights into their strengths and weaknesses, in this paper, we put the two approaches side by side. After presenting the fundamental concepts and algorithms for each of the two approaches, they are compared from the perspectives of scalability, exploration, adaptation to dynamic environments, and multi-agent learning. Then, the paper discusses hybrid algorithms, combining aspects of both DRL and ESs, and how they attempt to capitalize on the benefits of both techniques. Lastly, both approaches are compared based on the set of applications they support, showing their potential for tackling real-world problems.This paper aims to present an overview of how DRL and ESs can be used, either independently or in unison, to solve specific learning tasks. It is intended to guide researchers to select which method suits them best and provides a bird's eye view of the overall literature in the field. Further, we also provide application scenarios and open challenges.",ArXiv,2021
44f5f9dbe7ba6d3132d0f9482c7783d72548a307,https://www.semanticscholar.org/paper/44f5f9dbe7ba6d3132d0f9482c7783d72548a307,Bayesian Meta-Learning for Few-Shot Policy Adaptation Across Robotic Platforms,"Reinforcement learning methods can achieve significant performance but require a large amount of training data collected on the same robotic platform. A policy trained with expensive data is rendered useless after making even a minor change to the robot hardware. In this paper, we address the challenging problem of adapting a policy, trained to perform a task, to a novel robotic hardware platform given only few demonstrations of robot motion trajectories on the target robot. We formulate it as a few-shot meta-learning problem where the goal is to find a meta-model that captures the common structure shared across different robotic platforms such that data-efficient adaptation can be performed. We achieve such adaptation by introducing a learning framework consisting of a probabilistic gradient-based meta-learning algorithm that models the uncertainty arising from the few-shot setting with a low-dimensional latent variable. We experimentally evaluate our framework on a simulated reaching and a real-robot picking task using 400 simulated robots generated by varying the physical parameters of an existing set of robotic platforms. Our results show that the proposed method can successfully adapt a trained policy to different robotic platforms with novel physical parameters and the superiority of our meta-learning algorithm compared to state-of-the-art methods for the introduced few-shot policy adaptation problem.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
487f77e967453d8cea506aee3b83a1847e9de082,https://www.semanticscholar.org/paper/487f77e967453d8cea506aee3b83a1847e9de082,A multi-robot path-planning algorithm for autonomous navigation using meta-reinforcement learning based on transfer learning,"Abstract The adaptability of multi-robot systems in complex environments is a hot topic. Aiming at static and dynamic obstacles in complex environments, this paper presents dynamic proximal meta policy optimization with covariance matrix adaptation evolutionary strategies (dynamic-PMPO-CMA) to avoid obstacles and realize autonomous navigation. Firstly, we propose dynamic proximal policy optimization with covariance matrix adaptation evolutionary strategies (dynamic-PPO-CMA) based on original proximal policy optimization (PPO) to obtain a valid policy of obstacles avoidance. The simulation results show that the proposed dynamic-PPO-CMA can avoid obstacles and reach the designated target position successfully. Secondly, in order to improve the adaptability of multi-robot systems in different environments, we integrate meta-learning with dynamic-PPO-CMA to form the dynamic-PMPO-CMA algorithm. In training process, we use the proposed dynamic-PMPO-CMA to train robots to learn multi-task policy. Finally, in testing process, transfer learning is introduced to the proposed dynamic-PMPO-CMA algorithm. The trained parameters of meta policy are transferred to new environments and regarded as the initial parameters. The simulation results show that the proposed algorithm can have faster convergence rate and arrive the destination more quickly than PPO, PMPO and dynamic-PPO-CMA.",Appl. Soft Comput.,2021
70080fdcaff014b5acb1ec2d2db4de9bfb4f0c57,https://www.semanticscholar.org/paper/70080fdcaff014b5acb1ec2d2db4de9bfb4f0c57,Zero-Shot Uncertainty-Aware Deployment of Simulation Trained Policies on Real-World Robots,"While deep reinforcement learning (RL) agents have demonstrated incredible potential in attaining dexterous behaviours for robotics, they tend to make errors when deployed in the real world due to mismatches between the training and execution environments. In contrast, the classical robotics community have developed a range of controllers that can safely operate across most states in the real world given their explicit derivation. These controllers however lack the dexterity required for complex tasks given limitations in analytical modelling and approximations. In this paper, we propose Bayesian Controller Fusion (BCF), a novel uncertainty-aware deployment strategy that combines the strengths of deep RL policies and traditional handcrafted controllers. In this framework, we can perform zero-shot sim-to-real transfer, where our uncertainty based formulation allows the robot to reliably act within out-of-distribution states by leveraging the handcrafted controller while gaining the dexterity of the learned system otherwise. We show promising results on two real-world continuous control tasks, where BCF outperforms both the standalone policy and controller, surpassing what either can achieve independently. A supplementary video demonstrating our system is provided at https://bit.ly/bcf_deploy.",ArXiv,2021
79ac9bcf55778cb3ef208d8846bd5888f3c313a7,https://www.semanticscholar.org/paper/79ac9bcf55778cb3ef208d8846bd5888f3c313a7,Sim-to-Real Adaptation for Mobile Robots Based on LiDAR Odometry,"In this paper, we propose a method for the simulation-to-reality prob1 lem in the domain of wheeled mobile robotics. While most applications rely on 2 a low-level velocity controller, both in simulation and on the real robot, it may 3 be desirable to directly control other action spaces, e.g. raw control signals. Es4 pecially, this problem is of relevance for harsh outdoor environments and rough 5 terrains. To tackle this, we propose a two step domain adaptation technique that 6 includes: 1) mapping of source action space to the velocity space to apply the cor7 responding real world velocity in simulation, thus adapting the dynamics of the 8 robot, and 2) state correction that compensates imperfections of the simulation 9 controllers and thus helps to adapt sequence of simulated observations. We pro10 vide quantitative results that show relevance of our approach, showing the benefits 11 of combining these two adaptations. 12",,2021
8b8c26e4d1ff4ad342e06424f8fe4cf861c90d60,https://www.semanticscholar.org/paper/8b8c26e4d1ff4ad342e06424f8fe4cf861c90d60,Lifelong Robotic Reinforcement Learning by Retaining Experiences,"Multi-task learning ideally allows robots to acquire a diverse repertoire of useful skills. However, many multitask reinforcement learning efforts assume the robot can collect data from all tasks at all times. In reality, the tasks that the robot learns arrive sequentially, depending on the user and the robot’s current environment. In this work, we study a practical sequential multi-task RL problem that is motivated by the practical constraints of physical robotic systems, and derive an approach that effectively leverages the data and policies learned for previous tasks to cumulatively grow the robot’s skillset. In a series of simulated robotic manipulation experiments, our approach requires less than half the samples than learning each task from scratch, while avoiding impractical round-robin data collection. On a Franka Emika Panda robot arm, our approach incrementally learns ten challenging tasks, including bottle capping and block insertion.",ArXiv,2021
94bcbb759907f63d3529ce3af839d644d5fee09d,https://www.semanticscholar.org/paper/94bcbb759907f63d3529ce3af839d644d5fee09d,Few-Shot Model-Based Adaptation in Noisy Conditions,"Few-shot adaptation is a challenging problem in the context of simulation-to-real transfer in robotics, requiring safe and informative data collection. In physical systems, additional challenge may be posed by domain noise, which is present in virtually all real-world applications. In this letter, we propose to perform few-shot adaptation of dynamics models in noisy conditions using an uncertainty-aware Kalman filter-based neural network architecture. We show that the proposed method, which explicitly addresses domain noise, improves few-shot adaptation error over a blackbox adaptation LSTM baseline, and over a model-free on-policy reinforcement learning approach, which tries to learn an adaptable and informative policy at the same time. The proposed method also allows for system analysis by analyzing hidden states of the model during and after adaptation.",IEEE Robotics and Automation Letters,2020
9bc8dbe6665a327c72d3b62a0362530633160b15,https://www.semanticscholar.org/paper/9bc8dbe6665a327c72d3b62a0362530633160b15,Domain Curiosity: Learning Efficient Data Collection Strategies for Domain Adaptation,"Domain adaptation is a common problem in robotics, with applications such as transferring policies from simulation to real world and lifelong learning. Performing such adaptation, however, requires informative data about the environment to be available during the adaptation. In this paper, we present domain curiosity—a method of training exploratory policies that are explicitly optimized to provide data that allows a model to learn about the unknown aspects of the environment. In contrast to most curiosity methods, our approach explicitly rewards learning, which makes it robust to environment noise without sacrificing its ability to learn. We evaluate the proposed method by comparing how much a model can learn about environment dynamics given data collected by the proposed approach, compared to standard curious and random policies. The evaluation is performed using a toy environment, two simulated robot setups, and on a real-world haptic exploration task. The results show that the proposed method allows data-efficient and accurate estimation of dynamics.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021
a450d0ab24320591b3258acc648fda2d71de92b8,https://www.semanticscholar.org/paper/a450d0ab24320591b3258acc648fda2d71de92b8,Domain adversarial transfer for cross-domain and task-constrained grasp pose detection,"Abstract Transferring the grasping skills learned from simulated environments to the real world is favorable for many robotic applications, in which the collecting and labeling processes of real-world visual grasping datasets are often expensive or even impractical. However, the models purely trained on simulated data are often difficult to generalize well to the unseen real world due to the domain gap between the training and testing data. In this paper, we propose a novel domain adversarial transfer network to narrow the domain gap for cross-domain and task-constrained grasp pose detection. Generative adversarial training is exploited to constrain the generator to produce simulation-like data for extracting the shared features with the joint distribution. We also propose to improve the backbone by extracting task-constrained grasp candidates and constructing the grasp candidate evaluator with a lightweight structure and an embedded recalibration technique. To validate the effectiveness and superiority of our proposed method, grasping performance evaluation and task-oriented human–robot interaction experiments were investigated. The experiment results indicate that the proposed method achieves state-of-the-art performance in these experimental settings. An average task-constrained grasping success rate of 83.3% without using any real-world labels for the task-oriented human–robot interaction experiment was achieved especially.",Robotics Auton. Syst.,2021
d2f4b49930d3976b29e11886c90a3b824c7d996b,https://www.semanticscholar.org/paper/d2f4b49930d3976b29e11886c90a3b824c7d996b,MESA: Offline Meta-RL for Safe Adaptation and Fault Tolerance,"Safe exploration is critical for using reinforcement learning (RL) in risk-sensitive environments. Recent work learns risk measures which measure the probability of violating constraints, which can then be used to enable safety. However, learning such risk measures requires significant interaction with the environment, resulting in excessive constraint violations during learning. Furthermore, these measures are not easily transferable to new environments. We cast safe exploration as an offline metaRL problem, where the objective is to leverage examples of safe and unsafe behavior across a range of environments to quickly adapt learned risk measures to a new environment with previously unseen dynamics. We then propose MEta-learning for Safe Adaptation (MESA), an approach for meta-learning a risk measure for safe RL. Simulation experiments across 5 continuous control domains suggest that MESA can leverage offline data from a range of different environments to reduce constraint violations in unseen environments by up to a factor of 2 while maintaining task performance. See https://tinyurl.com/safe-meta-rl for code and supplementary material.",ArXiv,2021
d9574faa2f4ddaf44ac6af641f0ccad76439b814,https://www.semanticscholar.org/paper/d9574faa2f4ddaf44ac6af641f0ccad76439b814,Calibration-Free Monocular Vision-Based Robot Manipulations With Occlusion Awareness,"Vision-based manipulation has been largely used in various robot applications. Normally, in order to obtain the spatial information of the operated target, a carefully calibrated stereo vision system is required. However, it limits the application of robots in the unstructured environment which limits both the number and the pose of the camera. In this study, a calibration-free monocular vision-based robot manipulation approach is proposed based on domain randomization and deep reinforcement learning (DRL). Firstly, a learning strategy combined domain randomization is developed to estimate the spatial information of the target from a single monocular camera arbitrarily mounted in a large area of the manipulation environment. Secondly, to address the monocular occlusion problem which regularly happens during robot manipulations, an occlusion awareness DRL policy has been designed to control the robot to avoid occlusions actively in the manipulation tasks. The performance of our method has been evaluated on two common manipulation tasks, reaching and lifting of a target building block, which show the efficiency and effectiveness of our proposed approach.",IEEE Access,2021
dff6ceff1c6ad4b05c923a71b2ccba35118893f7,https://www.semanticscholar.org/paper/dff6ceff1c6ad4b05c923a71b2ccba35118893f7,Population-Based Evolution Optimizes a Meta-Learning Objective,"Meta-learning models, or models that learn to learn, have been a long-desired target for their ability to quickly solve new tasks. Traditional meta-learning methods can require expensive inner and outer loops, thus there is demand for algorithms that discover strong learners without explicitly searching for them. We draw parallels to the study of evolvable genomes in evolutionary systems – genomes with a strong capacity to adapt – and propose that meta-learning and adaptive evolvability optimize for the same objective: high performance after a set of learning iterations. We argue that population-based evolutionary systems with non-static fitness landscapes naturally bias towards high-evolvability genomes, and therefore optimize for populations with strong learning ability. We demonstrate this claim with a simple evolutionary algorithm, Population-Based Meta Learning (PBML), that consistently discovers genomes which display higher rates of improvement over generations, and can rapidly adapt to solve sparse fitness and robotic control tasks.",ArXiv,2021
33a9513d6bf2c90ec81f98cee3518565b142d028,https://www.semanticscholar.org/paper/33a9513d6bf2c90ec81f98cee3518565b142d028,Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning,"Learning adaptable policies is crucial for robots to operate autonomously in our complex and quickly changing world. In this work, we present a new meta-learning method that allows robots to quickly adapt to changes in dynamics. In contrast to gradient-based meta-learning algorithms that rely on second-order gradient estimation, we introduce a more noise-tolerant Batch Hill-Climbing adaptation operator and combine it with meta-learning based on evolutionary strategies. Our method significantly improves adaptation to changes in dynamics in high noise settings, which are common in robotics applications. We validate our approach on a quadruped robot that learns to walk while subject to changes in dynamics. We observe that our method significantly outperforms prior gradient-based approaches, enabling the robot to adapt its policy to changes based on less than 3 minutes of real data.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
39a16b5d8421a2eca2ba2fa1b76029d5bcacd165,https://www.semanticscholar.org/paper/39a16b5d8421a2eca2ba2fa1b76029d5bcacd165,Data-efficient visuomotor policy training using reinforcement learning and generative models,"We present a data-efficient framework for solving deep visuomotor sequential decision-making problems which exploits the combination of reinforcement learning (RL) with the latent variable generative models. Our framework trains deep visuomotor policies by introducing an action latent variable such that the feed-forward policy search can be divided into two parts: (1) training a sub-policy that outputs a distribution over the action latent variable given a state of the system, and (2) training a generative model that outputs a sequence of motor actions given a latent action representation. Our approach enables safe exploration and alleviates the data-inefficiency problem as it exploits prior knowledge about valid sequences of motor actions. Moreover, by evaluating the quality of the generative models we are able to predict the performance of the RL policy training prior to the actual training on the physical robot. We achieve this by defining two novel measures, disentanglement and local linearity, for assessing the quality of generative models' latent spaces, and complementing them with the existing measures for evaluation of generative models. We demonstrate the efficiency of our approach on a picking task using several different generative models and determine which of their properties have the most influence on the final policy training.",ArXiv,2020
4b402059c9a73487429d5cff9c32c6e79a6e54da,https://www.semanticscholar.org/paper/4b402059c9a73487429d5cff9c32c6e79a6e54da,Challenges of Reinforcement Learning,"This chapter introduces the existing challenges in deep reinforcement learning research and applications, including: (1) the sample efficiency problem; (2) stability of training; (3) the catastrophic interference problem; (4) the exploration problems; (5) meta-learning and representation learning for the generality of reinforcement learning methods across tasks; (6) multi-agent reinforcement learning with other agents as part of the environment; (7) sim-to-real transfer for bridging the gaps between simulated environments and the real world; (8) large-scale reinforcement learning with parallel training frameworks to shorten the wall-clock time for training, etc. This chapter proposes the above challenges with potential solutions and research directions, as the primers of the advanced topics in the second main part of the book, including Chaps. 8– 12, to provide the readers a relatively comprehensive understanding about the deficiencies of present methods, recent development, and future directions in deep reinforcement learning.",,2020
5a1b92aa50797a7c1e99b8840ff01aad66038596,https://www.semanticscholar.org/paper/5a1b92aa50797a7c1e99b8840ff01aad66038596,Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey,"Deep reinforcement learning has recently seen huge success across multiple areas in the robotics domain. Owing to the limitations of gathering real-world data, i.e., sample inefficiency and the cost of collecting it, simulation environments are utilized for training the different agents. This not only aids in providing a potentially infinite data source, but also alleviates safety concerns with real robots. Nonetheless, the gap between the simulated and real worlds degrades the performance of the policies once the models are transferred into real robots. Multiple research efforts are therefore now being directed towards closing this sim-toreal gap and accomplish more efficient policy transfer. Recent years have seen the emergence of multiple methods applicable to different domains, but there is a lack, to the best of our knowledge, of a comprehensive review summarizing and putting into context the different methods. In this survey paper, we cover the fundamental background behind sim-to-real transfer in deep reinforcement learning and overview the main methods being utilized at the moment: domain randomization, domain adaptation, imitation learning, meta-learning and knowledge distillation. We categorize some of the most relevant recent works, and outline the main application scenarios. Finally, we discuss the main opportunities and challenges of the different approaches and point to the most promising directions.",,2020
5a966f6cb904d2e4c5aa09a375bd79b19e9e4b2b,https://www.semanticscholar.org/paper/5a966f6cb904d2e4c5aa09a375bd79b19e9e4b2b,Crossing the Gap: A Deep Dive into Zero-Shot Sim-to-Real Transfer for Dynamics,"Zero-shot sim-to-real transfer of tasks with complex dynamics is a highly challenging and unsolved problem. A number of solutions have been proposed in recent years, but we have found that many works do not present a thorough evaluation in the real world, or underplay the significant engineering effort and task-specific fine tuning that is required to achieve the published results. In this paper, we dive deeper into the sim-to-real transfer challenge, investigate why this is such a difficult problem, and present objective evaluations of a number of transfer methods across a range of real-world tasks. Surprisingly, we found that a method which simply injects random forces into the simulation performs just as well as more complex methods, such as those which randomise the simulator’s dynamics parameters, or adapt a policy online using recurrent network architectures.",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2020
5aa29ada06cc39560285d20b1e495c78471a381e,https://www.semanticscholar.org/paper/5aa29ada06cc39560285d20b1e495c78471a381e,Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey,"Deep} reinforcement learning has recently seen huge success across multiple areas in the robotics domain. Owing to the limitations of gathering real-world data, i.e., sample inefficiency and the cost of collecting it, simulation environments are utilized for training the different agents. This not only aids in providing a potentially infinite data source, but also alleviates safety concerns with real robots. Nonetheless, the gap between the simulated and real worlds degrades the performance of the policies once the models are transferred into real robots. Multiple research efforts are therefore now being directed towards closing this sim-toreal gap and accomplish more efficient policy transfer. Recent years have seen the emergence of multiple methods applicable to different domains, but there is a lack, to the best of our knowledge, of a comprehensive review summarizing and putting into context the different methods. In this survey paper, we cover the fundamental background behind sim-to-real transfer in deep reinforcement learning and overview the main methods being utilized at the moment: domain randomization, domain adaptation, imitation learning, meta-learning and knowledge distillation. We categorize some of the most relevant recent works, and outline the main application scenarios. Finally, we discuss the main opportunities and challenges of the different approaches and point to the most promising directions.",2020 IEEE Symposium Series on Computational Intelligence (SSCI),2020
778bb3061f09f229b46ffe4cf587d198441ed0a5,https://www.semanticscholar.org/paper/778bb3061f09f229b46ffe4cf587d198441ed0a5,Towards Closing the Sim-to-Real Gap in Collaborative Multi-Robot Deep Reinforcement Learning,"Current research directions in deep reinforcement learning include bridging the simulation-reality gap, improving sample efficiency of experiences in distributed multi-agent reinforcement learning, together with the development of robust methods against adversarial agents in distributed learning, among many others. In this work, we are particularly interested in analyzing how multi-agent reinforcement learning can bridge the gap to reality in distributed multi-robot systems where the operation of the different robots is not necessarily homogeneous. These variations can happen due to sensing mismatches, inherent errors in terms of calibration of the mechanical joints, or simple differences in accuracy. While our results are simulation-based, we introduce the effect of sensing, calibration, and accuracy mismatches in distributed reinforcement learning with proximal policy optimization (PPO). We discuss on how both the different types of perturbances and how the number of agents experiencing those perturbances affect the collaborative learning effort. The simulations are carried out using a Kuka arm model in the Bullet physics engine. This is, to the best of our knowledge, the first work exploring the limitations of PPO in multi-robot systems when considering that different robots might be exposed to different environments where their sensors or actuators have induced errors. With the conclusions of this work, we set the initial point for future work on designing and developing methods to achieve robust reinforcement learning on the presence of real-world perturbances that might differ within a multi-robot system.",2020 5th International Conference on Robotics and Automation Engineering (ICRAE),2020
7ff09f598f3fa3c171e791a741de2802c1be0253,https://www.semanticscholar.org/paper/7ff09f598f3fa3c171e791a741de2802c1be0253,"Collaborative Multi-Robot Search and Rescue: Planning, Coordination, Perception, and Active Vision","Search and rescue (SAR) operations can take significant advantage from supporting autonomous or teleoperated robots and multi-robot systems. These can aid in mapping and situational assessment, monitoring and surveillance, establishing communication networks, or searching for victims. This paper provides a review of multi-robot systems supporting SAR operations, with system-level considerations and focusing on the algorithmic perspectives for multi-robot coordination and perception. This is, to the best of our knowledge, the first survey paper to cover (i) heterogeneous SAR robots in different environments, (ii) active perception in multi-robot systems, while (iii) giving two complementary points of view from the multi-agent perception and control perspectives. We also discuss the most significant open research questions: shared autonomy, sim-to-real transferability of existing methods, awareness of victims’ conditions, coordination and interoperability in heterogeneous multi-robot systems, and active perception. The different topics in the survey are put in the context of the different challenges and constraints that various types of robots (ground, aerial, surface, or underwater) encounter in different SAR environments (maritime, urban, wilderness, or other post-disaster scenarios). The objective of this survey is to serve as an entry point to the various aspects of multi-robot SAR systems to researchers in both the machine learning and control fields by giving a global overview of the main approaches being taken in the SAR robotics area.",IEEE Access,2020
a3e45d8dd69f2b83f623c2d2a86aca36d58c50ae,https://www.semanticscholar.org/paper/a3e45d8dd69f2b83f623c2d2a86aca36d58c50ae,Science Journals — AAAS,"The game of curling can be considered a good test bed for studying the interaction between artificial intelligence systems and the real world. In curling, the environmental characteristics change at every moment, and every throw has an impact on the outcome of the match. Furthermore, there is no time for relearning during a curling match due to the timing rules of the game. Here, we report a curling robot that can achieve human-level performance in the game of curling using an adaptive deep reinforcement learning framework. Our proposed adaptation framework extends standard deep reinforcement learning using temporal features, which learn to compensate for the uncertainties and nonstationarities that are an unavoidable part of curling. Our curling robot, Curly, was able to win three of four official matches against expert human teams [top-ranked women’s curling teams and Korea national wheelchair curling team (reserve team)]. These results indicate that the gap between physics-based simulators and the real world can be narrowed.",,2020
acf24ff124d9359d0404ed77967d292fc2e0a342,https://www.semanticscholar.org/paper/acf24ff124d9359d0404ed77967d292fc2e0a342,MELD: Meta-Reinforcement Learning from Images via Latent State Models,"Meta-reinforcement learning algorithms can enable autonomous agents, such as robots, to quickly acquire new behaviors by leveraging prior experience in a set of related training tasks. However, the onerous data requirements of meta-training compounded with the challenge of learning from sensory inputs such as images have made meta-RL challenging to apply to real robotic systems. Latent state models, which learn compact state representations from a sequence of observations, can accelerate representation learning from visual inputs. In this paper, we leverage the perspective of meta-learning as task inference to show that latent state models can \emph{also} perform meta-learning given an appropriately defined observation space. Building on this insight, we develop meta-RL with latent dynamics (MELD), an algorithm for meta-RL from images that performs inference in a latent state model to quickly acquire new skills given observations and rewards. MELD outperforms prior meta-RL methods on several simulated image-based robotic control problems, and enables a real WidowX robotic arm to insert an Ethernet cable into new locations given a sparse task completion signal after only $8$ hours of real world meta-training. To our knowledge, MELD is the first meta-RL algorithm trained in a real-world robotic control setting from images.",CoRL,2020
bcf05632914146831ce52a5c56322b2127f8c89d,https://www.semanticscholar.org/paper/bcf05632914146831ce52a5c56322b2127f8c89d,Collaborative Multi-Robot Systems for Search and Rescue: Coordination and Perception,"Autonomous or teleoperated robots have been playing increasingly important roles in civil applications in recent years. Across the different civil domains where robots can support human operators, one of the areas where they can have more impact is in search and rescue (SAR) operations. In particular, multi-robot systems have the potential to significantly improve the efficiency of SAR personnel with faster search of victims, initial assessment and mapping of the environment, real-time monitoring and surveillance of SAR operations, or establishing emergency communication networks, among other possibilities. SAR operations encompass a wide variety of environments and situations, and therefore heterogeneous and collaborative multi-robot systems can provide the most advantages. In this paper, we review and analyze the existing approaches to multi-robot SAR support, from an algorithmic perspective and putting an emphasis on the methods enabling collaboration among the robots as well as advanced perception through machine vision and multi-agent active perception. Furthermore, we put these algorithms in the context of the different challenges and constraints that various types of robots (ground, aerial, surface or underwater) encounter in different SAR environments (maritime, urban, wilderness or other post-disaster scenarios). This is, to the best of our knowledge, the first review considering heterogeneous SAR robots across different environments, while giving two complimentary points of view: control mechanisms and machine perception. Based on our review of the state-of-the-art, we discuss the main open research questions, and outline our insights on the current approaches that have potential to improve the real-world performance of multi-robot SAR systems.",ArXiv,2020
e1733a4863b16a33860b9342e819a5cde0f9ae22,https://www.semanticscholar.org/paper/e1733a4863b16a33860b9342e819a5cde0f9ae22,Ubiquitous Distributed Deep Reinforcement Learning at the Edge: Analyzing Byzantine Agents in Discrete Action Spaces,"The integration of edge computing in next-generation mobile networks is bringing low-latency and high-bandwidth ubiquitous connectivity to a myriad of cyber-physical systems. This will further boost the increasing intelligence that is being embedded at the edge in various types of autonomous systems, where collaborative machine learning has the potential to play a significant role. This paper discusses some of the challenges in multi-agent distributed deep reinforcement learning that can occur in the presence of byzantine or malfunctioning agents. As the simulation-to-reality gap gets bridged, the probability of malfunctions or errors must be taken into account. We show how wrong discrete actions can significantly affect the collaborative learning effort. In particular, we analyze the effect of having a fraction of agents that might perform the wrong action with a given probability. We study the ability of the system to converge towards a common working policy through the collaborative learning process based on the number of experiences from each of the agents to be aggregated for each policy update, together with the fraction of wrong actions from agents experiencing malfunctions. Our experiments are carried out in a simulation environment using the Atari testbed for the discrete action spaces, and advantage actor-critic (A2C) for the distributed multi-agent training.",EUSPN/ICTH,2020
f895aa166250324324fe167127ba03b9a46a0d8e,https://www.semanticscholar.org/paper/f895aa166250324324fe167127ba03b9a46a0d8e,An adaptive deep reinforcement learning framework enables curling robots with human-like performance in real-world conditions,"An AI curling robot can compete and win against top-ranked human teams in the game of curling. The game of curling can be considered a good test bed for studying the interaction between artificial intelligence systems and the real world. In curling, the environmental characteristics change at every moment, and every throw has an impact on the outcome of the match. Furthermore, there is no time for relearning during a curling match due to the timing rules of the game. Here, we report a curling robot that can achieve human-level performance in the game of curling using an adaptive deep reinforcement learning framework. Our proposed adaptation framework extends standard deep reinforcement learning using temporal features, which learn to compensate for the uncertainties and nonstationarities that are an unavoidable part of curling. Our curling robot, Curly, was able to win three of four official matches against expert human teams [top-ranked women’s curling teams and Korea national wheelchair curling team (reserve team)]. These results indicate that the gap between physics-based simulators and the real world can be narrowed.",Science Robotics,2020
43e68aba1abf6105efc88050d9d9b59a943ad61a,https://www.semanticscholar.org/paper/43e68aba1abf6105efc88050d9d9b59a943ad61a,Smart Vacuum Cleaner,,Global Transitions Proceedings,2021
5c92609ed277cf6bc29b4d5de2757791d6ef575e,https://www.semanticscholar.org/paper/5c92609ed277cf6bc29b4d5de2757791d6ef575e,Topological Semantic Mapping by Consolidation of Deep Visual Features,"Many works in the recent literature introduce semantic mapping methods that use CNNs (Convolutional Neural Networks) to recognize semantic properties in images. The types of properties (eg.: room size, place category, and objects) and their classes (eg.: kitchen and bathroom, for place category) are usually predefined and restricted to a specific task. Thus, all the visual data acquired and processed during the construction of the maps are lost and only the recognized semantic properties remain on the maps. In contrast, this work introduces a topological semantic mapping method that uses deep visual features extracted by a CNN (GoogLeNet), from 2D images captured in multiple views of the environment as the robot operates, to create, through averages, consolidated representations of the visual features acquired in the regions covered by each topological node. These representations allow flexible recognition of semantic properties of the regions and use in other visual tasks. Experiments with a real-world indoor dataset showed that the method is able to consolidate the visual features of regions and use them to recognize objects and place categories as semantic properties, and to indicate the topological location of images, with very promising results.",ArXiv,2021
719ddef224ec5e75315fc7543efb057cb1b54c5a,https://www.semanticscholar.org/paper/719ddef224ec5e75315fc7543efb057cb1b54c5a,Efficient semantic place categorization by a robot through active line-of-sight selection,,Knowledge-Based Systems,2021
7fa50fd594bb94ffee8520305f543086f691b149,https://www.semanticscholar.org/paper/7fa50fd594bb94ffee8520305f543086f691b149,Capsule-Based Networks for Road Marking Extraction and Classification From Mobile LiDAR Point Clouds,"Accurate road marking extraction and classification play a significant role in the development of autonomous vehicles (AVs) and high-definition (HD) maps. Due to point density and intensity variations from mobile laser scanning (MLS) systems, most of the existing thresholding-based extraction methods and rule-based classification methods cannot deliver high efficiency and remarkable robustness. To address this, we propose a capsule-based deep learning framework for road marking extraction and classification from massive and unordered MLS point clouds. This framework mainly contains three modules. Module I is first implemented to segment road surfaces from 3D MLS point clouds, followed by an inverse distance weighting (IDW) interpolation method for 2D georeferenced image generation. Then, in Module II, a U-shaped capsule-based network is constructed to extract road markings based on the convolutional and deconvolutional capsule operations. Finally, a hybrid capsule-based network is developed to classify different types of road markings by using a revised dynamic routing algorithm and large-margin Softmax loss function. A road marking dataset containing both 3D point clouds and manually labeled reference data is built from three types of road scenes, including urban roads, highways, and underground garages. The proposed networks were accordingly evaluated by estimating robustness and efficiency using this dataset. Quantitative evaluations indicate the proposed extraction method can deliver 94.11% in precision, 90.52% in recall, and 92.43% in F1-score, respectively, while the classification network achieves an average of 3.42% misclassification rate in different road scenes.",IEEE Transactions on Intelligent Transportation Systems,2021
71b9b12639bc001a8f4431841dce2712fbcdaf05,https://www.semanticscholar.org/paper/71b9b12639bc001a8f4431841dce2712fbcdaf05,Road Information Extraction from Mobile LiDAR Point Clouds using Deep Neural Networks,................................................................................................................................................. v Acknowledgements .............................................................................................................................. vii List of Figures ....................................................................................................................................... xi List of Tables ....................................................................................................................................... xiii List of Abbreviations ........................................................................................................................... xiv Chapter,,2020
b442f26802f2d758e0c915b4c1dc6013b4c1edaa,https://www.semanticscholar.org/paper/b442f26802f2d758e0c915b4c1dc6013b4c1edaa,Hybrid Semi-Dense 3D Semantic-Topological Mapping From Stereo Visual-Inertial Odometry SLAM With Loop Closure Detection,"Intelligent mobile vehicles asks for the ability to learn to comprehend immediate surroundings similar to human cognition and autonomously navigate in an unknown scene. Although simultaneous localization and mapping (SLAM) can construct a geometrically surrounding map, the map contains little semantic information. This paper presents a novel stereo visual-inertial system with loop closure detection based on a semantic-topological map framework. In our system, a hybrid 3D point cloud semantic-topological mapping framework is used to realize autonomous navigation simply by providing a map for path planning and meanwhile for storing semantic information under a dynamic environment. A stereo visual-inertial system can obtain more accurate visual-inertial odometry than a monocular system, and a visual-inertial system is capable of real-time map correction when the localization module detects a loop closure. This paper adopts state-of-the-art Mask R-CNN components to obtain 2D semantic information and project it to a semi-dense 3D semantic-topological map built by stereo visual-inertial SLAM. We perform experimental evaluation of our proposed system on the EuRoC MAV datasets and we also compare it with other competitive methods. Our results demonstrate that the proposed method is more effective than the other competitive methods.",IEEE Transactions on Vehicular Technology,2020
fd4edd88e98633e1c5bff639f52459f6f0ba073b,https://www.semanticscholar.org/paper/fd4edd88e98633e1c5bff639f52459f6f0ba073b,Semantic map for service robot navigation based on ROS,"The environment perception and navigation ability of robots are the basis of robot interaction with environment. The scene understanding is the prerequisite of robot autonomous navigation and navigation is the ultimate goal of robot scene understanding, therefore, a mobile robot semantic map navigation system is designed. Firstly, a dense pointcloud map is constructed by using a deep convolutional neural network. Then, the mapping relationship between the depth camera data and the laser data is proposed, for purpose of realizing their interconversion. And a method of constructing two-dimensional raster map by simulating laser data by using the data of the depth camera is proposed. Finally, a method that semantic information is integrated into the two-dimensional grid map is proposed, realizing the semantic navigation of the service robot. The experimental results showed that compared with other robotic navigation systems, the proposed algorithm can better realize the interactions between service robots and people and the environment.",Target Recognition and Artificial Intelligence Summit Forum,2020
02695dca78cfe5c6c4fc7e4659b7ecac2b793bbc,https://www.semanticscholar.org/paper/02695dca78cfe5c6c4fc7e4659b7ecac2b793bbc,Multi-Modal Human-Aware Image Caption System for Intelligent Service Robotics Applications,"Image captioning is a high-level task that generates the context scenario descriptions from an image. There are many ways to implement such kinds of ability that can generate a smooth sentence about the context scenario. Because of the open and extensive domain of the dataset, seldom of them can really help people to get the meaningful information of a specified scenario. In this paper, we propose a novel framework called Human-Aware Context Generator (HACG). We adopt the concept of dividing and conquer, which combines the ability of face recognition and facial expression recognition while retaining the capability of image caption model. This model aims to offer a significant context scenario sentence to the people, especially for those who are urgent to master the overall situation.",2019 IEEE 28th International Symposium on Industrial Electronics (ISIE),2019
621842b8736c34c54e9e17c0fb3f6a39bd467cf3,https://www.semanticscholar.org/paper/621842b8736c34c54e9e17c0fb3f6a39bd467cf3,DEDUCE: Diverse scEne Detection methods in Unseen Challenging Environments,"In recent years, there has been a rapid increase in the number of service robots deployed for aiding people in their daily activities. Unfortunately, most of these robots require human input for training in order to do tasks in indoor environments. Successful domestic navigation often requires access to semantic information about the environment, which can be learned without human guidance. In this paper, we propose a set of DEDUCE1 -Diverse scEne Detection methods in Unseen Challenging Environments algorithms which incorporate deep fusion models derived from scene recognition systems and object detectors. The five methods described here have been evaluated on several popular recent image datasets, as well as real-world videos acquired through multiple mobile platforms. The final results show an improvement over the existing state-of-the-art visual place recognition systems.1Supplementary material including code and the videos of the different experiments are available at https://sites.google.com/eng.ucsd.edu/deduce.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019
f5e4bfa84471ecc0272538eabb216f4eb94f03a0,https://www.semanticscholar.org/paper/f5e4bfa84471ecc0272538eabb216f4eb94f03a0,A Robot-Mediated Assessment of Tinetti Balance scale for Sarcopenia Evaluation in Frail Elderly*,"Aging society is characterized by a high prevalence of sarcopenia, which is considered one of the most common health problems of the elderly population. Sarcopenia is due to the age-related loss of muscle mass and muscle strength. Recent literature findings highlight that the Tinetti Balance Assessment (TBA) scale is used to assess the sarcopenia in elderly people. In this context, this article proposes a model for sarcopenia assessment that is able to provide a quantitative assessment of TBA-gait motor parameters by means of a cloud robotics approach. The proposed system is composed of cloud resources, an assistive robot namely ASTRO and two inertial wearable sensors. Particularly, data from two inertial sensors (i.e., accelerometers and gyroscopes), placed on the patient’s feet, and data from ASTRO laser sensor (position in the environment) were analyzed and combined to propose a set of motor features correspondent to the TBA gait domains. The system was preliminarily tested at the hospital of “Fondazione Casa Sollievo della Sofferenza” in Italy. The preliminary results suggest that the extracted set of features is able to describe the motor performance. In the future, these parameters could be used to support the clinicians in the assessment of sarcopenia, to monitoring the motor parameters over time and to propose personalized care-plan.",2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),2019
https://arxiv.org/abs/2011.06450,https://arxiv.org/abs/2011.06450,A deep Q-Learning based Path Planning and Navigation System for Firefighting Environments,"Live fire creates a dynamic, rapidly changing environment that presents a worthy challenge for deep learning and artificial intelligence methodologies to assist firefighters with scene comprehension in maintaining their situational awareness, tracking and relay of important features necessary for key decisions as they tackle these catastrophic events. We propose a deep Q-learning based agent who is immune to stress induced disorientation and anxiety and thus able to make clear decisions for navigation based on the observed and stored facts in live fire environments. As a proof of concept, we imitate structural fire in a gaming engine called Unreal Engine which enables the interaction of the agent with the environment. The agent is trained with a deep Q-learning algorithm based on a set of rewards and penalties as per its actions on the environment. We exploit experience replay to accelerate the learning process and augment the learning of the agent with human-derived experiences. The agent trained under this deep Q-learning approach outperforms agents trained through alternative path planning systems and demonstrates this methodology as a promising foundation on which to build a path planning navigation assistant capable of safely guiding fire fighters through live fire environments.",ArXiv,2020
https://www.mdpi.com/2076-3417/11/18/8425,https://www.mdpi.com/2076-3417/11/18/8425,An Initial Machine Learning-Based Victims Scream Detection Analysis for Burning Sites,"Fire incidents are responsible for severe damage and thousands of deaths every year all over the world. Extreme temperatures, low visibility, toxic gases, and unknown locations of victims create difficulties and delays in rescue operations, escalating the risk of injury or death. It is time-critical to detect the victims trapped inside the burning sites for facilitating the rescue operations. This research work presents an audio-based automated system for victim detection in fire emergencies, investigating two machine learning (ML) methods: support vector machines (SVM) and long short-term memory (LSTM). The performance of these two ML techniques has been evaluated based on a variety of performance metrics. Our analyses show that both ML methods provide superior scream detection performance, with SVM slightly overperforming LSTM. Because of its lower complexity, SVM is a better candidate for real-time implementation in our autonomous embedded system vehicle (AESV).",MDPI,2021
https://iopscience.iop.org/article/10.1088/2058-8585/ac32a9,https://iopscience.iop.org/article/10.1088/2058-8585/ac32a9,"Smart personal protective equipment (PPE): current PPE needs, opportunities for nanotechnology and e-textiles","Smart personal protective equipment (PPE) is the future of improved occupational health and safety, and nanotechnology facilitates the development of critical smart PPE components such as smart textiles, wearable/flexible electronics, and augmented reality among others. Smart PPE utilizes sensing and communication technology in a way that is non-intrusive to either improve workplace safety or enhance occupational capabilities. The development of such smart PPE requires a multidisciplinary approach. This paper investigates the current state of PPE technologies for firefighters, healthcare workers, police/military, and construction workers. The modern PPE needs are identified from both end user surveys as well as expert third-party studies. There are already some smart PPE solutions for the challenges identified. Recent advances in stretchable and textile-based electronics, enabled by nanotechnology, demonstrate almost all imaginable solutions to the unmet needs that PPE users and expert advisor groups have identified. However, integration into smart PPE requires attention to the unique harsh conditions of hazardous workplaces. This review aims to inspire researchers in the field of flexible and printed electronics to develop and improve future smart PPE.",IOP Science,2021
https://ieeexplore.ieee.org/abstract/document/9627122,https://ieeexplore.ieee.org/abstract/document/9627122,An Outlook on the Future Marine Traffic Management System for Autonomous Ships,"In the shipping digitalisation process, the peak will be reached with the advent of a wholly autonomous and at the same time safe and reliable ship. Full autonomy could be obtained by two linked Artificial-Intelligence systems representing the ship navigator and the ship engineer that possess sensing and analysis skills, situational awareness, planning, and control capabilities. Many efforts have been made in developing onboard systems; however, the shore facilities are not ready yet to deal with these new technologies. The paper aims to present the innovative technologies and methodologies needed to develop a futuristic Vessel Traffic System. The proposed systems will aim at faultless data acquisition and processing, provide input to decision-making systems, and suggest evasive manoeuvre; to deal with hazards and systems failure without human intervention onboard. The system is composed of three different and interacting layers. The first is an artificially intelligent tool to detect and control autonomous ships, thanks to situation recognition and obstacle avoidance strategies. The second is an orchestration and management platform designed to coordinate the sensing/actuation infrastructure and the AI algorithms results made available by multiple ships, mustering edge, and distributed computing techniques to fulfil the specific harsh requirements of the sea environment. The final part is a holistic guidance-navigation-control framework to manage autonomous ships navigation in a crowded area. Eventually, a cyber-physical scenario, using both a ship digital-twin and a real model-scale ship, is suggested to test and validate the innovative system without the availability of a full-scale scenario.",IEEE,2021
https://www.mdpi.com/1424-8220/21/11/3888,https://www.mdpi.com/1424-8220/21/11/3888,"Measuring User Experience, Usability and Interactivity of a Personalized Mobile Augmented Reality Training System","Innovative technology has been an important part of firefighting, as it advances firefighters safety and effectiveness. Prior research has examined the implementation of training systems using augmented reality (AR) in other domains, such as welding, aviation, army, and mathematics, offering significant pedagogical affordances. Nevertheless, firefighting training systems using AR are still an under-researched area. The increasing penetration of AR for training is the driving force behind this study, and the scope is to analyze the main aspects affecting the acceptance of AR by firefighters. The current research uses a technology acceptance model, extended by the external constructs of perceived interactivity and personalization, to consider both the system and individual level. The proposed model was evaluated by a sample of 200 users, and the results show that both the external variables of perceived interactivity and perceived personalization are prerequisite factors in extending the TAM model. The findings reveal that the usability is the strongest predictor of firefighters behavioral intentions to use the AR system, followed by the ease of use with smaller, yet meaningful, direct and indirect effects on firefighters intentions. The identified acceptance factors help AR developers enhance the firefighters experience in training operations.",MDPI,2021
https://www.sciencedirect.com/science/article/pii/S2352711021001837,https://www.sciencedirect.com/science/article/pii/S2352711021001837,tx2_fcnn_node: An open-source ROS compatible tool for monocular depth reconstruction,"We present tx2_fcnn_node a Robot Operating System (ROS) compatible tool that is aimed at seamless integration of various monocular depth reconstruction neural networks to the robotic software based on ROS (which is a de-facto standard in the area of robotics). Our tool simplifies the process of deploying, evaluating, and comparing depth reconstruction neural networks both on real robots and in simulation. We complement our software with a set of the precompiled neural networks which can be used off the shelf, with some of them being able to demonstrate near real-time performance when running onboard compact embedded platforms, e.g. Nvidia Jetson TX2, that are often used nowadays both in academia and industry.",Sciencedirect,2022