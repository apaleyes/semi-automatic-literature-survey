doi,publication_date,publication,publisher,title,abstract,database
10.1109/ICRA.2018.8460655,2018-05-21,p,IEEE,self supervised deep reinforcement learning with generalized computation graphs for robot navigation," Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and None $N$ None -step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg",project-academic
,2017-09-29,a,,self supervised deep reinforcement learning with generalized computation graphs for robot navigation," Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and $N$-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at this http URL",project-academic
10.15607/RSS.2020.XVI.064,2020-07-12,p,Robotics: Science and Systems Foundation,learning agile robotic locomotion skills by imitating animals," Reproducing the diverse and agile locomotion skills of animals has been a longstanding challenge in robotics. While manually-designed controllers have been able to emulate many complex behaviors, building such controllers involves a time-consuming and difficult development process, often requiring substantial expertise of the nuances of each skill. Reinforcement learning provides an appealing alternative for automating the manual effort involved in the development of controllers. However, designing learning objectives that elicit the desired behaviors from an agent can also require a great deal of skill-specific expertise. In this work, we present an imitation learning system that enables legged robots to learn agile locomotion skills by imitating real-world animals. We show that by leveraging reference motion data, a single learning-based approach is able to automatically synthesize controllers for a diverse repertoire behaviors for legged robots. By incorporating sample efficient domain adaptation techniques into the training process, our system is able to learn adaptive policies in simulation that can then be quickly adapted for real-world deployment. To demonstrate the effectiveness of our system, we train an 18-DoF quadruped robot to perform a variety of agile behaviors ranging from different locomotion gaits to dynamic hops and turns.",project-academic
,2020-04-02,a,,learning agile robotic locomotion skills by imitating animals," Reproducing the diverse and agile locomotion skills of animals has been a longstanding challenge in robotics. While manually-designed controllers have been able to emulate many complex behaviors, building such controllers involves a time-consuming and difficult development process, often requiring substantial expertise of the nuances of each skill. Reinforcement learning provides an appealing alternative for automating the manual effort involved in the development of controllers. However, designing learning objectives that elicit the desired behaviors from an agent can also require a great deal of skill-specific expertise. In this work, we present an imitation learning system that enables legged robots to learn agile locomotion skills by imitating real-world animals. We show that by leveraging reference motion data, a single learning-based approach is able to automatically synthesize controllers for a diverse repertoire behaviors for legged robots. By incorporating sample efficient domain adaptation techniques into the training process, our system is able to learn adaptive policies in simulation that can then be quickly adapted for real-world deployment. To demonstrate the effectiveness of our system, we train an 18-DoF quadruped robot to perform a variety of agile behaviors ranging from different locomotion gaits to dynamic hops and turns.",project-academic
10.1109/ICRA.2019.8794127,2019-05-20,p,IEEE,residual reinforcement learning for robot control," Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.",project-academic
,2018-12-07,a,,residual reinforcement learning for robot control," Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.",project-academic
,2018-05-20,a,,a lyapunov based approach to safe reinforcement learning," In many real-world reinforcement learning (RL) problems, besides optimizing the main objective function, an agent must concurrently avoid violating a number of constraints. In particular, besides optimizing performance it is crucial to guarantee the safety of an agent during training as well as deployment (e.g. a robot should avoid taking actions - exploratory or not - which irrevocably harm its hardware). To incorporate safety in RL, we derive algorithms under the framework of constrained Markov decision problems (CMDPs), an extension of the standard Markov decision problems (MDPs) augmented with constraints on expected cumulative costs. Our approach hinges on a novel \emph{Lyapunov} method. We define and present a method for constructing Lyapunov functions, which provide an effective way to guarantee the global safety of a behavior policy during training via a set of local, linear constraints. Leveraging these theoretical underpinnings, we show how to use the Lyapunov approach to systematically transform dynamic programming (DP) and RL algorithms into their safe counterparts. To illustrate their effectiveness, we evaluate these algorithms in several CMDP planning and decision-making tasks on a safety benchmark domain. Our results show that our proposed method significantly outperforms existing baselines in balancing constraint satisfaction and performance.",project-academic
10.1109/LRA.2019.2903261,2018-09-10,a,,primal pathfinding via reinforcement and imitation multi agent learning," Multi-agent path finding (MAPF) is an essential component of many large-scale, real-world robot deployments, from aerial swarms to warehouse automation. However, despite the community's continued efforts, most state-of-the-art MAPF planners still rely on centralized planning and scale poorly past a few hundred agents. Such planning approaches are maladapted to real-world deployments, where noise and uncertainty often require paths be recomputed online, which is impossible when planning times are in seconds to minutes. We present PRIMAL, a novel framework for MAPF that combines reinforcement and imitation learning to teach fully-decentralized policies, where agents reactively plan paths online in a partially-observable world while exhibiting implicit coordination. This framework extends our previous work on distributed learning of collaborative policies by introducing demonstrations of an expert MAPF planner during training, as well as careful reward shaping and environment sampling. Once learned, the resulting policy can be copied onto any number of agents and naturally scales to different team sizes and world dimensions. We present results on randomized worlds with up to 1024 agents and compare success rates against state-of-the-art MAPF planners. Finally, we experimentally validate the learned policies in a hybrid simulation of a factory mockup, involving both real-world and simulated robots.",project-academic
,2017-02-03,a,,uncertainty aware reinforcement learning for collision avoidance," Reinforcement learning can enable complex, adaptive behavior to be learned automatically for autonomous robotic platforms. However, practical deployment of reinforcement learning methods must contend with the fact that the training process itself can be unsafe for the robot. In this paper, we consider the specific case of a mobile robot learning to navigate an a priori unknown environment while avoiding collisions. In order to learn collision avoidance, the robot must experience collisions at training time. However, high-speed collisions, even at training time, could damage the robot. A successful learning method must therefore proceed cautiously, experiencing only low-speed collisions until it gains confidence. To this end, we present an uncertainty-aware model-based learning algorithm that estimates the probability of collision together with a statistical estimate of uncertainty. By formulating an uncertainty-dependent cost function, we show that the algorithm naturally chooses to proceed cautiously in unfamiliar environments, and increases the velocity of the robot in settings where it has high confidence. Our predictive model is based on bootstrapped neural networks using dropout, allowing it to process raw sensory inputs from high-bandwidth sensors such as cameras. Our experimental evaluation demonstrates that our method effectively minimizes dangerous collisions at training time in an obstacle avoidance task for a simulated and real-world quadrotor, and a real-world RC car. Videos of the experiments can be found at this https URL.",project-academic
,2016-10-11,a,,transfer from simulation to real world through learning deep inverse dynamics model," Developing control policies in simulation is often more practical and safer than directly running experiments in the real world. This applies to policies obtained from planning and optimization, and even more so to policies obtained from reinforcement learning, which is often very data demanding. However, a policy that succeeds in simulation often doesn't work when deployed on a real robot. Nevertheless, often the overall gist of what the policy does in simulation remains valid in the real world. In this paper we investigate such settings, where the sequence of states traversed in simulation remains reasonable for the real world, even if the details of the controls are not, as could be the case when the key differences lie in detailed friction, contact, mass and geometry properties. During execution, at each time step our approach computes what the simulation-based control policy would do, but then, rather than executing these controls on the real robot, our approach computes what the simulation expects the resulting next state(s) will be, and then relies on a learned deep inverse dynamics model to decide which real-world action is most suitable to achieve those next states. Deep models are only as good as their training data, and we also propose an approach for data collection to (incrementally) learn the deep inverse dynamics model. Our experiments shows our approach compares favorably with various baselines that have been developed for dealing with simulation to real world model discrepancy, including output error control and Gaussian dynamics adaptation.",project-academic
10.1126/SCIROBOTICS.AAZ9239,2020-04-22,a,Science Robotics,electronic skins and machine learning for intelligent soft robots," Soft robots have garnered interest for real-world applications because of their intrinsic safety embedded at the material level. These robots use deformable materials capable of shape and behavioral changes and allow conformable physical contact for manipulation. Yet, with the introduction of soft and stretchable materials to robotic systems comes a myriad of challenges for sensor integration, including multimodal sensing capable of stretching, embedment of high-resolution but large-area sensor arrays, and sensor fusion with an increasing volume of data. This Review explores the emerging confluence of e-skins and machine learning, with a focus on how roboticists can combine recent developments from the two fields to build autonomous, deployable soft robots, integrated with capabilities for informative touch and proprioception to stand up to the challenges of real-world environments.",project-academic
,2017-01-01,p,,unsupervised perceptual rewards for imitation learning," Reward function design and exploration time are arguably the biggest obstacles to the deployment of reinforcement learning (RL) agents in the real world. In many real-world tasks, designing a reward function takes considerable hand engineering and often requires additional sensors to be installed just to measure whether the task has been executed successfully. Furthermore, many interesting tasks consist of multiple implicit intermediate steps that must be executed in sequence. Even when the final outcome can be measured, it does not necessarily provide feedback on these intermediate steps. To address these issues, we propose leveraging the abstraction power of intermediate visual representations learned by deep models to quickly infer perceptual reward functions from small numbers of demonstrations. We present a method that is able to identify key intermediate steps of a task from only a handful of demonstration sequences, and automatically identify the most discriminative features for identifying these steps. This method makes use of the features in a pre-trained deep model, but does not require any explicit specification of sub-goals. The resulting reward functions can then be used by an RL agent to learn to perform the task in real-world settings. To evaluate the learned reward, we present qualitative results on two real-world tasks and a quantitative evaluation against a human-designed reward function. We also show that our method can be used to learn a real-world door opening skill using a real robot, even when the demonstration used for reward learning is provided by a human using their own hand. To our knowledge, these are the first results showing that complex robotic manipulation skills can be learned directly and without supervised labels from a video of a human performing the task. Supplementary material and data are available at this https URL",project-academic
10.15607/RSS.2017.XIII.050,2017-02-17,p,,unsupervised perceptual rewards for imitation learning," Reward function design and exploration time are arguably the biggest obstacles to the deployment of reinforcement learning (RL) agents in the real world. In many real-world tasks, designing a reward function takes considerable hand engineering and often requires additional sensors to be installed just to measure whether the task has been executed successfully. Furthermore, many interesting tasks consist of multiple implicit intermediate steps that must be executed in sequence. Even when the final outcome can be measured, it does not necessarily provide feedback on these intermediate steps. To address these issues, we propose leveraging the abstraction power of intermediate visual representations learned by deep models to quickly infer perceptual reward functions from small numbers of demonstrations. We present a method that is able to identify key intermediate steps of a task from only a handful of demonstration sequences, and automatically identify the most discriminative features for identifying these steps. This method makes use of the features in a pre-trained deep model, but does not require any explicit specification of sub-goals. The resulting reward functions can then be used by an RL agent to learn to perform the task in real-world settings. To evaluate the learned reward, we present qualitative results on two real-world tasks and a quantitative evaluation against a human-designed reward function. We also show that our method can be used to learn a real-world door opening skill using a real robot, even when the demonstration used for reward learning is provided by a human using their own hand. To our knowledge, these are the first results showing that complex robotic manipulation skills can be learned directly and without supervised labels from a video of a human performing the task. Supplementary material and data are available at this https URL",project-academic
10.1109/LRA.2019.2894216,2019-01-21,p,IEEE,vr goggles for robots real to sim domain adaptation for visual control," In this letter, we deal with the None reality gap None from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to None make the robot feel at home . We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective None shift loss None that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the None shift loss None for None artistic style transfer for videos None and None domain adaptation , and validate our visual control approach in indoor and outdoor robotics experiments.",project-academic
10.1109/ICRA48506.2021.9562117,2021-05-30,p,IEEE,agile robot navigation through hallucinated learning and sober deployment," Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination—a feature we call ""sober deployment""—and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",project-academic
,2020-10-16,a,,agile robot navigation through hallucinated learning and sober deployment," Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination -- a feature we call ""sober deployment"" -- and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",project-academic
10.1177/0278364917727062,2018-04-02,a,,deep spatiotemporal models for robust proprioceptive terrain classification," Terrain classification is a critical component of any autonomous mobile robot system operating in unknown real-world environments. Over the years, several proprioceptive terrain classification techniques have been introduced to increase robustness or act as a fallback for traditional vision based approaches. However, they lack widespread adaptation due to various factors that include inadequate accuracy, robustness and slow run-times. In this paper, we use vehicle-terrain interaction sounds as a proprioceptive modality and propose a deep Long-Short Term Memory (LSTM) based recurrent model that captures both the spatial and temporal dynamics of such a problem, thereby overcoming these past limitations. Our model consists of a new Convolution Neural Network (CNN) architecture that learns deep spatial features, complemented with LSTM units that learn complex temporal dynamics. Experiments on two extensive datasets collected with different microphones on various indoor and outdoor terrains demonstrate state-of-the-art performance compared to existing techniques. We additionally evaluate the performance in adverse acoustic conditions with high ambient noise and propose a noise-aware training scheme that enables learning of more generalizable models that are essential for robust real-world deployments.",project-academic
,2018-01-26,a,,safe exploration in continuous action spaces," We address the problem of deploying a reinforcement learning (RL) agent on a physical system such as a datacenter cooling unit or robot, where critical constraints must never be violated. We show how to exploit the typically smooth dynamics of these systems and enable RL algorithms to never violate constraints during learning. Our technique is to directly add to the policy a safety layer that analytically solves an action correction formulation per each state. The novelty of obtaining an elegant closed-form solution is attained due to a linearized model, learned on past trajectories consisting of arbitrary actions. This is to mimic the real-world circumstances where data logs were generated with a behavior policy that is implausible to describe mathematically; such cases render the known safety-aware off-policy methods inapplicable. We demonstrate the efficacy of our approach on new representative physics-based environments, and prevail where reward shaping fails by maintaining zero constraint violations.",project-academic
10.1109/ICRA.2018.8460635,2018-02-23,a,,verifying controllers against adversarial examples with bayesian optimization," Recent successes in reinforcement learning have lead to the development of complex controllers for real-world robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and impose hard constraints on the system. In our framework, we exploit regularity assumptions on individual functions in form of a Gaussian Process (GP) prior. We combine these into a coherent optimization framework using problem structure. The resulting algorithm is able to provably verify complex safety specifications or alternatively find counter examples. Experimental results show that the proposed method is able to find adversarial examples quickly.",project-academic
,2020-06-05,a,,deployment efficient reinforcement learning via model based offline optimization," Most reinforcement learning (RL) algorithms assume online access to the environment, in which one may readily interleave updates to the policy with experience collection using that policy. However, in many real-world applications such as health, education, dialogue agents, and robotics, the cost or potential risk of deploying a new data-collection policy is high, to the point that it can become prohibitive to update the data-collection policy more than a few times during learning. With this view, we propose a novel concept of deployment efficiency, measuring the number of distinct data-collection policies that are used during policy learning. We observe that naively applying existing model-free offline RL algorithms recursively does not lead to a practical deployment-efficient and sample-efficient algorithm. We propose a novel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN) that can effectively optimize a policy offline using 10-20 times fewer data than prior works. Furthermore, the recursive application of BREMEN is able to achieve impressive deployment efficiency while maintaining the same or better sample efficiency, learning successful policies from scratch on simulated robotic environments with only 5-10 deployments, compared to typical values of hundreds to millions in standard RL baselines. Codes and pre-trained models are available at this https URL .",project-academic
10.1109/TASE.2017.2731371,2017-08-16,a,IEEE,toward socially aware robot navigation in dynamic and crowded environments a proactive social motion model," Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot’s inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human–object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. None Note to Practitioners —In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning None [1] None to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in None [2] None and None [3] None will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",project-academic
10.1016/J.ROBOT.2017.11.010,2018-02-01,a,North-Holland,reset free trial and error learning for robot damage recovery," Abstract None None The high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In this situation, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require the robot and the environment to be reset to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called “Reset-free Trial-and-Error” (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention.",project-academic
,2020-10-16,a,,robot navigation in constrained pedestrian environments using reinforcement learning," Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction.",project-academic
10.1109/ICRA48506.2021.9560893,2021-05-30,p,IEEE,robot navigation in constrained pedestrian environments using reinforcement learning," Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/∼cdarpino/socialnavconstrained/",project-academic
,2020-07-30,a,,mapper multi agent path planning with evolutionary reinforcement learning in mixed dynamic environments," Multi-agent navigation in dynamic environments is of great industrial value when deploying a large scale fleet of robot to real-world applications. This paper proposes a decentralized partially observable multi-agent path planning with evolutionary reinforcement learning (MAPPER) method to learn an effective local planning policy in mixed dynamic environments. Reinforcement learning-based methods usually suffer performance degradation on long-horizon tasks with goal-conditioned sparse rewards, so we decompose the long-range navigation task into many easier sub-tasks under the guidance of a global planner, which increases agents' performance in large environments. Moreover, most existing multi-agent planning approaches assume either perfect information of the surrounding environment or homogeneity of nearby dynamic agents, which may not hold in practice. Our approach models dynamic obstacles' behavior with an image-based representation and trains a policy in mixed dynamic environments without homogeneity assumption. To ensure multi-agent training stability and performance, we propose an evolutionary training approach that can be easily scaled to large and complex environments. Experiments show that MAPPER is able to achieve higher success rates and more stable performance when exposed to a large number of non-cooperative dynamic obstacles compared with traditional reaction-based planner LRA* and the state-of-the-art learning-based method.",project-academic
10.1109/IROS45743.2020.9340876,2020-10-24,p,IEEE,mapper multi agent path planning with evolutionary reinforcement learning in mixed dynamic environments," Multi-agent navigation in dynamic environments is of great industrial value when deploying a large scale fleet of robot to real-world applications. This paper proposes a decentralized partially observable multi-agent path planning with evolutionary reinforcement learning (MAPPER) method to learn an effective local planning policy in mixed dynamic environments. Reinforcement learning-based methods usually suffer performance degradation on long-horizon tasks with goal-conditioned sparse rewards, so we decompose the long-range navigation task into many easier sub-tasks under the guidance of a global planner, which increases agents’ performance in large environments. Moreover, most existing multi-agent planning approaches assume either perfect information of the surrounding environment or homogeneity of nearby dynamic agents, which may not hold in practice. Our approach models dynamic obstacles’ behavior with an image-based representation and trains a policy in mixed dynamic environments without homogeneity assumption. To ensure multi-agent training stability and performance, we propose an evolutionary training approach that can be easily scaled to large and complex environments. Experiments show that MAPPER is able to achieve higher success rates and more stable performance when exposed to a large number of non-cooperative dynamic obstacles compared with traditional reaction-based planner LRA* and the state-of-the-art learning-based method.",project-academic
,2020-12-17,a,,ving learning open world navigation with visual goals," We propose a learning-based navigation system for reaching visually indicated goals and demonstrate this system on a real mobile robot platform. Learning provides an appealing alternative to conventional methods for robotic navigation: instead of reasoning about environments in terms of geometry and maps, learning can enable a robot to learn about navigational affordances, understand what types of obstacles are traversable (e.g., tall grass) or not (e.g., walls), and generalize over patterns in the environment. However, unlike conventional planning algorithms, it is harder to change the goal for a learned policy during deployment. We propose a method for learning to navigate towards a goal image of the desired destination. By combining a learned policy with a topological graph constructed out of previously observed data, our system can determine how to reach this visually indicated goal even in the presence of variable appearance and lighting. Three key insights, waypoint proposal, graph pruning and negative mining, enable our method to learn to navigate in real-world environments using only offline data, a setting where prior methods struggle. We instantiate our method on a real outdoor ground robot and show that our system, which we call ViNG, outperforms previously-proposed methods for goal-conditioned reinforcement learning, including other methods that incorporate reinforcement learning and search. We also study how ViNG generalizes to unseen environments and evaluate its ability to adapt to such an environment with growing experience. Finally, we demonstrate ViNG on a number of real-world applications, such as last-mile delivery and warehouse inspection. We encourage the reader to check out the videos of our experiments and demonstrations at our project website this https URL",project-academic
10.1109/ICRA48506.2021.9561936,2021-05-30,p,IEEE,ving learning open world navigation with visual goals," We propose a learning-based navigation system for reaching visually indicated goals and demonstrate this system on a real mobile robot platform. Learning provides an appealing alternative to conventional methods for robotic navigation: instead of reasoning about environments in terms of geometry and maps, learning can enable a robot to learn about navigational affordances, understand what types of obstacles are traversable (e.g., tall grass) or not (e.g., walls), and generalize over patterns in the environment. However, unlike conventional planning algorithms, it is harder to change the goal for a learned policy during deployment. We propose a method for learning to navigate towards a goal image of the desired destination. By combining a learned policy with a topological graph constructed out of previously observed data, our system can determine how to reach this visually indicated goal even in the presence of variable appearance and lighting. Three key insights, waypoint proposal, graph pruning and negative mining, enable our method to learn to navigate in real-world environments using only offline data, a setting where prior methods struggle. We instantiate our method on a real outdoor ground robot and show that our system, which we call ViNG, outperforms previously-proposed methods for goal-conditioned reinforcement learning, including other methods that incorporate reinforcement learning and search. We also study how ViNG generalizes to unseen environments and evaluate its ability to adapt to such an environment with growing experience. Finally, we demonstrate ViNG on a number of real-world applications, such as last-mile delivery and warehouse inspection. We encourage the reader to visit the project website for videos of our experiments and demonstrations 1.",project-academic
,2020-07-07,a,,human trajectory forecasting in crowds a deep learning perspective," Since the past few decades, human trajectory forecasting has been a field of active research owing to its numerous real-world applications: evacuation situation analysis, traffic operations, deployment of social robots in crowded environments, to name a few. In this work, we cast the problem of human trajectory forecasting as learning a representation of human social interactions. Early works handcrafted this representation based on domain knowledge. However, social interactions in crowded environments are not only diverse but often subtle. Recently, deep learning methods have outperformed their handcrafted counterparts, as they learned about human-human interactions in a more generic data-driven fashion. In this work, we present an in-depth analysis of existing deep learning based methods for modelling social interactions. Based on our analysis, we propose a simple yet powerful method for effectively capturing these social interactions. To objectively compare the performance of these interaction-based forecasting models, we develop a large scale interaction-centric benchmark TrajNet++, a significant yet missing component in the field of human trajectory forecasting. We propose novel performance metrics that evaluate the ability of a model to output socially acceptable trajectories. Experiments on TrajNet++ validate the need for our proposed metrics, and our method outperforms competitive baselines on both real-world and synthetic datasets.",project-academic
,2016-12-01,a,,generalizing skills with semi supervised reinforcement learning," Deep reinforcement learning (RL) can acquire complex behaviors from low-level inputs, such as images. However, real-world applications of such methods require generalizing to the vast variability of the real world. Deep networks are known to achieve remarkable generalization when provided with massive amounts of labeled data, but can we provide this breadth of experience to an RL agent, such as a robot? The robot might continuously learn as it explores the world around it, even while deployed. However, this learning requires access to a reward function, which is often hard to measure in real-world domains, where the reward could depend on, for example, unknown positions of objects or the emotional state of the user. Conversely, it is often quite practical to provide the agent with reward functions in a limited set of situations, such as when a human supervisor is present or in a controlled setting. Can we make use of this limited supervision, and still benefit from the breadth of experience an agent might collect on its own? In this paper, we formalize this problem as semisupervised reinforcement learning, where the reward function can only be evaluated in a set of ""labeled"" MDPs, and the agent must generalize its behavior to the wide range of states it might encounter in a set of ""unlabeled"" MDPs, by using experience from both settings. Our proposed method infers the task objective in the unlabeled MDPs through an algorithm that resembles inverse RL, using the agent's own prior experience in the labeled MDPs as a kind of demonstration of optimal behavior. We evaluate our method on challenging tasks that require control directly from images, and show that our approach can improve the generalization of a learned deep neural network policy by using experience for which no reward function is available. We also show that our method outperforms direct supervised learning of the reward.",project-academic
10.3390/S19214794,2019-11-04,a,Multidisciplinary Digital Publishing Institute,vision based multirotor following using synthetic learning techniques," Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep- and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights).",project-academic
,2019-11-04,a,Multidisciplinary Digital Publishing Institute,vision based multirotor following using synthetic learning techniques," Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep- and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights).",project-academic
10.1109/TPAMI.2019.2899570,2020-06-01,a,IEEE,end to end active object tracking and its real world deployment via reinforcement learning," We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as input and produces the corresponding camera control signals as output (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. These methods also require significant human efforts for image labeling and expensive trial-and-error system tuning in the real world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for successful training. The tracker trained in simulators (ViZDoom and Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.",project-academic
,2018-08-10,a,,end to end active object tracking and its real world deployment via reinforcement learning," We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as input and produces the corresponding camera control signals as output (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. These methods also require significant human efforts for image labeling and expensive trial-and-error system tuning in the real world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for successful training. The tracker trained in simulators (ViZDoom and Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.",project-academic
10.1109/TTE.2020.3019009,2020-10-27,a,,learning time reduction using warm start methods for a reinforcement learning based supervisory control in hybrid electric vehicle applications," Reinforcement Learning (RL) is widely utilized in the field of robotics, and as such, it is gradually being implemented in the Hybrid Electric Vehicle (HEV) supervisory control. Even though RL exhibits excellent performance in terms of fuel consumption minimization in simulation, the large learning iteration number needs a long learning time, making it hardly applicable in real-world vehicles. In addition, the fuel consumption of initial learning phases is much worse than baseline controls. This study aims to reduce the learning iterations of Q-learning in HEV application and improve fuel consumption in initial learning phases utilizing warm start methods. Different from previous studies, which initiated Q-learning with zero or random Q values, this study initiates the Q-learning with different supervisory controls (i.e., Equivalent Consumption Minimization Strategy control and heuristic control), and detailed analysis is given. The results show that the proposed warm start Q-learning requires 68.8% fewer iterations than cold start Q-learning. The trained Q-learning is validated in two different driving cycles, and the results show 10-16% MPG improvement when compared to Equivalent Consumption Minimization Strategy control. Furthermore, real-time feasibility is analyzed, and the guidance of vehicle implementation is provided. The results of this study can be used to facilitate the deployment of RL in vehicle supervisory control applications.",project-academic
,2019-05-08,p,International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS),how you act tells a lot privacy leaking attack on deep reinforcement learning," Machine learning has been widely applied to various applications, some of which involve training with privacy-sensitive data. A modest number of data breaches have been studied, including credit card information in natural language data and identities from face dataset. However, most of these studies focus on supervised learning models. As deep reinforcement learning (DRL) has been deployed in a number of real-world systems, such as indoor robot navigation, whether trained DRL policies can leak private information requires in-depth study.To explore such privacy breaches in general, we mainly propose two methods: environment dynamics search via genetic algorithm and candidate inference based on shadow policies. We conduct extensive experiments to demonstrate such privacy vulnerabilities in DRL under various settings. We leverage the proposed algorithms to infer floor plans from some trained Grid World navigation DRL agents with LiDAR perception. The proposed algorithm can correctly infer most of the floor plans and reaches an average recovery rate of 95.83% using policy gradient trained agents. In addition, we are able to recover the robot configuration in continuous control environments and an autonomous driving simulator with high accuracy. To the best of our knowledge, this is the first work to investigate privacy leakage in DRL settings and we show that DRL-based agents do potentially leak privacy-sensitive information from the trained policies.",project-academic
,2016-04-18,a,,end to end tracking and semantic segmentation using recurrent neural networks," In this work we present a novel end-to-end framework for tracking and classifying a robot's surroundings in complex, dynamic and only partially observable real-world environments. The approach deploys a recurrent neural network to filter an input stream of raw laser measurements in order to directly infer object locations, along with their identity in both visible and occluded areas. To achieve this we first train the network using unsupervised Deep Tracking, a recently proposed theoretical framework for end-to-end space occupancy prediction. We show that by learning to track on a large amount of unsupervised data, the network creates a rich internal representation of its environment which we in turn exploit through the principle of inductive transfer of knowledge to perform the task of it's semantic classification. As a result, we show that only a small amount of labelled data suffices to steer the network towards mastering this additional task. Furthermore we propose a novel recurrent neural network architecture specifically tailored to tracking and semantic classification in real-world robotics applications. We demonstrate the tracking and classification performance of the method on real-world data collected at a busy road junction. Our evaluation shows that the proposed end-to-end framework compares favourably to a state-of-the-art, model-free tracking solution and that it outperforms a conventional one-shot training scheme for semantic classification.",project-academic
10.23919/ACC.2018.8430770,2018-06-27,p,IEEE,safe reinforcement learning learning with supervision using a constraint admissible set," Despite recent advances in Reinforcement Learning (RL), its applications in real-world engineering systems are still rare. The primary reason is that RL algorithms involve exploratory actions that can lead to system constraint violations. These violations can damage physical systems and even cause safety issues, e.g., battery overheat, robot breakdown, and car crashes, hindering RL deployment in many engineering applications. In this paper, we develop a novel safe RL framework that guarantees safety during learning by exploiting a constraint-admissible set for supervision. System knowledge and recursive feasibility techniques are exploited to construct a state-dependent constraint-admissible set. We develop a new learning scheme where the constraint-admissible set regulates the exploratory actions from the RL agent and simultaneously guides the agent to learn the system constraints with a penalty for control regulation. The proposed safe RL algorithm is demonstrated in an adaptive cruise control example where a nonlinear fuel economy cost function is optimized without violating system constraints. We demonstrate that the safe RL agent is able to learn the system constraints to gradually fade out the control supervisor.",project-academic
10.1109/ICRA40945.2020.9196785,2020-05-01,p,,learning resilient behaviors for navigation under uncertainty," Deep reinforcement learning has great potential to acquire complex, adaptive behaviors for autonomous agents automatically. However, the underlying neural network polices have not been widely deployed in real-world applications, especially in these safety-critical tasks (e.g., autonomous driving). One of the reasons is that the learned policy cannot perform flexible and resilient behaviors as traditional methods to adapt to diverse environments. In this paper, we consider the problem that a mobile robot learns adaptive and resilient behaviors for navigating in unseen uncertain environments while avoiding collisions. We present a novel approach for uncertainty-aware navigation by introducing an uncertainty-aware predictor to model the environmental uncertainty, and we propose a novel uncertainty-aware navigation network to learn resilient behaviors in the prior unknown environments. To train the proposed uncertainty-aware network more stably and efficiently, we present the temperature decay training paradigm, which balances exploration and exploitation during the training process. Our experimental evaluation demonstrates that our approach can learn resilient behaviors in diverse environments and generate adaptive trajectories according to environmental uncertainties.",project-academic
,2019-10-22,a,,learning resilient behaviors for navigation under uncertainty," Deep reinforcement learning has great potential to acquire complex, adaptive behaviors for autonomous agents automatically. However, the underlying neural network polices have not been widely deployed in real-world applications, especially in these safety-critical tasks (e.g., autonomous driving). One of the reasons is that the learned policy cannot perform flexible and resilient behaviors as traditional methods to adapt to diverse environments. In this paper, we consider the problem that a mobile robot learns adaptive and resilient behaviors for navigating in unseen uncertain environments while avoiding collisions. We present a novel approach for uncertainty-aware navigation by introducing an uncertainty-aware predictor to model the environmental uncertainty, and we propose a novel uncertainty-aware navigation network to learn resilient behaviors in the prior unknown environments. To train the proposed uncertainty-aware network more stably and efficiently, we present the temperature decay training paradigm, which balances exploration and exploitation during the training process. Our experimental evaluation demonstrates that our approach can learn resilient behaviors in diverse environments and generate adaptive trajectories according to environmental uncertainties.",project-academic
,2020-03-10,a,,squirl robust and efficient learning from video demonstration of long horizon robotic manipulation tasks," Recent advances in deep reinforcement learning (RL) have demonstrated its potential to learn complex robotic manipulation tasks. However, RL still requires the robot to collect a large amount of real-world experience. To address this problem, recent works have proposed learning from expert demonstrations (LfD), particularly via inverse reinforcement learning (IRL), given its ability to achieve robust performance with only a small number of expert demonstrations. Nevertheless, deploying IRL on real robots is still challenging due to the large number of robot experiences it requires. This paper aims to address this scalability challenge with a robust, sample-efficient, and general meta-IRL algorithm, SQUIRL, that performs a new but related long-horizon task robustly given only a single video demonstration. First, this algorithm bootstraps the learning of a task encoder and a task-conditioned policy using behavioral cloning (BC). It then collects real-robot experiences and bypasses reward learning by directly recovering a Q-function from the combined robot and expert trajectories. Next, this algorithm uses the Q-function to re-evaluate all cumulative experiences collected by the robot to improve the policy quickly. In the end, the policy performs more robustly (90%+ success) than BC on new tasks while requiring no trial-and-errors at test time. Finally, our real-robot and simulated experiments demonstrate our algorithm's generality across different state spaces, action spaces, and vision-based manipulation tasks, e.g., pick-pour-place and pick-carry-drop.",project-academic
10.1109/IROS45743.2020.9340915,2020-10-24,p,IEEE,squirl robust and efficient learning from video demonstration of long horizon robotic manipulation tasks," Recent advances in deep reinforcement learning (RL) have demonstrated its potential to learn complex robotic manipulation tasks. However, RL still requires the robot to collect a large amount of real-world experience. To address this problem, recent works have proposed learning from expert demonstrations (LfD), particularly via inverse reinforcement learning (IRL), given its ability to achieve robust performance with only a small number of expert demonstrations. Nevertheless, deploying IRL on real robots is still challenging due to the large number of robot experiences it requires. This paper aims to address this scalability challenge with a robust, sample-efficient, and general meta-IRL algorithm, SQUIRL, that performs a new but related long-horizon task robustly given only a single video demonstration. First, this algorithm bootstraps the learning of a task encoder and a task-conditioned policy using behavioral cloning (BC). It then collects real-robot experiences and bypasses reward learning by directly recovering a Q-function from the combined robot and expert trajectories. Next, this algorithm uses the learned Q-function to re-evaluate all cumulative experiences collected by the robot to improve the policy quickly. In the end, the policy performs more robustly (90%+ success) than BC on new tasks while requiring no experiences at test time. Finally, our real-robot and simulated experiments demonstrate our algorithm’s generality across different state spaces, action spaces, and vision-based manipulation tasks, e.g., pick-pour-place and pick-carry-drop.",project-academic
10.1007/978-3-642-39250-4_15,2012-06-18,p,"Springer, Berlin, Heidelberg",people detection in 3d point clouds using local surface normals," The ability to detect people in domestic and unconstrained environments is crucial for every service robot. The knowledge where people are is required to perform several tasks such as navigation with dynamic obstacle avoidance and human-robot-interaction. In this paper we propose a people detection approach based on 3d data provided by a RGB-D camera. We introduce a novel 3d feature descriptor based on Local Surface Normals (LSN) which is used to learn a classifier in a supervised machine learning manner. In order to increase the systems flexibility and to detect people even under partial occlusion we introduce a top-down/bottom-up segmentation. We deployed the people detection system on a real-world service robot operating at a reasonable frame rate of 5Hz. The experimental results show that our approach is able to detect persons in various poses and motions such as sitting, walking, and running.",project-academic
10.1109/IROS.2016.7759720,2016-10-01,p,IEEE,object identification from few examples by improving the invariance of a deep convolutional neural network," The development of reliable and robust visual recognition systems is a main challenge towards the deployment of autonomous robotic agents in unconstrained environments. Learning to recognize objects requires image representations that are discriminative to relevant information while being invariant to nuisances, such as scaling, rotations, light and background changes, and so forth. Deep Convolutional Neural Networks can learn such representations from large web-collected image datasets and a natural question is how these systems can be best adapted to the robotics context where little supervision is often available. In this work, we investigate different training strategies for deep architectures on a new dataset collected in a real-world robotic setting. In particular we show how deep networks can be tuned to improve invariance and discriminability properties and perform object identification tasks with minimal supervision.",project-academic
,2020-11-09,a,,bimanual regrasping for suture needles using reinforcement learning for rapid motion planning," Regrasping a suture needle is an important yet time-consuming process in suturing. To bring efficiency into regrasping, prior work either designs a task-specific mechanism or guides the gripper toward some specific pick-up point for proper grasping of a needle. Yet, these methods are usually not deployable when the working space is changed. Therefore, in this work, we present rapid trajectory generation for bimanual needle regrasping via reinforcement learning (RL). Demonstrations from a sampling-based motion planning algorithm is incorporated to speed up the learning. In addition, we propose the ego-centric state and action spaces for this bimanual planning problem, where the reference frames are on the end-effectors instead of some fixed frame. Thus, the learned policy can be directly applied to any feasible robot configuration. Our experiments in simulation show that the success rate of a single pass is 97%, and the planning time is 0.0212s on average, which outperforms other widely used motion planning algorithms. For the real-world experiments, the success rate is 73.3% if the needle pose is reconstructed from an RGB image, with a planning time of 0.0846s and a run time of 5.1454s. If the needle pose is known beforehand, the success rate becomes 90.5%, with a planning time of 0.0807s and a run time of 2.8801s.",project-academic
10.1109/ICRA48506.2021.9561673,2021-05-30,p,IEEE,bimanual regrasping for suture needles using reinforcement learning for rapid motion planning," Regrasping a suture needle is an important yet time-consuming process in suturing. To bring efficiency into regrasping, prior work either designs a task-specific mechanism or guides the gripper toward some specific pick-up point for proper grasping of a needle. Yet, these methods are usually not deployable when the working space is changed. Therefore, in this work, we present rapid trajectory generation for bimanual needle regrasping via reinforcement learning (RL). Demonstrations from a sampling-based motion planning algorithm is incorporated to speed up the learning. In addition, we propose the ego-centric state and action spaces for this bimanual planning problem, where the reference frames are on the end-effectors instead of some fixed frame. Thus, the learned policy can be directly applied to any feasible robot configuration. Our experiments in simulation show that the success rate of a single pass is 97%, and the planning time is 0.0212s on average, which outperforms other widely used motion planning algorithms. For the real-world experiments, the success rate is 73.3% if the needle pose is reconstructed from an RGB image, with a planning time of 0.0846s and a run time of 5.1454s. If the needle pose is known beforehand, the success rate becomes 90.5%, with a planning time of 0.0807s and a run time of 2.8801s.",project-academic
,2019-04-24,a,,how you act tells a lot privacy leakage attack on deep reinforcement learning," Machine learning has been widely applied to various applications, some of which involve training with privacy-sensitive data. A modest number of data breaches have been studied, including credit card information in natural language data and identities from face dataset. However, most of these studies focus on supervised learning models. As deep reinforcement learning (DRL) has been deployed in a number of real-world systems, such as indoor robot navigation, whether trained DRL policies can leak private information requires in-depth study. To explore such privacy breaches in general, we mainly propose two methods: environment dynamics search via genetic algorithm and candidate inference based on shadow policies. We conduct extensive experiments to demonstrate such privacy vulnerabilities in DRL under various settings. We leverage the proposed algorithms to infer floor plans from some trained Grid World navigation DRL agents with LiDAR perception. The proposed algorithm can correctly infer most of the floor plans and reaches an average recovery rate of 95.83% using policy gradient trained agents. In addition, we are able to recover the robot configuration in continuous control environments and an autonomous driving simulator with high accuracy. To the best of our knowledge, this is the first work to investigate privacy leakage in DRL settings and we show that DRL-based agents do potentially leak privacy-sensitive information from the trained policies.",project-academic
,2018-08-11,a,,fully distributed multi robot collision avoidance via deep reinforcement learning for safe and efficient navigation in complex scenarios," In this paper, we present a decentralized sensor-level collision avoidance policy for multi-robot systems, which shows promising results in practical applications. In particular, our policy directly maps raw sensor measurements to an agent's steering commands in terms of the movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal policy. The policy is trained over a large number of robots in rich, complex environments simultaneously using a policy gradient based reinforcement learning algorithm. The learning algorithm is also integrated into a hybrid control framework to further improve the policy's robustness and effectiveness. 
We validate the learned sensor-level collision avoidance policy in a variety of simulated and real-world scenarios with thorough performance evaluations for large-scale multi-robot systems. The generalization of the learned policy is verified in a set of unseen scenarios including the navigation of a group of heterogeneous robots and a large-scale scenario with 100 robots. Although the policy is trained using simulation data only, we have successfully deployed it on physical robots with shapes and dynamics characteristics that are different from the simulated agents, in order to demonstrate the controller's robustness against the sim-to-real modeling error. Finally, we show that the collision-avoidance policy learned from multi-robot navigation tasks provides an excellent solution to the safe and effective autonomous navigation for a single robot working in a dense real human crowd. Our learned policy enables a robot to make effective progress in a crowd without getting stuck. Videos are available at this https URL",project-academic
10.24963/IJCAI.2018/451,2018-01-01,p,International Joint Conferences on Artificial Intelligence,fast model identification via physics engines for data efficient policy search," This paper presents a method for identifying mechanical parameters of robots or objects, such as their mass and friction coefficients. Key features are the use of off-the-shelf physics engines and the adaptation of a Bayesian optimization technique towards minimizing the number of real-world experiments needed for model-based reinforcement learning. The proposed framework reproduces in a physics engine experiments performed on a real robot and optimizes the model's mechanical parameters so as to match real-world trajectories. The optimized model is then used for learning a policy in simulation, before real-world deployment. It is well understood, however, that it is hard to exactly reproduce real trajectories in simulation. Moreover, a near-optimal policy can be frequently found with an imperfect model. Therefore, this work proposes a strategy for identifying a model that is just good enough to approximate the value of a locally optimal policy with a certain confidence, instead of wasting effort on identifying the most accurate model. Evaluations, performed both in simulation and on a real robotic manipulation task, indicate that the proposed strategy results in an overall time-efficient, integrated model identification and learning solution, which significantly improves the data-efficiency of existing policy search algorithms.",project-academic
,2017-10-24,a,,fast model identification via physics engines for data efficient policy search," This paper presents a method for identifying mechanical parameters of robots or objects, such as their mass and friction coefficients. Key features are the use of off-the-shelf physics engines and the adaptation of a Bayesian optimization technique towards minimizing the number of real-world experiments needed for model-based reinforcement learning. The proposed framework reproduces in a physics engine experiments performed on a real robot and optimizes the model's mechanical parameters so as to match real-world trajectories. The optimized model is then used for learning a policy in simulation, before real-world deployment. It is well understood, however, that it is hard to exactly reproduce real trajectories in simulation. Moreover, a near-optimal policy can be frequently found with an imperfect model. Therefore, this work proposes a strategy for identifying a model that is just good enough to approximate the value of a locally optimal policy with a certain confidence, instead of wasting effort on identifying the most accurate model. Evaluations, performed both in simulation and on a real robotic manipulation task, indicate that the proposed strategy results in an overall time-efficient, integrated model identification and learning solution, which significantly improves the data-efficiency of existing policy search algorithms.",project-academic
,2019-12-31,a,,information theoretic model predictive q learning," Model-free Reinforcement Learning (RL) works well when experience can be collected cheaply and model-based RL is effective when system dynamics can be modeled accurately. However, both assumptions can be violated in real world problems such as robotics, where querying the system can be expensive and real-world dynamics can be difficult to model. In contrast to RL, Model Predictive Control (MPC) algorithms use a simulator to optimize a simple policy class online, constructing a closed-loop controller that can effectively contend with real-world dynamics. MPC performance is usually limited by factors such as model bias and the limited horizon of optimization. In this work, we present a novel theoretical connection between information theoretic MPC and entropy regularized RL and develop a Q-learning algorithm that can leverage biased models. We validate the proposed algorithm on sim-to-sim control tasks to demonstrate the improvements over optimal control and reinforcement learning from scratch. Our approach paves the way for deploying reinforcement learning algorithms on real systems in a systematic manner.",project-academic
,2018-10-16,a,,composable action conditioned predictors flexible off policy learning for robot navigation," A general-purpose intelligent robot must be able to learn autonomously and be able to accomplish multiple tasks in order to be deployed in the real world. However, standard reinforcement learning approaches learn separate task-specific policies and assume the reward function for each task is known a priori. We propose a framework that learns event cues from off-policy data, and can flexibly combine these event cues at test time to accomplish different tasks. These event cue labels are not assumed to be known a priori, but are instead labeled using learned models, such as computer vision detectors, and then `backed up' in time using an action-conditioned predictive model. We show that a simulated robotic car and a real-world RC car can gather data and train fully autonomously without any human-provided labels beyond those needed to train the detectors, and then at test-time be able to accomplish a variety of different tasks. Videos of the experiments and code can be found at this https URL",project-academic
10.1109/HPCC/SMARTCITY/DSS.2019.00339,2019-08-01,p,IEEE,machine learning based cloudbot detection using multi layer traffic statistics," With the rapid development of e-commerce services and online transactions, an increasing number of advanced web robots are utilized by speculators and hackers in underground economy to perform click fraud, register fake accounts and commit other kinds of frauds, seriously harming the profit of businesses and the fairness of online activities. There is solid evidence that the vast majority of such malicious bot traffic comes from data centers. The malicious bot deployed on the hosts of data centers is referred to as a CloudBot. How to detect and block CloudBots effectively has become an urgent problem in practice, while the research on it can be seldom seen in public. To this end, we propose a traffic-based quasi-real-time method for CloudBot detection using machine learning, which exploits a new sample partitioning approach, as well as innovative multi-layer features that reveal the essential difference between CloudBots and human traffic. Our method achieves 93.4% precision in the experiment and performs well on the real-world dataset, which proves to be effective to detect unknown CloudBots and combat the concept drift caused by varying time. Besides, the approach is also privacy-preserving without using any specific application layer information. We believe our work can benefit network economy security and fairness in practice.",project-academic
10.1109/LRA.2020.2967296,2020-01-17,p,IEEE,aerial single view depth completion with image guided uncertainty estimation," On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.",project-academic
10.1109/TRO.2012.2228134,2013-04-01,a,IEEE,the impact of human robot interfaces on the learning of visual objects," This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human–robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user’s experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user’s experience, than teaching thanks to a gesture-based human-like interaction.",project-academic
10.1016/J.JSTROKECEREBROVASDIS.2021.105826,2021-04-28,a,W.B. Saunders,automatic acute stroke symptom detection and emergency medical systems alerting by mobile health technologies a review," Abstract None None Objectives None To survey recent advances in acute stroke symptom automatic detection and Emergency Medical Systems (EMS) alerting by mobile health technologies. None None None Materials and methods None Narrative review None None None Results None Delayed activation of EMS for stroke symptoms by patients and witnesses deprives patients of rapid access to brain-saving therapies and occurs due to public unawareness of stroke features, cognitive and motor deficits produced by the stroke itself, and sleep onset. A promising emerging approach to overcoming the inherent biologic constraints of patient capacity to self-detect and respond to stroke symptoms is continuous monitoring by mobile health technologies with wireless sensors and artificial intelligence recognition systems. This review surveys 11 sensing technologies - accelerometers, gyroscopes, magnetometers, pressure sensors, touch screen and keyboard input detectors, artificial vision, and artificial hearing; and 10 consumer device form factors in which they are increasingly implemented: smartphones, smart speakers, smart watches and fitness bands, smart speakers/voice assistants, home health robots, smart clothing, smart beds, closed circuit television, smart rings, and desktop/laptop/tablet computers. None None None Conclusions None The increase in computing power, wearable sensors, and mobile connectivity have ushered in an array of mobile health technologies that can transform stroke detection and EMS activation. By continuously monitoring a diverse range of biometric parameters, commercially available devices provide the technologic capability to detect cardinal language, motor, gait, and sensory signs of stroke onset. Intensified translational research to convert the promise of these technologies to validated, accurate real-world deployments are an important next priority for stroke investigation.",project-academic
,2018-02-01,a,,vr goggles for robots real to sim domain adaptation for visual control," In this paper, we deal with the reality gap from a novel perspective, targeting transferring Deep Reinforcement Learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as 1) no extra transfer steps are required during the expensive training of DRL agents in simulation; 2) the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; 3) the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",project-academic
10.5555/2936924.2937077,2016-05-09,p,International Foundation for Autonomous Agents and Multiagent Systems,unsupervised learning of qualitative motion behaviours by a mobile robot," The success of mobile robots, in daily living environments, depends on their capabilities to understand human movements and interact in a safe manner. This paper presents a novel unsupervised qualitative-relational framework for learning human motion patterns using a single mobile robot platform. It is capable of learning human motion patterns in real-world environments, in order to predict future behaviours.This previously untackled task is challenging because of the limited field of view provided by a single mobile robot. It is only able to observe one location at any time, resulting in incomplete and partial human detections and trajectories. Central to the success of the presented framework is mapping the detections into an abstract qualitative space, and then characterising motion invariant to exact metric position.This framework was used by a physical robot autonomously patrolling a company's office during a six week deployment. Experimental results from this deployment are discussed and demonstrate the effectiveness and applicability of the system.",project-academic
10.1109/LRA.2021.3062303,2020-11-24,a,,bi directional domain adaptation for sim2real transfer of embodied navigation agents," Deep reinforcement learning models are notoriously data hungry, yet real-world data is expensive and time consuming to obtain. The solution that many have turned to is to use simulation for training before deploying the robot in a real environment. Simulation offers the ability to train large numbers of robots in parallel, and offers an abundance of data. However, no simulation is perfect, and robots trained solely in simulation fail to generalize to the real-world, resulting in a ""sim-vs-real gap"". How can we overcome the trade-off between the abundance of less accurate, artificial data from simulators and the scarcity of reliable, real-world data? In this paper, we propose Bi-directional Domain Adaptation (BDA), a novel approach to bridge the sim-vs-real gap in both directions -- real2sim to bridge the visual domain gap, and sim2real to bridge the dynamics domain gap. We demonstrate the benefits of BDA on the task of PointGoal Navigation. BDA with only 5k real-world (state, action, next-state) samples matches the performance of a policy fine-tuned with ~600k samples, resulting in a speed-up of ~120x.",project-academic
10.1109/IROS45743.2020.9340948,2020-10-24,p,IEEE,reinforcement co learning of deep and spiking neural networks for energy efficient mapless navigation with neuromorphic hardware," Energy-efficient mapless navigation is crucial for mobile robots as they explore unknown environments with limited on-board resources. Although the recent deep rein-forcement learning (DRL) approaches have been successfully applied to navigation, their high energy consumption limits their use in several robotic applications. Here, we propose a neuromorphic approach that combines the energy-efficiency of spiking neural networks with the optimality of DRL and benchmark it in learning control policies for mapless navigation. Our hybrid framework, spiking deep deterministic policy gradient (SDDPG), consists of a spiking actor network (SAN) and a deep critic network, where the two networks were trained jointly using gradient descent. The co-learning enabled synergistic information exchange between the two networks, allowing them to overcome each other’s limitations through a shared representation learning. To evaluate our approach, we deployed the trained SAN on Intel’s Loihi neuromorphic processor. When validated on simulated and real-world complex environments, our method on Loihi consumed 75 times less energy per inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate of successful navigation to the goal, which ranged from 1% to 4.2% and depended on the forward-propagation timestep size. These results reinforce our ongoing efforts to design brain-inspired algorithms for controlling autonomous robots with neuromorphic hardware.",project-academic
,2020-03-02,a,,reinforcement co learning of deep and spiking neural networks for energy efficient mapless navigation with neuromorphic hardware," Energy-efficient mapless navigation is crucial for mobile robots as they explore unknown environments with limited on-board resources. Although the recent deep reinforcement learning (DRL) approaches have been successfully applied to navigation, their high energy consumption limits their use in several robotic applications. Here, we propose a neuromorphic approach that combines the energy-efficiency of spiking neural networks with the optimality of DRL and benchmark it in learning control policies for mapless navigation. Our hybrid framework, spiking deep deterministic policy gradient (SDDPG), consists of a spiking actor network (SAN) and a deep critic network, where the two networks were trained jointly using gradient descent. The co-learning enabled synergistic information exchange between the two networks, allowing them to overcome each other's limitations through a shared representation learning. To evaluate our approach, we deployed the trained SAN on Intel's Loihi neuromorphic processor. When validated on simulated and real-world complex environments, our method on Loihi consumed 75 times less energy per inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate of successful navigation to the goal, which ranged from 1% to 4.2% and depended on the forward-propagation timestep size. These results reinforce our ongoing efforts to design brain-inspired algorithms for controlling autonomous robots with neuromorphic hardware.",project-academic
10.1109/ICCE.2018.8326229,2018-01-01,p,IEEE,end to end deep learning for autonomous navigation of mobile robot," This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",project-academic
10.1557/S43577-021-00122-3,2021-06-17,a,Springer International Publishing,engineered neuromuscular actuators for medicine meat and machines," Movement is central to life. Neuromuscular tissues control voluntary movement in humans and many other living creatures, offering significant advantages in adaptability and robustness as compared to abiotic actuators. The impressive functional capabilities of neuromuscular tissues have inspired researchers to attempt de novo synthesis of the biological motor system via tissue engineering. This article highlights key recent advances in tissue engineering skeletal muscle and discusses promising strategies to control engineered muscle via biological neural networks and abiotic soft electronic interfaces. Challenges associated with cell sourcing, biomaterials design, and scalable precision manufacturing, along with emerging strategies to address those challenges, are presented. Finally, we highlight how engineered neuromuscular tissues have enabled studying, controlling, and deploying them as actuators in a range of real-world applications including drug discovery, regenerative medicine, cellular agriculture, and soft robotics.",project-academic
10.3390/S18113650,2018-10-27,a,Multidisciplinary Digital Publishing Institute,learn to steer through deep reinforcement learning," It is crucial for robots to autonomously steer in complex environments safely without colliding with any obstacles. Compared to conventional methods, deep reinforcement learning-based methods are able to learn from past experiences automatically and enhance the generalization capability to cope with unseen circumstances. Therefore, we propose an end-to-end deep reinforcement learning algorithm in this paper to improve the performance of autonomous steering in complex environments. By embedding a branching noisy dueling architecture, the proposed model is capable of deriving steering commands directly from raw depth images with high efficiency. Specifically, our learning-based approach extracts the feature representation from depth inputs through convolutional neural networks and maps it to both linear and angular velocity commands simultaneously through different streams of the network. Moreover, the training framework is also meticulously designed to improve the learning efficiency and effectiveness. It is worth noting that the developed system is readily transferable from virtual training scenarios to real-world deployment without any fine-tuning by utilizing depth images. The proposed method is evaluated and compared with a series of baseline methods in various virtual environments. Experimental results demonstrate the superiority of the proposed model in terms of average reward, learning efficiency, success rate as well as computational time. Moreover, a variety of real-world experiments are also conducted which reveal the high adaptability of our model to both static and dynamic obstacle-cluttered environments.",project-academic
10.1109/TVT.2019.2952926,2020-01-01,a,IEEE,mechanism design for wireless powered spatial crowdsourcing networks," Wireless power transfer (WPT) is a promising technology to prolong the lifetime of the sensors and communication devices, i.e., workers, in completing crowdsourcing tasks by providing continuous and cost-effective energy supplies. In this paper, we propose a wireless powered spatial crowdsourcing framework which consists of two mutually dependent phases: task allocation phase and data crowdsourcing phase. In the task allocation phase, we propose a Stackelberg game based mechanism for the spatial crowdsourcing platform to efficiently allocate spatial tasks and wireless charging power to each worker. In the data crowdsourcing phase, the workers may have an incentive to misreport its real working location to improve its utility, which causes adverse effects to the spatial crowdsourcing platform. To address this issue, we present three strategyproof deployment mechanisms for the spatial crowdsourcing platform to place a mobile base station, e.g., vehicle or robot, which is responsible for transferring the wireless power and collecting the crowdsourced data. As the benchmark, we first apply the classical median mechanism and evaluate its worst-case performance. Then, we design a conventional strategyproof deployment mechanism to improve the expected utility of the spatial crowdsourcing platform under the condition that the workers’ locations follow a known geographical distribution. For a more general case with only the historical location data available, we propose a deep learning based strategyproof deployment mechanism to maximize the spatial crowdsourcing platform's utility. Extensive experimental results based on synthetic and real-world datasets reveal the effectiveness of the proposed framework in allocating tasks and charging power to workers while avoiding the dishonest worker's manipulation.",project-academic
,2020-02-11,a,,robot navigation with map based deep reinforcement learning," This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and real-world robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing DRL-based models in many indicators.",project-academic
10.1109/ICNSC48988.2020.9238090,2020-10-30,p,IEEE,robot navigation with map based deep reinforcement learning," This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and realworld robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing DRL-based models in many indicators.",project-academic
,2021-08-13,a,,safe learning in robotics from learning based control to safe reinforcement learning," The last half-decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. Our review includes: learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximity to humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches.",project-academic
10.1016/J.NEUNET.2021.07.021,2021-11-01,a,Pergamon,continual learning for recurrent neural networks an empirical evaluation," Abstract None None Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning (CL) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on CL for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for CL with sequential data based on existing datasets, whose characteristics resemble real-world applications. None We also provide a broad empirical evaluation of CL and Recurrent Neural Networks in class-incremental scenario, by testing their ability to mitigate forgetting with a number of different strategies which are not specific to sequential data processing. Our results highlight the key role played by the sequence length and the importance of a clear specification of the CL scenario.",project-academic
10.1016/J.ACTAASTRO.2017.07.038,2017-11-01,a,Pergamon,self supervised learning as an enabling technology for future space exploration robots iss experiments on monocular distance learning," Abstract None None Although machine learning holds an enormous promise for autonomous space robots, it is currently not employed because of the inherent uncertain outcome of learning processes. In this article we investigate a learning mechanism, Self-Supervised Learning (SSL), which is very reliable and hence an important candidate for real-world deployment even on safety-critical systems such as space robots. To demonstrate this reliability, we introduce a novel SSL setup that allows a stereo vision equipped robot to cope with the failure of one of its cameras. The setup learns to estimate average depth using a monocular image, by using the stereo vision depths from the past as trusted ground truth. We present preliminary results from an experiment on the International Space Station (ISS) performed with the MIT/NASA SPHERES VERTIGO satellite. The presented experiments were performed on October 8th, 2015 on board the ISS. The main goals were (1) data gathering, and (2) navigation based on stereo vision. First the astronaut Kimiya Yui moved the satellite around the Japanese Experiment Module to gather stereo vision data for learning. Subsequently, the satellite freely explored the space in the module based on its (trusted) stereo vision system and a pre-programmed exploration behavior, while simultaneously performing the self-supervised learning of monocular depth estimation on board. The two main goals were successfully achieved, representing the first online learning robotic experiments in space. These results lay the groundwork for a follow-up experiment in which the satellite will use the learned single-camera depth estimation for autonomous exploration in the ISS, and are an advancement towards future space robots that continuously improve their navigation capabilities over time, even in harsh and completely unknown space environments.",project-academic
,2021-08-08,a,,towards real world navigation with deep differentiable planners," We train embodied neural networks to plan and navigate unseen complex 3D environments, emphasising real-world deployment. Rather than requiring prior knowledge of the agent or environment, the planner learns to model the state transitions and rewards. To avoid the potentially hazardous trial-and-error of reinforcement learning, we focus on differentiable planners such as Value Iteration Networks (VIN), which are trained offline from safe expert demonstrations. Although they work well in small simulations, we address two major limitations that hinder their deployment. First, we observed that current differentiable planners struggle to plan long-term in environments with a high branching complexity. While they should ideally learn to assign low rewards to obstacles to avoid collisions, we posit that the constraints imposed on the network are not strong enough to guarantee the network to learn sufficiently large penalties for every possible collision. We thus impose a structural constraint on the value iteration, which explicitly learns to model any impossible actions. Secondly, we extend the model to work with a limited perspective camera under translation and rotation, which is crucial for real robot deployment. Many VIN-like planners assume a 360 degrees or overhead view without rotation. In contrast, our method uses a memory-efficient lattice map to aggregate CNN embeddings of partial observations, and models the rotational dynamics explicitly using a 3D state-space grid (translation and rotation). Our proposals significantly improve semantic navigation and exploration on several 2D and 3D environments, succeeding in settings that are otherwise challenging for this class of methods. As far as we know, we are the first to successfully perform differentiable planning on the difficult Active Vision Dataset, consisting of real images captured from a robot.",project-academic
,2021-11-02,a,,a framework for real world multi robot systems running decentralized gnn based policies," Graph Neural Networks (GNNs) are a paradigm-shifting neural architecture to
facilitate the learning of complex multi-agent behaviors. Recent work has
demonstrated remarkable performance in tasks such as flocking, multi-agent path
planning and cooperative coverage. However, the policies derived through
GNN-based learning schemes have not yet been deployed to the real-world on
physical multi-robot systems. In this work, we present the design of a system
that allows for fully decentralized execution of GNN-based policies. We create
a framework based on ROS2 and elaborate its details in this paper. We
demonstrate our framework on a case-study that requires tight coordination
between robots, and present first-of-a-kind results that show successful
real-world deployment of GNN-based policies on a decentralized multi-robot
system relying on Adhoc communication. A video demonstration of this case-study
can be found online. https://www.youtube.com/watch?v=COh-WLn4iO4",project-academic
10.1016/J.NEUNET.2009.01.013,2009-03-01,a,Neural Netw,2009 special issue robotic sound source localisation architecture using cross correlation and recurrent neural networks," In this paper we present a sound-source model for localising and tracking an acoustic source of interest along the azimuth plane in acoustically cluttered environments, for a mobile service robot. The model we present is a hybrid architecture using cross-correlation and recurrent neural networks to develop a robotic model accurate and robust enough to perform within an acoustically cluttered environment. This model has been developed with considerations of both processing power and physical robot size, allowing for this model to be deployed on to a wide variety of robotic systems where power consumption and size is a limitation. The development of the system we present has its inspiration taken from the central auditory system (CAS) of the mammalian brain. In this paper we describe experimental results of the proposed model including the experimental methodology for testing sound-source localisation systems. The results of the system are shown in both restricted test environments and in real-world conditions. This paper shows how a hybrid architecture using band pass filtering, cross-correlation and recurrent neural networks can be used to develop a robust, accurate and fast sound-source localisation model for a mobile robot.",project-academic
,2021-09-13,a,,safe control gym a unified benchmark suite for safe learning based control and reinforcement learning," In recent years, reinforcement learning and learning-based control -- as well as the study of their safety, crucial for deployment in real-world robots -- have gained significant traction. However, to adequately gauge the progress and applicability of new results, we need the tools to equitably compare the approaches proposed by the controls and reinforcement learning communities. Here, we propose a new open-source benchmark suite, called safe-control-gym. Our starting point is OpenAI's Gym API, which is one of the de facto standard in reinforcement learning research. Yet, we highlight the reasons for its limited appeal to control theory researchers -- and safe control, in particular. E.g., the lack of analytical models and constraint specifications. Thus, we propose to extend this API with (i) the ability to specify (and query) symbolic models and constraints and (ii) introduce simulated disturbances in the control inputs, measurements, and inertial properties. We provide implementations for three dynamic systems -- the cart-pole, 1D, and 2D quadrotor -- and two control tasks -- stabilization and trajectory tracking. To demonstrate our proposal -- and in an attempt to bring research communities closer together -- we show how to use safe-control-gym to quantitatively compare the control performance, data efficiency, and safety of multiple approaches from the areas of traditional control, learning-based control, and reinforcement learning.",project-academic
10.1007/978-3-030-20131-9_213,2019-07-15,a,"Springer, Cham",a practical obstacle avoidance method using q learning with local information," Various methods have been proposed for solving the obstacle avoidance problem. However, many of them are based on information that might not be available for robots in real-world settings. We focus on the generalizability and the practical aspects of the problem instead of studying yet another obstacle avoidance method. We propose a simple but robust method based on reinforcement learning for obstacle avoidance using only local information that could be gathered by the sensors on the robot. We train the model with simple and random cases having only static obstacles in a simulated environment and deploy the trained model to an actual robot car. The robot successfully avoided the static and, surprisingly, dynamic obstacles and eventually reached the target.",project-academic
10.1109/ICRA.2019.8793556,2019-05-20,p,IEEE,vpe variational policy embedding for transfer reinforcement learning," Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.",project-academic
10.3390/S19030685,2019-02-07,a,MDPI,towards gas discrimination and mapping in emergency response scenarios using a mobile robot with an electronic nose," Emergency personnel, such as firefighters, bomb technicians, and urban search and rescue specialists, can be exposed to a variety of extreme hazards during the response to natural and human-made disasters. In many of these scenarios, a risk factor is the presence of hazardous airborne chemicals. The recent and rapid advances in robotics and sensor technologies allow emergency responders to deal with such hazards from relatively safe distances. Mobile robots with gas-sensing capabilities allow to convey useful information such as the possible source positions of different chemicals in the emergency area. However, common gas sampling procedures for laboratory use are not applicable due to the complexity of the environment and the need for fast deployment and analysis. In addition, conventional gas identification approaches, based on supervised learning, cannot handle situations when the number and identities of the present chemicals are unknown. For the purpose of emergency response, all the information concluded from the gas detection events during the robot exploration should be delivered in real time. To address these challenges, we developed an online gas-sensing system using an electronic nose. Our system can automatically perform unsupervised learning and update the discrimination model as the robot is exploring a given environment. The online gas discrimination results are further integrated with geometrical information to derive a multi-compound gas spatial distribution map. The proposed system is deployed on a robot built to operate in harsh environments for supporting fire brigades, and is validated in several different real-world experiments of discriminating and mapping multiple chemical compounds in an indoor open environment. Our results show that the proposed system achieves high accuracy in gas discrimination in an online, unsupervised, and computationally efficient manner. The subsequently created gas distribution maps accurately indicate the presence of different chemicals in the environment, which is of practical significance for emergency response.",project-academic
10.1007/978-3-030-75472-3_5,2021-01-01,a,"Springer, Cham",autonomous navigation with mobile robots using deep learning and the robot operating system," Autonomous navigation is a long-standing field of robotics research, which provides an essential capability for mobile robots to execute a series of tasks on the same environments performed by human everyday. In this chapter, we present a set of algorithms to train and deploy deep networks for autonomous navigation of mobile robots using the Robot Operation System (ROS). We describe three main steps to tackle this problem: (i) collecting data in simulation environments using ROS and Gazebo; (ii) designing deep network for autonomous navigation, and (iii) deploying the learned policy on mobile robots in both simulation and real-world. Theoretically, we present deep learning architectures for robust navigation in normal environments (e.g., man-made houses, roads) and complex environments (e.g., collapsed cities, or natural caves). We further show that the use of visual modalities such as RGB, Lidar, and point cloud is essential to improve the autonomy of mobile robots. Our project website and demonstration video can be found at https://sites.google.com/site/autonomousnavigationros.",project-academic
10.1109/TPDS.2020.3006238,2020-12-01,a,IEEE,gpu accelerated real time stereo estimation with binary neural network," Depth estimation from stereo images is essential to many applications such as robotics and autonomous vehicles, most of which ask for the real-time response, high energy and storage efficiency. Recent work has shown deep neural networks (DNN) perform extremely well for stereo estimation. However, these state-of-the-art DNN based algorithms are challenging to be deployed into real-world applications due to the high computational complexities of DNNs. Most of them are too slow for real-time inference and require several seconds of GPU computation to process image frames. In this article, we address the problem of fast stereo estimation and propose an efficient and light-weighted stereo matching system, called StereoBit, to produce a disparity map in a real-time manner while achieving close to state-of-the-art accuracy. To achieve this goal, we propose a binary neural network to generate weighted Hamming distance for an efficient similarity join in stereo estimation. In addition, we propose a novel approximation approach to derive StereoBit network directly from the well-trained network with the cosine similarity. Our approximation strategies enable a significant speedup while maintaining almost the same accuracy compared to the network with the cosine similarity. Furthermore, we present an optimization framework for fully exploiting the computing power of StereoBit. The framework provides a significant speedup of stereo estimation routines, and at the same time, reduces the memory usage for storing parameters. The effectiveness of StereoBit is evaluated by comprehensive experiments. StereoBit can achieve 60 frames per second on an NVIDIA TITAN Xp GPU on KITTI 2012 benchmark while achieving 3-pixel non-occluded stereo error 3.56 percent.",project-academic
10.1145/1071620.1071623,2004-06-01,a,ACM,an interdisciplinary field robotics program for undergraduate computer science and engineering education," Santa Clara University's Robotic Systems Laboratory conducts an aggressive robotic development and operations program in which interdisciplinary teams of undergraduate students build and deploy a wide range of robotic systems, ranging from underwater vehicles to spacecraft. These year-long projects expose students to the breadth of and interdependence among engineering disciplines, the span of processes in a system development lifecycle, and the challenges of managing a development process. Over the past five years, this program has provided more than 150 students with exposure to computer science and engineering topics, including software engineering, algorithm development, human-computer interface design, and artificial intelligence. This program provides exciting and compelling educational opportunities for students, offers real-world applications that naturally motivate the need for specific computing technologies, and serves a broader research and development program that utilizes the functional robotic systems to support externally-funded science and technology demonstration missions. The experience of the authors, as well as formal program assessment data, show that this program provides strong student motivation for learning, offers comprehensive and valuable educational experiences, and enhances student performance. This article reviews the Santa Clara robotics program, highlights the role of computer science and engineering in several projects, and presents the assessment data showing the positive results of this program.",project-academic
,2021-09-07,a,,robot sound interpretation learning visual audio representations for voice controlled robots," Inspired by sensorimotor theory, we propose a novel pipeline for voice-controlled robots. Previous work relies on explicit labels of sounds and images as well as extrinsic reward functions. Not only do such approaches have little resemblance to human sensorimotor development, but also require hand-tuning rewards and extensive human labor. To address these problems, we learn a representation that associates images and sound commands with minimal supervision. Using this representation, we generate an intrinsic reward function to learn robotic tasks with reinforcement learning. We demonstrate our approach on three robot platforms, a TurtleBot3, a Kuka-IIWA arm, and a Kinova Gen3 robot, which hear a command word, identify the associated target object, and perform precise control to approach the target. We show that our method outperforms previous work across various sound types and robotic tasks empirically. We successfully deploy the policy learned in simulator to a real-world Kinova Gen3.",project-academic
10.1007/978-981-15-9460-1_10,2019-07-12,a,EasyChair,towards precise robotic grasping by probabilistic post grasp displacement estimation," Precise robotic grasping is important for many industrial applications, such as assembly and palletizing, where the location of the object needs to be controlled and known. However, achieving precise grasps is challenging due to noise in sensing and control, as well as unknown object properties. We propose a method to plan robotic grasps that are both robust and precise by training two convolutional neural networks—one to predict the robustness of a grasp and another to predict a distribution of post-grasp object displacements. Our networks are trained with depth images in simulation on a dataset of over 1000 industrial parts and were successfully deployed on a real robot without having to be further fine-tuned. The proposed displacement estimator achieves a mean prediction errors of 0.68 cm and \(3.42\) \(^\circ \) on novel objects in real-world experiments .",project-academic
,2020-03-19,a,,learning to fly via deep model based reinforcement learning," Learning to control robots without requiring engineered models has been a long-term goal, promising diverse and novel applications. Yet, reinforcement learning has only achieved limited impact on real-time robot control due to its high demand of real-world interactions. In this work, by leveraging a learnt probabilistic model of drone dynamics, we learn a thrust-attitude controller for a quadrotor through model-based reinforcement learning. No prior knowledge of the flight dynamics is assumed; instead, a sequential latent variable model, used generatively and as an online filter, is learnt from raw sensory input. The controller and value function are optimised entirely by propagating stochastic analytic gradients through generated latent trajectories. We show that ""learning to fly"" can be achieved with less than 30 minutes of experience with a single drone, and can be deployed solely using onboard computational resources and sensors, on a self-built drone.",project-academic
,2020-10-21,a,,visual navigation in real world indoor environments using end to end deep reinforcement learning," Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or image segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we propose a novel approach that enables a direct deployment of the trained policy on real robots. We have designed visual auxiliary tasks, a tailored reward scheme, and a new powerful simulator to facilitate domain randomization. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took ~30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighborhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",project-academic
10.1109/LRA.2021.3068106,2021-03-23,p,Institute of Electrical and Electronics Engineers (IEEE),visual navigation in real world indoor environments using end to end deep reinforcement learning," Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",project-academic
,2020-11-07,a,,rapid pose label generation through sparse representation of unknown objects," Deep Convolutional Neural Networks (CNNs) have been successfully deployed on robots for 6-DoF object pose estimation through visual perception. However, obtaining labeled data on a scale required for the supervised training of CNNs is a difficult task - exacerbated if the object is novel and a 3D model is unavailable. To this end, this work presents an approach for rapidly generating real-world, pose-annotated RGB-D data for unknown objects. Our method not only circumvents the need for a prior 3D object model (textured or otherwise) but also bypasses complicated setups of fiducial markers, turntables, and sensors. With the help of a human user, we first source minimalistic labelings of an ordered set of arbitrarily chosen keypoints over a set of RGB-D videos. Then, by solving an optimization problem, we combine these labels under a world frame to recover a sparse, keypoint-based representation of the object. The sparse representation leads to the development of a dense model and the pose labels for each image frame in the set of scenes. We show that the sparse model can also be efficiently used for scaling to a large number of new scenes. We demonstrate the practicality of the generated labeled dataset by training a pipeline for 6-DoF object pose estimation and a pixel-wise segmentation network.",project-academic
10.1109/ICRA48506.2021.9561277,2021-05-30,p,IEEE,rapid pose label generation through sparse representation of unknown objects," Deep Convolutional Neural Networks (CNNs) have been successfully deployed on robots for 6-DoF object pose estimation through visual perception. However, obtaining labeled data on a scale required for the supervised training of CNNs is a difficult task - exacerbated if the object is novel and a 3D model is unavailable. To this end, this work presents an approach for rapidly generating real-world, pose-annotated RGB-D data for unknown objects. Our method not only circumvents the need for a prior 3D object model (textured or otherwise) but also bypasses complicated setups of fiducial markers, turntables, and sensors. With the help of a human user, we first source minimalistic labelings of an ordered set of arbitrarily chosen keypoints over a set of RGB-D videos. Then, by solving an optimization problem, we combine these labels under a world frame to recover a sparse, keypoint-based representation of the object. The sparse representation leads to the development of a dense model and the pose labels for each image frame in the set of scenes. We show that the sparse model can also be efficiently used for scaling to a large number of new scenes. We demonstrate the practicality of the generated labeled dataset by training a CNN based 6-DoF object pose estimator.",project-academic
,2020-05-28,a,,deep reinforcement learning for real autonomous mobile robot navigation in indoor environments," Deep Reinforcement Learning has been successfully applied in various computer games [8]. However, it is still rarely used in real-world applications, especially for the navigation and continuous control of real mobile robots [13]. Previous approaches lack safety and robustness and/or need a structured environment. In this paper we present our proof of concept for autonomous self-learning robot navigation in an unknown environment for a real robot without a map or planner. The input for the robot is only the fused data from a 2D laser scanner and a RGB-D camera as well as the orientation to the goal. The map of the environment is unknown. The output actions of an Asynchronous Advantage Actor-Critic network (GA3C) are the linear and angular velocities for the robot. The navigator/controller network is pretrained in a high-speed, parallel, and self-implemented simulation environment to speed up the learning process and then deployed to the real robot. To avoid overfitting, we train relatively small networks, and we add random Gaussian noise to the input laser data. The sensor data fusion with the RGB-D camera allows the robot to navigate in real environments with real 3D obstacle avoidance and without the need to fit the environment to the sensory capabilities of the robot. To further increase the robustness, we train on environments of varying difficulties and run 32 training instances simultaneously. Video: supplementary File / YouTube, Code: GitHub",project-academic
10.1109/FUZZ48607.2020.9177654,2020-07-19,p,IEEE,ai fml agent for robotic game of go and aiot real world co learning applications," In this paper, we propose an AI-FML agent for robotic game of Go and AIoT real-world co-learning applications. The fuzzy machine learning mechanisms are adopted in the proposed model, including fuzzy markup language (FML)-based genetic learning (GFML), eXtreme Gradient Boost (XGBoost), and a seven-layered deep fuzzy neural network (DFNN) with backpropagation learning, to predict the win rate of the game of Go as Black or White. This paper uses Google AlphaGo Master sixty games as the dataset to evaluate the performance of the fuzzy machine learning, and the desired output dataset were predicted by Facebook AI Research (FAIR) ELF Open Go AI bot. In addition, we use IEEE 1855 standard for FML to describe the knowledge base and rule base of the Open Go Darkforest (OGD) prediction platform in order to infer the win rate of the game. Next, the proposed AI-FML agent publishes the inferred result to communicate with the robot Kebbi Air based on MQTT protocol to achieve the goal of human and smart machine co-learning. From Sept. 2019 to Jan. 2020, we introduced the AI-FML agent into the teaching and learning fields in Taiwan. The experimental results show the robots and students can co-learn AI tools and FML applications effectively. In addition, XGBoost outperforms the other machine learning methods but DFNN has the most obvious progress after learning. In the future, we hope to deploy the AI-FML agent to more available robot and human co-learning platforms through the established AI-FML International Academy in the world.",project-academic
,2021-03-25,a,,self imitation learning by planning," Imitation learning (IL) enables robots to acquire skills quickly by transferring expert knowledge, which is widely adopted in reinforcement learning (RL) to initialize exploration. However, in long-horizon motion planning tasks, a challenging problem in deploying IL and RL methods is how to generate and collect massive, broadly distributed data such that these methods can generalize effectively. In this work, we solve this problem using our proposed approach called {self-imitation learning by planning (SILP)}, where demonstration data are collected automatically by planning on the visited states from the current policy. SILP is inspired by the observation that successfully visited states in the early reinforcement learning stage are collision-free nodes in the graph-search based motion planner, so we can plan and relabel robot's own trials as demonstrations for policy learning. Due to these self-generated demonstrations, we relieve the human operator from the laborious data preparation process required by IL and RL methods in solving complex motion planning tasks. The evaluation results show that our SILP method achieves higher success rates and enhances sample efficiency compared to selected baselines, and the policy learned in simulation performs well in a real-world placement task with changing goals and obstacles.",project-academic
10.1109/ICRA48506.2021.9561411,2021-05-30,p,IEEE,self imitation learning by planning," Imitation learning (IL) enables robots to acquire skills quickly by transferring expert knowledge, which is widely adopted in reinforcement learning (RL) to initialize exploration. However, in long-horizon motion planning tasks, a challenging problem in deploying IL and RL methods is how to generate and collect massive, broadly distributed data such that these methods can generalize effectively. In this work, we solve this problem using our proposed approach called self-imitation learning by planning (SILP), where demonstration data are collected automatically by planning on the visited states from the current policy. SILP is inspired by the observation that successfully visited states in the early reinforcement learning stage are collision-free nodes in the graph-search based motion planner, so we can plan and relabel robot's own trials as demonstrations for policy learning. Due to these self-generated demonstrations, we relieve the human operator from the laborious data preparation process required by IL and RL methods in solving complex motion planning tasks. The evaluation results show that our SILP method achieves higher success rates and enhances sample efficiency compared to selected baselines, and the policy learned in simulation performs well in a real-world placement task with changing goals and obstacles.",project-academic
10.1109/ROBOT.2001.933270,2001-05-21,p,IEEE,robotic antarctic meteorite search outcomes," Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to other planets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learned from the first field demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limited performance in the speed and coverage of autonomous search.",project-academic
10.1109/HST47167.2019.9032989,2019-11-01,p,IEEE,attacks on machine learning adversarial examples in connected and autonomous vehicles," Connected and autonomous vehicles (CAV a.k.a. driverless cars) offset human response for transportation infrastructure, enhancing traffic efficiency, travel leisure, and road safety. Behind the wheels of these mobile robots lies machine learning (ML) to automate mundane driving tasks and make decisions from situational awareness. Attacking ML, the brain of driverless cars, can cause catastrophes. This paper proposes a novel approach to attack CAV by fooling its ML model. Using adversarial examples in CAVs, the work demonstrates how adversarial machine learning can generate attacks hardly detectable by current ML classifiers for CAV misbehavior detection. First, adversarial datasets are generated by a traditional attack engine, which CAV misbehavior detection ML models can easily detect. Building attack ML model takes two phases: training and testing. Using supervised learning, Phase I trains the model on the time-series data, converted from the adversarial datasets. Phase II tests the model, which leads, for the next round of model improvement. The initial round deploys K-Nearest Neighbor (KNN) and Random Forest (RF) algorithms, respectively. The next round, guided by deep learning (DL) models, uses Logistic Regression (LG) of neural network and Long Short-Term Memory (LSTM) of recurrent neural network. The results, in precision-recall (PR) and receiver operating characteristic (ROC) curves, validate the effectiveness of the proposed adversarial ML models. This work reveals the vulnerability in ML. At the same time, it shows the promise to protect critical infrastructure by studying the opponent strategies. Future work includes retraining the adversarial ML models with real-world datasets from pilot CAV sites.",project-academic
10.1016/J.ESWA.2016.10.014,2017-02-01,a,Pergamon,semantic maps from multiple visual cues," Semantic mapping based on place and object recognition strategies.Place recognition involves learning through bag of visual words.Object recognition relies on HTM deep learning.Decision making endorses time embedded voting for objects and places.Topometric map is associated with place belief distribution. Future service robots targeted to operate in domestic or industrial environment and in close collaboration with humans should possess the ability to produce meaningful internal perceptual representations of their own surroundings, enabling them to fulfill a variety of real-world tasks. For this purpose, we present here a semantic mapping framework featuring geometrical and semasiological attributes that reveal the relationships between objects and places in a real-life environment. The geometrical component consists of a 3D metric map, onto which a topological map is deployed. The semasiological part is realized by putting together a place recognition algorithm and an object recognition one. The categorization of the different places relies on the resolution of appearance-based consistency histograms, while for the recognition of objects in the scene, a hierarchical temporal memory (HTM) network boosted by a saliency attentional model, is utilized. These semantic attributes are then deposited on the topological map to augment it with the belief distributions regarding the visited places, enabling thus the agent to act in an intelligent manner in human populated environments. Thus, the proposed framework outlines a proficient system in the construction of human conceivable environment representations, which has been successfully assessed on real-world scenarios, proving its ability to provide a consistent solution to the emerging problem of the human-robot cohabitation.",project-academic
10.1109/TCDS.2019.2928820,2021-01-30,a,IEEE,bnd ddqn learn to steer autonomously through deep reinforcement learning," It is vital for mobile robots to achieve safe autonomous steering in various changing environments. In this paper, a novel end-to-end network architecture is proposed for mobile robots to learn steering autonomously through deep reinforcement learning. Specifically, two sets of feature representations are first extracted from the depth inputs through two different input streams. The acquired features are then merged together to derive both linear and angular actions simultaneously. Moreover, a new action selection strategy is also introduced to achieve motion filtering by taking the consistency in angular velocity into account. Besides, in addition to the extrinsic rewards, the intrinsic bonuses are also adopted during training to improve the exploration capability. Furthermore, it is worth noting the proposed model is readily transferable from the simple virtual training environment to much more complicated real-world scenarios so that no further fine-tuning is required for real deployment. Compared to the existing methods, the proposed method demonstrates significant superiority in terms of average reward, convergence speed, success rate, and generalization capability. In addition, it exhibits outstanding performance in various cluttered real-world environments containing both static and dynamic obstacles. A video of our experiments can be found at None https://youtu.be/19jrQGG1oCU .",project-academic
,2021-11-03,a,,continual learning of semantic segmentation using complementary 2d 3d data representations," Semantic segmentation networks are usually pre-trained and not updated during deployment. As a consequence, misclassifications commonly occur if the distribution of the training data deviates from the one encountered during the robot's operation. We propose to mitigate this problem by adapting the neural network to the robot's environment during deployment, without any need for external supervision. Leveraging complementary data representations, we generate a supervision signal, by probabilistically accumulating consecutive 2D semantic predictions in a volumetric 3D map. We then retrain the network on renderings of the accumulated semantic map, effectively resolving ambiguities and enforcing multi-view consistency through the 3D representation. To preserve the previously-learned knowledge while performing network adaptation, we employ a continual learning strategy based on experience replay. Through extensive experimental evaluation, we show successful adaptation to real-world indoor scenes both on the ScanNet dataset and on in-house data recorded with an RGB-D sensor. Our method increases the segmentation performance on average by 11.8% compared to the fixed pre-trained neural network, while effectively retaining knowledge from the pre-training dataset.",project-academic
10.1109/SAHCN.2014.6990347,2014-12-18,p,IEEE,area coverage under low sensor density," This paper presents a solution to the problem of monitoring a region of interest (RoI) using a set of nodes that is not sufficient to achieve the required degree of monitoring coverage. In particular, sensing coverage of wireless sensor networks (WSNs) is a crucial issue in projects due to failure of sensors. The lack of sensor equipment resources hinders the traditional method of using mobile robots to move around the RoI to collect readings. Instead, our solution employs supervised neural networks to produce the values of the uncovered locations by extracting the non-linear relation among randomly deployed sensor nodes throughout the area. Moreover, we apply a hybrid backpropagation method to accelerate the learning convergence speed to a local minimum solution. We use a real-world data set from meteorological deployment for experimental validation and analysis.",project-academic
10.1145/3366636,2020-02-07,a,"ACMPUB27New York, NY, USA",design and optimization of energy accuracy tradeoff networks for mobile platforms via pretrained deep models," Many real-world edge applications including object detection, robotics, and smart health are enabled by deploying deep neural networks (DNNs) on energy-constrained mobile platforms. In this article, we propose a novel approach to trade off energy and accuracy of inference at runtime using a design space called Learning Energy Accuracy Tradeoff Networks (LEANets). The key idea behind LEANets is to design classifiers of increasing complexity using pretrained DNNs to perform input-specific adaptive inference. The accuracy and energy consumption of the adaptive inference scheme depends on a set of thresholds, one for each classifier. To determine the set of threshold vectors to achieve different energy and accuracy tradeoffs, we propose a novel multiobjective optimization approach. We can select the appropriate threshold vector at runtime based on the desired tradeoff. We perform experiments on multiple pretrained DNNs including ConvNet, VGG-16, and MobileNet using diverse image classification datasets. Our results show that we get up to a 50% gain in energy for negligible loss in accuracy, and optimized LEANets achieve significantly better energy and accuracy tradeoff when compared to a state-of-the-art method referred to as Slimmable neural networks.",project-academic
10.1109/HRI.2019.8673019,2019-03-11,p,IEEE,sail simulation informed active in the wild learning," Robots in real-world environments may need to adapt context-specific behaviors learned in one environment to new environments with new constraints. In many cases, copresent humans can provide the robot with information, but it may not be safe for them to provide hands-on demonstrations and there may not be a dedicated supervisor to provide constant feedback. In this work we present the SAIL (Simulation-Informed Active In-the-Wild Learning) algorithm for learning new approaches to manipulation skills starting from a single demonstration. In this three-step algorithm, the robot simulates task execution to choose new potential approaches; collects unsupervised data on task execution in the target environment; and finally, chooses informative actions to show to co-present humans and obtain labels. Our approach enables a robot to learn new ways of executing two different tasks by using success/failure labels obtained from naive users in a public space, performing 496 manipulation actions and collecting 163 labels from users in the wild over six 45-minute to 1-hour deployments. We show that classifiers based low-level sensor data can be used to accurately distinguish between successful and unsuccessful motions in a multi-step task ( $\mathbf{p} None ), even when trained in the wild. We also show that using the sensor data to choose which actions to sample is more effective than choosing the least-sampled action.",project-academic
10.1109/TNNLS.2016.2545298,2017-07-01,a,IEEE,embedded streaming deep neural networks accelerator with applications," Deep convolutional neural networks (DCNNs) have become a very powerful tool in visual perception. DCNNs have applications in autonomous robots, security systems, mobile phones, and automobiles, where high throughput of the feedforward evaluation phase and power efficiency are important. Because of this increased usage, many field-programmable gate array (FPGA)-based accelerators have been proposed. In this paper, we present an optimized streaming method for DCNNs’ hardware accelerator on an embedded platform. The streaming method acts as a compiler, transforming a high-level representation of DCNNs into operation codes to execute applications in a hardware accelerator. The proposed method utilizes maximum computational resources available based on a novel-scheduled routing topology that combines data reuse and data concatenation. It is tested with a hardware accelerator implemented on the Xilinx Kintex-7 XC7K325T FPGA. The system fully explores weight-level and node-level parallelizations of DCNNs and achieves a peak performance of 247 G-ops while consuming less than 4 W of power. We test our system with applications on object classification and object detection in real-world scenarios. Our results indicate high-performance efficiency, outperforming all other presented platforms while running these applications.",project-academic
10.1007/S10489-013-0461-5,2014-03-01,a,Springer US,a machine learning based intelligent vision system for autonomous object detection and recognition," Existing object recognition techniques often rely on human labeled data conducting to severe limitations to design a fully autonomous machine vision system. In this work, we present an intelligent machine vision system able to learn autonomously individual objects present in real environment. This system relies on salient object detection. In its design, we were inspired by early processing stages of human visual system. In this context we suggest a novel fast algorithm for visually salient object detection, robust to real-world illumination conditions. Then we use it to extract salient objects which can be efficiently used for training the machine learning-based object detection and recognition unit of the proposed system. We provide results of our salient object detection algorithm on MSRA Salient Object Database benchmark comparing its quality with other state-of-the-art approaches. The proposed system has been implemented on a humanoid robot, increasing its autonomy in learning and interaction with humans. We report and discuss the obtained results, validating the proposed concepts.",project-academic
10.1109/ICRA40945.2020.9197512,2020-03-31,p,,sim to real transfer for optical tactile sensing," Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.",project-academic
,2020-03-31,a,,sim to real transfer for optical tactile sensing," Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.",project-academic
10.1109/IROS40897.2019.8968072,2019-02-25,p,IEEE,quickly inserting pegs into uncertain holes using multi view images and deep network trained on synthetic data," This paper explores the use of robots to autonomously assemble parts with variations in colors and textures. Specifically, we focus on peg-in-hole assembly with some initial position uncertainty and holes located on surfaces of different colors and textures. Two in-hand cameras and a force-torque sensor are used to account for the position uncertainty. A program sequence comprising learning-based visual servoing, spiral search, and impedance control is implemented to perform the peg-in-hole task with feedback from the above sensors. Contributions are mainly made in the learning-based visual servoing component of the sequence, where a deep neural network is trained with various sets of synthetic data generated using the concept of domain randomization to predict where a hole is. In the experiments and analysis section, the network is analyzed and compared, and a real-world robotic system to insert pegs to holes using the proposed method is implemented. The results show that the implemented peg-in-hole assembly system can perform successful peg-in-hole insertions on surfaces with various colors and textures. It can generally speed up the entire peg-in-hole process, especially when the initial position uncertainty is large.",project-academic
,2019-02-25,a,,quickly inserting pegs into uncertain holes using multi view images and deep network trained on synthetic data," This paper uses robots to assemble pegs into holes on surfaces with different colors and textures. It especially targets at the problem of peg-in-hole assembly with initial position uncertainty. Two in-hand cameras and a force-torque sensor are used to account for the position uncertainty. A program sequence comprising learning-based visual servoing, spiral search, and impedance control is implemented to perform the peg-in-hole task with feedback from the above sensors. Contributions are mainly made in the learning-based visual servoing of the sequence, where a deep neural network is trained with various sets of synthetic data generated using the concept of domain randomization to predict where a hole is. In the experiments and analysis section, the network is analyzed and compared, and a real-world robotic system to insert pegs to holes using the proposed method is implemented. The results show that the implemented peg-in-hole assembly system can perform successful peg-in-hole insertions on surfaces with various colors and textures. It can generally speed up the entire peg-in-hole process.",project-academic
,2017-10-10,,,neural networks for selecting actions to be performed by a robotic agent," A system includes a neural network system implemented by one or more computers. The neural network system is configured to receive an observation characterizing a current state of a real-world environment being interacted with by a robotic agent to perform a robotic task and to process the observation to generate a policy output that defines an action to be performed by the robotic agent in response to the observation. The neural network system includes: (i) a sequence of deep neural networks (DNNs), in which the sequence of DNNs includes a simulation-trained DNN that has been trained on interactions of a simulated version of the robotic agent with a simulated version of the real-world environment to perform a simulated version of the robotic task, and (ii) a first robot-trained DNN that is configured to receive the observation and to process the observation to generate the policy output.",project-academic
10.1109/ICOSTA48221.2020.1570615971,2020-02-01,p,IEEE,detecting features of middle size soccer field using omnidirectional camera for robot soccer ersow," ERSOW (EEPIS Robot Soccer on Wheeled) is robot soccer developed by Politeknik Elektronika Negeri Surabaya that is designed and implemented on a Middle Size League division by following the rules of RoboCup, an international robot competition. One of the most famous division is a soccer robot, that is divided into two divisions: (1) SSL (Small Size League) and (2) MSL (Middle Size League). There are many research fields related to soccer robot which must be developed in robot ERSOW such as Artificial Intelligence (AI), Computer Vision, Embedded System, Mechanic Systems, and Hardware. This paper focuses on computer vision research for robot ERSOW, especially detecting features of the middle size soccer field, so that specific features of the field like X-junction, T-junction and L-junction can be detected to help robot positioning task where the result is represented into x and y in real-world coordinate. By knowing the position of the features, the robot position can be calculated. The localization system at robot ERSOW uses odometry, which has a large percentage of data errors. Therefore, we attempt to extract the feature of X-junction that is done to find its x and y coordinates and then the obtained coordinate can be used as a reference for correcting odometry data by AI.",project-academic
,2019-12-02,a,,human robot collaboration via deep reinforcement learning of real world interactions," We present a robotic setup for real-world testing and evaluation of human-robot and human-human collaborative learning. Leveraging the sample-efficiency of the Soft Actor-Critic algorithm, we have implemented a robotic platform able to learn a non-trivial collaborative task with a human partner, without pre-training in simulation, and using only 30 minutes of real-world interactions. This enables us to study Human-Robot and Human-Human collaborative learning through real-world interactions. We present preliminary results, showing that state-of-the-art deep learning methods can take human-robot collaborative learning a step closer to that of humans interacting with each other.",project-academic
10.1109/ROBIO.2018.8665255,2018-12-01,p,IEEE,knowledge driven deep deterministic policy gradient for robotic multiple peg in hole assembly tasks," It remains a formidable challenge for traditional control strategies to perform automatic multiple peg-in-hole assembly tasks due to the complicated and dynamic contact states. Inspired by that human could generalize the learned skills to perform the different assembly tasks well, a general learning-based algorithm based on deep deterministic policy gradient (DDPG) is proposed. To make robots learn the multiple peg-in-hole assembly skills from experience efficiently and stably, the learning process is driven by the basic knowledge like PD force control strategy. To achieve a fast learning process in the real-world assembly tasks, a hybrid exploration strategy is applied to drive a efficient exploration during policy search phase. A dual peg-in-hole assembly simulation and real-world experiments are implemented to verify the effectiveness of the proposed algorithm. The performance measured by the assembly time and the maximum contact forces demonstrates that the multiple peg-in-hole assembly skills could be improved only after 150 training episodes in dual peg-in-hole assembly task.",project-academic
10.1142/S0218213008003820,2008-02-01,a,World Scientific Publishing Company,polynomial regression with automated degree a function approximator for autonomous agents," In order for an autonomous agent to behave robustly in a variety of environments, it must have the ability to learn approximations to many different functions. The function approximator used by such an agent is subject to a number of constraints that may not apply in a traditional supervised learning setting. Many different function approximators exist and are appropriate for different problems. This paper proposes a set of criteria for function approximators for autonomous agents. Additionally, for those problems on which polynomial regression is a candidate technique, the paper presents an enhancement that meets these criteria. In particular, using polynomial regression typically requires a manual choice of the polynomial's degree, trading off between function accuracy and computational and memory efficiency. Polynomial Regression with Automated Degree (PRAD) is a novel function approximation method that uses training data to automatically identify an appropriate degree for the polynomial. PRAD is fully implemented. Empirical tests demonstrate its ability to efficiently and accurately approximate both a wide variety of synthetic functions and real-world data gathered by a mobile robot.",project-academic
10.1109/ICTAI.2006.96,2006-11-13,p,IEEE,polynomial regression with automated degree a function approximator for autonomous agents," In order for an autonomous agent to behave robustly in a variety of environments, it must have the ability to learn approximations to many different functions. The function approximator used by such an agent is subject to a number of constraints that may not apply in a traditional supervised learning setting. Many different function approximators exist and are appropriate for different problems. This paper proposes a set of criteria for function approximators for autonomous agents. Additionally, for those problems on which polynomial regression is a candidate technique, the paper presents an enhancement that meets these criteria. In particular, using polynomial regression typically requires a manual choice of the polynomial?s degree, trading off between function accuracy and computational and memory efficiency. Polynomial Regression with Automated Degree (PRAD) is a novel function approximation method that uses training data to automatically identify an appropriate degree for the polynomial. PRAD is fully implemented. Empirical tests demonstrate its ability to efficiently and accurately approximate both a wide variety of synthetic functions and real-world data gathered by a mobile robot.",project-academic
,2021-03-09,a,,i am robot neuromuscular reinforcement learning to actuate human limbs through functional electrical stimulation," Human movement disorders or paralysis lead to the loss of control of muscle activation and thus motor control. Functional Electrical Stimulation (FES) is an established and safe technique for contracting muscles by stimulating the skin above a muscle to induce its contraction. However, an open challenge remains on how to restore motor abilities to human limbs through FES, as the problem of controlling the stimulation is unclear. We are taking a robotics perspective on this problem, by developing robot learning algorithms that control the ultimate humanoid robot, the human body, through electrical muscle stimulation. Human muscles are not trivial to control as actuators due to their force production being non-stationary as a result of fatigue and other internal state changes, in contrast to robot actuators which are well-understood and stationary over broad operation ranges. We present our Deep Reinforcement Learning approach to the control of human muscles with FES, using a recurrent neural network for dynamic state representation, to overcome the unobserved elements of the behaviour of human muscles under external stimulation. We demonstrate our technique both in neuromuscular simulations but also experimentally on a human. Our results show that our controller can learn to manipulate human muscles, applying appropriate levels of stimulation to achieve the given tasks while compensating for advancing muscle fatigue which arises throughout the tasks. Additionally, our technique can learn quickly enough to be implemented in real-world human-in-the-loop settings.",project-academic
10.1109/TCYB.2019.2946090,2020-12-03,a,IEEE,a robust collision perception visual neural network with specific selectivity to darker objects," Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust’s visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",project-academic
10.1109/HUMANOIDS.2014.7041490,2014-11-30,p,IEEE,can active impedance protect robots from landing impact," This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",project-academic
10.5121/CSIT.2020.101117,2020-09-26,p,AIRCC Publishing Corporation,deep reinforcement learning for navigation in cluttered environments," Collision-free motion is essential for mobile robots. Most approaches to collision-free and efficient navigation with wheeled robots require parameter tuning by experts to obtain good navigation behavior. In this paper, we aim at learning an optimal navigation policy by deep reinforcement learning to overcome this manual parameter tuning. Our approach uses proximal policy optimization to train the policy and achieve collision-free and goal-directed behavior. The output of the learned network are the robot’s translational and angular velocities for the next time step. Our method combines path planning on a 2D grid with reinforcement learning and does not need any supervision. Our network is first trained in a simple environment and then transferred to scenarios of increasing complexity. We implemented our approach in C++ and Python for the Robot Operating System (ROS) and thoroughly tested it in several simulated as well as real-world experiments. The experiments illustrate that our trained policy can be applied to solve complex navigation tasks. Furthermore, we compare the performance of our learned controller to the popular dynamic window approach (DWA) of ROS. As the experimental results show, a robot controlled by our learned policy reaches the goal significantly faster compared to using the DWA by closely bypassing obstacles and thus saving time.",project-academic
10.3390/S20226697,2020-11-23,a,Multidisciplinary Digital Publishing Institute,mobile manipulation integrating enhanced amcl high precision location and dynamic tracking grasp," Mobile manipulation, which has more flexibility than fixed-base manipulation, has always been an important topic in the field of robotics. However, for sophisticated operation in complex environments, efficient localization and dynamic tracking grasp still face enormous challenges. To address these challenges, this paper proposes a mobile manipulation method integrating laser-reflector-enhanced adaptive Monte Carlo localization (AMCL) algorithm and a dynamic tracking and grasping algorithm. First, by fusing the information of laser-reflector landmarks to adjust the weight of particles in AMCL, the localization accuracy of mobile platforms can be improved. Second, deep-learning-based multiple-object detection and visual servo are exploited to efficiently track and grasp dynamic objects. Then, a mobile manipulation system integrating the above two algorithms into a robotic with a 6-degrees-of-freedom (DOF) operation arm is implemented in an indoor environment. Technical components, including localization, multiple-object detection, dynamic tracking grasp, and the integrated system, are all verified in real-world scenarios. Experimental results demonstrate the efficacy and superiority of our method.",project-academic
10.1109/JIOT.2020.3004339,2020-06-23,a,IEEE,airscope mobile robots assisted cooperative indoor air quality sensing by distributed deep reinforcement learning," Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep None None None $Q$ None None -learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.",project-academic
10.3390/ROBOTICS9010008,2020-02-25,a,MDPI AG,sim to real quadrotor landing via sequential deep q networks and domain randomization," The autonomous landing of an Unmanned Aerial Vehicle (UAV) on a marker is one of the most challenging problems in robotics. Many solutions have been proposed, with the best results achieved via customized geometric features and external sensors. This paper discusses for the first time the use of deep reinforcement learning as an end-to-end learning paradigm to find a policy for UAVs autonomous landing. Our method is based on a divide-and-conquer paradigm that splits a task into sequential sub-tasks, each one assigned to a Deep Q-Network (DQN), hence the name Sequential Deep Q-Network (SDQN). Each DQN in an SDQN is activated by an internal trigger, and it represents a component of a high-level control policy, which can navigate the UAV towards the marker. Different technical solutions have been implemented, for example combining vanilla and double DQNs, and the introduction of a partitioned buffer replay to address the problem of sample efficiency. One of the main contributions of this work consists in showing how an SDQN trained in a simulator via domain randomization, can effectively generalize to real-world scenarios of increasing complexity. The performance of SDQNs is comparable with a state-of-the-art algorithm and human pilots while being quantitatively better in noisy conditions.",project-academic
,2018-01-01,b,,computational intelligence an introduction," Computational Intelligence: An Introduction, Second Edition offers an in-depth exploration into the adaptive mechanisms that enable intelligent behaviour in complex and changing environments. The main focus of this text is centred on the computational modelling of biological and natural intelligent systems, encompassing swarm intelligence, fuzzy systems, artificial neutral networks, artificial immune systems and evolutionary computation. Engelbrecht provides readers with a wide knowledge of Computational Intelligence (CI) paradigms and algorithms; inviting readers to implement and problem solve real-world, complex problems within the CI development framework. This implementation framework will enable readers to tackle new problems without any difficulty through a single Java class as part of the CI library. Key features of this second edition include: A tutorial, hands-on based presentation of the material. State-of-the-art coverage of the most recent developments in computational intelligence with more elaborate discussions on intelligence and artificial intelligence (AI). New discussion of Darwinian evolution versus Lamarckian evolution, also including swarm robotics, hybrid systems and artificial immune systems. A section on how to perform empirical studies; topics including statistical analysis of stochastic algorithms, and an open source library of CI algorithms. Tables, illustrations, graphs, examples, assignments, Java code implementing the algorithms, and a complete CI implementation and experimental framework. Computational Intelligence: An Introduction, Second Edition is essential reading for third and fourth year undergraduate and postgraduate students studying CI. The first edition has been prescribed by a number of overseas universities and is thus a valuable teaching tool. In addition, it will also be a useful resource for researchers in Computational Intelligence and Artificial Intelligence, as well as engineers, statisticians, operational researchers, and bioinformaticians with an interest in applying AI or CI to solve problems in their domains. Check out http://www.ci.cs.up.ac.za for examples, assignments and Java code implementing the algorithms.",project-academic
,2021-05-31,p,,multibench multiscale benchmarks for multimodal representation learning," Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. It is a challenging yet crucial area with numerous real-world applications in multimedia, affective computing, robotics, finance, human-computer interaction, and healthcare. Unfortunately, multimodal research has seen limited resources to study (1) generalization across domains and modalities, (2) complexity during training and inference, and (3) robustness to noisy and missing modalities. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiBench, a systematic and unified large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. MultiBench provides an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, MultiBench offers a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench introduces impactful challenges for future research, including scalability to large-scale multimodal datasets and robustness to realistic imperfections. To accompany this benchmark, we also provide a standardized implementation of 20 core approaches in multimodal learning. Simply applying methods proposed in different research areas can improve the state-of-the-art performance on 9/15 datasets. Therefore, MultiBench presents a milestone in unifying disjoint efforts in multimodal research and paves the way towards a better understanding of the capabilities and limitations of multimodal models, all the while ensuring ease of use, accessibility, and reproducibility. MultiBench, our standardized code, and leaderboards are publicly available, will be regularly updated, and welcomes inputs from the community.",project-academic
,2018-09-20,a,PMLR,benchmarking reinforcement learning algorithms on real world robots," Through many recent successes in simulation, model-free reinforcement learning has emerged as a promising approach to solving continuous control robotic tasks. The research community is now able to reproduce, analyze and build quickly on these results due to open source implementations of learning algorithms and simulated benchmark tasks. To carry forward these successes to real-world applications, it is crucial to withhold utilizing the unique advantages of simulations that do not transfer to the real world and experiment directly with physical robots. However, reinforcement learning research with physical robots faces substantial resistance due to the lack of benchmark tasks and supporting source code. In this work, we introduce several reinforcement learning tasks with multiple commercially available robots that present varying levels of learning difficulty, setup, and repeatability. On these tasks, we test the learning performance of off-the-shelf implementations of four reinforcement learning algorithms and analyze sensitivity to their hyper-parameters to determine their readiness for applications in various real-world tasks. Our results show that with a careful setup of the task interface and computations, some of these implementations can be readily applicable to physical robots. We find that state-of-the-art learning algorithms are highly sensitive to their hyper-parameters and their relative ordering does not transfer across tasks, indicating the necessity of re-tuning them for each task for best performance. On the other hand, the best hyper-parameter configuration from one task may often result in effective learning on held-out tasks even with different robots, providing a reasonable default. We make the benchmark tasks publicly available to enhance reproducibility in real-world reinforcement learning.",project-academic
10.1145/2830772.2830789,2015-12-05,p,ACM,neuromorphic accelerators a comparison between neuroscience and machine learning approaches," A vast array of devices, ranging from industrial robots to self-driven cars or smartphones, require increasingly sophisticated processing of real-world input data (image, voice, radio, ...). Interestingly, hardware neural network accelerators are emerging again as attractive candidate architectures for such tasks. The neural network algorithms considered come from two, largely separate, domains: machine-learning and neuroscience. These neural networks have very different characteristics, so it is unclear which approach should be favored for hardware implementation. Yet, few studies compare them from a hardware perspective. We implement both types of networks down to the layout, and we compare the relative merit of each approach in terms of energy, speed, area cost, accuracy and functionality.Within the limit of our study (current SNN and machine-learning NN algorithms, current best effort at hardware implementation efforts, and workloads used in this study), our analysis helps dispel the notion that hardware neural network accelerators inspired from neuroscience, such as SNN+STDP, are currently a competitive alternative to hardware neural networks accelerators inspired from machine-learning, such as MLP+BP: not only in terms of accuracy, but also in terms of hardware cost for realistic implementations, which is less expected. However, we also outline that SNN+STDP carry potential for reduced hardware cost compared to machine-learning networks at very large scales, if accuracy issues can be controlled (or for applications where they are less important). We also identify the key sources of inaccuracy of SNN+STDP which are less related to the loss of information due to spike coding than to the nature of the STDP learning algorithm. Finally, we outline that for the category of applications which require permanent online learning and moderate accuracy, SNN+STDP hardware accelerators could be a very cost-efficient solution.",project-academic
10.1126/SCIROBOTICS.AAV3123,2019-01-30,a,American Association for the Advancement of Science,see feel act hierarchical learning for complex manipulation skills with multisensory fusion," Humans are able to seamlessly integrate tactile and visual stimuli with their intuitions to explore and execute complex manipulation skills. They not only see but also feel their actions. Most current robotic learning methodologies exploit recent progress in computer vision and deep learning to acquire data-hungry pixel-to-action policies. These methodologies do not exploit intuitive latent structure in physics or tactile signatures. Tactile reasoning is omnipresent in the animal kingdom, yet it is underdeveloped in robotic manipulation. Tactile stimuli are only acquired through invasive interaction, and interpretation of the data stream together with visual stimuli is challenging. Here, we propose a methodology to emulate hierarchical reasoning and multisensory fusion in a robot that learns to play Jenga, a complex game that requires physical interaction to be played effectively. The game mechanics were formulated as a generative process using a temporal hierarchical Bayesian model, with representations for both behavioral archetypes and noisy block states. This model captured descriptive latent structures, and the robot learned probabilistic models of these relationships in force and visual domains through a short exploration phase. Once learned, the robot used this representation to infer block behavior patterns and states as it played the game. Using its inferred beliefs, the robot adjusted its behavior with respect to both its current actions and its game strategy, similar to the way humans play the game. We evaluated the performance of the approach against three standard baselines and show its fidelity on a real-world implementation of the game.",project-academic
,2020-02-22,a,,guided constrained policy optimization for dynamic quadrupedal robot locomotion," Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We also introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.",project-academic
10.1109/LRA.2020.2979656,2020-03-09,p,IEEE,guided constrained policy optimization for dynamic quadrupedal robot locomotion," Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.",project-academic
,2021-08-06,a,,what matters in learning from offline human demonstrations for robot manipulation," Imitating human demonstrations is a promising approach to endow robots with various manipulation capabilities. While recent advances have been made in imitation learning and batch (offline) reinforcement learning, a lack of open-source human datasets and reproducible learning methods make assessing the state of the field difficult. In this paper, we conduct an extensive study of six offline learning algorithms for robot manipulation on five simulated and three real-world multi-stage manipulation tasks of varying complexity, and with datasets of varying quality. Our study analyzes the most critical challenges when learning from offline human data for manipulation. Based on the study, we derive a series of lessons including the sensitivity to different algorithmic design choices, the dependence on the quality of the demonstrations, and the variability based on the stopping criteria due to the different objectives in training and evaluation. We also highlight opportunities for learning from human datasets, such as the ability to learn proficient policies on challenging, multi-stage tasks beyond the scope of current reinforcement learning methods, and the ability to easily scale to natural, real-world manipulation scenarios where only raw sensory signals are available. We have open-sourced our datasets and all algorithm implementations to facilitate future research and fair comparisons in learning from human demonstration data. Codebase, datasets, trained models, and more available at this https URL",project-academic
10.1016/S2589-7500(21)00005-4,2021-05-06,a,Elsevier,health information technology and digital innovation for national learning health and care systems," Health information technology can support the development of national learning health and care systems, which can be defined as health and care systems that continuously use data-enabled infrastructure to support policy and planning, public health, and personalisation of care. The COVID-19 pandemic has offered an opportunity to assess how well equipped the UK is to leverage health information technology and apply the principles of a national learning health and care system in response to a major public health shock. With the experience acquired during the pandemic, each country within the UK should now re-evaluate their digital health and care strategies. After leaving the EU, UK countries now need to decide to what extent they wish to engage with European efforts to promote interoperability between electronic health records. Major priorities for strengthening health information technology in the UK include achieving the optimal balance between top-down and bottom-up implementation, improving usability and interoperability, developing capacity for handling, processing, and analysing data, addressing privacy and security concerns, and encouraging digital inclusivity. Current and future opportunities include integrating electronic health records across health and care providers, investing in health data science research, generating real-world data, developing artificial intelligence and robotics, and facilitating public-private partnerships. Many ethical challenges and unintended consequences of implementation of health information technology exist. To address these, there is a need to develop regulatory frameworks for the development, management, and procurement of artificial intelligence and health information technology systems, create public-private partnerships, and ethically and safely apply artificial intelligence in the National Health Service.",project-academic
10.1109/LRA.2020.3007455,2020-07-07,p,IEEE,image transformation and cnns a strategy for encoding human locomotor intent for autonomous wearable robots," Wearable robots have the potential to improve the lives of countless individuals; however, challenges associated with controlling these systems must be addressed before they can reach their full potential. Modern control strategies for wearable robots are predicated on activity-specific implementations, and testing is usually limited to a single, fixed activity within the laboratory (e.g., level ground walking). To accommodate various activities in real-world scenarios, control strategies must include the ability to safely and seamlessly transition between activity-specific controllers. One potential solution to this challenge is to the infer wearer's intent using pattern recognition of locomotion sensor data. To this end, we developed an intent recognition framework implementing convolutional neural networks with image encoding (i.e. spectrogram) that enables prediction of the upcoming locomotor activity of the wearer's next step. In this letter, we describe our intent recognition system, comprised of a mel-spectrogram and subsequent neural network architecture. In addition, we analyzed the effect of sensor locations and modalities on the recognition system, and compared our proposed system to state-of-the-art locomotor intent recognition strategies. We were able to attain high classification performance (error rate: 1.1%), which was comparable or better than previous systems.",project-academic
10.1007/S12369-017-0414-Y,2017-07-20,a,Springer Netherlands,automatically classifying user engagement for dynamic multi party human robot interaction," A robot agent designed to engage in real-world human–robot joint action must be able to understand the social states of the human users it interacts with in order to behave appropriately. In particular, in a dynamic public space, a crucial task for the robot is to determine the needs and intentions of all of the people in the scene, so that it only interacts with people who intend to interact with it. We address the task of estimating the engagement state of customers for a robot bartender based on the data from audiovisual sensors. We begin with an offline experiment using hidden Markov models, confirming that the sensor data contains the information necessary to estimate user state. We then present two strategies for online state estimation: a rule-based classifier based on observed human behaviour in real bars, and a set of supervised classifiers trained on a labelled corpus. These strategies are compared in offline cross-validation, in an online user study, and through validation against a separate test corpus. These studies show that while the trained classifiers are best in a cross-validation setting, the rule-based classifier performs best with novel data; however, all classifiers also change their estimate too frequently for practical use. To address this issue, we present a final classifier based on Conditional Random Fields: this model has comparable performance on the test data, with increased stability. In summary, though, the rule-based classifier shows competitive performance with the trained classifiers, suggesting that for this task, such a simple model could actually be a preferred option, providing useful online performance while avoiding the implementation and data-scarcity issues involved in using machine learning for this task.",project-academic
,2020-03-25,,,machine learning methods and apparatus for robotic manipulation and that utilize multi task domain adaptation," Implementations are directed to training a machine learning model that, once trained, is used in performance of robotic grasping and/or other manipulation task(s) by a robot. The model can be trained using simulated training examples that are based on simulated data that is based on simulated robot(s) attempting simulated manipulations of various simulated objects. At least portions of the model can also be trained based on real training examples that are based on data from real-world physical robots attempting manipulations of various objects. The simulated training examples can be utilized to train the model to predict an output that can be utilized in a particular task—and the real training examples used to adapt at least a portion of the model to the real-world domain can be tailored to a distinct task. In some implementations, domain-adversarial similarity losses are determined during training, and utilized to regularize at least portion(s) of the model.",project-academic
10.1109/ROBIO49542.2019.8961764,2019-12-01,p,IEEE,sarl deep reinforcement learning based human aware navigation for mobile robot in indoor environments," In a human-robot coexisting environment, reaching the goal position safely and efficiently is essential for a mobile service robot. In this paper, we present an advanced version of the Socially Attentive Reinforcement Learning (SARL) algorithm, namely SARL*, to achieve human-aware navigation in indoor environments. Recently, deep reinforcement learning has achieved great success in generating human-aware navigation policies. However, there exist some limitations in the real-world implementations: the learned navigation policies are limited to certain distances associated with the training process, and the simplification of the environment neglects obstacles other than humans. In this work, we improve the state-of-the-art SARL algorithm by introducing a dynamic local goal setting mechanism and a map-based safe action space to tackle the above problems. Real-world experimental results demonstrate that the proposed algorithm outperforms the original SARL algorithm in both time cost and path length in the human-aware navigation tasks in the indoor environment.",project-academic
10.1007/S10514-013-9323-6,2013-04-01,a,Springer US,ros open source audio recognizer roar environmental sound detection tools for robot programming," Advances in audio recognition have enabled the real-world success of a wide variety of interactive voice systems over the last two decades. More recently, these same techniques have shown promise in recognizing non-speech audio events. Sounds are ubiquitous in real-world manipulation, such as the click of a button, the crash of an object being knocked over, and the whine of activation from an electric power tool. Surprisingly, very few autonomous robots leverage audio feedback to improve their performance. Modern audio recognition techniques exist that are capable of learning and recognizing real-world sounds, but few implementations exist that are easily incorporated into modern robotic programming frameworks. This paper presents a new software library known as the ROS Open-source Audio Recognizer (ROAR). ROAR provides a complete set of end-to-end tools for online supervised learning of new audio events, feature extraction, automatic one-class Support Vector Machine model tuning, and real-time audio event detection. Through implementation on a Barrett WAM arm, we show that combining the contextual information of the manipulation action with a set of learned audio events yields significant improvements in robotic task-completion rates.",project-academic
10.3390/S19163602,2019-08-19,a,Multidisciplinary Digital Publishing Institute,bin picking for planar objects based on a deep learning network a case study of usb packs," Random bin-picking is a prominent, useful, and challenging industrial robotics application. However, many industrial and real-world objects are planar and have oriented surface points that are not sufficiently compact and discriminative for those methods using geometry information, especially depth discontinuities. This study solves the above-mentioned problems by proposing a novel and robust solution for random bin-picking for planar objects in a cluttered environment. Different from other research that has mainly focused on 3D information, this study first applies an instance segmentation-based deep learning approach using 2D image data for classifying and localizing the target object while generating a mask for each instance. The presented approach, moreover, serves as a pioneering method to extract 3D point cloud data based on 2D pixel values for building the appropriate coordinate system on the planar object plane. The experimental results showed that the proposed method reached an accuracy rate of 100% for classifying two-sided objects in the unseen dataset, and 3D appropriate pose prediction was highly effective, with average translation and rotation errors less than 0.23 cm and 2.26°, respectively. Finally, the system success rate for picking up objects was over 99% at an average processing time of 0.9 s per step, fast enough for continuous robotic operation without interruption. This showed a promising higher successful pickup rate compared to previous approaches to random bin-picking problems. Successful implementation of the proposed approach for USB packs provides a solid basis for other planar objects in a cluttered environment. With remarkable precision and efficiency, this study shows significant commercialization potential.",project-academic
10.1007/S10514-020-09925-W,2020-09-01,a,Springer US,iterative residual tuning for system identification and sim to real robot learning," Robots are increasingly learning complex skills in simulation, increasing the need for realistic simulation environments. Existing techniques for approximating real-world physics with a simulation require extensive observation data and/or thousands of simulation samples. This paper presents iterative residual tuning (IRT), a deep learning system identification technique that modifies a simulator’s parameters to better match reality using minimal real-world observations. IRT learns to estimate the parameter difference between two parameterized models, allowing repeated iterations to converge on the true parameters similarly to gradient descent. In this paper, we develop and analyze IRT in depth, including its similarities and differences with gradient descent. Our IRT implementation, TuneNet, is pre-trained via supervised learning over an auto-generated simulated dataset. We show that TuneNet can perform rapid, efficient system identification even when the true parameter values lie well outside those in the network’s training data, and can also learn real-world parameter values from visual data. We apply TuneNet to a sim-to-real task transfer experiment, allowing a robot to perform a dynamic manipulation task with a new object after a single observation.",project-academic
,2020-10-17,a,,learning from suboptimal demonstration via self supervised reward regression," Learning from Demonstration (LfD) seeks to democratize robotics by enabling non-roboticist end-users to teach robots to perform a task by providing a human demonstration. However, modern LfD techniques, such as inverse reinforcement learning (IRL), assume users provide at least stochastically optimal demonstrations. This assumption fails to hold in all but the most isolated, controlled scenarios, reducing the ability to achieve the goal of empowering real end-users. Recent attempts to learn from sub-optimal demonstration leverage pairwise rankings through Preference-based Reinforcement Learning (PbRL) to infer a more optimal policy than the demonstration. However, we show that these approaches make incorrect assumptions and, consequently, suffer from brittle, degraded performance. In this paper, we overcome the limitations of prior work by developing a novel computational technique that infers an idealized reward function from suboptimal demonstration and bootstraps suboptimal demonstrations to synthesize optimality-parameterized training data for training our reward function. We empirically validate we can learn an idealized reward function with $\sim0.95$ correlation with the ground truth reward versus only $\sim 0.75$ for prior work. We can then train policies achieving $\sim 200\%$ improvement over the suboptimal demonstration and $\sim 90\%$ improvement over prior work. Finally, we present a real-world implementation for teaching a robot to hit a topspin shot in table tennis better than user demonstration.",project-academic
10.21535/JIAS.V3I3.934,2017-09-26,a,UNSYS Digital,automatic convergence estimation by utilizing fractal dimensional analysis for reinforcement learning," This paper presents an automatic convergence estimation method for the reinforcement learning (RL) of autonomous agents. Recently, a multi-agent robot system (MARS) that uses an RL algorithm has been studied in real-world situations. This system can obtain behaviors autonomously through multi-agent reinforcement learning (MARL). However, MARL takes a long time to obtain an optimal or near-optimal solution. Furthermore, the agents continued learning after obtaining of the solution may lead to overfitting. It is difficult for the MARL operator to determine whether the learning has been converged or not, because the operator has to determine the convergence of all learning agents. The convergence of the learning curve indicates that knowledge has been obtained. However, judging the convergence of RL depends on human intuition and experience, and few studies have discussed convergence estimation methods. Therefore, in this paper, we address development of an automatic convergence estimation method that does not require human judgement. In prior work, we proposed automatic convergence estimation method using fractal dimensional analysis which evaluates the learning curve of the learner as agents, and we confirmed the effectiveness of our previous method by conducting a computer simulation. In this study, we propose a method based on fractal dimensional analysis considering implementation to the robots and evaluate the effectiveness of the method by using an expanded experimental setup that considering a computer simulation and an actual mobile robot environment.",project-academic
10.1109/SSCI.2016.7849899,2016-12-01,p,IEEE,a fuzzy based machine learning model for robot prediction of link quality," With foresight into the state of the wireless channel, a robot can make various optimization decisions with regards to routing packets, planning mobility paths, or switching between diverse radios. However, the process of predicting link quality (LQ) is nontrivial due to the streaming and dynamic nature of radio wave propagation, which is complicated by robot mobility. Due to robot movement, the wireless propagation environment can change considerably in terms of distance, obstacles, noise, and interference. Therefore, LQ must be learned and regularly updated while the robot is online. However, the existing fuzzy-based models for assessing LQ are non-adaptable due to the absence of any learning mechanism. To address this issue, we introduce a fuzzy-based prediction model designed for the efficient online and incremental learning of LQ. The unique approach uses fuzzy logic to infer LQ based on the collective output from a series of offset classifiers and their posterior probabilities. In essence, the proposed model leverages machine learning for extracting the underlying functional relationship between the input and output variables, but deeper inferences are made from the output of the learning algorithms using fuzzy logic. Wireless link data from a real-world robot network was used to compare the model with the traditional linear regression approach. The results show statistically significant improvements in three out of the six real-world indoor and outdoor environments where the robot operated. Additionally, the novel approach offers a number of other benefits, including the flexibility to use fuzzy logic for model tuning, as well as the ability to make implementation efficiencies in terms of parallelization and the conservation of labeling resources.",project-academic
,2014-10-30,b,,latest advances in inductive logic programming," This book represents a selection of papers presented at the Inductive Logic Programming (ILP) workshop held at Cumberland Lodge, Great Windsor Park. The collection marks two decades since the first ILP workshop in 1991. During this period the area has developed into the main forum for work on logic-based machine learning. The chapters cover a wide variety of topics, ranging from theory and ILP implementations to state-of-the-art applications in real-world domains. The international contributors represent leaders in the field from prestigious institutions in Europe, North America and Asia. Graduate students and researchers in this field will find this book highly useful as it provides an up-to-date insight into the key sub-areas of implementation and theory of ILP. For academics and researchers in the field of artificial intelligence and natural sciences, the book demonstrates how ILP is being used in areas as diverse as the learning of game strategies, robotics, natural language understanding, query search, drug design and protein modelling.Readership: Graduate students and researchers in the field of ILP, and academics and researchers in the fields of artificial intelligence and natural sciences.",project-academic
10.1126/SCIENCE.AAT8414,2019-06-21,a,American Association for the Advancement of Science,trends and challenges in robot manipulation," BACKGROUND None Humans have a fantastic ability to manipulate objects of various shapes, sizes, and materials and can control the objects’ position in confined spaces with the advanced dexterity capabilities of our hands. Building machines inspired by human hands, with the functionality to autonomously pick up and manipulate objects, has always been an essential component of robotics. The first robot manipulators date back to the 1960s and are some of the first robotic devices ever constructed. In these early days, robotic manipulation consisted of carefully prescribed movement sequences that a robot would execute with no ability to adapt to a changing environment. As time passed, robots gradually gained the ability to automatically generate movement sequences, drawing on artificial intelligence and automated reasoning. Robots would stack boxes according to size, weight, and so forth, extending beyond geometric reasoning. This task also required robots to handle errors and uncertainty in sensing at run time, given that the slightest imprecision in the position and orientation of stacked boxes might cause the entire tower to topple. Methods from control theory also became instrumental for enabling robots to comply with the environment’s natural uncertainty by empowering them to adapt exerted forces upon contact. The ability to stably vary forces upon contact expanded robots’ manipulation repertoire to more-complex tasks, such as inserting pegs in holes or hammering. However, none of these actions truly demonstrated fine or in-hand manipulation capabilities, and they were commonly performed using simple two-fingered grippers. To enable multipurpose fine manipulation, roboticists focused their efforts on designing humanlike hands capable of using tools. Wielding a tool in-hand became a problem of its own, and a variety of advanced algorithms were developed to facilitate stable holding of objects and provide optimality guarantees. Because optimality was difficult to achieve in a stochastic environment, from the 1990s onward researchers aimed to increase the robustness of object manipulation at all levels. These efforts initiated the design of sensors and hardware for improved control of hand–object contacts. Studies that followed were focused on robust perception for coping with object occlusion and noisy measurements, as well as on adaptive control approaches to infer an object’s physical properties, so as to handle objects whose properties are unknown or change as a result of manipulation. None ADVANCES None Roboticists are still working to develop robots capable of sorting and packaging objects, chopping vegetables, and folding clothes in unstructured and dynamic environments. Robots used for modern manufacturing have accomplished some of these tasks in structured settings that still require fences between the robots and human operators to ensure safety. Ideally, robots should be able to work side by side with humans, offering their strength to carry heavy loads while presenting no danger. Over the past decade, robots have gained new levels of dexterity. This enhancement is due to breakthroughs in mechanics with sensors for perceiving touch along a robot’s body and new mechanics for soft actuation to offer natural compliance. Most notably, this development leverages the immense progress in machine learning to encapsulate models of uncertainty and support further advances in adaptive and robust control. Learning to manipulate in real-world settings is costly in terms of both time and hardware. To further elaborate on data-driven methods but avoid generating examples with real, physical systems, many researchers use simulation environments. Still, grasping and dexterous manipulation require a level of reality that existing simulators are not yet able to deliver—for example, in the case of modeling contacts for soft and deformable objects. Two roads are hence pursued: The first draws inspiration from the way humans acquire interaction skills and prompts robots to learn skills from observing humans performing complex manipulation. This allows robots to acquire manipulation capabilities in only a few trials. However, generalizing the acquired knowledge to apply to actions that differ from those previously demonstrated remains difficult. The second road constructs databases of real object manipulation, with the goal to better inform the simulators and generate examples that are as realistic as possible. Yet achieving realistic simulation of friction, material deformation, and other physical properties may not be possible anytime soon, and real experimental evaluation will be unavoidable for learning to manipulate highly deformable objects. None OUTLOOK None Despite many years of software and hardware development, achieving dexterous manipulation capabilities in robots remains an open problem—albeit an interesting one, given that it necessitates improved understanding of human grasping and manipulation techniques. We build robots to automate tasks but also to provide tools for humans to easily perform repetitive and dangerous tasks while avoiding harm. Achieving robust and flexible collaboration between humans and robots is hence the next major challenge. Fences that currently separate humans from robots will gradually disappear, and robots will start manipulating objects jointly with humans. To achieve this objective, robots must become smooth and trustable partners that interpret humans’ intentions and respond accordingly. Furthermore, robots must acquire a better understanding of how humans interact and must attain real-time adaptation capabilities. There is also a need to develop robots that are safe by design, with an emphasis on soft and lightweight structures as well as control and planning methodologies based on multisensory feedback.",project-academic
,2018-08-23,a,,soter a runtime assurance framework for programming safe robotics systems," The recent drive towards achieving greater autonomy and intelligence in robotics has led to high levels of complexity. Autonomous robots increasingly depend on third party off-the-shelf components and complex machine-learning techniques. This trend makes it challenging to provide strong design-time certification of correct operation. 
To address these challenges, we present SOTER, a robotics programming framework with two key components: (1) a programming language for implementing and testing high-level reactive robotics software and (2) an integrated runtime assurance (RTA) system that helps enable the use of uncertified components, while still providing safety guarantees. SOTER provides language primitives to declaratively construct a RTA module consisting of an advanced, high-performance controller (uncertified), a safe, lower-performance controller (certified), and the desired safety specification. The framework provides a formal guarantee that a well-formed RTA module always satisfies the safety specification, without completely sacrificing performance by using higher performance uncertified components whenever safe. SOTER allows the complex robotics software stack to be constructed as a composition of RTA modules, where each uncertified component is protected using a RTA module. 
To demonstrate the efficacy of our framework, we consider a real-world case-study of building a safe drone surveillance system. Our experiments both in simulation and on actual drones show that the SOTER-enabled RTA ensures the safety of the system, including when untrusted third-party components have bugs or deviate from the desired behavior.",project-academic
10.1109/DSN.2019.00027,2019-06-24,p,IEEE,soter a runtime assurance framework for programming safe robotics systems," The recent drive towards achieving greater autonomy and intelligence in robotics has led to high levels of complexity. Autonomous robots increasingly depend on third-party off-the-shelf components and complex machine-learning techniques. This trend makes it challenging to provide strong design-time certification of correct operation. To address these challenges, we present SOTER, a robotics programming framework with two key components: (1) a programming language for implementing and testing high-level reactive robotics software, and (2) an integrated runtime assurance (RTA) system that helps enable the use of uncertified components, while still providing safety guarantees. SOTER provides language primitives to declaratively construct a RTA module consisting of an advanced, high-performance controller (uncertified), a safe, lower-performance controller (certified), and the desired safety specification. The framework provides a formal guarantee that a well-formed RTA module always satisfies the safety specification, without completely sacrificing performance by using higher performance uncertified components whenever safe. SOTER allows the complex robotics software stack to be constructed as a composition of RTA modules, where each uncertified component is protected using a RTA module. To demonstrate the efficacy of our framework, we consider a real-world case-study of building a safe drone surveillance system. Our experiments both in simulation and on actual drones show that the SOTER-enabled RTA ensures the safety of the system, including when untrusted third-party components have bugs or deviate from the desired behavior.",project-academic
10.1109/ROMAN.2011.6005223,2011-08-30,p,IEEE,effect of human guidance and state space size on interactive reinforcement learning," The Interactive Reinforcement Learning algorithm enables a human user to train a robot by providing rewards in response to past actions and anticipatory guidance to guide the selection of future actions. Past work with software agents has shown that incorporating user guidance into the policy learning process through Interactive Reinforcement Learning significantly improves the policy learning time by reducing the number of states the agent explores. We present the first study of Interactive Reinforcement Learning in real-world robotic systems. We report on four experiments that study the effects that teacher guidance and state space size have on policy learning performance. We discuss modifications made to apply Interactive Reinforcement Learning to a real-world system and show that guidance significantly reduces the learning rate, and that its positive effects increase with state space size.",project-academic
10.1109/HUMANOIDS.2018.8625038,2018-11-01,p,IEEE,nimbro op2x adult sized open source 3d printed humanoid robot," Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already open-source software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montreal, Canada, where it won all possible awards in the Humanoid AdultSize class.",project-academic
,2018-10-19,a,,nimbro op2x adult sized open source 3d printed humanoid robot," Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19 kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already open-source software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montr\'eal, Canada, where it won all possible awards in the Humanoid AdultSize class.",project-academic
10.1145/2157689.2157843,2012-03-05,p,ACM,human agent robot teamwork," Teamwork has become a widely accepted metaphor for describing the nature of multi-robot and multi-agent cooperation. By virtue of teamwork models, team members attempt to manage general responsibilities and commitments to each other in a coherent fashion that both enhances performance and facilitates recovery when unanticipated problems arise. Whereas early research on teamwork focused mainly on interaction within groups of autonomous agents or robots, there is a growing interest in leveraging human participation effectively. Unlike autonomous systems designed primarily to take humans out of the loop, many important applications require people, agents, and robots to work together in close and relatively continuous interaction. For software agents and robots to participate in teamwork alongside people in carrying out complex real-world tasks, they must have some of the capabilities that enable natural and effective teamwork among groups of people. Just as important, developers of such systems need tools and methodologies to assure that such systems will work together reliably and safely, even when they have been designed independently.The purpose of the HART workshop is to explore theories, methods, and tools in support of humans, agents and robots working together in teams. Position papers that combine findings from fields such as computer science, artificial intelligence, cognitive science, anthropology, social and organizational psychology, human-computer interaction to address the problem of HART are strongly encouraged. The workshop will formulate perspectives on the current state-of-the-art, identify key challenges and opportunities for future studies, and promote community-building among researchers and practitioners.The workshop will be structured around four two-hour sessions on themes relevant to HART. Each session will consist of presentations and questions on selected position papers, followed by a whole-group discussion of the current state-of-the-art and the key challenges and research opportunities relevant to the theme. During the final hour, the workshop organizers will facilitate a discussion to determine next steps. The workshop will be deemed a success when collaborative scientific projects for the coming year are defined, and publication venues are explored. For example, results from the most recent HART workshop (Lorentz Center, Leiden, The Netherlands, December 2010) will be reflected in a special issue of IEEE Intelligent Systems on HART that is slated to appear in January/February 2012.",project-academic
10.1007/S13740-018-0096-0,2019-06-01,a,Springer Berlin Heidelberg,automated planning for business process management," Business Process Management (BPM) is a central element of today’s organizations. Over the years, its main focus has been the support of business processes (BPs) in highly controlled domains. However—in the current era of Big Data and Internet-of-Things—several real-world domains are becoming cyber-physical (e.g., consider the shift from traditional manufacturing to Industry 4.0), characterized by ever-changing requirements, unpredictable environments and increasing amounts of data and events that influence the enactment of BPs. In such unconstrained settings, BPM professionals lack the needed knowledge to model all possible BP variants/contingencies at the outset. Consequently, BPM systems must increase their level of automation to provide the reactivity and flexibility necessary for process management. On the other hand, the Artificial Intelligence (AI) community has concentrated its efforts on investigating dynamic domains that involve active control of computational entities and physical devices (e.g., robots, software agents). In this context, automated planning, which is one of the oldest areas in AI, is conceived as a model-based approach to synthesize autonomous behaviors in automated way from a model. In this paper, we discuss how automated planning techniques can be leveraged to enable new levels of automation and support for solving concrete problems in the BPM field that were previously tackled with hard-coded solutions. To this aim, we first propose a methodology that shows how a researcher/practitioner should approach the task of encoding a concrete problem as an appropriate planning problem. Then, we discuss the required steps to integrate the planning technology in BPM environments. Finally, we show some concrete examples of the successful application of planning techniques to the different stages of the BPM life cycle.",project-academic
10.1109/MSMC.2018.2881233,2020-01-15,a,IEEE,cloud fog and mist computing advanced robot applications," As we are witnessing the dawn of the artificial intelligence revolution, it is a good time to discuss the system-architecture challenges of the new age of robotics. Most of the disputes are related to the wide variety of cloud-computing arrangements along the questions of why, with what, and how to exploit existing information technologies to cope effectively with the increasing demands. Traditional industrial robot makers are very conservative, relying exclusively on onboard execution. However, the rising user demand for advanced robot skills, such as dexterous manipulation and free navigation in an unstructured environment, has inspired newcomers to break with tradition and move robot software architecture to the next level. Inspired by the talks of Prof. Imre Rudas on cloud robotics, this article highlights some substantial factors of system design and discusses a real-world industrial example from my RaD practice.",project-academic
10.1007/BFB0095437,1998-09-15,p,"Springer, Berlin, Heidelberg",golex bridging the gap between logic golog and a real robot," The control of mobile robots acting autonomously in the real world is one of the long-term goals of the field of artificial intelligence. So far the field lacks methods bridging the gap between the sophisticated symbolic techniques to represent and reason about action and more and more reliable low-level robot control and navigation systems. In this paper we present GOLEX, an execution and monitoring system for the logic-based action language GOLOG and the complex and distributed RHINO control software which operates on RWI B21 and B14 mobile robots. GOLEX provides the following features: it maps abstract primitive actions into low-level commands of the robot control system, thus allowing the user to concentrate on the application rather than the inner workings of the robot; it monitors the execution of the primitive GOLOG actions, making it possible to detect simple execution failures and timeouts; and it includes means to deal with sensing and user input and to continue the operation appropriately. We present two different real-world applications in which GOLEX successfully operated a mobile robot in dynamic and even unstructured environments. These results suggest that the time is ripe for using symbolic action languages for mobile robot applications.",project-academic
10.1109/ICARSC.2018.8374189,2018-04-25,p,IEEE,a generic visual perception domain randomisation framework for gazebo," The impressive results of applying deep neural networks in tasks such as object recognition, language translation, and solving digital games are largely attributed to the availability of massive amounts of high quality labelled data. However, despite numerous promising steps in incorporating these techniques in robotic tasks, the cost of gathering data with a real robot has halted the proliferation of deep learning in robotics. In this work, a plugin for the Gazebo simulator is presented, which allows rapid generation of synthetic data. By introducing variations in simulator-specific or irrelevant aspects of a task, one can train a model which exhibits some degree of robustness against those aspects, and ultimately narrow the reality gap between simulated and real-world data. To show a use-case of the developed software, we build a new dataset for detection and localisation of three object classes: box, cylinder and sphere. Our results in the object detection and localisation task demonstrate that with small datasets generated only in simulation, one can achieve comparable performance to that achieved when training on real-world images.",project-academic
10.1109/LRA.2018.2870466,2018-10-01,p,IEEE,introduction to the special issue on ai for long term autonomy," The papers in this special section focus on the use of artificial intelligence (AI) for long term autonomy. Autonomous systems have a long history in the fields of AI and robotics. However, only through recent advances in technology has it been possible to create autonomous systems capable of operating in long-term, real-world scenarios. Examples include autonomous robots that operate outdoors on land, in air, water, and space; and indoors in offices, care homes, and factories. Designing, developing, and maintaining intelligent autonomous systems that operate in real-world environments over long periods of time, i.e. weeks, months, or years, poses many challenges. This special issue focuses on such challenges and on ways to overcome them using methods from AI. Long-term autonomy can be viewed as both a challenge and an opportunity. The challenge of long-term autonomy requires system designers to ensure that an autonomous system can continue operating successfully according to its real-world application demands in unstructured and semi-structured environments. This means addressing issues related to hardware and software robustness (e.g., gluing in screws and profiling for memory leaks), as well as ensuring that all modules and functions of the system can deal with the variation in the environment and tasks that is expected to occur over its operating time.",project-academic
,2021-09-22,a,,autonomous blimp control using deep reinforcement learning," Aerial robot solutions are becoming ubiquitous for an increasing number of tasks. Among the various types of aerial robots, blimps are very well suited to perform long-duration tasks while being energy efficient, relatively silent and safe. To address the blimp navigation and control task, in our recent work, we have developed a software-in-the-loop simulation and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, often resulting in large trajectory tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to changes in the ambient temperature and pressure. In the present paper, we explore a deep reinforcement learning (DRL) approach to address these issues. We train only in simulation, while keeping conditions as close as possible to the real-world scenario. We derive a compact state representation to reduce the training time and a discrete action space to enforce control smoothness. Our initial results in simulation show a significant potential of DRL in solving the blimp control task and robustness against moderate wind and parameter uncertainty. Extensive experiments are presented to study the robustness of our approach. We also openly provide the source code of our approach.",project-academic
,2013-01-01,a,,virtual humans a new toolkit for cognitive science research," Virtual Humans: A New Toolkit for Cognitive Science Research Jonathan Gratch (gratch@ict.usc.edu), Arno Hartholt (hartholt@ict.usc.edu), Morteza Dehghani (morteza@ict.usc.edu), Stacy Marsella (marsella@ict.usc.edu) Institute for Creative Technologies, University of Southern California 12015 Waterfront Drive, Playa Vista, CA 90094, USA Social Cognition: People interact socially through their bodies and VHs allow researchers to systematically examine and model the cognitions underlying social interaction. VHs can act as “virtual confederates” (Blascovich et al., 2002), allowing systematic manipulation of visual appearance, speech type, and contextual graphical environments. This makes VHs a convenient platform to isolate unique socio- cultural characteristics and realize them through simulation. Along with enhanced experimental control, ease of manipu- lations, consistency and controlled measurements, these features make VHs useful and reliable tools for studying social cognitions. In the tutorial, we will review several ex- amples, including how expressions of emotion by VHs can influence decision making in negotiations tasks and social dilemmas (e.g. de Melo et al., 2012; Dehghani et al., 2012); the role of accent in cultural cognition (Dehghani et al., 2012) and the role of rapport and gender in enhancing par- ticipants’ performance (Karacora et al., 2012). Keywords: Virtual humans, embodied cognition, social cog- nition, virtual confederates Tutorial Objectives Virtual humans (VHs) are digital anthropomorphic charac- ters that exist within virtual worlds but are designed to per- ceive, understand and interact with real-world humans. Alt- hough typically conceived as practical tools to assist in a range of application (e.g., HCI, training and entertainment), the technology is gaining interest as a methodological tool for studying human cognition. VHs not only simulate the cognitive abilities of people, but also many of the embodied and social aspects of human behavior more traditionally studied in fields outside of cognitive science. By integrating multiple cognitive capabilities (e.g., language, gesture, emo- tion, and the control problems associated with navigating and interacting with a simulated virtual world) and requiring these processes to support real-time interactions with peo- ple, VHs create a unique and challenging environment with- in which to develop and validate cognitive theories. In this tutorial, we will review recent advances in VH technologies, demonstrate examples of use of VHs in cognitive science research and provide hands on training using our Virtual Human Toolkit (http://vhtoolkit.ict.usc.edu/). The Virtual Human Toolkit The University of Southern California’s Institute for Crea- tive Technologies (ICT) is recognized as a leader in the de- velopment of VH technology (Gratch et al., 2002) and in applying this research to application domains including “vir- tual role players” for interpersonal-skills training (e.g., Campbell et al. 2011), informal science education (e.g. Swartout et al., 2010), intelligent tutoring, (e.g. Lane et al., 2011), and as “virtual confederates” to study cognitive and social processes (e.g. de Melo et al., 2012; Dehghani et al., 2012). One goal of the institute is to foster research in VH by making this technology freely available for research pur- poses through the Virtual Human Toolkit. The research underlying the toolkit draws heavily on cognitive science research. For example, VH “brains” are inspired by psychological theories of human cognition (e.g. Swartout, Gratch et al., 2006), language (e.g. Traum, 2008) and emotion (Gratch & Marsella, 2005), VH bodies are in- formed by knowledge of physiological and biomechanical processes (e.g. Honglun, et al. 2007; Thiebaux et al., 2008) and the relation between the VH’s brain and body is in- formed by social psychology research (Lee & Marsella, 2006, Wang et al, 2013). Translating these theories and findings into working software requires the integration of advanced capabilities from a number of domains of comput- er science research including machine perception, artificial intelligence, cognitive modeling, graphics and animation. The complexity of creating a VH can appear daunting. Fortunately, considerable research has focused on the de- Virtual Humans and Cognitive Science In helping to define the field of cognitive science, Herb Si- mon emphasized the importance of “understanding by simu- lating” (Simon 1969, 17-22). From the perspective of cogni- tive science, VHs provide the opportunity to understand the mind by simulating the body. Although still limited in their capabilities, VHs combine a rich set of capabilities for ex- ploring how cognitive processes manage interactions with the physical and social world. In this sense, they comple- ment recent interest in robotics as a tool for cognitive sci- ence, and address many of the limitations of physical robots. Embodied Cognition: Embodied theories argue that the brain and body are tightly linked: the configuration and state of one’s body profoundly influence cognitive processes and vice versa. For example, posture can impact how easily we are persuaded (Petty, et al. 1983); gestures and language are closely coupled, often grounded in shared metaphors (McNeill 2005); and facial expressions can influence our emotions (Niedenthal, et al., 2010). VH technology is in- creasingly used to unpack this relationship between mind and body (e.g., Sprague, et al., 2007) and in the tutorial we will review research in this growing area.",project-academic
10.5555/378613.378656,2001-04-20,p,Consortium for Computing Sciences in Colleges,facilitating active learning with inexpensive mobile robots," Our educational system must nurture a student's ability to acquire knowledge. Research has proven that active learning, learning promoted by interacting with one's environment, as opposed to lectures, is most effective in developing a students ability to acquire knowledge. In the computer science domain, active learning can be facilitated by using mobile robots in a collaborative setting. We believe that a context-based, collaborative approach, combined with the excitement, motivation, and real-world experiences provided by a robot, provide a nearly optimal method of teaching students how to acquire knowledge about computer science. However, this methodology has not seen wide acceptance. In order to facilitate the use of robots we have developed an inexpensive wheeled robot that uses common parts and requires only a simple set of tools for assembly. An abstracted Java interface allows students to interact with the robot from any desktop computer using the simple commands provided. Additionally, students can develop sophisticated distributed software solutions that require only simple changes to the interface, and development of software for both the embedded microcontroller and desktop machine. Our approach makes a wide variety of robot-based projects accessible to all level of courses, and for even the smallest computer science departments.",project-academic
10.1007/978-3-030-20467-9_8,2019-07-24,a,"Springer, Cham",a nursing robot for social interactions and health assessment," Social Robotics for nursing care gain increasing importance in the age of demographic change and fast development of artificial intelligence. Social robots are automated or autonomous machines capable of interacting with people on the basis of social rules and are mostly humanoid and mobile. The Cologne Cobots Lab (Cologne Cobots Lab is an interdisciplinary research lab of the TH Koln – University of Applied Sciences, with its main research focus in the areas of collaborative and social robotics) is currently carrying out research in social and cognitive robotics. In the context of nursing care, approaches for capturing emotions and the state of mind of patients through different interaction analytics will be developed. We will use the humanoid robot pepper and extend its software functions so that it can take initiatives in human-machine-conversation. We conduct different user-centered experiments in real-world conditions and investigate the verbal interactions among human users and the robot system. In this regard, it would be both valuable and interesting to find out whether an AI enabled humanoid robot is able to stimulate or encourage conversation or even perform better than a natural conversation partner.",project-academic
,1999-01-01,a,Springer,isr an intelligent service robot," A major challenge in mobile robotics is integration of methods into operational autonomous systems. Construction of such systems requires use of methods from perception, control engineering, software engineering, mathematical modelling, and artificial intelligence. In this paper it is described how such a variety of methods have been integrated to provide an autonomous service robot system that can carry out fetch-and-carry type missions. The system integrates sensory information from sonars, laser scanner, and computer vision to allow navigation and human-computer interaction through the use of a hybrid deliberative architecture. The paper presents the underlying objectives, the underlying architecture, and the needed behaviours. Throughout the paper, examples from real-world evaluation of the system are presented.",project-academic
10.1007/10705474_16,1998-09-28,p,"Springer, Berlin, Heidelberg",isr an intelligent service robot," A major challenge in mobile robotics is integration of methods into operational autonomous systems. Construction of such systems requires use of methods from perception, control engineering, software engineering, mathematical modelling, and artificial intelligence. In this paper it is described how such a variety of methods have been integrated to provide an autonomous service robot system that can carry out fetch-and-carry type missions. The system integrates sensory information from sonars, laser scanner, and computer vision to allow navigation and human-computer interaction through the use of a hybrid deliberative architecture. The paper presents the underlying objectives, the underlying architecture, and the needed behaviours. Throughout the paper, examples from real-world evaluation of the system are presented.",project-academic
10.3390/S20051500,2020-03-09,a,Multidisciplinary Digital Publishing Institute,towards iot aided human robot interaction using nep and ros a platform independent accessible and distributed approach," This article presents the novel Python, C# and JavaScript libraries of Node Primitives (NEP), a high-level, open, distributed, and component-based framework designed to enable easy development of cross-platform software architectures. NEP is built on top of low-level, high-performance and robust sockets libraries (ZeroMQ and Nanomsg) and robot middlewares (ROS 1 and ROS 2). This enables platform-independent development of Human-Robot Interaction (HRI) software architectures. We show minimal code examples for enabling Publish/Subscribe communication between Internet of Things (IoT) and Robotics modules. Two user cases performed outside laboratories are briefly described in order to prove the technological feasibility of NEP for developing real-world applications. The first user case briefly shows the potential of using NEP for enabling the creation of End-User Development (EUD) interfaces for IoT-aided Human-Robot Interaction. The second user case briefly describes a software architecture integrating state-of-art sensory devices, deep learning perceptual modules, and a ROS -based humanoid robot to enable IoT-aided HRI in a public space. Finally, a comparative study showed better latency results of NEP over a popular state-of-art tool (ROS using rosbridge) for connecting different nodes executed in local-host and local area network (LAN).",project-academic
10.15607/RSS.2018.XIV.010,2018-06-26,p,Robotics: Science and Systems Foundation,sim to real learning agile locomotion for quadruped robots," Designing agile locomotion for quadruped robots often requires extensive expertise and tedious manual tuning. In this paper, we present a system to automate this process by leveraging deep reinforcement learning techniques. Our system can learn quadruped locomotion from scratch using simple reward signals. In addition, users can provide an open loop reference to guide the learning process when more control over the learned gait is needed. The control policies are learned in a physics simulator and then deployed on real robots. In robotics, policies trained in simulation often do not transfer to the real world. We narrow this reality gap by improving the physics simulator and learning robust policies. We improve the simulation using system identification, developing an accurate actuator model and simulating latency. We learn robust controllers by randomizing the physical environments, adding perturbations and designing a compact observation space. We evaluate our system on two agile locomotion gaits: trotting and galloping. After learning in simulation, a quadruped robot can successfully perform both gaits in the real world.",project-academic
,2018-04-27,a,,sim to real learning agile locomotion for quadruped robots," Designing agile locomotion for quadruped robots often requires extensive expertise and tedious manual tuning. In this paper, we present a system to automate this process by leveraging deep reinforcement learning techniques. Our system can learn quadruped locomotion from scratch using simple reward signals. In addition, users can provide an open loop reference to guide the learning process when more control over the learned gait is needed. The control policies are learned in a physics simulator and then deployed on real robots. In robotics, policies trained in simulation often do not transfer to the real world. We narrow this reality gap by improving the physics simulator and learning robust policies. We improve the simulation using system identification, developing an accurate actuator model and simulating latency. We learn robust controllers by randomizing the physical environments, adding perturbations and designing a compact observation space. We evaluate our system on two agile locomotion gaits: trotting and galloping. After learning in simulation, a quadruped robot can successfully perform both gaits in the real world.",project-academic
,2021-10-28,a,,from machine learning to robotics challenges and opportunities for embodied intelligence," Machine learning has long since become a keystone technology, accelerating science and applications in a broad range of domains. Consequently, the notion of applying learning methods to a particular problem set has become an established and valuable modus operandi to advance a particular field. In this article we argue that such an approach does not straightforwardly extended to robotics -- or to embodied intelligence more generally: systems which engage in a purposeful exchange of energy and information with a physical environment. In particular, the purview of embodied intelligent agents extends significantly beyond the typical considerations of main-stream machine learning approaches, which typically (i) do not consider operation under conditions significantly different from those encountered during training; (ii) do not consider the often substantial, long-lasting and potentially safety-critical nature of interactions during learning and deployment; (iii) do not require ready adaptation to novel tasks while at the same time (iv) effectively and efficiently curating and extending their models of the world through targeted and deliberate actions. In reality, therefore, these limitations result in learning-based systems which suffer from many of the same operational shortcomings as more traditional, engineering-based approaches when deployed on a robot outside a well defined, and often narrow operating envelope. Contrary to viewing embodied intelligence as another application domain for machine learning, here we argue that it is in fact a key driver for the advancement of machine learning technology. In this article our goal is to highlight challenges and opportunities that are specific to embodied intelligence and to propose research directions which may significantly advance the state-of-the-art in robot learning.",project-academic
,2019-11-23,a,,scalable sim to real transfer of soft robot designs," The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented---or, in some cases, entirely replaced---by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: this https URL",project-academic
10.1109/ROBOSOFT48309.2020.9116004,2020-05-01,p,IEEE,scalable sim to real transfer of soft robot designs," The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented—or, in some cases, entirely replaced—by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs",project-academic
,2020-02-01,a,,bail or jail judicial versus algorithmic decision making in the pretrial system," To date, there are approximately 60 risk assessment tools deployed in the criminal justice system. These tools aim to differentiate between low-, medium-, and high-risk defendants and to increase the likelihood that only those who pose a risk to public safety or are likely to flee are detained. Proponents of actuarial tools claim that these tools meant to eliminate human biases and to rationalize the decision-making process by summarizing all relevant information in a more efficient way than the human brain. Opponents of such tools fear that in the name of science, actuarial tools reinforce human biases, harm defendants’ rights and increase racial disparities in the system. The gap between the two camps has widened in the last few years, and policy makers are torn between the promises of technology to contribute to a more just system, and a growing movement that calls for the abolishment of the use of actuarial risk assessment tools in general, and machine learning-based tools in particular.

This paper examines the role that the technology play in this debate, and whether deploying AI in existing risk assessment tools realizes the fears hyped in the media or improves our criminal justice system? It focuses on the pretrial stage and examines in depth the seven most commonly used tools. Five of these tools are based on traditional regression analysis, and two have a certain machine-learning component. The paper concludes that, classifying pretrial risk assessment tools as AI-based tools creates the impression that sophisticated robots are taking over the courts and pushing judges from their jobs, but this is far from reality. Despite the hype, there are more similarities than differences between tools based on traditional regression analysis and tools based on machine learning. Robots have a long way to go before they can replace judges, and this is not the solution that this paper is arguing for. The long list of policy recommendations discussed in the last chapter, highlight the extensive work that needs to be done to ensure that risk assessment tools are both accurate and fair toward all members of society. These recommendations are beneficial regardless of the technique used; and especial attention is dedicated to assessing how machine learning would impact those recommendations. For example, the paper argues that detailing each one of the factors used in the tools, to include multiple options to choose from (not juts yes or no question), will be useful for both regression analysis and machine learning, but if machine learning is used, the final score could be more personalized and meaningful because of the ability to zoom in on the unique details of the individual case.",project-academic
10.7916/STLR.V21I2.6838,2020-07-29,a,,bail or jail judicial versus algorithmic decision making in the pretrial system," To date, there are approximately sixty risk assessment tools deployed in the criminal justice system. These tools aim to differentiate between low-, medium-, and high-risk defendants and to increase the likelihood that only those who pose a risk to public safety or who are likely to flee are detained. Proponents of actuarial tools claim that these tools are meant to eliminate human biases and to rationalize the decision-making process by summarizing all relevant information in a more efficient way than can the human brain. Opponents of such tools fear that in the name of science, actuarial tools reinforce human biases, harm defendants’ rights, and increase racial disparities in the system. The gap between the two camps has widened in the last few years. Policymakers are torn between the promise of technology to contribute to a more just system and a growing movement that calls for the abolishment of the use of actuarial risk assessment tools in general and the use of machine learning-based tools in particular.
This paper examines the role that technology plays in this debate and examines whether deploying artificial intelligence (“AI”) in existing risk assessment tools realizes the fears emphasized by opponents of automation or improves our criminal justice system. It focuses on the pretrial stage and examines in depth the seven most commonly used tools. Five of these tools are based on traditional regression analysis, and two have a machine-learning component. This paper concludes that classifying pretrial risk assessment tools as AI-based tools creates the impression that sophisticated robots are taking over the courts and pushing judges from their jobs, but that impression is far from reality. Despite the hype, there are more similarities than differences between tools based on traditional regression analysis and tools based on machine learning. Robots have a long way to go before they can replace judges, and this paper does not argue for replacement. The long list of policy recommendations discussed in the last chapter highlights the extensive work that needs to be done to ensure that risk assessment tools are both accurate and fair toward all members of society. These recommendations apply regardless of whether machine learning or regression analysis is used. Special attention is paid to assessing how machine learning would impact those recommendations. For example, this paper argues that carefully detailing each of the factors used in the tools and including multiple options to choose from (i.e., not just binary “yes-or-no” questions) will be useful for both regression analysis and machine learning. However, machine learning would likely lead to more personalized and meaningful scoring of criminal defendants because of the ability of machine learning techniques to “zoom in” on the unique details of each individual case.",project-academic
,2018-10-23,p,PMLR,sim to real transfer with neural augmented robot simulation," Despite the recent successes of deep reinforcement learning, teaching complex motor skills to a physical robot remains a hard problem. While learning directly on a real system is usually impractical, doing so in simulation has proven to be fast and safe. Nevertheless, because of the ""reality gap,"" policies trained in simulation often perform poorly when deployed on a real system. In this work, we introduce a method for training a recurrent neural network on the differences between simulated and real robot trajectories and then using this model to augment the simulator. This Neural-Augmented Simulation (NAS) can be used to learn control policies that transfer significantly better to real environments than policies learned on existing simulators. We demonstrate the potential of our approach through a set of experiments on the Mujoco simulator with added backlash and the Poppy Ergo Jr robot. NAS allows us to learn policies that are competitive with ones that would have been learned directly on the real robot.",project-academic
10.1145/3352460.3358253,2019-10-12,p,ACM,asv accelerated stereo vision system," Estimating depth from stereo vision cameras, i.e., ""depth from stereo"", is critical to emerging intelligent applications deployed in energy- and performance-constrained devices, such as augmented reality headsets and mobile autonomous robots. While existing stereo vision systems make trade-offs between accuracy, performance and energy-efficiency, we describe ASV, an accelerated stereo vision system that simultaneously improves both performance and energy-efficiency while achieving high accuracy. The key to ASV is to exploit unique characteristics inherent to stereo vision, and apply stereo-specific optimizations, both algorithmically and computationally. We make two contributions. Firstly, we propose a new stereo algorithm, invariant-based stereo matching (ISM), that achieves significant speedup while retaining high accuracy. The algorithm combines classic ""hand-crafted"" stereo algorithms with recent developments in Deep Neural Networks (DNNs), by leveraging the correspondence invariant unique to stereo vision systems. Secondly, we observe that the bottleneck of the ISM algorithm is the DNN inference, and in particular the deconvolution operations that introduce massive compute-inefficiencies. We propose a set of software optimizations that mitigate these inefficiencies. We show that with less than 0.5% hardware area overhead, these algorithmic and computational optimizations can be effectively integrated within a conventional DNN accelerator. Overall, ASV achieves 5× speedup and 85% energy saving with 0.02% accuracy loss compared to today's DNN-based stereo vision systems.",project-academic
10.1109/ICRA40945.2020.9196754,2020-05-01,p,Institute of Electrical and Electronics Engineers Inc.,helping robots learn a human robot master apprentice model using demonstrations via virtual reality teleoperation," As artificial intelligence becomes an increasingly prevalent method of enhancing robotic capabilities, it is important to consider effective ways to train these learning pipelines and to leverage human expertise. Working towards these goals, a master-apprentice model is presented and is evaluated during a grasping task for effectiveness and human perception. The apprenticeship model augments self-supervised learning with learning by demonstration, efficiently using the human’s time and expertise while facilitating future scalability to supervision of multiple robots; the human provides demonstrations via virtual reality when the robot cannot complete the task autonomously. Experimental results indicate that the robot learns a grasping task with the apprenticeship model faster than with a solely self-supervised approach and with fewer human interventions than a solely demonstration-based approach; 100% grasping success is obtained after 150 grasps with 19 demonstrations. Preliminary user studies evaluating workload, usability, and effectiveness of the system yield promising results for system scalability and deployability. They also suggest a tendency for users to overestimate the robot’s skill and to generalize its capabilities, especially as learning improves.",project-academic
10.1038/S42256-020-0161-X,2020-03-01,a,Nature Publishing Group,human ownership of artificial creativity," Advances in generative algorithms have enhanced the quality and accessibility of artificial intelligence (AI) as a tool in building synthetic datasets. By generating photorealistic images and videos, these networks can pose a major technological disruption to a broad range of industries from medical imaging to virtual reality. However, as artwork developed by generative algorithms and cognitive robotics enters the arena, the notion of human-driven creativity has been thoroughly tested. When creativity is automated by the programmer, in a style determined by the trainer, using features from information available in public and private datasets, who is the proprietary owner of the rights in AI-generated artworks and designs? This Perspective seeks to provide an answer by systematically exploring the key issues in copyright law that arise at each phase of artificial creativity, from programming to deployment. Ultimately, four guiding actions are established for artists, programmers and end users that utilize AI as a tool such that they may be appropriately awarded the necessary proprietary rights. As artists are beginning to employ deep learning techniques to create new and interesting art, questions arise about how copyright and ownership apply to those works. This Perspective discusses how artists, programmers and users can ensure clarity about the ownership of their creations.",project-academic
,2019-03-02,a,,robot learning via human adversarial games," Much work in robotics has focused on ""human-in-the-loop"" learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",project-academic
10.1109/IROS40897.2019.8968306,2019-11-01,p,Institute of Electrical and Electronics Engineers Inc.,robot learning via human adversarial games," Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",project-academic
10.1007/S43154-021-00048-3,2021-06-01,a,Springer International Publishing,multi agent systems for search and rescue applications," The goal of this review is to evaluate the current status of multi-robot systems in the context of search and rescue. This includes an investigation of their current use in the field, what major technical challenge areas currently preclude more widespread use, and which key topics will drive future development and adoption. Work blending machine learning with classical control techniques is driving progress in perception-driven autonomy, decentralized multi-robot coordination, and human–robot interaction, among others. Ad hoc mesh networking has achieved reliability suitable for safety-critical applications and may be a partial solution for communication. New modular and multimodal platforms may overcome mobility limitations without significantly increasing cost. Multi-agent systems are not currently ready for deployment in search and rescue applications; however, progress is being made in a number of critical domains. As the field matures, research should focus on realistic evaluations of constituent technologies, and on confronting the challenges of simulation-to-reality transfer, algorithmic bias in autonomous agents that rely on machine learning, and novelty-versus-reliability incentive mismatch",project-academic
10.1017/CBO9781316597873.004,2016-08-01,a,Cambridge University Press,human machine autonomies," We are responsible for the world of which we are a part, not because it is an arbitrary construction of our choosing but because reality is sedimented out of particular practices that we have a role in shaping and through which we are shaped. None Karen Barad, None Meeting the Universe Halfway None None None None None None None None None None None None None None None None None None None None None None None None None None [R]esearch and development in automation are advancing from a state of automatic systems requiring human control toward a state of autonomous systems able to make decisions and react without human interaction. DoD will continue to carefully consider the implications of these advancements. None US Department of Defense, None Unmanned Systems Integrated Roadmap None None None None None None None None None None None None None None None None None None None None None None None None None This chapter takes up the question of how we might think about the increasing automation of military systems not as an inevitable ‘advancement’ of which we are the interested observers, but rather as an effect of particular world-making practices in which we need urgently to intervene. We begin from the premise that the foundation of the legality of killing in situations of war is the possibility of discrimination between combatants and non-combatants. At a time when this defining form of situational awareness seems increasingly problematic, military investments in the automation of weapon systems are growing. The trajectory of these investments, moreover, is towards the development and deployment of lethal autonomous weapons – that is, weapon systems in which the identification of targets and the initiation of fire is automated in ways that preclude deliberative human intervention. Challenges to these developments underscore the immorality and illegality of delegating responsibility for the use of force against human targets to machines, and the requirements of international humanitarian law that there be (human) accountability for acts of killing. In these debates, the articulation of differences between humans and machines is key. None The aim of this chapter is to strengthen arguments against the increasing automation of weapon systems, by expanding the frame or unit of analysis that informs these debates. We begin by tracing the genealogy of concepts of autonomy within the philosophical traditions that animate artificial intelligence, with a focus on the history of early cybernetics and contemporary approaches to machine learning in behaviour-based robotics.",project-academic
10.1016/B978-0-12-816176-0.00045-4,2020-01-01,c,Academic Press,challenges in computer assisted interventions challenges in design development evaluation and clinical deployment of computer assisted intervention solutions," Abstract None None None None Challenges in design, implementation, clinical evaluation, and deployment of computer assisted intervention solutions are manifold. Some of these challenges will be discussed in this chapter. None Computer assistance in both surgical procedures and radiology interventions aim at augmenting the clinicians with the overall objective of providing better clinical outcome. Multimodal imaging, robotics, artificial intelligence, and augmented reality play a major role in computer assisted interventions. After a brief analysis of the state-of-the-art and practice in this field, we discuss the challenges in design and development, as well as translation and deployment of the technology, from research projects motivated by clinical needs to solutions routinely used within clinical setups. We also consider the required training of surgeons and the surgical team as a major component for smooth and successful translation. We present simulation as an important tool not only for the design and development of computer assisted intervention solutions but also in their fast and smooth translation into daily practice.",project-academic
10.1016/J.NEUCOM.2020.10.097,2021-03-21,a,Elsevier,3d rvp a method for 3d object reconstruction from a single depth view using voxel and point," Abstract None None Three-dimensional object reconstruction technology has a wide range of applications such as augment reality, virtual reality, industrial manufacturing and intelligent robotics. Although deep learning-based 3D object reconstruction technology has developed rapidly in recent years, there remain important problems to be solved. One of them is that the resolution of reconstructed 3D models is hard to improve because of the limitation of memory and computational efficiency when deployed on resource-limited devices. In this paper, we propose 3D-RVP to reconstruct a complete and accurate 3D geometry from a single depth view, where R, V and P represent Reconstruction, Voxel and Point, respectively. It is a novel two-stage method that combines a 3D encoder-decoder network with a point prediction network. In the first stage, we propose a 3D encoder-decoder network with residual learning to output coarse prediction results. In the second stage, we propose an iterative subdivision algorithm to predict the labels of adaptively selected points. The proposed method can output high-resolution 3D models by increasing a small number of parameters. Experiments are conducted on widely used benchmarks of a ShapeNet dataset in which four categories of models are selected to test the performance of neural networks. Experimental results show that our proposed method outperforms the state-of-the-arts, and achieves about None None None None 2.7 None % None None None None improvement in terms of the intersection-over-union metric.",project-academic
,2014-03-31,a,,governing the ungovernable algorithms bots and threats to our information comfort zones," Laws, norms, policies, and institutions have failed to keep up with advances in artificial intelligence. Popularly, we still think of governance of these systems using quotes and metaphors from science fiction authors. The public awareness of the sophistication and capabilities of current systems are also skewed, often in extremes: predicting robot warfare and mind control or suffering complete naivete. Furthermore, the public often equates artificial intelligence with physical animatronics or other macro-embodiments like self-driving cars. 
The reality is one in which intelligent systems are embedded in more and more everyday products and services. The so-called “internet of things” represents a kind of ubiquitous computing that anticipates our needs and provides us information like time on daily commute without asking, in the case of Google Now, or adjusts the room temperature based on usage patterns, in the case of the Nest. More basically though, we see smarter algorithms powering seemingly neutral services like Google’s search engine or Facebook’s news feed. 
We are entering an era of personalization and technological service by means of machine learning. The concomitant effects of widespread intelligent systems are still unknown for the long-term, especially given that laws, norms, policies, and institutions will eventually develop. However in the near-term, we are already seeing the positive outcomes of convenience and superior service delivery overshadowed by problematic outcomes like censorship and privacy invasion. And beyond the consumer application of this technology, there exist weaponized versions in use by activists such as those under the banner of Anonymous, and states or terrorists pursuing toolkits for cyberwarfare. 
This panel will discuss the current capabilities and emerging trends in the deployment and use of intelligent systems, as well as the unique ethical, legal, and political challenges posed by them. We will explore the gaps that already exist in policies around issues like privacy and cyberwarfare, and how they are exacerbated by new intelligent systems and degrees of automation. Panelists will offer suggestions for policymakers, technology creators, and average users, as well as future research needs to advance the cause of effective governance around intelligent systems. 
SPEAKERS Erhardt Graeff (moderator) is a graduate student at the MIT Media Lab and MIT Center for Civic Media. He has studied and spoken about the civic potential of bots, as well as their privacy issues surrounding their commercial use. Erhardt holds an MPhil in Modern Society and Global Transformations from the University of Cambridge. 
Tim Hwang is a researcher of web communities, intelligent systems, and the economics of the Internet. He currently is principal investigator of the Social Architecture of Intelligent Systems project at the Data & Society Research Institute in New York. He has worked with the Mozilla Foundation, the Berkman Center for Internet and Society, the Electronic Frontier Foundation, Creative Commons, Google, Tumblr, and Imgur. He is also the co-founder of ROFLCon, a series of conferences on memes and internet culture. 
Kate Darling is a Research Specialist at the MIT Media Lab, and a Fellow at the Harvard Berkman Center for Internet & Society and the Yale Information Society Project. Her passion for technology and robots has led her to interdisciplinary fields: After co-teaching a robot ethics course at Harvard Law School, she now increasingly writes and lectures at the intersection of law and robotics, with focus on the legal impact of social issues. Kate holds a PhD in Intellectual Property at the ETH Zurich. 
Paulo Shakarian is a Major in the U.S. Army and an Assistant Professor in the Department of Electrical Engineering and Computer Science, U.S. Military Academy, West Point. Additionally, he is a Research Fellow with the West Point Network Science Center, as well as an Affiliate Scholar with the West Point Cyber Research Center. Paulo is also the primary investigator for the Algorithmic Network Science Group. He is the lead author of Introduction to Cyber-Warfare: A Multidisciplinary Approach. Paulo holds a Ph.D. in Computer Science from the University of Maryland, College Park. 
Kashmir Hill is a senior online editor at Forbes writing about privacy, technology and the law at The Not-So Private Parts. She has previously worked for the International Herald Tribune in Hong Kong; The Washington Examiner; the National Press Foundation; and Covington & Burling in Washington, D.C.",project-academic
10.1109/ICIP.2019.8803544,2019-09-01,p,IEEE,lightweight monocular depth estimation model by joint end to end filter pruning," Convolutional neural networks (CNNs) have emerged as the state-of-the-art in multiple vision tasks including depth estimation. However, memory and computing power requirements remain as challenges to be tackled in these models. Monocular depth estimation has significant use in robotics and virtual reality that requires deployment on low-end devices. Training a small model from scratch results in a significant drop in accuracy and it does not benefit from pre-trained large models. Motivated by the literature of model pruning, we propose a lightweight monocular depth model obtained from a large trained model. This is achieved by removing the least important features with a novel joint end-to-end filter pruning. We propose to learn a binary mask for each filter to decide whether to drop the filter or not. These masks are trained jointly to exploit relations between filters at different layers as well as redundancy within the same layer. We show that we can achieve around 5x compression rate with small drop in accuracy on the KITTI driving dataset. We also show that masking can improve accuracy over the baseline with fewer parameters, even without enforcing compression loss.",project-academic
10.1109/NAECON.2018.8556769,2018-07-23,p,IEEE,a rapid situational awareness development framework for heterogeneous manned unmanned teams," This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator.",project-academic
,2021-03-09,a,,decentralized circle formation control for fish like robots in the real world via reinforcement learning," In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",project-academic
10.1109/ICRA48506.2021.9562019,2021-05-30,p,IEEE,decentralized circle formation control for fish like robots in the real world via reinforcement learning," In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",project-academic
10.1016/J.IFACOL.2020.12.2306,2020-01-01,a,Elsevier,path following control of fish like robots a deep reinforcement learning approach," Abstract None None In this paper, we propose a deep reinforcement learning (DRL) approach for path-following control of a fish-like robot. The desired path may be a randomly generated Bezier curve. First, to implement the locomotion control of the fish-like robot, we design a modified Central Pattern Generated (CPG) model, using which the fish achieves varied swimming behaviors just by adjusting a single control input. To reduce the reality gap between simulation and the physical system, using the experimental data of the real fish-like robot, we build a surrogate simulation environment, which also well balances the accuracy and the speed of training. Second, for the path-following control, we select the advantage actor-critic (A2C) approach and train the control policy in the surrogate simulation environment with a straight line as the desired path. Then the trained control policy is directly deployed on a physical fish-like robot to follow a randomly generated Bezier curve. The experimental results show that our proposed approach has good practical applicability in view of its efficiency and feasibility in controlling the physical fishlike robot. This work shows a novel and promising way to control biomimetic underwater robots in the real world.",project-academic
10.1109/MC.2007.372,2007-11-01,a,IEEE,automated killers and the computing profession," When will we realize that our artificial-intelligence and autonomous-robotics research projects have been harnessed to manufacture killing machines? This is not terminator-style science fiction but grim reality: South Korea and Israel have both deployed armed robot border guards, while other nations-including China, India, Russia, Singapore, and the UK-increasingly use military robots. Fully autonomous robots that make their own decisions about lethality appear high on the US military agenda. They benefit the US military by enabling a single battlefield soldier to initiate a large-scale robot attack from the air or on the ground.",project-academic
10.1007/978-3-030-12719-0_1,2020-01-01,a,"Springer, Cham",introduction to digital health entrepreneurship," We are entering the new digital era of medicine where telemedicine, virtual reality, robotics, smartphones, and other technological advancements are slowly becoming part of regular healthcare practices. Digital health technology offers a way to change many of the current issues that the U.S. healthcare system faces. However, there is an urgent need for entrepreneurs, both in the healthcare field and non-related fields, to challenge the status quo, work together and forge ahead. Digital health entrepreneurship is the pursuit of opportunity under conditions of uncertainty with the goal of creating user defined value through the deployment of digital health innovations. The goal is to transform the medical field—improving patient outcomes, increasing quality of health care, improving the health professional experience and reducing costs. This book provides an overview of a large variety of topics ranging from artificial intelligence to regulatory affairs in digital health with the aim of helping digital health technologists, entrepreneurs, health care providers, investors, service providers and other stakeholders transform the healthcare system. This chapter will provide an overview of some of the drivers, trends, barriers and importance of digital health entrepreneurship.",project-academic
10.1109/IROS.2018.8593871,2018-05-04,p,IEEE,motion planning among dynamic decision making agents with deep reinforcement learning," Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.",project-academic
,2018-05-04,a,,motion planning among dynamic decision making agents with deep reinforcement learning," Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed, without the use of a 3D Lidar.",project-academic
10.5555/2484920.2484930,2013-05-06,p,International Foundation for Autonomous Agents and Multiagent Systems,humanoid robots learning to walk faster from the real world to simulation and back," Simulation is often used in research and industry as a low cost, high efficiency alternative to real model testing. Simulation has also been used to develop and test powerful learning algorithms. However, parameters learned in simulation often do not translate directly to the application, especially because heavy optimization in simulation has been observed to exploit the inevitable simulator simplifications, thus creating a gap between simulation and application that reduces the utility of learning in simulation.This paper introduces Grounded Simulation Learning (GSL), an iterative optimization framework for speeding up robot learning using an imperfect simulator. In GSL, a behavior is developed on a robot and then repeatedly: 1) the behavior is optimized in simulation; 2) the resulting behavior is tested on the real robot and compared to the expected results from simulation, and 3) the simulator is modified, using a machine-learning approach to come closer in line with reality. This approach is fully implemented and validated on the task of learning to walk using an Aldebaran Nao humanoid robot. Starting from a set of stable, hand-coded walk parameters, four iterations of this three-step optimization loop led to more than a 25% increase in the robot's walking speed.",project-academic
10.1145/2696454.2696491,2015-03-02,p,ACM,how robot verbal feedback can improve team performance in human robot task collaborations," We detail an approach to planning effective verbal feedback during pairwise human-robot task collaboration. The approach is motivated by social science literature as well as existing work in robotics and is applicable to a variety of task scenarios. It consists of a dynamic, synthetic task implemented in an augmented reality environment. The result is combined robot task control and speech production, allowing the robot to actively participate and communicate with its teammate. A user study was conducted to experimentally validate the efficacy of the approach on a task in which a single user collaborates with an autonomous robot. The results demonstrate that the approach is capable of improving both objective measures of team performance and the user’s subjective evaluation of both the task and the robot as a teammate. Categories and Subject Descriptors H.1.2 [Models and Principles]: User/Machine Systems—human factors, software psychology; H.5.2 [Information Interfaces and Presentation]: User Interfaces—evaluation/methodology, natural language; I.2.9 [Artificial Intelligence]: Robotics—operator interfaces",project-academic
,2017-10-20,,,human computer interaction system for upper limb rehabilitation training," The invention discloses a human-computer interaction system for upper limb rehabilitation training. The human-computer interaction system comprises an upper limb training robot which can implement rotating in a multi-dimension mode, an upper computer which is used for implementing information interaction with the upper limb training robot, and an interactive interface for displaying interaction information, wherein the upper limb training robot is provided with a detection device for capturing motion morphology of upper limbs; the upper computer comprises a virtual reality module for generating a virtual scene; the detection device is used for transmitting collected upper limb motion data signals to the upper computer in real time; and the upper computer is used for converting the data signals into real-time motion morphology characteristics through an artificial intelligence algorithm and for combining the motion morphology characteristics with the virtual scene, so that human-computer interaction is achieved. According to the human-computer interaction system for the upper limb rehabilitation training provided by the invention, the upper limb training robot and the upper computer are arranged and the upper computer is in charge of combining the motion characteristics of a trained object with the virtual scene which is established by the arranged virtual reality module, so that human-machine interaction is implemented, and interesting in a training process and initiative of training are enhanced.",project-academic
10.1109/ACCESS.2020.2996576,2020-05-22,a,IEEE,an embedded system for collection and real time classification of a tactile dataset," Tactile perception of the material properties in real-time using tiny embedded systems is a challenging task and of grave importance for dexterous object manipulation such as robotics, prosthetics and augmented reality. As the psychophysical dimensions of the material properties cover a wide range of percepts, embedded tactile perception systems require efficient signal feature extraction and classification techniques to process signals collected by tactile sensors in real-time. For this purpose, we developed two embedded systems, one that served as a vibrotactile stimulator system and one that recorded and classified the vibrotactile signals collected by its sensors. The quality of the collected data was first verified offline using Fourier transform for feature extraction and then applying powerful machine learning classifiers such as support vector machines and neural networks. We implemented the proposed memory-less signal feature extraction method in order to achieve real-time processing as the data is being collected. The experimental results have shown that the proposed method significantly reduces the computational complexity of feature extraction and still has led to high classification accuracy even when fed to the less complex classifiers such as random forests that can be easily implemented on embedded systems. Finally, we have also shown that low-cost, highly accurate, and real-time tactile texture classification can be achieved using the proposed approach with an ensemble of sensors.",project-academic
10.1007/S12553-016-0132-8,2016-05-27,a,Springer Berlin Heidelberg,cybercare 2 0 meeting the challenge of the global burden of disease in 2030," In this paper, we propose to advance and transform today's healthcare system using a model of networked health care called Cybercare. Cybercare means ""health care in cyberspace"" - for example, doctors consulting with patients via videoconferencing across a distributed network; or patients receiving care locally - in neighborhoods, ""minute clinics,"" and homes - using information technologies such as telemedicine, smartphones, and wearable sensors to link to tertiary medical specialists. This model contrasts with traditional health care, in which patients travel (often a great distance) to receive care from providers in a central hospital. The Cybercare model shifts health care provision from hospital to home; from specialist to generalist; and from treatment to prevention. Cybercare employs advanced technology to deliver services efficiently across the distributed network - for example, using telemedicine, wearable sensors and cell phones to link patients to specialists and upload their medical data in near-real time; using information technology (IT) to rapidly detect, track, and contain the spread of a global pandemic; or using cell phones to manage medical care in a disaster situation. Cybercare uses seven ""pillars"" of technology to provide medical care: genomics; telemedicine; robotics; simulation, including virtual and augmented reality; artificial intelligence (AI), including intelligent agents; the electronic medical record (EMR); and smartphones. All these technologies are evolving and blending. The technologies are integrated functionally because they underlie the Cybercare network, and/or form part of the care for patients using that distributed network. Moving health care provision to a networked, distributed model will save money, improve outcomes, facilitate access, improve security, increase patient and provider satisfaction, and may mitigate the international global burden of disease. In this paper we discuss how Cybercare is being implemented now, and envision its growth by 2030.",project-academic
10.1109/ACCESS.2019.2895653,2019-01-29,a,Institute of Electrical and Electronics Engineers (IEEE),high quality 3d reconstruction with depth super resolution and completion," The 3D reconstruction is an important topic in computer vision with many applications, such as robotics and augmented reality. Since the raw depth images captured by consumer RGB-D cameras are often low resolution (LR), noisy, and incomplete. How to obtain high-quality 3D models with a consumer RGB-D camera is still a challenge for the existing systems. In this paper, we propose a new depth super-resolution and completion method implemented in a deep learning framework and build a high-quality 3D reconstruction system. We first improve the resolution of LR depth image with a depth super-resolution network and remove the outliers in high-resolution (HR) depth image based on gradient saliency. To further enhance the quality of HR depth image with the guide of HR color image, we learn surface normal and occlusion boundary images from the corresponding HR color image through two deep fully convolutional networks. In particular, the blurriness of HR color image is also detected and pixel-wise quantized. Finally, we obtain a completed HR depth image by optimizing the HR depth image with the surface normal, occlusion boundary, and color image blurriness. We have carried out qualitative and quantitative evaluations with baseline methods on public datasets. The experimental results demonstrate that our method has better performance both on single depth image enhancement and 3D reconstruction.",project-academic
10.1080/08839514.2011.606767,2011-09-01,a,Taylor & Francis Group,a path planning method based on cellular automata for cooperative robots," A Cellular Automaton-based technique suitable for solving the path planning problem in a distributed robot team is outlined. Real-time path planning is a challenging task that has many applications in the fields of artificial intelligence, moving robots, virtual reality, and agent behavior simulation. The problem refers to finding a collision-free path for autonomous robots between two specified positions in a configuration area. The complexity of the problem increases in systems of multiple robots. More specifically, some distance should be covered by each robot in an unknown environment, avoiding obstacles found on its route to the destination. On the other hand, all robots must adjust their actions in order to keep their initial team formation immutable. Two different formations were tested in order to study the efficiency and the flexibility of the proposed method. Using different formations, the proposed technique could find applications to image processing tasks, swarm intelligence, etc. Furthermore, the presented Cellular Automaton (CA) method was implemented and tested in a real system using three autonomous mobile minirobots called E-pucks. Experimental results indicate that accurate collision-free paths could be created with low computational cost. Additionally, cooperation tasks could be achieved using minimal hardware resources, even in systems with low-cost robots.",project-academic
10.1007/978-3-319-95678-7_67,2018-03-21,p,"Springer, Cham",exposing robot learning to students in augmented reality experience," This paper considers a learning process in which the student teaches the robot new tasks, such as lifting unknown weights, via reinforcement learning procedure. Using CAD software, we ran virtual trials using the robot’s digital twin in place of physical robot trials. When performing the task, the robot measures and sends the value of the weight to an IoT controller implemented on the ThingWorx platform and receives parameters of the optimal posture found through the virtual trials. When we presented the robot learning process to high school students they had difficulty fully understanding the robot’s dynamics and selection of posture parameters. To address this difficulty, we developed an augmented reality interface which allows students to visualize robot postures on the digital twin and monitor the change in parameters (such as the center of gravity) measured by virtual sensors. The student can select a weightlifting posture and control the robot to implement it.",project-academic
10.1007/978-981-15-4474-3_31,2021-01-01,a,"Springer, Singapore",artificial intelligence prospect in mechanical engineering field a review," With the continuous progress of science and technology, the mechanical field is also constantly upgrading from traditional mechanical engineering to the mechatronics engineering and artificial intelligence (AI) is one of them. AI deals with a computer program that possesses own decision-making capability to solve a problem of interest with imitates the intelligent behavior of expertise which finally turns into higher productivity with better quality output. From the inception, various developments have been done on AI system which nowadays widely implemented in the mechanical and/or manufacturing industries with broaden area of application such as pattern recognition, automation, computer vision, virtual reality, diagnosis, image processing, nonlinear control, robotics, automated reasoning, data mining and process control systems. In this study, review attempt has been made for AI technologies used in various mechanical fields such as thermal, manufacturing, design, quality control and various connected fields of mechanical engineering. The study shows the blend mixed of AI technologies like deep convolutional neural network (DCNN), convolutional neural network (CNN), artificial neural network (ANN), fuzzy logic and many more to control the process parameters, process planning, machining, quality control and optimization in the mechanical era for smooth development of product or system. With the implementation of AI in mechanical engineering applications, the error, rejection of components can be minimized or eliminated and system optimization can be achieved effectively turn in economical better quality products.",project-academic
10.1109/CBS.2018.8612261,2018-10-01,p,IEEE,semg based torque estimation using time delay ann for control of an upper limb rehabilitation robot," Robotic-assisted rehabilitation of the upper limb following neurological injury can achieve best possible functional recovery when patients are engaged in the therapy. However, implementation of active training is still difficult as it’s challenging to detect human motion intention online and impose corresponding robot control. This paper introduces a novel upper-limb rehabilitation robot, and proposes a sEMG-driven (sEMG: surface Electromyography) torque estimation model based on artificial neural networks (ANN). The robot has three DOFs, of which the first two DOFs adopt a planar parallel structure, and the wrist module has an exoskeleton form. In this study, we design an impedance controller and an admittance controller for the first two DOFs and the wrist module, respectively. Specifically, for the first two DOFs, the assistance/resistance force at the end-effector was controlled according to its motions and desired interaction impedance; for the wrist module, an sEMG armband was used to collect 8 channels of sEMG signals from the forearm muscles, and a time-delay ANN model was developed to estimate the wrist pronation/supination torque, based on which the wrist rotation was controlled according to the human motion intention. To overcome the overfitting problem, besides the experimental samples of wrist rotation, both resting and co-contraction samples were collected for training. Finally, combining with the design of a virtual reality game and force fields, the proposed methods were implemented and tested experimentally on the upper-limb rehabilitation robot.",project-academic
10.1109/TETC.2017.2769705,2017-11-03,a,IEEE,robust robot tracking for next generation collaborative robotics based gaming environments," The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",project-academic
10.1007/S43154-021-00053-6,2021-06-01,a,Springer International Publishing,ethics of corporeal co present robots as agents of influence a review," To summarize the set of roboethics issues that uniquely arise due to the corporeality and physical interaction modalities afforded by robots, irrespective of the degree of artificial intelligence present in the system. One of the recent trends in the discussion of ethics of emerging technologies has been the treatment of roboethics issues as those of “embodied AI,” a subset of AI ethics. In contrast to AI, however, robots leverage human’s natural tendency to be influenced by our physical environment. Recent work in human-robot interaction highlights the impact a robot’s presence, capacity to touch, and move in our physical environment has on people, and helping to articulate the ethical issues particular to the design of interactive robotic systems. The corporeality of interactive robots poses unique sets of ethical challenges. These issues should be considered in the design irrespective of and in addition to the ethics of artificial intelligence implemented in them.",project-academic
,2018-02-01,a,,virtual to real learning to control in visual semantic segmentation," Collecting training data from the physical world is usually time-consuming and even dangerous for fragile robots, and thus, recent advances in robot learning advocate the use of simulators as the training platform. Unfortunately, the reality gap between synthetic and real visual data prohibits direct migration of the models trained in virtual worlds to the real world. This paper proposes a modular architecture for tackling the virtual-to-real problem. The proposed architecture separates the learning model into a perception module and a control policy module, and uses semantic image segmentation as the meta representation for relating these two modules. The perception module translates the perceived RGB image to semantic image segmentation. The control policy module is implemented as a deep reinforcement learning agent, which performs actions based on the translated image segmentation. Our architecture is evaluated in an obstacle avoidance task and a target following task. Experimental results show that our architecture significantly outperforms all of the baseline methods in both virtual and real environments, and demonstrates a faster learning curve than them. We also present a detailed analysis for a variety of variant configurations, and validate the transferability of our modular architecture.",project-academic
10.1093/OXFORDHB/9780199942237.001.0001,2014-12-02,b,Oxford University Press,the oxford handbook of affective computing," Affective Computing is a growing multidisciplinary field encompassing computer science, engineering, psychology, education, neuroscience, and many other disciplines. It explores how affective factors influence interactions between humans and technology, how affect sensing and affect generation techniques can inform our understanding of human affect, and on the design, implementation, and evaluation of systems that intricately involve affect at their core. The Oxford Handbook of Affective Computing will help both new and experienced researchers identify trends, concepts, methodologies, and applications in this burgeouning field. The volume features 41 chapters divided into five main sections: history and theory, detection, generation, methodologies, and applications. Section One begins with a look at the makings of AC and a historical review of the science of emotion. Chapters discuss the theoretical underpinnings of AC from an interdisciplinary perspective involving the affective, cognitive, social, media, and brain sciences. Section Two focuses on affect detection or affect recognition, which is one of the most commonly investigated areas in AC. Section Three examines aspects of affect generation including the synthesis of emotion and its expression via facial features, speech, postures and gestures. Cultural issues in affect generation are also discussed. Section Four features chapters on methodological issues in AC research, including data collection techniques, multimodal affect databases, emotion representation formats, crowdsourcing techniques, machine learning approaches, affect elicitation techniques, useful AC tools, and ethical issues in AC. Finally, Section Five highlights existing and future applications of AC in domains such as formal and informal learning, games, robotics, virtual reality, autism research, healthcare, cyberpsychology, music, deception, reflective writing, and cyberpsychology.With chapters authored by world leaders in each area, The Oxford Handbook of Affective Computing is suitable for use as a textbook in undergraduate or graduate courses in AC, and will serve as a valuable resource for students, researchers, and practitioners across the globe.",project-academic
10.2139/SSRN.3855059,2020-01-01,a,,digital accounting trends of the future a behavioral analysis," The academic accounting literature usually applies a retrospective approach in capturing reality. Accounting topics are explored considering past implementation in the economic practice in a ‘backtesting’ approach. This is very much criticized outside academia, as academia may thereby miss the practical relevance due to this backward approach. Accounting in academia is said to therefore fail to treat real practical business issues on time as for lacking the intention to perform any predictive statements. Accounting is the language of business, however, the landscape of business is changing dramatically at breakneck speed with a technological disruption ongoing in the wake of the artificial intelligence, algorithms and robotics introduction into our contemporary economy. This paper intends to follow a prospective approach and future-oriented direction in attempting to predict the future of digital accounting. The main research question is how accounting will be impacted by digitalization and how will the dynamic business in reverse impact the future of accounting? The method applied is a qualitative. In a focus group, in which accounting experts were asked to brainstorm on future trends with regards to accounting, four mega trends were identified. Those four mega trends are: (1) Blockchain/Distributed Ledger Technology, (2) Big Data, (3) Agile organizational model and (4) artificial intelligence, which are analyzed applying a behavioral approach in this paper to assess from which accounting will be the most impacted and how. The discussion reflects on the fact that the digital accounting revolution may be completely novel as – for the very first time in a historical line of economic disruptions and market innovations – this time decision making will be given up to algorithms. The results of this conceptual paper are structured applying Scott’s model of Financial accounting to the four mega trends. The final outlook projects the need for measuring economic growth differently and legally prepare for a preponderance of artificial agents. The paper is of unprecedented value in a current market of rising corporate debt as the outlook can aid the integration of novel economic growth features derived from the new economy that are not accounted for in neither standard economic growth theory nor accounting standards.",project-academic
10.3390/SYM11040496,2019-04-05,a,Multidisciplinary Digital Publishing Institute,an automated training of deep learning networks by 3d virtual models for object recognition," Small series production with a high level of variability is not suitable for full automation. So, a manual assembly process must be used, which can be improved by cooperative robots and assisted by augmented reality devices. The assisted assembly process needs reliable object recognition implementation. Currently used technologies with markers do not work reliably with objects without distinctive texture, for example, screws, nuts, and washers (single colored parts). The methodology presented in the paper introduces a new approach to object detection using deep learning networks trained remotely by 3D virtual models. Remote web application generates training input datasets from virtual 3D models. This new approach was evaluated by two different neural network models (Faster RCNN Inception v2 with SSD, MobileNet V2 with SSD). The main advantage of this approach is the very fast preparation of the 2D sample training dataset from virtual 3D models. The whole process can run in Cloud. The experiments were conducted with standard parts (nuts, screws, washers) and the recognition precision achieved was comparable with training by real samples. The learned models were tested by two different embedded devices with an Android operating system: Virtual Reality (VR) glasses, Cardboard (Samsung S7), and Augmented Reality (AR) smart glasses (Epson Moverio M350). The recognition processing delays of the learned models running in embedded devices based on an ARM processor and standard x86 processing unit were also tested for performance comparison.",project-academic
10.1109/JPROC.2018.2856739,2018-08-14,a,IEEE,navigating the landscape for real time localization and mapping for robotics and virtual and augmented reality," Visual understanding of 3-D environments in real time, at low power, is a huge computational challenge. Often referred to as simultaneous localization and mapping (SLAM), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, and virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are: 1) tools and methodology for systematic quantitative evaluation of SLAM algorithms; 2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives; 3) end-to-end simulation tools to enable optimization of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches; and 4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",project-academic
,2019-03-06,a,,the ai driving olympics at neurips 2018," Despite recent breakthroughs, the ability of deep learning and reinforcement learning to outperform traditional approaches to control physically embodied robotic agents remains largely unproven. To help bridge this gap, we created the 'AI Driving Olympics' (AI-DO), a competition with the objective of evaluating the state of the art in machine learning and artificial intelligence for mobile robotics. Based on the simple and well specified autonomous driving and navigation environment called 'Duckietown', AI-DO includes a series of tasks of increasing complexity -- from simple lane-following to fleet management. For each task, we provide tools for competitors to use in the form of simulators, logs, code templates, baseline implementations and low-cost access to robotic hardware. We evaluate submissions in simulation online, on standardized hardware environments, and finally at the competition event. The first AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems (NeurIPS) conference in December 2018. The results of AI-DO 1 highlight the need for better benchmarks, which are lacking in robotics, as well as improved mechanisms to bridge the gap between simulation and reality.",project-academic
10.1007/978-3-030-29135-8_3,2020-01-01,p,Springer,the ai driving olympics at neurips 2018," Despite recent breakthroughs, the ability of deep learning and reinforcement learning to outperform traditional approaches to control physically embodied robotic agents remains largely unproven. To help bridge this gap, we present the “AI Driving Olympics” (AI-DO), a competition with the objective of evaluating the state of the art in machine learning and artificial intelligence for mobile robotics. Based on the simple and well-specified autonomous driving and navigation environment called “Duckietown,” the AI-DO includes a series of tasks of increasing complexity—from simple lane-following to fleet management. For each task, we provide tools for competitors to use in the form of simulators, logs, code templates, baseline implementations and low-cost access to robotic hardware. We evaluate submissions in simulation online, on standardized hardware environments, and finally at the competition event. The first AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems (NeurIPS) conference in December 2018. In this paper we will describe the AI-DO 1 including the motivation and design objections, the challenges, the provided infrastructure, an overview of the approaches of the top submissions, and a frank assessment of what worked well as well as what needs improvement. The results of AI-DO 1 highlight the need for better benchmarks, which are lacking in robotics, as well as improved mechanisms to bridge the gap between simulation and reality. 
Open image in new window",project-academic
10.1007/S00345-019-03037-6,2020-10-01,a,Springer Berlin Heidelberg,artificial intelligence and robotics a combination that is changing the operating room," The aim of the current narrative review was to summarize the available evidence in the literature on artificial intelligence (AI) methods that have been applied during robotic surgery. A narrative review of the literature was performed on MEDLINE/Pubmed and Scopus database on the topics of artificial intelligence, autonomous surgery, machine learning, robotic surgery, and surgical navigation, focusing on articles published between January 2015 and June 2019. All available evidences were analyzed and summarized herein after an interactive peer-review process of the panel. The preliminary results of the implementation of AI in clinical setting are encouraging. By providing a readout of the full telemetry and a sophisticated viewing console, robot-assisted surgery can be used to study and refine the application of AI in surgical practice. Machine learning approaches strengthen the feedback regarding surgical skills acquisition, efficiency of the surgical process, surgical guidance and prediction of postoperative outcomes. Tension-sensors on the robotic arms and the integration of augmented reality methods can help enhance the surgical experience and monitor organ movements. The use of AI in robotic surgery is expected to have a significant impact on future surgical training as well as enhance the surgical experience during a procedure. Both aim to realize precision surgery and thus to increase the quality of the surgical care. Implementation of AI in master–slave robotic surgery may allow for the careful, step-by-step consideration of autonomous robotic surgery.",project-academic
10.1109/JPROC.2018.2856739,2018-08-20,a,,navigating the landscape for real time localisation and mapping for robotics and virtual and augmented reality," Visual understanding of 3D environments in real-time, at low power, is a huge computational challenge. Often referred to as SLAM (Simultaneous Localisation and Mapping), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are (1) tools and methodology for systematic quantitative evaluation of SLAM algorithms, (2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives, (3) end-to-end simulation tools to enable optimisation of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches, and (4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",project-academic
10.1016/J.JNS.2020.117081,2020-11-15,a,Elsevier,new technologies and amyotrophic lateral sclerosis which step forward rushed by the covid 19 pandemic," Amyotrophic Lateral Sclerosis (ALS) is a fast-progressive neurodegenerative disease leading to progressive physical immobility with usually normal or mild cognitive and/or behavioural involvement. Many patients are relatively young, instructed, sensitive to new technologies, and professionally active when developing the first symptoms. Older patients usually require more time, encouragement, reinforcement and a closer support but, nevertheless, selecting user-friendly devices, provided earlier in the course of the disease, and engaging motivated carers may overcome many technological barriers. ALS may be considered a model for neurodegenerative diseases to further develop and test new technologies. From multidisciplinary teleconsults to telemonitoring of the respiratory function, telemedicine has the potentiality to embrace other fields, including nutrition, physical mobility, and the interaction with the environment. Brain-computer interfaces and eye tracking expanded the field of augmentative and alternative communication in ALS but their potentialities go beyond communication, to cognition and robotics. Virtual reality and different forms of artificial intelligence present further interesting possibilities that deserve to be investigated. COVID-19 pandemic is an unprecedented opportunity to speed up the development and implementation of new technologies in clinical practice, improving the daily living of both ALS patients and carers. The present work reviews the current technologies for ALS patients already in place or being under evaluation with published publications, prompted by the COVID-19 pandemic.",project-academic
10.1038/SREP27380,2016-06-07,a,Nature Publishing Group,virtual planning control and machining for a modular based automated factory operation in an augmented reality environment," This study presents a modular-based implementation of augmented reality to provide an immersive experience in learning or teaching the planning phase, control system, and machining parameters of a fully automated work cell. The architecture of the system consists of three code modules that can operate independently or combined to create a complete system that is able to guide engineers from the layout planning phase to the prototyping of the final product. The layout planning module determines the best possible arrangement in a layout for the placement of various machines, in this case a conveyor belt for transportation, a robot arm for pick-and-place operations, and a computer numerical control milling machine to generate the final prototype. The robotic arm module simulates the pick-and-place operation offline from the conveyor belt to a computer numerical control (CNC) machine utilising collision detection and inverse kinematics. Finally, the CNC module performs virtual machining based on the Uniform Space Decomposition method and axis aligned bounding box collision detection. The conducted case study revealed that given the situation, a semi-circle shaped arrangement is desirable, whereas the pick-and-place system and the final generated G-code produced the highest deviation of 3.83 mm and 5.8 mm respectively.",project-academic
10.3390/APP8020302,2018-02-19,a,Multidisciplinary Digital Publishing Institute,designing the mind of a social robot," Humans have an innate tendency to anthropomorphize surrounding entities and have always been fascinated by the creation of machines endowed with human-inspired capabilities and traits. In the last few decades, this has become a reality with enormous advances in hardware performance, computer graphics, robotics technology, and artificial intelligence. New interdisciplinary research fields have brought forth cognitive robotics aimed at building a new generation of control systems and providing robots with social, empathetic and affective capabilities. This paper presents the design, implementation, and test of a human-inspired cognitive architecture for social robots. State-of-the-art design approaches and methods are thoroughly analyzed and discussed, cases where the developed system has been successfully used are reported. The tests demonstrated the system’s ability to endow a social humanoid robot with human social behaviors and with in-silico robotic emotions.",project-academic
10.3390/BUILDINGS10110204,2020-11-01,a,MDPI AG,a systematic review of digital technology adoption in off site construction current status and future direction towards industry 4 0," Off-site construction (OSC) is known as an efficient construction method that could save time and cost, reduce waste of resources, and improve the overall productivity of projects. Coupled with digital technologies associated with the Industry 4.0 concept, OSC can offer a higher rate of productivity and safety. While there is a rich literature focusing on both OSC and Industry 4.0, the implementation of associated digital technologies in the OSC context has not been fully evaluated. This paper intends to evaluate the current literature of digital technology applications in OSC. Scientometric analyses and a systematic review were carried out evaluating fifteen typical digital technologies adopted by OSC projects, including building information modelling (BIM), radio frequency identification devices (RFID), global positioning systems (GPS), the Internet of Things (IoT), geographic information systems (GIS), sensors, augmented reality (AR), virtual reality (VR), photogrammetry, laser scanning, artificial intelligence (AI), 3D printing, robotics, big data, and blockchain. This review formulates a clear picture of the current practice of these digital technologies and summarizes the main area of application and limitations of each technology when utilized in OSC. The review also points out their potential and how they can be better adopted to improve OSC practice in the future.",project-academic
10.1109/ICRA40945.2020.9197443,2020-05-01,p,Institute of Electrical and Electronics Engineers (IEEE),aggressive online control of a quadrotor via deep network representations of optimality principles," Optimal control holds great potential to improve a variety of robotic applications. The application of optimal control on-board limited platforms has been severely hindered by the large computational requirements of current state of the art implementations. In this work, we make use of a deep neural network to directly map the robot states to control actions. The network is trained offline to imitate the optimal control computed by a time consuming direct nonlinear method. A mixture of time optimality and power optimality is considered with a continuation parameter used to select the predominance of each objective. We apply our networks (termed G&CNets) to aggressive quadrotor control, first in simulation and then in the real world. We give insight into the factors that influence the ‘reality gap’ between the quadrotor model used by the offline optimal control method and the real quadrotor. Furthermore, we explain how we set up the model and the control structure on-board of the real quadrotor to successfully close this gap and perform time-optimal maneuvers in the real world. Finally, G&CNet’s performance is compared to state-of-the-art differential-flatness-based optimal control methods. We show, in the experiments, that G&CNets lead to significantly faster trajectory execution due to, in part, the less restrictive nature of the allowed state-to-input mappings.",project-academic
10.4301/S1807-1775201916001,2019-01-17,a,TECSI Laboratório de Tecnologia e Sistemas de Informação - FEA/USP,the future digital work force robotic process automation rpa," The Robotic Process Automation (RPA) is a new wave of future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering, and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available on google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching of the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment, and onboarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor onboarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea.",project-academic
10.1007/S11721-014-0092-4,2014-03-12,a,Springer US,automode a novel approach to the automatic design of control software for robot swarms," We introduce AutoMoDe: a novel approach to the automatic design of control software for robot swarms. The core idea in AutoMoDe recalls the approach commonly adopted in machine learning for dealing with the bias–variance tradedoff: to obtain suitably general solutions with low variance, an appropriate design bias is injected. AutoMoDe produces robot control software by selecting, instantiating, and combining preexisting parametric modules—the injected bias. The resulting control software is a probabilistic finite state machine in which the topology, the transition rules and the values of the parameters are obtained automatically via an optimization process that maximizes a task-specific objective function. As a proof of concept, we define AutoMoDe-Vanilla, which is a specialization of AutoMoDe for the e-puck robot. We use AutoMoDe-Vanilla to design the robot control software for two different tasks: aggregation and foraging. The results show that the control software produced by AutoMoDe-Vanilla (i) yields good results, (ii) appears to be robust to the so called reality gap, and (iii) is naturally human-readable.",project-academic
10.1007/978-3-540-71541-2_7,2006-09-30,p,"Springer, Berlin, Heidelberg",communication in a swarm of miniature robots the e puck as an educational tool for swarm robotics," Swarm intelligence, and swarm robotics in particular, are reaching a point where leveraging the potential of communication within an artificial systempromises to uncover newand varied directions for interesting research without compromising the key properties of swarmintelligent systems such as self-organization, scalability, and robustness. However, the physical constraints of using radios in a robotic swarm are hardly obvious, and the intuitive models often used for describing such systems do not always capture them with adequate accuracy. In order to demonstrate this effectively in the classroom, certain tools can be used, including simulation and real robots. Most instructors currently focus on simulation, as it requires significantly less investment of time, money, and maintenance--but to really understand the differences between simulation and reality, it is also necessary to work with the real platforms from time to time. To our knowledge, our coursemay be the only one in the world where individual students are consistently afforded the opportunity to work with a networked multi-robot system on a tabletop. The e-Puck, a low-cost small-scale mobile robotic platform designed for educational use, allows us bringing real robotic hardware into the classroom in numbers sufficient to demonstrate and teach swarm-robotic concepts.We present here a custom module for local radio communication as a stackable extension board for the e-Puck, enabling information exchange between robots and also with any other IEEE 802.15.4-compatible devices. Transmission power can be modified in software to yield effective communication ranges as small as fifteen centimeters. This intentionally small range allows us to demonstrate interesting collective behavior based on local information and control in a limited amount of physical space, where ordinary radios would typically result in a completely connected network. Here we show the use of this module facilitating a collective decision among a group of 10 robots.",project-academic
10.1109/ACCESS.2016.2571058,2016-05-30,a,IEEE,a review of theoretical and practical challenges of trusted autonomy in big data," Despite the advances made in artificial intelligence, software agents, and robotics, there is little we see today that we can truly call a fully autonomous system. We conjecture that the main inhibitor for advancing autonomy is lack of trust. Trusted autonomy is the scientific and engineering field to establish the foundations and ground work for developing trusted autonomous systems (robotics and software agents) that can be used in our daily life, and can be integrated with humans seamlessly, naturally, and efficiently. In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus this paper on the trust component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three subtopics: 1) reviewing and positioning the trust modeling literature for the purpose of trusted autonomy; 2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and 3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enable trusted autonomous systems to become a reality. This paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner.",project-academic
,2016-03-01,a,,a review of theoretical and practical challenges of trusted autonomy in big data," Despite the advances made in artificial intelligence, software agents, and robotics, there is little we see today that we can truly call a fully autonomous system. We conjecture that the main inhibitor for advancing autonomy is lack of trust. Trusted autonomy is the scientific and engineering field to establish the foundations and ground work for developing trusted autonomous systems (robotics and software agents) that can be used in our daily life, and can be integrated with humans seamlessly, naturally and efficiently. In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus the paper on the `trust' component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three sub-topics: (1) reviewing and positioning the trust modelling literature for the purpose of trusted autonomy; (2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and (3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enables trusted autonomous systems to become a reality. The paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner.",project-academic
10.21037/JSS.2019.04.16,2019-06-01,a,J Spine Surg,the use of robotics in minimally invasive spine surgery," The field of spine surgery has changed significantly over the past few decades as once technological fantasy has become reality. The advent of stereotaxis, intra-operative navigation, endoscopy, and percutaneous instrumentation have altered the landscape of spine surgery. The concept of minimally invasive spine (MIS) surgery has blossomed over the past ten years and now robot-assisted spine surgery is being championed by some as another potential paradigm altering technological advancement. The application of robotics in other surgical specialties has been shown to be a safe and feasible alternative to the traditional, open approach. In 2004 the Mazor Spine Assist robot was approved by FDA to assist with placement of pedicle screws and since then, more advanced robots with promising clinical outcomes have been introduced. Currently, robotic platforms are limited to pedicle screw placement. However, there are centers investigating the role of robotics in decompression, dural closure, and pre-planned osteotomies. Robot-assisted spine surgery has been shown to increase the accuracy of pedicle screw placement and decrease radiation exposure to surgeons. However, modern robotic technology also has certain disadvantages including a high introductory cost, steep learning curve, and inherent technological glitches. Currently, robotic spine surgery is in its infancy and most of the objective evidence available regarding its benefits draws from the use of robots in a shared-control model to assist with the placement of pedicle screws. As artificial intelligence software and feedback sensor design become more sophisticated, robots could facilitate other, more complex surgical tasks such as bony decompression or dural closure. The accuracy and precision afforded by the current robots available for use in spinal surgery potentially allow for even less tissue destructive and more meticulous MIS surgery. This article aims to provide a contemporary review of the use of robotics in MIS surgery.",project-academic
10.1007/S005300050109,1999-01-01,a,"Springer-Verlag New York, Inc.",interactive environments for music and multimedia," Multimodal Environments (MEs) are systems capable of establishing creative, multimodal user interactionby exhibiting real-time adaptive behaviour. In a typical scenario, one or more users are immersed in an environmentallowing them to communicate by means of full-body movement, singing or playing. Users get feedback from the environment in real time in terms of sound, music, visual media,and actuators, i.e. movement of semi-autonomous mobilesystems including mobile scenography, on-stage robots behaving as actors or players, possibly equipped with musicand multimedia output. MEs are therefore a sort of extension of augmented reality environments. From another viewpoint, an ME can be seen as a sort of prolongation of thehuman mind and senses. From an artificial intelligence perspective, an ME consists of a population of physical andas software agents capable of changing their reactions andtheir social interaction over time. For example, a gesture ofthe user(s) can mean different things in different situations,and can produce changes in the agents populating the ME.The paradigm adopted for movement recognition is that ofa human observer of the dance, where the focus of attentionchanges according to the evolution of the dance itself andof the music produced. MEs are therefore agents able to observe the user, extract ""gesture gestalts"", and change theirstate, including artificial emotions, over time. MEs open newniches of application, many still to be discovered, includingmusic, dance, theatre, interactive arts, entertainment, interactive exhibitions and museal installations, information atelier, edutainment, training, industrial applications and cognitive rehabilitation (e.g. for autism). The environment canbe a theatre, a museum, a discotheque, a school classroom,a rehabilitation centre for patients with a variety of sensory/motor and cognitive impairments, etc. The ME conceptgeneralizes the bio-feedback methods which already havefound widespread applications. The paper introduces MEs,then a flexible ME architecture, with a special focus on themodeling of the emotional component of the agents formingan ME. Description of four applications we recently developed, currently used in several real testbeds, conclude thepaper.",project-academic
10.1007/978-90-481-9151-2,2010-07-12,b,"Springer Publishing Company, Incorporated",technological developments in networking education and automation," Technological Developments in Networking, Education and Automation includes a set of rigorously reviewed world-class manuscripts addressing and detailing state-of-the-art research projects in the following areas: Computer Networks: Access Technologies, Medium Access Control, Network architectures and Equipment, Optical Networks and Switching, Telecommunication Technology, and Ultra Wideband Communications. Engineering Education and Online Learning: including development of courses and systems for engineering, technical and liberal studies programs; online laboratories; intelligent testing using fuzzy logic; taxonomy of e-courses; and evaluation of online courses. Pedagogy: including benchmarking; group-learning; active learning; teaching of multiple subjects together; ontology; and knowledge management. Instruction Technology: including internet textbooks; virtual reality labs, instructional design, virtual models, pedagogy-oriented markup languages; graphic design possibilities; open source classroom management software; automatic email response systems; tablet-pcs; personalization using web mining technology; intelligent digital chalkboards; virtual room concepts for cooperative scientific work; and network technologies, management, and architecture. Coding and Modulation: Modeling and Simulation, OFDM technology , Space-time Coding, Spread Spectrum and CDMA Systems. Wireless technologies: Bluetooth , Cellular Wireless Networks, Cordless Systems and Wireless Local Loop, HIPERLAN, IEEE 802.11, Mobile Network Layer, Mobile Transport Layer, and Spread Spectrum. Network Security and applications: Authentication Applications, Block Ciphers Design Principles, Block Ciphers Modes of Operation, Electronic Mail Security, Encryption & Message Confidentiality, Firewalls, IP Security, Key Cryptography & Message Authentication, and Web Security. Robotics, Control Systems and Automation: Distributed Control Systems, Automation, Expert Systems, Robotics, Factory Automation, Intelligent Control Systems, Man Machine Interaction, Manufacturing Information System, Motion Control, and Process Automation. Vision Systems: for human action sensing, face recognition, and image processing algorithms for smoothing of high speed motion. Electronics and Power Systems: Actuators, Electro-Mechanical Systems, High Frequency Converters, Industrial Electronics, Motors and Drives, Power Converters, Power Devices and Components, and Power Electronics.",project-academic
10.1109/TASE.2019.2938316,2020-04-01,a,IEEE,semiautomatic labeling for deep learning in robotics," In this article, we propose an augmented reality semiautomatic labeling (ARS), a semiautomatic method which leverages on moving a 2-D camera by means of a robot, proving precise camera tracking, and an augmented reality pen (ARP) to define initial object bounding box, to create large labeled data sets with minimal human intervention. By removing the burden of generating annotated data from humans, we make the deep learning technique applied to computer vision, which typically requires very large data sets, truly automated and reliable. With the ARS pipeline, we created two novel data sets effortlessly, one on electromechanical components (industrial scenario) and other on fruits (daily-living scenario) and trained two state-of-the-art object detectors robustly, based on convolutional neural networks, such as you only look once (YOLO) and single shot detector (SSD). With respect to conventional manual annotation of 1000 frames that takes us slightly more than 10 h, the proposed approach based on ARS allows to annotate 9 sequences of about 35 000 frames in less than 1 h, with a gain factor of about 450. Moreover, both the precision and recall of object detection is increased by about 15% with respect to manual labeling. All our software is available as a robot operating system (ROS) package in a public repository alongside with the novel annotated data sets. None Note to Practitioners —This article was motivated by the lack of a simple and effective solution for the generation of data sets usable to train a data-driven model, such as a modern deep neural network, so as to make them accessible in an industrial environment. Specifically, a deep learning robot guidance vision system would require such a large amount of manually labeled images that it would be too expensive and impractical for a real use case, where system reconfigurability is a fundamental requirement. With our system, on the other hand, especially in the field of industrial robotics, the cost of image labeling can be reduced, for the first time, to nearly zero, thus paving the way for self-reconfiguring systems with very high performance (as demonstrated by our experimental results). One of the limitations of this approach is the need to use a manual method for the detection of objects of interest in the preliminary stages of the pipeline (ARP or graphical interface). A feasible extension, related to the field of collaborative robotics, could be used to exploit the robot itself, manually moved by the user, even for this preliminary stage, so as to eliminate any source of inaccuracy.",project-academic
,2020-01-22,a,,artificial intelligence in medicine and healthcare a review and classification of current and near future applications and their ethical and social impact," This paper provides an overview of the current and near-future applications of Artificial Intelligence (AI) in Medicine and Health Care and presents a classification according to their ethical and societal aspects, potential benefits and pitfalls, and issues that can be considered controversial and are not deeply discussed in the literature. 
This work is based on an analysis of the state of the art of research and technology, including existing software, personal monitoring devices, genetic tests and editing tools, personalized digital models, online platforms, augmented reality devices, and surgical and companion robotics. Motivated by our review, we present and describe the notion of 'extended personalized medicine', we then review existing applications of AI in medicine and healthcare and explore the public perception of medical AI systems, and how they show, simultaneously, extraordinary opportunities and drawbacks that even question fundamental medical concepts. Many of these topics coincide with urgent priorities recently defined by the World Health Organization for the coming decade. In addition, we study the transformations of the roles of doctors and patients in an age of ubiquitous information, identify the risk of a division of Medicine into 'fake-based', 'patient-generated', and 'scientifically tailored', and draw the attention of some aspects that need further thorough analysis and public debate.",project-academic
10.2139/SSRN.3015972,2017-08-09,a,,computational legal research and the advocates of the future," Artificial intelligence and machine learning grab headlines these days, and for good reason. Consider the remarkable developments that machine learning has made in the past decade. Many of us have come to expect instantaneous access to all of the world’s knowledge with search engines. Logistics companies use machine learning to optimize supply chains in ways that were unthinkable in years past. Online retailers make suggestions about what consumers might like to buy based on past browsing activity, generating billions in additional revenues annually. Autonomous vehicles are on the road in many jurisdictions and are predicted to be mainstream within the next ten years. In the legal realm, various popular and legal publications include headlines that use sci-fi terms like “robot lawyer” and sensationalize the use of computing power and algorithms in the legal profession. All of this appears to blend reality with science fiction, and to combine software engineering with hype and marketing bluster. 
Lawyers typically react to media accounts of these developments in one of two, polar opposite ways. Some confidently dismiss the hype around legal technology and take the position that artificial intelligence will never replicate precisely what they can do as advocates and so conclude that there is nothing at all that they should even consider changing about what they do and how they do it. Others are anxious about the advent of machine learning and artificial intelligence and what it might mean for their own work and the future of the profession more generally. This anxiety is fomented by a sense of helplessness: that there is nothing in particular that they feel they can do to prepare themselves for developments that have had and will continue have significant impact on other industries (e.g., transportation). Both reactions are understandable; each has some merit. Neither, however, captures the full story.",project-academic
10.1007/978-3-030-85469-0_19,2021-09-06,p,"Springer, Cham",from symbolic rpa to intelligent rpa challenges for developing and operating intelligent software robots," Robotic process automation (RPA) is a novel technology that automates tasks by interacting with other software through their respective user interfaces. The technology has received substantial business attention because of its potential for rapid automation of process-driven tasks that would otherwise require tedious manual labor. This article explores the dichotomy between the practical reality of symbolic RPA, which requires handcrafting robots using process models and rulesets, and the promise of intelligent RPA, which relies on artificial intelligence technology to implement intelligent robots. Our research is based on a scholarly literature review as well as an interview study to derive and discuss challenges for this transition. We found that issues such as the lack of training data, human bias in data, compliance issues with transfer learning, poor explainability of robot decisions, and job-security-induced fear of AI robots all need to be addressed to enable the transition from symbolic to intelligent RPA.",project-academic
10.1117/12.871196,2010-06-13,p,International Society for Optics and Photonics,electronics and telecommunications in poland issues and perspectives part iii innovativeness applications economy development scenarios politics," Electronics is under development in this country in an organized and institutional way since the beginning of 30-ties of the previous century. It grew up from electrical engineering of weak currents and its first name used popularly was communications. It was time when television was born and the radio was maturing. Electronics is a branch of research and technology which deals with generation and processing of electrical and electromagnetic signals. A subject of telecommunications is signal transmission for a distance. Electronics and telecommunications (ET) includes or is combined with other branches like: microelectronics, radioelectronics, optoelectronics, photonics, acoustoelectronics, magnetronics, bioelectronics, energoelectronics, material engineering, semiconductor physics, automation and robotics, mechatronics and microsystems, informatics, teleinformatics, software engineering and other. Devices and functional systems of ET such as computers, data warehouses, cell phones, TV sets, Internet, GPS are build of electronic components and circuits. ET is a branch which belongs to hi-tech area, where the products gather a large load of knowledge of value overcoming frequently the price of work and material. ET has recently turned to an active participant of the processes of generation, storing, processing, transportation, distribution and usage of knowledge in the society. ET started to create artificial intelligence, co-creates intellectual property, searches for knowledge in big data sets, aids medicine, extends virtual/augmented reality, builds Internet of persons and things, strengthens security, protects natural environment, facilitates our life, aids our decisions, activates individuals, equalizes chances, provides convenient personal communications and access to data, starts building a penetrating ubiquitous infrastructure, ceases to be only a branch of technology, grows into the social space, touches culture, sociology, psychology and art. Such an important role of ET is combined with the existence in the society of an adequate infrastructure which recreates the full development cycle of high technology embracing: people, institutions, finances and logistics, in this also science, higher education, education, continuous training, dissemination and outreach, professional social environment, legal basis, political support and lobbying, innovation structures, applications, industry and economy. The digest of chosen development tendencies in ET was made here from the academic perspective, in a wider scale and on this background the national one, trying to situate this branch in the society, determine its changing role to build a new technical infrastructure of a society based on knowledge, a role of builder of many practical gadgets facilitating life, a role of a big future integrator of today's single bricks into certain more useful unity. This digest does not have a character of a systematic analysis of ET. It is a kind of an arbitrary utterance of the authors inside their field of competence. The aim of this paper is to take an active part in the discussion of the academic community in this country on the development strategy of ET, choice of priorities for cyclically rebuilding economy, in competitive environments. The review paper was initiated by the Committee of Electronics and Telecommunications of Polish Academy of Sciences and was published in Polish as introductory chapter of a dedicated expertise, printed in a book format. This version makes the included opinions available for a wider community.",project-academic
10.1126/SCIROBOTICS.AAU5872,2019-01-16,a,American Association for the Advancement of Science (AAAS),learning agile and dynamic motor skills for legged robots," Legged robots pose one of the greatest challenges in robotics. Dynamic and agile maneuvers of animals cannot be imitated by existing methods that are crafted by humans. A compelling alternative is reinforcement learning, which requires minimal craftsmanship and promotes the natural evolution of a control policy. However, so far, reinforcement learning research for legged robots is mainly limited to simulation, and only few and comparably simple examples have been deployed on real systems. The primary reason is that training with real robots, particularly with dynamically balancing systems, is complicated and expensive. In the present work, we introduce a method for training a neural network policy in simulation and transferring it to a state-of-the-art legged system, thereby leveraging fast, automated, and cost-effective data generation schemes. The approach is applied to the ANYmal robot, a sophisticated medium-dog-sized quadrupedal system. Using policies trained in simulation, the quadrupedal machine achieves locomotion skills that go beyond what had been achieved with prior methods: ANYmal is capable of precisely and energy-efficiently following high-level body velocity commands, running faster than before, and recovering from falling even in complex configurations.",project-academic
10.1109/ICRA.2019.8793485,2019-05-20,p,IEEE,making sense of vision and touch self supervised learning of multimodal representations for contact rich tasks," Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.",project-academic
,2018-10-24,a,,making sense of vision and touch self supervised learning of multimodal representations for contact rich tasks," Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. Results for simulated and real robot experiments are presented.",project-academic
,2017-12-01,b,,factor graphs for robot perception," Factor Graphs for Robot Perception reviews the use of factor graphs for the modeling and solving of large-scale inference problems in robotics. Factor graphs are a family of probabilistic graphical models, other examples of which are Bayesian networks and Markov random fields, well known from the statistical modeling and machine learning literature. They provide a powerful abstraction that gives insight into particular inference problems, making it easier to think about and design solutions, and write modular software to perform the actual inference. This book illustrates their use in the simultaneous localization and mapping problem and other important problems associated with deploying robots in the real world. Factor graphs are introduced as an economical representation within which to formulate the different inference problems, setting the stage for the subsequent sections on practical methods to solve them. The book explains the nonlinear optimization techniques for solving arbitrary nonlinear factor graphs, which requires repeatedly solving large sparse linear systems. Factor Graphs for Robot Perception will be of interest to students, researchers and practicing roboticists with an interest in the broad impact factor graphs have had, and continue to have, in robot perception.",project-academic
10.1109/MRA.2016.2636359,2016-04-15,a,,the strands project long term autonomy in everyday environments," Thanks to the efforts of the robotics and autonomous systems community, robots are becoming ever more capable. There is also an increasing demand from end-users for autonomous service robots that can operate in real environments for extended periods. In the STRANDS project we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile service robots, and deploying these systems for long-term installations in security and care environments. Over four deployments, our robots have been operational for a combined duration of 104 days autonomously performing end-user defined tasks, covering 116km in the process. In this article we describe the approach we have used to enable long-term autonomous operation in everyday environments, and how our robots are able to use their long run times to improve their own performance.",project-academic
,2019-07-28,a,,making sense of vision and touch learning multimodal representations for contact rich tasks," Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. It is non-trivial to manually design a robot controller that combines these modalities which have very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. In this work, we use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. Evaluating our method on a peg insertion task, we show that it generalizes over varying geometries, configurations, and clearances, while being robust to external perturbations. We also systematically study different self-supervised learning objectives and representation learning architectures. Results are presented in simulation and on a physical robot.",project-academic
10.1007/S12369-015-0310-2,2016-01-01,a,Springer Netherlands,socially adaptive path planning in human environments using inverse reinforcement learning," A key skill for mobile robots is the ability to navigate efficiently through their environment. In the case of social or assistive robots, this involves navigating through human crowds. Typical performance criteria, such as reaching the goal using the shortest path, are not appropriate in such environments, where it is more important for the robot to move in a socially adaptive manner such as respecting comfort zones of the pedestrians. We propose a framework for socially adaptive path planning in dynamic environments, by generating human-like path trajectory. Our framework consists of three modules: a feature extraction module, inverse reinforcement learning (IRL) module, and a path planning module. The feature extraction module extracts features necessary to characterize the state information, such as density and velocity of surrounding obstacles, from a RGB-depth sensor. The inverse reinforcement learning module uses a set of demonstration trajectories generated by an expert to learn the expert’s behaviour when faced with different state features, and represent it as a cost function that respects social variables. Finally, the planning module integrates a three-layer architecture, where a global path is optimized according to a classical shortest-path objective using a global map known a priori, a local path is planned over a shorter distance using the features extracted from a RGB-D sensor and the cost function inferred from IRL module, and a low-level system handles avoidance of immediate obstacles. We evaluate our approach by deploying it on a real robotic wheelchair platform in various scenarios, and comparing the robot trajectories to human trajectories.",project-academic
10.1109/JIOT.2019.2917066,2019-05-15,a,IEEE,a 64 mw dnn based visual navigation engine for autonomous nano drones," Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm2. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",project-academic
,2018-04-06,a,,structured evolution with compact architectures for scalable policy optimization," We present a new method of blackbox optimization via gradient approximation with the use of structured random orthogonal matrices, providing more accurate estimators than baselines and with provable theoretical guarantees. We show that this algorithm can be successfully applied to learn better quality compact policies than those using standard gradient estimation techniques. The compact policies we learn have several advantages over unstructured ones, including faster training algorithms and faster inference. These benefits are important when the policy is deployed on real hardware with limited resources. Further, compact policies provide more scalable architectures for derivative-free optimization (DFO) in high-dimensional spaces. We show that most robotics tasks from the OpenAI Gym can be solved using neural networks with less than 300 parameters, with almost linear time complexity of the inference phase, with up to 13x fewer parameters relative to the Evolution Strategies (ES) algorithm introduced by Salimans et al. (2017). We do not need heuristics such as fitness shaping to learn good quality policies, resulting in a simple and theoretically motivated training mechanism.",project-academic
,2016-02-22,a,UCL Knowledge Lab,intelligence unleashed an argument for ai in education," This paper on artificial intelligence in education (AIEd) has two aims. The first: to explain to a non-specialist, interested, reader what AIEd is: its goals, how it is built, and how it works. The second: to set out the argument for what AIEd can offer teaching and learning, both now and in the future, with an eye towards improving learning and life outcomes for all. Computer systems that are artificially intelligent interact with the world using capabilities (such as speech recognition) and intelligent behaviours (such as using available information to take the most sensible actions toward a stated goal) that we would think of as essentially human. At the heart of artificial intelligence in education is the scientific goal to make knowledge, which is often left implicit, computationally precise and explicit. In other words, in addition to being the engine behind much ‘smart’ ed tech, AIEd is also designed to be a powerful tool to open up what is sometimes called the ‘black box of learning,’ giving us more fine-grained understandings of how learning actually happens. Although some might find the concept of AIEd alienating, the algorithms and models that underpin ed tech powered by AIEd form the basis of an essentially human endeavor. Using AIEd, teachers will be able to offer learners educational experiences that are more personalised, flexible, inclusive and engaging. Crucially, we do not see a future in which AIEd replaces teachers. What we do see is a future in which the extraordinary expertise of teachers is better leveraged and augmented through the thoughtful deployment of well designed AIEd. We have available, right now, AIEd tools that could support student learning at a scale previously unimaginable by providing one-on-one tutoring to every student, in every subject. Existing technologies also have the capacity to provide intelligent support to learners working in a group, and to create authentic virtual learning environments where students have the right support, at the right time, to tackle real-life problems and puzzles. In the near future, we expect that teaching and learning will increasingly be supported by the thoughtful application of AIEd tools. For example, by lifelong learning companions powered by AI that can accompany and support individual learners throughout their studies - in and beyond school - and new forms of assessment that measure learning while it is taking place, shaping the learning experience in real time. If we are ultimately successful, we predict that AIEd will help us address some of the most intractable problems in education, including achievement gaps and teacher retention. AIEd will also help us respond to the most significant social challenge that AI has already brought - the steady replacement of jobs and occupations with clever algorithms and robots. It is our view that this provides a new innovation imperative in education, which can be expressed simply: as humans live and work alongside increasingly smart machines, our education systems will need to achieve at levels that none have managed to date. True progress will require the development of an AIEd infrastructure. This will not, however, be a single monolithic AIEd system. Instead, it will resemble the marketplace that has developed for smartphone apps: hundreds and then thousands of individual AIEd components, developed in collaboration with educators, conformed to uniform international data standards, and shared with researchers and developers worldwide. These standards will also enable system-level data collation and analysis that will help us to learn much more about learning itself – and how to improve it. Moving forward, we will need to pay close attention to three powerful forces as we map the future of artificial intelligence in education, namely pedagogy, technology, and system change. Paying attention to the pedagogy will mean that the design of new edtech should always start with what we know about learning. It also means that the system for funding this work must be simultaneously opened up and refocused, moving away from isolated pockets of R&D and toward collaborative enterprises that prioritise areas known to make a real difference to teaching and learning. Paying attention to the technology will mean creating smarter demand for commercial grade AIEd products that work. It also means the development of a robust, component-based AIEd infrastructure, similar to the smartphone app marketplace, where researchers and developers can access standardised components that have been developed in collaboration with educators. Paying attention to system change will mean involving teachers, students, and parents in co-designing new tools, so that AIEd will appropriately address the inherent “messiness” of real classroom, university, and workplace learning environments. It also means the development of data standards that promote the safe and ethical use of data. Said succinctly, we need intelligent technologies that embody what we know about great teaching and learning, embodied in enticing consumer grade products, which are then used effectively in real-life settings that combine the best of human and machine. We do not underestimate the new-thinking, inevitable wrong-turns, and effort required to realise these recommendations. However, if we are to properly unleash the intelligence of AIEd, we must do things differently - via new collaborations, sensible funding, and (always) a keen eye on the pedagogy. The potential prize is too great to act otherwise.",project-academic
,2018-06-20,a,,sim to real reinforcement learning for deformable object manipulation," We have seen much recent progress in rigid object manipulation, but interaction with deformable objects has notably lagged behind. Due to the large configuration space of deformable objects, solutions using traditional modelling approaches require significant engineering work. Perhaps then, bypassing the need for explicit modelling and instead learning the control in an end-to-end manner serves as a better approach? Despite the growing interest in the use of end-to-end robot learning approaches, only a small amount of work has focused on their applicability to deformable object manipulation. Moreover, due to the large amount of data needed to learn these end-to-end solutions, an emerging trend is to learn control policies in simulation and then transfer them over to the real world. To-date, no work has explored whether it is possible to learn and transfer deformable object policies. We believe that if sim-to-real methods are to be employed further, then it should be possible to learn to interact with a wide variety of objects, and not only rigid objects. In this work, we use a combination of state-of-the-art deep reinforcement learning algorithms to solve the problem of manipulating deformable objects (specifically cloth). We evaluate our approach on three tasks --- folding a towel up to a mark, folding a face towel diagonally, and draping a piece of cloth over a hanger. Our agents are fully trained in simulation with domain randomisation, and then successfully deployed in the real world without having seen any real deformable objects.",project-academic
10.1109/ICRA.2019.8793690,2019-05-20,p,IEEE,a fog robotics approach to deep robot learning application to object recognition and grasp planning in surface decluttering," The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a ‘Fog Robotics’ approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by $4\times$ to successfully declutter 86% of objects over 213 attempts.",project-academic
,2019-03-22,a,,a fog robotics approach to deep robot learning application to object recognition and grasp planning in surface decluttering," The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4\times to successfully declutter 86% of objects over 213 attempts.",project-academic
10.1109/IROS.2017.8206245,2017-09-01,p,IEEE,adversarially robust policy learning active construction of physically plausible perturbations," Policy search methods in reinforcement learning have demonstrated success in scaling up to larger problems beyond toy examples. However, deploying these methods on real robots remains challenging due to the large sample complexity required during learning and their vulnerability to malicious intervention. We introduce Adversarially Robust Policy Learning (ARPL), an algorithm that leverages active computation of physically-plausible adversarial examples during training to enable robust policy learning in the source domain and robust performance under both random and adversarial input perturbations. We evaluate ARPL on four continuous control tasks and show superior resilience to changes in physical environment dynamics parameters and environment state as compared to state-of-the-art robust policy learning methods. Code, data, and additional experimental results are available at: stanfordvl.github.io/ARPL",project-academic
,2018-04-10,a,,planning multi fingered grasps as probabilistic inference in a learned deep network, We propose a novel approach to multi-fingered grasp planning leveraging learned deep neural network models. We train a convolutional neural network to predict grasp success as a function of both visual information of an object and grasp configuration. We can then formulate grasp planning as inferring the grasp configuration which maximizes the probability of grasp success. We efficiently perform this inference using a gradient-ascent optimization inside the neural network using the backpropagation algorithm. Our work is the first to directly plan high quality multifingered grasps in configuration space using a deep neural network without the need of an external planner. We validate our inference method performing both multifinger and two-finger grasps on real robots. Our experimental results show that our planning method outperforms existing planning methods for neural networks; while offering several other benefits including being data-efficient in learning and fast enough to be deployed in real robotic applications.,project-academic
10.1007/978-3-030-28619-4_35,2020-01-01,a,"Springer, Cham",planning multi fingered grasps as probabilistic inference in a learned deep network, We propose a novel approach to multi-fingered grasp planning leveraging learned deep neural network models. We train a convolutional neural network to predict grasp success as a function of both visual information of an object and grasp configuration. We can then formulate grasp planning as inferring the grasp configuration which maximizes the probability of grasp success. We efficiently perform this inference using a gradient-ascent optimization inside the neural network using the backpropagation algorithm. Our work is the first to directly plan high quality multi-fingered grasps in configuration space using a deep neural network without the need of an external planner. We validate our inference method performing both multi-finger and two-finger grasps on real robots. Our experimental results show that our planning method outperforms existing planning methods for neural networks; while offering several other benefits including being data-efficient in learning and fast enough to be deployed in real robotic applications.,project-academic
,2018-10-25,a,,wearable affective robot," With the development of the artificial intelligence (AI), the AI applications have influenced and changed people's daily life greatly. Here, a wearable affective robot that integrates the affective robot, social robot, brain wearable, and wearable 2.0 is proposed for the first time. The proposed wearable affective robot is intended for a wide population, and we believe that it can improve the human health on the spirit level, meeting the fashion requirements at the same time. In this paper, the architecture and design of an innovative wearable affective robot, which is dubbed as Fitbot, are introduced in terms of hardware and algorithm's perspectives. In addition, the important functional component of the robot-brain wearable device is introduced from the aspect of the hardware design, EEG data acquisition and analysis, user behavior perception, and algorithm deployment, etc. Then, the EEG based cognition of user's behavior is realized. Through the continuous acquisition of the in-depth, in-breadth data, the Fitbot we present can gradually enrich user's life modeling and enable the wearable robot to recognize user's intention and further understand the behavioral motivation behind the user's emotion. The learning algorithm for the life modeling embedded in Fitbot can achieve better user's experience of affective social interaction. Finally, the application service scenarios and some challenging issues of a wearable affective robot are discussed.",project-academic
10.1109/ACCESS.2018.2877919,2018-10-24,a,IEEE,wearable affective robot," With the development of the artificial intelligence (AI), the AI applications have influenced and changed people’s daily life greatly. Here, a wearable affective robot that integrates the affective robot, social robot, brain wearable, and Wearable 2.0 is proposed for the first time. The proposed wearable affective robot is intended for a wide population, and we believe that it can improve the human health on the spirit level, meeting the fashion requirements at the same time. In this paper, the architecture and design of an innovative wearable affective robot, which is dubbed as Fitbot, are introduced in terms of hardware and algorithm’s perspectives. In addition, the important functional component of the robot-brain wearable device is introduced from the aspect of the hardware design, EEG data acquisition and analysis, user behavior perception, and algorithm deployment. Then, the EEG-based cognition of user’s behavior is realized. Through the continuous acquisition of the in-depth, in-breadth data, the Fitbot we present can gradually enrich user’s life modeling and enable the wearable robot to recognize user’s intention and further understand the behavioral motivation behind the user’s emotion. The learning algorithm for the life modeling embedded in Fitbot can achieve better user’s experience of affective social interaction. Finally, the application service scenarios and some challenging issues of a wearable affective robot are discussed.",project-academic
10.1016/J.ESWA.2016.06.021,2016-11-15,a,Pergamon,neural networks based reinforcement learning for mobile robots obstacle avoidance," We propose a new path planning algorithm based on the use of Q-learning and artificial neural networks.We analyze and model in VR the mobile robot PowerBot.We implement and test the proposed algorithm in both VR and real workspaces.The solution converges to collision-free trajectories in dynamic environments. This study proposes a new approach for solving the problem of autonomous movement of robots in environments that contain both static and dynamic obstacles. The purpose of this research is to provide mobile robots a collision-free trajectory within an uncertain workspace which contains both stationary and moving entities. The developed solution uses Q-learning and a neural network planner to solve path planning problems. The algorithm presented proves to be effective in navigation scenarios where global information is available. The speed of the robot can be set prior to the computation of the trajectory, which provides a great advantage in time-constrained applications. The solution is deployed in both Virtual Reality (VR) for easier visualization and safer testing activities, and on a real mobile robot for experimental validation. The algorithm is compared with Powerbot's ARNL proprietary navigation algorithm. Results show that the proposed solution has a good conversion rate computed at a satisfying speed.",project-academic
10.1109/TE.2012.2224867,2013-02-01,a,IEEE,syrotek distance teaching of mobile robotics," E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",project-academic
10.1109/DCOSS.2019.00111,2019-05-29,p,IEEE,an open source and open hardware deep learning powered visual navigation engine for autonomous nano uavs," Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.",project-academic
10.1109/ICRA.2019.8793510,2019-05-20,p,IEEE,bonnet an open source training and deployment framework for semantic segmentation in robotics using cnns," The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",project-academic
,2018-02-25,p,,bonnet an open source training and deployment framework for semantic segmentation in robotics using cnns," The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides a C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",project-academic
,2018-07-09,p,International Foundation for Autonomous Agents and Multiagent Systems,towards a robust interactive and learning social robot," Pepper is a humanoid robot, specifically designed for social interaction, that has been deployed in a variety of public environments. A programmable version of Pepper is also available, enabling our focused research on perception and behavior robustness and capabilities of an interactive social robot. We address Pepper perception by integrating state-of-the-art vision and speech recognition systems and experimentally analyzing their effectiveness. As we recognize limitations of the individual perceptual modalities, we introduce a multi-modality approach to increase the robustness of human social interaction with the robot. We combine vision, gesture, speech, and input from an onboard tablet, a remote mobile phone, and external microphones. Our approach includes the proactive seeking of input from a different modality, adding robustness to the failures of the separate components. We also introduce a learning algorithm to improve communication capabilities over time, updating speech recognition through social interactions. Finally, we realize the rich robot body-sensory data and introduce both a nearest-neighbor and a deep learning approach to enable Pepper to classify and speak up a variety of its own body motions. We view the contributions of our work to be relevant both to Pepper specifically and to other general social robots.",project-academic
10.1109/CASE48305.2020.9216902,2020-08-01,p,IEEE,industrial robot grasping with deep learning using a programmable logic controller plc," Universal grasping of a diverse range of previously unseen objects from heaps is a grand challenge in e-commerce order fulfillment, manufacturing, and home service robotics. Recently, deep learning based grasping approaches have demonstrated results that make them increasingly interesting for industrial deployments. This paper explores the problem from an automation systems point-of-view. We develop a robotics grasping system using Dex-Net, which is fully integrated at the controller level. Two neural networks are deployed on a novel industrial AI hardware acceleration module close to a PLC with a power footprint of less than 10 W for the overall system. The software is tightly integrated with the hardware allowing for fast and efficient data processing and real-time communication. The success rate of grasping an object form a bin is up to 95% with more than 350 picks per hour, if object and receptive bins are in close proximity. The system was presented at the Hannover Fair 2019 (world’s largest industrial trade fair) and other events, where it performed over 5,000 grasps per event.",project-academic
,2020-04-21,a,,industrial robot grasping with deep learning using a programmable logic controller plc," Universal grasping of a diverse range of previously unseen objects from heaps is a grand challenge in e-commerce order fulfillment, manufacturing, and home service robotics. Recently, deep learning based grasping approaches have demonstrated results that make them increasingly interesting for industrial deployments. This paper explores the problem from an automation systems point-of-view. We develop a robotics grasping system using Dex-Net, which is fully integrated at the controller level. Two neural networks are deployed on a novel industrial AI hardware acceleration module close to a PLC with a power footprint of less than 10 W for the overall system. The software is tightly integrated with the hardware allowing for fast and efficient data processing and real-time communication. The success rate of grasping an object form a bin is up to 95 percent with more than 350 picks per hour, if object and receptive bins are in close proximity. The system was presented at the Hannover Fair 2019 (world s largest industrial trade fair) and other events, where it performed over 5,000 grasps per event.",project-academic
10.15607/RSS.2020.XVI.018,2020-02-04,p,Robotics: Science and Systems Foundation,simultaneous enhancement and super resolution of underwater imagery for improved visual perception," In this paper, we introduce and tackle the simultaneous enhancement and super-resolution (SESR) problem for underwater robot vision and provide an efficient solution for near real-time applications. We present Deep SESR, a residual-in-residual network-based generative model that can learn to restore perceptual image qualities at 2x, 3x, or 4x higher spatial resolution. We supervise its training by formulating a multi-modal objective function that addresses the chrominance-specific underwater color degradation, lack of image sharpness, and loss in high-level feature representation. It is also supervised to learn salient foreground regions in the image, which in turn guides the network to learn global contrast enhancement. We design an end-to-end training pipeline to jointly learn the saliency prediction and SESR on a shared hierarchical feature space for fast inference. Moreover, we present UFO-120, the first dataset to facilitate large-scale SESR learning; it contains over 1500 training samples and a benchmark test set of 120 samples. By thorough experimental evaluation on the UFO-120 and other standard datasets, we demonstrate that Deep SESR outperforms the existing solutions for underwater image enhancement and super-resolution. We also validate its generalization performance on several test cases that include underwater images with diverse spectral and spatial degradation levels, and also terrestrial images with unseen natural objects. Lastly, we analyze its computational feasibility for single-board deployments and demonstrate its operational benefits for visually-guided underwater robots. The model and dataset information will be available at: this https URL.",project-academic
,2020-02-04,a,,simultaneous enhancement and super resolution of underwater imagery for improved visual perception," In this paper, we introduce and tackle the simultaneous enhancement and super-resolution (SESR) problem for underwater robot vision and provide an efficient solution for near real-time applications. We present Deep SESR, a residual-in-residual network-based generative model that can learn to restore perceptual image qualities at 2x, 3x, or 4x higher spatial resolution. We supervise its training by formulating a multi-modal objective function that addresses the chrominance-specific underwater color degradation, lack of image sharpness, and loss in high-level feature representation. It is also supervised to learn salient foreground regions in the image, which in turn guides the network to learn global contrast enhancement. We design an end-to-end training pipeline to jointly learn the saliency prediction and SESR on a shared hierarchical feature space for fast inference. Moreover, we present UFO-120, the first dataset to facilitate large-scale SESR learning; it contains over 1500 training samples and a benchmark test set of 120 samples. By thorough experimental evaluation on the UFO-120 and other standard datasets, we demonstrate that Deep SESR outperforms the existing solutions for underwater image enhancement and super-resolution. We also validate its generalization performance on several test cases that include underwater images with diverse spectral and spatial degradation levels, and also terrestrial images with unseen natural objects. Lastly, we analyze its computational feasibility for single-board deployments and demonstrate its operational benefits for visually-guided underwater robots. The model and dataset information will be available at: this https URL.",project-academic
10.1016/J.ROBOT.2020.103472,2020-04-01,a,North-Holland,deploying mavs for autonomous navigation in dark underground mine environments," Abstract None None Operating Micro Aerial Vehicles (MAVs) in subterranean environments is becoming more and more relevant in the field of aerial robotics. Despite the large spectrum of technological advances in the field, flying in such challenging environments is still an ongoing quest that requires the combination of multiple sensor modalities like visual/thermal cameras as well as 3D and 2D lidars. Nevertheless, there exist cases in subterranean environments where the aim is to deploy fast and lightweight aerial robots for area reckoning purposes after an event (e.g. blasting in production areas). This work proposes a novel baseline approach for the navigation of resource constrained robots, introducing the aerial underground scout, with the main goal to rapidly explore unknown areas and provide a feedback to the operator. The main proposed framework focuses on the navigation, control and vision capabilities of the aerial platforms with low-cost sensor suites, contributing significantly towards real-life applications. The merit of the proposed control architecture is that it considers the flying platform as a floating object, composing a velocity controller on the None None None x None None , None None None y None None None axes and altitude control to navigate along the tunnel. Two novel approaches make up the cornerstone of the proposed contributions for the task of navigation: (1) a vector geometry method based on 2D lidar, and (2) a Deep Learning (DL) method through a classification process based on an on-board image stream, where both methods correct the heading towards the center of the mine tunnel. Finally, the framework has been evaluated in multiple field trials in an underground mine in Sweden.",project-academic
10.1007/978-3-319-78890-6_1,2018-05-02,p,"Springer, Cham",approximate fpga based lstms under computation time constraints," Recurrent Neural Networks, with the prominence of Long Short-Term Memory (LSTM) networks, have demonstrated state-of-the-art accuracy in several emerging Artificial Intelligence tasks. Nevertheless, the highest performing LSTM models are becoming increasingly demanding in terms of computational and memory load. At the same time, emerging latency-sensitive applications including mobile robots and autonomous vehicles often operate under stringent computation time constraints. In this paper, we address the challenge of deploying computationally demanding LSTMs at a constrained time budget by introducing an approximate computing scheme that combines iterative low-rank compression and pruning, along with a novel FPGA-based LSTM architecture. Combined in an end-to-end framework, the approximation method parameters are optimised and the architecture is configured to address the problem of high-performance LSTM execution in time-constrained applications. Quantitative evaluation on a real-life image captioning application indicates that the proposed system required up to 6.5\(\times \) less time to achieve the same application-level accuracy compared to a baseline method, while achieving an average of 25\(\times \) higher accuracy under the same computation time constraints.",project-academic
,2018-01-07,a,,approximate fpga based lstms under computation time constraints," Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM) networks have demonstrated state-of-the-art accuracy in several emerging Artificial Intelligence tasks. However, the models are becoming increasingly demanding in terms of computational and memory load. Emerging latency-sensitive applications including mobile robots and autonomous vehicles often operate under stringent computation time constraints. In this paper, we address the challenge of deploying computationally demanding LSTMs at a constrained time budget by introducing an approximate computing scheme that combines iterative low-rank compression and pruning, along with a novel FPGA-based LSTM architecture. Combined in an end-to-end framework, the approximation method's parameters are optimised and the architecture is configured to address the problem of high-performance LSTM execution in time-constrained applications. Quantitative evaluation on a real-life image captioning application indicates that the proposed methods required up to 6.5x less time to achieve the same application-level accuracy compared to a baseline method, while achieving an average of 25x higher accuracy under the same computation time constraints.",project-academic
10.1109/ICRA.2019.8793600,2019-05-20,p,IEEE,a fog robotic system for dynamic visual servoing," Cloud Robotics is a paradigm where multiple robots are connected to cloud services via Internet to access “unlimited” computation power, at the cost of network communication. However, due to limitations such as network latency and variability, it is difficult to control dynamic, human compliant service robots directly from the cloud. In this work, we combine cloud robotics with an agile edge device to build a Fog Robotic system by leveraging an asynchronous protocol with a “heartbeat” signal. We use the system to enable robust teleoperation of a dynamic self-balancing robot from the cloud. We use the system to pick up boxes from static locations, a task commonly performed in warehouse logistics. To make cloud teleoperation more intuitive and efficient, we program a cloud-based image based visual servoing (IBVS) module to automatically assist the cloud teleoperator during the object pickups. Visual feedbacks, including apriltag recognition and tracking, are performed in the cloud to emulate a Fog Robotic object recognition system for IBVS. We demonstrate the feasibility of a dynamic real-time automation system using this cloud-edge hybrid design, which opens up possibilities of deploying dynamic robotic control with deep-learning recognition systems in Fog Robotics. Finally, we show that Fog Robotics enables the self-balancing service robot to pick up a box automatically from a person under unstructured environments.",project-academic
10.1109/ICRA48506.2021.9561926,2021-05-30,p,IEEE,circus anymal a quadruped learning dexterous manipulation with its limbs," Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 °/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",project-academic
,2020-11-17,a,,circus anymal a quadruped learning dexterous manipulation with its limbs," Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 deg/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",project-academic
,2019-04-08,a,,sim real joint reinforcement transfer for 3d indoor navigation," There has been an increasing interest in 3D indoor navigation, where a robot in an environment moves to a target according to an instruction. To deploy a robot for navigation in the physical world, lots of training data is required to learn an effective policy. It is quite labour intensive to obtain sufficient real environment data for training robots while synthetic data is much easier to construct by rendering. Though it is promising to utilize the synthetic environments to facilitate navigation training in the real world, real environment are heterogeneous from synthetic environment in two aspects. First, the visual representation of the two environments have significant variances. Second, the houseplans of these two environments are quite different. Therefore two types of information, i.e. visual representation and policy behavior, need to be adapted in the reinforcement model. The learning procedure of visual representation and that of policy behavior are presumably reciprocal. We propose to jointly adapt visual representation and policy behavior to leverage the mutual impacts of environment and policy. Specifically, our method employs an adversarial feature adaptation model for visual representation transfer and a policy mimic strategy for policy behavior imitation. Experiment shows that our method outperforms the baseline by 19.47% without any additional human annotations.",project-academic
10.1109/ICRA40945.2020.9196769,2020-05-01,p,,online lidar slam for legged robots with robust registration and deep learned loop closure," In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.",project-academic
,2020-01-28,a,,online lidar slam for legged robots with robust registration and deep learned loop closure," In this paper, we present a factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. These facilities can be badly lit and comprised of indistinct metallic structures, thus our system uses only LiDAR sensing and was developed to run on the quadruped robot's navigation PC. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.",project-academic
,2017-03-13,a,,sensor fusion for robot control through deep reinforcement learning," Deep reinforcement learning is becoming increasingly popular for robot control algorithms, with the aim for a robot to self-learn useful feature representations from unstructured sensory input leading to the optimal actuation policy. In addition to sensors mounted on the robot, sensors might also be deployed in the environment, although these might need to be accessed via an unreliable wireless connection. In this paper, we demonstrate deep neural network architectures that are able to fuse information coming from multiple sensors and are robust to sensor failures at runtime. We evaluate our method on a search and pick task for a robot both in simulation and the real world.",project-academic
10.1109/IROS.2017.8206048,2017-09-01,p,Ieee,sensor fusion for robot control through deep reinforcement learning," Deep reinforcement learning is becoming increasingly popular for robot control algorithms, with the aim for a robot to self-learn useful feature representations from unstructured sensory input leading to the optimal actuation policy. In addition to sensors mounted on the robot, sensors might also be deployed in the environment, although these might need to be accessed via an unreliable wireless connection. In this paper, we demonstrate deep neural network architectures that are able to fuse information generated by multiple sensors and are robust to sensor failures at runtime. We evaluate our method on a search and pick task for a robot both in simulation and the real world.",project-academic
,2020-04-21,p,,efficient adaptation for end to end vision based robotic manipulation," One of the great promises of robot learning systems is that they will be able to learn from their mistakes and continuously adapt to ever-changing environments. Despite this potential, most of the robot learning systems today are deployed as a fixed policy and they are not being adapted after their deployment. Can we efficiently adapt previously learned behaviors to new environments, objects and percepts in the real world? In this paper, we present a method and empirical evidence towards a robot learning framework that facilitates continuous adaption. In particular, we demonstrate how to adapt vision-based robotic manipulation policies to new variations by fine-tuning via off-policy reinforcement learning, including changes in background, object shape and appearance, lighting conditions, and robot morphology. Further, this adaptation uses less than 0.2% of the data necessary to learn the task from scratch. We find that our approach of adapting pre-trained policies leads to substantial performance gains over the course of fine-tuning, and that pre-training via RL is essential: training from scratch or adapting from supervised ImageNet features are both unsuccessful with such small amounts of data. We also find that these positive results hold in a limited continual learning setting, in which we repeatedly fine-tune a single lineage of policies using data from a succession of new tasks. Our empirical conclusions are consistently supported by experiments on simulated manipulation tasks, and by 52 unique fine-tuning experiments on a real robotic grasping system pre-trained on 580,000 grasps.",project-academic
10.1109/ICRA40945.2020.9196540,2020-05-01,p,IEEE,meta reinforcement learning for sim to real domain adaptation," Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.",project-academic
,2019-09-16,a,,meta reinforcement learning for sim to real domain adaptation," Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.",project-academic
10.1109/LRA.2020.2998414,2020-05-28,p,IEEE,rilaas robot inference and learning as a service," Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",project-academic
10.1016/J.AUTCON.2020.103078,2020-04-01,a,Elsevier,complete coverage path planning using reinforcement learning for tetromino based cleaning and maintenance robot," Abstract None None Tiling robotics have been deployed in autonomous complete area coverage tasks such as floor cleaning, building inspection, and maintenance, surface painting. One class of tiling robotics, polyomino-based reconfigurable robots, overcome the limitation of fixed-form robots in achieving high-efficiency area coverage by adopting different morphologies to suit the needs of the current environment. Since the reconfigurable actions of these robots are produced by real-time intelligent decisions during operations, an optimal path planning algorithm is paramount to maximize the area coverage while minimizing the energy consumed by these robots. This paper proposes a complete coverage path planning (CCPP) model trained using deep blackreinforcement learning (RL) for the tetromino based reconfigurable robot platform called hTetro to simultaneously generate the optimal set of shapes for any pretrained arbitrary environment shape with a trajectory that has the least overall cost. To this end, a Convolutional Neural Network (CNN) with Long Short Term Memory (LSTM) layers is trained using Actor Critic Experience Replay (ACER) reinforcement learning algorithm. The results are compared with existing approaches which are based on the traditional tiling theory model, including zigzag, spiral, and greedy search schemes. The model is also compared with the Travelling salesman problem (TSP) based Genetic Algorithm (GA) and Ant Colony Optimization (ACO) schemes. The proposed scheme generates a path with lower cost while also requiring lesser time to generate it. The model is also highly robust and can generate a path in any pretrained arbitrary environments.",project-academic
10.1109/IROS.2018.8594067,2018-10-01,p,IEEE,robust object recognition through symbiotic deep learning in mobile robots," Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",project-academic
10.1109/LRA.2021.3062323,2021-02-01,p,Institute of Electrical and Electronics Engineers (IEEE),differentiable simulation for physical system identification," Simulating frictional contacts remains a challenging research topic in robotics. Recently, differentiable physics emerged and has proven to be a key element in model-based Reinforcement Learning (RL) and optimal control fields. However, most of the current formulations deploy coarse approximations of the underlying physical principles. Indeed, the classic simulators loose precision by casting the Nonlinear Complementarity Problem (NCP) of frictional contact into a Linear Complementarity Problem (LCP) to simplify computations. Moreover, such methods deploy non-smooth operations and cannot be automatically differentiated. In this letter, we propose (i) an extension of the staggered projections algorithm for more accurate solutions of the problem of contacts with friction. Based on this formulation, we introduce (ii) a differentiable simulator and an efficient way to compute the analytical derivatives of the involved optimization problems. Finally, (iii) we validate the proposed framework with a set of experiments to present a possible application of our differentiable simulator. In particular, using our approach we demonstrate accurate estimation of friction coefficients and object masses both in synthetic and real experiments.",project-academic
10.1109/ICRA.2017.7989184,2017-05-01,p,,rapidly exploring learning trees," Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT∗), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT∗) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT∗ cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT∗ achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT∗ on a real telepresence robot.",project-academic
10.3389/FNBOT.2011.00001,2011-07-12,a,Frontiers Media SA,robot cognitive control with a neurophysiologically inspired reinforcement learning model," A major challenge in modern robotics is to liberate robots from controlled industrial settings, and allow them to interact with humans and changing environments in the real world. The current research attempts to determine if a neurophysiologically motivated model of cortical function in the primate can help to address this challenge. Primates are endowed with cognitive systems that allow them to maximize the feedback from their environment by learning the values of actions in diverse situations and by adjusting their behavioral parameters (i.e. cognitive control) to accommodate unexpected events. In such contexts uncertainty can arise from at least two distinct sources – expected uncertainty resulting from noise during sensory-motor interaction in a known context, and unexpected uncertainty resulting from the changing probabilistic structure of the environment. However, it is not clear how neurophysiological mechanisms of reinforcement learning and cognitive control integrate in the brain to produce efficient behavior. Based on primate neuroanatomy and neurophysiology, we propose a novel computational model for the interaction between lateral prefrontal and anterior cingulate cortex (LPFC and ACC) reconciling previous models dedicated to these two functions. We deployed the model in two robots and demonstrate that, based on adaptive regulation of a meta-parameter β that controls the exploration rate, the model can robustly deal with the two kinds of uncertainties in the real world. In addition the model could reproduce monkey behavioral performance and neurophysiological data in two problem-solving tasks. A last experiment extends this to human-robot interaction with the iCub humanoid, and novel sources of uncertainty corresponding to “cheating” by the human. The combined results provide concrete evidence for the ability of neurophysiologically inspired cognitive systems to control advanced robots in the real world.",project-academic
,2018-02-24,a,,adaptive deep learning through visual domain localization," A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.",project-academic
10.1109/ICRA.2018.8460650,2018-05-01,p,IEEE,adaptive deep learning through visual domain localization," A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.",project-academic
,2018-01-01,a,,learning to learn with gradients," Humans have a remarkable ability to learn new concepts from only a few examples and quickly adapt to unforeseen circumstances. To do so, they build upon their prior experience and prepare for the ability to adapt, allowing the combination of previous observations with small amounts of new evidence for fast learning. In most machine learning systems, however, there are distinct train and test phases: training consists of updating the model using data, and at test time, the model is deployed as a rigid decision-making engine. In this thesis, we discuss gradient-based algorithms for learning to learn, or meta-learning, which aim to endow machines with flexibility akin to that of humans. Instead of deploying a fixed, non-adaptable system, these meta-learning techniques explicitly train for the ability to quickly adapt so that, at test time, they can learn quickly when faced with new scenarios.To study the problem of learning to learn, we first develop a clear and formal definition of the meta-learning problem, its terminology, and desirable properties of meta-learning algorithms. Building upon these foundations, we present a class of model-agnostic meta-learning methods that embed gradient-based optimization into the learner. Unlike prior approaches to learning to learn, this class of methods focus on acquiring a transferable representation rather than a good learning rule. As a result, these methods inherit a number of desirable properties from using a fixed optimization as the learning rule, while still maintaining full expressivity, since the learned representations can control the update rule.We show how these methods can be extended for applications in motor control by combining elements of meta-learning with techniques for deep model-based reinforcement learning, imitation learning, and inverse reinforcement learning. By doing so, we build simulated agents that can adapt in dynamic environments, enable real robots to learn to manipulate new objects by watching a video of a human, and allow humans to convey goals to robots with only a few images. Finally, we conclude by discussing open questions and future directions in meta-learning, aiming to identify the key shortcomings and limiting assumptions of our existing approaches.",project-academic
10.1109/ICRA48506.2021.9561020,2021-05-30,p,IEEE,sqrp sensing quality aware robot programming system for non expert programmers," Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot’s environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",project-academic
,2021-06-30,a,,sqrp sensing quality aware robot programming system for non expert programmers," Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot's environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",project-academic
,2018-10-23,a,PMLR,learning deployable navigation policies at kilometer scale from a single traversal," Model-free reinforcement learning has recently been shown to be effective at learning navigation policies from complex image input. However, these algorithms tend to require large amounts of interaction with the environment, which can be prohibitively costly to obtain on robots in the real world. We present an approach for efficiently learning goal-directed navigation policies on a mobile robot, from only a single coverage traversal of recorded data. The navigation agent learns an effective policy over a diverse action space in a large heterogeneous environment consisting of more than 2km of travel, through buildings and outdoor regions that collectively exhibit large variations in visual appearance, self-similarity, and connectivity. We compare pretrained visual encoders that enable precomputation of visual embeddings to achieve a throughput of tens of thousands of transitions per second at training time on a commodity desktop computer, allowing agents to learn from millions of trajectories of experience in a matter of hours. We propose multi- ple forms of computationally efficient stochastic augmentation to enable the learned policy to generalise beyond these precomputed embeddings, and demonstrate successful deployment of the learned policy on the real robot without fine tuning, despite environmental appearance differences at test time. The dataset and code required to reproduce these results and apply the technique to other datasets and robots is made publicly available at rl-navigation.github.io/deployable .",project-academic
10.1093/MILMED/USAA253,2021-01-25,a,Association of Military Surgeons of the US,from the dexterous surgical skill to the battlefield a robotics exploratory study," INTRODUCTION Short response time is critical for future military medical operations in austere settings or remote areas. Such effective patient care at the point of injury can greatly benefit from the integration of semi-autonomous robotic systems. To achieve autonomy, robots would require massive libraries of maneuvers collected with the goal of training machine learning algorithms. Although this is attainable in controlled settings, obtaining surgical data in austere settings can be difficult. Hence, in this article, we present the Dexterous Surgical Skill (DESK) database for knowledge transfer between robots. The peg transfer task was selected as it is one of the six main tasks of laparoscopic training. In addition, we provide a machine learning framework to evaluate novel transfer learning methodologies on this database. METHODS A set of surgical gestures was collected for a peg transfer task, composed of seven atomic maneuvers referred to as surgemes. The collected Dexterous Surgical Skill dataset comprises a set of surgical robotic skills using the four robotic platforms: Taurus II, simulated Taurus II, YuMi, and the da Vinci Research Kit. Then, we explored two different learning scenarios: no-transfer and domain-transfer. In the no-transfer scenario, the training and testing data were obtained from the same domain; whereas in the domain-transfer scenario, the training data are a blend of simulated and real robot data, which are tested on a real robot. RESULTS Using simulation data to train the learning algorithms enhances the performance on the real robot where limited or no real data are available. The transfer model showed an accuracy of 81% for the YuMi robot when the ratio of real-tosimulated data were 22% to 78%. For the Taurus II and the da Vinci, the model showed an accuracy of 97.5% and 93%, respectively, training only with simulation data. CONCLUSIONS The results indicate that simulation can be used to augment training data to enhance the performance of learned models in real scenarios. This shows potential for the future use of surgical data from the operating room in deployable surgical robots in remote areas.",project-academic
10.4018/978-1-60566-014-1.CH070,2009-01-01,c,IGI Global,evolution of technologies standards and deployment of 2g 5g networks," The fourth and fifth generation wireless mobile systems, commonly known as 4G and 5G, are expected to provide global roaming across different types of wireless and mobile networks, for instance, from satellite to mobile networks and to Wireless Local Area Networks (WLANs). 4G is an all IP-based mobile network using different radio access technologies providing seamless roaming and providing connection always via the best available network [1]. The vision of 4G wireless/mobile systems is the provision of broadband access, seamless global roaming, and Internet/data/voice everywhere, utilizing for each the most “appropriate” always best connected technology [2]. These systems are about integrating terminals, networks, and applications to satisfy increasing user demands ([3], [4]). 4G systems are expected to offer a speed of over 100 Mbps in stationary mode and an average of 20 Mbps for mobile stations reducing the download time of graphics and multimedia components by more than 10 times compared to currently available 2 Mbps on 3G systems. The fifth generation communication system is envisioned as the real wireless network, capable of supporting wireless world wide web (wwww) applications in 2010 to 2015 time frame. There are two views of 5G systems: evolutionary and revolutionary. In the evolutionary view the 5G (or beyond 4G) systems will be capable of supporting wwww allowing a highly flexible network such as a Dynamic Adhoc Wireless Network (DAWN). In this view advanced technologies including intelligent antenna and flexible modulation are keys to optimize the adhoc wireless networks. In revolutionary view 5G systems should be an intelligent technology capable of interconnecting the entire world without limits. An example application could be a robot with built-in wireless communication with artificial intelligence. The 4G system is still predominantly a research and development initiative based upon 3G, which is struggling to meet its performance goals. The challenges for development of 4G systems depend upon the evolution of different underlying technologies, standards, and deployment. We present an overall vision of the 4G features, framework, and integration of mobile communication. First we explain the evolutionary process from 2G to 5G in light of used technologies and business demands. Next we discuss the architectural developments for 2G-5G systems, followed by the discussion on standards and services. Finally we address the market demands and discuss the development of terminals for these systems.",project-academic
,2021-03-19,a,,fully onboard ai powered human drone pose estimation on ultra low power autonomous flying nano uavs," Artificial intelligence-powered pocket-sized air robots have the potential to revolutionize the Internet-of-Things ecosystem, acting as autonomous, unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor, nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor human-drone interaction missions, as the pose estimation task we address in this work. However, this scenario is challenged by the nano-UAVs' limited payload and computational power that severely relegates the onboard brain to the sub-100 mW microcontroller unit-class. Our work stands at the intersection of the novel parallel ultra-low-power (PULP) architectural paradigm and our general development methodology for deep neural network (DNN) visual pipelines, i.e., covering from perception to control. Addressing the DNN model design, from training and dataset augmentation to 8-bit quantization and deployment, we demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for the real-time execution (up to 135 frame/s) of our novel DNN, called PULP-Frontnet. We showcase how, scaling our model's memory and computational requirement, we can significantly improve the onboard inference (top energy efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a resource-unconstrained baseline (i.e., full-precision DNN). Field experiments demonstrate a closed-loop top-notch autonomous navigation capability, with a heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared against the control performance achieved using an ideal sensing setup, onboard relative pose inference yields excellent drone behavior in terms of median absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular (onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).",project-academic
10.1109/JIOT.2021.3091643,2021-01-01,a,Institute of Electrical and Electronics Engineers (IEEE),fully onboard ai powered human drone pose estimation on ultra low power autonomous flying nano uavs," Artificial intelligence-powered pocket-sized air robots have the potential to revolutionize the Internet-of-Things ecosystem, acting as autonomous, unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor, nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor human-drone interaction missions, as the pose estimation task we address in this work. However, this scenario is challenged by the nano-UAVs' limited payload and computational power that severely relegates the onboard brain to the sub-100 mW microcontroller unit-class. Our work stands at the intersection of the novel parallel ultra-low-power (PULP) architectural paradigm and our general development methodology for deep neural network (DNN) visual pipelines, i.e., covering from perception to control. Addressing the DNN model design, from training and dataset augmentation to 8-bit quantization and deployment, we demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for the real-time execution (up to 135 frame/s) of our novel DNN, called PULP-Frontnet. We showcase how, scaling our model's memory and computational requirement, we can significantly improve the onboard inference (top energy efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a resource-unconstrained baseline (i.e., full-precision DNN). Field experiments demonstrate a closed-loop top-notch autonomous navigation capability, with a heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared against the control performance achieved using an ideal sensing setup, onboard relative pose inference yields excellent drone behavior in terms of median absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular (onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).",project-academic
10.3390/S18051530,2018-05-12,a,Multidisciplinary Digital Publishing Institute,convolutional neural network based embarrassing situation detection under camera for social robot in smart homes," Recent research has shown that the ubiquitous use of cameras and voice monitoring equipment in a home environment can raise privacy concerns and affect human mental health. This can be a major obstacle to the deployment of smart home systems for elderly or disabled care. This study uses a social robot to detect embarrassing situations. Firstly, we designed an improved neural network structure based on the You Only Look Once (YOLO) model to obtain feature information. By focusing on reducing area redundancy and computation time, we proposed a bounding-box merging algorithm based on region proposal networks (B-RPN), to merge the areas that have similar features and determine the borders of the bounding box. Thereafter, we designed a feature extraction algorithm based on our improved YOLO and B-RPN, called F-YOLO, for our training datasets, and then proposed a real-time object detection algorithm based on F-YOLO (RODA-FY). We implemented RODA-FY and compared models on our MAT social robot. Secondly, we considered six types of situations in smart homes, and developed training and validation datasets, containing 2580 and 360 images, respectively. Meanwhile, we designed three types of experiments with four types of test datasets composed of 960 sample images. Thirdly, we analyzed how a different number of training iterations affects our prediction estimation, and then we explored the relationship between recognition accuracy and learning rates. Our results show that our proposed privacy detection system can recognize designed situations in the smart home with an acceptable recognition accuracy of 94.48%. Finally, we compared the results among RODA-FY, Inception V3, and YOLO, which indicate that our proposed RODA-FY outperforms the other comparison models in recognition accuracy.",project-academic
10.1109/ICRA.2018.8462969,2018-05-21,p,IEEE,robust human following by deep bayesian trajectory prediction for home service robots," The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",project-academic
10.3390/S20061698,2020-03-18,a,Sensors (Basel),table cleaning task by human support robot using deep learning technique," This work presents a table cleaning and inspection method using a Human Support Robot (HSR) which can operate in a typical food court setting. The HSR is able to perform a cleanliness inspection and also clean the food litter on the table by implementing a deep learning technique and planner framework. A lightweight Deep Convolutional Neural Network (DCNN) has been proposed to recognize the food litter on top of the table. In addition, the planner framework was proposed to HSR for accomplishing the table cleaning task which generates the cleaning path according to the detection of food litter and then the cleaning action is carried out. The effectiveness of the food litter detection module is verified with the cleanliness inspection task using Toyota HSR, and its detection results are verified with standard quality metrics. The experimental results show that the food litter detection module achieves an average of 96 % detection accuracy, which is more suitable for deploying the HSR robots for performing the cleanliness inspection and also helps to select the different cleaning modes. Further, the planner part has been tested through the table cleaning tasks. The experimental results show that the planner generated the cleaning path in real time and its generated path is optimal which reduces the cleaning time by grouping based cleaning action for removing the food litters from the table.",project-academic
,2018-05-04,a,,ultra low power deep learning powered autonomous nano drones," Flying in dynamic, urban, highly-populated environments represents an open problem in robotics. State-of-the-art (SoA) autonomous Unmanned Aerial Vehicles (UAVs) employ advanced computer vision techniques based on computationally expensive algorithms, such as Simultaneous Localization and Mapping (SLAM) or Convolutional Neural Networks (CNNs) to navigate in such environments. In the Internet-of-Things (IoT) era, nano-size UAVs capable of autonomous navigation would be extremely desirable as self-aware mobile IoT nodes. However, autonomous flight is considered unaffordable in the context of nano-scale UAVs, where the ultra-constrained power envelopes of tiny rotor-crafts limit the on-board computational capabilities to low-power microcontrollers. In this work, we present the first vertically integrated system for fully autonomous deep neural network-based navigation on nano-size UAVs. Our system is based on GAP8, a novel parallel ultra-low-power computing platform, and deployed on a 27 g commercial, open-source CrazyFlie 2.0 nano-quadrotor. We discuss a methodology and software mapping tools that enable the SoA CNN presented in [1] to be fully executed on-board within a strict 12 fps real-time constraint with no compromise in terms of flight results, while all processing is done with only 94 mW on average - 1% of the power envelope of the deployed nano-aircraft.",project-academic
10.1109/TRO.2021.3084374,2021-06-17,a,,cat like jumping and landing of legged robots in low gravity using deep reinforcement learning," In this article, we show that learned policies can be applied to solve legged locomotion control tasks with extensive flight phases, such as those encountered in space exploration. Using an off-the-shelf deep reinforcement learning algorithm, we trained a neural network to control a jumping quadruped robot while solely using its limbs for attitude control. We present tasks of increasing complexity leading to a combination of three-dimensional (re-)orientation and landing locomotion behaviors of a quadruped robot traversing simulated low-gravity celestial bodies. We show that our approach easily generalizes across these tasks and successfully trains policies for each case. Using sim-to-real transfer, we deploy trained policies in the real world on the SpaceBok robot placed on an experimental testbed designed for two-dimensional micro-gravity experiments. The experimental results demonstrate that repetitive, controlled jumping and landing with natural agility is possible.",project-academic
10.1109/LRA.2019.2955941,2020-01-01,p,Institute of Electrical and Electronics Engineers,generative localization with uncertainty estimation through video ct data for bronchoscopic biopsy," Robot-assisted endobronchial intervention requires accurate localisation based on both intra- and pre-operative data. Most existing methods achieve this by registering 2D videos with 3D CT models according to a defined similarity metric with local features. Instead, we formulate the bronchoscopic localisation as a learning-based global localisation using deep neural networks. The proposed network consists of two generative architectures and one auxiliary learning component. The cycle generative architecture bridges the domain variance between the real bronchoscopic videos and virtual views derived from pre-operative CT data so that the proposed approach can be trained through a large number of generated virtual images but deployed through real images. The auxiliary learning architecture leverages complementary relative pose regression to constrain the search space, ensuring consistent global pose predictions. Most importantly, the uncertainty of each global pose is obtained through variational inference by sampling within the learned underlying probability distribution. Detailed validation results demonstrate the localisation accuracy with reasonable uncertainty achieved and its potential clinical value.",project-academic
10.1145/3022099.3022101,2016-07-01,p,ACM,intelligent agent based stimulation for testing robotic software in human robot interactions," The challenges of robotic software testing extend beyond conventional software testing. Valid, realistic and interesting tests need to be generated for multiple programs and hardware running concurrently, deployed into dynamic environments with people. We investigate the use of Belief-Desire-Intention (BDI) agents as models for test generation, in the domain of human-robot interaction (HRI) in simulations. These models provide rational agency, causality, and a reasoning mechanism for planning, which emulate both intelligent and adaptive robots, as well as smart testing environments directed by humans. We introduce reinforcement learning (RL) to automate the exploration of the BDI models using a reward function based on coverage feedback. Our approach is evaluated using a collaborative manufacture example, where the robotic software under test is stimulated indirectly via a simulated human co-worker. We conclude that BDI agents provide intuitive models for test generation in the HRI domain. Our results demonstrate that RL can fully automate BDI model exploration, leading to very effective coverage-directed test generation.",project-academic
10.1007/S43154-020-00021-6,2020-12-01,a,Springer International Publishing,a survey on learning based robotic grasping," This review provides a comprehensive overview of machine learning approaches for vision-based robotic grasping and manipulation. Current trends and developments as well as various criteria for categorization of approaches are provided. Model-free approaches are attractive due to their generalization capabilities to novel objects, but are mostly limited to top-down grasps and do not allow a precise object placement which can limit their applicability. In contrast, model-based methods allow a precise placement and aim for an automatic configuration without any human intervention to enable a fast and easy deployment. Both approaches to robotic grasping and manipulation with and without object-specific knowledge are discussed. Due to the large amount of data required to train AI-based approaches, simulations are an attractive choice for robot learning. This article also gives an overview of techniques and achievements in transfers from simulations to the real world.",project-academic
10.1109/JIOT.2019.2917066,2018-05-04,a,,a 64mw dnn based visual navigation engine for autonomous nano drones," Fully-autonomous miniaturized robots (e.g., drones), with artificial intelligence (AI) based visual navigation capabilities are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nanodrones with size of a few cm${}^\mathrm{2}$. In this work, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on-bard of resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultra-low-power computing platform, and a 27 g commercial, open-source CrazyFlie 2.0 nano-quadrotor. As part of our general methodology we discuss the software mapping techniques that enable the state-of-the-art deep convolutional neural network presented in [1] to be fully executed on-board within a strict 6 fps real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner it achieves 18 fps while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft.",project-academic
,2020-04-21,a,,never stop learning the effectiveness of fine tuning in robotic reinforcement learning," One of the great promises of robot learning systems is that they will be able to learn from their mistakes and continuously adapt to ever-changing environments. Despite this potential, most of the robot learning systems today are deployed as a fixed policy and they are not being adapted after their deployment. Can we efficiently adapt previously learned behaviors to new environments, objects and percepts in the real world? In this paper, we present a method and empirical evidence towards a robot learning framework that facilitates continuous adaption. In particular, we demonstrate how to adapt vision-based robotic manipulation policies to new variations by fine-tuning via off-policy reinforcement learning, including changes in background, object shape and appearance, lighting conditions, and robot morphology. Further, this adaptation uses less than 0.2% of the data necessary to learn the task from scratch. We find that our approach of adapting pre-trained policies leads to substantial performance gains over the course of fine-tuning, and that pre-training via RL is essential: training from scratch or adapting from supervised ImageNet features are both unsuccessful with such small amounts of data. We also find that these positive results hold in a limited continual learning setting, in which we repeatedly fine-tune a single lineage of policies using data from a succession of new tasks. Our empirical conclusions are consistently supported by experiments on simulated manipulation tasks, and by 52 unique fine-tuning experiments on a real robotic grasping system pre-trained on 580,000 grasps.",project-academic
10.1109/IROS45743.2020.9341606,2020-10-24,p,IEEE,a framework for online updates to safe sets for uncertain dynamics," Safety is crucial for deploying robots in the real world. One way of reasoning about safety of robots is by building safe sets through Hamilton-Jacobi (HJ) reachability. However, safe sets are often computed offline, assuming perfect knowledge of the dynamics, due to high compute time. In the presence of uncertainty, the safe set computed offline becomes inaccurate online, potentially leading to dangerous situations on the robot. We propose a novel framework to learn a safe control policy in simulation, and use it to generate online safe sets under uncertain dynamics. We start with a conservative safe set and update it online as we gather more information about the robot dynamics. We also show an application of our framework to a model-based reinforcement learning problem, proposing a safe model-based RL setup. Our framework enables robots to simultaneously learn about their dynamics, accomplish tasks, and update their safe sets. It also generalizes to complex high-dimensional dynamical systems, like 3-link manipulators and quadrotors, and reliably avoids obstacles, while achieving a task, even in the presence of unmodeled noise.",project-academic
10.1109/CIRA.2007.382878,2007-06-20,p,IEEE,reinforcement learning with a supervisor for a mobile robot in a real world environment," This paper describes two experiments with supervised reinforcement learning (RL) on a real, mobile robot. Two types of experiments were preformed. One tests the robot's reliability in implementing a navigation task it has been taught by a supervisor. The other, in which new obstacles are placed along the previously learned path to the goal, measures the robot's robustness to changes in environment. Supervision consisted of human-guided, remote-controlled runs through a navigation task during the initial stages of reinforcement learning. The RL algorithms deployed enabled the robot to learn a path to a goal yet retain the ability to explore different solutions when confronted with a new obstacle. Experimental analysis was based on measurements of average time to reach the goal, the number of failed states encountered during an episode, and how closely the RL learner matched the supervisor's actions.",project-academic
10.1145/3406499.3418765,2020-11-10,p,ACM,at your service coffee beans recommendation from a robot assistant," With advances in the field of machine learning, service robots are envisioned to become more present. The COVID-19 pandemic has accelerated this need. One such example would be coffee shops, which have become intrinsic to our everyday lives. Yet, serving an excellent cup of coffee is not trivial as a coffee blend typically comprises rich aromas, indulgent and unique flavours. Our work addresses this by proposing a computational model which recommends optimal coffee beans resulting from users' preferences. Given coffee properties (objective features), we apply different supervised learning techniques to predict coffee qualities (subjective features). We then consider an unsupervised learning method to analyse the relationship between coffee beans in the subjective feature space. Evaluated on a real coffee beans dataset based on digitised reviews, our results illustrate that the proposed computational model gives up to 92.7 percent recommendation accuracy for coffee prediction. From this, we propose how it can be deployed on a robot.",project-academic
,2020-08-26,a,,at your service coffee beans recommendation from a robot assistant," With advances in the field of machine learning, precisely algorithms for recommendation systems, robot assistants are envisioned to become more present in the hospitality industry. Additionally, the COVID-19 pandemic has also highlighted the need to have more service robots in our everyday lives, to minimise the risk of human to-human transmission. One such example would be coffee shops, which have become intrinsic to our everyday lives. However, serving an excellent cup of coffee is not a trivial feat as a coffee blend typically comprises rich aromas, indulgent and unique flavours and a lingering aftertaste. Our work addresses this by proposing a computational model which recommends optimal coffee beans resulting from the user's preferences. Specifically, given a set of coffee bean properties (objective features), we apply different supervised learning techniques to predict coffee qualities (subjective features). We then consider an unsupervised learning method to analyse the relationship between coffee beans in the subjective feature space. Evaluated on a real coffee beans dataset based on digitised reviews, our results illustrate that the proposed computational model gives up to 92.7 percent recommendation accuracy for coffee beans prediction. From this, we propose how this computational model can be deployed on a service robot to reliably predict customers' coffee bean preferences, starting from the user inputting their coffee preferences to the robot recommending the coffee beans that best meet the user's likings.",project-academic
10.1109/ICRA40945.2020.9197523,2020-09-15,p,IEEE,snapnav learning mapless visual navigation with sparse directional guidance and visual reference," Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.",project-academic
,2019-01-22,a,,robust recovery controller for a quadrupedal robot using deep reinforcement learning," The ability to recover from a fall is an essential feature for a legged robot to navigate in challenging environments robustly. Until today, there has been very little progress on this topic. Current solutions mostly build upon (heuristically) predefined trajectories, resulting in unnatural behaviors and requiring considerable effort in engineering system-specific components. In this paper, we present an approach based on model-free Deep Reinforcement Learning (RL) to control recovery maneuvers of quadrupedal robots using a hierarchical behavior-based controller. The controller consists of four neural network policies including three behaviors and one behavior selector to coordinate them. Each of them is trained individually in simulation and deployed directly on a real system. We experimentally validate our approach on the quadrupedal robot ANYmal, which is a dog-sized quadrupedal system with 12 degrees of freedom. With our method, ANYmal manifests dynamic and reactive recovery behaviors to recover from an arbitrary fall configuration within less than 5 seconds. We tested the recovery maneuver more than 100 times, and the success rate was higher than 97 %.",project-academic
10.1016/J.MECHATRONICS.2018.08.011,2018-11-01,a,Pergamon,an interactive and intuitive control interface for a tele operated robot avatar system," Abstract None None Robotic systems, which are controlled by artificial intelligent or tele-operation control interfaces, have been developed to be deployed instead of the human in extreme environments. However, insufficient artificial intelligence performance in unknown and unpredictable environments, and non-intuitive control interfaces with low immersive feedback have prevented wide spread of such robotic systems. In this paper, an intuitive and interactive control interface with inertial measurement units (IMUs), haptic gloves and a head mounted display (HMD) was developed to control a tele-operated robot in remote environments, which was abbreviated as AVATAR system. The tele-operated robot can be operated by a user’s motions which are measured by the wearable interface. Through a kinematic analysis of the user and the tele-operated robot, desired robot joint angles are calculated to follow the user’s motions in real time. Also, dual cameras on the robot head provide 3D visual information around the robot to the user. A grasping force of the robot hands, measured by motor current, is transmitted to the user as vibration feedback to fingertips of the haptic gloves. A long term evolution (LTE) was used as wireless communication between the user and the robot. The performance of the proposed AVATAR system has been verified by experiments.",project-academic
10.1145/3386569.3392474,2020-07-08,a,Association for Computing Machinery (ACM),catch carry reusable neural controllers for vision guided whole body tasks," We address the longstanding challenge of producing flexible, realistic humanoid character controllers that can perform diverse whole-body tasks involving object interactions. This challenge is central to a variety of fields, from graphics and animation to robotics and motor neuroscience. Our physics-based environment uses realistic actuation and first-person perception - including touch sensors and egocentric vision - with a view to producing active-sensing behaviors (e.g. gaze direction), transferability to real robots, and comparisons to the biology. We develop an integrated neural-network based approach consisting of a motor primitive module, human demonstrations, and an instructed reinforcement learning regime with curricula and task variations. We demonstrate the utility of our approach for several tasks, including goal-conditioned box carrying and ball catching, and we characterize its behavioral robustness. The resulting controllers can be deployed in real-time on a standard PC.1",project-academic
,2019-11-15,a,,catch carry reusable neural controllers for vision guided whole body tasks," We address the longstanding challenge of producing flexible, realistic humanoid character controllers that can perform diverse whole-body tasks involving object interactions. This challenge is central to a variety of fields, from graphics and animation to robotics and motor neuroscience. Our physics-based environment uses realistic actuation and first-person perception -- including touch sensors and egocentric vision -- with a view to producing active-sensing behaviors (e.g. gaze direction), transferability to real robots, and comparisons to the biology. We develop an integrated neural-network based approach consisting of a motor primitive module, human demonstrations, and an instructed reinforcement learning regime with curricula and task variations. We demonstrate the utility of our approach for several tasks, including goal-conditioned box carrying and ball catching, and we characterize its behavioral robustness. The resulting controllers can be deployed in real-time on a standard PC. See overview video, this https URL .",project-academic
10.3389/FROBT.2021.630935,2021-01-01,a,Frontiers Media SA,a vision based sensing approach for a spherical soft robotic arm," Sensory feedback is essential for the control of soft robotic systems and to enable deployment in a variety of different tasks. Proprioception refers to sensing the robot's own state and is of crucial importance in order to deploy soft robotic systems outside of laboratory environments, i.e. where no external sensing, such as motion capture systems, is available. A vision-based sensing approach for a soft robotic arm made from fabric is presented, leveraging the high-resolution sensory feedback provided by cameras. No mechanical interaction between the sensor and the soft structure is required and consequently the compliance of the soft system is preserved. The integration of a camera into an inflatable, fabric-based bellow actuator is discussed. Three actuators, each featuring an integrated camera, are used to control the spherical robotic arm and simultaneously provide sensory feedback of the two rotational degrees of freedom. A convolutional neural network architecture predicts the two angles describing the robot's orientation from the camera images. Ground truth data is provided by a motion capture system during the training phase of the supervised learning approach and its evaluation thereafter. The camera-based sensing approach is able to provide estimates of the orientation in real-time with an accuracy of about one degree. The reliability of the sensing approach is demonstrated by using the sensory feedback to control the orientation of the robotic arm in closed-loop.",project-academic
,2020-12-11,a,,a vision based sensing approach for a spherical soft robotic arm," Sensory feedback is essential for the control of soft robotic systems and to enable deployment in a variety of different tasks. Proprioception refers to sensing the robot's own state and is of crucial importance in order to deploy soft robotic systems outside of laboratory environments, i.e. where no external sensing, such as motion capture systems, is available. 
A vision-based sensing approach for a soft robotic arm made from fabric is presented, leveraging the high-resolution sensory feedback provided by cameras. No mechanical interaction between the sensor and the soft structure is required and consequently, the compliance of the soft system is preserved. The integration of a camera into an inflatable, fabric-based bellow actuator is discussed. Three actuators, each featuring an integrated camera, are used to control the spherical robotic arm and simultaneously provide sensory feedback of the two rotational degrees of freedom. A convolutional neural network architecture predicts the two angles describing the robot's orientation from the camera images. Ground truth data is provided by a motion capture system during the training phase of the supervised learning approach and its evaluation thereafter. 
The camera-based sensing approach is able to provide estimates of the orientation in real-time with an accuracy of about one degree. The reliability of the sensing approach is demonstrated by using the sensory feedback to control the orientation of the robotic arm in closed-loop.",project-academic
10.1109/IROS45743.2020.9341340,2020-10-24,p,IEEE,applying surface normal information in drivable area and road anomaly detection for ground mobile robots," The joint detection of drivable areas and road anomalies is a crucial task for ground mobile robots. In recent years, many impressive semantic segmentation networks, which can be used for pixel-level drivable area and road anomaly detection, have been developed. However, the detection accuracy still needs improvement. Therefore, we develop a novel module named the Normal Inference Module (NIM), which can generate surface normal information from dense depth images with high accuracy and efficiency. Our NIM can be deployed in existing convolutional neural networks (CNNs) to refine the segmentation performance. To evaluate the effectiveness and robustness of our NIM, we embed it in twelve state-of-the-art CNNs. The experimental results illustrate that our NIM can greatly improve the performance of the CNNs for drivable area and road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the KITTI road benchmark and exhibits a real-time inference speed.",project-academic
10.3390/S20174836,2020-08-27,a,Multidisciplinary Digital Publishing Institute,distributed non communicating multi robot collision avoidance via map based deep reinforcement learning," It is challenging to avoid obstacles safely and efficiently for multiple robots of different shapes in distributed and communication-free scenarios, where robots do not communicate with each other and only sense other robots’ positions and obstacles around them. Most existing multi-robot collision avoidance systems either require communication between robots or require expensive movement data of other robots, like velocities, accelerations and paths. In this paper, we propose a map-based deep reinforcement learning approach for multi-robot collision avoidance in a distributed and communication-free environment. We use the egocentric local grid map of a robot to represent the environmental information around it including its shape and observable appearances of other robots and obstacles, which can be easily generated by using multiple sensors or sensor fusion. Then we apply the distributed proximal policy optimization (DPPO) algorithm to train a convolutional neural network that directly maps three frames of egocentric local grid maps and the robot’s relative local goal positions into low-level robot control commands. Compared to other methods, the map-based approach is more robust to noisy sensor data, does not require robots’ movement data and considers sizes and shapes of related robots, which make it to be more efficient and easier to be deployed to real robots. We first train the neural network in a specified simulator of multiple mobile robots using DPPO, where a multi-stage curriculum learning strategy for multiple scenarios is used to improve the performance. Then we deploy the trained model to real robots to perform collision avoidance in their navigation without tedious parameter tuning. We evaluate the approach with multiple scenarios both in the simulator and on four differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient and outperforms existing DRL-based approaches in many indicators. We also conduct ablation studies showing the positive effects of using egocentric grid maps and multi-stage curriculum learning.",project-academic
,2018-06-29,,,indoor human pose recognition method based on multi sensor fusion," The invention provides an indoor human pose recognition method based on multi-sensor fusion and belongs to an indoor scene recognition method of a mobile robot. The method comprises the following steps: 1) deploying an optical sensor, a depth sensor and an infrared sensor; 2) acquiring images of the three sensors in the same scene and calibrating the images of the three sensors; 3) recognizing thecurrent real-time human pose with a pre-trained deep neural network. Fusion processing and comprehensive decision making are performed on data of the multiple sensors with machine learning and a computer vision algorithm, various limitations and bottlenecks of the traditional recognition method based on single sensor are solved, and the recognition accuracy and robustness for various indoor humanposes are improved greatly.",project-academic
,2014-01-01,p,,multi robot human guidance using topological graphs," Prior approaches to human guidance using robots inside a building have typically been limited to a single robot guide that navigates a human from start to goal. However, due to their limited mobility, the robot is often unable to keep up with the human’s natural speed. In contrast, this paper addresses this difference in mobility between robots and people by presenting an approach that uses multiple robots to guide a human. Our approach uses a compact topological graph representation of the environment, and we first present the procedure for generating this representation. Next, we formulate the multi-robot guidance problem as a Markov Decision Process (MDP). Using a model of human motion in the presence of guiding robots, we define the transition function for this MDP. Finally, we solve the MDP using Value Iteration to obtain an optimal policy for placing robots and evaluate this policy’s effectiveness. Indoor environments such as airports, shopping malls, hospitals, and warehouse stores are characteristically full of people hurrying towards a destination or trying to locate a particular item. Often, they are unfamiliar with the environment and spend a fair amount of time locating these resources. With recent advancements in service robots, it is becoming far more feasible to deploy a large number of robots to aid humans in these environments. This paper studies how ubiquitous robots in an environment can be used to guide people efficiently to their destinations. Past research has explored the possibility of using a single robot to guide people (Thrun et al. 1999; Philippsen and Siegwart 2003). However, in environments densely packed with moving people and goods, navigating a guide robot the entire length from a human’s start location to their goal can be a significant challenge. The same navigation task can be completed far more efficiently by people, and yet they become limited by the navigation speed of the guide. A multirobot solution can make use of a human’s ease of navigation by proactively placing robots where the human is likely to need help in the future. Whenever the system needs to guide a human at a specific location, it can commission a nearby robot to direct the human towards the next objective, whether it be another guide robot or the goal. Once that Copyright c ￿ 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. robot’s task is completed, it can go back to performing its other duties. Potentially, this approach can greatly reduce the time each individual robot has to spend guiding the human, allowing robots to assist more people in the same time. This paper specifically studies the problem of deciding where to place robots in an environment to guide a human as he or she moves around. First, we formulate this multi-robot guidance problem as a Markov Decision Process (MDP), and use a hand-coded model of human motion in the presence of guide robots to define the transition function for this MDP. We then use Value Iteration (Sutton and Barto 1998) to solve this MDP, generating an optimal solution for placing robots. Such a solution can take the uncertainty in a human’s movement into account and avoid actions that have a significant probability of failure. Finally, we evaluate the generated policy by comparing it against a heuristic solution for deciding robot placements. Experiments are run using the model of human motion, as well as with avatars controlled by real humans in a simulation environment. To reason about human movement and robot placements, a representation of the environment is required. This paper uses a topological graph representation of the environment for reasoning (see Fig. 1h). Topological graphs can provide a compact representation of the environment while still retaining all key locations and the connectivity between these locations. The process of topological graph generation described in this paper is built on previous work (Thrun and Bucken 1996). As such, the main contribution of this paper is the procedure for generating topological graphs, formulating the multi-robot guidance problem as an MDP using these topological graphs, and solving the MDP using Value Iteration to produce the best graph nodes for placing robots. All code in this paper has been implemented using the ROS middleware package (Quigley et al. 2009) and is available in the public domain along with videos from the experiments1.",project-academic
10.1021/ACS.ACCOUNTS.0C00736,2021-01-20,a,American Chemical Society,automated experimentation powers data science in chemistry," Data science has revolutionized chemical research and continues to break down barriers with new interdisciplinary studies. The introduction of computational models and machine learning (ML) algorithms in combination with automation and traditional experimental techniques has enabled scientific advancement across nearly every discipline of chemistry, from materials discovery, to process optimization, to synthesis planning. However, predictive tools powered by data science are only as good as their data sets and, currently, many of the data sets used to train models suffer from several limitations, including being sparse, limited in scope and requiring human curation. Likewise, computational data faces limitations in terms of accurate modeling of nonideal systems and can suffer from low translation fidelity from simulation to real conditions. The lack of diverse data and the need to be able to test it experimentally reduces both the accuracy and scope of the predictive models derived from data science. This Account contextualizes the need for more complex and diverse experimental data and highlights how the seamless integration of robotics, machine learning, and data-rich monitoring techniques can be used to access it with minimal human labor.We propose three broad categories of data in chemistry: data on fundamental properties, data on reaction outcomes, and data on reaction mechanics. We highlight flexible, automated platforms that can be deployed to acquire and leverage these data. The first platform combines solid- and liquid-dosing modules with computer vision to automate solubility screening, thereby gathering fundamental data that are necessary for almost every experimental design. Using computer vision offers the additional benefit of creating a visual record, which can be referenced and used to further interrogate and gain insight on the data collected. The second platform iteratively tests reaction variables proposed by a ML algorithm in a closed-loop fashion. Experimental data related to reaction outcomes are fed back into the algorithm to drive the discovery and optimization of new materials and chemical processes. The third platform uses automated process analytical technology to gather real-time data related to reaction kinetics. This system allows the researcher to directly interrogate the reaction mechanisms in granular detail to determine exactly how and why a reaction proceeds, thereby enabling reaction optimization and deployment.",project-academic
10.1007/978-3-030-89098-8_12,2021-10-22,p,"Springer, Cham",dorep 2 0 an upgraded version of robot control teaching experimental platform with reinforcement learning and visual analysis," The Deep Open Robot Experiment Platform (DOREP) is an experimental system for general robot control. It includes a robot toolbox, a Linux based real-time controller and corresponding environment deployment tools. It is compatible with ROKAE robots, Universal robots, ABB robots, AUBO robots and other 6-DOF small low load general robots. It aims to provide users with a direct, high-level, more open and comprehensive programming interface. The toolbox of the original version of DOREP system contains more than 30 functions, including forward and inverse kinematics calculation, point-to-point joint and Cartesian control, trajectory generation, graphic display, 3D animation and diagnosis. On the basis of the original version, DOREP 2.0 system adds some new functional modules such as reinforcement learning and visual analysis, which further improves the performance of DOREP system. Taking the newly added module as an example, this paper expounds the functions of reinforcement learning module and visual analysis module, and applies them to simulation and experiment successfully.",project-academic
,2019-12-31,a,,mir vehicle cost effective research platform for autonomous vehicle applications," This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a feasible option of transforming an electric ride-on-car into a modular Graphics Processing Unit (GPU) powered autonomous platform equipped with the capability that supports test and deployment of various intelligent autonomous vehicles algorithms. To use a platform for research, two components must be provided: perception and control. The sensors such as incremental encoders, an Inertial Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR) must be able to be installed on the platform to add the capability of environmental perception. A microcontroller-powered control box is designed to properly respond to the environmental changes by regulating drive and steering motors. This drive-by-wire capability is controlled by a GPU powered laptop computer where high-level perception algorithms are processed and complex actions are generated by various methods including behavior cloning using deep neural networks. The main goal of this paper is to provide an adequate and comprehensive approach for fabricating a cost-effective platform that would contribute to the research quality from the wider community. The proposed platform is to use a modular and hierarchical software architecture where the lower and simpler motor controls are taken care of by microcontroller programs, and the higher and complex algorithms are processed by a GPU powered laptop computer. The platform uses the Robot Operating System (ROS) as middleware to maintain the modularity of the perceptions and decision-making modules. It is expected that the level three and above autonomous vehicle systems and Advanced Driver Assistance Systems (ADAS) can be tested on and deployed to the platform with a decent real-time system behavior due to the capabilities and affordability of the proposed platform.",project-academic
10.1109/TDSC.2019.2903049,2021-03-01,a,IEEE,real time error detection in nonlinear control systems using machine learning assisted state space encoding," Successful deployment of autonomous systems in a wide range of societal applications depends on error-free operation of the underlying signal processing and control functions. Real-time error detection in nonlinear systems has mostly relied on redundancy at the component or algorithmic level causing expensive area and power overheads. This paper describes a real-time error detection methodology for nonlinear control systems for detecting sensor and actuator degradations as well as malfunctions due to soft errors in the execution of the control algorithm on a digital processor. Our approach is based on creation of a redundant check state in such a way that its value can be computed from the current states of the system as well as from a history of prior observable state values and inputs (via machine learning algorithms). By checking for consistency between the two, errors are detected with low latency. The method is demonstrated on two test case simulations - an inverted pendulum balancing problem and a sliding mode controller driven brake-by-wire (BBW) system. In addition, hardware results from error injection experiments in an ARM core representation on an FPGA and artificial sensor degradations on a self-balancing robot prove the practical feasibility of implementation.",project-academic
10.1109/LRA.2021.3064284,2020-08-18,a,,super human performance in gran turismo sport using deep reinforcement learning," Autonomous car racing is a major challenge in robotics. It raises fundamental problems for classical approaches such as planning minimum-time trajectories under uncertain dynamics and controlling the car at the limits of its handling. Besides, the requirement of minimizing the lap time, which is a sparse objective, and the difficulty of collecting training data from human experts have also hindered researchers from directly applying learning-based approaches to solve the problem. In the present work, we propose a learning-based system for autonomous car racing by leveraging a high-fidelity physical car simulation, a course-progress proxy reward, and deep reinforcement learning. We deploy our system in Gran Turismo Sport, a world-leading car simulator known for its realistic physics simulation of different race cars and tracks, which is even used to recruit human race car drivers. Our trained policy achieves autonomous racing performance that goes beyond what had been achieved so far by the built-in AI, and, at the same time, outperforms the fastest driver in a dataset of over 50,000 human players.",project-academic
10.1016/J.ENGAPPAI.2019.103427,2020-03-01,a,Pergamon,stochastic parallel extreme artificial hydrocarbon networks an implementation for fast and robust supervised machine learning in high dimensional data," Abstract None None Artificial hydrocarbon networks (AHN) – a supervised learning method inspired on organic chemical structures and mechanisms – have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than None None None None 10 None , None 000 None x None None None None times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential.",project-academic
,2020-03-06,a,,practical reinforcement learning for mpc learning from sparse objectives in under an hour on a real robot," Model Predictive Control (MPC) is a powerful control technique that handles constraints, takes the system's dynamics into account, and optimizes for a given cost function. In practice, however, it often requires an expert to craft and tune this cost function and find trade-offs between different state penalties to satisfy simple high level objectives. In this paper, we use Reinforcement Learning and in particular value learning to approximate the value function given only high level objectives, which can be sparse and binary. Building upon previous works, we present improvements that allowed us to successfully deploy the method on a real world unmanned ground vehicle. Our experiments show that our method can learn the cost function from scratch and without human intervention, while reaching a performance level similar to that of an expert-tuned MPC. We perform a quantitative comparison of these methods with standard MPC approaches both in simulation and on the real robot.",project-academic
10.3929/ETHZ-B-000404690,2020-07-31,p,OpenReview,practical reinforcement learning for mpc learning from sparse objectives in under an hour on a real robot," Model Predictive Control (MPC) is a powerful control technique that handles constraints, takes the system's dynamics into account, and optimizes for a given cost function. In practice, however, it often requires an expert to craft and tune this cost function and find trade-offs between different state penalties to satisfy simple high level objectives. In this paper, we use Reinforcement Learning and in particular value learning to approximate the value function given only high level objectives, which can be sparse and binary. Building upon previous works, we present improvements that allowed us to successfully deploy the method on a real world unmanned ground vehicle. Our experiments show that our method can learn the cost function from scratch and without human intervention, while reaching a performance level similar to that of an expert-tuned MPC. We perform a quantitative comparison of these methods with standard MPC approaches both in simulation and on the real robot.",project-academic
,2018-07-30,a,,learning to interrupt a hierarchical deep reinforcement learning framework for efficient exploration," To achieve scenario intelligence, humans must transfer knowledge to robots by developing goal-oriented algorithms, which are sometimes insensitive to dynamically changing environments. While deep reinforcement learning achieves significant success recently, it is still extremely difficult to be deployed in real robots directly. In this paper, we propose a hybrid structure named Option-Interruption in which human knowledge is embedded into a hierarchical reinforcement learning framework. Our architecture has two key components: options, represented by existing human-designed methods, can significantly speed up the training process and interruption mechanism, based on learnable termination functions, enables our system to quickly respond to the external environment. To implement this architecture, we derive a set of update rules based on policy gradient methods and present a complete training process. In the experiment part, our method is evaluated in Four-room navigation and exploration task, which shows the efficiency and flexibility of our framework.",project-academic
10.1007/S11432-019-9932-3,2019-09-19,a,Science China Press,accelerating dnn based 3d point cloud processing for mobile computing," 3D point cloud data, which are produced by various 3D sensors such as LIDAR and stereo cameras, have been widely deployed by industry leaders such as Google, Uber, Tesla, and Mobileye, for mobile robotic applications such as autonomous driving and humanoid robots. Point cloud data, which are composed of reliable depth information, can provide accurate location and shape characteristics for scene understanding, such as object recognition and semantic segmentation. However, deep neural networks (DNNs), which directly consume point cloud data, are particularly computation-intensive because they have to not only perform multiplication-and-accumulation (MAC) operations but also search neighbors from the irregular 3D point cloud data. Such a task goes beyond the capabilities of general-purpose processors in real-time to figure out the solution as the scales of both point cloud data and DNNs increase from application to application. We present the first accelerator architecture that dynamically configures the hardware on-the-fly to match the computation of both neighbor point search and MAC computation for point-based DNNs. To facilitate the process of neighbor point search and reduce the computation costs, a grid-based algorithm is introduced to search neighbor points from a local region of grids. Evaluation results based on the scene recognition and segmentation tasks show that the proposed design harvests 16.4$\times$ higher performance and saves 99.95% of energy than an NVIDIA Tesla K40 GPU baseline in point cloud scene understanding applications.",project-academic
10.1109/ICRA.2017.7989323,2017-05-01,p,Institute of Electrical and Electronics Engineers (IEEE),semantic web mining and deep vision for lifelong object discovery," Autonomous robots that are to assist humans in their daily lives must recognize and understand the meaning of objects in their environment. However, the open nature of the world means robots must be able to learn and extend their knowledge about previously unknown objects on-line. In this work we investigate the problem of unknown object hypotheses generation, and employ a semantic web-mining framework along with deep-learning-based object detectors. This allows us to make use of both visual and semantic features in combined hypotheses generation. Experiments on data from mobile robots in real world application deployments show that this combination improves performance over the use of either method in isolation.",project-academic
,2018-07-09,p,International Foundation for Autonomous Agents and Multiagent Systems,incrementally learning semantic attributes through dialogue interaction," Enabling a robot to properly interact with users plays a key role in the effective deployment of robotic platforms in domestic environments. Robots must be able to rely on interaction to improve their behaviour and adaptively understand their operational world. Semantic mapping is the task of building a representation of the environment, that can be enhanced through interaction with the user. In this task, a proper and effective acquisition of semantic attributes of targeted entities is essential for the task accomplishment itself. In this paper, we focus on the problem of learning dialogue policies to support semantic attribute acquisition, so that the effort required by humans in providing knowledge to the robot through dialogue is minimized. To this end, we design our Dialogue Manager as a multi-objective Markov Decision Process, solving the optimisation problem through Reinforcement Learning. The Dialogue Manager interfaces with an online incremental visual classifier, based on a Load-Balancing Self-Organizing Incremental Neural Network (LB-SOINN). Experiments in a simulated scenario show the effectiveness of the proposed solution, suggesting that perceptual information can be properly exploited to reduce human tutoring cost. Moreover, a dialogue policy trained on a small amount of data generalises well to larger datasets, and so the proposed online scheme, as well as the real-time nature of the processing, are suited for an extensive deployment in real scenarios. To this end, this paper provides a demonstration of the complete system on a real robot.",project-academic
,2018-11-21,a,,integrating task motion planning with reinforcement learning for robust decision making in mobile robots," Task-motion planning (TMP) addresses the problem of efficiently generating executable and low-cost task plans in a discrete space such that the (initially unknown) action costs are determined by motion plans in a corresponding continuous space. However, a task-motion plan can be sensitive to unexpected domain uncertainty and changes, leading to suboptimal behaviors or execution failures. In this paper, we propose a novel framework, TMP-RL, which is an integration of TMP and reinforcement learning (RL) from the execution experience, to solve the problem of robust task-motion planning in dynamic and uncertain domains. TMP-RL features two nested planning-learning loops. In the inner TMP loop, the robot generates a low-cost, feasible task-motion plan by iteratively planning in the discrete space and updating relevant action costs evaluated by the motion planner in continuous space. In the outer loop, the plan is executed, and the robot learns from the execution experience via model-free RL, to further improve its task-motion plans. RL in the outer loop is more accurate to the current domain but also more expensive, and using less costly task and motion planning leads to a jump-start for learning in the real world. Our approach is evaluated on a mobile service robot conducting navigation tasks in an office area. Results show that TMP-RL approach significantly improves adaptability and robustness (in comparison to TMP methods) and leads to rapid convergence (in comparison to task planning (TP)-RL methods). We also show that TMP-RL can reuse learned values to smoothly adapt to new scenarios during long-term deployments.",project-academic
10.1109/LRA.2020.3013937,2020-08-04,p,IEEE,invariant transform experience replay data augmentation for deep reinforcement learning," Deep Reinforcement Learning (RL) is a promising approach for adaptive robot control, but its current application to robotics is currently hindered by high sample requirements. To alleviate this issue, we propose to exploit the symmetries present in robotic tasks. Intuitively, symmetries from observed trajectories define transformations that leave the space of feasible RL trajectories invariant and can be used to generate new feasible trajectories, which could be used for training. Based on this data augmentation idea, we formulate a general framework, called Invariant Transform Experience Replay that we present with two techniques: (i) Kaleidoscope Experience Replay exploits reflectional symmetries and (ii) Goal-augmented Experience Replay which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI Gym, our experimental results show significant increases in learning rates and success rates. Particularly, we attain a 13, 3, and 5 times speedup in the pushing, sliding, and pick-and-place tasks respectively in the multi-goal setting. Performance gains are also observed in similar tasks with obstacles and we successfully deployed a trained policy on a real Baxter robot. Our work demonstrates that invariant transformations on RL trajectories are a promising methodology to speed up learning in deep RL. Code, video, and supplementary materials are available at [1].",project-academic
,2020-09-01,a,,deep samplable observation model for global localization and kidnapping," Global localization and kidnapping are two challenging problems in robot localization. The popular method, Monte Carlo Localization (MCL) addresses the problem by iteratively updating a set of particles with a ""sampling-weighting"" loop. Sampling is decisive to the performance of MCL [1]. However, traditional MCL can only sample from a uniform distribution over the state space. Although variants of MCL propose different sampling models, they fail to provide an accurate distribution or generalize across scenes. To better deal with these problems, we present a distribution proposal model, named Deep Samplable Observation Model (DSOM). DSOM takes a map and a 2D laser scan as inputs and outputs a conditional multimodal probability distribution of the pose, making the samples more focusing on the regions with higher likelihood. With such samples, the convergence is expected to be more effective and efficient. Considering that the learning-based sampling model may fail to capture the true pose sometimes, we furthermore propose the Adaptive Mixture MCL (AdaM MCL), which deploys a trusty mechanism to adaptively select updating mode for each particle to tolerate this situation. Equipped with DSOM, AdaM MCL can achieve more accurate estimation, faster convergence and better scalability compared to previous methods in both synthetic and real scenes. Even in real environments with long-term changing, AdaM MCL is able to localize the robot using DSOM trained only by simulation observations from a SLAM map or a blueprint map.",project-academic
10.1109/LRA.2021.3061339,2021-02-23,p,Institute of Electrical and Electronics Engineers (IEEE),deep samplable observation model for global localization and kidnapping," Global localization and kidnapping are two challenging problems in robot localization. The popular method, Monte Carlo Localization (MCL) addresses the problem by iteratively updating a set of particles with a “sampling-weighting” loop. Sampling is decisive to the performance of MCL None [1] . However, traditional MCL can only sample from a uniform distribution over the state space. Although variants of MCL propose different sampling models, they fail to provide an accurate distribution or generalize across scenes. To better deal with these problems, we present a distribution proposal model named Deep Samplable Observation Model (DSOM). DSOM takes a map and a 2D laser scan as inputs and outputs a conditional multimodal probability distribution of the pose, making the samples more focusing on the regions with higher likelihood. With such samples, the convergence is expected to be more effective and efficient. Considering that the learning-based sampling model may fail to capture the accurate pose sometimes, we furthermore propose the Adaptive Mixture MCL (AdaM MCL), which deploys a trusty mechanism to adaptively select updating mode for each particle to tolerate this situation. Equipped with DSOM, AdaM MCL can achieve more accurate estimation, faster convergence and better scalability than previous methods in both synthetic and real scenes. Even in real environments with long-term changes, AdaM MCL is able to localize the robot using DSOM trained only by simulation observations from a SLAM map or a blueprint map. Source code for this paper is available here: None https://github.com/Runjian-Chen/AdaM_MCL .",project-academic
,2009-05-10,p,International Foundation for Autonomous Agents and Multiagent Systems,an empirical analysis of value function based and policy search reinforcement learning," In several agent-oriented scenarios in the real world, an autonomous agent that is situated in an unknown environment must learn through a process of trial and error to take actions that result in long-term benefit. Reinforcement Learning (or sequential decision making) is a paradigm well-suited to this requirement. Value function-based methods and policy search methods are contrasting approaches to solve reinforcement learning tasks. While both classes of methods benefit from independent theoretical analyses, these often fail to extend to the practical situations in which the methods are deployed. We conduct an empirical study to examine the strengths and weaknesses of these approaches by introducing a suite of test domains that can be varied for problem size, stochasticity, function approximation, and partial observability. Our results indicate clear patterns in the domain characteristics for which each class of methods excels. We investigate whether their strengths can be combined, and develop an approach to achieve that purpose. The effectiveness of this approach is also demonstrated on the challenging benchmark task of robot soccer Keepaway. We highlight several lines of inquiry that emanate from this study.",project-academic
10.1109/LRA.2021.3056371,2021-02-03,p,IEEE,learning optimal impedance control during complex 3d arm movements," Humans use their limbs to perform various movements to interact with an external environment. Thanks to limb's variable and adaptive stiffness, humans can adapt their movements to the external unstable dynamics. The underlying adaptive mechanism has been investigated, employing a simple planar device perturbed by external 2D force patterns. In this work, we will employ a more advanced, compliant robot arm to extend previous work to a more realistic 3D-setting. We study the adaptive mechanism and use machine learning to capture the human adaptation behavior. In order to model human's stiffness adaptive skill, we give human subjects the task to reach for a target by moving a handle assembled on the end-effector of a compliant robotic arm. The arm is force controlled and the human is required to navigate the handle inside a non-visible, virtual maze and explore it only through robot force feedback when contacting maze virtual walls. By sampling the hand's position and force data, a computational model based on a combination of model predictive control and nonlinear regression is used to predict participants' successful trials. Our study shows that participants selectively increased the stiffness within the axis direction of uncertainty to compensate for instability caused by a divergent external force field. The learned controller was able to successfully mimic this behavior. When it is deployed on the robot for the navigation task, the robot arm successfully adapt to the unstable dynamics in the virtual maze, in a similar manner as observed in the participants’ adaptation skill.",project-academic
10.1109/IROS.2018.8594243,2018-12-27,p,"IEEE, Institute of Electrical and Electronics Engineers",cream condensed real time models for depth prediction using convolutional neural networks," Since the resurgence of CNNs the robotic vision community has developed a range of algorithms that perform classification, semantic segmentation and structure prediction (depths, normals, surface curvature) using neural networks. While some of these models achieve state-of-the art results and super human level performance, deploying these models in a time critical robotic environment remains an ongoing challenge. Real-time frameworks are of paramount importance to build a robotic society where humans and robots integrate seamlessly. To this end, we present a novel real-time structure prediction framework that predicts depth at 30 frames per second on an NVIDIA-TX2. At the time of writing, this is the first piece of work to showcase such a capability on a mobile platform. We also demonstrate with extensive experiments that neural networks with very large model capacities can be leveraged in order to train accurate condensed model architectures in a “from teacher to student” style knowledge transfer.",project-academic
,2018-07-24,a,,cream condensed real time models for depth prediction using convolutional neural networks," Since the resurgence of CNNs the robotic vision community has developed a range of algorithms that perform classification, semantic segmentation and structure prediction (depths, normals, surface curvature) using neural networks. While some of these models achieve state-of-the art results and super human level performance, deploying these models in a time critical robotic environment remains an ongoing challenge. Real-time frameworks are of paramount importance to build a robotic society where humans and robots integrate seamlessly. To this end, we present a novel real-time structure prediction framework that predicts depth at 30fps on an NVIDIA-TX2. At the time of writing, this is the first piece of work to showcase such a capability on a mobile platform. We also demonstrate with extensive experiments that neural networks with very large model capacities can be leveraged in order to train accurate condensed model architectures in a ""from teacher to student"" style knowledge transfer.",project-academic
,2011-01-01,a,,autonomous robot skill acquisition," Among the most impressive of aspects of human intelligence is skill acquisition—the ability to identify important behavioral components, retain them as skills, refine them through practice, and apply them in new task contexts. Skill acquisition underlies both our ability to choose to spend time and effort to specialize at particular tasks, and our ability to collect and exploit previous experience to become able to solve harder and harder problems over time with less and less cognitive effort. 
Hierarchical reinforcement learning provides a theoretical basis for skill acquisition, including principled methods for learning new skills and deploying them during problem solving. However, existing work focuses largely on small, discrete problems. This dissertation addresses the question of how we scale such methods up to high-dimensional, continuous domains, in order to design robots that are able to acquire skills autonomously. This presents three major challenges; we introduce novel methods addressing each of these challenges. 
First, how does an agent operating in a continuous environment discover skills? Although the literature contains several methods for skill discovery in discrete environments, it offers none for the general continuous case. We introduce skill chaining, a general skill discovery method for continuous domains. Skill chaining incrementally builds a skill tree that allows an agent to reach a solution state from any of its start states by executing a sequence (or chain) of acquired skills. We empirically demonstrate that skill chaining can improve performance over monolithic policy learning in the Pinball domain, a challenging dynamic and continuous reinforcement learning problem. 
Second, how do we scale up to high-dimensional state spaces? While learning in relatively small domains is generally feasible, it becomes exponentially harder as the number of state variables grows. We introduce abstraction selection, an efficient algorithm for selecting skill-specific, compact representations from a library of available representations when creating a new skill. Abstraction selection can be combined with skill chaining to solve hard tasks by breaking them up into chains of skills, each defined using an appropriate abstraction. We show that abstraction selection selects an appropriate representation for a new skill using very little sample data, and that this leads to significant performance improvements in the Continuous Playroom, a relatively high-dimensional reinforcement learning problem. 
Finally, how do we obtain good initial policies? The amount of experience required to learn a reasonable policy from scratch in most interesting domains is unrealistic for robots operating in the real world. We introduce CST, an algorithm for rapidly constructing skill trees (with appropriate abstractions) from sample trajectories obtained via human demonstration, a feedback controller, or a planner. We use CST to construct skill trees from human demonstration in the Pinball domain, and to extract a sequence of low-dimensional skills from demonstration trajectories on a mobile robot. The resulting skills can be reliably reproduced using a small number of example trajectories. 
Finally, these techniques are applied to build a mobile robot control system for the uBot-5, resulting in a mobile robot that is able to acquire skills autonomously. We demonstrate that this system is able to use skills acquired in one problem to more quickly solve a new problem.",project-academic
10.1109/LRA.2021.3061336,2021-02-23,p,IEEE,imitation learning of hierarchical driving model from continuous intention to continuous trajectory," One of the challenges to reduce the gap between the machine and the human level driving is how to endow the system with the learning capacity to deal with the coupled complexity of environments, intentions, and dynamics. In this letter, we propose a hierarchical driving model with explicit models of continuous intention and continuous dynamics, which decouples the complexity in the observation-to-action reasoning in the human driving data. Specifically, the continuous intention module takes perception to generate a potential map encoded with obstacles and intentions. Then, the potential map is regarded as a condition, together with the current dynamics, to generate a continuous trajectory as output by a continuous function approximator network, whose derivatives can be used for supervision without additional parameters. Finally, our method is validated by both datasets and stimulation, demonstrating that our method has higher prediction accuracy of displacement and velocity and generates smoother trajectories. Our method is also deployed on the real vehicle with loop latency, validating its effectiveness. To the best of our knowledge, this is the first work to produce the driving trajectory using a continuous function approximator network. Our code is available at None https://github.com/ZJU-Robotics-Lab/CICT .",project-academic
,2021-05-21,a,,learning visible connectivity dynamics for cloth smoothing," Robotic manipulation of cloth remains challenging for robotics due to the complex dynamics of the cloth, lack of a low-dimensional state representation, and self-occlusions. In contrast to previous model-based approaches that learn a pixel-based dynamics model or a compressed latent vector dynamics, we propose to learn a particle-based dynamics model from a partial point cloud observation. To overcome the challenges of partial observability, we infer which visible points are connected on the underlying cloth mesh. We then learn a dynamics model over this visible connectivity graph. Compared to previous learning-based approaches, our model poses strong inductive bias with its particle based representation for learning the underlying cloth physics; it is invariant to visual features; and the predictions can be more easily visualized. We show that our method greatly outperforms previous state-of-the-art model-based and model-free reinforcement learning methods in simulation. Furthermore, we demonstrate zero-shot sim-to-real transfer where we deploy the model trained in simulation on a Franka arm and show that the model can successfully smooth different types of cloth from crumpled configurations. Videos can be found on our project website.",project-academic
10.1007/978-3-030-27544-0_8,2018-06-18,p,"Springer, Cham",real time scene understanding using deep neural networks for robocup spl," Convolutional neural networks (CNNs) are the state-of-the-art method for most computer vision tasks. But, the deployment of CNNs on mobile or embedded platforms is challenging because of CNNs’ excessive computational requirements. We present an end-to-end neural network solution to scene understanding for robot soccer. We compose two key neural networks: one to perform semantic segmentation on an image, and another to propagate class labels between consecutive frames. We trained our networks on synthetic datasets and fine-tuned them on a set consisting of real images from a Nao robot. Furthermore, we investigate and evaluate several practical methods for increasing the efficiency and performance of our networks. Finally, we present RoboDNN, a C++ neural network library designed for fast inference on the Nao robots.",project-academic
10.1109/ETS.2017.7968218,2017-05-22,p,IEEE,real time self learning for control law adaptation in nonlinear systems using encoded check states," With the wide proliferation of autonomous sense-and-control real-time systems (such as robots and self-driven cars), a key research objective is rapid recovery from the effects of anomalies and impairments arising from performance degradation of sensors and actuators and electro-mechanical subsystems due to field wear and tear. This must be achieved with minimal impact on system performance while maintaining low implementation overhead and high coverage of multi-parameter failure mechanisms. In this work, we propose a reinforcement learning framework for on-line control law adaptation in autonomous nonlinear systems assisted by system state encodings. These encodings are exploited to generate time-varying error signals whose (transient) waveforms in relation to the input stimulus, contain root-cause diagnostic information. This establishes a statistical correlation between the transient waveforms and the parameters of the optimal nonlinear controller under arbitrary multi-parameter perturbations of sensor/actuator and subsystem performances. Consequently this correlation is tapped, using pre-deployment supervised learning algorithms, to predict near-optimal controller parameter values whenever sufficiently large parameter deviations are detected (due to non-zero error signals). From these near-optimal starting conditions, an actor-critic reinforcement learning controller for nonlinear systems quickly converges to the optimal control law for the parameter-perturbed system (up to 10× faster than for systems not assisted by the diagnostic information provided by the state encoding driven error signal above). We implement the proposed methodology on two nonlinear systems demonstrating fast performance recovery in real time.",project-academic
,2019-05-08,p,International Foundation for Autonomous Agents and Multiagent Systems,actor based simulation for closed loop control of supply chain using reinforcement learning," Reinforcement Learning (RL) has achieved a degree of success in control applications such as online gameplay and robotics, but has rarely been used to manage operations of business-critical systems such as supply chains. A key aspect of using RL in the real world is to train the agent before deployment, so as to minimise experimentation in live operation. While this is feasible for online gameplay (where the rules of the game are known) and robotics (where the dynamics are predictable), it is much more difficult for complex systems due to associated complexities, such as uncertainty, adaptability and emergent behaviour. In this paper, we describe a framework for effective integration of a reinforcement learning controller with an actor-based simulation of the complex networked system, in order to enable deployment of the RL agent in the real system with minimal further tuning.",project-academic
10.1109/ICRA.2013.6631325,2013-05-06,p,IEEE,deploying artificial landmarks to foster data association in simultaneous localization and mapping," Data association is an essential problem in simultaneous localization and mapping. It is hard to solve correctly, especially in ambiguous environments. We consider a scenario where the robot can ease the data association problem by deploying a limited number of uniquely identifiable artificial landmarks along its path and use them afterwards as fixed anchors. Obviously, the choice of the positions where the robot should drop these markers is crucial as poor choices might prevent the robot from establishing accurate data associations. In this paper, we present a novel approach for learning when to drop the landmarks so as to optimize the data association performance. We use Monte Carlo reinforcement learning for computing an optimal policy and apply a statistical convergence test to decide if the policy is converged and the learning process can be stopped. Extensive experiments also carried out with a real robot demonstrate that the data association performance using landmarks deployed according to our learned policies is significantly higher compared to other strategies.",project-academic
10.1016/J.IMAGE.2018.09.013,2019-02-01,a,Elsevier,object instance detection with pruned alexnet and extended training data," Abstract None None Object instance detection has garnered much concern in many practical applications, especially in the field of intelligent service robot. Imagine robots working in real scenes, one may expect the instance detection system to be light-weighted to enable mobile or embedded system deployment. Focusing on reconstructing a smaller learning network from a noted deep model,we have pruned Alexnet to a compressed model with fewer parameters but equivalent accuracy, denoted as BING-Pruned Alexnet(B-PA). Our method first utilizes BING(Binarized Normed Gradient) to compute bounding boxes, then builds a pruned network for recognition by reducing neurons and cutting fully connected layers on the classic architecture Alexnet. Since the training samples for instance detection are limited and of small variation, we extend the training data by combining data augmentation with synthetic generation. In the end, our B-PA network occupies only 5MB, which is 50 times smaller than the original Alexnet, but can still achieve Alexnet-level accuracy when recognizing on GMU Kitchen dataset. Numerical experiments are conducted to compare our algorithm with the state-of-art instance detection algorithms on a self-made BHID database and two public database i.e.,WRGB-D dataset and GMU Kitchen dataset, which demonstrate that B-PA reduces the storage requirements of neural networks substantially while preserving generalization performance on object instance detection.",project-academic
10.1007/S11628-020-00423-8,2020-01-01,a,Springer Berlin Heidelberg,impacts of service robots on service quality," With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority.",project-academic
10.1088/1742-6596/1746/1/012035,2021-01-01,a,IOP Publishing,robotdrlsim a real time robot simulation platform for reinforcement learning and human interactive demonstration learning," Deep reinforcement learning (DRL) techniques give robotics research an AI boost in many applications. In order to simultaneously accommodate the complex robotic behaviour simulation and DRL algorithm verification, a new simulation platform, namely the RobotDrlSim, is proposed.First, we design a standardized API interfacing mechanism for coordinating diverse environments on RobotDrlSim platform, where PyBullet simulator is equipped with an API to form a physical engine for robotics simulation. Second, benchmark DRL models are included in the baseline library for evaluation. Third, real-time human-robot interactions can be captured and imported to drive the RobotDrlSim tasks, which provide big data-stream for reinforcement learning. Experimentations show that cutting-edge DRL algorithms developed in python can be seamlessly deployed to the robots, and human interactions can be availed in training the robots. RobotDrlSim is valid for efficiently developing DRL algorithms for artificial intelligence models of robots, and it is especially suitable for the robot educational purposes.",project-academic
,2020-11-22,p,,robotdrlsim a real time robot simulation platform for reinforcement learning and human interactive demonstration learning," Deep reinforcement learning (DRL) techniques give robotics research an AI boost in many applications. In order to simultaneously accommodate the complex robotic behaviour simulation and DRL algorithm verification, a new simulation platform, namely the RobotDrlSim, is proposed. First, we design a standardized API interfacing mechanism for coordinating diverse environments on RobotDrlSim platform, where PyBullet simulator is equipped with an API to form a physical engine for robotics simulation. Second, benchmark DRL models are included in the baseline library for evaluation. Third, real-time human-robot interactions can be captured and imported to drive the RobotDrlSim tasks, which provide big data-stream for reinforcement learning. Experimentations show that cutting-edge DRL algorithms developed in python can be seamlessly deployed to the robots, and human interactions can be availed in training the robots. RobotDrlSim is valid for efficiently developing DRL algorithms for artificial intelligence models of robots, and it is especially suitable for the robot educational purposes.",project-academic
10.1177/1548512916628335,2019-04-01,a,SAGE Publications,securing unmanned autonomous systems from cyber threats," Unmanned systems, with and without a human-in-the loop, are being deployed in a range of military and civilian applications spanning air, ground, sea-surface and undersea environments. Large investments, particularly in robotics, electronic miniaturization, sensors, network communication, information technology and artificial intelligence are likely to further accelerate this trend. The operation of unmanned systems, and of applications that use these systems, are heavily dependent on cyber systems that are used to collect, store, process and communicate data, making data a critical resource. At the same time, undesirable elements of our society and adversarial states have also realized the high value of this resource. While enormous efforts have been made to secure data and cyber systems, lack of rigorous threat modeling and risk analysis can lead to more specific, rather than generic, security solutions relevant to the cyber system to be protected. This scenario has created an urgent need to develop a h...",project-academic
10.1109/BIGCOMP48618.2020.00-21,2020-02-01,p,IEEE,benchmarking jetson platform for 3d point cloud and hyper spectral image classification," Modern innovations of embedded system platforms (hardware accelerations) play a vital role in revolutionizing deep learning into practical scenarios, transforming human efforts into an automated intelligent system such as autonomous driving, robotics, IoT (Internet-of-Things) and many other useful applications. NVIDIA Jetson platform provides promising performance in terms of energy efficiency, favorable accuracy, and throughput for running deep learning algorithms. In this paper, we present benchmarking of Jetson platforms (Nano, TX1, and Xavier) by evaluating its performance based on computationally expensive deep learning algorithms. Previously, most of the benchmark results were based on 2-D images with conventional deep learning models for image processing. However, the implementation of many other complex data types at Jetson platform has remained a challenge. We also showed the practical impact of optimizing the algorithm vs improving the hardware accelerations by deploying a diverse range of dense and intensive deep learning architectures at all three aforementioned Jetson platforms, to make a better comparison of performance. In this regard, we have used two entirely different data-types, namely (i) ModelNet-40(Princeton-3D point-cloud) data-set along with PointNet deep learning architecture for classification of 3D point-cloud, and (ii) hyperspectral images (HSI) datasets (KSC and Pavia) alongside stacked autoencoders(SAE) to classify HSI correspondingly. This will broaden the scope of edge-devices to handle 3-D and HSI data whilst real-time classification will be processed at edge-server under the umbrella of edge-computing. The selection of (i) was made to exploit GPU heavily as the code uses TensorFlowgpu whereas (ii) was chosen to challenge the CPU cores of each platform as the code is based on Theano and may suffer from under-utilizing the GPU cores. We have presented the detailed evaluation exclusively in term of performance indices as inference time, the maximum number of concurrent processes, resource utilization per process and efficiency",project-academic
10.1109/TMECH.2021.3079409,2021-05-12,a,IEEE,valve detection for autonomous water pipeline inspection platform," Water distribution and transmission lines are indispensable to urban infrastructure. The water pipelines are subject to both structural and functional deterioration due to various reasons including aging, negligence, and high demand for water supply. Hence, to ensure a safe and reliable water supply, the water utilities need to perform routine pipe condition assessments. The condition assessment is usually carried out by visual inspection with the machine vision system carried by a robotic platform. The inspection platforms will capture the internal condition of the water pipelines in a video stream. However, the robotic platform frequently experiences difficulties while traversing through the valves installed along the pipeline. This inhibits and disrupts the inspection process of the water pipelines. Therefore, this paper proposes a deep learning-based automatic valve detection framework to facilitate the robot's navigation and ensure continuous inspection without any interruptions. The valve detection model is developed by combining MobileNet-160 and Feature Pyramid Network (FPN) and is named as MFPN. The developed framework also employs a generative adversarial network to solve the sparse data set issues and improve the generality of the framework. The comparative study and ablation analyses demonstrate that the proposed framework can achieve a higher mAP value of 89.11% in comparison with the state-of-the-art. Hence, this light-weight and efficient solution can be deployed to the robotic platform for real-time valve detection and enable autonomous navigation of the robotic platform for condition assessment of water pipelines.",project-academic
10.1109/MWC.001.1900346,2020-05-13,a,IEEE,network intelligence empowered industrial robot control in the f ran environment," Industrial robots are widely adopted in modern industries, including automobile manufacturing, warehousing, and so on. The industrial robot with cellular network connection will be more flexible and intelligent than that without a network connection or with a conventional industrial communication network connection (e.g., fieldbus, real-time Ethernet, and WiFi). This is seen as the direction of development of the next generation of industrial robots. As a promising candidate for the next generation of cellular networks, fog radio access network (F-RAN) can provide artificial intelligence (AI) on the network edge, which is equipped with some computing and storage facilities, thus promoting the development of industrial robots in the future. In this article, we first propose a local-network cooperative control architecture for industrial robots in the F-RAN environment, which divides the robot controller into an onboard controller and a network controller, in order to decouple the basic control functions and application-dependent functions. The network controller is implemented on the fog access node (F-AP), and it possibly uses AI to bring advanced capabilities to the robot control. Then, based on the proposed architecture, a testbed for multiple automated guided vehicle (AGV) coordination in F-RAN has been designed and implemented, and a recurrent neural network (RNN)-empowered multi-AGV coordination policy is also developed. Finally, its performance is examined by several experiments. The results show that network intelligence deployed in F-RAN can improve the scheduling efficiency up to 35 percent, and the proposed control architecture can save huge backhaul traffic compared to the conventional cloud-based control architecture for industrial robots.",project-academic
,2021-03-14,a,,success weighted by completion time a dynamics aware evaluation criteria for embodied navigation," We present Success weighted by Completion Time (SCT), a new metric for evaluating navigation performance for mobile robots. Several related works on navigation have used Success weighted by Path Length (SPL) as the primary method of evaluating the path an agent makes to a goal location, but SPL is limited in its ability to properly evaluate agents with complex dynamics. In contrast, SCT explicitly takes the agent's dynamics model into consideration, and aims to accurately capture how well the agent has approximated the fastest navigation behavior afforded by its dynamics. While several embodied navigation works use point-turn dynamics, we focus on unicycle-cart dynamics for our agent, which better exemplifies the dynamics model of popular mobile robotics platforms (e.g., LoCoBot, TurtleBot, Fetch, etc.). We also present RRT*-Unicycle, an algorithm for unicycle dynamics that estimates the fastest collision-free path and completion time from a starting pose to a goal location in an environment containing obstacles. We experiment with deep reinforcement learning and reward shaping to train and compare the navigation performance of agents with different dynamics models. In evaluating these agents, we show that in contrast to SPL, SCT is able to capture the advantages in navigation speed a unicycle model has over a simpler point-turn model of dynamics. Lastly, we show that we can successfully deploy our trained models and algorithms outside of simulation in the real world. We embody our agents in an real robot to navigate an apartment, and show that they can generalize in a zero-shot manner.",project-academic
10.1109/IEEE.ICCC.2017.20,2017-06-25,p,IEEE,cognitive acoustic analytics service for internet of things," The rapid development of the Internet of Things (IoT) has brought great changes for non-contact and non-destructive sensing and diagnosis. For every inanimate object can tell us something by the sound it makes, acoustic sensor demonstrates great advantages comparing to conventional electronic and mechanic sensors in such cases: overcoming environmental obstacles, mapping to existing use cases of detecting problems with human ears, low cost for deployment, etc. It could be widely applied to various domains, such as predictive maintenance of machinery, robot sensory, elderly and baby care in smart home, etc. Whether we can use the acoustic sensor data to understand what is happening and to predict what will happen relies heavily on the analytics capabilities we apply to the acoustic data, which has to overcome the obstacles of noise, disturbance and errors, and has to meet the requirement of real-time processing of high volume signals with large number of sensors. In this paper, we propose a scalable cognitive acoustics analytics service for IoT that provides the user an incremental learning approach to evolve their analytics capability on non-intuitive and unstructured acoustic data through the combination of acoustic signal processing and machine learning technology. It first performs acoustic signal processing and denoising, enables acoustic signal based abnormal detection based on sound intensity, spectral centroid, etc. Then based on the accumulated abnormal data, a supervised learning method is performed as baseline and a neural network based classifier is used to recognize acoustic events in different scenarios with various volume of sample data and requirement of accuracy. In addition, acoustic sensor arrays processing is supported for localization of moving acoustic source in more complex scenario. In this paper, we designed a hybrid computing structure. Finally, we conduct experiments on acoustic event recognition for machinery diagnosis, and show that the proposed system can achieve high accuracy.",project-academic
10.1007/978-1-84882-548-2_8,2009-01-01,a,Springer London,real time motion planning of kinematically redundant manipulators using recurrent neural networks," With the wide deployment of kinematically redundant manipulators in complex working environments, obstacle avoidance emerges as an important issue to be addressed in robot motion planning. In this chapter, the inverse kinematic control of redundant manipulators for obstacle avoidance task is formulated as a convex quadratic programming (QP) problem subject to equality and inequality constraints with time-varying parameters. Compared with our previous formulation, the new scheme is more favorable in the sense that it can yield better solutions for the control problem. To solve this time-varying QP problem in real time, a recently proposed recurrent neural network, called an improved dual neural network, is adopted, which has lower structural complexity compared with existing neural networks for solving this particular problem. Moreover, different from previous work in this line where the nearest points to the links on obstacles are often assumed to be known or given, we consider the case of obstacles with convex hull and formulate another time-varying QP problem to compute the critical points on the manipulator. Since this problem is not strictly convex, an existing recurrent neural network, called a general projection neural network, is applied for solving it. The effectiveness of the proposed approaches is demonstrated by simulation results based on the Mitsubishi PA10-7C manipulator.",project-academic
10.1109/AERO47225.2020.9172804,2020-03-07,p,IEEE,autonomous search for underground mine rescue using aerial robots," In this paper we present a comprehensive solution for autonomous underground mine rescue using aerial robots. In particular, a new class of Micro Aerial Vehicles are equipped with the ability to localize and map in subterranean settings, explore unknown mine environments on their own, and perform detection and localization of objects of interest for the purposes of mine rescue (i.e., “human survivors” and associated objects such as “backpacks”, “smartphones” or “tools”). For the purposes of GPS-denied localization and mapping in the visually-degraded underground environments (e.g., a smoke-filled mine during an accident) the solution relies on the fusion of LiDAR data with thermal vision frames and inertial cues. Autonomous exploration is enabled through a graph-based search algorithm and an online volumetric representation of the environment. Object search is then enabled through a deep learning-based classifier, while the associated location is queried using the online reconstructed map. The complete software framework runs onboard the aerial robots utilizing the integrated embedded processing resources. The overall system is extensively evaluated in real-life deployments in underground mines.",project-academic
10.1109/NEWCAS.2015.7181997,2015-06-07,p,IEEE,hardware design of a neural processing unit for bio inspired computing," Unsupervised artificial neural networks are now considered as a likely alternative to classical computing models in many application domains. For example, recent neural models defined by neuro-scientists exhibit interesting properties for an execution in embedded and autonomous systems: distributed computing, unsupervised learning, self-adaptation, self-organisation, tolerance. But these properties only emerge from large scale and fully connected neural maps that result in intensive computation coupled with high synaptic communications. We are interested in deploying these powerful models in the embedded context of an autonomous bio-inspired robot learning its environment in realtime. So we study in this paper in what extent these complex models can be simplified and deployed in hardware accelerators compatible with an embedded integration. Thus we propose a Neural Processing Unit designed as a programmable accelerator implementing recent equations close to self-organizing maps and neural fields. The proposed architecture is validated on FPGA devices and compared to state of the art solutions. The trade-off proposed by this dedicated but programmable neural processing unit allows to achieve significant improvements and makes our architecture adapted to many embedded systems.",project-academic
10.1109/ROBOT.2009.5152197,2009-05-12,p,IEEE,robust servo control for underwater robots using banks of visual filters," We present an application of machine learning to the semi-automatic synthesis of robust servo-trackers for underwater robotics. In particular, we investigate an approach based on the use of Boosting for robust visual tracking of color objects in an underwater environment. To this end, we use AdaBoost, the most common variant of the Boosting algorithm, to select a number of low-complexity but moderately accurate color feature trackers and we combine their outputs. The novelty of our approach lies in the design of this family of weak trackers, which enhances a straightforward color segmentation tracker in multiple ways. From a large and diverse family of possible filters, we select a small subset that optimizes the performance of our trackers. The tracking process applies these trackers on the input video frames, and the final tracker output is chosen based on the weights of the final array of trackers. By using computationally inexpensive, but somewhat accurate trackers as members of the ensemble, the system is able to run at quasi real-time, and thus, is deployable on-board our underwater robot. We present quantitative cross-validation results of our spatio-chromatic visual tracker, and conclude by pointing out some difficulties faced and subsequent shortcomings in the experiments we performed, along with directions of future research in the area of ensemble tracking in real-time.",project-academic
,2019-09-24,a,,residual reactive navigation combining classical and learned navigation strategies for deployment in unknown environments," In this work we focus on improving the efficiency and generalisation of learned navigation strategies when transferred from its training environment to previously unseen ones. We present an extension of the residual reinforcement learning framework from the robotic manipulation literature and adapt it to the vast and unstructured environments that mobile robots can operate in. The concept is based on learning a residual control effect to add to a typical sub-optimal classical controller in order to close the performance gap, whilst guiding the exploration process during training for improved data efficiency. We exploit this tight coupling and propose a novel deployment strategy, switching Residual Reactive Navigation (sRRN), which yields efficient trajectories whilst probabilistically switching to a classical controller in cases of high policy uncertainty. Our approach achieves improved performance over end-to-end alternatives and can be incorporated as part of a complete navigation stack for cluttered indoor navigation tasks in the real world. The code and training environment for this project is made publicly available at this https URL.",project-academic
10.1109/ICRA40945.2020.9197386,2020-09-15,p,Institute of Electrical and Electronics Engineers Inc.,residual reactive navigation combining classical and learned navigation strategies for deployment in unknown environments," In this work we focus on improving the efficiency and generalisation of learned navigation strategies when transferred from its training environment to previously unseen ones. We present an extension of the residual reinforcement learning framework from the robotic manipulation literature and adapt it to the vast and unstructured environments that mobile robots can operate in. The concept is based on learning a residual control effect to add to a typical sub-optimal classical controller in order to close the performance gap, whilst guiding the exploration process during training for improved data efficiency. We exploit this tight coupling and propose a novel deployment strategy, switching Residual Reactive Navigation (sRRN), which yields efficient trajectories whilst probabilistically switching to a classical controller in cases of high policy uncertainty. Our approach achieves improved performance over end-to-end alternatives and can be incorporated as part of a complete navigation stack for cluttered indoor navigation tasks in the real world. The code and training environment for this project is made publicly available at https://sites.google.com/view/srrn/home.",project-academic
10.1109/MDAT.2020.2971201,2020-04-21,a,IEEE,guest editorial robust resource constrained systems for machine learning," Machine learning (ML) None is nowadays embedded in several computing devices, consumer electronics, and cyber-physical systems. Smart sensors are deployed everywhere, in applications such as wearables and perceptual computing devices, and intelligent algorithms power our connected world. These devices collect and aggregate volumes of data, and in doing so, they augment our society in multiple ways; from healthcare, to social networks, to consumer electronics, and many more. To process these immense volumes of data, ML is emerging as the None de facto None analysis tool that powers several aspects of our Big Data society. Applications spanning from infrastructure (smart cities, intelligent transportation systems, smart grids, and to name a few), to social networks and content delivery, to e-commerce and smart factories, and emerging concepts such as self-driving cars and autonomous robots, are powered by ML technologies. These emerging systems require real-time inference and decision support; such scenarios, therefore, may use customized hardware accelerators, are typically bound by limited resources, and are restricted to limited connectivity and bandwidth. Thus, near-sensor computation and near-sensor intelligence have started emerging as necessities to continue supporting the paradigm shift of our connected world. The need for real-time intelligent data analytics (especially in the era of Big Data) for decision support near the data acquisition points emphasizes the need for revolutionizing the way we design, build, test, and verify processors, accelerators, and systems that facilitate ML (and deep learning, in particular) implemented in resource-constrained environments for use at the edge and the fog. As such, traditional von Neumann architectures are no longer sufficient and suitable, primarily because of limitations in both performance and energy efficiency caused especially by large amounts of data movement. Furthermore, due to the connected nature of such systems, security and reliability are also critically important. Robustness, therefore, in the form of reliability and operational capability in the presence of faults, whether malicious or accidental, is a critical need for such systems. Moreover, the operating nature of these systems relies on input data that is characterized by the four “V’s”: velocity (speed of data generation), variability (variable forms and types), veracity (unreliable and unpredictable), and volume (i.e., large amounts of data). Thus, the robustness of such systems needs to consider this issue as well. Furthermore, robustness in terms of security, and in terms of reliability to hardware and software faults, in particular, besides their importance when it comes to safety-critical applications, is also a positive factor in building trustworthiness toward these disrupting technologies from our society. To achieve this envisioned robustness, we need to refocus on problems such as design, verification, architecture, scheduling and allocation policies, optimization, and many more, for determining the most efficient, secure, and reliable way of implementing these novel applications within a robust, resource-constrained system, which may or may not be connected. This special issue, therefore, addresses a key aspect of fog and edge-based ML algorithms; robustness (as defined above) under resource-constraint scenarios. The special issue presents emerging works in how we design robust systems, both in terms of reliability as well as fault tolerance and security, while operating with a limited number of resources, and possibly in the presence of harsh environments that may eliminate connectivity and pollute the input data.",project-academic
10.1109/TCAD.2020.3012864,2020-10-02,a,IEEE,stereoengine an fpga based accelerator for real time high quality stereo estimation with binary neural network," Stereo estimation is essential to many applications such as mobile autonomous robots, most of which ask for real-time response, high energy, and storage efficiency. Deep neural networks (DNNs) have shown to yield significant gains in improving accuracy. However, these DNN-based algorithms are challenging to be deployed on energy and resource-constrained devices due to the high computational complexities of DNNs. In this article, we present StereoEngine, a fully pipelined end-to-end stereo vision accelerator that computes accurate dense depth in a real-time and energy-efficient manner. An efficient stereo algorithm is developed and optimized for a high-quality hardware-friendly implementation, that leverages binary neural network (BNN) to learn discriminative binary descriptors to improve the disparity. The design of StereoEngine is a standalone DNN-based stereo vision system where all processing procedures are implemented on a hardware platform. The effectiveness of StereoEngine is evaluated by comprehensive experiments. Compared with software-based implementations on the high-end and embedded Nvidia GPUs, StereoEngine achieves up to None None None $3\times $ None None , None None None $13\times $ None None , and None None None $50\times $ None None None speedups, as well as up to None None None $211\times $ None None , None None None $58\times $ None None , and None None None $73\times $ None None None energy efficiency improvement, respectively. Furthermore, StereoEngine achieves leading accuracy when compared to state-of-the-art hardware implementations on the challenging KITTI dataset.",project-academic
10.1109/ISWCS.2019.8877305,2019-08-01,p,IEEE,visible light positioning for location based services in industry 4 0," Industry 4.0 refers to the evolution in manufacturing from computerization to fully cyberphysical systems that exploit rich sensor data, adaptive real-time safety-critical control, and machine learning. An important aspect of this vision is the sensing and subsequent association of objects in the physical world with their cyber and virtual counterparts. In this paper we propose Visible Light Positioning (VLP) as an enabler for these Industry 4.0 applications. We also explore sensing techniques, including cameras (and depth sensors), and other light-based solutions for object positioning and detection along with their respective limitations. We then demonstrate an application of positioning for real time robot control in an interactive multiparty cyber-physical-virtual deployment. Lastly, based on our experience with this cyberphysical-virtual application, we propose Ray-Surface Positioning (RSP), a novel VLP technique, as a low cost positioning system for Industry 4.0.",project-academic
10.1109/ICRA48506.2021.9561941,2021-05-30,p,IEEE,a robot walks into a bar automatic robot joke success assessment," Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naive Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",project-academic
10.1007/S11370-021-00358-7,2021-04-01,a,Springer Berlin Heidelberg,combining cnn and lstm for activity of daily living recognition with a 3d matrix skeleton representation," In socially assistive robotics, human activity recognition plays a central role when the adaptation of the robot behavior to the human one is required. In this paper, we present an activity recognition approach for activities of daily living based on deep learning and skeleton data. In the literature, ad hoc features extraction/selection algorithms with supervised classification methods have been deployed, reaching an excellent classification performance. Here, we propose a deep learning approach, combining CNN and LSTM, that exploits both the learning of spatial dependencies correlating the limbs in a skeleton 3D grid representation and the learning of temporal dependencies from instances with a periodic pattern that works on raw data and so without requiring an explicit feature extraction process. These models are proposed for real-time activity recognition, and they are tested on the CAD-60 dataset. Results show that the proposed model behaves better than an LSTM model thanks to the automatic features extraction of the limbs’ correlation. “New Person” results show that the CNN-LSTM model achieves None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None $$95.4\%$$
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None of precision and None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None $$94.4\%$$
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None of recall, while the “Have Seen” results are None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None $$96.1\%$$
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None of precision and None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None $$94.7\%$$
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None of recall.",project-academic
,2021-04-23,a,,risk aware path planning for ground vehicles using occluded aerial images," We consider scenarios where a ground vehicle plans its path using data gathered by an aerial vehicle. In the aerial images, navigable areas of the scene may be occluded due to obstacles. Naively planning paths using aerial images may result in longer paths as a conservative planner may try to avoid regions that are occluded. We propose a modular, deep learning-based framework that allows the robot to predict the existence of navigable areas in the occluded regions. Specifically, we use image inpainting methods to fill in parts of the areas that are potentially occluded, which can then be semantically segmented to determine navigability. We use supervised neural networks for both modules. However, these predictions may be incorrect. Therefore, we extract uncertainty in these predictions and use a risk-aware approach that takes these uncertainties into account for path planning. We compare modules in our approach with non-learning-based approaches to show the efficacy of the proposed framework through photo-realistic simulations. The modular pipeline allows further improvement in path planning and deployment in different settings.",project-academic
,2013-07-04,b,,texplore temporal difference reinforcement learning for robots and time constrained domains," This book presents and develops new reinforcement learning methods that enable fast and robust learning on robots in real-time. Robots have the potential to solve many problems in society, because of their ability to work in dangerous places doing necessary jobs that no one wants or is able to do. One barrier to their widespread deployment is that they are mainly limited to tasks where it is possible to hand-program behaviors for every situation that may be encountered. For robots to meet their potential, they need methods that enable them to learn and adapt to novel situations that they were not programmed for. Reinforcement learning (RL) is a paradigm for learning sequential decision making processes and could solve the problems of learning and adaptation on robots. This book identifies four key challenges that must be addressed for an RL algorithm to be practical for robotic control tasks. These RL for Robotics Challenges are: 1) it must learn in very few samples; 2) it must learn in domains with continuous state features; 3) it must handle sensor and/or actuator delays; and 4) it should continually select actions in real time. This book focuses on addressing all four of these challenges. In particular, this book is focused on time-constrained domains where the first challenge is critically important. In these domains, the agents lifetime is not long enough for it to explore the domains thoroughly, and it must learn in very few samples.",project-academic
10.1109/ICRA48506.2021.9562075,2021-05-30,p,IEEE,reaching pruning locations in a vine using a deep reinforcement learning policy," We outline a neural network-based pipeline for perception, control and planning of a 7 DoF robot for tasks that involve reaching into a dormant grapevine canopy. The proposed system consists of a 6 DoF industrial robot arm and a linear slider that can actuate on an entire grape vine. Our approach uses Convolutional Neural Networks to detect buds in dormant grape vines and a Reinforcement Learning based control strategy to reach desired cut-point locations for pruning tasks. Within this framework, three methodologies are developed and compared to reach the desired locations: the learned policy-based approach (RL), a hybrid method that uses the learned policy and an inverse kinematics solver (RL+IK), and lastly a classical approach commonly used in robotics. We first tested and validated the suitability of the proposed learning methodology in a simulated environment that resembled laboratory conditions. A reaching accuracy of up to 61.90% and 85.71% for the RL and RL+IK approaches respectively was obtained for a vine that the agent observed while learning. When testing in a new vine, the accuracy was up to 66.66% and 76.19% for RL and RL+IK, respectively. The same methods were then deployed on a real system in an end to end procedure: autonomously scan the vine using a vision system, create its model and finally use the learned policy to reach cutting points. The reaching accuracy obtained in these tests was 73.08%.",project-academic
10.1162/089976602760407955,2002-11-01,a,MIT Press,real time computing without stable states a new framework for neural computation based on perturbations," A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.",project-academic
,2017-03-02,a,,deep predictive policy training using reinforcement learning," Skilled robot task learning is best implemented by predictive action policies due to the inherent latency of sensorimotor processes. However, training such predictive policies is challenging as it involves finding a trajectory of motor activations for the full duration of the action. We propose a data-efficient deep predictive policy training (DPPT) framework with a deep neural network policy architecture which maps an image observation to a sequence of motor activations. The architecture consists of three sub-networks referred to as the perception, policy and behavior super-layers. The perception and behavior super-layers force an abstraction of visual and motor data trained with synthetic and simulated training samples, respectively. The policy super-layer is a small sub-network with fewer parameters that maps data in-between the abstracted manifolds. It is trained for each task using methods for policy search reinforcement learning. We demonstrate the suitability of the proposed architecture and learning framework by training predictive policies for skilled object grasping and ball throwing on a PR2 robot. The effectiveness of the method is illustrated by the fact that these tasks are trained using only about 180 real robot attempts with qualitative terminal rewards.",project-academic
10.1109/IROS.2017.8206046,2017-03-02,p,Institute of Electrical and Electronics Engineers (IEEE),deep predictive policy training using reinforcement learning," Skilled robot task learning is best implemented by predictive action policies due to the inherent latency of sensorimotor processes. However, training such predictive policies is challenging as it involves finding a trajectory of motor activations for the full duration of the action. We propose a data-efficient deep predictive policy training (DPPT) framework with a deep neural network policy architecture which maps an image observation to a sequence of motor activations. The architecture consists of three sub-networks referred to as the perception, policy and behavior super-layers. The perception and behavior super-layers force an abstraction of visual and motor data trained with synthetic and simulated training samples, respectively. The policy super-layer is a small subnetwork with fewer parameters that maps data in-between the abstracted manifolds. It is trained for each task using methods for policy search reinforcement learning. We demonstrate the suitability of the proposed architecture and learning framework by training predictive policies for skilled object grasping and ball throwing on a PR2 robot. The effectiveness of the method is illustrated by the fact that these tasks are trained using only about 180 real robot attempts with qualitative terminal rewards.",project-academic
10.1016/J.NEUCOM.2018.01.002,2018-04-12,a,Elsevier,robot manipulator control using neural networks a survey," Robot manipulators are playing increasingly significant roles in scientific researches and engineering applications in recent years. Using manipulators to save labors and increase accuracies are becoming common practices in industry. Neural networks, which feature high-speed parallel distributed processing, and can be readily implemented by hardware, have been recognized as a powerful tool for real-time processing and successfully applied widely in various control systems. Particularly, using neural networks for the control of robot manipulators have attracted much attention and various related schemes and methods have been proposed and investigated. In this paper, we make a review of research progress about controlling manipulators by means of neural networks. The problem foundation of manipulator control and the theoretical ideas on using neural network to solve this problem are first analyzed and then the latest progresses on this topic in recent years are described and reviewed in detail. Finally, toward practical applications, some potential directions possibly deserving investigation in controlling manipulators by neural networks are pointed out and discussed. (C) 2018 Elsevier B.V. All rights reserved.",project-academic
10.1007/BF00117447,1996-05-01,a,Kluwer Academic Publishers,purposive behavior acquisition for a real robot by vision based reinforcement learning," This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a “state-action deviation” problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",project-academic
10.1109/CVPR46437.2021.00844,2021-01-01,p,IEEE,robust neural routing through space partitions for camera relocalization in dynamic indoor environments," Localizing the camera in a known indoor environment is a key building block for scene mapping, robot navigation, AR, etc. Recent advances estimate the camera pose via optimization over the 2D/3D-3D correspondences established between the coordinates in 2D/3D camera space and 3D world space. Such a mapping is estimated with either a convolution neural network or a decision tree using only the static input image sequence, which makes these approaches vulnerable to dynamic indoor environments that are quite common yet challenging in the real world. To address the aforementioned issues, in this paper, we propose a novel outlier-aware neural tree which bridges the two worlds, deep learning and decision tree approaches. It builds on three important blocks: (a) a hierarchical space partition over the indoor scene to construct the decision tree; (b) a neural routing function, implemented as a deep classification network, employed for better 3D scene understanding; and (c) an outlier rejection module used to filter out dynamic points during the hierarchical routing process. Our proposed algorithm is evaluated on the RIO-10 benchmark developed for camera relocalization in dynamic indoor environments. It achieves robust neural routing through space partitions and outperforms the state-of-the-art approaches by around 30% on camera pose accuracy, while running comparably fast for evaluation.",project-academic
,2020-12-08,a,,robust neural routing through space partitions for camera relocalization in dynamic indoor environments," Localizing the camera in a known indoor environment is a key building block for scene mapping, robot navigation, AR, etc. Recent advances estimate the camera pose via optimization over the 2D/3D-3D correspondences established between the coordinates in 2D/3D camera space and 3D world space. Such a mapping is estimated with either a convolution neural network or a decision tree using only the static input image sequence, which makes these approaches vulnerable to dynamic indoor environments that are quite common yet challenging in the real world. To address the aforementioned issues, in this paper, we propose a novel outlier-aware neural tree which bridges the two worlds, deep learning and decision tree approaches. It builds on three important blocks: (a) a hierarchical space partition over the indoor scene to construct the decision tree; (b) a neural routing function, implemented as a deep classification network, employed for better 3D scene understanding; and (c) an outlier rejection module used to filter out dynamic points during the hierarchical routing process. Our proposed algorithm is evaluated on the RIO-10 benchmark developed for camera relocalization in dynamic indoor environments. It achieves robust neural routing through space partitions and outperforms the state-of-the-art approaches by around 30% on camera pose accuracy, while running comparably fast for evaluation.",project-academic
10.1016/S0921-8890(01)00113-0,2001-07-31,a,North-Holland,acquisition of stand up behavior by a real robot using hierarchical reinforcement learning," Abstract None None In this paper, we propose a hierarchical reinforcement learning architecture that realizes practical learning speed in real hardware control tasks. In order to enable learning in a practical number of trials, we introduce a low-dimensional representation of the state of the robot for higher-level planning. The upper level learns a discrete sequence of sub-goals in a low-dimensional state space for achieving the main goal of the task. The lower-level modules learn local trajectories in the original high-dimensional state space to achieve the sub-goal specified by the upper level. None We applied the hierarchical architecture to a three-link, two-joint robot for the task of learning to stand up by trial and error. The upper-level learning was implemented by Q-learning, while the lower-level learning was implemented by a continuous actor–critic method. The robot successfully learned to stand up within 750 trials in simulation and then in an additional 170 trials using real hardware. The effects of the setting of the search steps in the upper level and the use of a supplementary reward for achieving sub-goals are also tested in simulation.",project-academic
,2000-06-29,p,Morgan Kaufmann Publishers Inc.,acquisition of stand up behavior by a real robot using hierarchical reinforcement learning," In this paper, we propose a hierarchical reinforcement learning architecture that realizes practical learning speed in real hardware control tasks. In order to enable learning in a practical number of trials, we introduce a low-dimensional representation of the state of the robot for higher-level planning. The upper level learns a discrete sequence of sub-goals in a low-dimensional state space for achieving the main goal of the task. The lower-level modules learn local trajectories in the original high-dimensional state space to achieve the sub-goal specified by the upper level. We applied the hierarchical architecture to a three-link, two-joint robot for the task of learning to stand up by trial and error. The upper-level learning was implemented by Q-learning, while the lower-level learning was implemented by a continuous actor–critic method. The robot successfully learned to stand up within 750 trials in simulation and then in an additional 170 trials using real hardware. The effects of the setting of the search steps in the upper level and the use of a supplementary reward for achieving sub-goals are also tested in simulation. © 2001 Elsevier Science B.V. All rights reserved.",project-academic
10.1145/2696454.2696463,2015-03-02,p,ACM,may i help you design of human like polite approaching behavior," When should service staff initiate interaction with a visitor? Neither simply-proactive (e.g. talk to everyone in a sight) nor passive (e.g. wait until being talked to) strategies are desired. This paper reports our modeling of polite approaching behavior. In a shopping mall, there are service staff members who politely approach visitors who need help. Our analysis revealed that staff members are sensitive to ‘intentions’ of nearby visitors. That is, when a visitor intends to talk to a staff member and starts to approach, the staff member also walks a few steps toward the visitors in advance to being talked. Further, even when not being approached, staff members exhibit ’’availability’’ behavior in the case that a visitor’s intention seems uncertain. We modeled these behaviors that are adaptive to pedestrians’ intentions, occurred prior to initiation of conversation. The model was implemented into a robot and tested in a real shopping mall. The experiment confirmed that the proposed method is less intrusive to pedestrians, and that our robot successfully initiated interaction with pedestrians.Categories and Subject Descriptors H.5.2 [Information Interfaces and Presentation]: User Interfaces - Interaction styles; I.2.9 [Artificial Intelligence]: RoboticsAlgorithms; Design; Experimentation; Human Factors",project-academic
10.3389/FNBOT.2017.00002,2017-01-25,a,Frontiers,connecting artificial brains to robots in a comprehensive simulation framework the neurorobotics platform," Combined efforts in the fields of neuroscience, computer science and biology allowed to design biologically realistic models of the brain based on spiking neural networks. For a proper validation of these models, an embodiment in a dynamic and rich sensory environment, where the model is exposed to a realistic sensory-motor task, is needed. Due to the complexity of these brain models that, at the current stage, cannot deal with real-time constraints, it is not possible to embed them into a real world task. Rather, the embodiment has to be simulated as well. While adequate tools exist to simulate either complex neural networks or robots and their environments, there is so far no tool that allows to easily establish a communication between brain and body models. The Neurorobotics Platform is a new web-based environment that aims to filling this gap by offering scientists and technology developers a software infrastructure allowing them to connect brain models to detailed simulations of robot bodies and environments and to use the resulting neurorobotic systems for in-silico experimentation. In order to simplify the workflow and reduce the level of the required programming skills, the platform provides editors for the specification of experimental sequences and conditions, envi-ronments, robots, and brain-body connectors. In addition to that, a variety of existing robots and environments are provided. This work presents the architecture of the first release of the Neurorobotics Platform developed in subproject 10 “Neurorobotics” of the Human Brain Project (HBP). At the current state, the Neurorobotics Platform allows researchers to design and run basic experiments in neurorobotics using simulated robots and simulated environments linked to simplified versions of brain models. We illustrate the capabilities of the platform with three example experiments: a Braitenberg task implemented on a mobile robot, a sensory-motor learning task based on a robotic controller and a visual tracking embedding a retina model on the iCub humanoid robot. These use-cases allow to assess the applicability of the Neurorobotics Platform for robotic tasks as well as in neuroscientific experiments.",project-academic
10.1109/TIE.2015.2425359,2016-02-01,a,IEEE,coordination of multiple robotic fish with applications to underwater robot competition," This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",project-academic
,2019-08-24,a,,planning beyond the sensing horizon using a learned context," Last-mile delivery systems commonly propose the use of autonomous robotic vehicles to increase scalability and efficiency. The economic inefficiency of collecting accurate prior maps for navigation motivates the use of planning algorithms that operate in unmapped environments. However, these algorithms typically waste time exploring regions that are unlikely to contain the delivery destination. Context is key information about structured environments that could guide exploration toward the unknown goal location, but the abstract idea is difficult to quantify for use in a planning algorithm. Some approaches specifically consider contextual relationships between objects, but would perform poorly in object-sparse environments like outdoors. Recent deep learning-based approaches consider context too generally, making training/transferability difficult. Therefore, this work proposes a novel formulation of utilizing context for planning as an image-to-image translation problem, which is shown to extract terrain context from semantic gridmaps, into a metric that an exploration-based planner can use. The proposed framework has the benefit of training on a static dataset instead of requiring a time-consuming simulator. Across 42 test houses with layouts from satellite images, the trained algorithm enables a robot to reach its goal 189\% faster than with a context-unaware planner, and within 63\% of the optimal path computed with a prior map. The proposed algorithm is also implemented on a vehicle with a forward-facing camera in a high-fidelity, Unreal simulation of neighborhood houses.",project-academic
10.1109/LRA.2020.3010739,2020-07-21,p,Institute of Electrical and Electronics Engineers (IEEE),learning force control for contact rich manipulation tasks with rigid position controlled robots," Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",project-academic
10.1016/J.PATREC.2018.04.009,2019-12-01,a,North-Holland,a real time and unsupervised face re identification system for human robot interaction," Abstract None None In the context of Human-Robot Interaction (HRI), face Re-Identification (face Re-ID) aims to verify if certain detected faces have already been observed by robots. The ability of distinguishing between different users is crucial in social robots as it will enable the robot to tailor the interaction strategy toward the users’ individual preferences. So far face recognition research has achieved great success, however little attention has been paid to the realistic applications of Face Re-ID in social robots. In this paper, we present an effective and unsupervised face Re-ID system which simultaneously re-identifies multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural Networks to extract features, and an online clustering algorithm to determine the face's ID. Its performance is evaluated on two datasets: the TERESA video dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF Dataset). We demonstrate that the optimised combination of techniques achieves an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on YTF dataset. We have implemented the proposed method into a software module in the HCI^2 Framework None [1] None for it to be further integrated into the TERESA robot None [2] , and has achieved real-time performance at 10–26 Frames per second.",project-academic
,2018-04-10,a,,a real time and unsupervised face re identification system for human robot interaction," In the context of Human-Robot Interaction (HRI), face Re-Identification (face Re-ID) aims to verify if certain detected faces have already been observed by robots. The ability of distinguishing between different users is crucial in social robots as it will enable the robot to tailor the interaction strategy toward the users' individual preferences. So far face recognition research has achieved great success, however little attention has been paid to the realistic applications of Face Re-ID in social robots. In this paper, we present an effective and unsupervised face Re-ID system which simultaneously re-identifies multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural Networks to extract features, and an online clustering algorithm to determine the face's ID. Its performance is evaluated on two datasets: the TERESA video dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF Dataset). We demonstrate that the optimised combination of techniques achieves an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on YTF dataset. We have implemented the proposed method into a software module in the HCI^2 Framework for it to be further integrated into the TERESA robot, and has achieved real-time performance at 10~26 Frames per second.",project-academic
10.1002/ROB.21418,2012-05-01,a,John Wiley and Sons Ltd.,development of the six legged walking and climbing robot spaceclimber," In this article, we present SpaceClimber,1 a six-legged, bio-inspired, energy-efficient and adaptable free-climbing robot for mobility on steep gradients. The long-term stool is to provide a system for extraterrestrial surface exploration missions, paying special attention to mobility in lunar craters to retrieve or analyze scientific samples from the interior of these craters. We present an envisaged mission for SpaceClimber and summarize the deriving system requirements. The robot's morphology determination procedure is depicted, considering the predefined demands and utilizing a simulation environment in combination with evolutionary optimization strategies, followed by a detailed description of the system's hardware design. The theoretical concept for the control of such machines with an extensive sensory–motor configuration is explained, as well as the implemented locomotion control approach and attempts to optimize the behavior of the robot using machine learning techniques. In addition, the experimental plant that was built for testing and evaluating the performance of the developed system in an environment as realistic as possible is introduced, followed by a description of the experiments performed. Concluding, we summarize the results and experiences and give an outlook on further developments. © 2012 Wiley Periodicals, Inc.

(Web page: http://wwww.dfki.de/robotik.)",project-academic
10.3390/S18072110,2018-06-30,a,Multidisciplinary Digital Publishing Institute,lired a light weight real time fault detection system for edge computing using lstm recurrent neural networks," Monitoring the status of the facilities and detecting any faults are considered an important technology in a smart factory. Although the faults of machine can be analyzed in real time using collected data, it requires a large amount of computing resources to handle the massive data. A cloud server can be used to analyze the collected data, but it is more efficient to adopt the edge computing concept that employs edge devices located close to the facilities. Edge devices can improve data processing and analysis speed and reduce network costs. In this paper, an edge device capable of collecting, processing, storing and analyzing data is constructed by using a single-board computer and a sensor. And, a fault detection model for machine is developed based on the long short-term memory (LSTM) recurrent neural networks. The proposed system called LiReD was implemented for an industrial robot manipulator and the LSTM-based fault detection model showed the best performance among six fault detection models.",project-academic
10.1016/J.CHB.2015.03.062,2015-09-01,a,Pergamon,comparative study of soft computing techniques for mobile robot navigation in an unknown environment," Robot navigation and obstacle avoidance using fuzzy logic controller is presented.Soft computing techniques are used to optimize the performance of fuzzy logic.The automatic tuning was done by using three soft computing techniques: GA, PSO, and NN.The best performance in terms of travelling time and speed is based on GA-Fuzzy.The PSO-Fuzzy and Neuro-Fuzzy methods have better performance in terms of distance travelled. An autonomous mobile robot operating in an unstructured environment must be able to deal with dynamic changes of the environment. Navigation and control of a mobile robot in an unstructured environment are one of the most challenging problems. Fuzzy logic control is a useful tool in the field of navigation of mobile robot. In this research, fuzzy logic controller is optimized by integrating fuzzy logic with other soft computing techniques like genetic algorithm, neural networks, and Particle Swarm Optimization (PSO). Soft computing techniques are used in this work to tune the membership function parameters of fuzzy logic controller to improve the navigation performance. Four methods have been designed and implemented: manually constructed fuzzy logic (M-Fuzzy), fuzzy logic with genetic algorithm (GA-Fuzzy), fuzzy logic with neural network (Neuro-Fuzzy), and fuzzy logic with PSO (PSO-Fuzzy). The performances of these approaches are compared through computer simulations and experiment number of scenarios using Khepera III mobile robot platform. Hybrid fuzzy logic controls with soft computing techniques are found to be most efficient for mobile robot navigation. The GA-Fuzzy technique is found to perform better than the other techniques in most of the test scenarios in terms of travelling time and average speed. The performances of both PSO-Fuzzy and Neuro-Fuzzy are found to be better than the other methods in terms of distance travelled. In terms of bending energy, the PSO-Fuzzy and Neuro-Fuzzy are found to be better in simulation results. Although, the M-Fuzzy is found to be better using real experimental results. Hence, the most important system parameter will dictate which of the four methods to use.",project-academic
10.3390/S19163542,2019-08-14,a,Multidisciplinary Digital Publishing Institute,unsupervised human detection with an embedded vision system on a fully autonomous uav for search and rescue operations," Unmanned aerial vehicles (UAVs) play a primary role in a plethora of technical and scientific fields owing to their wide range of applications. In particular, the provision of emergency services during the occurrence of a crisis event is a vital application domain where such aerial robots can contribute, sending out valuable assistance to both distressed humans and rescue teams. Bearing in mind that time constraints constitute a crucial parameter in search and rescue (SAR) missions, the punctual and precise detection of humans in peril is of paramount importance. The paper in hand deals with real-time human detection onboard a fully autonomous rescue UAV. Using deep learning techniques, the implemented embedded system was capable of detecting open water swimmers. This allowed the UAV to provide assistance accurately in a fully unsupervised manner, thus enhancing first responder operational capabilities. The novelty of the proposed system is the combination of global navigation satellite system (GNSS) techniques and computer vision algorithms for both precise human detection and rescue apparatus release. Details about hardware configuration as well as the system’s performance evaluation are fully discussed.",project-academic
10.1109/TMECH.2015.2396114,2015-03-10,a,IEEE,adaptive neural network control of a compact bionic handling arm," In this paper, autonomous control problem of a class of bionic continuum robots named “Compact Bionic Handling Arm” (CBHA) is addressed. These robots can reproduce biological behaviors of trunks, tentacles, or snakes. The modeling problem associated with continuum robots includes nonlinearities, structured and unstructured uncertainties, and the hyperredundancy. In addition to these problems, the CBHA comprises the hysteresis behavior of its actuators and a memory phenomenon related to its structure made of polyamide materials. These undesirable effects make it difficult to design a control system based on quantitative models of the CBHA. Thus, two subcontrollers are proposed in this paper. One, encapsulated in the other, and both implemented in real time allow controlling of the CBHA's end-effector position. The first subcontroller controls the CBHA's kinematics based on a distal supervised learning scheme. The second subcontroller controls the CBHA's kinetics based on an adaptive neural control. These subcontrollers allow a better assessment of the stability of the control architecture while ensuring the convergence of Cartesian errors. The obtained experimental results using a CBHA robot show an accurate tracking of the CBHA's end-effector position.",project-academic
10.1109/ROBOT.1995.525277,1995-05-21,p,IEEE,vision based reinforcement learning for purposive behavior acquisition," This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal, and discusses several issues in applying the reinforcement learning method to a real robot with vision sensor. First, a ""state-action deviation"" problem is found as a form of perceptual aliasing in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To cope with this, an action set is constructed in such a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of learning form easy missions (or LEM) which is a similar technique to ""shaping"" in animal learning is implemented. LEM reduces the learning time from the exponential order in the size of the state space to about the linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",project-academic
10.1109/LRA.2018.2851148,2018-06-27,p,IEEE,visual navigation for biped humanoid robots using deep reinforcement learning," In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",project-academic
10.1007/S00170-015-7422-6,2016-03-01,a,Springer London,on line learning of welding bead geometry in industrial robots," In this paper, we propose an architecture based on an artificial neural network (ANN), to learn welding skills automatically in industrial robots. With the aid of an optic camera and a laser-based sensor, the bead geometry (width and height) is measured. We propose a real-time computer vision algorithm to extract training patterns in order to acquire knowledge to later predict specific geometries. The proposal is implemented and tested in an industrial KUKA KR16 robot and a GMAW type machine within a manufacturing cell. Several data analysis are described as well as off-line and on-line training, learning strategies, and testing experimentation. It is demonstrated during our experiments that, after learning the skill, the robot is able to produce the requested bead geometry even without any knowledge about the welding parameters such as arc voltage and current. We implemented an on-line learning test, where the whole experiments and learning process take only about 4 min. Using this knowledge later, we obtained up to 95 % accuracy in prediction.",project-academic
10.1109/ICRA.2019.8793627,2019-05-20,p,IEEE,reinforcement learning meets hybrid zero dynamics a case study for rabbit," The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot’s reduced order states to a set of parameters that define the desired trajectories for the robot’s joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.",project-academic
,2005-07-09,p,American Association for Artificial Intelligence,semantic place classification of indoor environments with mobile robots using boosting," Indoor environments can typically be divided into places with different functionalities like kitchens, offices, or seminar rooms. We believe that such semantic information enables a mobile robot to more efficiently accomplish a variety of tasks such as human-robot interaction, path-planning, or localization. This paper presents a supervised learning approach to label different locations using boosting. We train a classifier using features extracted from vision and laser range data. Furthermore, we apply a Hidden Markov Model to increase the robustness of the final classification. Our technique has been implemented and tested on real robots as well as in simulation. The experiments demonstrate that our approach can be utilized to robustly classify places into semantic categories. We also present an example of localization using semantic labeling.",project-academic
10.1038/S41467-020-19597-W,2020-11-24,a,Nature Publishing Group,on the fly closed loop materials discovery via bayesian active learning," Active learning—the field of machine learning (ML) dedicated to optimal experiment design—has played a part in science as far back as the 18th century when Laplace used it to guide his discovery of celestial mechanics. In this work, we focus a closed-loop, active learning-driven autonomous system on another major challenge, the discovery of advanced materials against the exceedingly complex synthesis-processes-structure-property landscape. We demonstrate an autonomous materials discovery methodology for functional inorganic compounds which allow scientists to fail smarter, learn faster, and spend less resources in their studies, while simultaneously improving trust in scientific results and machine learning tools. This robot science enables science-over-the-network, reducing the economic impact of scientists being physically separated from their labs. The real-time closed-loop, autonomous system for materials exploration and optimization (CAMEO) is implemented at the synchrotron beamline to accelerate the interconnected tasks of phase mapping and property optimization, with each cycle taking seconds to minutes. We also demonstrate an embodiment of human-machine interaction, where human-in-the-loop is called to play a contributing role within each cycle. This work has resulted in the discovery of a novel epitaxial nanocomposite phase-change memory material. Machine learning driven research holds big promise towards accelerating materials’ discovery. Here the authors demonstrate CAMEO, which integrates active learning Bayesian optimization with practical experiments execution, for the discovery of new phase- change materials using X-ray diffraction experiments.",project-academic
10.1109/ICIT.2004.1490796,2004-12-08,p,IEEE,neural network based control of a four rotor helicopter," In this paper the design and development of an intelligent controller based on neural networks for a hoverable flying robot to be capable of achieving vertical take off and landing and to be able to sustain a specified attitude is presented. The ability to be able to autonomously navigate through a predefined path was designated for a future phase. This work is different from most autonomous flying robots as it focuses on a four-propeller configuration. This is a very rare helicopter design because of its inherent instability and it is believed that an autonomous robot of this configuration has not yet been successfully developed. In addition, this project uses fixed pitch propellers instead of variable pitch rotors resulting in a greatly reduced cost and mechanical complexity. The downside is that this introduces significant additional challenges in the control. Relative stability was achieved in three axis and all the supporting modules were successfully designed and implemented. However, significant challenges were encountered including the complexities of creating a neural networks controller (NNC) to work in real-time in a slow microcontroller as well as to develop the training process.",project-academic
10.1109/TIE.2005.847576,2005-05-31,a,IEEE,obstacle avoidance of a mobile robot using hybrid learning approach," in this paper, a hybrid learning approach for obstacle avoidance of a mobile robot is presented. the key features of the approach are, firstly, innate hardwired behaviors which are used to bootstrap learning in the mobile robot system. a neuro-fuzzy controller is developed from a pre-wired or innate controller based on supervised learning in a simulation environment. the fuzzy inference system has been constructed based on the generalized dynamic fuzzy neural networks learning algorithm of Wu and Er, whereby structure and parameters identification are carried out automatically and simultaneously. Secondly, the neuro-fuzzy controller is capable of re-adapting in a new environment. After carrying out the learning phase on a simulated robot, the controller is implemented on a real robot. A reinforcement learning method based on the fuzzy actor-critic learning algorithm is employed so that the system can re-adapt to a new environment without human intervention. In this phase, the structure of the fuzzy inference system and the parameters of the antecedent parts of fuzzy rules are frozen, and reinforcement learning is applied to further tune the parameters in the consequent parts of the fuzzy rules. Through the hybrid learning approach, an efficient and compact neuro-fuzzy system is generated for obstacle avoidance of a mobile robot in the real world.",project-academic
,2007-10-29,b,,robot brains circuits and systems for conscious machines," Haikonen envisions autonomous robots that perceive and understand the world directly, acting in it in a natural human-like way without the need of programs and numerical representation of information. By developing higher-level cognitive functions through the power of artificial associative neuron architectures, the author approaches the issues of machine consciousness. Robot Brains expertly outlines a complete system approach to cognitive machines, offering practical design guidelines for the creation of non-numeric autonomous creative machines. It details topics such as component parts and realization principles, so that different pieces may be implemented in hardware or software. Real-world examples for designers and researchers are provided, including circuit and systems examples that few books on this topic give. In novel technical and practical detail, this book also considers: the limitations and remedies of traditional neural associators in creating true machine cognition; basic circuit assemblies cognitive neural architectures; how motors can be interfaced with the associative neural system in order for fluent motion to be achieved without numeric computations; memorization, imagination, planning and reasoning in the machine; the concept of machine emotions for motivation and value systems; an approach towards the use and understanding of natural language in robots. The methods presented in this book have important implications for computer vision, signal processing, speech recognition and other information technology fields. Systematic and thoroughly logical, it will appeal to practising engineers involved in the development and design of robots and cognitive machines, also researchers in Artificial Intelligence. Postgraduate students in computational neuroscience and robotics, and neuromorphic engineers will find it an exciting source of information.",project-academic
10.1162/978-0-262-32621-6-CH037,2014-07-01,p,MIT Press,evolved electrophysiological soft robots," The embodied cognition paradigm emphasizes that both bodies and brains combine to produce complex behaviors, in contrast to the traditional view that the only seat of intelligence is the brain. Despite recent excitement about embodied cognition, brains and bodies remain thought of, and implemented as, two separate entities that merely interface with one another to carry out their respective roles. Previous research co-evolving bodies and brains has simulated the physics of bodies that collect sensory information and pass that information on to disembodied neural networks, which then processes that information and return motor commands. Biological animals, in contrast, produce behavior through physically embedded control structures and a complex and continuous interplay between neural and mechanical forces. In addition to the electrical pulses flowing through the physical wiring of the nervous system, the heart elegantly combines control with actuation, as the physical properties of the tissue itself (or defects therein) determine the actuation of the organ. Inspired by these phenomena from cardiac electrophysiology (the study of the electrical properties of heart tissue), we introduce electrophysiological robots, whose behavior is dictated by electrical signals flowing though the tissue cells of soft robots. Here we describe these robots and how they are evolved. Videos and images of these robots reveal lifelike behaviors despite the added challenge of having physically embedded control structures. We also provide an initial experimental investigation into the impact of different implementation decisions, such as alternatives for sensing, actuation, and locations of central pattern generators. Overall, this paper provides a first step towards removing the chasm between bodies and brains to encourage further research into physically realistic embodied cognition. Introduction and Background The fields of evolutionary robotics and artificial life have seen a great deal of emphasis on embodied cognition in recent years [Cheney et al. (2013); Bongard (2013); Rieffel et al. (2013); Auerbach and Bongard (2012); Hiller and Lipson (2012a); Lehman and Stanley (2011); Auerbach and Bongard (2010a,b); Pfeifer et al. (2007); Hornby et al. (2001); Lipson and Pollack (2000)]. There is even a paradigm called embodied cognition, which argues that the specifics of the embodiment (such as the morphology) are Figure 1: Current flowing through an evolved creature. The legend for voltage within each cell (colors) is given in Fig. 3. vital parts of the resulting behavior of the system: It argues that the co-evolutionary connection between body and brain is more deeply intertwined than the body simply acting as a minimal physical interface between the brain and the environment [Pfeifer and Bongard (2006)]. Recent work in evolutionary robotics has shown that complex behaviors can arise when co-evolving bodies and brains. At one end of the spectrum, Auerbach and Bongard (2010b) demonstrated the evolution of physical structures that had no joints or actuators, and evolved to cover the largest distance in a controlled fall due to gravity. While that work exemplifies the evolution of behavior emerging from morphology alone, it does not co-evolve any actuation or control. Auerbach and Bongard (2010a) then evolved the placement of CPG controlled rotational joints between cellular spheres, thus co-evolving morphology and control. Cheney et al. (2013) evolved locomoting soft robots made of multiple different materials: two passive voxels of differing rigidity and two actuated voxel types that expanded cyclically via out-of-phase central pattern generators (CPGs). While this work added a variety of soft materials and a new type of actuation, the pairing of muscle types directly to a CPG again reflected a focus on evolving morphology rather than sophisticated neural control. Many examples in the literature include the co-evolution of a robot morphology with an artificial neural network controller [Sims (1994); Lipson and Pollack (2000); Hornby et al. (2001); Lehman and Stanley (2011)]. These studies (and many more like them) involve what might be called “ghost” networks: artificial neural networks that provide control to the body, yet do not have any physical embodiALIFE 14: Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems Figure 2: An example of complex electrical wave propagation in cardiac modeling [Fenton et al. (2005)]. ment in the system they control. The state of input nodes to these networks is often set by sensors in the robot and output nodes typically signify behavioral outcomes in the actuators, but the computation is done supernaturally, disjoint from the body itself. In the age of 3D printing, it is a realistic goal for robots to physically walk out of a printer. It is thus worthwhile to consider designing robots that can be physically realized: i.e., those whose controllers are accounted for by being physically woven into the design of the robot. While the brains of animals are often a separate module within their bodies, animals also have central and peripheral nervous systems extending throughout their bodies. An extreme example of this is the octopus, which has as much as 90% of its neurons existing outside of its central nervous system [Zullo et al. (2009)]. The distributed and physical layout of the nervous system over space may contribute significantly to neural processing, as the delays and branching in axons (the basis for nerves) are suggested to serve computational functions [Segev and Schneidman (1999)]. Despite the prevalence of embodied, distributed circuitry in nearly all of animal life, the idea of an embodied nervous system has been absent from the field of evolutionary robotics. The sub-field called Evolvable Hardware evolves physical circuits for computer chips [Floreano and Mattiussi (2008)], but such work has not been applied to evolving the circuitry of artificial life organisms. We are unaware of work with virtual creatures that have physically embodied control systems (e.g. where neural circuitry physically runs throughout the body of the creature). We present the first such work in this paper. We propose a very basic model of electrical signal propagation throughout the body of an evolved creature. This embodied controller is based on electrophysiology (specifically at large scales, such as cardiac electrophysiology, Fig. 2). Electrophysiology is the study of the electrical properties of biological cells and tissues [Hoffman et al. (1960)]. In this model, electrical pulses from a single centralized sinusoidal pacemaker (analogous to the sinoatrial node – the pacemaker in the heart [Brown (1982)]) are propagated through the electrically conductive tissue of the creature. The location and patterning of this conductive tissue is described by an evolved Compositional Pattern Producing Network (CPPN) genome. Evolution controls the shape of the body and the electrical pathways within it, which both combine to determine the robot’s behavior. The model involves conductive tissue cells that collect voltage from neighboring cells, causing an action potential (spike) if the collected voltage exceeds the cell’s firing threshold (Fig. 3). Once this threshold is crossed, the cell depolarizes, causing a voltage spike that excites neighboring cells. This voltage spike is followed by a refractory period, during which the cell is temporarily unable to be re-excited. This model allows for the propagation of information through the body of the creature in the form of electrical signals. The structure of this flow is produced entirely by the topology of the creature and the state of each cell’s direct neighbors. In this sense, the model can be seen as a form of distributed information processing. One could draw similarities between this model and a 3D-grid of neurons, where each neuron receives inputs from, and has outputs to, its immediate neighbors. In this analogy, we are evolving where neurons should exist in the grid, what type of material the neuron is housed in, as well as the material type, if any, of grid locations that do not contain neurons. The placement of material, which is under evolutionary control, directly determines the resultant behavior of the organism. Cells that actuate will contract and expand as they depolarize (much like the contraction of cardiac muscles), leading to the locomotion behavior of the creature. In order to control the signal flow throughout the creature, insulator cells are allowed, which are unable to accept and pass on the signal. Evolution can also choose not to fill a voxel with material. The morphology of the simulated robot and tissue type at each cell is determined by a CPPN genome. This model examines the evolution of embodied cognition at a more detailed level of implementation than is typical in the literature – with embodied control circuitry resulting directly from the morphology of the individual creature. While this study only covers the classic problem of locomotion, it is a step towards truly physically embodied robots.",project-academic
,2018-06-30,a,"MIT Press One Rogers Street, Cambridge, MA 02142-1209 USA journals-info@mit.edu",evolved electrophysiological soft robots," The embodied cognition paradigm emphasizes that both bodies and brains combine to produce complex behaviors, in contrast to the traditional view that the only seat of intelligence is the brain. Despite recent excitement about embodied cognition, brains and bodies remain thought of, and implemented as, two separate entities that merely interface with one another to carry out their respective roles. Previous research co-evolving bodies and brains has simulated the physics of bodies that collect sensory information and pass that information on to disembodied neural networks, which then processes that information and return motor commands. Biological animals, in contrast, produce behavior through physically embedded control structures and a complex and continuous interplay between neural and mechanical forces. In addition to the electrical pulses flowing through the physical wiring of the nervous system, the heart elegantly combines control with actuation, as the physical properties of the tissue itself (or defects therein) determine the actuation of the organ. Inspired by these phenomena from cardiac electrophysiology (the study of the electrical properties of heart tissue), we introduce electrophysiological robots, whose behavior is dictated by electrical signals flowing though the tissue cells of soft robots. Here we describe these robots and how they are evolved. Videos and images of these robots reveal lifelike behaviors despite the added challenge of having physically embedded control structures. We also provide an initial experimental investigation into the impact of different implementation decisions, such as alternatives for sensing, actuation, and locations of central pattern generators. Overall, this paper provides a first step towards removing the chasm between bodies and brains to encourage further research into physically realistic embodied cognition. Introduction and Background The fields of evolutionary robotics and artificial life have seen a great deal of emphasis on embodied cognition in recent years [Cheney et al. (2013); Bongard (2013); Rieffel et al. (2013); Auerbach and Bongard (2012); Hiller and Lipson (2012a); Lehman and Stanley (2011); Auerbach and Bongard (2010a,b); Pfeifer et al. (2007); Hornby et al. (2001); Lipson and Pollack (2000)]. There is even a paradigm called embodied cognition, which argues that the specifics of the embodiment (such as the morphology) are Figure 1: Current flowing through an evolved creature. The legend for voltage within each cell (colors) is given in Fig. 3. vital parts of the resulting behavior of the system: It argues that the co-evolutionary connection between body and brain is more deeply intertwined than the body simply acting as a minimal physical interface between the brain and the environment [Pfeifer and Bongard (2006)]. Recent work in evolutionary robotics has shown that complex behaviors can arise when co-evolving bodies and brains. At one end of the spectrum, Auerbach and Bongard (2010b) demonstrated the evolution of physical structures that had no joints or actuators, and evolved to cover the largest distance in a controlled fall due to gravity. While that work exemplifies the evolution of behavior emerging from morphology alone, it does not co-evolve any actuation or control. Auerbach and Bongard (2010a) then evolved the placement of CPG controlled rotational joints between cellular spheres, thus co-evolving morphology and control. Cheney et al. (2013) evolved locomoting soft robots made of multiple different materials: two passive voxels of differing rigidity and two actuated voxel types that expanded cyclically via out-of-phase central pattern generators (CPGs). While this work added a variety of soft materials and a new type of actuation, the pairing of muscle types directly to a CPG again reflected a focus on evolving morphology rather than sophisticated neural control. Many examples in the literature include the co-evolution of a robot morphology with an artificial neural network controller [Sims (1994); Lipson and Pollack (2000); Hornby et al. (2001); Lehman and Stanley (2011)]. These studies (and many more like them) involve what might be called “ghost” networks: artificial neural networks that provide control to the body, yet do not have any physical embodiALIFE 14: Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems Figure 2: An example of complex electrical wave propagation in cardiac modeling [Fenton et al. (2005)]. ment in the system they control. The state of input nodes to these networks is often set by sensors in the robot and output nodes typically signify behavioral outcomes in the actuators, but the computation is done supernaturally, disjoint from the body itself. In the age of 3D printing, it is a realistic goal for robots to physically walk out of a printer. It is thus worthwhile to consider designing robots that can be physically realized: i.e., those whose controllers are accounted for by being physically woven into the design of the robot. While the brains of animals are often a separate module within their bodies, animals also have central and peripheral nervous systems extending throughout their bodies. An extreme example of this is the octopus, which has as much as 90% of its neurons existing outside of its central nervous system [Zullo et al. (2009)]. The distributed and physical layout of the nervous system over space may contribute significantly to neural processing, as the delays and branching in axons (the basis for nerves) are suggested to serve computational functions [Segev and Schneidman (1999)]. Despite the prevalence of embodied, distributed circuitry in nearly all of animal life, the idea of an embodied nervous system has been absent from the field of evolutionary robotics. The sub-field called Evolvable Hardware evolves physical circuits for computer chips [Floreano and Mattiussi (2008)], but such work has not been applied to evolving the circuitry of artificial life organisms. We are unaware of work with virtual creatures that have physically embodied control systems (e.g. where neural circuitry physically runs throughout the body of the creature). We present the first such work in this paper. We propose a very basic model of electrical signal propagation throughout the body of an evolved creature. This embodied controller is based on electrophysiology (specifically at large scales, such as cardiac electrophysiology, Fig. 2). Electrophysiology is the study of the electrical properties of biological cells and tissues [Hoffman et al. (1960)]. In this model, electrical pulses from a single centralized sinusoidal pacemaker (analogous to the sinoatrial node – the pacemaker in the heart [Brown (1982)]) are propagated through the electrically conductive tissue of the creature. The location and patterning of this conductive tissue is described by an evolved Compositional Pattern Producing Network (CPPN) genome. Evolution controls the shape of the body and the electrical pathways within it, which both combine to determine the robot’s behavior. The model involves conductive tissue cells that collect voltage from neighboring cells, causing an action potential (spike) if the collected voltage exceeds the cell’s firing threshold (Fig. 3). Once this threshold is crossed, the cell depolarizes, causing a voltage spike that excites neighboring cells. This voltage spike is followed by a refractory period, during which the cell is temporarily unable to be re-excited. This model allows for the propagation of information through the body of the creature in the form of electrical signals. The structure of this flow is produced entirely by the topology of the creature and the state of each cell’s direct neighbors. In this sense, the model can be seen as a form of distributed information processing. One could draw similarities between this model and a 3D-grid of neurons, where each neuron receives inputs from, and has outputs to, its immediate neighbors. In this analogy, we are evolving where neurons should exist in the grid, what type of material the neuron is housed in, as well as the material type, if any, of grid locations that do not contain neurons. The placement of material, which is under evolutionary control, directly determines the resultant behavior of the organism. Cells that actuate will contract and expand as they depolarize (much like the contraction of cardiac muscles), leading to the locomotion behavior of the creature. In order to control the signal flow throughout the creature, insulator cells are allowed, which are unable to accept and pass on the signal. Evolution can also choose not to fill a voxel with material. The morphology of the simulated robot and tissue type at each cell is determined by a CPPN genome. This model examines the evolution of embodied cognition at a more detailed level of implementation than is typical in the literature – with embodied control circuitry resulting directly from the morphology of the individual creature. While this study only covers the classic problem of locomotion, it is a step towards truly physically embodied robots.",project-academic
,2020-09-16,a,,domain invariant similarity activation map metric learning for retrieval based long term visual localization," Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g. illumination, seasonal and weather changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant feature through multi-domain image translation. And then a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the metric learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models without and with Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified on RobotCar dataset using models pre-trained on urban part of CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under the challenging environments with illumination variance, vegetation and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.",project-academic
10.1109/JAS.2021.1003907,2021-02-19,a,Institute of Electrical and Electronics Engineers (IEEE),domain invariant similarity activation map metric learning for retrieval based long term visual localization," Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss ( Grad-SAM ) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the metric learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.",project-academic
10.1109/JTEHM.2018.2822681,2018-05-08,a,IEEE J Transl Eng Health Med,an iot enabled stroke rehabilitation system based on smart wearable armband and machine learning," Surface electromyography signal plays an important role in hand function recovery training. In this paper, an IoT-enabled stroke rehabilitation system was introduced which was based on a smart wearable armband (SWA), machine learning (ML) algorithms, and a 3-D printed dexterous robot hand. User comfort is one of the key issues which should be addressed for wearable devices. The SWA was developed by integrating a low-power and tiny-sized IoT sensing device with textile electrodes, which can measure, pre-process, and wirelessly transmit bio-potential signals. By evenly distributing surface electrodes over user’s forearm, drawbacks of classification accuracy poor performance can be mitigated. A new method was put forward to find the optimal feature set. ML algorithms were leveraged to analyze and discriminate features of different hand movements, and their performances were appraised by classification complexity estimating algorithms and principal components analysis. According to the verification results, all nine gestures can be successfully identified with an average accuracy up to 96.20%. In addition, a 3-D printed five-finger robot hand was implemented for hand rehabilitation training purpose. Correspondingly, user’s hand movement intentions were extracted and converted into a series of commands which were used to drive motors assembled inside the dexterous robot hand. As a result, the dexterous robot hand can mimic the user’s gesture in a real-time manner, which shows the proposed system can be used as a training tool to facilitate rehabilitation process for the patients after stroke.",project-academic
10.1109/FORMALISE.2019.00012,2019-05-27,p,IEEE,parallelizable reachability analysis algorithms for feed forward neural networks," Artificial neural networks (ANN) have displayed considerable utility in a wide range of applications such as image processing, character and pattern recognition, self-driving cars, evolutionary robotics, and non-linear system identification and control. While ANNs are able to carry out complicated tasks efficiently, they are susceptible to unpredictable and errant behavior due to irregularities that emanate from their complex non-linear structure. As a result, there have been reservations about incorporating them into safety-critical systems. In this paper, we present a reachability analysis method for feed-forward neural networks (FNN) that employ rectified linear units (ReLUs) as activation functions. The crux of our approach relies on three reachable-set computation algorithms, namely exact schemes, lazy-approximate schemes, and mixing schemes. The exact scheme computes an exact reachable set for FNN, while the lazy-approximate and mixing schemes generate an over-approximation of the exact reachable set. All schemes are designed efficiently to run on parallel platforms to reduce the computation time and enhance the scalability. Our methods are implemented in a MATLAB® toolbox called, NNV, and is evaluated using a set of benchmarks that consist of realistic neural networks with sizes that range from tens to a thousand neurons. Notably, NNV successfully computes and visualizes the exact reachable sets of the real world ACAS Xu deep neural networks (DNNs), which are a variant of a family of novel airborne collision detection systems known as the ACAS System X, using a representation of tens to hundreds of polyhedra.",project-academic
10.1145/2522848.2522879,2013-12-09,p,ACM,how can i help you comparing engagement classification strategies for a robot bartender," A robot agent existing in the physical world must be able to understand the social states of the human users it interacts with in order to respond appropriately. We compared two implemented methods for estimating the engagement state of customers for a robot bartender based on low-level sensor data: a rule-based version derived from the analysis of human behaviour in real bars, and a trained version using supervised learning on a labelled multimodal corpus. We first compared the two implementations using cross-validation on real sensor data and found that nearly all classifier types significantly outperformed the rule-based classifier. We also carried out feature selection to see which sensor features were the most informative for the classification task, and found that the position of the head and hands were relevant, but that the torso orientation was not. Finally, we performed a user study comparing the ability of the two classifiers to detect the intended user engagement of actual customers of the robot bartender; this study found that the trained classifier was faster at detecting initial intended user engagement, but that the rule-based classifier was more stable.",project-academic
10.1109/37.621469,1997-10-01,a,IEEE,human control strategy abstraction verification and replication," In this article, we describe and develop methodologies for modeling and transferring human control strategy. This research has potential application in a variety of areas such as the intelligent vehicle highway system, human-machine interfacing, real-time training, space telerobotics, and agile manufacturing. We specifically address the following issues: (1) how to efficiently model human control strategy through learning cascade neural networks, (2) how to select state inputs in order to generate reliable models, (3) how to validate the computed models through an independent, hidden Markov model-based procedure, and (4) how to effectively transfer human control strategy. We have implemented this approach experimentally in the real-time control of a human driving simulator, and are working to transfer these methodologies for the control of an autonomous vehicle and a mobile robot. In providing a framework for abstracting computational models of human skill, we expect to facilitate analysis of human control, the development of human-like intelligent machines, improved human-robot coordination, and the transfer of skill from one human to another.",project-academic
10.1109/CRV52889.2021.00019,2021-05-01,p,IEEE,pathbench a benchmarking platform for classical and learned path planning algorithms," Path planning is a key component in mobile robotics. A wide range of path planning algorithms exist, but few attempts have been made to benchmark the algorithms holistically or unify their interface. Moreover, with the recent advances in deep neural networks, there is an urgent need to facilitate the development and benchmarking of such learning-based planning algorithms. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learned 2D and 3D path planning algorithms, while offering support for Robot Operating System (ROS). Many existing path planning algorithms are supported; e.g. A*, wavefront, rapidly-exploring random tree, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. We demonstrate the benchmarking capability of PathBench by comparing implemented classical and learned algorithms for metrics, such as path length, success rate, computational time and path deviation. These evaluations are done on built-in PathBench maps and external path planning environments from video games and real world databases. PathBench is open source 1.",project-academic
,2021-05-04,a,,pathbench a benchmarking platform for classical and learned path planning algorithms," Path planning is a key component in mobile robotics. A wide range of path planning algorithms exist, but few attempts have been made to benchmark the algorithms holistically or unify their interface. Moreover, with the recent advances in deep neural networks, there is an urgent need to facilitate the development and benchmarking of such learning-based planning algorithms. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learned 2D and 3D path planning algorithms, while offering support for Robot Oper-ating System (ROS). Many existing path planning algorithms are supported; e.g. A*, wavefront, rapidly-exploring random tree, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. We demonstrate the benchmarking capability of PathBench by comparing implemented classical and learned algorithms for metrics, such as path length, success rate, computational time and path deviation. These evaluations are done on built-in PathBench maps and external path planning environments from video games and real world databases. PathBench is open source.",project-academic
10.1109/ROBOT.2008.4543627,2008-05-19,p,IEEE,online self supervised terrain classification via discriminatively trained submodular markov random fields," The authors present a novel approach to the task of autonomous terrain classification based on structured prediction. We consider the problem of learning a classifier that will accurately segment an image into ""obstacle"" and ""ground"" patches based on supervised input. Previous approaches to this problem have focused mostly on local appearance; typically, a classifier is trained and evaluated on a pixel-by-pixel basis, making an implicit assumption of independence in local pixel neighborhoods. We relax this assumption by modeling correlations between pixels in the submodular MRF framework. We show how both the learning and inference tasks can be simply and efficiently implemented-exact inference via an efficient max flow computation; and learning, via an averaged-subgradient method. Unlike most comparable MRF-based approaches, our method is suitable for implementation on a robot in real-time. Experimental results are shown that demonstrate a marked increase in classification accuracy over standard methods in addition to real-time performance.",project-academic
10.1016/J.ROBOT.2018.11.017,2019-05-01,a,North-Holland,a real time framework for kinodynamic planning in dynamic environments with application to quadrotor obstacle avoidance," Abstract None None The objective of this paper is to present a full-stack, real-time motion planning framework for kinodynamic robots and then show how it is applied and demonstrated on a physical quadrotor system operating in a laboratory environment. The proposed framework utilizes an offline–online computation paradigm, neighborhood classification through machine learning, sampling-based motion planning with an optimal cost distance metric, and trajectory smoothing to achieve real-time planning for aerial vehicles. This framework accounts for dynamic obstacles with an event-based replanning structure and a locally reactive control layer that minimizes replanning events. The approach is demonstrated on a quadrotor navigating moving obstacles in an indoor space and stands as, arguably, one of the first demonstrations of full-online kinodynamic motion planning, with execution cycles of 3 Hz to 5 Hz. For the quadrotor, a simplified dynamics model is used during the planning phase to accelerate online computation. A trajectory smoothing phase, which leverages the differentially flat nature of quadrotor dynamics, is then implemented to guarantee a dynamically feasible trajectory.",project-academic
,2004-01-01,a,Massachusetts Institute of Technology,applied optimal control for dynamically stable legged locomotion," Online learning and controller adaptation will be an essential component for legged robots in the next few years as they begin to leave the laboratory setting and join our world. I present the first example of a learning system which is able to quickly and reliably acquire a robust feedback control policy for 3D dynamic bipedal walking from a blank slate using only trials implemented on the physical robot. The robot begins walking within a minute and learning converges in approximately 20 minutes. The learning works quickly enough that the robot is able to continually adapt to the terrain as it walks. This success can be attributed in part to the mechanics of our robot, which is capable of stable walking down a small ramp even when the computer is turned off. 
In this thesis, I analyze the dynamics of passive dynamic walking, starting with reduced planar models and working up to experiments on our real robot. I describe, in detail, the actor-critic reinforcement learning algorithm that is implemented on the return map dynamics of the biped. Finally, I address issues of scaling and controller augmentation using tools from optimal control theory and a simulation of a planar one-leg hopping robot. These learning results provide a starting point for the production of robust and energy efficient walking and running robots that work well initially, and continue to improve with experience. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)",project-academic
10.1109/IROS.2003.1250667,2003-12-08,p,IEEE,a robot that reinforcement learns to identify and memorize important previous observations," It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",project-academic
10.1109/TOH.2017.2753233,2018-01-01,a,IEEE,functional contour following via haptic perception and reinforcement learning," Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.",project-academic
10.1109/ICMA.2013.6618104,2013-10-03,p,IEEE,real time scene recognition on embedded system with sift keypoints and a new descriptor," The vision system of a mobile robot has to interpret the environment in real time at low power. As a good algorithm for extracting information from images, SIFT (Scale Invariant Feature Transform) is widely used in computer vision. However, the high computational complexity makes it hard to achieve real-time performance of SIFT with pure software. This paper presents a machine vision system implementing the SIFT algorithm on an embedded image processing card, where real-time scene recognition is accomplished with low power consumption through the cooperation between an FPGA (Field Programmable Gate Array) and a DSP (Digital Signal Processor) chip. The original SIFT keypoint detection algorithm is adapted for parallel computation and implemented with a hardware pipeline in the FPGA. Although our current system is designed for 360×288 video frames, this pipelined architecture can be applied to images with arbitrary resolution. Meanwhile, the original 128-dimensional SIFT descriptor is replaced by an 18-dimensional new descriptor which can be generated more efficiently and can be matched according to an absolute distance threshold with the distance defined by infinity-norm. On this basis, a five-branch-tree data structure is designed for fast searching and matching of descriptors, and robust scene recognition is realized through the combination of keypoints. Since our new descriptor allows one keypoint to be matched to several keypoints, which is a distinct property from the original SIFT algorithm, our system can recognize multiple images with overlapping contents simultaneously. In addition, compared with traditional work that needs off-line training, our system can perform fast on-line learning, which is a desirable property for mobile robots.",project-academic
10.1109/JSEN.2019.2956901,2020-03-15,a,IEEE,human action recognition using deep learning methods on limited sensory data," In recent years, due to the widespread usage of various sensors action recognition is becoming more popular in many fields such as person surveillance, human-robot interaction etc. In this study, we aimed to develop an action recognition system by using only limited accelerometer and gyroscope data. Several deep learning methods like Convolutional Neural Network(CNN), Long-Short Term Memory (LSTM) with classical machine learning algorithms and their combinations were implemented and a performance analysis was carried out. Data balancing and data augmentation methods were applied and accuracy rates were increased noticeably. We achieved new state-of-the-art result on the UCI HAR dataset by 97.4% accuracy rate with using 3 layer LSTM model. Also, we implemented same model on collected dataset (ETEXWELD) and 99.0% accuracy rate was obtained which means a solid contribution. Moreover, the performance analysis is not only based on accuracy results, but also includes precision, recall and f1-score metrics. Additionally, a real-time application was developed by using 3 layer LSTM network for evaluating how the best model classifies activities robustly.",project-academic
10.1016/J.AST.2019.105657,2020-03-01,a,Elsevier Masson,reinforcement learning in dual arm trajectory planning for a free floating space robot," Abstract None None A free-floating space robot exhibits strong dynamic coupling between the arm and the base, and the resulting position of the end of the arm depends not only on the joint angles but also on the state of the base. Dynamic modeling is complicated for multiple degree of freedom (DOF) manipulators, especially for a space robot with two arms. Therefore, the trajectories are typically planned offline and tracked online. However, this approach is not suitable if the target has relative motion with respect to the servicing space robot. To handle this issue, a model-free reinforcement learning strategy is proposed for training a policy for online trajectory planning without establishing the dynamic and kinematic models of the space robot. The model-free learning algorithm learns a policy that maps states to actions via trial and error in a simulation environment. With the learned policy, which is represented by a feedforward neural network with 2 hidden layers, the space robot can schedule and perform actions quickly and can be implemented for real-time applications. The feasibility of the trained policy is demonstrated for both fixed and moving targets.",project-academic
10.1016/J.INS.2014.05.001,2015-02-10,a,Elsevier,multiple chaotic central pattern generators with learning for legged locomotion and malfunction compensation," An originally chaotic system can be controlled into various periodic dynamics. When it is implemented into a legged robot's locomotion control as a central pattern generator (CPG), sophisticated gait patterns arise so that the robot can perform various walking behaviors. However, such a single chaotic CPG controller has difficulties dealing with leg malfunction. Specifically, in the scenarios presented here, its movement permanently deviates from the desired trajectory. To address this problem, we extend the single chaotic CPG to multiple CPGs with learning. The learning mechanism is based on a simulated annealing algorithm. In a normal situation, the CPGs synchronize and their dynamics are identical. With leg malfunction or disability, the CPGs lose synchronization leading to independent dynamics. In this case, the learning mechanism is applied to automatically adjust the remaining legs' oscillation frequencies so that the robot adapts its locomotion to deal with the malfunction. As a consequence, the trajectory produced by the multiple chaotic CPGs resembles the original trajectory far better than the one produced by only a single CPG. The performance of the system is evaluated first in a physical simulation of a quadruped as well as a hexapod robot and finally in a real six-legged walking machine called AMOSII. The experimental results presented here reveal that using multiple CPGs with learning is an effective approach for adaptive locomotion generation where, for instance, different body parts have to perform independent movements for malfunction compensation.",project-academic
10.1109/TSMCB.2009.2014470,2010-02-01,a,IEEE,biomimetic approach to tacit learning based on compound control," The remarkable capability of living organisms to adapt to unknown environments is due to learning mechanisms that are totally different from the current artificial machine-learning paradigm. Computational media composed of identical elements that have simple activity rules play a major role in biological control, such as the activities of neurons in brains and the molecular interactions in intracellular control. As a result of integrations of the individual activities of the computational media, new behavioral patterns emerge to adapt to changing environments. We previously implemented this feature of biological controls in a form of machine learning and succeeded to realize bipedal walking without the robot model or trajectory planning. Despite the success of bipedal walking, it was a puzzle as to why the individual activities of the computational media could achieve the global behavior. In this paper, we answer this question by taking a statistical approach that connects the individual activities of computational media to global network behaviors. We show that the individual activities can generate optimized behaviors from a particular global viewpoint, i.e., autonomous rhythm generation and learning of balanced postures, without using global performance indices.",project-academic
10.2514/1.9457,2004-09-01,a,American Institute of Aeronautics and Astronautics,anytime control algorithm model reduction approach," Recently, there has been considerable interest in anytime algorithms for real-time systems. Anytime algorithms are computational models that compromise quality of result for computational time. The tolerance to fluctuating CPU time makes anytime algorithms operationally optimal for real-time task scheduling. A methodology is presented that transforms linear control algorithms into anytime control algorithms. Implementation of a linear control algorithm involves matrix‐vector multiplications that require a fixed computational time. Such algorithms fail to compute the controller output if the alloted CPU time is less than required and cannot make use of any excess CPU time that might be available. When implemented as a real-time system, the static nature of the required computational time makes it operationally suboptimal for task scheduling. Linear control algorithms are transformed to anytime control algorithms by switching between controllers of different order. Balanced truncation and residualization are considered as model reduction tools to generate a set of reduced-order controllers, and a switching algorithm is presented that smoothly switches between them to accommodate variation in available computational time. I. Introduction I N recent times, advancement in digital technology has led to the design of complex computational systems. These systems usually interact with an environment that demands more out of some algorithms and less out of others, at different times in their operation life. Therefore, it is not feasible to perform accurate computation at all times by all of the algorithms in the system. Anytime algorithms provide a technique for allocating computational resources to the most useful algorithm, thereby enabling optimal usage of hardware resources. Anytime algorithms differ from conventional computational procedures in several ways. 1 Anytime algorithms are algorithms that compromise performance for computational time. They are capable of providing results at any point in their execution. The quality, accuracy, or performance of the algorithm improves with increased processing time. The improvement in the solution is large in the early stages of computation but diminishes over time. Anytime algorithms first emerged in the area of artificial intelligence. Early applications of such algorithms can be found in medical diagnosis and mobile robot navigation. The term anytime algorithm was coined by Dean and Boddy 2,3 in the late 1980s in the context of their work on time-dependent planning. They used this idea to solve a path-planning problem involving a robot assigned to deliver packages to a set of locations. Horvitz introduced a similar idea, called flexible computation, to solve time-critical decision problems. 4 In 1991, Liu et al. 5 introduced the concept of imprecise computation and applied it to real-time systems. They showed that imprecise computation techniques provide scheduling flexibility by trading off the quality of result to meet computational deadlines. Ever since, the concept of imprecise computation has been applied to solve several diverse problems. 6−9 The idea of anytime algorithms",project-academic
10.1371/JOURNAL.PONE.0112265,2014-11-12,a,Public Library of Science,adaptive robotic control driven by a versatile spiking cerebellar network," The cerebellum is involved in a large number of different neural processes, especially in associative learning and in fine motor control. To develop a comprehensive theory of sensorimotor learning and control, it is crucial to determine the neural basis of coding and plasticity embedded into the cerebellar neural circuit and how they are translated into behavioral outcomes in learning paradigms. Learning has to be inferred from the interaction of an embodied system with its real environment, and the same cerebellar principles derived from cell physiology have to be able to drive a variety of tasks of different nature, calling for complex timing and movement patterns. We have coupled a realistic cerebellar spiking neural network (SNN) with a real robot and challenged it in multiple diverse sensorimotor tasks. Encoding and decoding strategies based on neuronal firing rates were applied. Adaptive motor control protocols with acquisition and extinction phases have been designed and tested, including an associative Pavlovian task (Eye blinking classical conditioning), a vestibulo-ocular task and a perturbed arm reaching task operating in closed-loop. The SNN processed in real-time mossy fiber inputs as arbitrary contextual signals, irrespective of whether they conveyed a tone, a vestibular stimulus or the position of a limb. A bidirectional long-term plasticity rule implemented at parallel fibers-Purkinje cell synapses modulated the output activity in the deep cerebellar nuclei. In all tasks, the neurorobot learned to adjust timing and gain of the motor responses by tuning its output discharge. It succeeded in reproducing how human biological systems acquire, extinguish and express knowledge of a noisy and changing world. By varying stimuli and perturbations patterns, real-time control robustness and generalizability were validated. The implicit spiking dynamics of the cerebellar model fulfill timing, prediction and learning functions.",project-academic
,2001-01-01,a,Massachusetts Institute of Technology,foundations for a theory of mind for a humanoid robot," Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a “theory of mind” (Premack & Woodruff, 1978). Existing models of theory of mind have sought to identify a developmental progression of social skills that serve as the basis for more complex cognitive abilities. These skills include detecting eye contact, identifying self-propelled stimuli, and attributing intent to moving objects. 
If we are to build machines that interact naturally with people, our machines must both interpret the behavior of others according to these social rules and display the social cues that will allow people to naturally interpret the machine's behavior. 
Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)",project-academic
,2021-01-16,a,,semi supervised deep quick instance detection and segmentation," In this paper, we present a semi supervised deep quick learning framework for instance detection and pixel-wise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked 3rd, 4th and 5th worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC17 where novel features such as instance detection and online learning has been added.",project-academic
10.1109/ICRA.2019.8793595,2019-05-20,p,IEEE,semi supervised deep quick instance detection and segmentation," In this paper, we present a semi supervised deep quick learning framework for instance detection and pixelwise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework: semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked $3 ^{rd}$ rd, $4 ^{th}$ and $5 ^{th}$ worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC’17 where novel features such as instance detection and online learning has been added.",project-academic
10.1007/S10514-017-9681-6,2018-04-01,a,Springer US,searching and tracking people with cooperative mobile robots," Social robots should be able to search and track people in order to help them. In this paper we present two different techniques for coordinated multi-robot teams for searching and tracking people. A probability map (belief) of a target person location is maintained, and to initialize and update it, two methods were implemented and tested: one based on a reinforcement learning algorithm and the other based on a particle filter. The person is tracked if visible, otherwise an exploration is done by making a balance, for each candidate location, between the belief, the distance, and whether close locations are explored by other robots of the team. The validation of the approach was accomplished throughout an extensive set of simulations using up to five agents and a large amount of dynamic obstacles; furthermore, over three hours of real-life experiments with two robots searching and tracking were recorded and analysed.",project-academic
10.1109/ACCESS.2018.2845855,2018-06-11,a,Institute of Electrical and Electronics Engineers (IEEE),color transfer pulse coupled neural networks for underwater robotic visual systems," With rapid developments in cloud computing, artificial intelligence, and robotic systems, ever more complex tasks, such as space and ocean exploration, are being implemented by intelligent robots. Here, we propose an underwater image enhancement scheme for robotic visual systems. The proposed algorithm and its implementation enhances and outputs an image captured by an underwater robot in real time. In this scheme, pulse-coupled neural network (PCNN)-based image enhancement and color transfer algorithms are combined to enhance the underwater image. To avoid color imbalance in the underwater image and enhance details while suppressing noise, color correction is first carried out on the underwater image before converting it into the hue–saturation–intensity domain and enhancing it by PCNN. The enhanced result improves the color and contrast of the source image and enhances the details and edges of darker regions. Experiments are performed on real world data to demonstrate the effectiveness of the proposed scheme.",project-academic
10.1109/RO-MAN46459.2019.8956364,2019-10-01,p,IEEE,extending policy from one shot learning through coaching," Humans generally teach their fellow collaborators to perform tasks through a small number of demonstrations, often followed by episodes of coaching that tune and refine the execution during practice. Adopting a similar framework for teaching robots through demonstrations makes teaching tasks highly intuitive and imitating the refinement of complex tasks through coaching improves the efficacy. Unlike traditional Learning from Demonstration (LfD) approaches which rely on multiple demonstrations to train a task, we present a novel one-shot learning from demonstration approach, augmented by coaching, to transfer the task from task expert to robot. The demonstration is automatically segmented into a sequence of a priori skills (the task policy) parametrized to match task goals. During practice, the robotic skills self-evaluate their performances and refine the task policy to locally optimize cumulative performance. Then, human coaching further refines the task policy to explore and globally optimize the net performance. Both the self-evaluation and coaching are implemented using reinforcement learning (RL) methods. The proposed approach is evaluated using the task of scooping and unscooping granular media. The self-evaluator of the scooping skill uses the realtime force signature and resistive force theory to minimize scooping resistance similar to how humans scoop. Coaching feedback focuses modifications to sub-domains of the action space, using RL to converge to desired performance. Thus, the proposed method provides a framework for learning tasks from one demonstration and generalizing it using human feedback through coaching achieving a success rate of ≈90%.",project-academic
10.1016/J.MEASUREMENT.2016.09.026,2016-12-01,a,Elsevier,gesture imitation and recognition using kinect sensor and extreme learning machines," Abstract None None This study presents a framework that recognizes and imitates human upper-body motions in real time. The framework consists of two parts. In the first part, a transformation algorithm is applied to 3D human motion data captured by a Kinect. The data are then converted into the robot’s joint angles by the algorithm. The human upper-body motions are successfully imitated by the NAO humanoid robot in real time. None In the second part, the human action recognition algorithm is implemented for upper-body gestures. A human action dataset is also created for the upper-body movements. Each action is performed 10 times by twenty-four users. The collected joint angles are divided into six action classes. Extreme Learning Machines (ELMs) are used to classify the human actions. Additionally, the Feed-Forward Neural Networks (FNNs) and K-Nearest Neighbor (K-NN) classifiers are used for comparison. According to the comparative results, ELMs produce a good human action recognition performance.",project-academic
10.1109/ICAEE.2017.8255341,2017-09-01,p,IEEE,hardware and software implementation of real time electrooculogram eog acquisition system to control computer cursor with eyeball movement," Human computer interface (HCI) is an emerging technology of neuroscience and artificial intelligence. Development of HCI system using bio signal e.g. Electrooculogram (EOG), Electromyogram (EMG), Electroencephalogram (EEG), Functional near-infrared spectroscopy (fNIRS) etc. are attracted more and more attention of researchers all over the world in recent years because through this it is possible to get acquainted with advanced technologies of artificial intelligence. This paper presents the design and implementation of a fully functional Electrooculogram (EOG) based human computer interface. In this work we have designed and implemented necessary hardware and software for EOG signal acquisition along with controlling hardware such as wheelchair, robotic arm, mobile robot etc., and move computer mouse cursor simultaneously using EOG signal. This interface has three portion: EOG signal acquisition and amplification, analog to digital conversion, and real time hardware and mouse cursor movement. Eye movement is detected by measuring potential difference between cornea and retina using five Ag-Agcl disposable electrodes. Frequency range of EOG signal is considered as 0.3 to 15Hz, so this frequency range is taken using an active high and low pass filter so that accurate EOG signal can be achieved. The analog output of the EOG signal from filter is converted into digital signal by using an Arduino. Arduino serialize the EOG data for calibration and provides a threshold reference point which is used for controlling Hardware. The Classification module e.g. Support Vector machine (SVM) and Linear Discriminant Analysis (LDA) classify live data with respect to the horizontal and vertical data. This works as a binary classifier and choose optimal hyper-plane between two variables. According to each update on the eye position, cursor automatically accelerated in particular direction. PyMouse module in python is used for this task. Eye gesture based Hardware like robot, wheelchair etc. control and mouse cursor movement are the principle outcome of this research work.",project-academic
10.1109/TCDS.2016.2565542,2016-05-10,a,IEEE,spatial concept acquisition for a mobile robot that integrates self localization and unsupervised word discovery from spoken sentences," In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",project-academic
10.1109/ICPHYS.2018.8390780,2018-05-15,p,IEEE,industrial cyber physical system for condition based monitoring in manufacturing processes," Nowadays, manufacturing processes is adopting solutions with more sensoring systems on the basis of Industrial Cyber-Physical System (ICPS) approaches in order to carry out real-time process monitoring, optimal parametrization and self-reconfiguration of machine tools, robots and industrial processes from individual equipment's to global production environments. The present article introduces an ICPS architecture for condition-based monitoring to manage alarm and events combining local information extracted by multiple sensors integrated a family of CNC machine tools with a cloud information as a service to manage and update the local parametrization in order to predict failure pattern in CNC machine tools. The architecture is divided in two modes: a local mode embedded in each CNC machine tool and a global mode able to connect and reconfigure the local monitoring system based on global information knowledge. Finally, a case study based on a bearing benchmark is selected to evaluate the behavior and accuracy of the proposed architecture and the implemented condition-based monitoring system in multiple local CNC Machines tool (local modes) with self-learning and optimal parametrization provided by the cloud service (global mode).",project-academic
10.3390/ROBOTICS7020025,2018-06-04,a,MDPI AG,deep learning systems for estimating visual attention in robot assisted therapy of children with autism and intellectual disability," Recent studies suggest that some children with autism prefer robots as tutors for improving their social interaction and communication abilities which are impaired due to their disorder. Indeed, research has focused on developing a very promising form of intervention named Robot-Assisted Therapy. This area of intervention poses many challenges, including the necessary flexibility and adaptability to real unconstrained therapeutic settings, which are different from the constrained lab settings where most of the technology is typically tested. Among the most common impairments of children with autism and intellectual disability is social attention, which includes difficulties in establishing the correct visual focus of attention. This article presents an investigation on the use of novel deep learning neural network architectures for automatically estimating if the child is focusing their visual attention on the robot during a therapy session, which is an indicator of their engagement. To study the application, the authors gathered data from a clinical experiment in an unconstrained setting, which provided low-resolution videos recorded by the robot camera during the child–robot interaction. Two deep learning approaches are implemented in several variants and compared with a standard algorithm for face detection to verify the feasibility of estimating the status of the child directly from the robot sensors without relying on bulky external settings, which can distress the child with autism. One of the proposed approaches demonstrated a very high accuracy and it can be used for off-line continuous assessment during the therapy or for autonomously adapting the intervention in future robots with better computational capabilities.",project-academic
10.1007/S10015-011-0925-9,2011-09-07,a,Springer Japan,development of a pulse control type mems microrobot with a hardware neural network," This article presents the micro-electro-mechanical systems (MEMS) microrobot which demonstrates locomotion controlled by hardware neural networks (HNN). The size of the microrobot fabricated by the MEMS technology is 4 × 4 × 3.5 mm. The frame of the robot is made of silicon wafer, and it is equipped with a rotary-type actuator, a link mechanism, and six legs. The rotary-type actuator generates rotational movement by applying an electrical current to artificial muscle wires. The locomotion of the microrobot is obtained by the rotation of the rotary-type actuator. As in a living organism, the HNN realized robot control without using any software programs, A/D converters, or additional driving circuits. A central pattern generator (CPG) model was implemented as an HNN system to emulate the locomotion pattern. The MEMS microrobot emulated the locomotion method and the neural networks of an insect with the rotary-type actuator, the link mechanism, and the HNN. The microrobot performed forward and backward locomotion, and also changed direction by inputting an external trigger pulse. The locomotion speed was 0.325 mm/s and the step width was 1.3 mm.",project-academic
10.1016/J.CNSNS.2010.04.046,2011-05-01,a,Elsevier,discrete neural dynamic programming in wheeled mobile robot control," Abstract None None In this paper we propose a discrete algorithm for a tracking control of a two-wheeled mobile robot (WMR), using an advanced Adaptive Critic Design (ACD). We used Dual-Heuristic Programming (DHP) algorithm, that consists of two parametric structures implemented as Neural Networks (NNs): an actor and a critic, both realized in a form of Random Vector Functional Link (RVFL) NNs. In the proposed algorithm the control system consists of the DHP adaptive critic, a PD controller and a supervisory term, derived from the Lyapunov stability theorem. The supervisory term guaranties a stable realization of a tracking movement in a learning phase of the adaptive critic structure and robustness in face of disturbances. The discrete tracking control algorithm works online, uses the WMR model for a state prediction and does not require a preliminary learning. Verification has been conducted to illustrate the performance of the proposed control algorithm, by a series of experiments on the WMR Pioneer 2-DX.",project-academic
,2020-01-01,a,,internet of robotic things with digital platforms digitization of robotics enterprise," Internet of Things (IoT) provides a strong platform for computer users to connect objects, devices, and people to the Internet for exchanging or sharing of information with each other. IoT is growing rapidly and is expected to adapt to disciplines such as manufacturing, agriculture, healthcare, and robotics. Furthermore, the new concept of IoT is proposed and shown, especially for robotics areas as Internet of Robotics Things (IoRT). IoRT is a mixed structure of diverse technologies such as cloud computing, artificial intelligence, and machine learning. However, to promote and realize IoRT, digitization and digital transformation should be proceeded and implemented in the robotics enterprise. In this paper, we propose an architecture framework for IoRT-based digital platforms and verify it using a planned case in a global robotics enterprise. The associated challenges and future research directions in this field are also presented.",project-academic
10.1007/978-981-15-5784-2_31,2021-01-01,a,"Springer, Singapore",internet of robotic things with digital platforms digitization of robotics enterprise," Internet of Things (IoT) provides a strong platform for computer users to connect objects, devices, and people to the Internet for exchanging or sharing of information with each other. IoT is growing rapidly and is expected to adapt to disciplines such as manufacturing, agriculture, healthcare, and robotics. Furthermore, the new concept of IoT is proposed and shown, especially for robotics areas as Internet of Robotics Things (IoRT). IoRT is a mixed structure of diverse technologies such as cloud computing, artificial intelligence, and machine learning. However, to promote and realize IoRT, digitization and digital transformation should be proceeded and implemented in the robotics enterprise. In this paper, we propose an architecture framework for IoRT-based digital platforms and verify it using a planned case in a global robotics enterprise. The associated challenges and future research directions in this field are also presented.",project-academic
,2005-06-01,p,"Institute of Control, Robotics and Systems",obstacle avoidance using velocity dipole field method," Mobile robot navigation in dynamic environments is a complex task, which is generally implemented as a hierarchical control system [1]. At the highest level of the hierarchy, a global path is planned using expert knowledge or methods from artificial intelligence, and uses that path as a recommendation (not as a mandate) for the lowest level in the hierarchy, where real-time feedback control of steering and speed take place. The lowest level of the hierarchy keeps watching the local surrounding through sensor feedback such as sonar and laser range finders, and tries to avoid such obstacles (if any) that have not been taken into account by the global path planner. These obstacles may contradict with the recommended path, thus, the real-time path modifications are required to evade them. The local obstacle avoidance is dominantly based on potential field methods that assign repulsive potential fields for obstacles, and an attractive field for the goal. These individual fields are superimposed to construct the potential landscape in which the robot moves downhill, probably towards the goal. The simple structure of potential field method makes it appropriate for real-time collision avoidance, with extendability to higher dimensions as well. However, potential field method could trap in local potential wells that could have been created after superimposition of individual fields. Oscillatory motion through narrow passages and difficulty in entering through door-frames are also typical problems of conventional potential field method [4]. Ironically, most of these drawbacks appear partly due to the implementation of potential field methods in static environments, for which a global path planner alone would be quite adequate, such as the nearness diagram method [7], and vector field histogram method, where the obstacle distribution is used to create navigation maps and guide the robot through safe areas and narrow passages. The local minima problem of potential field method has been addressed by Khosla , using superquadric potential functions to design local-minima-free potential landscapes for static obstacles. For the same purpose Koditschek [8] investigated function topologies to create a unique potential minima at the goal for an arbitrary number of obstacles assuming that they have disjoint potential functions. In this paper, we introduce the velocity dipole field method and demonstrate how it could be used to devise an explicit navigation strategy for real-time collision avoidance. The proposed method has the capability of navigating the robot skillfully, similar to the way a human would move to avoid an obstacle that approaches a collision path. The expected performance is quoted as follows: “If the obstacle approaches fast, and is in a collision path, turn towards it, go around, and behind it while keeping a safe distance”.",project-academic
10.1109/AIM.2009.5229901,2009-07-14,p,IEEE,neural q learning controller for mobile robot," In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBot™ robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",project-academic
10.1109/TOH.2020.2975555,2020-02-24,a,IEEE,perception of tactile directionality via artificial fingerpad deformation and convolutional neural networks," Humans can perceive tactile directionality with angular perception thresholds of 14-40° via fingerpad skin displacement. Using deformable, artificial tactile sensors, the ability to perceive tactile directionality was developed for a robotic system to aid in object manipulation tasks. Two convolutional neural networks (CNNs) were trained on tactile images created from fingerpad deformation measurements during perturbations to a handheld object. A primary CNN regression model provided a point estimate of tactile directionality over a range of grip forces, perturbation angles, and perturbation speeds. A secondary CNN model provided a variance estimate that was used to determine uncertainty about the point estimate. A 5-fold cross-validation was performed to evaluate model performance. The primary CNN produced tactile directionality point estimates with an error rate of 4.3% for a 20° angular resolution and was benchmarked against an open-source force estimation network. The model was implemented in real-time for interactions with an external agent and the environment with different object shapes and widths. The perception of tactile directionality could be used to enhance the situational awareness of human operators of telerobotic systems and to develop decision-making algorithms for context-appropriate responses by semi-autonomous robots.",project-academic
10.1109/ICMLC.2016.7872960,2016-07-01,p,IEEE,muscle gesture robot hand control based on semg signals with wavelet transform features and neural network classifier," In this paper, we propose a muscle gesture-computer interface (MGCI) system for a five-fingered robotic hand control employing a commercial wearable MYO gesture armband. Eight channels of surface EMG (sEMG) signals were acquired and segmented. Then four levels of Daubechies 5 Wavelet family were performed to analyze the EMG signal. Totally 72 features were extracted from the EMG raw data for 16 hand motions recognition utilizing artificial Neural Networks. The average of best overall classification rate during off-line training is 87.8%. Consequently, real-time hand gesture recognition was implemented to evaluate the performance of the proposed system and the average recognition accuracy was 89.38%. Finally, it was applied to control a five-fingered robot hand.",project-academic
10.1109/INISTA.2014.6873613,2014-06-23,p,IEEE,fuzzy logic based design of classical behaviors for mobile robots in ros middleware," Autonomous mobile vehicles are used in many applications to realize special tasks. These tasks involve obstacle avoidance, target reaching and/or tracking. Such vehicles include the use of artificial intelligence to assist the vehicle's operator. Fuzzy logic can be used in the design of an autonomous vehicle to improve the classical control mechanisms. Classical robot control/decision mechanisms can give imperfect results due to sensor compensation errors or calculation costs. These drawbacks can be eliminated by using a combined fuzzy inference. In this study, we have modified the mobile robot ATEKS, which is an intelligent wheelchair, by introducing three fuzzy inference systems to realize goal reaching, obstacle avoidance and a controller for combined behavior selection. Designed fuzzy control system has been implemented on Robot Operating System (ROS) under Ubuntu 12.04 operating system and tested under Gazebo simulation platform. Simulation results verified faithful behavior outputs of ATEKS.",project-academic
10.1109/IJCNN.2000.859467,2000-07-27,p,IEEE,biologically inspired neural controllers for motor control in a quadruped robot," This paper presents biologically inspired neural controllers for generating motor patterns in a quadruped robot. Sets of artificial neural networks are presented which provide 1) pattern generation and gait control, allowing continuous passage from walking to trotting to galloping, 2) control of sitting and lying down behaviors, and 3) control of scratching. The neural controllers consist of sets of oscillators composed of leaky-integrator neurons, which control pairs of flexor-extensor muscles attached to each joint. The networks receive sensory feedback proportional to the contraction of simulated muscles and to joint flexion. Similarly to what is observed in cats, locomotion can be initiated by either applying tonic (i.e. non-oscillating) input to the locomotion network or by sensory feedback from extending the legs. The networks are implemented in a quadruped robot. It is shown that computation can be carried out in real time and that the networks can generate the above mentioned motor behaviors.",project-academic
10.1016/J.NEUCOM.2019.11.007,2020-03-14,a,Elsevier,neuropod a real time neuromorphic spiking cpg applied to robotics," Abstract None None Initially, robots were developed with the aim of making our life easier, carrying out repetitive or dangerous tasks for humans. Although they were able to perform these tasks, the latest generation of robots are being designed to take a step further, by performing more complex tasks that have been carried out by smart animals or humans up to date. To this end, inspiration needs to be taken from biological examples. For instance, insects are able to optimally solve complex environment navigation problems, and many researchers have started to mimic how these insects behave. Recent interest in neuromorphic engineering has motivated us to present a real-time, neuromorphic, spike-based Central Pattern Generator of application in neurorobotics, using an arthropod-like robot. A Spiking Neural Network was designed and implemented on SpiNNaker. The network models a complex, online-change capable Central Pattern Generator which generates three gaits for a hexapod robot locomotion in real-time. Reconfigurable hardware was used to manage both the motors of the robot and the low-latency communication interface with the Spiking Neural Networks. Real-time measurements confirm the simulation results, and locomotion tests show that NeuroPod can perform the gaits without any balance loss or added delay.",project-academic
10.1002/ROB.10110,2003-10-01,a,"John Wiley & Sons, Ltd",neural networks based control of mobile robots development and experimental validation," The paper proposes a neural networks approach to the solution of the tracking problem for mobile robots. Neural networks based controllers are investigated in order to exploit the nonlinear approximation capabilities of the nets for modeling the kinematic behavior of the vehicle and for reducing unmodeled tracking errors contributions. The training of the nets and the control performances analysis have been done in a real experimental setup. The proposed solutions are implemented on a PC-based control architecture for the real-time control of the LabMate mobile base and are compared with classical kinematic control schemes. Experimental results are satisfactory in terms of tracking errors and computational efforts. © 2003 Wiley Periodicals, Inc.",project-academic
10.24018/EJFOOD.2020.2.3.45,2020-06-19,a,European Open Access Publishing (Europa Publishing),deep learning based self driving car jetbot with nvidia ai board to deliver items at agricultural workplace with object finding and avoidance functions," In this study, we attempt to develop a deep learning-based self-driving car system to deliver items (e.g., harvested onions, agri-tools, PET bottles) to agricultural (agri-) workers at an agri-workplace. The system is based around a car-shaped robot, JetBot, with an NVIDIA artificial intelligence (AI) oriented board. JetBot can find diverse objects and avoid them. We implemented experimental trials at a real warehouse where various items (glove, boot, sickle (falx), scissors, and hoe), called obstacles, were scattered. The assumed agri-worker was a man suspending dried onions on a beam. Specifically, we developed a system focusing on the function of precisely detecting obstacles with deep learning-based techniques (techs), self-avoidance, and automatic delivery of small items for manual agri-workers and managers. Both the car-shaped figure and the deep learning-based obstacles-avoidance function differ from existing mobile agri-machine techs and products with respect to their main aims and structural features. Their advantages are their low costs in comparison with past similar mechanical systems found in the literature and similar commercial goods. The robot is extremely agile and easily identifies and learns obstacles. Additionally, the JetBot kit is a minimal product and includes a feature allowing users to arbitrarily expand and change functions and mechanical settings.
This study consists of six phases: (1) designing and confirming the validity of the entire system, (2) constructing and tuning various minor system settings (e.g., programs and JetBot specifications), (3) accumulating obstacle picture data, (4) executing deep learning, (5) conducting experiments in an indoor warehouse to simulate a real agri-working situation, and (6) assessing and discussing the trial data quantitatively (presenting the success and error rates of the trials) and qualitatively. We consider that from the limited trials, the system can be judged as valid to some extent in certain situations. However, we were unable to perform more broad or generalizable experiments (e.g., execution at mud farmlands and running JetBot on non-flat floor). We present experimental ranges for the success ratio of these trials, particularly noting crashed obstacle types and other error types. We were also able to observe features of the system’s practical operations. The novel achievements of this study lie in the fusion of recent deep learning-based agricultural informatics. In the future, agri-workers and their managers could use the proposed system in real agri-places as a common automatic delivering system. Furthermore, we believe, by combining this application with other existing systems, future agri-fields and other workplaces could become more comfortable and secure (e.g., delivering water bottles could avoid heat (stress) disorders).",project-academic
10.1109/IROS.2009.5354270,2009-10-10,p,"Ieee Service Center, 445 Hoes Lane, Po Box 1331, Piscataway, Nj 08855-1331 Usa",consideration on robotic giant swing motion generated by reinforcement learning," This study attempts to make a compact humanoid robot acquire a giant-swing motion without any robotic models by using reinforcement learning; only the interaction with environment is available. Generally, it is widely said that this type of learning method is not appropriated to obtain dynamic motions because Markov property is not necessarily guaranteed during the dynamic task. However, in this study, we try to avoid this problem by embedding the dynamic information in the robotic state space; the applicability of the proposed method is considered using both the real robot and dynamic simulator. This paper, in particular, discusses how the robot with 5-DOF, in which the Q-Learning algorithm is implemented, acquires a giant-swing motion. Further, we describe the reward effects on the Q-Learning. Finally, this paper demonstrates that the application of the Q-Learning enable the robot to perform a very attractive giant-swing motion.",project-academic
10.1109/TASE.2004.840071,2005-01-17,a,IEEE,artificial intelligence approach for biomedical sample characterization using raman spectroscopy," An artificial-intelligence approach is proposed to differentiate various biomedical samples via Raman spectroscopy technology to obtain accurate medical diagnosis and decision making. The complete process consists of noise filtering, fluorescence identification, optimization and elimination, spectral normalization, multivariate statistical analysis, and data clustering, as well as the final decision making. Numerous modeling, intelligent control, and system-identification schemes have been employed. By means of fuzzy control, genetic algorithms, and principal component analysis (PCA), as well as system identification, a systematic intelligent-control approach is formulated, which is capable of classifying diversified biomedical samples. Raman spectra are weak signals whose features are sensitive to a variety of noises, which have to be reduced to an acceptable level. Fuzzy logic has been known to interpret uncertainty, imprecision, and vague phenomena. Thus, a fuzzy controller is used for noise filtering. On the other hand, background fluorescence acts as a secondary intensity component within a raw Raman spectrograph, so its spectral baseline should be determined. By removing background fluorescence, intrinsic Raman spectrum can be extracted in consequence. To optimize this detrend process, genetic algorithms have been implemented for baseline-function global optimization by selecting an optimal combination of individual spectroscopic functions. Normalization is performed by standard normal variate (SNV) afterwards to compensate for scattering effects. Normalized intrinsic spectra can be used for sample differentiation, where the PCA approach distinguishes some signatures from different samples in terms of dominant principal components. Eventually, various principal components are accumulated for clustering using scatter plots. The long-term objective of this intelligent-control approach is to create a real-time technique for sample analysis, using a Raman spectrometer directly mounted at the end-effectors of medical robots, which is to enhance the robotic surgery.",project-academic
10.1109/ICMA.2013.6618173,2013-10-03,p,IEEE,an intelligent object manipulation framework for industrial tasks," This paper presents an intelligent object manipulation framework for industrial tasks, which integrates a sensor-rich multi-fingered robot hand, an industrial robot manipulator, a conveyor belt and employs machine learning algorithms. The framework software architecture is implemented using a Windows 7 operating system with RTX real-time extension for synchronous handling of peripheral devices. The framework uses Scale Invariant Feature Transform (SIFT) image processing algorithm, Support Vector Machine (SVM) machine learning algorithm and 3D point cloud techniques for intelligent object recognition based on RGB camera and laser rangefinder information from the robot hand end effector. The objective is automated manipulation of objects with different shapes and poses with minimum programming effort applied by a user.",project-academic
10.1109/FPL.2005.1515790,2005-10-10,p,IEEE,design and fpga implementation of an embedded real time biologically plausible spiking neural network processor," The implementation of a large scale, leaky-integrate-and-fire neural network processor using the Xilinx Virtex-II family of field programmable gate array (FPGA) is presented. The processor has been designed to model biologically plausible networks of spiking neurons in real-time to assist with the control of a mobile robot. The real-time constraint has led to a re-evaluation of some of the established architectural and algorithmic features of previous spiking neural network based hardware. The design was coded and simulated using Handel-C hardware description language (HDL) and the DK3 design suite from Celoxica. The processor has been physically implemented and tested on a RC200 development board, also from Celoxica.",project-academic
10.1016/S0921-8890(02)00165-3,2002-03-31,a,North-Holland,visual approach skill for a mobile robot using learning and fusion of simple skills," Abstract None None This paper presents a reinforcement learning algorithm which allows a robot, with a single camera mounted on a pan tilt platform, to learn simple skills such as watch and orientation and to obtain the complex skill called approach combining the previously learned ones. The reinforcement signal the robot receives is a real continuous value so it is not necessary to estimate an expected reward. Skills are implemented with a generic structure which permits complex skill creation from sequencing, output addition and data flow of available simple skills.",project-academic
10.1109/TIM.2018.2884450,2019-05-01,a,IEEE,low order nonlinear finite impulse response soft sensors for ionic electroactive actuators based on deep learning," This paper introduces a soft sensor (SS) for the estimation of the deflection of a polymeric mechanical actuator. The actuator is based on ionic polymer-metal composites (IPMCs). Applications of IPMCs have been proposed in fields such as robotics, surgery, and aerospace, to mention the most interesting ones. In such application fields, both the complexity and the size of the actuating system are of chief importance. An SS can be, therefore, preferred to hardware measuring the actuator output, for estimating the actuator motion. Also, low-order models are of interest to limit the computational load, which can be a constraint in real-time applications. To this aim, several data-driven nonlinear finite-impulse response (NFIR) models have been investigated. Data, used for the model identification, have been acquired, in controlled environmental conditions, by using swept signals as the input to the IPMC actuator. Linear and nonlinear models, based on principal component analysis, shallow, and deep neural networks (NNs), have been investigated, for different model orders. The best results have been obtained by an SS based on a fifth-order NFIR model, implemented by a deep belief NN.",project-academic
10.1109/TAMD.2013.2255050,2013-06-01,a,IEEE,redundant neural vision systems competing for collision recognition roles," Ability to detect collisions is vital for future robots that interact with humans in complex visual environments. Lobula giant movement detectors (LGMD) and directional selective neurons (DSNs) are two types of identified neurons found in the visual pathways of insects such as locusts. Recent modeling studies showed that the LGMD or grouped DSNs could each be tuned for collision recognition. In both biological and artificial vision systems, however, which one should play the collision recognition role and the way the two types of specialized visual neurons could be functioning together are not clear. In this modeling study, we compared the competence of the LGMD and the DSNs, and also investigate the cooperation of the two neural vision systems for collision recognition via artificial evolution. We implemented three types of collision recognition neural subsystems - the LGMD, the DSNs and a hybrid system which combines the LGMD and the DSNs subsystems together, in each individual agent. A switch gene determines which of the three redundant neural subsystems plays the collision recognition role. We found that, in both robotics and driving environments, the LGMD was able to build up its ability for collision recognition quickly and robustly therefore reducing the chance of other types of neural networks to play the same role. The results suggest that the LGMD neural network could be the ideal model to be realized in hardware for collision recognition.",project-academic
10.1023/A:1008817110013,1998-03-01,a,Kluwer Academic Publishers,interleaving planning and robot execution for asynchronous user requests," ROGUE is an architecture built on a real robot which provides algorithms for the integration of high-level planning, low-level robotic execution, and learning. ROGUE addresses successfully several of the challenges of a dynamic office gopher environment. This article presents the techniques for the integration of planning and execution.

ROGUE uses and extends a classical planning algorithm to create plans for multiple interacting goals introduced by asynchronous user requests. ROGUE translates the planner‘s actions to robot execution actions and monitors real world execution. ROGUE is currently implemented using the PRODIGY4.0 planner and the Xavier robot. This article describes how plans are created for multiple asynchronous goals, and how task priority and compatibility information are used to achieve appropriate efficient execution. We describe how ROGUE communicates with the planner and the robot to interleave planning with execution so that the planner can replan for failed actions, identify the actual outcome of an action with multiple possible outcomes, and take opportunities from changes in the environment.

ROGUE represents a successful integration of a classical artificial intelligence planner with a real mobile robot.",project-academic
10.1016/J.JMSY.2020.06.018,2020-07-01,a,Elsevier,reinforcement learning for facilitating human robot interaction in manufacturing," For many contemporary manufacturing processes, autonomous robotic operators have become ubiquitous. Despite this, the number of human operators within these processes remains high, and as a consequence, the number of interactions between humans and robots has increased in this context. This is a problem, as human beings introduce a source of disturbance and unpredictability into these processes in the form of performance variation. Despite the natural human aptitude for flexibility, their presence remains a source of disturbance within the system and make modelling and optimization of these systems considerably more challenging, and in many cases impossible. Improving the ability of robotic operators to adapt their behaviour to variations in human task performance is, therefore, a significant challenge to be overcome to enable many ideas in the larger intelligent manufacturing paradigm to be realised. This work presents the development of a methodology to effectively model these systems and a reinforcement learning agent capable of autonomous decision-making. This decision-making provides the robotic operators with greater adaptability, by enabling its behaviour to change based on observed information, both of its environment and human colleagues. The work extends theoretical knowledge on how learning methods can be implemented for robotic control, and how the capabilities that they enable may be leveraged to improve the interaction between robots and their human counterparts. The work further presents a novel methodology for the implementation of a reinforcement learning-based intelligent agent which enables a change in behavioural policy in robotic operators in response to performance variation in their human colleagues. The development and evaluation are supported by a generalized simulation model, which is parameterized to enable appropriate variation in human performance. The evaluation demonstrates that the reinforcement agent can effectively learn to make adjustments to its behaviour based on the knowledge extracted from observed information, and balance the task demands to optimise these adjustments.",project-academic
10.1109/ICRA.2013.6631340,2013-05-06,p,IEEE,humanoid robot posture control learning in real time based on human sensorimotor learning ability," In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",project-academic
10.3390/MACHINES7020024,2019-04-15,a,MDPI AG,neural network based learning from demonstration of an autonomous ground robot," This paper presents and experimentally validates a concept of end-to-end imitation learning for autonomous systems by using a composite architecture of convolutional neural network (ConvNet) and Long Short Term Memory (LSTM) neural network. In particular, a spatio-temporal deep neural network is developed, which learns to imitate the policy used by a human supervisor to drive a car-like robot in a maze environment. The spatial and temporal components of the imitation model are learned by using deep convolutional network and recurrent neural network architectures, respectively. The imitation model learns the policy of a human supervisor as a function of laser light detection and ranging (LIDAR) data, which is then used in real time to drive a robot in an autonomous fashion in a laboratory setting. The performance of the proposed model for imitation learning is compared with that of several other state-of-the-art methods, reported in the machine learning literature, for spatial and temporal modeling. The learned policy is implemented on a robot using a Nvidia Jetson TX2 board which, in turn, is validated on test tracks. The proposed spatio-temporal model outperforms several other off-the-shelf machine learning techniques to learn the policy.",project-academic
10.1016/J.ROBOT.2004.03.006,2004-06-30,a,North-Holland,self valuing learning and generalization with application in visually guided grasping of complex objects," Abstract None None For programming by demonstration and for reinforcement learning, the learned skills need appropriate representations for generalization and possibilities for further improvements by the robot itself. We present a self-valuing learning technique which is capable of learning how to grasp unfamiliar objects and generalize the learned abilities. The learning system consists of two components which distinguish between local and global quality criteria for grasp points. The local criteria are not object-specific while the global criteria cover physical properties of each object. In this case we present a generalization method of the learning parameters based on a tree distance model for the medial axis transformations. The system is self-valuing, i.e. it rates its actions by evaluating sensory information and the usage of image processing techniques. This learning system has been implemented in a real robot assembly system equipped with hand-cameras and force/torque sensors. Both the theory and the experiments have shown it ability to grasp a wide range of objects and to apply pre-learned knowledge to new objects.",project-academic
10.1016/J.ROBOT.2018.10.015,2019-02-01,a,North-Holland,time dependent genetic algorithm and its application to quadruped s locomotion," Abstract None None Genetic algorithms (GAs) are widely used in machine learning and optimization. This paper proposes a time-dependent genetic algorithm (TDGA) based on real-coded genetic algorithm (RCGA) to improve the convergence performance of functions over time such as a foot trajectory. TDGA has several distinguishing features when compared with traditional RCGA. First, individuals are arranged over time, and then the individuals are optimized in sequence. Second, search spaces of design variables are newly comprised of processes of reductions for search spaces. Third, the search space for crossover operations is expanded to avoid local minima traps that can occur in new search spaces up to the previous search space before performing any reduction of search space, and boundary mutation operation is performed to the new search spaces. Computer simulations are implemented to verify the convergence performance of the robot locomotion optimized by TDGA. Then, TDGA optimizes the desired feet trajectories of quadruped robots that climb up a slope and the impedance parameters of admittance control so that quadruped robots can trot stably over irregular terrains. Simulation results clearly represent that the convergence performance is improved by TDGA, which also shows that TDGA could be broadly used in robot locomotion research.",project-academic
,2020-06-27,a,,thermodynamic machine learning through maximum work production," Author(s): Boyd, AB; Crutchfield, JP; Gu, M | Abstract: Adaptive systems -- such as a biological organism gaining survival advantage, an autonomous robot executing a functional task, or a motor protein transporting intracellular nutrients -- must model the regularities and stochasticity in their environments to take full advantage of thermodynamic resources. Analogously, but in a purely computational realm, machine learning algorithms estimate models to capture predictable structure and identify irrelevant noise in training data. This happens through optimization of performance metrics, such as model likelihood. If physically implemented, is there a sense in which computational models estimated through machine learning are physically preferred? We introduce the thermodynamic principle that work production is the most relevant performance metric for an adaptive physical agent and compare the results to the maximum-likelihood principle that guides machine learning. Within the class of physical agents that most efficiently harvest energy from their environment, we demonstrate that an efficient agent's model explicitly determines its architecture and how much useful work it harvests from the environment. We then show that selecting the maximum-work agent for given environmental data corresponds to finding the maximum-likelihood model. This establishes an equivalence between nonequilibrium thermodynamics and dynamic learning. In this way, work maximization emerges as an organizing principle that underlies learning in adaptive thermodynamic systems.",project-academic
10.1016/J.NEUCOM.2017.03.028,2017-06-28,a,Elsevier,a real time fpga implementation of a biologically inspired central pattern generator network," We engineer a basic CPG with conductance-based KomendantovKononenko neuron model.We propose a multiplier-less FPGA implementation method with low hardware cost.The neural dynamics are highlighted in the design in a biorealistic manner.We employ piecewise linearization method to obtain the reduced neuron model. Central pattern generators (CPGs) functioning as biological neuronal circuits are responsible for generating rhythmic patterns to control locomotion. In this paper, a biologically inspired CPG composed of two reciprocally inhibitory neurons was implemented on a reconfigurable FPGA with real-time computational speed and considerably low hardware cost. High-accuracy neural circuit implementation can be computationally expensive, especially for a high-dimensional conductance-based neuron model. Thus, we aimed to present an efficient multiplier-less hardware implementation method for the investigation of real-time hardware CPG (hCPG) networks. In order to simplify the hardware implementation, a modified neuron model without nonlinear parts was given to decrease the complexity of the original model. A simple CPG network involving two chemical coupled neurons was realized which represented the pyloric dilator (PD) and lateral pyloric (LP) neurons in the crustacean pyloric CPG. The implementation results of the hCPG network showed that rhythmic behaviors were successfully reproduced and the resource consumption was dramatically reduced by using our multiplier-less implementation method. The presented FPGA-based implementation of hCPG network with remarkable performance set a prototype for the realization of other large-scale CPG networks and could be applied in bio-inspired robotics and motion rehabilitation for locomotion control.",project-academic
10.1016/J.JFRANKLIN.2009.10.019,2010-08-01,a,Pergamon,decentralized neural identification and control for uncertain nonlinear systems application to planar robot," This paper presents a discrete-time decentralized neural identification and control for large-scale uncertain nonlinear systems, which is developed using recurrent high order neural networks (RHONN); the neural network learning algorithm uses an extended Kalman filter (EKF). The discrete-time control law proposed is based on block control and sliding mode techniques. The control algorithm is first simulated, and then implemented in real time for a two degree of freedom (DOF) planar robot.",project-academic
10.1109/RTAS.2018.00028,2018-04-11,p,IEEE,s 3dnn supervised streaming and scheduling for gpu accelerated real time dnn workloads," Deep Neural Networks (DNNs) are being widely applied in many advanced embedded systems that require autonomous decision making, e.g., autonomous driving and robotics. To handle resource-demanding DNN workloads, graphic processing units (GPUs) have been used as the main acceleration engine. Although much research has been conducted to algorithmically optimize the efficiency of applying DNN to applications such as object recognition, limited attention has been given to optimizing the execution of GPU-accelerated DNN workloads at the system level. In this paper, we propose S^3DNN, a system solution that optimizes the execution of DNN workloads on GPU in a real-time multi-tasking environment, which simultaneously optimizes the two (sometimes) conflicting goals of real-time correctness and throughput. S^3DNN contains a governor that selectively gathers system-wide DNN requests to perform smart data fusion, and a novel supervised streaming and scheduling framework that combines a deadline-aware scheduler with the concurrency-enabled CUDA stream technique. To simultaneously maximize concurrency-induced benefits and real-time performance, S^3DNN explores a rather interesting and unique characteristic of DNN workloads, where multiple layers of a DNN instance often exhibit a gradually decreased GPU resource utilization pattern. We have fully implemented S^3DNN in a GPU-accelerated system and have conducted extensive sets of experiments evaluating the efficacy of S^3DNN under a wide range of system and workload scenarios. The results show that S^3DNN significantly improves upon state-of-the-art GPU-accelerated DNN processing frameworks, e.g., up to 37% and over 40% improvements in real-time performance and throughput, respectively.",project-academic
10.1109/ISIE.1998.711559,1998-07-07,p,IEEE,the sensor control jacobian as a basis for controlling calibration free robots," A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",project-academic
,2007-01-01,a,,hardware implementation of cmac type neural network on fpga for command surface approximation," The hardware implementation of neural networks is a new step in the evolution and use of neural networks in practical applications. The CMAC cerebellar model articulation controller is intended especially for hardware implementation, and this type of network is used successfully in the areas of robotics and control, where the real time capabilities of the network are of particular importance. The implementation of neural networks on FPGA's has several benefits, with emphasis on parallelism and the real time capabilities.This paper discusses the hardware implementation of the CMAC type neural network, the architecture and parameters and the functional modules of the hardware implemented neuro-processor.",project-academic
,2021-06-16,a,,tactile sim to real policy transfer via real to sim image translation," Simulation has recently become key for deep reinforcement learning to safely and efficiently acquire general and complex control policies from visual and proprioceptive inputs. Tactile information is not usually considered despite its direct relation to environment interaction. In this work, we present a suite of simulated environments tailored towards tactile robotics and reinforcement learning. A simple and fast method of simulating optical tactile sensors is provided, where high-resolution contact geometry is represented as depth images. Proximal Policy Optimisation (PPO) is used to learn successful policies across all considered tasks. A data-driven approach enables translation of the current state of a real tactile sensor to corresponding simulated depth images. This policy is implemented within a real-time control loop on a physical robot to demonstrate zero-shot sim-to-real policy transfer on several physically-interactive tasks requiring a sense of touch.",project-academic
10.1109/TCSVT.2017.2726564,2018-10-01,a,IEEE,a hardware architecture for cell based feature extraction and classification using dual feature space," Many computer-vision and machine-learning applications in robotics, mobile, wearable devices, and automotive domains are constrained by their real-time performance requirements. This paper reports a dual-feature-based object recognition coprocessor that exploits both histogram of oriented gradient (HOG) and Haar-like descriptors with a cell-based parallel sliding-window recognition mechanism. The feature extraction circuitry for HOG and Haar-like descriptors is implemented by a pixel-based pipelined architecture, which synchronizes to the pixel frequency from the image sensor. After extracting each cell feature vector, a cell-based sliding window scheme enables parallelized recognition for all windows, which contain this cell. The nearest neighbor search classifier is, respectively, applied to the HOG and Haar-like feature space. The complementary aspects of the two feature domains enable a hardware-friendly implementation of the binary classification for pedestrian detection with improved accuracy. A proof-of-concept prototype chip fabricated in a 65-nm SOI CMOS, having thin gate oxide and buried oxide layers (SOTB CMOS), with 3.22-mm2 core area achieves an energy efficiency of 1.52 nJ/pixel and a processing speed of 30 fps for None None None $1024\times 1616$ None None -pixel image frames at 200-MHz recognition working frequency and 1-V supply voltage. Furthermore, multiple chips can implement image scaling, since the designed chip has image-size flexibility attributable to the pixel-based architecture.",project-academic
10.1109/CIFER.2019.8759121,2019-05-04,p,IEEE,chatbot application on cryptocurrency," Many chatbots have been developed that provide a multitude of services through a wide range of methods. A chatbot is a brand-new conversational agent in the highspeed changing technology world. With the advance of Artificial Intelligence and machine learning, chatbots are becoming more and more popular. A chatbot is the extension of human interface mediums such as the phone and social platforms. Similarly, Cryptocurrency is a new extension of digital or virtual currency designed to work as a medium of exchange. In the current digital exchanging world, investors and interested parties are eager to know more information about, and the capabilites of, this new type of currency. One of the potential paths to retrieve the info automatically and quickly is through a chatbot. We explored the open source python library, Chatterbot, to apply Itchat API (a WeChat interface) with the aim of building a robot chatting application, I&C Chat, on the topic of cryptocurrency. First, we collected question and answer pairs datasets from Quora websites. Furthermore, we also created API calls to query the real time quote for the top 25 cryptocurrencies. Then we used the collected data to train our chatbot and implemented a logic adapter to receive the price quote of cryptocurrencies based on the incoming question. The Itchat API method will return the best matched answer to the asking party automatically. The response time of different questions has been investigated. The results imply that this application is quite useful, feasible and beneficial to the digital currency world.",project-academic
10.1016/S0921-8890(98)00054-2,1998-11-30,a,North-Holland,q learning of complex behaviours on a six legged walking machine," We present work on a six-legged walking machine that uses a hierarchical version of [C.J.C.H. Watkins, Learning with delayed rewards, Ph.D. Thesis, Psychology Department, Cambridge University, 1989] Q-learning (HQL) to learn both: the elementary swing and stance movements of individual legs as well as the overall coordination scheme to perform forward movements. The architecture consists of a hierarchy of local controllers implemented in layers. The lowest layer consists of control modules performing elementary actions, like moving a leg up, down, left or right to achieve the elementary swing and stance motions for individual legs. The next level consists of controllers that learn to perform more complex tasks like forward movement by using the previously learned, lower level modules. The work is related to similar, although simulation based, work [L.J. Lin, Reinforcement learning for robots using neural networks, Ph.D. Thesis, Carnegie Mellon University, 1993] on hierarchical reinforcement-learning and [S.P. Singh, learning to solve Markovian decision problems, Ph.D. Thesis, Department of Computer Science at the University of Massachusetts, 1994] on compositional Q-learning. We report on the HQL architecture as well as on its implementation on the walking machine Sir Arthur. Results from experiments carried out on the real robot are reported to show the applicability of the HQL approach to real world robot problems.",project-academic
10.1109/EURBOT.1997.633565,1997-10-22,p,IEEE,q learning of complex behaviours on a six legged walking machine," We present work on a six-legged walking machine that uses a hierarchical version of Q-learning (HQL) to learn both the elementary swing and stance movements of individual legs as well as the overall coordination scheme to perform forward movements. The architecture consists of a hierarchy of local controllers implemented in layers. The lowest layer consists of control modules performing elementary actions, like moving a leg up, down, left or right to achieve the elementary swing and stance motions for individual legs. The next level consists of controllers that learn to perform more complex tasks like forward movement by using the previously learned, lower level modules. On the third the highest layer in the architecture presented here the previously learned complex movements are themselves reused to achieve goals in the environment using external sensory input. The work is related to similar, although simulation-based, work by Lin (1993) on hierarchical reinforcement learning and Singh (1994) on compositional Q-learning. We report on the HQL architecture as well as on its implementation on the walking machine SIR ARTHUR. Results from experiments carried out on the real robot are reported to show the applicability of the HQL approach to real world robot problems.",project-academic
10.1016/S0004-3702(99)00068-5,1999-10-01,a,Elsevier,smart office robot collaboration based on multi agent programming," Abstract None None As a new Artificial Intelligence (AI) application to our everyday life, we designed and implemented a smart office environment in which various information appliances work collaboratively to support our office activities. In this environment, many cameras and infrared sensors allow handling robots and mobile robots to perform complex tasks such as printing and delivering document. The delivery task is a typical example of an important class of tasks supporting humans in the smart office. In this paper, such robots are modeled as robotic agents, and collaboration between the agents is realized using multi-agent programming. We have developed a multi-agent robot language (MRL) as an evolution of concurrent logic programming. MRL provides synchronous and asynchronous control of agents based on guarded Horn clauses. It also supports describing an advanced negotiation protocol using broadcast and incomplete messages, and making decisions using a set of logical rules. These features are unified within an MRL framework, yielding an intelligent integration of the robotic agents. We view the smart office environment as a human assistant system through agent collaboration, and this view is novel and extendable as AI for everyday functions.",project-academic
,2010-01-01,a,,beyond teleoperation exploiting human motor skills with marionet," Although machine learning has improved the rate and accuracy at which robots are able to learn, there still exist tasks for which humans can improve performance significantly faster and more robustly than computers. While some ongoing work considers the role of human reinforcement in intelligent algorithms, the burden of learning is often placed solely on the computer. These approaches neglect the expressive capabilities of humans, especially regarding our ability to quickly refine motor skills. In this paper, we propose a general framework for Motion Acquisition for Robots through Iterative Online Evaluative Training (MARIOnET). Our novel paradigm centers around a human in a motion-capture laboratory that “puppets” a robot in realtime. This mechanism allows for rapid motion development for different robots, with a training process that provides a natural human interface and requires no technical knowledge. Fully implemented and tested on two robotic platforms (one quadruped and one biped), this paper demonstrates that MARIOnET is a viable way to directly transfer human motion skills to robots.",project-academic
10.1109/BIOCAS.2012.6418493,2012-11-01,p,IEEE,live demo spiking ratslam rat hippocampus cells in spiking neural hardware," We will demonstrate a model of rat hippocampus place, grid and Border cells implemented with the SpiNNaker spiking neural hardware, configured using the Neural Engineering Framework (NEF) package Nengo, hosted on a mobile robot. These cells are used by rats for odometry, to locate landmarks and for navigation. Nengo provides a dynamical systems approach to configure large scale spiking neural hardware, while SpiNNaker allows these large scale networks to be realized in real-time and to control small mobile platforms. The hippocampus model implemented in this work uses Spatial Envelope Synthesis (SES), which produces place, Border and grid cells by interfering velocity tuned neural oscillators. Such cells have been recorded in the rat's hippocampus and are used during navigation.",project-academic
10.1016/J.ASOC.2003.07.001,2004-02-01,a,Elsevier,recognizing environments from action sequences using self organizing maps," Abstract None None In this paper, we describe development of a mobile robot which does unsupervised learning for recognizing an environment from action sequences. We call this novel recognition approach action-based environment modeling ( AEM ). Most studies on recognizing an environment have tried to build precise geometric maps with high sensitive and global sensors. However such precise and global information may be hardly obtained in a real environment, and may be unnecessary to recognize an environment. Furthermore unsupervised-learning is necessary for recognition in an unknown environment without help of a teacher. Thus we attempt to build a mobile robot which does unsupervised-learning to recognize environments with low sensitive and local sensors. The mobile robot is behavior-based and does wall-following in enclosures (called rooms). Then the sequences of actions executed in each room are transformed into environment vectors for self-organizing maps. Learning without a teacher is done, and the robot becomes able to identify rooms. Moreover, we develop a method to identify environments independent of a start point using a partial sequence. We have fully implemented the system with a real mobile robot, and made experiments for evaluating the ability. As a result, we found out that the environment recognition was done well and our method was adaptive to noisy environments.",project-academic
10.1186/1471-2202-11-S1-P163,2010-07-20,a,BioMed Central,space and time related firing in a model of hippocampo cortical interactions," The present work is part of a project aiming at modeling the hippocampo-cortical interactions in order to solve complex navigation tasks. It is the result of a long partnership between neurobiologists and computer scientists. A close feedback loop between in vivo experiments and computer models leads us to produce biologically accurate neural networks used in robotic navigation. Place cells are pyramidal neurons of the hippocampus (Hs) exhibiting high rates of firing at a particular location in the environment, corresponding to the cell’s “place field”. In a task where rats have to navigate to a goal location and wait for a reward, we recently observed the timing prediction capabilities of CA place cells [1]. This “out-of-field” firing was recorded at the goal location, far from the original place fields of the cells. These patterns of activity are suggested to spread from the Hs to the medial prefrontal cortex (mPFC) where similar activities were observed [2]. Methods In a previous model [3], a spectral timing neural network [4] was used to account for the role of the Hs in the acquisition of classical conditioning. The ability to estimate the timing between separate events was then used to learn and predict transitions between places in the environment. We propose a neural architecture based on this work and explaining the out-of-field activities in the Hs along with their temporal prediction capabilities. The model uses the hippocampo-cortical pathway as a means to spread reward signals to entorhinal neurons. Secondary predictions of the reward signal are then learned, based on transition learning, by pyramidal neurons of the CA region. Results The architecture was implemented in a simulated environment. An agent learned to navigate to a goal location and wait for a reward with the supervision of the experimenter. The results match neurophysiological observations in several ways: 1) Recorded neural activities in hippocampal place cells display out-of-field firing, predictive of the reward at the goal location, in addition to the usual firing on the primary place field. 2) Timing-related firing in the Hs is propagated to the mPFC. This is coherent with observations of the abolition of such activity in the mPFC following hippocampal lesions in rats. 3) The mPFC only plays ar ole during the learning phase of the secondary associations. This is consistent with neurophysiological data on the lack of effect of mPFC inactivation on out-of-field firing in the Hs after learning. Our model is realistic and makes testable hypotheses as to the neural pathways involved. In vivo experiments will be conducted to confirm or infirm those hypotheses. Future work involves testing the system on a real robot in large scale environments.",project-academic
10.1007/3-540-48422-1_7,1999-01-01,p,"Springer, Berlin, Heidelberg",the cs freiburg robotic soccer team reliable self localization multirobot sensor integration and basic soccer skills," Robotic soccer is a challenging research domain because problems in robotics, artificial intelligence, multi-agent systems and real-time reasoning have to be solved in order to create a successful team of robotic soccer players. In this paper, we describe the key components of the CS Freiburg team. We focus on the self-localization and object recognition method based on using laser range finders and the integration of all this information into a global world model. Using the explicit model of the environment built by these components, we have implemented path planning, simple ball handling skills and basic multi-agent cooperation. The resulting system is a very successful robotic soccer team, which has not lost any game yet.",project-academic
10.1016/J.ENCEP.2018.08.002,2019-04-01,a,Elsevier Masson,toward a motor signature in autism studies from human machine interaction," Abstract None None Background None Autism spectrum disorder (ASD) is a heterogeneous group of neurodevelopmental disorders which core symptoms are impairments in socio-communication and repetitive symptoms and stereotypies. Although not cardinal symptoms per se, motor impairments are fundamental aspects of ASD. These impairments are associated with postural and motor control disabilities that we investigated using computational modeling and developmental robotics through human-machine interaction paradigms. None None None Method None First, in a set of studies involving a human–robot posture imitation, we explored the impact of 3 different groups of partners (including a group of children with ASD) on robot learning by imitation. Second, using an ecological task, i.e. a real-time motor imitation with a tightrope walker (TW) avatar, we investigated interpersonal synchronization, motor coordination and motor control during the task in children with ASD (n = 29), TD children (n = 39) and children with developmental coordination disorder (n = 17, DCD). None None None Results None From the human–robot experiments, we evidenced that motor signature at both groups’ and individuals’ levels had a key influence on imitation learning, posture recognition and identity recognition. From the more dynamic motor imitation paradigm with a TW avatar, we found that interpersonal synchronization, motor coordination and motor control were more impaired in children with ASD compared to both TD children and children with DCD. Taken together these results confirm the motor peculiarities of children with ASD despite imitation tasks were adequately performed. None None None Discussion None Studies from human-machine interaction support the idea of a behavioral signature in children with ASD. However, several issues need to be addressed. Is this behavioral signature motoric in essence? Is it possible to ascertain that these peculiarities occur during all motor tasks (e.g. posture, voluntary movement)? Could this motor signature be considered as specific to autism, notably in comparison to DCD that also display poor motor coordination skills? We suggest that more work comparing the two conditions should be implemented, including analysis of kinematics and movement smoothness with sufficient measurement quality to allow spectral analysis.",project-academic
10.1109/ROMAN.2016.7745248,2016-08-01,p,IEEE,real time human detection for robots using cnn with a feature based layered pre filter," Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",project-academic
10.1109/RO-MAN47096.2020.9223566,2020-08-01,p,IEEE,robust real time hand gestural recognition for non verbal communication with tabletop robot haru," In this paper, we present our work in close-distance non-verbal communication with tabletop robot Haru through hand gestural interaction. We implemented a novel hand gestural understanding system by training a machine-learning architecture for real-time hand gesture recognition with the Leap Motion. The proposed system is activated based on the velocity of a user's palm and index finger movement, and subsequently labels the detected movement segments under an early classification scheme. Our system is able to combine multiple gesture labels for recognition of consecutive gestures without clear movement boundaries. System evaluation is conducted on data simulating real human-robot interaction conditions, taking into account relevant performance variables such as movement style, timing and posture. Our results show robustness in hand gesture classification performance under variant conditions. We furthermore examine system behavior under sequential data input, paving the way towards seamless and natural real-time close-distance hand-gestural communication in the future.",project-academic
10.1109/IJCNN.2014.6889647,2014-07-06,p,IEEE,intelligent facial action and emotion recognition for humanoid robots," This research focuses on the development of a realtime intelligent facial emotion recognition system for a humanoid robot. In our system, Facial Action Coding System is used to guide the automatic analysis of emotional facial behaviours. The work includes both an upper and a lower facial Action Units (AU) analyser. The upper facial analyser is able to recognise six AUs including Inner and Outer Brow Raiser, Upper Lid Raiser etc, while the lower facial analyser is able to detect eleven AUs including Upper Lip Raiser, Lip Corner Puller, Chin Raiser, etc. Both of the upper and lower analysers are implemented using feedforward Neural Networks (NN). The work also further decodes six basic emotions from the recognised AUs. Two types of facial emotion recognisers are implemented, NN-based and multi-class Support Vector Machine (SVM) based. The NN-based facial emotion recogniser with the above recognised AUs as inputs performs robustly and efficiently. The Multi-class SVM with the radial basis function kernel enables the robot to outperform the NN-based emotion recogniser in real-time posed facial emotion detection tasks for diverse testing subjects.",project-academic
10.1109/ISC2.2016.7580798,2016-09-01,p,Institute of Electrical and Electronics Engineers Inc.,smartseal a ros based home automation framework for heterogeneous devices interconnection in smart buildings," With this paper we present the SmartSEAL inter-connection system developed for the nationally founded SEAL project. SEAL is a research project aimed at developing Home Automation (HA) solutions for building energy management, user customization and improved safety of its inhabitants. One of the main problems of HA systems is the wide range of communication standards that commercial devices use. Usually this forces the designer to choose devices from a few brands, limiting the scope of the system and its capabilities. In this context, SmartSEAL is a framework that aims to integrate heterogeneous devices, such as sensors and actuators from different vendors, providing networking features, protocols and interfaces that are easy to implement and dynamically configurable. The core of our system is a Robotics middleware called Robot Operating System (ROS). We adapted the ROS features to the HA problem, designing the network and protocol architectures for this particular needs. These software infrastructure allows for complex HA functions that could be realized only levering the services provided by different devices. The system has been tested in our laboratory and installed in two real environments, Palazzo Fogazzaro in Schio and “Le Case” childhood school in Malo. Since one of the aim of the SEAL project is the personalization of the building environment according to the user needs, and the learning of their patterns of behaviour, in the final part of this work we also describe the ongoing design and experiments to provide a Machine Learning based re-identification module implemented with Convolutional Neural Networks (CNNs). The description of the adaptation module complements the description of the SmartSEAL system and helps in understanding how to develop complex HA services through it.",project-academic
10.1145/2559636.2559792,2014-03-03,p,ACM,puzzling exercises for spatial training with robot manipulators," Robot operation requires spatial reasoning and can be used for spatial training. This paper proposes exercises for training spatial skills through operating robot manipulators in virtual and real environments. The exercises were implemented in a robotics workshop, and the follow-up indicated a significant advance of the participants in performing mental rotation tasks.Categories and Subject DescriptorsI.2.9 [Artificial Intelligence]: Robotics – manipulators, operator interfaces, workcell organization and planning.General TermsPerformance, Experimentation, Human Factors.",project-academic
10.1109/COASE.2017.8256157,2017-08-01,p,IEEE,full automatic path planning of cooperating robots in industrial applications," Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",project-academic
,2018-10-01,p,,motion planning with obstacle avoidance of an ur3 robot using charge system search," For a cyber-physical system (CPS) of a future intelligent factory, a robotic manipulator is requested to co-work with human efficiently and safely in an environment with flexible arrangements. Therefore, an autonomous path planning of robotic manipulator is the most necessary issue to be resolved for the factory automation. For the robotic manipulator, optimizations and artificial intelligence (AI) methods are widely used to investigate the autonomous dynamic path-planning tasks with obstacle avoidance. Among these methods, the Rapidly Exploring Random Tree (RRT) algorithm has been widely used in path planning for a complex environment, because the RRT algorithm has the advantages of perfect expansion, probability completeness, and fast exploring speed. However, for some practical cases, the existing RRT algorithm may obtain a discontinuous solution of the angular trajectory. To solve the above problem, we studied a particle swarm optimization with the charge search system (CSS) to find the optimal path planning with obstacle avoidance. The steps of the proposed method are mentioned as follows: (1) establish the configuration space with the obstacle regions, (2) formulate the motion planning with obstacle using the CSS method and (3) use the PSO method to solve the path planning problem. Finally, the simulation of the path-planning task with obstacle avoidance is visually illustrated using the software RoboDK and the proposed method is implemented by the real-time experiments of the UR3 robot.",project-academic
10.1109/ICRA.2019.8794123,2019-05-20,p,IEEE,visual guidance and automatic control for robotic personalized stent graft manufacturing," Personalized stent graft is designed to treat Abdominal Aortic Aneurysms (AAA). Due to the individual difference in arterial structures, stent graft has to be custom made for each AAA patient. Robotic platforms for autonomous personalized stent graft manufacturing have been proposed in recently which rely upon stereo vision systems for coordinating multiple robots for fabricating customized stent grafts. This paper proposes a novel hybrid vision system for real-time visual-sevoing for personalized stent-graft manufacturing. To coordinate the robotic arms, this system is based on projecting a dynamic stereo microscope coordinate system onto a static wide angle view stereo webcam coordinate system. The multiple stereo camera configuration enables accurate localization of the needle in 3D during the sewing process. The scale-invariant feature transform (SIFT) method and color filtering are implemented for stereo matching and feature identifications for object localization. To maintain the clear view of the sewing process, a visual-servoing system is developed for guiding the stereo microscopes for tracking the needle movements. The deep deterministic policy gradient (DDPG) reinforcement learning algorithm is developed for real-time intelligent robotic control. Experimental results have shown that the robotic arm can learn to reach the desired targets autonomously.",project-academic
10.1109/IROS.2005.1545188,2005-12-05,p,IEEE,interactive evolution of human robot communication in real world," This paper describes how to implement interactive evolutionary computation (IEC) into a human-robot communication system. IEC is an evolutionary computation (EC) in which the fitness function is performed by human assessors. We used IEC to configure the human-robot communication system. We have already simulated IEC's application. In this paper, we implemented IEC into a real robot. Since this experiment leads considerable burdens on both the robot and experimental subjects, we propose the human-machine hybrid evaluation (HMHE) to increase the diversity within the genetic pool without increasing the number of interactions. We used a communication robot, WAMOEBA-3 (Waseda artificial mind on emotion base), which is appropriate for this experiment. In the experiment, human assessors interacted with WAMOEBA-3 in various ways. The fitness values increased gradually, and assessors felt the robot learnt the motions they desired. Therefore, it was confirmed that the IEC is most suitable as the communication learning system.",project-academic
10.1109/SSCI.2017.8280907,2017-11-01,p,IEEE,obstacle avoidance of hexapod robots using fuzzy q learning," Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",project-academic
,2005-01-01,p,,reinforcement learning of hierarchical skills on the sony aibo robot," Humans frequently engage in activities for their own sake rather than as a step towards solving a specific task. During such behavior, which psychologists refer to as being intrinsically motivated, we often develop skills that allow us to exercise mastery over our environment. Reference [7] have recently proposed an algorithm for intrinsically motivated reinforcement learning (IMRL) aimed at constructing hierarchies of skills through self-motivated interaction of an agent with its environment. While they were able to successfully demonstrate the utility of IMRL in simulation, we present the first realization of this approach on a real robot. To this end, we implemented a control architecture for the Sony-AIBO robot that extends the IMRL algorithm to this platform. Through experiments, we examine whether the Aibo is indeed able to learn useful skill hierarchies.",project-academic
10.1016/J.COGSYS.2009.12.003,2010-09-01,a,Elsevier Science Publishers B. V.,cognitive concepts in autonomous soccer playing robots," Computational concepts of cognition, their implementation in complex autonomous systems, and their empirical evaluation are key techniques to understand and validate concepts of cognition and intelligence. In this paper we want to describe computational concepts of cognition that were successfully implemented in the domain of soccer playing robots and show the interactions between cognitive concepts, software engineering and real-time application development. Beside a description of the general concepts we will focus on aspects of perception, behavior architecture, and reinforcement learning.",project-academic
10.3390/S20030635,2020-01-23,a,Multidisciplinary Digital Publishing Institute,simultaneous semantic segmentation and depth completion with constraint of boundary," As the core task of scene understanding, semantic segmentation and depth completion play a vital role in lots of applications such as robot navigation, AR/VR and autonomous driving. They are responsible for parsing scenes from the angle of semantics and geometry, respectively. While great progress has been made in both tasks through deep learning technologies, few works have been done on building a joint model by deeply exploring the inner relationship of the above tasks. In this paper, semantic segmentation and depth completion are jointly considered under a multi-task learning framework. By sharing a common encoder part and introducing boundary features as inner constraints in the decoder part, the two tasks can properly share the required information from each other. An extra boundary detection sub-task is responsible for providing the boundary features and constructing cross-task joint loss functions for network training. The entire network is implemented end-to-end and evaluated with both RGB and sparse depth input. Experiments conducted on synthesized and real scene datasets show that our proposed multi-task CNN model can effectively improve the performance of every single task.",project-academic
10.1109/IROS.2018.8594070,2018-10-01,p,IEEE,hark bird box a portable real time bird song scene analysis system," This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.",project-academic
10.1109/ISCAS.2007.378701,2007-05-27,p,IEEE,configuring of spiking central pattern generator networks for bipedal walking using genetic algorthms," In limbed animals, spinal neural circuits responsible for controlling muscular activities during walking are called central pattern generators (CPG). CPG networks display oscillatory activities that actuates individual or groups of muscles in a coordinated fashion so that the limbs of the animal are flexed and extended at the appropriate time and with the required velocity for the animal to efficiently traverse various types of terrain, and to recover from environmental perturbation. Typically, the CPG networks are constructed with many neurons, each of which has a number of control parameters. As the number of muscles increases, it is often impossible to manually, albeit intelligently, select the network parameters for a particular movement. Furthermore, it is virtually impossible to reconfigure the parameters on-line. This paper describes how genetic algorithms (GA) can be used for on-line (re)configuring of CPG networks for a bipedal robot. We show that the neuron parameters and connection weights/network topology of a canonical walking network can be reconfigured within a few of generations of the GA. The networks, constructed with integrate-and-fire-with-adaptation (IFA) neurons, are implemented with a microcontroller and can be reconfigured to vary walking speed from 0.5Hz to 3.5Hz. The phase relationship between the hips and knees can be arbitrarily set (to within 1 degree) and prescribed complex joint angle profiles are realized. This is a powerful approach to generating complex muscle synergies for robots with multiple joints and distributed actuators.",project-academic
10.1016/S0141-9331(02)00069-8,2002-12-20,a,Elsevier,real time implementation of a dynamic fuzzy neural networks controller for a scara," Abstract None None This paper presents the design, development and implementation of a Dynamic Fuzzy Neural Networks (D-FNNs) Controller suitable for real-time industrial applications. The unique feature of the D-FNNs controller is that it has dynamic self-organising structure, fast learning speed, good generalisation and flexibility in learning. The approach of rapid prototyping is employed to implement the D-FNNs controller with a view of controlling a Selectively Compliance Assembly Robot Arm (SCARA) in real time. Simulink, an iterative software for simulating dynamic systems, is used for modelling, simulation and analysis of the dynamic system. The D-FNNs controller was implemented through Real-Time Workshop (RTW). RTW generates C-codes from the Simulink block diagrams and in turn, the generated codes (object codes) are downloaded to the dSPACE DS1102 floating-point processor, together with the supporting files, for execution. The performance of the D-FNNs controller was found to be superior and it matches favourably with the simulation results.",project-academic
10.1109/ICSTCC.2019.8885611,2019-10-01,p,IEEE,visual analytics framework for condition monitoring in cyber physical systems," One of the biggest challenges facing the factory of the future today is to reduce the time-to-market access and increase through the improvement of competitiveness and efficiency. In order to achieve this target, data analytics in Industrial Cyber-Physical System becomes a feasible option. In this paper, a visual analytics framework for condition monitoring of the machine tool is presented with the aim to manage events and alarms at factory level. The framework is assessed in a particular use case that consists in a multi-threaded cloud-based solution for the global analysis of the behaviour of variables acquired from PLC, CNC and robot manipulator. A human-machine interface is also designed for the real-time visualization of the key performance indicators according to the user’s criteria. This tool implemented is a great solution for condition monitoring and decision-making process based on data analytics from simple statistics to complex machine learning methods. The results achieved are part of the vision and implementation of the industrial test bed of “Industry and Society 5.0” platform.",project-academic
10.1007/978-3-642-10817-4_114,2009-12-16,p,Springer-Verlag,the study on optimal gait for five legged robot with reinforcement learning," The research of legged robot was rapidly developed. It can be seen from recent ideas about new systems of robot movement that take ideas from nature, called biology inspired. This type of robot begins replacing wheeled robot with various functions and interesting maneuvers ability. However, designers should decide how many legs are required to realize the ideas. One of the ideas that are rarely developed is odd number of legs. This research focused on five legs robot that inspired from starfish. To realize the intelligent system in robot that does not depend on the model, this research used reinforcement learning algorithm to find the optimal gait when robot is walking. In order to achieve this goal, trial and error have been used to provide learning through an interaction between robot and environment based on a policy of reward and punishment. The algorithm is successfully implemented to get the optimal gait on a five-legged robot.",project-academic
10.1109/SOFA.2009.5254883,2009-09-22,p,IEEE,neurodynamic optimization with its application for model predictive control," Optimization problems arise in a wide variety of scientific and engineering applications. It is computationally challenging when optimization procedures have to be performed in real time to optimize the performance of dynamical systems. For such applications, classical optimization techniques may not be competent due to the problem dimensionality and stringent requirement on computational time. One very promising approach to dynamic optimization is to apply artificial neural networks. Because of the inherent nature of parallel and distributed information processing in neural networks, the convergence rate of the solution process is not decreasing as the size of the problem increases. Neural networks can be implemented physically in designated hardware such as ASICs where optimization is carried out in a truly parallel and distributed manner. This feature is particularly desirable for dynamic optimization in decentralized decision-making situations arising frequently in control and robotics. In this talk, I will present the historic review and the state of the art of neurodynamic optimization models and selected applications in robotics and control. Specifically, starting from the motivation of neurodynamic optimization, we will review various recurrent neural network models for optimization. Theoretical results about the stability and optimality of the neurodynamic optimization models will be given along with illustrative examples and simulation results. It will be shown that many problems in control systems, such model predictive control, can be readily solved by using the neurodynamic optimization models. Specifically, linear and nonlinear model predictive control based on neurodynamic optimization will be delineated.",project-academic
10.1016/J.NEUCOM.2021.08.115,2021-11-20,a,Elsevier,hurai a brain inspired computational model for human robot auditory interface," Abstract None None The deep learning era endows immense opportunities for ubiquitous robotic applications by leveraging big data generated from widespread sensors and ever-growing computing capability. While the growing demands for natural human-robot interaction (HRI) as well as concerns for energy efficiency, real-time performance, and data security motive novel solutions. In this paper, we present a brain-inspired spiking neural network (SNN) based Human-Robot Auditory Interface, namely HuRAI. The HuRAI integrates the voice activity detection, speaker localization and voice command recognition systems into a unified framework that can be implemented on the emerging low-power neuromorphic computing (NC) devices. Our experimental results demonstrate superior modeling capabilities of SNNs, achieving accurate and rapid prediction for each task. Moreover, the energy efficiency analysis reveals a compelling prospect, with up to three orders of magnitude energy savings, over the equivalent artificial neural networks that running on the state-of-the-art Nvidia graphics processing unit (GPU). Therefore, integrating the algorithmic power of large-scale SNN models and the energy efficiency of NC devices offers an attractive solution for real-time, low-power robotic applications.",project-academic
10.1109/TASE.2020.3017022,2021-10-01,a,IEEE,robotic grasping of unknown objects using novel multilevel convolutional neural networks from parallel gripper to dexterous hand," To achieve high-accuracy grasping of unknown objects, we present novel multilevel convolutional neural networks (CNNs) for robotic grasping with a parallel gripper or multifingered dexterous hand. The multilevel CNNs include four levels with different structures and functions. The first level is constructed to get the approximate position of the grasped object. The second level aims to obtain the preselected grasping rectangles. The third level is constructed to re-evaluate the preselected grasping rectangles and obtain substantially detailed features with quite a large network, so as to assess each preselected grasping rectangle exactly. By using a selection algorithm, the optimal grasping rectangle can be determined and unknown object grasping can be achieved with a parallel gripper. The purpose of the fourth level is to obtain the finger position distribution to complete the accurate grasping of unknown objects with a multifingered dexterous hand. The test results indicate that, compared to state-of-the-art methods, the proposed multilevel CNNs can greatly increase the precision of the grasping rectangle. Grasping experiments were implemented on a Youbot arm with five degrees of freedom and a Shadow four-fingered dexterous hand. The results show that the multilevel CNNs can determine the optimal grasping rectangle and finger position distribution, thereby achieving high-accuracy grasping of various unknown objects, even under several complex environmental conditions. None Note to Practitioners—Robot grasping of objects lags far behind human experiences and poses a significant challenge in the robotics area. To solve it, we present new multilevel convolutional neural networks (CNNs) to process red green blue-depth (RGB-D) images and realize optimal grasping detection of unknown objects. Moreover, we provide details of the network structure, network training, and network testing. The testing results obtained from the open grasping data set show that the multilevel CNNs can significantly increase the accuracy of the grasping rectangle compared to state-of-the-art methods. Experiments were implemented on different robotic platforms, including a five-degrees-of-freedom Youbot arm with a parallel gripper and a UR5 robot arm with a Shadow multifingered dexterous hand. The results validate that the multilevel CNNs offer excellent generalization and robustness for handling different sizes and shapes of unknown objects, as well as background disturbances, which are key problems in robotic manipulation.",project-academic
10.3390/S20236896,2020-12-03,a,Multidisciplinary Digital Publishing Institute,real time plant leaf counting using deep object detection networks," The use of deep neural networks (DNNs) in plant phenotyping has recently received considerable attention. By using DNNs, valuable insights into plant traits can be readily achieved. While these networks have made considerable advances in plant phenotyping, the results are processed too slowly to allow for real-time decision-making. Therefore, being able to perform plant phenotyping computations in real-time has become a critical part of precision agriculture and agricultural informatics. In this work, we utilize state-of-the-art object detection networks to accurately detect, count, and localize plant leaves in real-time. Our work includes the creation of an annotated dataset of Arabidopsis plants captured using Cannon Rebel XS camera. These images and annotations have been complied and made publicly available. This dataset is then fed into a Tiny-YOLOv3 network for training. The Tiny-YOLOv3 network is then able to converge and accurately perform real-time localization and counting of the leaves. We also create a simple robotics platform based on an Android phone and iRobot create2 to demonstrate the real-time capabilities of the network in the greenhouse. Additionally, a performance comparison is conducted between Tiny-YOLOv3 and Faster R-CNN. Unlike Tiny-YOLOv3, which is a single network that does localization and identification in a single pass, the Faster R-CNN network requires two steps to do localization and identification. While with Tiny-YOLOv3, inference time, F1 Score, and false positive rate (FPR) are improved compared to Faster R-CNN, other measures such as difference in count (DiC) and AP are worsened. Specifically, for our implementation of Tiny-YOLOv3, the inference time is under 0.01 s, the F1 Score is over 0.94, and the FPR is around 24%. Last, transfer learning using Tiny-YOLOv3 to detect larger leaves on a model trained only on smaller leaves is implemented. The main contributions of the paper are in creating dataset (shared with the research community), as well as the trained Tiny-YOLOv3 network for leaf localization and counting.",project-academic
10.1016/J.AEI.2020.101052,2020-04-01,a,IOS Press,deep learning based method for vision guided robotic grasping of unknown objects," Abstract None None Nowadays, robots are heavily used in factories for different tasks, most of them including grasping and manipulation of generic objects in unstructured scenarios. In order to better mimic a human operator involved in a grasping action, where he/she needs to identify the object and detect an optimal grasp by means of visual information, a widely adopted sensing solution is Artificial Vision. Nonetheless, state-of-art applications need long training and fine-tuning for manually build the object’s model that is used at run-time during the normal operations, which reduce the overall operational throughput of the robotic system. To overcome such limits, the paper presents a framework based on Deep Convolutional Neural Networks (DCNN) to predict both single and multiple grasp poses for multiple objects all at once, using a single RGB image as input. Thanks to a novel loss function, our framework is trained in an end-to-end fashion and matches state-of-art accuracy with a substantially smaller architecture, which gives unprecedented real-time performances during experimental tests, and makes the application reliable for working on real robots. The system has been implemented using the ROS framework and tested on a Baxter collaborative robot.",project-academic
10.1002/CTA.186,2002-07-01,a,Wiley,multi template approach to realize central pattern generators for artificial locomotion control," Biologically inspired control of artificial locomotion often makes use of the concept of central pattern generator (CPG), a network of neurons establishing the locomotion pattern within a lattice of neural activity. In this paper a new approach, based on cellular neural networks (CNNs), for the design of CPGs is presented. From a biological point of view this new approach includes an approximated chemical synapse realized and implemented in a CNN structure. This allows to extend the results, previously obtained with a reaction-diffusion-CNN (RD-CNN) for the locomotion control of a hexapod robot, to a more general class of artificial CPGs in which the desired locomotion pattern and the switching among patterns are realized by means of a spatio-temporal algorithm implemented in the same CNN structure. Copyright © 2002 John Wiley & Sons, Ltd.",project-academic
,2004-01-01,a,Massachusetts Institute of Technology,cognitive developmental learning for a humanoid robot a caregiver s gift," The goal of this work is to build a cognitive system for the humanoid robot, Cog, that exploits human caregivers as catalysts to perceive and learn about actions, objects, scenes, people, and the robot itself. This thesis addresses a broad spectrum of machine learning problems across several categorization levels. Actions by embodied agents are used to automatically generate training data for the learning mechanisms, so that the robot develops categorization autonomously. 
Taking inspiration from the human brain, a framework of algorithms and methodologies was implemented to emulate different cognitive capabilities on the humanoid robot Cog. This framework is effectively applied to a collection of AI, computer vision, and signal processing problems. Cognitive capabilities of the humanoid robot are developmentally created, starting from infant-like abilities for detecting, segmenting, and recognizing percepts over multiple sensing modalities. Human caregivers provide a helping hand for communicating such information to the robot. This is done by actions that create meaningful events (by changing the world in which the robot is situated) thus inducing the “compliant perception” of objects from these human-robot interactions. Self-exploration of the world extends the robot's knowledge concerning object properties. 
This thesis argues for enculturating humanoid robots using infant development as a metaphor for building a humanoid robot's cognitive abilities. A human caregiver redesigns a humanoid's brain by teaching the humanoid robot as she would teach a child, using children's learning aids such as books, drawing boards, or other cognitive artifacts. Multi-modal object properties are learned using these tools and inserted into several recognition schemes, which are then applied to developmentally acquire new object representations. The humanoid robot therefore sees the world through the caregiver's eyes. 
Building an artificial humanoid robot's brain, even at an infant's cognitive level, has been a long quest which still lies only in the realm of our imagination. Our efforts towards such a dimly imaginable task are developed according to two alternate and complementary views: cognitive and developmental. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)",project-academic
10.1109/RAMECH.2011.6070484,2011-11-07,p,IEEE,a q learning based cartesian model reference compliance controller implementation for a humanoid robot arm, This paper presents the implementation (real time and simulation) of a model-free Q-learning based discrete model reference compliance controller for a humanoid robot arm. The Reinforcement learning (RL) scheme uses a recently developed Q-learning scheme to develop an optimal policy on-line. The RL Cartesian (x and y) tracking controller with model reference compliance was implemented using two links (shoulder flexion and elbow flexion joints) of the right arm of the humanoid Bristol-Elumotion-Robotic-Torso II (BERT II) torso.,project-academic
10.1016/J.NEUNET.2014.10.001,2015-01-01,a,Neural Netw,trends in extreme learning machines," Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of ELM from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to ELM which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, ELM has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, ELM have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in ELM together with its future perspectives.",project-academic
10.1007/S10845-018-1433-8,2020-01-01,a,Springer US,literature review of industry 4 0 and related technologies," Manufacturing industry profoundly impact economic and societal progress. As being a commonly accepted term for research centers and universities, the Industry 4.0 initiative has received a splendid attention of the business and research community. Although the idea is not new and was on the agenda of academic research in many years with different perceptions, the term “Industry 4.0” is just launched and well accepted to some extend not only in academic life but also in the industrial society as well. While academic research focuses on understanding and defining the concept and trying to develop related systems, business models and respective methodologies, industry, on the other hand, focuses its attention on the change of industrial machine suits and intelligent products as well as potential customers on this progress. It is therefore important for the companies to primarily understand the features and content of the Industry 4.0 for potential transformation from machine dominant manufacturing to digital manufacturing. In order to achieve a successful transformation, they should clearly review their positions and respective potentials against basic requirements set forward for Industry 4.0 standard. This will allow them to generate a well-defined road map. There has been several approaches and discussions going on along this line, a several road maps are already proposed. Some of those are reviewed in this paper. However, the literature clearly indicates the lack of respective assessment methodologies. Since the implementation and applications of related theorems and definitions outlined for the 4th industrial revolution is not mature enough for most of the reel life implementations, a systematic approach for making respective assessments and evaluations seems to be urgently required for those who are intending to speed this transformation up. It is now main responsibility of the research community to developed technological infrastructure with physical systems, management models, business models as well as some well-defined Industry 4.0 scenarios in order to make the life for the practitioners easy. It is estimated by the experts that the Industry 4.0 and related progress along this line will have an enormous effect on social life. As outlined in the introduction, some social transformation is also expected. It is assumed that the robots will be more dominant in manufacturing, implanted technologies, cooperating and coordinating machines, self-decision-making systems, autonom problem solvers, learning machines, 3D printing etc. will dominate the production process. Wearable internet, big data analysis, sensor based life, smart city implementations or similar applications will be the main concern of the community. This social transformation will naturally trigger the manufacturing society to improve their manufacturing suits to cope with the customer requirements and sustain competitive advantage. A summary of the potential progress along this line is reviewed in introduction of the paper. It is so obvious that the future manufacturing systems will have a different vision composed of products, intelligence, communications and information network. This will bring about new business models to be dominant in industrial life. Another important issue to take into account is that the time span of this so-called revolution will be so short triggering a continues transformation process to yield some new industrial areas to emerge. This clearly puts a big pressure on manufacturers to learn, understand, design and implement the transformation process. Since the main motivation for finding the best way to follow this transformation, a comprehensive literature review will generate a remarkable support. This paper presents such a review for highlighting the progress and aims to help improve the awareness on the best experiences. It is intended to provide a clear idea for those wishing to generate a road map for digitizing the respective manufacturing suits. By presenting this review it is also intended to provide a hands-on library of Industry 4.0 to both academics as well as industrial practitioners. The top 100 headings, abstracts and key words (i.e. a total of 619 publications of any kind) for each search term were independently analyzed in order to ensure the reliability of the review process. Note that, this exhaustive literature review provides a concrete definition of Industry 4.0 and defines its six design principles such as interoperability, virtualization, local, real-time talent, service orientation and modularity. It seems that these principles have taken the attention of the scientists to carry out more variety of research on the subject and to develop implementable and appropriate scenarios. A comprehensive taxonomy of Industry 4.0 can also be developed through analyzing the results of this review.",project-academic
10.1109/AGRO-GEOINFORMATICS.2017.8047016,2017-08-01,p,IEEE,disease detection on the leaves of the tomato plants by using deep learning," The aim of this work is to detect diseases that occur on plants in tomato fields or in their greenhouses. For this purpose, deep learning was used to detect the various diseases on the leaves of tomato plants. In the study, it was aimed that the deep learning algorithm should be run in real time on the robot. So the robot will be able to detect the diseases of the plants while wandering manually or autonomously on the field or in the greenhouse. Likewise, diseases can also be detected from close-up photographs taken from plants by sensors built in fabricated greenhouses. The examined diseases in this study cause physical changes in the leaves of the tomato plant. These changes on the leaves can be seen with RGB cameras. In the previous studies, standard feature extraction methods on plant leaf images to detect diseases have been used. In this study, deep learning methods were used to detect diseases. Deep learning architecture selection was the key issue for the implementation. So that, two different deep learning network architectures were tested first AlexNet and then SqueezeNet. For both of these deep learning networks training and validation were done on the Nvidia Jetson TX1. Tomato leaf images from the PlantVillage dataset has been used for the training. Ten different classes including healthy images are used. Trained networks are also tested on the images from the internet.",project-academic
10.1007/S10846-017-0468-Y,2017-05-01,a,Springer Netherlands,survey of model based reinforcement learning applications on robotics," Reinforcement learning is an appealing approach for allowing robots to learn new tasks. Relevant literature reveals a plethora of methods, but at the same time makes clear the lack of implementations for dealing with real life challenges. Current expectations raise the demand for adaptable robots. We argue that, by employing model-based reinforcement learning, the--now limited--adaptability characteristics of robotic systems can be expanded. Also, model-based reinforcement learning exhibits advantages that makes it more applicable to real life use-cases compared to model-free methods. Thus, in this survey, model-based methods that have been applied in robotics are covered. We categorize them based on the derivation of an optimal policy, the definition of the returns function, the type of the transition model and the learned task. Finally, we discuss the applicability of model-based reinforcement learning approaches in new applications, taking into consideration the state of the art in both algorithms and hardware.",project-academic
10.1016/J.NEUNET.2018.07.006,2018-08-04,a,Pergamon,state representation learning for control an overview," Abstract None None Representation learning algorithms are designed to learn abstract features that characterize data. State representation learning (SRL) focuses on a particular kind of representation learning where learned features are in low dimension, evolve through time, and are influenced by actions of an agent. The representation is learned to capture the variation in the environment generated by the agent’s actions; this kind of representation is particularly suitable for robotics and control scenarios. In particular, the low dimension characteristic of the representation helps to overcome the curse of dimensionality, provides easier interpretation and utilization by humans and can help improve performance and speed in policy learning algorithms such as reinforcement learning. None This survey aims at covering the state-of-the-art on state representation learning in the most recent years. It reviews different SRL methods that involve interaction with the environment, their implementations and their applications in robotics control tasks (simulated or real). In particular, it highlights how generic learning objectives are differently exploited in the reviewed algorithms. Finally, it discusses evaluation methods to assess the representation learned and summarizes current and future lines of research.",project-academic
,1996-12-03,p,MIT Press,learning from demonstration," By now it is widely accepted that learning a task from scratch, i.e., without any prior knowledge, is a daunting undertaking. Humans, however, rarely attempt to learn from scratch. They extract initial biases as well as strategies how to approach a learning problem from instructions and/or demonstrations of other humans. For teaming control, this paper investigates how learning from demonstration can be applied in the context of reinforcement learning. We consider priming the Q-function, the value function, the policy, and the model of the task dynamics as possible areas where demonstrations can speed up learning. In general nonlinear learning problems, only model-based reinforcement learning shows significant speed-up after a demonstration, while in the special case of linear quadratic regulator (LQR) problems, all methods profit from the demonstration. In an implementation of pole balancing on a complex anthropomorphic robot arm, we demonstrate that, when facing the complexities of real signal processing, model-based reinforcement learning offers the most robustness for LQR problems. Using the suggested methods, the robot learns pole balancing in just a single trial after a 30 second long demonstration of the human instructor.",project-academic
10.1016/J.FUTURE.2018.08.006,2019-01-01,a,North-Holland,irobot factory an intelligent robot factory based on cognitive manufacturing and edge computing," Abstract None None The Internet of Things (IoT) and Artificial Intelligence (AI) have been driving forces in propelling the technical innovation of intelligent manufacturing, promoting economic growth, and improving the quality of people’s lives. In an intelligent factory, introducing edge computing is conducive to expanding the computing resources, the network bandwidth, and the storage capacity of the cloud platform to the IoT edge, as well as realizing the resource scheduling and data uplink and downlink processing during the manufacturing and production processes. Moreover, the emotion recognition and interaction of the Affective Interaction Intelligence Robot (iRobot), with the IoT cloud platform as the infrastructure and AI technology as the core competitiveness, can better solve the psychological problems of the user. Accordingly, this has become a hot research topic in the field of intelligent manufacturing. In this paper, we describe an intelligent robot factory (iRobot-Factory), adopt a highly interconnected and deeply integrated intelligent production line, and introduce the overall structure, composition, characteristics, and advantages of such a factory in details from the two aspects of cognitive manufacturing and edge computing. Then, we describe the implementation of the volume production of iRobot using iRobot-Factory and look at the system performance experimental results and analysis of the iRobot-Factory and a traditional factory. The experimental results show that our scheme significantly improved both the chip assembly and the production efficiency, while the number of system instructions also decreased significantly. In addition, we discuss some open issues relating to cloud-end fusion, load balancing, and personalized robots to make reference to promoting the emotion recognition and interaction experience of users.",project-academic
10.1007/S11548-019-02011-2,2019-06-11,a,Springer International Publishing,enabling machine learning in x ray based procedures via realistic simulation of image formation," Machine learning-based approaches now outperform competing methods in most disciplines relevant to diagnostic radiology. Image-guided procedures, however, have not yet benefited substantially from the advent of deep learning, in particular because images for procedural guidance are not archived and thus unavailable for learning, and even if they were available, annotations would be a severe challenge due to the vast amounts of data. In silico simulation of X-ray images from 3D CT is an interesting alternative to using true clinical radiographs since labeling is comparably easy and potentially readily available. We extend our framework for fast and realistic simulation of fluoroscopy from high-resolution CT, called DeepDRR, with tool modeling capabilities. The framework is publicly available, open source, and tightly integrated with the software platforms native to deep learning, i.e., Python, PyTorch, and PyCuda. DeepDRR relies on machine learning for material decomposition and scatter estimation in 3D and 2D, respectively, but uses analytic forward projection and noise injection to ensure acceptable computation times. On two X-ray image analysis tasks, namely (1) anatomical landmark detection and (2) segmentation and localization of robot end-effectors, we demonstrate that convolutional neural networks (ConvNets) trained on DeepDRRs generalize well to real data without re-training or domain adaptation. To this end, we use the exact same training protocol to train ConvNets on naive and DeepDRRs and compare their performance on data of cadaveric specimens acquired using a clinical C-arm X-ray system. Our findings are consistent across both considered tasks. All ConvNets performed similarly well when evaluated on the respective synthetic testing set. However, when applied to real radiographs of cadaveric anatomy, ConvNets trained on DeepDRRs significantly outperformed ConvNets trained on naive DRRs (
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None $$p<0.01$$
 None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None None ). Our findings for both tasks are positive and promising. Combined with complementary approaches, such as image style transfer, the proposed framework for fast and realistic simulation of fluoroscopy from CT contributes to promoting the implementation of machine learning in X-ray-guided procedures. This paradigm shift has the potential to revolutionize intra-operative image analysis to simplify surgical workflows.",project-academic
10.1038/S41598-018-38343-3,2019-02-14,a,Nature Publishing Group,deepweeds a multiclass weed species image dataset for deep learning," Robotic weed control has seen increased research of late with its potential for boosting productivity in agriculture. Majority of works focus on developing robotics for croplands, ignoring the weed management problems facing rangeland stock farmers. Perhaps the greatest obstacle to widespread uptake of robotic weed control is the robust classification of weed species in their natural environment. The unparalleled successes of deep learning make it an ideal candidate for recognising various weed species in the complex rangeland environment. This work contributes the first large, public, multiclass image dataset of weed species from the Australian rangelands; allowing for the development of robust classification methods to make robotic weed control viable. The DeepWeeds dataset consists of 17,509 labelled images of eight nationally significant weed species native to eight locations across northern Australia. This paper presents a baseline for classification performance on the dataset using the benchmark deep learning models, Inception-v3 and ResNet-50. These models achieved an average classification accuracy of 95.1% and 95.7%, respectively. We also demonstrate real time performance of the ResNet-50 architecture, with an average inference time of 53.4 ms per image. These strong results bode well for future field implementation of robotic weed control methods in the Australian rangelands.",project-academic
10.1016/J.ESWA.2017.03.002,2017-09-01,a,Pergamon,incremental q learning strategy for adaptive pid control of mobile robots," Adaptive PID control strategy of mobile robots.Integration of Reinforcement Learning with PID control for complex systems.Incremental Q-learning algorithm for real-time tuning of multiples PID controllers.Managing the adaptation process by temporal memories comparison. Expert and intelligent systems are being developed to control many technological systems including mobile robots. However, the PID (Proportional-Integral-Derivative) controller is a fast low-level control strategy widely used in many control engineering tasks. Classic control theory has contributed with different tuning methods to obtain the gains of PID controllers for specific operation conditions. Nevertheless, when the system is not fully known and the operative conditions are variable and not previously known, classical techniques are not entirely suitable for the PID tuning. To overcome these drawbacks many adaptive approaches have been arisen, mainly from the field of artificial intelligent. In this work, we propose an incremental Q-learning strategy for adaptive PID control. In order to improve the learning efficiency we define a temporal memory into the learning process. While the memory remains invariant, a non-uniform specialization process is carried out generating new limited subspaces of learning. An implementation on a real mobile robot demonstrates the applicability of the proposed approach for a real-time simultaneous tuning of multiples adaptive PID controllers for a real system operating under variable conditions in a real environment.",project-academic
10.1007/978-3-319-27702-8_26,2016-01-01,p,"Springer, Cham",vision and learning for deliberative monocular cluttered flight," Cameras provide a rich source of information while being passive, cheap and lightweight for small Unmanned Aerial Vehicles (UAVs). In this work we present the first implementation of receding horizon control, which is widely used in ground vehicles, with monocular vision as the only sensing mode for autonomous UAV flight in dense clutter. Two key contributions make this possible: novel coupling of perception and control via relevant and diverse, multiple interpretations of the scene around the robot, leveraging recent advances in machine learning to showcase anytime budgeted cost-sensitive feature selection, and fast non-linear regression for monocular depth prediction. We empirically demonstrate the efficacy of our novel pipeline via real world experiments of more than 2 kms through dense trees with an off-the-shelf quadrotor. Moreover our pipeline is designed to combine information from other modalities like stereo and lidar.",project-academic
,2014-11-24,a,,vision and learning for deliberative monocular cluttered flight," Cameras provide a rich source of information while being passive, cheap and lightweight for small and medium Unmanned Aerial Vehicles (UAVs). In this work we present the first implementation of receding horizon control, which is widely used in ground vehicles, with monocular vision as the only sensing mode for autonomous UAV flight in dense clutter. We make it feasible on UAVs via a number of contributions: novel coupling of perception and control via relevant and diverse, multiple interpretations of the scene around the robot, leveraging recent advances in machine learning to showcase anytime budgeted cost-sensitive feature selection, and fast non-linear regression for monocular depth prediction. We empirically demonstrate the efficacy of our novel pipeline via real world experiments of more than 2 kms through dense trees with a quadrotor built from off-the-shelf parts. Moreover our pipeline is designed to combine information from other modalities like stereo and lidar as well if available.",project-academic
10.1109/ISSCC.2016.7418005,2016-02-25,p,IEEE,14 3 a 0 55v 1 1mw artificial intelligence processor with pvt compensation for micro robots," Micro robots with artificial intelligence (AI) are being investigated for many applications, such as unmanned delivery services. The robots, shown in Fig. 14.3.1, have enhanced controllers that realize AI functions, such as perception (information extraction) and cognition (decision making). Historically, controllers have been based on general-purpose CPUs, and only recently, a few perception SoCs [1–3] have been reported. SoCs with cognition capability have not been reported thus far, even though cognition is a key AI function in micro robots for decision making, especially autonomous drones. Path planning and obstacle avoidance require more than 10,000 searches within 50ms for a fast response, but a software implementation running on a Cortex-M3 takes ∼5s to make decisions. Micro robots require 10× lower power and 100× faster decision making than conventional robots because of their fast movement in the environment, small form factor, and limited battery capacity. Therefore, an ultra-low-power high-performance artificial-intelligence processor (AIP) is necessary for micro robots to make fast and smart maneuvers in dynamic environments filled with obstacles.",project-academic
10.1109/TMECH.2013.2245337,2014-04-01,a,IEEE,image based visual servoing of a 7 dof robot manipulator using an adaptive distributed fuzzy pd controller," This paper is concerned with the design and implementation of a distributed proportional-derivative (PD) controller of a 7-degrees of freedom (DOF) robot manipulator using the Takagi-Sugeno (T-S) fuzzy framework. Existing machine learning approaches to visual servoing involve system identification of image and kinematic Jacobians. In contrast, the proposed approach actuates a control signal primarily as a function of the error and derivative of the error in the desired visual feature space. This approach leads to a significant reduction in the computational burden as compared to model-based approaches, as well as existing learning approaches to model inverse kinematics. The simplicity of the controller structure will make it attractive in industrial implementations where PD/PID type schemes are in common use. While the initial values of PD gain are learned with the help of model-based controller, an online adaptation scheme has been proposed that is capable of compensating for local uncertainties associated with the system and its environment. Rigorous experiments have been performed to show that visual servoing tasks such as reaching a static target and tracking of a moving target can be achieved using the proposed distributed PD controller. It is shown that the proposed adaptive scheme can dynamically tune the controller parameters during visual servoing, so as to improve its initial performance based on parameters obtained while mimicking the model-based controller. The proposed control scheme is applied and assessed in real-time experiments using an uncalibrated eye-in-hand robotic system with a 7-DOF PowerCube robot manipulator.",project-academic
10.1007/978-3-319-57870-5_1,2018-01-01,a,"Springer, Cham",a conceptual framework for industry 4 0," Industrial Revolution emerged many improvements in manufacturing and service systems. Because of remarkable and rapid changes appeared in manufacturing and information technology, synergy aroused from the integration of the advancements in information technology, services and manufacturing were realized. These advancements conduced to the increasing productivity both in service systems and manufacturing environment. In recent years, manufacturing companies and service systems have been faced substantial challenges due to the necessity in the coordination and connection of disruptive concepts such as communication and networking (Industrial Internet), embedded systems (Cyber Physical Systems), adaptive robotics, cyber security, data analytics and artificial intelligence, and additive manufacturing. These advancements caused the extension of the developments in manufacturing and information technology, and these coordinated and communicative technologies are constituted to the term, Industry 4.0 which was first announced from German government as one of the key initiatives and highlights a new industrial revolution. As a result, Industry 4.0 indicates more productive systems; companies have been searching the right adaptation of this term. On the other hand, the achievement criteria and performance measurements of the transformation to Industry 4.0 are still uncertain. Additionally, a structured and systematic implementation roadmap is still not clear. Thus, in this study, the fundamental relevance between design principles and technologies is given and conceptual framework for Industry 4.0 is proposed concerning fundamentals of smart products and smart processes development.",project-academic
10.3390/S150409022,2015-04-16,a,Multidisciplinary Digital Publishing Institute,comparison of semg based feature extraction and motion classification methods for upper limb movement," The surface electromyography (sEMG) technique is proposed for muscle activation detection and intuitive control of prostheses or robot arms. Motion recognition is widely used to map sEMG signals to the target motions. One of the main factors preventing the implementation of this kind of method for real-time applications is the unsatisfactory motion recognition rate and time consumption. The purpose of this paper is to compare eight combinations of four feature extraction methods (Root Mean Square (RMS), Detrended Fluctuation Analysis (DFA), Weight Peaks (WP), and Muscular Model (MM)) and two classifiers (Neural Networks (NN) and Support Vector Machine (SVM)), for the task of mapping sEMG signals to eight upper-limb motions, to find out the relation between these methods and propose a proper combination to solve this issue. Seven subjects participated in the experiment and six muscles of the upper-limb were selected to record sEMG signals. The experimental results showed that NN classifier obtained the highest recognition accuracy rate (88.7%) during the training process while SVM performed better in real-time experiments (85.9%). For time consumption, SVM took less time than NN during the training process but needed more time for real-time computation. Among the four feature extraction methods, WP had the highest recognition rate for the training process (97.7%) while MM performed the best during real-time tests (94.3%). The combination of MM and NN is recommended for strict real-time applications while a combination of MM and SVM will be more suitable when time consumption is not a key requirement.",project-academic
10.1109/TSMCB.2010.2089978,2011-06-01,a,Institute of Electrical and Electronics Engineers (IEEE),walking motion generation synthesis and control for biped robot by using pgrl lpi and fuzzy logic," This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",project-academic
,2009-10-01,a,American-Eurasian Network for Scientific Information,design and implementation of fpga based systems a review," This paper reviews the state of the art of field programmable gate array (FPGA) with the focus on FPGA-based systems. The paper starts with an overview of FPGA in the previous literature, after that starts to get an idea about FPGA programming. FPGA-based neural networks also provided in this paper in order to highlight the best advantage by using FPGA with this type of intelligent systems, and a survey of FPGA-based control systems design with different applications. In this paper, we focus on the main differences between software-based systems with respect to FPGA-based systems, and the main features for FPGA technology and its real-time applications. FPGA-based robotics systems design also provided in this review, finally, the most popular simulation results with FPGA design and implementations are highlighted.",project-academic
10.1016/J.ASOC.2010.05.002,2011-03-01,p,Elsevier,a highly interpretable fuzzy rule base using ordinal structure for obstacle avoidance of mobile robot," Conventional fuzzy logic controller is applicable when there are only two fuzzy inputs with usually one output. Complexity increases when there are more than one inputs and outputs making the system unrealizable. The ordinal structure model of fuzzy reasoning has an advantage of managing high-dimensional problem with multiple input and output variables ensuring the interpretability of the rule set. This is achieved by giving an associated weight to each rule in the defuzzification process. In this work, a methodology to design an ordinal fuzzy logic controller with application for obstacle avoidance of Khepera mobile robot is presented. The implementation will show that ordinal structure fuzzy is easier to design with highly interpretable rules compared to conventional fuzzy controller. In order to achieve high accuracy, a specially tailored Genetic Algorithm (GA) approach for reinforcement learning has been proposed to optimize the ordinal structure fuzzy controller. Simulation results demonstrated improved obstacle avoidance performance in comparison with conventional fuzzy controllers. Comparison of direct and incremental GA for optimization of the controller is also presented.",project-academic
10.1016/0004-3702(94)90047-7,1994-12-01,a,Elsevier,robot shaping developing autonomous agents through learning," Abstract None None Learning plays a vital role in the development of autonomous agents. In this paper, we explore the use of reinforcement learning to “shape” a robot to perform a predefined target behavior. We connect both simulated and real robots to None Alecsys , a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behaviors, we explore the effects on learning of different types of agent's architecture and training strategies. We show that the best results are achieved when both the agent's architecture and the training strategy match the structure of the behavior pattern to be learned. We report the results of a number of experiments carried out both in simulated and in real environments, and show that the results of simulations carry smoothly to physical robots. While most of our experiments deal with simple reactive behavior, in one of them we demonstrate the use of a simple and general memory mechanism. As a whole, our experimental activity demonstrates that classifier systems with genetic algorithms can be practically employed to develop autonomous agents.",project-academic
10.1016/J.MECHMACHTHEORY.2018.06.019,2018-11-01,a,Pergamon,grasp configuration planning for a low cost and easy operation underactuated three fingered robot hand," Abstract None None This paper proposes a method for modeling and planning the grasping configuration of a robotic hand with underactuated finger mechanisms. The proposed modeling algorithm is based on analysis and mimicking of human grasping experience. Results of the analysis is preprocessed and stored in a database. The grasp configuration planning algorithm can be used within a real time online grasp control as based on artificial neural networks. Namely, shapes and sizes of task objects are described by taxonomy data, which are used to generate grasp configurations. Then, a robot hand grasp control system is designed as based on the proposed grasp planning with close-loop position and force feedback. Simulations and experiments are carried out to show the basic features of the proposed formulation for identifying the grasp configurations while dealing with target objects of different shapes and sizes. It is hoped that the well-trained underactuated robot hand can solve most of grasping tasks in our life. The research approach is aimed to research low-cost easy-operation solution for feasible and practical implementation.",project-academic
10.1109/TMECH.2015.2490180,2016-06-01,a,IEEE,hybrid approach for modeling and solving of kinematics of a compact bionic handling assistant manipulator," This paper deals with a methodology for real-time solving of a complex kinematics of a class of continuum manipulators, namely the compact bionic handling assistant (CBHA). First, a quantitative approach is used to model kinematically the CBHA inspired from the modeling of parallel rigid manipulators. For this case, the CBHA is modeled as a series of vertebrae, where each vertebra is connected to the next one through a flexible link. The latter named an intervertebra is modeled by three universal-prismatic-spherical and one universal-prismatic joints. The kinematic models of the CBHA are derived from the inverse kinematic equations (IKE) of each intervertebra. A qualitative approach based on neural networks is used to provide approximated solutions of the IKE for real-time implementation. Thus, the combination of the advantages of quantitative and qualitative approaches allows proposing a hybrid methodology for accurate modeling and solving the kinematics of this class of continuum robots. A set of experiments is conducted using a CBHA in order to evaluate the level of efficiency of the proposed hybrid approach.",project-academic
10.1016/J.NEUNET.2015.07.004,2015-12-01,a,Neural Netw,neuromorphic implementations of neurobiological learning algorithms for spiking neural networks," The application of biologically inspired methods in design and control has a long tradition in robotics. Unlike previous approaches in this direction, the emerging field of neurorobotics not only mimics biological mechanisms at a relatively high level of abstraction but employs highly realistic simulations of actual biological nervous systems. Even today, carrying out these simulations efficiently at appropriate timescales is challenging. Neuromorphic chip designs specially tailored to this task therefore offer an interesting perspective for neurorobotics. Unlike Von Neumann CPUs, these chips cannot be simply programmed with a standard programming language. Like real brains, their functionality is determined by the structure of neural connectivity and synaptic efficacies. Enabling higher cognitive functions for neurorobotics consequently requires the application of neurobiological learning algorithms to adjust synaptic weights in a biologically plausible way. In this paper, we therefore investigate how to program neuromorphic chips by means of learning. First, we provide an overview over selected neuromorphic chip designs and analyze them in terms of neural computation, communication systems and software infrastructure. On the theoretical side, we review neurobiological learning techniques. Based on this overview, we then examine on-die implementations of these learning algorithms on the considered neuromorphic chips. A final discussion puts the findings of this work into context and highlights how neuromorphic hardware can potentially advance the field of autonomous robot systems. The paper thus gives an in-depth overview of neuromorphic implementations of basic mechanisms of synaptic plasticity which are required to realize advanced cognitive capabilities with spiking neural networks.",project-academic
10.1016/S0921-8890(96)00036-X,1996-11-01,a,North-Holland,application of evolved locomotion controllers to a hexapod robot," In previous work, we demonstrated that genetic algorithms could be used to evolve dynamical neural networks for controlling the locomotion of a simulated hexapod agent. We also demonstrated that these evolved controllers were robust to loss of sensory feedback and other peripheral variations. In this paper, we show that these locomotion controllers, evolved in simulation, are capable of directing the walking of a real six-legged robot, and that many of the desirable properties observed in simulation carry over directly to the real world. In addition, we demonstrate that these controllers are amenable to hardware implementation and can thus be easily embodied within the robot.",project-academic
10.3390/SU12125037,2020-06-01,a,MDPI AG,a sustainable deep learning framework for object recognition using multi layers deep features fusion and selection," With an overwhelming increase in the demand of autonomous systems, especially in the applications related to intelligent robotics and visual surveillance, come stringent accuracy requirements for complex object recognition. A system that maintains its performance against a change in the object’s nature is said to be sustainable and it has become a major area of research for the computer vision research community in the past few years. In this work, we present a sustainable deep learning architecture, which utilizes multi-layer deep features fusion and selection, for accurate object classification. The proposed approach comprises three steps: (1) By utilizing two deep learning architectures, Very Deep Convolutional Networks for Large-Scale Image Recognition and Inception V3, it extracts features based on transfer learning, (2) Fusion of all the extracted feature vectors is performed by means of a parallel maximum covariance approach, and (3) The best features are selected using Multi Logistic Regression controlled Entropy-Variances method. For verification of the robust selected features, the Ensemble Learning method named Subspace Discriminant Analysis is utilized as a fitness function. The experimental process is conducted using four publicly available datasets, including Caltech-101, Birds database, Butterflies database and CIFAR-100, and a ten-fold validation process which yields the best accuracies of 95.5%, 100%, 98%, and 68.80% for the datasets respectively. Based on the detailed statistical analysis and comparison with the existing methods, the proposed selection method gives significantly more accuracy. Moreover, the computational time of the proposed selection method is better for real-time implementation.",project-academic
10.1109/LRA.2018.2799741,2017-09-09,a,,how to train a cat learning canonical appearance transformations for direct visual localization under illumination change," Direct visual localization has recently enjoyed a resurgence in popularity with the increasing availability of cheap mobile computing power. The competitive accuracy and robustness of these algorithms compared to state-of-the-art feature-based methods, as well as their natural ability to yield dense maps, makes them an appealing choice for a variety of mobile robotics applications. However, direct methods remain brittle in the face of appearance change due to their underlying assumption of photometric consistency, which is commonly violated in practice. In this paper, we propose to mitigate this problem by training deep convolutional encoder-decoder models to transform images of a scene such that they correspond to a previously-seen canonical appearance. We validate our method in multiple environments and illumination conditions using high-fidelity synthetic RGB-D datasets, and integrate the trained models into a direct visual localization pipeline, yielding improvements in visual odometry (VO) accuracy through time-varying illumination conditions, as well as improved metric relocalization performance under illumination change, where conventional methods normally fail. We further provide a preliminary investigation of transfer learning from synthetic to real environments in a localization context. An open-source implementation of our method using PyTorch is available at this https URL.",project-academic
10.1016/J.NEUNET.2013.01.019,2013-11-01,a,Neural Netw,2013 special issue realtime cerebellum a large scale spiking network model of the cerebellum that runs in realtime using a graphics processing unit," The cerebellum plays an essential role in adaptive motor control. Once we are able to build a cerebellar model that runs in realtime, which means that a computer simulation of 1 s in the simulated world completes within 1 s in the real world, the cerebellar model could be used as a realtime adaptive neural controller for physical hardware such as humanoid robots. In this paper, we introduce ''Realtime Cerebellum (RC)'', a new implementation of our large-scale spiking network model of the cerebellum, which was originally built to study cerebellar mechanisms for simultaneous gain and timing control and acted as a general-purpose supervised learning machine of spatiotemporal information known as reservoir computing, on a graphics processing unit (GPU). Owing to the massive parallel computing capability of a GPU, RC runs in realtime, while reproducing qualitatively the same simulation results of the Pavlovian delay eyeblink conditioning with the previous version. RC is adopted as a realtime adaptive controller of a humanoid robot, which is instructed to learn a proper timing to swing a bat to hit a flying ball online. These results suggest that RC provides a means to apply the computational power of the cerebellum as a versatile supervised learning machine towards engineering applications.",project-academic
10.3390/MACHINES7020042,2019-06-14,a,Multidisciplinary Digital Publishing Institute,unmanned ground vehicle modelling in gazebo ros based environments," The fusion of different technologies is the base of the fourth industrial revolution. Companies are encouraged to integrate new tools in their production processes in order to improve working conditions and increase productivity and production quality. The integration between information, communication technologies and industrial automation can create highly flexible production models for products and services that can be customized through real-time interactions between consumer, production and machinery throughout the production process. The future of production, therefore, depends on increasingly intelligent machinery through the use of digital systems. The key elements for future integrated devices are intelligent systems and machines, based on human–machine interaction and information sharing. To do so, the implementation of shared languages that allow different systems to dialogue in a simple way is necessary. In this perspective, the use of advanced prototyping tools like Open-Source programming systems, the development of more detailed multibody models through the use of CAD software and the use of self-learning techniques will allow for developing a new class of machines capable of revolutionizing our companies. The purpose of this paper is to present a waypoint navigation activity of a custom Wheeled Mobile Robot (WMR) in an available simulated 3D indoor environment by using the Gazebo simulator. Gazebo was developed in 2002 at the University of Southern California. The idea was to create a high-fidelity simulator that gave the possibility to simulate robots in outdoor environments under various conditions. In particular, we wanted to test the high-performance physics Open Dynamics Engine (ODE) and the sensors feature present in Gazebo for prototype development activities. This choice was made for the possibility of emulating not only the system under analysis, but also the world in which the robot will operate. Furthermore, the integration tools available with Solidworks and Matlab-Simulink, well known commercial platforms of modelling and robotics control respectively, are also explored.",project-academic
,2009-02-04,,,synthesis experiment platform for electric energy quality and energy saving apparatuses," The invention provides a comprehensive experimental platform for a power quality and energy-saving equipment based on the thinking of an artificial intelligence robot. The comprehensive experimental platform adopts a high-power electronic interface device to replace the conventional power amplifier so as to improve the electrical parameters of the interface and at the same time, realize greater power handling capacity to solve the problem of performance restrictions of power amplifiers in digital-physical hybrid simulation. The platform is regarded as an intelligent robot, and the structure and the function of the platform are divided based on a perception unit, a planning unit and an implementation unit of the robot. The platform robot can plan the operation of the next step according to the perceived system information and then realize the planning through the implementation unit. The comprehensive experimental platform makes use of the repeatability in the experimental process and the self-learning ability of the platform robot, and adopts a successive approximation method of repeated experiments to enable the experimental process to eventually reach the required operating conditions. Finally, based on the parameters tallied with the experimental requirements, the comprehensive experimental platform analyzes the performances of the power quality equipment and completes the experimental process.",project-academic
10.1016/J.SFTR.2020.100023,2020-01-01,a,Elsevier,challenges opportunities and future directions of smart manufacturing a state of art review," Abstract None None Smart manufacturing is the technology utilizing the interconnected machines and tools for improving manufacturing performance and optimizing the energy and workforce required by the implementation of bigdata processing, artificial intelligence and advanced robotics technology and interconnectivity of them. This paper defines and discusses the smart manufacturing system and states it current implementation status and analyzes the gap between current manufacturing system and the predicted future smart manufacturing system, discusses the technologies associated with it and their contribution in smart manufacturing technology. Also, to realize this rapidly growing technology and cover its all dimensions a survey of the latest developments in this field and its impacts were analyzed and presented along with the challenges of implementation, opportunities and the future directions for smart manufacturing system.",project-academic
10.1109/TIE.2017.2764849,2018-05-01,a,IEEE,a vision aided approach to perching a bioinspired unmanned aerial vehicle," This paper presents the implementation of a machine learning approach for replicating highly adaptive avian perching behavior. With full consideration of both the configuration of flying vehicles and perching principles, a bioinspired aerial robot comprising one flight subsystem and one perching subsystem is designed. Based on the real-time landing speed and attitude, a novel type of soft grasping mechanism for dexterous perching is proposed to provide adhesive force and absorb impact force. During the critical perching phase, the dynamics of the perching actuator change with the touchdown conditions and the type of perching target. A hybrid automation of a time-to-contact theory-based attitude controller and a robust self-localization system are utilized to regulate the desired perching maneuvers. The experimental results are provided to attest to the effectiveness of the proposed perching method.",project-academic
10.1177/0278364907085097,2008-03-01,a,SAGE Publications,million module march scalable locomotion for large self reconfiguring robots," Self-reconfiguring robots have the potential to explore highly variable terrain, operating as parallel groups or combining to surmount large obstacles. If the modules are at a smaller scale, they may also be able to physically render arbitrary shapes in an interactive way. In order to realize these capabilities, groups with large numbers of modules must be used, and algorithms to control such large groups must be extremely scalable in order to be executed on simple modules. In this work, we present an algorithm for locomotion of lattice-based self-reconfiguring robots that uses constant memory per module with execution times that are sublinear in the number of modules. The algorithm is inspired by reinforcement learning and uses dynamic programming to plan module paths in parallel. We have also developed a novel localized cooperation scheme that allows the modules to move both without disconnecting the system and with small amounts of communication. The combined algorithm is able to direct locomotion over arbitrary obstacles, and due to continuous replanning the goal can be moved at any time to `joystick' the robot over the environment. The formulation of the goal used in the planning also encourages dynamic stability. We have developed both centralized and decentralized implementations in simulation, as well as an implementation for the Superbot system, and present empirical results showing the sublinear nature of our technique.",project-academic
,2005-03-11,b,,intelligent mobile robot navigation," Intelligent Mobile Robot Navigation builds upon the application of fuzzy logic to the area of intelligent control of mobile robots. Reactive, planned, and teleoperated techniques are considered, leading to the development of novel fuzzy control systems for perception and navigation of nonholonomic autonomous vehicles. The unique feature of this monograph lies in its comprehensive treatment of the problem, from the theoretical development of the various schemes down to the real-time implementation of algorithms on mobile robot prototypes. As such, the book spans different domains ranging from mobile robots to intelligent transportation systems, from automatic control to artificial intelligence.",project-academic
10.1109/ICRA48506.2021.9560951,2021-05-30,p,IEEE,navrep unsupervised representations for reinforcement learning of robot navigation in dynamic human environments," Robot navigation is a task where reinforcement learning approaches are still unable to compete with traditional path planning. State-of-the-art methods differ in small ways, and do not all provide reproducible, openly available implementations. This makes comparing methods a challenge. Recent research has shown that unsupervised learning methods can scale impressively, and be leveraged to solve difficult problems. In this work, we design ways in which unsupervised learning can be used to assist reinforcement learning for robot navigation. We train two end-to-end, and 18 unsupervised-learning-based architectures, and compare them, along with existing approaches, in unseen test cases. We demonstrate our approach working on a real life robot. Our results show that unsupervised learning methods are competitive with end-to-end methods. We also highlight the importance of various components such as input representation, predictive unsupervised learning, and latent features. We make all our models publicly available, as well as training and testing environments, and tools 1. This release also includes OpenAI-gym-compatible environments designed to emulate the training conditions described by other papers, with as much fidelity as possible. Our hope is that this helps in bringing together the field of RL for robot navigation, and allows meaningful comparisons across state-of-the-art methods.",project-academic
,2020-12-08,a,,navrep unsupervised representations for reinforcement learning of robot navigation in dynamic human environments," Robot navigation is a task where reinforcement learning approaches are still unable to compete with traditional path planning. State-of-the-art methods differ in small ways, and do not all provide reproducible, openly available implementations. This makes comparing methods a challenge. Recent research has shown that unsupervised learning methods can scale impressively, and be leveraged to solve difficult problems. In this work, we design ways in which unsupervised learning can be used to assist reinforcement learning for robot navigation. We train two end-to-end, and 18 unsupervised-learning-based architectures, and compare them, along with existing approaches, in unseen test cases. We demonstrate our approach working on a real life robot. Our results show that unsupervised learning methods are competitive with end-to-end methods. We also highlight the importance of various components such as input representation, predictive unsupervised learning, and latent features. We make all our models publicly available, as well as training and testing environments, and tools. This release also includes OpenAI-gym-compatible environments designed to emulate the training conditions described by other papers, with as much fidelity as possible. Our hope is that this helps in bringing together the field of RL for robot navigation, and allows meaningful comparisons across state-of-the-art methods.",project-academic
10.1109/3477.735392,1998-12-01,a,IEEE,a neuro fuzzy controller for mobile robot navigation and multirobot convoying," A Neural integrated Fuzzy conTroller (NiF-T) which integrates the fuzzy logic representation of human knowledge with the learning capability of neural networks is developed for nonlinear dynamic control problems. NiF-T architecture comprises of three distinct parts: (1) Fuzzy logic Membership Functions (FMF), (2) a Rule Neural Network (RNN), and (3) an Output-Refinement Neural Network (ORNN). FMF are utilized to fuzzify sensory inputs. RNN interpolates the fuzzy rule set; after defuzzification, the output is used to train ORNN. The weights of the ORNN can be adjusted on-line to fine-tune the controller. In this paper, real-time implementations of autonomous mobile robot navigation and multirobot convoying behavior utilizing the NiF-T are presented. Only five rules were used to train the wall following behavior, while nine were used for the hall centering. Also, a robot convoying behavior was realized with only nine rules. For all of the described behaviors-wall following, hall centering, and convoying, their RNN's are trained only for a few hundred iterations and so are their ORNN's trained for only less than one hundred iterations to learn their parent rule sets.",project-academic
10.1088/1748-3182/7/2/025009,2012-05-22,a,IOP Publishing,a biologically inspired meta control navigation system for the psikharpax rat robot," A biologically inspired navigation system for the mobile rat-like robot named Psikharpax is presented, allowing for self-localization and autonomous navigation in an initially unknown environment. The ability of parts of the model (e.g. the strategy selection mechanism) to reproduce rat behavioral data in various maze tasks has been validated before in simulations. But the capacity of the model to work on a real robot platform had not been tested. This paper presents our work on the implementation on the Psikharpax robot of two independent navigation strategies (a place-based planning strategy and a cue-guided taxon strategy) and a strategy selection meta-controller. We show how our robot can memorize which was the optimal strategy in each situation, by means of a reinforcement learning algorithm. Moreover, a context detector enables the controller to quickly adapt to changes in the environment—recognized as new contexts—and to restore previously acquired strategy preferences when a previously experienced context is recognized. This produces adaptivity closer to rat behavioral performance and constitutes a computational proposition of the role of the rat prefrontal cortex in strategy shifting. Moreover, such a brain-inspired meta-controller may provide an advancement for learning architectures in robotics.",project-academic
10.1109/ICCSCE.2015.7482163,2015-11-01,p,Institute of Electrical and Electronics Engineers Inc.,review on simultaneous localization and mapping slam," Simultaneous localization and mapping (SLAM) is a technique applied in artificial intelligence mobile robot for a self-exploration in numerous geographical environment. SLAM becomes fundamental research area in recent days as it promising solution in solving most of problems which related to the self-exploratory oriented artificial intelligence mobile robot field. For example, the capability to explore without any prior knowledge on environment it explores and without any human interference. The unique feature in SLAM is that the process of mapping and localization is done concurrently and recursively. Since SLAM introduction, many SLAM algorithms have been proposed to apply SLAM technique in real practice. The aim of this paper is to provide an insightful review on information background, recent development, feature, implementation and recent issue in SLAM.",project-academic
,2008-03-01,a,Institute of Electrical and Electronics Engineers,robotics software the future should be open," This column introduces a number of problem claims about the pitiful state of practice in software for robotics (and for all kinds of engineering domains in general). It also presents solution claims, whose realization can lead to a long-term, macroeconomically optimal solution, both for the industry and academia. Key problems in robotics software in the industrial and the academic practice are a chronic lack of standardization, interoperability and reuse of software libraries, both proprietary and open source. For example, we still have not standardized the Kalman filter or particle filter that everyone can and wants to use, and the same holds for many other mature robotics software components such as kinematics and dynamics, control laws, or planning algorithms. As a result, thousands of (Ph.D.) person months are lost worldwide every year in reimplementing these things for the zillionth time, without any new contribution to software reuse. This pitiful state of the practice is not unique to robotics, and only a few engineering domains do it right: numerical linear algebra (starting many decades ago already); the World Wide Web [with (X)HTML, cascading style sheets (CSS), scalable vector graphics (SVG), and other W3C standards as the fundamental enablers]; the Java middleware ecosystem [XML processing, open services gateway initiative (OSGi, now obsolete), Eclipse, mobile phone frameworks, etc.]; and tools around the Object Management Group (OMG) standards of UML, SysML, and modeldriven architecture. These examples are not tied to specific applications (this is not a coincidence but a very wise design decision about modularity and decoupling!), and they all have healthy commercial and open-source offerings, with real and rapid innovation taking place in both software development models. Every section in this article focuses on one of the fundamental issues that has led to the retarded state of software in robotics and suggests a concrete solution. Most neighboring scientific and technologic domains (computer vision, systems and control, cognitive science, artificial intelligence, etc.) suffer from exactly the same problems, such that cooperation with those domains can lead to faster implementation of the presented solutions.",project-academic
10.1109/ACIRS.2019.8936030,2019-07-13,p,IEEE,single bit per weight deep convolutional neural networks without batch normalization layers for embedded systems," Batch-normalization (BN) layers are thought to be an integrally important layer type in today’s state-of-the-art deep convolutional neural networks for computer vision tasks such as classification and detection. However, BN layers introduce complexity and computational overheads that are highly undesirable for training and/or inference on low-power custom hardware implementations of real-time embedded vision systems such as UAVs, robots and Internet of Things (IoT) devices. They are also problematic when batch sizes need to be very small during training, and innovations such as residual connections introduced more recently than BN layers could potentially have lessened their impact. In this paper we aim to quantify the benefits BN layers offer in image classification networks, in comparison with alternative choices. In particular, we study networks that use shifted-ReLU layers instead of BN layers. We found, following experiments with wide residual networks applied to the ImageNet, CIFAR 10 and CIFAR 100 image classification datasets, that BN layers do not consistently offer a significant advantage. We found that the accuracy margin offered by BN layers depends on the data set, the network size, and the bit-depth of weights. We conclude that in situations where BN layers are undesirable due to speed, memory or complexity costs, that using shifted-ReLU layers instead should be considered; we found they can offer advantages in all these areas, and often do not impose a significant accuracy cost.",project-academic
,2019-07-16,a,,single bit per weight deep convolutional neural networks without batch normalization layers for embedded systems," Batch-normalization (BN) layers are thought to be an integrally important layer type in today's state-of-the-art deep convolutional neural networks for computer vision tasks such as classification and detection. However, BN layers introduce complexity and computational overheads that are highly undesirable for training and/or inference on low-power custom hardware implementations of real-time embedded vision systems such as UAVs, robots and Internet of Things (IoT) devices. They are also problematic when batch sizes need to be very small during training, and innovations such as residual connections introduced more recently than BN layers could potentially have lessened their impact. In this paper we aim to quantify the benefits BN layers offer in image classification networks, in comparison with alternative choices. In particular, we study networks that use shifted-ReLU layers instead of BN layers. We found, following experiments with wide residual networks applied to the ImageNet, CIFAR 10 and CIFAR 100 image classification datasets, that BN layers do not consistently offer a significant advantage. We found that the accuracy margin offered by BN layers depends on the data set, the network size, and the bit-depth of weights. We conclude that in situations where BN layers are undesirable due to speed, memory or complexity costs, that using shifted-ReLU layers instead should be considered; we found they can offer advantages in all these areas, and often do not impose a significant accuracy cost.",project-academic
10.1016/J.ESWA.2017.11.011,2017-11-01,a,Pergamon,towards a common implementation of reinforcement learning for multiple robotic tasks," Abstract None None Mobile robots are increasingly being employed for performing complex tasks in dynamic environments. Those tasks can be either explicitly programmed by an engineer or learned by means of some automatic learning method, which improves the adaptability of the robot and reduces the effort of setting it up. In this sense, reinforcement learning (RL) methods are recognized as a promising tool for a machine to learn autonomously how to do tasks that are specified in a relatively simple manner. However, the dependency between these methods and the particular task to learn is a well-known problem that has strongly restricted practical implementations in robotics so far. Breaking this barrier would have a significant impact on these and other intelligent systems; in particular, having a core method that requires little tuning effort for being applicable to diverse tasks would boost their autonomy in learning and self-adaptation capabilities. In this paper we present such a practical core implementation of RL, which enables the learning process for multiple robotic tasks with minimal per-task tuning or none. Based on value iteration methods, we introduce a novel approach for action selection, called Q-biased softmax regression (QBIASSR), that takes advantage of the structure of the state space by attending the physical variables involved (e.g., distances to obstacles, robot pose, etc.), thus experienced sets of states accelerate the decision-making process of unexplored or rarely-explored states. Intensive experiments with both real and simulated robots, carried out with the software framework also introduced here, show that our implementation is able to learn different robotic tasks without tuning the learning method. They also suggest that the combination of true online SARSA(λ) (TOSL) with QBIASSR can outperform the existing RL core algorithms in low-dimensional robotic tasks. All of these are promising results towards the possibility of learning much more complex tasks autonomously by a robotic agent.",project-academic
10.1007/S11063-019-10076-Y,2020-02-01,a,Springer US,methodologies of compressing a stable performance convolutional neural networks in image classification," Deep learning has made a real revolution in the embedded computing environment. Convolutional neural network (CNN) revealed itself as a reliable fit to many emerging problems. The next step, is to enhance the CNN role in the embedded devices including both implementation details and performance. Resources needs of storage and computational ability are limited and constrained, resulting in key issues we have to consider in embedded devices. Compressing (i.e., quantizing) the CNN network is a valuable solution. In this paper, Our main goals are: memory compression and complexity reduction (both operations and cycles reduction) of CNNs, using methods (including quantization and pruning) that don’t require retraining (i.e., allowing us to exploit them in mobile system, or robots). Also, exploring further quantization techniques for further complexity reduction. To achieve these goals, we compress a CNN model layers (i.e., parameters and outputs) into suitable precision formats using several quantization methodologies. The methodologies are: First, we describe a pruning approach, which allows us to reduce the required storage and computation cycles in embedded devices. Such enhancement can drastically reduce the consumed power and the required resources. Second, a hybrid quantization approach with automatic tuning for the network compression. Third, a K-means quantization approach. With a minor degradation relative to the floating-point performance, the presented pruning and quantization methods are able to produce a stable performance fixed-point reduced networks. A precise fixed-point calculations for coefficients, input/output signals and accumulators are considered in the quantization process.",project-academic
10.1109/TII.2012.2205395,2012-06-20,a,IEEE,minimal resource allocating networks for discrete time sliding mode control of robotic manipulators," This paper presents a discrete-time sliding mode control based on neural networks designed for robotic manipulators. Radial basis function neural networks are used to learn about uncertainties affecting the system. The online learning algorithm combines the growing criterion and the pruning strategy of the minimal resource allocating network technique with an adaptive extended Kalman filter to update all the parameters of the networks. A method to improve the run-time performance for the real-time implementation of the learning algorithm has been considered. The analysis of the control stability is given and the controller is evaluated on the ERICC robot arm. Experiments show that the proposed controller produces good trajectory tracking performance and it is robust in the presence of model inaccuracies, disturbances and payload perturbations.",project-academic
,2007-01-06,p,Morgan Kaufmann Publishers Inc.,learning and multiagent reasoning for autonomous agents," One goal of Artificial Intelligence is to enable the creation of robust, fully autonomous agents that can coexist with us in the real world. Such agents will need to be able to learn, both in order to correct and circumvent their inevitable imperfections, and to keep up with a dynamically changing world. They will also need to be able to interact with one another, whether they share common goals, they pursue independent goals, or their goals are in direct conflict. This paper presents current research directions in machine learning, multiagent reasoning, and robotics, and advocates their unification within concrete application domains. Ideally, new theoretical results in each separate area will inform practical implementations while innovations from concrete multiagent applications will drive new theoretical pursuits, and together these synergistic research approaches will lead us towards the goal of fully autonomous agents.",project-academic
10.1109/LRA.2020.2965911,2020-01-07,p,Institute of Electrical and Electronics Engineers (IEEE),aggressive perception aware navigation using deep optical flow dynamics and pixelmpc," Recently, vision-based control has gained traction by leveraging the power of machine learning. In this work, we couple a model predictive control (MPC) framework to a visual pipeline. We introduce deep optical flow (DOF) dynamics, which is a combination of optical flow and robot dynamics. Using the DOF dynamics, MPC explicitly incorporates the predicted movement of relevant pixels into the planned trajectory of a robot. Our implementation of DOF is memory-efficient, data-efficient, and computationally cheap so that it can be computed in real-time for use in an MPC framework. The suggested Pixel Model Predictive Control (PixelMPC) algorithm controls the robot to accomplish a high-speed racing task while maintaining visibility of the important features (gates). This improves the reliability of vision-based estimators for localization and can eventually lead to safe autonomous flight. The proposed algorithm is tested in a photorealistic simulation with a high-speed drone racing task.",project-academic
,2020-01-07,a,,aggressive perception aware navigation using deep optical flow dynamics and pixelmpc," Recently, vision-based control has gained traction by leveraging the power of machine learning. In this work, we couple a model predictive control (MPC) framework to a visual pipeline. We introduce deep optical flow (DOF) dynamics, which is a combination of optical flow and robot dynamics. Using the DOF dynamics, MPC explicitly incorporates the predicted movement of relevant pixels into the planned trajectory of a robot. Our implementation of DOF is memory-efficient, data-efficient, and computationally cheap so that it can be computed in real-time for use in an MPC framework. The suggested Pixel Model Predictive Control (PixelMPC) algorithm controls the robot to accomplish a high-speed racing task while maintaining visibility of the important features (gates). This improves the reliability of vision-based estimators for localization and can eventually lead to safe autonomous flight. The proposed algorithm is tested in a photorealistic simulation with a high-speed drone racing task.",project-academic
10.1109/81.747195,1999-02-01,a,IEEE,reaction diffusion cnn algorithms to generate and control artificial locomotion," In this paper a physiological-behavioral approach to neural processing is used to realize artificial locomotion in mechatronic devices. The task has been realized by using a particular model of reaction-diffusion cellular neural networks (RD-CNN's) generating autowave fronts as well as Turing patterns. Moreover a programmable hardware cellular neural network structure is presented in order to model, generate, and control in real time some biorobots. The programmable hardware implementation gives the possibility of generating locomotion in real time and also to control the transition among several types of locomotion, with particular attention to hexapodes. The approach proposed allows not only the design of walking robots, but also the ability to build structures able to efficiently solve typical problems in industrial automation, such as online routing of objects moved on conveyor belts.",project-academic
,2019-12-13,a,,solving visual object ambiguities when pointing an unsupervised learning approach," Whenever we are addressing a specific object or refer to a certain spatial location, we are using referential or deictic gestures usually accompanied by some verbal description. Especially pointing gestures are necessary to dissolve ambiguities in a scene and they are of crucial importance when verbal communication may fail due to environmental conditions or when two persons simply do not speak the same language. With the currently increasing advances of humanoid robots and their future integration in domestic domains, the development of gesture interfaces complementing human-robot interaction scenarios is of substantial interest. The implementation of an intuitive gesture scenario is still challenging because both the pointing intention and the corresponding object have to be correctly recognized in real-time. The demand increases when considering pointing gestures in a cluttered environment, as is the case in households. Also, humans perform pointing in many different ways and those variations have to be captured. Research in this field often proposes a set of geometrical computations which do not scale well with the number of gestures and objects, use specific markers or a predefined set of pointing directions. In this paper, we propose an unsupervised learning approach to model the distribution of pointing gestures using a growing-when-required (GWR) network. We introduce an interaction scenario with a humanoid robot and define so-called ambiguity classes. Our implementation for the hand and object detection is independent of any markers or skeleton models, thus it can be easily reproduced. Our evaluation comparing a baseline computer vision approach with our GWR model shows that the pointing-object association is well learned even in cases of ambiguities resulting from close object proximity.",project-academic
10.1007/S00521-020-05109-W,2021-04-01,a,Springer London,solving visual object ambiguities when pointing an unsupervised learning approach," Whenever we are addressing a specific object or refer to a certain spatial location, we are using referential or deictic gestures usually accompanied by some verbal description. Particularly, pointing gestures are necessary to dissolve ambiguities in a scene and they are of crucial importance when verbal communication may fail due to environmental conditions or when two persons simply do not speak the same language. With the currently increasing advances of humanoid robots and their future integration in domestic domains, the development of gesture interfaces complementing human–robot interaction scenarios is of substantial interest. The implementation of an intuitive gesture scenario is still challenging because both the pointing intention and the corresponding object have to be correctly recognized in real time. The demand increases when considering pointing gestures in a cluttered environment, as is the case in households. Also, humans perform pointing in many different ways and those variations have to be captured. Research in this field often proposes a set of geometrical computations which do not scale well with the number of gestures and objects and use specific markers or a predefined set of pointing directions. In this paper, we propose an unsupervised learning approach to model the distribution of pointing gestures using a growing-when-required (GWR) network. We introduce an interaction scenario with a humanoid robot and define the so-called ambiguity classes. Our implementation for the hand and object detection is independent of any markers or skeleton models; thus, it can be easily reproduced. Our evaluation comparing a baseline computer vision approach with our GWR model shows that the pointing-object association is well learned even in cases of ambiguities resulting from close object proximity.",project-academic
10.1109/ROBOT.2002.1014331,2002-08-07,p,IEEE,self organized flocking with agent failure off line optimization and demonstration with real robots," This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",project-academic
10.1109/IROS40897.2019.8967642,2019-11-01,p,IEEE,sim to real learning for casualty detection from ground projected point cloud data," This paper addresses the problem of human body detection—particularly a human body lying on the ground (a.k.a. casualty)—using point cloud data. This ability to detect a casualty is one of the most important features of mobile rescue robots, in order for them to be able to operate autonomously. We propose a deep-learning-based casualty detection method using a deep convolutional neural network (CNN). This network is trained to be able to detect a casualty using a point-cloud data input. In the method we propose, the point cloud input is pre-processed to generate a depth image-like ground-projected heightmap. This heightmap is generated based on the projected distance of each point onto the detected ground plane within the point cloud data. The generated heightmap—in image form—is then used as an input for the CNN to detect a human body lying on the ground. To train the neural network, we propose a novel sim-to-real approach, in which the network model is trained using synthetic data obtained in simulation and then tested on real sensor data. To make the model transferable to real data implementations, during the training we adopt specific data augmentation strategies with the synthetic training data. The experimental results show that data augmentation introduced during the training process is essential for improving the performance of the trained model on real data. More specifically, the results demonstrate that the data augmentations on raw point-cloud data have contributed to a considerable improvement of the trained model performance.",project-academic
,2017-01-04,,,unmanned aerial vehicle transport airborne robot cargo express delivery device and implementation method," The invention discloses an unmanned aerial vehicle transport airborne robot cargo express delivery device and an implementation method. By making full use of modern network, artificial intelligence and modern aerial vehicle technology, a cargo express delivery system network operation platform receives network transaction orders of customers, cargoes and parcels, particularly fast food delivery, can be fast delivered to homes and handed over to the customers within the shortest time, the problem of 'last one-meter distance' of logistic express delivery is really solved, elder populations, residence populations, high-rise building office and living populations can be more effectively served by aerial vehicle transport, airborne delivery, robot operation, fast direct arrival, easiness, convenience and artificial intelligent delivery modes and programs, whenever and wherever possible consumption demands of people in outdoor places and even in the driving process can be met, and the fashion psychology of young people pursuing high-technology content and following trend is met.",project-academic
10.3389/FNINS.2016.00496,2016-11-02,a,Frontiers Media,benchmarking spike based visual recognition a dataset and evaluation," Today, increasing attention is being paid to research into spike-based neural computation both to gain a better understanding of the brain and to explore biologically-inspired computation. Within this field, the primate visual pathway and its hierarchical organisation have been extensively studied. Spiking Neural Networks (SNNs), inspired by the understanding of observed biological structure and function, have been successfully applied to visual recognition and classification tasks. In addition, implementations on neuromorphic hardware have enabled large-scale networks to run in (or even faster than) real time, making spike-based neural vision processing accessible on mobile robots. Neuromorphic sensors such as silicon retinas are able to feed such mobile systems with real-time visual stimuli. A new set of vision benchmarks for spike-based neural processing are now needed to measure progress quantitatively within this rapidly advancing field. We propose that a large dataset of spike-based visual stimuli is needed to provide meaningful comparisons between different systems, and a corresponding evaluation methodology is also required to measure the performance of SNN models and their hardware implementations. In this paper we first propose an initial NE (Neuromorphic Engineering) dataset based on standard computer vision benchmarks and that uses digits from the MNIST database. This dataset is compatible with the state of current research on spike-based image recognition. The corresponding spike trains are produced using a range of techniques: rate-based Poisson spike generation, rank order encoding, and recorded output from a silicon retina with both flashing and oscillating input stimuli. In addition, a complementary evaluation methodology is presented to assess both model-level and hardware-level performance. Finally, we demonstrate the use of the dataset and the evaluation methodology using two SNN models to validate the performance of the models and their hardware implementations. With this dataset we hope to (1) promote meaningful comparison between algorithms in the field of neural computation, (2) allow comparison with conventional image recognition methods, (3) provide an assessment of the state of the art in spike-based visual recognition, and (4) help researchers identify future directions and advance the field.",project-academic
10.1007/S00521-020-05515-0,2021-05-01,a,Springer Science and Business Media LLC,adaptive control of manipulator based on neural network," With the development of economic science and technology, the development of computer vision has undergone rapid changes, and various products relying on computer vision are also more and more, such as smart home, robot technology, and so on. At present, robot technology has become a very important part of the development of human science and technology, and in the field of industrial robots, the most rapid development is the robot with robot arm adaptive motion. It is very necessary to study the adaptive motion control of the manipulator based on machine learning. The robot with the adaptive motion of the manipulator can carry out logistics express sorting, operate in the doors and windows outside the building, and pick fruits in the orchard, which can ensure the effective implementation of hard work. Therefore, this paper proposes a mechanical adaptive control method based on a neural network. According to the motion model of the manipulator, the RBF neural network model is used to judge the stability of the system according to the Lyapunov function. The related algorithms of machine learning and multi-degree of freedom manipulator are studied and improved. The RBF neural network model approximates the unknown function infinitely and then establishes the complex motion model. Aiming at the adaptive neural network of a manipulator, a network adaptive terminal control method is proposed. Firstly, a stable manipulator motion system is designed by using a neural network, and then the terminal synovial controller is designed by using backstepping control technology. The stability of the method is proved by using the approximation virtual control technology of the neural network. The adaptive control is realized by using the learning and self-adaptability of the neural network; thus, the stability analysis of the closed-loop system is realized.",project-academic
,2017-01-31,a,,deep reinforcement learning for robotic manipulation the state of the art," The focus of this work is to enumerate the various approaches and algorithms that center around application of reinforcement learning in robotic ma- ]]nipulation tasks. Earlier methods utilized specialized policy representations and human demonstrations to constrict the policy. Such methods worked well with continuous state and policy space of robots but failed to come up with generalized policies. Subsequently, high dimensional non-linear function approximators like neural networks have been used to learn policies from scratch. Several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning. This has led to the emergence of a new branch of dynamic robot control system called deep r inforcement learning(DRL). This work embodies a survey of the most recent algorithms, architectures and their implementations in simulations and real world robotic platforms. The gamut of DRL architectures are partitioned into two different branches namely, discrete action space algorithms(DAS) and continuous action space algorithms(CAS). Further, the CAS algorithms are divided into stochastic continuous action space(SCAS) and deterministic continuous action space(DCAS) algorithms. Along with elucidating an organ- isation of the DRL algorithms this work also manifests some of the state of the art applications of these approaches in robotic manipulation tasks.",project-academic
10.3389/FNBOT.2014.00021,2014-07-25,a,Frontiers,operant conditioning a minimal components requirement in artificial spiking neurons designed for bio inspired robot s controller," In this paper, we investigate the operant conditioning (OC) learning process within a bio-inspired paradigm, using artificial spiking neural networks (ASNN) to act as robot brain controllers. In biological agents, OC results in behavioral changes learned from the consequences of previous actions, based on progressive prediction adjustment from rewarding or punishing signals. In a neurorobotics context, virtual and physical autonomous robots may benefit from a similar learning skill when facing unknown and unsupervised environments. In this work, we demonstrate that a simple invariant micro-circuit can sustain OC in multiple learning scenarios. The motivation for this new OC implementation model stems from the relatively complex alternatives that have been described in the computational literature and recent advances in neurobiology. Our elementary kernel includes only a few crucial neurons, synaptic links and originally from the integration of habituation and spike-timing dependent plasticity as learning rules. Using several tasks of incremental complexity, our results show that a minimal neural component set is sufficient to realize many OC procedures. Hence, with the proposed OC module, designing learning tasks with an ASNN and a bio-inspired robot context leads to simpler neural architectures for achieving complex behaviors.",project-academic
10.1109/ICRA.2016.7487661,2016-05-16,p,Institute of Electrical and Electronics Engineers (IEEE),model predictive control with stochastic collision avoidance using bayesian policy optimization," Robots are increasingly expected to move out of the controlled environment of research labs and into populated streets and workplaces. Collision avoidance in such cluttered and dynamic environments is of increasing importance as robots gain more autonomy. However, efficient avoidance is fundamentally difficult since computing safe trajectories may require considering both dynamics and uncertainty. While heuristics are often used in practice, we take a holistic stochastic trajectory optimization perspective that merges both collision avoidance and control. We examine dynamic obstacles moving without prior coordination, like pedestrians or vehicles. We find that common stochastic simplifications lead to poor approximations when obstacle behavior is difficult to predict. We instead compute efficient approximations by drawing upon techniques from machine learning. We propose to combine policy search with model-predictive control. This allows us to use recent fast constrained model-predictive control solvers, while gaining the stochastic properties of policy-based methods. We exploit recent advances in Bayesian optimization to efficiently solve the resulting probabilistically-constrained policy optimization problems. Finally, we present a real-time implementation of an obstacle avoiding controller for a quadcopter. We demonstrate the results in simulation as well as with real flight experiments.",project-academic
10.2147/MDER.S262590,2020-08-20,a,Informa UK Limited,conceptualising artificial intelligence as a digital healthcare innovation an introductory review," Artificial intelligence (AI) is widely recognised as a transformative innovation and is already proving capable of outperforming human clinicians in the diagnosis of specific medical conditions, especially in image analysis within dermatology and radiology. These abilities are enhanced by the capacity of AI systems to learn from patient records, genomic information and real-time patient data. Uses of AI range from integrating with robotics to creating training material for clinicians. Whilst AI research is mounting, less attention has been paid to the practical implications on healthcare services and potential barriers to implementation. AI is recognised as a ""Software as a Medical Device (SaMD)"" and is increasingly becoming a topic of interest for regulators. Unless the introduction of AI is carefully considered and gradual, there are risks of automation bias, overdependence and long-term staffing problems. This is in addition to already well-documented generic risks associated with AI, such as data privacy, algorithmic biases and corrigibility. AI is able to potentiate innovations which preceded it, using Internet of Things, digitisation of patient records and genetic data as data sources. These synergies are important in both realising the potential of AI and utilising the potential of the data. As machine learning systems begin to cross-examine an array of databases, we must ensure that clinicians retain autonomy over the diagnostic process and understand the algorithmic processes generating diagnoses. This review uses established management literature to explore artificial intelligence as a digital healthcare innovation and highlight potential risks and opportunities.",project-academic
10.1109/ISSCC.2011.5746250,2011-04-07,p,IEEE,a 57mw embedded mixed mode neuro fuzzy accelerator for intelligent multi core processor," Artificial intelligence (AI) functions are becoming important in smartphones, portable game consoles, and robots for such intelligent applications as object detection, recognition, and human-computer interfaces (HCI). Most of these functions are realized in software with neural networks (NN) and fuzzy systems (FS), but due to power and speed limitations, a hardware solution is needed. For example, software implementations of object-recognition algorithms like SIFT consume ∼10W and ∼1s delay even on a 2.4GHz PC CPU. Previously, GPGPUs or ASICs were used to realize AI functions [1–2]. But GPGPUs just emulate NN/FS with many processing elements to speed up the software, while still consuming a large amount of power. On the other hand, low-power ASICs have been mostly dedicated stand-alone processors, not suitable to be ported into many different systems [2].",project-academic
10.1016/J.ESWA.2019.05.035,2019-11-15,a,Pergamon,social mimic optimization algorithm and engineering applications," Abstract None None Increase in complexity of real world problems has provided an area to explore efficient methods to solve computer science problems. Meta-heuristic methods based on evolutionary computations and swarm intelligence are instances of techniques inspired by nature. This paper presents a novel social mimic optimization (SMO) algorithm inspired by mimicking behavior to solve optimization problems. The proposed algorithm is evaluated using 23 test functions. Obtained results are compared with 14 known optimization algorithms including Whale optimization algorithm (WOA), Grasshopper optimization algorithm (GOA), Particle Swarm Optimization (PSO), Stochastic fractal search (SFS), Grey Wolf Optimizer (GWO), Optics Inspired Optimization (OIO), League Championship Algorithm (LCA), Wind Driven Optimization (WDO), Harmony search (HS), Firefly Algorithm (FA), Artificial Bee Colony (ABC), Biogeography Based Optimization (BBO), Bat Algorithm (BA), and Teaching Learning Based Optimization (TLBO). Obtained results indicate higher capability of the SMO algorithm in solving high-dimensional decision variables. Furthermore, SMO is used to solve two classic engineering design problems. Three important features of SMO are simple implementation, solving optimization problems with minimum population size and not requiring control parameters. Results of various evaluations show superiority of the proposed method in finding the optimal solution with minimum function evaluations. This superiority is achieved based on reducing number of initial population. The proposed method can be applied to applications like automatic evolution of robotics, automatic control of machines and innovation of machines in finding better solutions with less cost.",project-academic
10.1080/08993400903525099,2010-04-07,a,Routledge,games and machine learning a powerful combination in an artificial intelligence course," Project MLeXAI (Machine Learning eXperiences in Artificial Intelligence (AI)) seeks to build a set of reusable course curriculum and hands on laboratory projects for the artificial intelligence classroom. In this article, we describe two game-based projects from the second phase of project MLeXAI: Robot Defense – a simple real-time strategy game and Checkers – a classic turn-based board game. From the instructors' prospective, we examine aspects of design and implementation as well as the challenges and rewards of using the curricula. We explore students' responses to the projects via the results of a common survey. Finally, we compare the student perceptions from the game-based projects to non-game based projects from the first phase of Project MLeXAI.",project-academic
10.3389/FROBT.2018.00025,2018-01-01,a,Frontiers Media SA,exploiting three dimensional gaze tracking for action recognition during bimanual manipulation to enhance human robot collaboration," Human-robot collaboration could be advanced by facilitating the intuitive, gaze-based control of robots, and enabling robots to recognize human actions, infer human intent, and plan actions that support human goals. Traditionally, gaze tracking approaches to action recognition have relied upon computer vision-based analyses of two-dimensional egocentric camera videos. The objective of this study was to identify useful features that can be extracted from three-dimensional (3D) gaze behavior and used as inputs to machine learning algorithms for human action recognition. We investigated human gaze behavior and gaze-object interactions in 3D during the performance of a bimanual, instrumental activity of daily living: the preparation of a powdered drink. A marker-based motion capture system and binocular eye tracker were used to reconstruct 3D gaze vectors and their intersection with 3D point clouds of objects being manipulated. Statistical analyses of gaze fixation duration and saccade size suggested that some actions (pouring and stirring) may require more visual attention than other actions (reach, pick up, set down, and move). 3D gaze saliency maps, generated with high spatial resolution for six subtasks, appeared to encode action-relevant information. The ""gaze object sequence"" was used to capture information about the identity of objects in concert with the temporal sequence in which the objects were visually regarded. Dynamic time warping barycentric averaging was used to create a population-based set of characteristic gaze object sequences that accounted for intra- and inter-subject variability. The gaze object sequence was used to demonstrate the feasibility of a simple action recognition algorithm that utilized a dynamic time warping Euclidean distance metric. Averaged over the six subtasks, the action recognition algorithm yielded an accuracy of 96.4%, precision of 89.5%, and recall of 89.2%. This level of performance suggests that the gaze object sequence is a promising feature for action recognition whose impact could be enhanced through the use of sophisticated machine learning classifiers and algorithmic improvements for real-time implementation. Robots capable of robust, real-time recognition of human actions during manipulation tasks could be used to improve quality of life in the home and quality of work in industrial environments.",project-academic
10.1016/J.ROBOT.2003.11.006,2004-02-29,a,North-Holland,a reinforcement learning with evolutionary state recruitment strategy for autonomous mobile robots control," Abstract None None In recent robotics fields, much attention has been focused on utilizing reinforcement learning (RL) for designing robot controllers, since environments where the robots will be situated in should be unpredictable for human designers in advance. However there exist some difficulties. One of them is well known as ‘curse of dimensionality problem’. Thus, in order to adopt RL for complicated systems, not only ‘adaptability’ but also ‘computational efficiencies’ should be taken into account. The paper proposes an adaptive state recruitment strategy for NGnet-based actor-critic RL. The strategy enables the learning system to rearrange/divide its state space gradually according to the task complexity and the progress of learning. Some simulation results and real robot implementations show the validity of the method.",project-academic
10.9746/SICETR1965.39.857,2003-09-30,a,The Society of Instrument and Control Engineers,a reinforcement learning with evolutionary state recruitment strategy for autonomous mobile robots control," Abstract None None In recent robotics fields, much attention has been focused on utilizing reinforcement learning (RL) for designing robot controllers, since environments where the robots will be situated in should be unpredictable for human designers in advance. However there exist some difficulties. One of them is well known as ‘curse of dimensionality problem’. Thus, in order to adopt RL for complicated systems, not only ‘adaptability’ but also ‘computational efficiencies’ should be taken into account. The paper proposes an adaptive state recruitment strategy for NGnet-based actor-critic RL. The strategy enables the learning system to rearrange/divide its state space gradually according to the task complexity and the progress of learning. Some simulation results and real robot implementations show the validity of the method.",project-academic
10.1109/SECON.2017.7925321,2017-03-01,p,,towards real time segmentation of 3d point cloud data into local planar regions," This article describes an algorithm for efficient segmentation of point cloud data into local planar surface regions. This is a problem of generic interest to researchers in the computer graphics, computer vision, artificial intelligence and robotics community where it plays an important role in applications such as object recognition, mapping, navigation and conversion from point clouds representations to 3D surface models. Prior work on the subject is either computationally burdensome, precluding real time applications such as robotic navigation and mapping, prone to error for noisy measurements commonly found at long range or requires availability of coregistered color imagery. The approach we describe consists of 3 steps: (1) detect a set of candidate planar surfaces, (2) cluster the planar surfaces merging redundant plane models, and (3) segment the point clouds by imposing a Markov Random Field (MRF) on the data and planar models and computing the Maximum A-Posteriori (MAP) of the segmentation labels using Bayesian Belief Propagation (BBP). In contrast to prior work which relies on color information for geometric segmentation, our implementation performs detection, clustering and estimation using only geometric data. Novelty is found in the fast clustering technique and new MRF clique potentials that are heretofore unexplored in the literature. The clustering procedure removes redundant detections of planes in the scene prior to segmentation using BBP optimization of the MRF to improve performance. The MRF clique potentials dynamically change to encourage distinct labels across depth discontinuities. These modifications provide improved segmentations for geometry-only depth images while simultaneously controlling the computational cost. Algorithm parameters are tunable to enable researchers to strike a compromise between segmentation detail and computational performance. Experimental results apply the algorithm to depth images from the NYU depth dataset which indicate that the algorithm can accurately extract large planar surfaces from depth sensor data.",project-academic
10.3390/S17030558,2017-03-10,a,Multidisciplinary Digital Publishing Institute,real time digital signal processing based on fpgas for electronic skin implementation," Enabling touch-sensing capability would help appliances understand interaction behaviors with their surroundings. Many recent studies are focusing on the development of electronic skin because of its necessity in various application domains, namely autonomous artificial intelligence (e.g., robots), biomedical instrumentation, and replacement prosthetic devices. An essential task of the electronic skin system is to locally process the tactile data and send structured information either to mimic human skin or to respond to the application demands. The electronic skin must be fabricated together with an embedded electronic system which has the role of acquiring the tactile data, processing, and extracting structured information. On the other hand, processing tactile data requires efficient methods to extract meaningful information from raw sensor data. Machine learning represents an effective method for data analysis in many domains: it has recently demonstrated its effectiveness in processing tactile sensor data. In this framework, this paper presents the implementation of digital signal processing based on FPGAs for tactile data processing. It provides the implementation of a tensorial kernel function for a machine learning approach. Implementation results are assessed by highlighting the FPGA resource utilization and power consumption. Results demonstrate the feasibility of the proposed implementation when real-time classification of input touch modalities are targeted.",project-academic
10.1016/J.ENGAPPAI.2007.01.003,2007-10-01,a,"Pergamon Press, Inc.",application of reinforcement learning in robot soccer," The robot soccer game has been proposed as a benchmark problem for the artificial intelligence and robotic researches. Decision-making system is the most important part of the robot soccer system. As the environment is dynamic and complex, one of the reinforcement learning (RL) method named FNN-RL is employed in learning the decision-making strategy. The FNN-RL system consists of the fuzzy neural network (FNN) and RL. RL is used for structure identification and parameters tuning of FNN. On the other hand, the curse of dimensionality problem of RL can be solved by the function approximation characteristics of FNN. Furthermore, the residual algorithm is used to calculate the gradient of the FNN-RL method in order to guarantee the convergence and rapidity of learning. The complex decision-making task is divided into multiple learning subtasks that include dynamic role assignment, action selection, and action implementation. They constitute a hierarchical learning system. We apply the proposed FNN-RL method to the soccer agents who attempt to learn each subtask at the various layers. The effectiveness of the proposed method is demonstrated by the simulation and the real experiments.",project-academic
10.1109/ICRA48506.2021.9561729,2021-05-30,p,IEEE,deep neuromorphic controller with dynamic topology for aerial robots," Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",project-academic
,2018-09-14,,,image identification method and system for electric power instrument," The invention discloses an image identification method and system for an electric power instrument. The method comprises the following implementation steps: obtaining a to-be-identified image, performing conv5 convolution operation on the to-be-identified image to obtain a characteristic pattern, generating a candidate region box set on the characteristic pattern based on a convolutional neural network, filtering aiming at the candidate region box set and performing target identification and localization on the candidate region box set based on the convolutional neural network to obtain an instrument region box in the image. The image identification system comprises computer equipment programmed to perform the steps of the image identification method for the electric power instrument. Theimage identification method and system disclosed by the invention have the benefits that based on the substation instrument equipment image acquired by a power robot, the automatic identification andlocalization of the instrument are realized by adopting a deep learning method, so that the localization of different types of instruments in a substation can be quickly and efficiently realized; a very important practical significance in the operation and the maintenance of the electric power equipment is realized.",project-academic
,2008-11-11,,,virtual game dealer based on artificial intelligence," Virtual game dealers based on artificial intelligence are described. In one implementation, an artificial intelligence (AI) engine tracks player attributes and game states of a given electronic game, such as a multiplayer electronic card game hosted by a virtual dealer. The virtual dealer may be embodied as a video, hologram, or robot. The AI engine selects speech and gestures for the virtual dealer based on the game states and player attributes. The player attributes may be retrieved from a player tracking system, from an identifier card carried by the player, and from machine perception of the player in real time. In one implementation, the AI engine determines emotions for the virtual dealer to portray, based on circumstances. Supported by the AI engine, the virtual dealer may personalize dialogue, provide information, and perform card and chip tricks. The AI engine may also animate a virtual player and select interactions between the virtual dealer and the virtual player based on game states and attributes of the human players.",project-academic
,2008-11-11,,,virtual game assistant based on artificial intelligence," Virtual game dealers based on artificial intelligence are described. In one implementation, an artificial intelligence (AI) engine tracks player attributes and game states of a given electronic game, such as a multiplayer electronic card game hosted by a virtual dealer. The virtual dealer may be embodied as a video, hologram, or robot. The AI engine selects speech and gestures for the virtual dealer based on the game states and player attributes. The player attributes may be retrieved from a player tracking system, from an identifier card carried by the player, and from machine perception of the player in real time. In one implementation, the AI engine determines emotions for the virtual dealer to portray, based on circumstances. Supported by the AI engine, the virtual dealer may personalize dialogue, provide information, and perform card and chip tricks. The AI engine may also animate a virtual player and select interactions between the virtual dealer and the virtual player based on game states and attributes of the human players.",project-academic
,2020-11-04,a,,asynchronous deep model reference adaptive control," In this paper, we present Asynchronous implementation of Deep Neural Network-based Model Reference Adaptive Control (DMRAC). We evaluate this new neuro-adaptive control architecture through flight tests on a small quadcopter. We demonstrate that a single DMRAC controller can handle significant nonlinearities due to severe system faults and deliberate wind disturbances while executing high-bandwidth attitude control. We also show that the architecture has long-term learning abilities across different flight regimes, and can generalize to fly different flight trajectories than those on which it was trained. These results demonstrating the efficacy of this architecture for high bandwidth closed-loop attitude control of unstable and nonlinear robots operating in adverse situations. To achieve these results, we designed a software+communication architecture to ensure online real-time inference of the deep network on a high-bandwidth computation-limited platform. We expect that this architecture will benefit other deep learning in the closed-loop experiments on robots.",project-academic
10.1109/ASAP.2018.8445099,2018-07-10,p,IEEE,towards hardware accelerated reinforcement learning for application specific robotic control," Reinforcement Learning (RL) is an area of machine learning in which an agent interacts with the environment by making sequential decisions. The agent receives reward from the environment based on how good the decisions are and tries to find an optimal decision-making policy that maximises its longterm cumulative reward. This paper presents a novel approach which has showon promise in applying accelerated simulation of RL policy training to automating the control of a real robot arm for specific applications. The approach has two steps. First, design space exploration techniques are developed to enhance performance of an FPGA accelerator for RL policy training based on Trust Region Policy Optimisation (TRPO), which results in a 43% speed improvement over a previous FPGA implementation, while achieving 4.65 times speed up against deep learning libraries running on GPU and 19.29 times speed up against CPU. Second, the trained RL policy is transferred to a real robot arm. Our experiments show that the trained arm can successfully reach to and pick up predefined objects, demonstrating the feasibility of our approach.",project-academic
10.1109/ICRA.2019.8794187,2019-05-20,p,IEEE,deep learning based motion prediction for exoskeleton robot control in upper limb rehabilitation," The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user’s motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user’s arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.",project-academic
10.1109/ISESD.2017.8253306,2017-10-01,p,IEEE,analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall following autonomous mobile robot," This paper presents a comparison of two methods of artificial intelligence which applied in Wallfollowing Autonomous Mobile Robot; both of them are Neural Network Backpropagationand Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wallfollowing Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural NetworkBackpropagation is faster than using Fuzzy Logic Controller.",project-academic
10.1109/IROS45743.2020.9341657,2020-10-24,p,IEEE,autonomous exploration under uncertainty via deep reinforcement learning on graphs," We consider an autonomous exploration problem in which a range-sensing mobile robot is tasked with accurately mapping the landmarks in an a priori unknown environment efficiently in real-time; it must choose sensing actions that both curb localization uncertainty and achieve information gain. For this problem, belief space planning methods that forward- simulate robot sensing and estimation may often fail in real-time implementation, scaling poorly with increasing size of the state, belief and action spaces. We propose a novel approach that uses graph neural networks (GNNs) in conjunction with deep reinforcement learning (DRL), enabling decision-making over graphs containing exploration information to predict a robot's optimal sensing action in belief space. The policy, which is trained in different random environments without human intervention, offers a real-time, scalable decision-making process whose high-performance exploratory sensing actions yield accurate maps and high rates of information gain.",project-academic
,2020-07-24,a,,autonomous exploration under uncertainty via deep reinforcement learning on graphs," We consider an autonomous exploration problem in which a range-sensing mobile robot is tasked with accurately mapping the landmarks in an a priori unknown environment efficiently in real-time; it must choose sensing actions that both curb localization uncertainty and achieve information gain. For this problem, belief space planning methods that forward-simulate robot sensing and estimation may often fail in real-time implementation, scaling poorly with increasing size of the state, belief and action spaces. We propose a novel approach that uses graph neural networks (GNNs) in conjunction with deep reinforcement learning (DRL), enabling decision-making over graphs containing exploration information to predict a robot's optimal sensing action in belief space. The policy, which is trained in different random environments without human intervention, offers a real-time, scalable decision-making process whose high-performance exploratory sensing actions yield accurate maps and high rates of information gain.",project-academic
10.1007/978-981-13-3549-5_6,2020-01-01,a,"Springer, Singapore",brain inspired perception motion and control," In this chapter, a possible solution for the future real implementation of brain-inspired perception (vision, audition and tactile), motion (the optimal path planning) and control (robots’ behavior management) is further presented. Based on the results from Chaps. 2– 5, a conceptual model is established to evaluate cognition efficiency of the vision–brain, taking danger recognition as an example. Based on the vision hypothesis, the underwater robots with a deep vision system—single-shot multibox detector (SSD)—can preliminarily link the robotic vision cognition module with the brain-inspired perception, motion and control. Such a deep vision system can also be utilized to further enhance the performance of planetary exploration wheeled mobile robot in Chap. 5 or other robots. Core functional modules for future rebuilding a real vision–brain, along with the major principles to implement a real brain cognition, are presented, which include memory, thinking, imagination, feeling, speaking and other aspects associated with visual perception. Realization of a vision–brain not only includes the fusion of sensors, but also includes the fusion of feature and knowledge. Deep robotic vision is strongly suggested to be introduced into the future advanced robotic control system. At the end of this chapter, the intelligence extremes of the vision–brain and the necessity for the avoidance of robots’ threatening to human are theoretically analyzed, and therefore, the necessity to set an up limit for the development of artificial intelligence is theoretically demonstrated.",project-academic
10.1007/S12559-017-9510-4,2018-04-01,a,Springer US,a primal neural network for online equality constrained quadratic programming," This paper aims at solving online equality-constrained quadratic programming problem, which is widely encountered in science and engineering, e.g., computer vision and pattern recognition, digital signal processing, and robotics. Recurrent neural networks such as conventional GradientNet and ZhangNet are considered as powerful solvers for such a problem in light of its high computational efficiency and capability of circuit realisation. In this paper, an improved primal recurrent neural network and its electronic implementation are proposed and analysed. Compared to the existing recurrent networks, i.e. GradientNet and ZhangNet, our network can theoretically guarantee superior global exponential convergence. Robustness performance of our such neural model is also analysed under a large model implementation error, with the upper bound of stead-state solution error estimated. Simulation results demonstrate theoretical analysis on the proposed model, which also verify the effectiveness of the proposed model for online equality-constrained quadratic programming.",project-academic
10.1109/IROS.2012.6385977,2012-12-24,p,IEEE,semi parametric gaussian process for robot system identification," One reason why control of biomimetic robots is so difficult is the fact that we do not have sufficiently accurate mathematical models of their system dynamics. Recent nonparametric machine learning approaches to system identification have shown good promise, outperforming parameterized mathematical models when applied to complex robot system identification problems. Unfortunately, non-parametric methods perform poorly when applied to regions of the state space that are not densely covered by the training dataset. This problem becomes particularly critical as the state space grows. Parametric methods use the available data very efficiently but, on the flip side, they only provide crude approximations to the actual system dynamics. In practice the systematic deviations between the parametric mathematical model and its physical realization results in control laws that do not take advantage of the compliance and complex dynamics of the robot. Here we present an approach to robot system identification, named Semi-Parametric Gaussian Processes (SGP), that elegantly combines the advantages of parametric and non-parametric approaches. Computer simulations and a physical implementation of an underactuated robot system identification problem show very promising results. We also demonstrate the applicability of SGP to articulated tree-structured robots of arbitrary complexity. In all experiments, SGP significantly out-performed previous parametric and non-parametric approaches as well as previous methods for combining the two approaches.",project-academic
10.1371/JOURNAL.PONE.0060599,2013-04-05,a,Public Library of Science,spiking neurons in a hierarchical self organizing map model can learn to develop spatial and temporal properties of entorhinal grid cells and hippocampal place cells," Medial entorhinal grid cells and hippocampal place cells provide neural correlates of spatial representation in the brain. A place cell typically fires whenever an animal is present in one or more spatial regions, or places, of an environment. A grid cell typically fires in multiple spatial regions that form a regular hexagonal grid structure extending throughout the environment. Different grid and place cells prefer spatially offset regions, with their firing fields increasing in size along the dorsoventral axes of the medial entorhinal cortex and hippocampus. The spacing between neighboring fields for a grid cell also increases along the dorsoventral axis. This article presents a neural model whose spiking neurons operate in a hierarchy of self-organizing maps, each obeying the same laws. This spiking GridPlaceMap model simulates how grid cells and place cells may develop. It responds to realistic rat navigational trajectories by learning grid cells with hexagonal grid firing fields of multiple spatial scales and place cells with one or more firing fields that match neurophysiological data about these cells and their development in juvenile rats. The place cells represent much larger spaces than the grid cells, which enable them to support navigational behaviors. Both self-organizing maps amplify and learn to categorize the most frequent and energetic co-occurrences of their inputs. The current results build upon a previous rate-based model of grid and place cell learning, and thus illustrate a general method for converting rate-based adaptive neural models, without the loss of any of their analog properties, into models whose cells obey spiking dynamics. New properties of the spiking GridPlaceMap model include the appearance of theta band modulation. The spiking model also opens a path for implementation in brain-emulating nanochips comprised of networks of noisy spiking neurons with multiple-level adaptive weights for controlling autonomous adaptive robots capable of spatial navigation.",project-academic
10.1016/J.MICPRO.2004.04.002,2004-11-02,a,Elsevier,control of a mobile robot using generalized dynamic fuzzy neural networks," Abstract None None This paper presents the design and implementation of a neural fuzzy controller suitable for real-time control of an autonomous mobile robot. The neural fuzzy controller is developed based on the Generalized Dynamic Fuzzy Neural Networks (GDFNN) learning algorithm of Wu et al. (IEEE Transactions on Fuzzy System 9 (4), 2001, 578–594). Not only the parameters of the controller can be optimized, but also the structure of the controller can be self-adaptive. Experimental results show that in comparison with a conventional fuzzy-logic-based controller, the proposed controller is superior in performance.",project-academic
10.3390/S21041526,2021-02-22,a,Multidisciplinary Digital Publishing Institute,danae a smart approach for denoising underwater attitude estimation," One of the main issues for the navigation of underwater robots consists in accurate vehicle positioning, which heavily depends on the orientation estimation phase. The systems employed to this end are affected by different noise typologies, mainly related to the sensors and to the irregular noise of the underwater environment. Filtering algorithms can reduce their effect if opportunely configured, but this process usually requires fine techniques and time. This paper presents DANAE++, an improved denoising autoencoder based on DANAE (deep Denoising AutoeNcoder for Attitude Estimation), which is able to recover Kalman Filter (KF) IMU/AHRS orientation estimations from any kind of noise, independently of its nature. This deep learning-based architecture already proved to be robust and reliable, but in its enhanced implementation significant improvements are obtained in terms of both results and performance. In fact, DANAE++ is able to denoise the three angles describing the attitude at the same time, and that is verified also using the estimations provided by an extended KF. Further tests could make this method suitable for real-time applications in navigation tasks.",project-academic
10.20944/PREPRINTS202101.0344.V1,2021-01-18,a,Preprints,danae a smart approach for denoising underwater attitude estimation," One of the main issues for the navigation of underwater robots consists in accurate vehicle positioning, which heavily depends on the orientation estimation phase. The systems employed to this end are affected by different noise typologies, mainly related to the sensors and to the irregular noise of the underwater environment. Filtering algorithms can reduce their effect if opportunely configured, but this process usually requires fine techniques and time. This paper presents DANAE++, an improved denoising autoencoder based on DANAE (deep Denoising AutoeNcoder for Attitude Estimation), which is able to recover Kalman Filter (KF) IMU/AHRS orientation estimations from any kind of noise, independently of its nature. This deep learning-based architecture already proved to be robust and reliable, but in its enhanced implementation significant improvements are obtained in terms of both results and performance. In fact, DANAE++ is able to denoise the three angles describing the attitude at the same time, and that is verified also using the estimations provided by an extended KF. Further tests could make this method suitable for real-time applications in navigation tasks.",project-academic
10.1109/HPCA51647.2021.00015,2021-02-01,p,IEEE,a computational stack for cross domain acceleration," Domain-specific accelerators obtain performance benefits by restricting their algorithmic domain. These accelerators utilize specialized languages constrained to particular hardware, thus trading off expressiveness for high performance. The pendulum has swung from one hardware for all domains (general-purpose processors) to one hardware per individual domain. The middle-ground on this spectrum–which provides a unified computational stack across multiple, but not all, domains– is an emerging and open research challenge. This paper sets out to explore this region and its associated tradeoff between expressiveness and performance by defining a cross-domain stack, dubbed PolyMath. This stack defines a high-level cross-domain language (CDL), called PMLang, that in a modular and reusable manner encapsulates mathematical properties to be expressive across multiple domains–Robotics, Graph Analytics, Digital Signal Processing, Deep Learning, and Data Analytics. PMLang is backed by a recursively-defined intermediate representation allowing simultaneous access to all levels of operation granularity, called sr DFG. Accelerator-specific or domain-specific IRs commonly capture operations in the granularity that best fits a set of Domain-Specific Architectures (DSAs). In contrast, the recursive nature of the sr DFG enables simultaneous access to all the granularities of computation for every operation, thus forming an ideal bridge for converting to various DSA-specific IRs across multiple domains. Our stack unlocks multi-acceleration for end-to-end applications that cross the boundary of multiple domains each comprising different data and compute patterns. Evaluations show that by using PolyMath it is possible to harness accelerators across the five domains to realize an average speedup of 3.3× over a Xeon CPU along with 18.1× reduction in energy. In comparison to Jetson Xavier and Titan XP, cross-domain acceleration offers 1.7× and 7.2× improvement in performance-per-watt, respectively. We measure the cross-domain expressiveness and performance tradeoff by comparing each benchmark against its hand-optimized implementation to achieve 83.9% and 76.8% of the optimal performance for single-domain algorithms and end-to-end applications. For the two case studies of end-to-end applications (comprising algorithms from multiple domains), results show that accelerating all kernels offers an additional 2.0× speedup over CPU, 6.1× improvement in performance-per-watt over Titan Xp, and 2.8× speedup over Jetson Xavier compared to only the one most effective single-domain kernel being accelerated. Finally, we examine the utility and expressiveness of PolyMath through a user study, which shows, on average, PolyMath requires 1.9× less time to implement algorithms from two different domains with 2.5× fewer lines of code relative to Python.",project-academic
10.1109/CDC40024.2019.9029973,2019-12-01,p,IEEE,active training trajectory generation for inverse dynamics model learning with deep neural networks," Inverse dynamics models have been used in robot control algorithms to realize a desired motion or to enhance a robot’s performance. As robot dynamics and their operating environments become more complex, there is a growing trend of learning uncertain or unknown dynamics from data. While techniques such as deep neural networks (DNNs) have been successfully used to learn inverse dynamics, it is usually implicitly assumed that the learning modules are trained on sufficiently rich datasets. In practical implementations, this assumption typically results in a trial-and-error training process, which can be inefficient or unsafe for robot applications. In this paper, we present an active trajectory generation framework that allows us to systematically design informative trajectories for training DNN inverse dynamics modules. In particular, we introduce an episode-based algorithm that integrates a spline trajectory optimization approach with DNN active learning for efficient data collection. We consider different DNN uncertainty estimation techniques and active learning heuristics in our work and illustrate the proposed active training trajectory generation approach in simulation. We show that the proposed active training trajectory generation outperforms adhoc, intuitive training approaches.",project-academic
10.2514/6.2019-1703,2019-01-07,p,American Institute of Aeronautics and Astronautics,structural material property tailoring using deep neural networks," Advances in robotics, artificial intelligence, and machine learning are ushering in a new age of automation, as machines match or outperform human performance. Machine intelligence can enable businesses to improve performance by reducing errors, improving sensitivity, quality and speed, and in some cases achieving outcomes that go beyond current resource capabilities. Relevant applications include new product architecture design, rapid material characterization, and life-cycle management tied with a digital strategy that will enable efficient development of products from cradle to grave. In addition, there are also challenges to overcome that must be addressed through a major, sustained research effort that is based solidly on both inferential and computational principles applied to design tailoring of functionally optimized structures. Current applications of structural materials in the aerospace industry demand the highest quality control of material microstructure, especially for advanced rotational turbomachinery in aircraft engines in order to have the best tailored material property. In this paper, deep convolutional neural networks were developed to accurately predict processing-structure-property relations from materials microstructures images, surpassing current best practices and modeling efforts. The models automatically learn critical features, without the need for manual specification and/or subjective and expensive image analysis. Further, in combination with generative deep learning models, a framework is proposed to enable rapid material design space exploration and property identification and optimization. The implementation must take account of real-time decision cycles and the trade-offs between speed and accuracy.",project-academic
,2019-01-29,a,,structural material property tailoring using deep neural networks," Advances in robotics, artificial intelligence, and machine learning are ushering in a new age of automation, as machines match or outperform human performance. Machine intelligence can enable businesses to improve performance by reducing errors, improving sensitivity, quality and speed, and in some cases achieving outcomes that go beyond current resource capabilities. Relevant applications include new product architecture design, rapid material characterization, and life-cycle management tied with a digital strategy that will enable efficient development of products from cradle to grave. In addition, there are also challenges to overcome that must be addressed through a major, sustained research effort that is based solidly on both inferential and computational principles applied to design tailoring of functionally optimized structures. Current applications of structural materials in the aerospace industry demand the highest quality control of material microstructure, especially for advanced rotational turbomachinery in aircraft engines in order to have the best tailored material property. In this paper, deep convolutional neural networks were developed to accurately predict processing-structure-property relations from materials microstructures images, surpassing current best practices and modeling efforts. The models automatically learn critical features, without the need for manual specification and/or subjective and expensive image analysis. Further, in combination with generative deep learning models, a framework is proposed to enable rapid material design space exploration and property identification and optimization. The implementation must take account of real-time decision cycles and the trade-offs between speed and accuracy.",project-academic
10.1016/J.ESWA.2008.06.040,2009-04-01,a,"Pergamon Press, Inc.",motion planning in order to optimize the length and clearance applying a hopfield neural network," This paper deals with motion planning in plane for a mobile robot with two freedom degrees through some polygonal unmoved obstacles. Applying Minkowski sum, we can represent the robot as a point. Then, by using traditional approaches such as visibility graphs, simple and generalized Voronoi diagrams, decomposition methods, etc, it is possible to provide a graph covering obstacles, say roadmap. In order to find a real-time collision-free robot motion planning between two arbitrary source and target configurations through the roadmap, an adoptive Hopfield neural network is considered. Maximizing the clearance of path together with minimizing the length of path are pursued in a bi-objective framework. For treating with multiple objectives TOPSIS method, as a kind of goal programming techniques, is provided to find the efficient solutions. Because of capability of parallel computation through hardware implementation of neural networks, the presented approach is a reasonable technique in mobile robot navigation and traveler guidance systems. The advantages of the proposed system are confirmed by simulation experiments. This approach can be directly extended in unknown environment including time-varying conditions.",project-academic
10.1145/3377930.3390217,2020-06-25,p,ACM,scaling map elites to deep neuroevolution," Quality-Diversity (QD) algorithms, and MAP-Elites (ME) in particular, have proven very useful for a broad range of applications including enabling real robots to recover quickly from joint damage, solving strongly deceptive maze tasks or evolving robot morphologies to discover new gaits. However, present implementations of ME and other QD algorithms seem to be limited to low-dimensional controllers with far fewer parameters than modern deep neural network models. In this paper, we propose to leverage the efficiency of Evolution Strategies (ES) to scale MAP-Elites to high-dimensional controllers parameterized by large neural networks. We design and evaluate a new hybrid algorithm called MAP-Elites with Evolution Strategies (ME-ES) for post-damage recovery in a difficult high-dimensional control task where traditional ME fails. Additionally, we show that ME-ES performs efficient exploration, on par with state-of-the-art exploration algorithms in high-dimensional control tasks with strongly deceptive rewards.",project-academic
10.1109/TSMC.2020.2967936,2020-02-10,a,IEEE,deep q learning with q matrix transfer learning for novel fire evacuation environment," Deep reinforcement learning (RL) is achieving significant success in various applications like control, robotics, games, resource management, and scheduling. However, the important problem of emergency evacuation, which clearly could benefit from RL, has been largely unaddressed. Indeed, emergency evacuation is a complex task that is difficult to solve with RL. An emergency situation is highly dynamic, with a lot of changing variables and complex constraints that make it challenging to solve. Also, there is no standard benchmark environment available that can be used to train RL agents for evacuation. A realistic environment can be complex to design. In this article, we propose the first fire evacuation environment to train RL agents for evacuation planning. The environment is modeled as a graph capturing the building structure. It consists of realistic features like fire spread, uncertainty, and bottlenecks. The implementation of our environment is in the OpenAI gym format, to facilitate future research. We also propose a new RL approach that entails pretraining the network weights of a DQN-based agent [DQN/Double-DQN (DDQN)/Dueling-DQN] to incorporate information on the shortest path to the exit. We achieved this by using tabular Q-learning to learn the shortest path on the building model's graph. This information is transferred to the network by deliberately overfitting it on the Q-matrix. Then, the pretrained DQN model is trained on the fire evacuation environment to generate the optimal evacuation path under time varying conditions due to fire spread, bottlenecks, and uncertainty. We perform comparisons of the proposed approach with state-of-the-art RL algorithms like DQN, DDQN, Dueling-DQN, PPO, VPG, state-action-reward-state-action (SARSA), actor-critic method, and ACKTR. The results show that our method is able to outperform state-of-the-art models by a huge margin including the original DQN-based models. Finally, our model is tested on a large and complex real building consisting of 91 rooms, with the possibility to move to any other room, hence giving 8281 actions. In order to reduce the action space, we propose a strategy that involves one step simulation. That is, an action importance vector is added to the final output of the pretrained DQN and acts like an attention mechanism. Using this strategy, the action space is reduced by 90.1%. In this manner, the model is able to deal with large action spaces. Hence, our model achieves near optimal performance on the real world emergency environment.",project-academic
,2019-01-18,,,an underwater vehicle motion planning method based on multi constrained objectives," The invention relates to an underwater vehicle motion planning method based on multi-constrained objects, belonging to the field of machine learning and underwater vehicle motion planning. In the phase of modeling, the signal of robot obstacle avoidance sonar and the velocity signal of velocity sensor are transformed into the current environment. According to the dynamic constraint, the discrete motion space is established. The reward function is established under the constraint of the underwater obstacle. Markov decision-making process is established based on multi-objective constraints, which establishes the basis for the algorithm implementation. Training phase: Q learning algorithm-based training, in the current environment, based on greedy strategy to execute action, each step of theimplementation of the strategy, based on the original strategy to evaluate and update the strategy, improve the strategy until adapted to the environment, to achieve the planning purpose. The invention considers multiple constraint targets such as water flow, navigation object and target, combines the reinforcement learning method with the underwater multiple constraint targets, realizes the motion planning of the underwater robot, has strong real-time performance, and can be applied to multiple environments.",project-academic
10.1109/BIOROB.2014.6913811,2014-10-02,p,IEEE,eeg based classification of upper limb adl using snn for active robotic rehabilitation," Repetitive activities of daily living (ADL) and robotic active training are commonly practised in the rehabilitation of paralyzed patients, both of which have been proven rather effective to recover the locomotor function of impaired limbs. ADL classification based on electroencephalogram (EEG) is of great significance to perform active robotic rehabilitation for patients with complete spinal cord injury (SCI) who lose locomotion of affected limbs absolutely, where surface electromyography (sEMG) or active force signal can hardly be detected. It is a challenge to achieve a satisfying result in neuro-rehabilitation robotics using EEG signals due to the high randomness of the EEG data. A classification method is proposed based on spiking neural networks (SNN) to identify the upper-limb ADL of three classes with 14-channel EEG data. The continuous real-number signals are firstly encoded into spike trains through Ben's Spike Algorithm (BSA). The generated spikes are then submitted into a 3-D brain-mapped SNN reservoir called NeuCube trained by Spike Timing Dependant Plasticity (STDP). Spike trains from all neurons of the trained reservoir are finally classified using one version of dynamic evolving spiking neuron networks (deSNN) — deSNNs. Classifications are presented with and without NeuCube respectively on the same EEG data set. Results indicate that using the reservoir improves identification accuracy which turns out pretty promising despite that EEG data is highly noisy, low frequently sampled, and only from 14 channels. The classification technique reveals a great potential for the further implementation of active robotic rehabilitation to the sufferers of complete SCI.",project-academic
10.1109/SBR-LARS-R.2017.8215337,2017-11-01,p,IEEE,cognitive and robotic systems speeding up integration and results," Nowadays, state-of-the-art robots are capable of millimetric motion accuracy by performing highly repetitive tasks, however, as a constraint they operate in highly structured environments where objects are in known and predictable locations. Thus, it is not surprising that robots are more often used in high-volume operations such as painting and welding, rather than operations where diversity of actions, direct contact with humans, and variability of the environment meet fundamental requirements. Social robotics is an area of research that aims to make viable the direct interaction of robots with humans in unstructured environments. It uses several techniques, such as, machine learning, cognitive modeling, artificial intelligence, knowledge representation and ontology. One factor that compromises the rapid evolution of social robotics is the difficulty in modeling cognitive systems due to the volume and complexity of information produced by a chaotic world full of sensory information. In addition, the validation of results with the use of real environments involving buildings, streets and people presents a high cost of installation and maintenance. This article offers two strategies to speed up the evolution of social robotics. The first involves the definition of OntCog ontology that models the senses captured by the agent robotic sensors. This modeling facilitates the reproduction of experiments associated with cognitive models and the comparison among different implementations. The second is associated with the development of Robot House Simulator (RHS), which provides an environment where a robot and a human character can interact socially with increasing levels of cognitive processing. An unprecedented feature of this simulator is to provide information about all the senses of the robot, actually only the sense of vision or touch has been considered in the existing robotic simulators.",project-academic
10.1075/AIS.2,2011-12-21,b,John Benjamins Publishing Company,new frontiers in human robot interaction," HumanRobot Interaction (HRI) considers how people can interact with robots in order to enable robots to best interact with people. HRI presents many challenges with solutions requiring a unique combination of skills from many fields, including computer science, artificial intelligence, social sciences, ethology and engineering. We have specifically aimed this work to appeal to such a multi-disciplinary audience. This volume presents new and exciting material from HRI researchers who discuss research at the frontiers of HRI. The chapters address the human aspects of interaction, such as how a robot may understand, provide feedback and act as a social being in interaction with a human, to experimental studies and field implementations of humanrobot collaboration ranging from joint action, robots practically and safely helping people in real world situations, robots helping people via rehabilitation and robots acquiring concepts from communication. This volume reflects current trends in this exciting research field.",project-academic
10.1109/TRO.2004.829480,2004-08-01,a,IEEE,improving efficiency in mobile robot task planning through world abstraction," Task planning in mobile robotics should be performed efficiently, due to real-time requirements of robot-environment interaction. Its computational efficiency depends both on the number of operators (actions the robot can perform without planning) and the size of the world states (descriptions of the world before and after the application of operators). Thus, in real robotic applications, where both components can be large, planning may turn inefficient, and even unsolvable. In the artificial intelligence (AI) literature on planning, little attention has been put into efficient management of large-scale world descriptions. In real large-scale situations, conventional AI planners (in spite of the most modern improvements) may consume intractable amounts of storage and computing time, due to the huge amount of information. This paper proposes a new approach to task planning called ""hierarchical task planning through world abstraction"" that, by hierarchically arranging the world representation, becomes a good complement of Stanford Research Institute Problem Solver-style planners, significantly improving their computational efficiency. Broadly speaking, our approach works by first solving the task-planning problem in a highly abstracted model of the environment of the robot, and then refines the solution under more detailed models, where irrelevant world elements can be ignored, due to the results previously obtained at abstracted levels. Among the different implementations that can be made with our general strategy, we describe two that use a graph-based hierarchical world representation named the ""annotated and hierarchical"" graph. We show experiments, as well as results of a mobile robot operating in a large-scale environment, that demonstrate an important improvement in the efficiency of our algorithms with respect to conventional (both hierarchical and nonhierarchical) planning and their nice integration with existing planners.",project-academic
10.1109/3477.499796,1996-06-01,a,IEEE,hidden state and reinforcement learning with instance based state identification," Real robots with real sensors are not omniscient. When a robot's next course of action depends on information that is hidden from the sensors because of problems such as occlusion, restricted range, bounded field of view and limited attention, we say the robot suffers from the hidden state problem. State identification techniques use history information to uncover hidden state. Some previous approaches to encoding history include: finite state machines, recurrent neural networks and genetic programming with indexed memory. A chief disadvantage of all these techniques is their long training time. This paper presents instance-based state identification, a new approach to reinforcement learning with state identification that learns with much fewer training steps. Noting that learning with history and learning in continuous spaces both share the property that they begin without knowing the granularity of the state space, the approach applies instance-based (or ""memory-based"") learning to history sequences-instead of recording instances in a continuous geometrical space, we record instances in action-percept-reward sequence space. The first implementation of this approach, called Nearest Sequence Memory, learns with an order of magnitude fewer steps than several previous approaches.",project-academic
10.3390/S21082689,2021-04-11,a,Multidisciplinary Digital Publishing Institute,soft grippers for automatic crop harvesting a review," Agriculture 4.0 is transforming farming livelihoods thanks to the development and adoption of technologies such as artificial intelligence, the Internet of Things and robotics, traditionally used in other productive sectors. Soft robotics and soft grippers in particular are promising approaches to lead to new solutions in this field due to the need to meet hygiene and manipulation requirements in unstructured environments and in operation with delicate products. This review aims to provide an in-depth look at soft end-effectors for agricultural applications, with a special emphasis on robotic harvesting. To that end, the current state of automatic picking tasks for several crops is analysed, identifying which of them lack automatic solutions, and which methods are commonly used based on the botanical characteristics of the fruits. The latest advances in the design and implementation of soft grippers are also presented and discussed, studying the properties of their materials, their manufacturing processes, the gripping technologies and the proposed control methods. Finally, the challenges that have to be overcome to boost its definitive implementation in the real world are highlighted. Therefore, this review intends to serve as a guide for those researchers working in the field of soft robotics for Agriculture 4.0, and more specifically, in the design of soft grippers for fruit harvesting robots.",project-academic
10.1016/J.PROMFG.2020.01.168,2019-01-01,a,Elsevier BV,robot assisted concept for assembling form coils in laminated stator cores of large electric motors," Abstract None None Manufacturers of large electric motors, whether for automation or traction purposes, are facing major challenges in high-wage countries. Due to the high proportion of manual activities, a conflict between ensuring profitability and increasing variant variety arises. In order to meet the high demand for large electric motors and to maintain the value added in high-wage countries, manual manufacturing processes must be automated, at least partially. For large electric motors with form coil technology, especially the assembly into the laminated stator core represents a tedious, cost-intensive manual activity. Therefore, this paper deals with the development of a hybrid, robot-assisted assembly system for inserting form coils in laminated stator cores. The combination of manual and automated assembly activities is intended to ensure high productivity while maintaining flexibility. Before realizing such a hybrid assembly system, all process steps are simulated first. In addition, additive manufacturing is used to quickly produce and practically validate different end effector geometries. As shown by the final prototypical implementation, a major portion of the assembly of form coils can be carried out fully automatically by a dual-arm robot. Remaining challenges could be addressed by adding a vision system and thereby making use of novel machine learning techniques.",project-academic
10.5772/5760,2006-03-01,a,SAGE Publications,design and implementation of modular software for programming mobile robots," This article describes a software development toolkit for programming mobile robots, that has been used on different platforms and for different robotic applications. We address design choices, implementation issues and results in the realization of our robot programming environment, that has been devised and built from many people since 1998. We believe that the proposed framework is extremely useful not only for experienced robotic Research on developing autonomous agents, and in particular mobile robots, has been carried out within the field of Artificial Intelligence and Robotics from many different perspectives and for several different kinds of applications, and the development of robotic applications is receiving increasing attention in many laboratories. Moreover, robotic competitions (e.g. AAAI contexts, RoboCup, etc.) have encouraged researchers to develop effective robotic systems with a predefined goal (e.g. playing soccer, searching victims in a disaster scenario, etc.). Moreover, mobile robots are also used for teaching purposes within computer science laboratories and often students are required to work and develop robotic applications on them 1 . This increasing population of robots in the research laboratories and the consequent need for developing robotic applications have started a process of design and implementation of robotic software, that aims at having a design methodology and a software engineering approach in the development of such applications. Furthermore, companies producing and selling mobile robots make available to their users development libraries and software tools for building and debugging robotic applications (e.g., Saphira/ARIA for Pioneer robots (Konolige et al., 1997), OPEN-R SDK for Sony AIBO2, etc.). These tools are obviously platform dependent and thus they cannot easily be used for building multi-platform robotic systems. Moreover, they usually lack some features that are required from a general purpose robot development toolkit. For instance, the OPEN-R SDK completely lacks facilities for remote",project-academic
10.1109/MED48518.2020.9183337,2020-09-01,p,IEEE,unsupervised learning for subterranean junction recognition based on 2d point cloud," This article proposes a novel unsupervised learning framework for detecting the number of tunnel junctions in subterranean environments based on acquired 2D point clouds. The implementation of the framework provides valuable information for high level mission planners to navigate an aerial platform in unknown areas or robot homing missions. The framework utilizes spectral clustering, which is capable of uncovering hidden structures from connected data points lying on non-linear manifolds. The spectral clustering algorithm computes a spectral embedding of the original 2D point cloud by utilizing the eigen decomposition of a matrix that is derived from the pairwise similarities of these points. We validate the developed framework using multiple data-sets, collected from multiple realistic simulations, as well as from real flights in underground environments, demonstrating the performance and merits of the proposed methodology.",project-academic
10.1108/01439910510629136,2005-12-01,a,Emerald Group Publishing Limited,scalpel please robot penelope s debut in the operating room," Purpose – Aims to demonstrate how robot technology, machine vision, voice recognition and artificial intelligence can be applied to creating an automated surgeon's assistant that is functional and cost‐effective.Design/methodology/approach – Presents the development process that led to the construction of the Penelope Surgical Instrument Server (SIS), outlines the mechanical design of the robot, describes the control strategy and reports on the first real live implementation in an operating room. Machine vision, voice recognition and artificial intelligence are combined to create a robot assistant that is able to anticipate a specific surgeon's needs for a specific surgical procedure.Findings – Finds that a robot can manage an array of surgical instruments and present the right one to the surgeon at the right time.Practical implications – A robot for assisting a surgeon can relieve support staff in hospital operating rooms of repetitive tasks and thereby improve patient care.Originality/value – Introduces...",project-academic
,2020-08-17,a,,learning to actively reduce memory requirements for robot control tasks," Robots equipped with rich sensing modalities (e.g., RGB-D cameras) performing long-horizon tasks motivate the need for policies that are highly memory-efficient. State-of-the-art approaches for controlling robots often use memory representations that are excessively rich for the task or rely on hand-crafted tricks for memory efficiency. Instead, this work provides a general approach for jointly synthesizing memory representations and policies; the resulting policies actively seek to reduce memory requirements. Specifically, we present a reinforcement learning framework that leverages an implementation of the group LASSO regularization to synthesize policies that employ low-dimensional and task-centric memory representations. We demonstrate the efficacy of our approach with simulated examples including navigation in discrete and continuous spaces as well as vision-based indoor navigation set in a photo-realistic simulator. The results on these examples indicate that our method is capable of finding policies that rely only on low-dimensional memory representations, improving generalization, and actively reducing memory requirements.",project-academic
10.1016/J.ROBOT.2003.11.002,2004-03-31,a,North-Holland,maze exploration behaviors using an integrated evolutionary robotics environment," This paper presents results generated with a new evolutionary robotics (ER) simulation environment and its complementary real mobile robot colony research test-bed. Neural controllers producing mobile robot maze searching and exploration behaviors using binary tactile sensors as inputs were evolved in a simulated environment and subsequently transferred to and tested on real robots in a physical environment. There has been a considerable amount of proof-of-concept and demonstration research done in the field of ER control in recent years, most of which has focused on elementary behaviors such as object avoidance and homing. Artificial neural networks (ANN) are the most commonly used evolvable controller paradigm found in current ER literature. Much of the research reported to date has been restricted to the implementation of very simple behaviors using small ANN controllers. In order to move beyond the proof-of-concept stage our ER research was designed to train larger more complicated ANN controllers, and to implement those controllers on real robots quickly and efficiently. To achieve this a physical robot test-bed that includes a colony of eight real robots with advanced computing and communication abilities was designed and built. The real robot platform has been coupled to a simulation environment that facilitates the direct wireless transfer of evolved neural controllers from simulation to real robots (and vice versa). We believe that it is the simultaneous development of ER computing systems in both the simulated and the physical worlds that will produce advances in mobile robot colony research. Our simulation and training environment development focuses on the definition and training of our new class of ANNs, networks that include multiple hidden layers, and time-delayed and recurrent connections. Our physical mobile robot design focuses on maximizing computing and communications power while minimizing robot size, weight, and energy usage. The simulation and ANN-evolution environment was developed using MATLAB. To allow for efficient control software portability our physical evolutionary robots (EvBots) are equipped with a PC-104-based computer running a custom distribution of Linux and connected to the Internet via a wireless network connection. In addition to other high-level computing applications, the mobile robots run a condensed version of MATLAB, enabling ANN controllers evolved in simulation to be transferred directly onto physical robots without any alteration to the code. This is the first paper in a series to be published cataloging our results in this field. © 2004 Elsevier B.V. All rights reserved.",project-academic
10.1109/ICMA.2018.8484489,2018-08-01,p,IEEE,design of integrated vision and speech technology for a robot receptionist," Service robot, which is proposed to relive repeated labor work for human, are widely researched nowadays. In this work, we propose a robot receptionist system. The robot receptionist system follows a modularize design style which is consists of several independent functions modules. This system design enables us easily to be able to integrate other functions. Driven by the rapid development of deep learning, visual recognition tasks including such as image classification, object detection and semantic segmentation have made remarkable progress. Combining some existing state-of-art approaches, the robot receptionist system integrates face recognition, human-computer interaction and facial expression display. In the following of this paper, we elaborate the design and implementation of the system from two aspects, software and hardware, respectively. The contribution of this paper mainly includes two aspects. Firstly, we propose a method for combining several software modules of speech recognition and vision. Secondly, we construct a simple and effective experimental system to realize our design.",project-academic
10.1109/TII.2020.3002197,2021-02-01,a,Institute of Electrical and Electronics Engineers (IEEE),utilizing industry 4 0 on the construction site challenges and opportunities," In recent years, a step change has been seen in the rate of adoption of Industry 4.0 technologies by manufacturers and industrial organizations alike. This article discusses the current state of the art in the adoption of Industry 4.0 technologies within the construction industry. Increasing complexity in onsite construction projects coupled with the need for higher productivity is leading to increased interest in the potential use of Industry 4.0 technologies. This article discusses the relevance of the following key Industry 4.0 technologies to construction: data analytics and artificial intelligence, robotics and automation, building information management, sensors and wearables, digital twin, and industrial connectivity. Industrial connectivity is a key aspect as it ensures that all Industry 4.0 technologies are interconnected allowing the full benefits to be realized. This article also presents a research agenda for the adoption of Industry 4.0 technologies within the construction sector, a three-phase use of intelligent assets from the point of manufacture up to after build, and a four-staged R&D process for the implementation of smart wearables in a digital enhanced construction site.",project-academic
10.1145/2185632.2185634,2012-04-17,p,ACM,verification and control of hybrid systems using reachability analysis with machine learning," This talk will present reachability analysis as a tool for model checking and controller synthesis for dynamic systems. We will consider the problem of guaranteeing reachability to a given desired subset of the state space while satisfying a safety property defined in terms of state constraints. We allow for nonlinear and hybrid dynamics, and possibly nonconvex state constraints. We use these results to synthesize controllers that ensure safety and reachability properties under bounded model disturbances that vary continuously.The resulting control policy is a set-valued feedback map involving both a selection of continuous inputs and discrete switching commands as a function of system state. We show that new control policies based on machine learning are included in this map, resulting in high performance with guarantees of safety. We discuss real-time implementations of this, and present several examples from multiple aerial vehicle control, human-robot interaction, and multiple player games.",project-academic
10.1016/J.PROTCY.2016.08.007,2016-01-01,a,Elsevier,embedded electronic system based on dedicated hardware dsps for electronic skin implementation," Abstract None None The effort to develop an electronic skin is highly motivated by many application domains namely robotics, biomedical instrumentations, and replacement prosthetic devices. Several e-skin systems have been proposed recently and have demonstrated the need of an embedded electronic system for tactile data processing either to mimic the human skin or to respond to the application demands. Processing tactile data requires efficient methods to extract meaningful information from raw sensors data. None In this framework, our goal is the development of a dedicated embedded electronic system for electronic skin. The embedded electronic system has to acquire the tactile data, process and extract structured information. Machine Learning (ML) represents an effective method for data analysis in many domains: it has recently demonstrated its effectiveness in processing tactile sensors data. None This paper presents an embedded electronic system based on dedicated hardware implementation for electronic skin systems. It provides a Tensorial kernel function implementation for machine learning based on Tensorial kernel approach. Results assess the time latency and the hardware complexity for real time functionality. The implementation results highlight the high amount of power consumption needed for the input touch modalities classification task. Conclusions and future perspectives are also presented.",project-academic
10.1007/978-3-662-44468-9_33,2013-06-24,p,"Springer, Berlin, Heidelberg",unsupervised recognition of salient colour for real time image processing," Humans have the subconscious ability to create simple abstractions from observations of their physical environment. The ability to consider the colour of an object in terms of “red” or “blue”, rather than spatial distributions of reflected light wavelengths, is vital in processing and communicating information about important features within our local environment. The real-time identification of such features in image processing necessitates the software implementation of such a process; segmenting an image into regions of salient colour, and in doing so reducing the information stored and processed from 3-dimensional pixel values to a simple colour class label. This paper details a method by which colour segmentation may be performed offline and stored in a static look-up table, allowing for constant time dimensionality reduction in an arbitrary environment of coloured features. The machine learning framework requires no human supervision, and its performance is evaluated in terms of feature classification performance within a RoboCup robot soccer environment. The developed system is demonstrated to yield an 8% improvement over slower traditional methods of manual colour mapping.",project-academic
10.1016/J.ROBOT.2018.02.010,2018-06-01,a,Elsevier BV,visual attention and object naming in humanoid robots using a bio inspired spiking neural network," Abstract None None Recent advances in behavioural and computational neuroscience, cognitive robotics, and in the hardware implementation of large-scale neural networks, provide the opportunity for an accelerated understanding of brain functions and for the design of interactive robotic systems based on brain-inspired control systems. This is especially the case in the domain of action and language learning, given the significant scientific and technological developments in this field. In this work we describe how a neuroanatomically grounded spiking neural network for visual attention has been extended with a word learning capability and integrated with the iCub humanoid robot to demonstrate attention-led object naming. Experiments were carried out with both a simulated and a real iCub robot platform with successful results. The iCub robot is capable of associating a label to an object with a ‘preferred’ orientation when visual and word stimuli are presented concurrently in the scene, as well as attending to said object, thus naming it. After learning is complete, the name of the object can be recalled successfully when only the visual input is present, even when the object has been moved from its original position or when other objects are present as distractors.",project-academic
10.1007/978-3-030-33274-7_11,2019-01-01,a,"Springer, Cham",toward faster reinforcement learning for robotics using gaussian processes," Standard robotic control works perfectly in case of ordinary conditions, but in the case of a change in the conditions (e.g. damaging of one of the motors), the robot won’t achieve its task anymore. We need an algorithm that provide the robot with the ability of adaption to unforeseen situations. Reinforcement learning provide a framework corresponds with that requirements, but it needs big data sets to learn robotic tasks, which is impractical. We discuss using Gaussian processes to improve the efficiency of the Reinforcement learning, where a Gaussian Process will learn a state transition model using data from the robot (interaction) phase, and after that use the learned GP model to simulate trajectories and optimize the robot’s controller in a (simulation) phase. PILCO algorithm considered as the most data efficient RL algorithm. It gives promising results in Cart-pole task, where a working controller was learned after seconds of (interaction) on the real robot, but the whole training time, considering the training in the (simulation) was longer. In this work, we will try to leverage the abilities of the computational graphs to produce a ROS friendly python implementation of PILCO, and discuss a case study of a real world robotic task.",project-academic
10.1038/S41598-020-68156-2,2020-07-08,a,Nature Publishing Group,a machine learning workflow for raw food spectroscopic classification in a future industry," Over the years, technology has changed the way we produce and have access to our food through the development of applications, robotics, data analysis, and processing techniques. The implementation of these approaches by the food industry ensure quality and affordability, reducing at the same time the costs of keeping the food fresh and increase productivity. A system, as the one presented herein, for raw food categorization is needed in future food industries to automate food classification according to type, the process of algorithm approaches that will be applied to every different food origin and also for serving disabled people. The purpose of this work was to develop a machine learning workflow based on supervised PLS regression and SVM classification, towards automated raw food categorization from FTIR. The system exhibited high efficiency in multi-class classification of 7 different types of raw food. The selected food samples, were diverse in terms of storage conditions (temperature, storage time and packaging), while the variability within each food was also taken into account by several different batches; leading in a classifier able to embed this variation towards increased robustness and efficiency, ready for real life applications targeting to the digital transformation of the food industry.",project-academic
,2018-10-04,a,,simulator predictive control using learned task representations and mpc for zero shot generalization and sequencing," Simulation-to-real transfer is an important strategy for making reinforcement learning practical with real robots. Successful sim-to-real transfer systems have difficulty producing policies which generalize across tasks, despite training for thousands of hours equivalent real robot time. To address this shortcoming, we present a novel approach to efficiently learning new robotic skills directly on a real robot, based on model-predictive control (MPC) and an algorithm for learning task representations. In short, we show how to reuse the simulation from the pre-training step of sim-to-real methods as a tool for foresight, allowing the sim-to-real policy adapt to unseen tasks. Rather than end-to-end learning policies for single tasks and attempting to transfer them, we first use simulation to simultaneously learn (1) a continuous parameterization (i.e. a skill embedding or latent) of task-appropriate primitive skills, and (2) a single policy for these skills which is conditioned on this representation. We then directly transfer our multi-skill policy to a real robot, and actuate the robot by choosing sequences of skill latents which actuate the policy, with each latent corresponding to a pre-learned primitive skill controller. We complete unseen tasks by choosing new sequences of skill latents to control the robot using MPC, where our MPC model is composed of the pre-trained skill policy executed in the simulation environment, run in parallel with the real robot. We discuss the background and principles of our method, detail its practical implementation, and evaluate its performance by using our method to train a real Sawyer Robot to achieve motion tasks such as drawing and block pushing.",project-academic
10.1016/0921-8890(96)81008-6,1995-12-01,a,North-Holland,evolution of neural control structures some experiments on mobile robots," From perception to action and form action to perception, all elements of an autonomous agent are interdependent and need to be strongly coherent. The final behavior of the agent is the result of the global activity of this loop and every weakness of incoherence of a single element has strong consequences on the performances of the agent. We think that, for the purpose of building autonomous robots, all these elements need to be developed together in continuous interaction with the environment. We describe the implementation of a possible solution (artificial neural networks and genetic algorithms) on a real mobile robot through a set of three different experiments. We focus our attention on three different aspects of the control structure: perception, internal representation and action. In all the experiments these aspects are not considered as single processing elements, but as part of an agent. For every experiment, the advantages and disadvantages of this approach are presented and discussed. The results show that the combination of genetic algorithms and neural networks is a very interesting technique for the development of control structures in autonomous agents. The time necessary for evolution, on the other hand, is very important limitation of the evolutionary approach.",project-academic
10.1016/S0952-1976(01)00031-8,2001-10-01,a,Pergamon,reinforcement learning control of nonlinear multi link system," Abstract None None In this paper, the effects of basic parameters in reinforcement learning control such as eligibility, action and critic network constrained weights, system nonlinearities, gradient information, state-space partitioning, variance of exploration are studied in detail. It is attempted to increase feasibility for practical applications, implementation, learning efficiency, and enhance performance. Also, a novel adaptive grid algorithm is proposed to overcome the difficulty in partitioning the input space to achieve better performance. Reinforcement learning is applied for control of a nonlinear one and two-link robots. This problem dictates that the learning is performed on-line, based on a binary or real-valued reinforcement signal from a critic network, without knowing the system model or nonlinearity.",project-academic
10.1016/S1567-4223(03)00041-3,2003-12-01,a,Elsevier,rule based agents for the semantic web," Abstract None None Artificial agents, subsuming both robots and software agents, represent a new paradigm in software engineering and artificial intelligence. Depending on the technologies used in their implementation, they may exhibit various skills; in particular, they may act more or less None autonomously , they may be able to None learn None and to None adapt None to a changing environment, and they may be able to pursue their goals None pro - actively . An artificial agent is called None rule - based , if its behaviour and/or its knowledge is expressed by means of rules. In this paper, we discuss a general architecture for rule-based agents and how it can be realized with the help of semantic web languages. We also show how such agents can go live on the web by presenting an implementation in None Mandarax , a Java rule platform. The concept and implementation are complemented by a running example, the None portfolio agent .",project-academic
10.5772/6799,2009-04-01,a,InTech,adaptive unscented kalman filter and its applications in nonlinear control," Active estimation is becoming a more important issue in control theory and its application, especially in the nonlinear control of uncertain systems, such as robots and unmanned vehicles where time-varying parameters and uncertainties exist extensively in the dynamics and working environment. Among the available techniques for active modeling, Neural Networks (NN) and NN-based self learning have been proposed as one of the most effective approaches in 1990s (Pesonen et al., 2004). However the problems involved in NN, such as training data selection, online guaranteed convergence, robustness, reliability and real-time implementation, still remain open and limit its application in real systems, especially those requiring high reliable control. Most recently, the encouraging achievements in sequential estimation makes it becoming an important direction for online modeling and model-reference control (Napolitano, et al., 2000). Among stochastic estimations, the most popular one for nonlinear system is the Extended Kalman Filter (EKF). Although widely used, EKF suffers from the deficiencies including the requirement of sufficient differentiability of the state dynamics, the susceptibility to bias and divergence during the estimation. Unscented Kalman Filter (UKF) (Julier et al., 1995; Wan & Van der Merwe, 2000) provides a derivative-free way to the state parameter estimation of nonlinear systems by introducing the so called ‘unscented transformation’, while achieving the second-order accuracy (the accuracy of EKF is first order) with the same computational complexity as that of EKF. Although the nonlinear state dynamics are used without linearization and the calculations on Jacobians or Hessians are not involved, UKF still falls into the framework of Kalman-type filters, which can only achieve good performance under a priori assumptions (Jazwinski, 1970), which includes: 1) accurate reference models, 2) complete information of the noise distribution, and 3) proper initial conditions. However, such a priori knowledge is often not accurate, or even not available in practice. The normal UKF will suffer from performance degradation or even instability due to the mismatch between the a priori assumptions and the real ones within the system to be controlled. One of the approaches solving this problem is to introduce adaptive mechanism into a normal filter, i.e., the adaptive law automatically tunes the filter parameters to match the O pe n A cc es s D at ab as e w w w .in te ch w eb .o rg",project-academic
10.1007/S11063-019-09983-X,2019-10-01,a,Springer US,improved gradient neural networks for solving moore penrose inverse of full rank matrix," Being with parallel-computation nature and convenience of hardware implementation, linear gradient neural networks (LGNN) are widely used to solve large-scale online matrix-involved problems. In this paper, two improved GNN (IGNN) models, which are activated by nonlinear functions, are first developed and investigated for Moore-Penrose inverse of full-rank matrix. The global convergence performances of such two models and LGNN models are theoretically analyzed. Two illustrative examples are performed to further demonstrate the theoretical results as well as the feasibility and efficacy of the proposed IGNN models for solving full-rank matrix Moore-Penrose inverse in real time. At last, a robot application example is provided to show the practical utility of the proposed IGNN models.",project-academic
10.1142/S0129065718500533,2019-07-29,a,World Scientific Publishing Company,perceptual generalization and context in a network memory inspired long term memory for artificial cognition," In the framework of open-ended learning cognitive architectures for robots, this paper deals with the design of a Long-Term Memory (LTM) structure that can accommodate the progressive acquisition of experience-based decision capabilities, or what different authors call ""automation"" of what is learnt, as a complementary system to more common prospective functions. The LTM proposed here provides for a relational storage of knowledge nuggets given the form of artificial neural networks (ANNs) that is representative of the contexts in which they are relevant in a configural associative structure. It also addresses the problem of continuous perceptual spaces and the task- and context-related generalization or categorization of perceptions in an autonomous manner within the embodied sensorimotor apparatus of the robot. These issues are analyzed and a solution is proposed through the introduction of two new types of knowledge nuggets: P-nodes representing perceptual classes and C-nodes representing contexts. The approach is studied and its performance evaluated through its implementation and application to a real robotic experiment.",project-academic
10.1101/2021.10.26.466039,2021-10-28,a,Cold Spring Harbor Laboratory,deep heterogeneous dilation of lstm for transient phase gesture prediction through high density electromyography application in neurorobotics," Deep networks have been recently proposed to estimate motor intention using conventional bipolar surface electromyography (sEMG) signals for myoelectric control of neurorobots. In this regard, deepnets are generally challenged by long training times (affecting the practicality and calibration), complex model architectures (affecting the predictability of the outcomes), a large number of trainable parameters (increasing the need for big data), and possibly overfitting. Capitalizing on our recent work on homogeneous temporal dilation in a Recurrent Neural Network (RNN) model, this paper proposes, for the first time, heterogeneous temporal dilation in an LSTM model and applies that to high-density surface electromyography (HD-sEMG), allowing for decoding dynamic temporal dependencies with tunable temporal foci. In this paper, a 128-channel HD-sEMG signal space is considered due to the potential for enhancing the spatiotemporal resolution of human-robot interfaces. Accordingly, this paper addresses a challenging motor intention decoding problem of neurorobots, namely, transient intention identification. The aforementioned problem only takes into account the dynamic and transient phase of gesture movements when the signals are not stabilized or plateaued, addressing which can significantly enhance the temporal resolution of human-robot interfaces. This would eventually enhance seamless real-time implementations. Additionally, this paper introduces the concept of dilation foci to modulate the modeling of temporal variation in transient phases. In this work a high number (i.e. 65) of gestures is included, which adds to the complexity and significance of the understudied problem. Our results show state-of-the-art performance for gesture prediction in terms of accuracy, training time, and model convergence.",project-academic
,2021-08-01,a,,bundletrack 6d pose tracking for novel objects without instance or category level 3d models," Tracking the 6D pose of objects in video sequences is important for robot manipulation. Most prior efforts, however, often assume that the target object's CAD model, at least at a category-level, is available for offline training or during online template matching. This work proposes BundleTrack, a general framework for 6D pose tracking of novel objects, which does not depend upon 3D models, either at the instance or category-level. It leverages the complementary attributes of recent advances in deep learning for segmentation and robust feature extraction, as well as memory-augmented pose graph optimization for spatiotemporal consistency. This enables long-term, low-drift tracking under various challenging scenarios, including significant occlusions and object motions. Comprehensive experiments given two public benchmarks demonstrate that the proposed approach significantly outperforms state-of-art, category-level 6D tracking or dynamic SLAM methods. When compared against state-of-art methods that rely on an object instance CAD model, comparable performance is achieved, despite the proposed method's reduced information requirements. An efficient implementation in CUDA provides a real-time performance of 10Hz for the entire framework. Code is available at: this https URL",project-academic
10.1109/AMS.2017.22,2017-12-01,p,IEEE,autonomous rover navigation using gps based path planning," Nowadays, with the constant evolution of Artificial Intelligence and Machine Learning, robots are getting more perceptive than ever. For this quality they are being used in varying circumstances which humans cannot control. Rovers are special robots, capable of traversing through areas that are too difficult for humans. Even though it is a robust bot, lack of proper intelligence and automation are its basic shortcomings. As the main purpose of a rover is to traverse through areas of extreme difficulties, therefore an intelligent path generation and following system is highly required. Our research work aimed at developing an algorithm for autonomous path generation using GPS (Global Positioning System) based coordinate system and implementation of this algorithm in real life terrain, which in our case is MDRS, Utah, USA. Our prime focus was the development of a robust but easy to implement system. After developing such system, we have been able to successfully traverse our rover through that difficult terrain. It uses GPS coordinates of target points that will be fed into the rover from a control station. The rover capturing its own GPS signal generates a path between the current location and the destination location on its own. It then finds the deviation in its current course of direction and position. And eventually it uses Proportional Integral Derivative control loop feedback mechanism (PID control algorithm) for compensating the error or deviation and thus following that path and reach destination. A low cost on board computer (Raspberry Pi in our case) handles all the calculations during the process and drives the rover fulfilling its task using an microcontroller (Arduino).",project-academic
10.1002/CTA.395,2007-07-01,a,"John Wiley & Sons, Ltd.",robot vision with cellular neural networks a practical implementation of new algorithms," Cellular neural networks (CNNs) are well suited for image processing due to the possibility of a parallel computation. In this paper, we present two algorithms for tracking and obstacle avoidance using CNNs. Furthermore, we show the implementation of an autonomous robot guided using only real-time visual feedback; the image processing is performed entirely by a CNN system embedded in a digital signal processor (DSP). We successfully tested the two algorithms on this robot. Copyright © 2006 John Wiley & Sons, Ltd.",project-academic
10.3390/APP9030470,2019-01-30,a,Multidisciplinary Digital Publishing Institute,an indoor room classification system for social robots via integration of cnn and ecoc," The ability to classify rooms in a home is one of many attributes that are desired for social robots. In this paper, we address the problem of indoor room classification via several convolutional neural network (CNN) architectures, i.e., VGG16, VGG19, & Inception V3. The main objective is to recognize five indoor classes (bathroom, bedroom, dining room, kitchen, and living room) from a Places dataset. We considered 11600 images per class and subsequently fine-tuned the networks. The simulation studies suggest that cleaning the disparate data produced much better results in all the examined CNN architectures. We report that VGG16 & VGG19 fine-tuned models with training on all layers produced the best validation accuracy, with 93.29% and 93.61% on clean data, respectively. We also propose and examine a combination model of CNN and a multi-binary classifier referred to as error correcting output code (ECOC) with the clean data. The highest validation accuracy of 15 binary classifiers reached up to 98.5%, where the average of all classifiers was 95.37%. CNN and CNN-ECOC, and an alternative form called CNN-ECOC Regression, were evaluated in real-time implementation on a NAO humanoid robot. The results show the superiority of the combination model of CNN and ECOC over the conventional CNN. The implications and the challenges of real-time experiments are also discussed in the paper.",project-academic
10.1109/MRA.2002.1035212,2002-11-07,a,IEEE,working with robots in disasters," The Robot World Cup Initiative (RoboCup) is an international research and education initiative. It was started in order to foster artificial intelligence search. RoboCupRescue's domain is search and rescue operations in urban disasters. The RoboCup Rescue league consists of two projects: the simulation project and the robotics and infrastructure project. A multi-agent-based approach to disaster simulation provides many research themes and supports rescue operations in real situations. Simulation Project, not only agent implementation, but also the evaluation of the social agents' performance, the architecture of the distribution system, and the quality of communications, etc. The following features are important in this project to promote the research and provide verification methods.",project-academic
10.1109/IROS.2013.6696494,2013-11-01,p,IEEE,adaptive collision limitation behavior for an assistive manipulator," An approach for adaptive shared control of an assistive manipulator is presented. A set of distributed collision and proximity sensors is used to aid in limiting collisions during direct control by the disabled user. Artificial neural networks adapt the use of the proximity sensors online, which limits movements in the direction of an obstacle before a collision occurs. The system learns by associating the different proximity sensors to the collision sensors where collisions are detected. This enables the user and the robot to adapt simultaneously and in real-time, with the objective of converging on a usage of the proximity sensors that increases performance for a given user, robot implementation and task-set. The system was tested in a controlled setting with a simulated 5 DOF assistive manipulator and showed promising reductions in the mean time on simplified manipulation tasks. It extends earlier work by showing that the approach can be applied to full multi-link manipulators.",project-academic
,2004-03-05,b,,introduction to autonomous mobile robots," Mobile robots range from the Mars Pathfinder mission's teleoperated Sojourner to the cleaning robots in the Paris Metro. This text offers students and other interested readers an introduction to the fundamentals of mobile robotics, spanning the mechanical, motor, sensory, perceptual, and cognitive layers the field comprises. The text focuses on mobility itself, offering an overview of the mechanisms that allow a mobile robot to move through a real world environment to perform its tasks, including locomotion, sensing, localization, and motion planning. It synthesizes material from such fields as kinematics, control theory, signal analysis, computer vision, information theory, artificial intelligence, and probability theory. The book presents the techniques and technology that enable mobility in a series of interacting modules. Each chapter treats a different aspect of mobility, as the book moves from low-level to high-level details. It covers all aspects of mobile robotics, including software and hardware design considerations, related technologies, and algorithmic techniques.] This second edition has been revised and updated throughout, with 130 pages of new material on such topics as locomotion, perception, localization, and planning and navigation. Problem sets have been added at the end of each chapter. Bringing together all aspects of mobile robotics into one volume, Introduction to Autonomous Mobile Robots can serve as a textbook or a working tool for beginning practitioners.",project-academic
,2016-07-01,a,,the rise of social bots," Bots (short for software robots) have been around since the early days of computers. One compelling example of bots is chatbots, algorithms designed to hold a conversation with a human, as envisioned by Alan Turing in the 1950s. The dream of designing a computer algorithm that passes the Turing test has driven artificial intelligence research for decades, as witnessed by initiatives like the Loebner Prize, awarding progress in natural language processing. Many things have changed since the early days of AI, when bots like Joseph Weizenbaum's ELIZA, mimicking a Rogerian psychotherapist, were developed as demonstrations or for delight. 
Today, social media ecosystems populated by hundreds of millions of individuals present real incentives—including economic and political ones—to design algorithms that exhibit human-like behavior. Such ecosystems also raise the bar of the challenge, as they introduce new dimensions to emulate in addition to content, including the social network, temporal activity, diffusion patterns, and sentiment expression. A social bot is a computer algorithm that automatically produces content and interacts with humans on social media, trying to emulate and possibly alter their behavior. Social bots have inhabited social media platforms for the past few years.",project-academic
10.1609/AIMAG.V18I1.1276,1997-03-15,a,,robocup a challenge problem for ai," The Robot World-Cup Soccer (RoboCup) is an attempt to foster AI and intelligent robotics research by providing a standard problem where a wide range of technologies can be integrated and examined. The first RoboCup competition will be held at the Fifteenth International Joint Conference on Artificial Intelligence in Nagoya, Japan. A robot team must actually perform a soccer game, incorporating various technologies, including design principles of autonomous agents, multiagent collaboration, strategy acquisition, real-time reasoning, robotics, and sensor fusion. RoboCup is a task for a team of multiple fast-moving robots under a dynamic environment. Although RoboCup's final target is a world cup with real robots, RoboCup offers a software platform for research on the software aspects of RoboCup. This article describes technical challenges involved in RoboCup, rules, and the simulation environment.",project-academic
10.1126/SCIENCE.AAX1566,2019-08-09,a,American Association for the Advancement of Science,a robotic platform for flow synthesis of organic compounds informed by ai planning," INTRODUCTION None The ability to synthesize complex organic molecules is essential to the discovery and manufacture of functional compounds, including small-molecule medicines. Despite advances in laboratory automation, the identification and development of synthetic routes remain a manual process and experimental synthesis platforms must be manually configured to suit the type of chemistry to be performed, requiring time and effort investment from expert chemists. The ideal automated synthesis platform would be capable of planning its own synthetic routes and executing them under conditions that facilitate scale-up to production goals. Individual elements of the chemical development process (design, route development, experimental configuration, and execution) have been streamlined in previous studies, but none has presented a path toward integration of computer-aided synthesis planning (CASP), expert refined chemical recipe generation, and robotically executed chemical synthesis. None RATIONALE None We describe an approach toward automated, scalable synthesis that combines techniques in artificial intelligence (AI) for planning and robotics for execution. Millions of previously published reactions inform the computational design of synthetic routes; expert-refined chemical recipe files (CRFs) are run on a robotic flow chemistry platform for scalable, reproducible synthesis. This development strategy augments a chemist’s ability to approach target-oriented flow synthesis while substantially reducing the necessary information gathering and manual effort. None RESULTS None We developed an open source software suite for CASP trained on millions of reactions from the Reaxys database and the U.S. Patent and Trademark Office. The software was designed to generalize known chemical reactions to new substrates by learning to apply retrosynthetic transformations, to identify suitable reaction conditions, and to evaluate whether reactions are likely to be successful when attempted experimentally. Suggested routes partially populate CRFs, which require additional details from chemist users to define residence times, stoichiometries, and concentrations that are compatible with continuous flow. To execute these syntheses, a robotic arm assembles modular process units (reactors and separators) into a continuous flow path according to the desired process configuration defined in the CRF. The robot also connects reagent lines and computer-controlled pumps to reactor inlets through a fluidic switchboard. When that is completed, the system primes the lines and starts the synthesis. After a specified synthesis time, the system flushes the lines with a cleaning solvent, and the robotic arm disconnects reagent lines and removes process modules to their appropriate storage locations. None This paradigm of flow chemistry development was demonstrated for a suite of 15 medicinally relevant small molecules. In order of increasing complexity, we investigated the synthesis of aspirin and secnidazole run back to back; lidocaine and diazepam run back to back to use a common feedstock; (S)-warfarin and safinamide to demonstrate the planning program’s stereochemical awareness; and two compound libraries: a family of five ACE inhibitors including quinapril and a family of four nonsteroidal anti-inflammatory drugs including celecoxib. These targets required a total of eight particular retrosynthetic routes and nine specific process configurations. None CONCLUSION None The software and platform herein represent a milestone on the path toward fully autonomous chemical synthesis, where routes still require human input and process development. Over time, the results generated by this and similar automated experimental platforms may reduce our reliance on historical reaction data, particularly in combination with smaller-scale flow-screening platforms. Increased availability of reaction data will further enable robotically realized syntheses based on AI recommendations, relieving expert chemists of manual tasks so that they may focus on new ideas.",project-academic
10.1016/J.ARTINT.2007.09.009,2008-04-01,a,Elsevier,teachable robots understanding human teaching behavior to build more effective robot learners," While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a Reinforcement Learning agent: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback, possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. Given this, we made specific modifications to the simulated RL robot, and analyzed and evaluated its learning behavior in four follow-up experiments with human trainers. We report significant improvements on several learning measures. This work demonstrates the importance of understanding the human-teacher/robot-learner partnership in order to design algorithms that support how people want to teach and simultaneously improve the robot's learning behavior.",project-academic
10.1007/978-1-4613-8997-2_30,1983-02-24,a,"Springer, New York, NY",the stanford cart and the cmu rover," The Stanford Cart was a remotely controlled TV-equipped mobile robot. A computer program was written which drove the Cart through cluttered spaces, gaining its knowledge of the world entirely from images broadcast by an on-board TV system. The CMU Rover is a more capable, and neatly operational, robot being built to develop and extend the Stanford work and to explore new directions. The Cart used several kinds of stereopsis to locate objects around it in three dimensions and to deduce its own motion. It planned an obstacle-avoiding path to a desired destination on the basis of a model built with this information. The plan changed as the Cart perceived new obstacles on its journey. The system was reliable for short runs, but slow. The Cart moved 1 m every 10 to 15 min, in lurches. After rolling a meter it stopped, took some pictures, and thought about them for a long time. Then it planned a new path, executed a little of it, and paused again. It successfully drove the Cart through several 20-m courses (each taking about 5 h) complex enough to necessitate three or four avoiding swerves; it failed in other trials in revealing ways. The Rover system has been designed with maximum mechanical and control system flexibility to support a wide range of research in perception and control. It features an omnidirectional steering system, a dozen on-board processors for essential real-time tasks, and a large remote computer to be helped by a high-speed digitizing/data playback unit and a high-performance array processor. Distributed high-level control software similar in organization to the Hearsay II speech-understanding system and the beginnings of a vision library are being readied. By analogy with the evolution of natural intelligence, we believe that incrementally solving the control and perception problems of an autonomous mobile mechanism is one of the best ways of arriving at general artificial intelligence.",project-academic
,1990-07-01,b,"Springer-Verlag New York, Inc.",the stanford cart and the cmu rover," The Stanford Cart was a remotely controlled TV-equipped mobile robot. A computer program was written which drove the Cart through cluttered spaces, gaining its knowledge of the world entirely from images broadcast by an on-board TV system. The CMU Rover is a more capable, and neatly operational, robot being built to develop and extend the Stanford work and to explore new directions. The Cart used several kinds of stereopsis to locate objects around it in three dimensions and to deduce its own motion. It planned an obstacle-avoiding path to a desired destination on the basis of a model built with this information. The plan changed as the Cart perceived new obstacles on its journey. The system was reliable for short runs, but slow. The Cart moved 1 m every 10 to 15 min, in lurches. After rolling a meter it stopped, took some pictures, and thought about them for a long time. Then it planned a new path, executed a little of it, and paused again. It successfully drove the Cart through several 20-m courses (each taking about 5 h) complex enough to necessitate three or four avoiding swerves; it failed in other trials in revealing ways. The Rover system has been designed with maximum mechanical and control system flexibility to support a wide range of research in perception and control. It features an omnidirectional steering system, a dozen on-board processors for essential real-time tasks, and a large remote computer to be helped by a high-speed digitizing/data playback unit and a high-performance array processor. Distributed high-level control software similar in organization to the Hearsay II speech-understanding system and the beginnings of a vision library are being readied. By analogy with the evolution of natural intelligence, we believe that incrementally solving the control and perception problems of an autonomous mobile mechanism is one of the best ways of arriving at general artificial intelligence.",project-academic
10.1002/9780470569962,2010-03-22,b,Wiley-Blackwell,evolving intelligent systems methodology and applications," From theory to techniques, the first all-in-one resource for EIS There is a clear demand in advanced process industries, defense, and Internet and communication (VoIP) applications for intelligent yet adaptive/evolving systems. Evolving Intelligent Systems is the first self- contained volume that covers this newly established concept in its entirety, from a systematic methodology to case studies to industrial applications. Featuring chapters written by leading world experts, it addresses the progress, trends, and major achievements in this emerging research field, with a strong emphasis on the balance between novel theoretical results and solutions and practical real-life applications. Explains the following fundamental approaches for developing evolving intelligent systems (EIS): the Hierarchical Prioritized Structure the Participatory Learning Paradigm the Evolving Takagi-Sugeno fuzzy systems (eTS+) the evolving clustering algorithm that stems from the well-known Gustafson-Kessel offline clustering algorithm Emphasizes the importance and increased interest in online processing of data streams Outlines the general strategy of using the fuzzy dynamic clustering as a foundation for evolvable information granulation Presents a methodology for developing robust and interpretable evolving fuzzy rule-based systems Introduces an integrated approach to incremental (real-time) feature extraction and classification Proposes a study on the stability of evolving neuro-fuzzy recurrent networks Details methodologies for evolving clustering and classification Reveals different applications of EIS to address real problems in areas of: evolving inferential sensors in chemical and petrochemical industry learning and recognition in robotics Features downloadable software resources Evolving Intelligent Systems is the one-stop reference guide for both theoretical and practical issues for computer scientists, engineers, researchers, applied mathematicians, machine learning and data mining experts, graduate students, and professionals.",project-academic
10.1016/J.PROMFG.2017.04.039,2017-01-01,a,Elsevier,digital twin as enabler for an innovative digital shopfloor management system in the esb logistics learning factory at reutlingen university," Abstract None None Technologies for mapping the “digital twin” have been under development for approximately 20 years. Nowadays increasingly intelligent, individualized products encourages companies to respond innovatively to customer requirements and to handle the rising product variations quickly. None An integrated engineering network, spanning across the entire value chain, is operated to intelligently connect various company divisions, and to generate a business ecosystem for products, services and communities. The conditions for the digital twin are thereby determined in which the digital world can be fed into the real, and the real world back into the digital to deal such intelligent products with rising variations. None The term digital twin can be described as a digital copy of a real factory, machine, worker etc., that is created and can be independently expanded, automatically updated as well as being globally available in real time. Every real product and production site is permanently accompanied by a digital twin. First prototypes of such digital twins already exist in the ESB Logistics Learning Factory on a cloud- and app-based software that builds on a dynamic, multidimensional data and information model. A standardized language of the robot control systems via software agents and positioning systems has to be integrated. The aspect of the continuity of the real factory in the digital factory as an economical means of ensuring continuous actuality of digital models looks as the basis of changeability. None For the indoor localization sensor combinations that in addition to the hardware already contain the software required for the sensor data fusion should be used. Processing systems, scenario-live-simulations and digital shop floor management results in a mandatory procedural combination. Essential to the digital twin is the ability to consistently provide all subsystems with the latest state of all required information, methods and algorithms.",project-academic
10.1145/273133.274326,1998-03-01,p,ACM,a robot laboratory for teaching artificial intelligence," There is a growing consensus among computer science faculty that it is quite difficult to teach the introductory course on Artificial Intelligence well [4, 6]. In part this is because AI lacks a unified methodology, overlaps with many other disciplines, and involves a wide range of skills from very applied to quite formal. In the funded project described here we have addressed these problems by"" Offering a unifying theme that draws together the disparate topics of AI;"" Focusing the course syllabus on the role AI plays in the core computer science curriculum; and"" Motivating the students to learn by using concrete, hands-on laboratory exercises.Our approach is to conceive of topics in AI as robotics tasks. In the laboratory, students build their own robots and program them to accomplish the tasks. By constructing a physical entity in conjunction with the code to control it, students have a unique opportunity to directly tackle many central issues of computer science including the interaction between hardware and software, space complexity in terms of the memory limitations of the robot's controller, and time complexity in terms of the speed of the robot's action decisions. More importantly, the robot theme provides a strong incentive towards learning because students want to see their inventions succeed.This robot-centered approach is an extension of the agent-centered approach adopted by Russell and Norvig in their recent text book [11]. Taking the agent perspective, the problem of AI is seen as describing and building agents that receive perceptions as input and then output appropriate actions based on them. As a result the study of AI centers around how best to implement this mapping from perceptions to actions. The robot perspective takes this approach one step further; rather than studying software agents in a simulated environment, we embed physical agents in the real world. This adds a dimension of complexity as well as excitement to the AI course. The complexity has to do with additional demands of learning robot building techniques but can be overcome by the introduction of kits that are easy to assemble. Additionally, they are lightweight, inexpensive to maintain, programmable through the standard interfaces provided on most computers, and yet, offer sufficient extensibility to create and experiment with a wide range of agent behaviors. At the same time, using robots also leads the students to an important conclusion about scalability: the real world is very different from a simulated world, which has been a long standing criticism of many well-known AI techniques.We proposed a plan to develop identical robot building laboratories at both Bryn Mawr and Swarthmore Colleges that would allow us to integrate the construction of robots into our introductory AI courses. Furthermore, we hoped that these laboratories would encourage our undergraduate students to pursue honors theses and research projects dealing with the building of physical agents.",project-academic
10.1109/CT.1997.617707,1997-08-25,p,IEEE Computer Society,the intelligent room project," At the MIT Artificial Intelligence Laboratory, we have been working on technologies for an Intelligent Room. Rather than pull people into the virtual world of the computer, we are trying to pull the computer out into the real world of people. To do this, we are combining robotics and vision technology with speech understanding systems and agent-based architectures to provide ready-at-hand computation and information services for people engaged in day-to-day activities, both on their own and in conjunction with others. We have built a layered architecture where, at the bottom level, vision systems track people and identify their activities and gestures, and, through word spotting, decide whether people in the room are talking to each other or to the room itself. At the next level, an agent architecture provides a uniform interface to such specially-built systems, and to other off-the-shelf software, such as Web browsers, etc. At the highest level, we are able to build application systems that provide occupants of the room with specialized services; examples we have built include systems for command-and-control situations rooms and as a room for giving presentations.",project-academic
10.1007/978-3-319-68792-6_33,2016-06-30,p,"Springer, Cham",a deep learning approach for object recognition with nao soccer robots," The use of identical robots in the RoboCup Standard Platform League (SPL) made software development the key aspect to achieve good results in competitions. In particular, the visual detection process is crucial for extracting information about the environment. In this paper, we present a novel approach for object detection and classification based on Convolutional Neural Networks (CNN). The approach is designed to be used by NAO robots and is made of two stages: image region segmentation, for reducing the search space, and Deep Learning, for validation. The proposed method can be easily extended to deal with different objects and adapted to be used in other RoboCup leagues. Quantitative experiments have been conducted on a data set of annotated images captured in real conditions from NAO robots in action. The used data set is made available for the community.",project-academic
10.2196/10410,2018-07-04,a,JMIR Publications Inc.,health care robotics qualitative exploration of key challenges and future directions," Background: The emergence of robotics is transforming industries around the world. Robot technologies are evolving exponentially, particularly as they converge with other functionalities such as artificial intelligence to learn from their environment, from each other, and from humans. Objective: The goal of the research was to understand the emerging role of robotics in health care and identify existing and likely future challenges to maximize the benefits associated with robotics and related convergent technologies. Methods: We conducted qualitative semistructured one-to-one interviews exploring the role of robotic applications in health care contexts. Using purposive sampling, we identified a diverse range of stakeholders involved in conceiving, procuring, developing, and using robotics in a range of national and international health care settings. Interviews were digitally recorded, transcribed verbatim, and analyzed thematically, supported by NVivo 10 (QSR International) software. Theoretically, this work was informed by the sociotechnical perspective, where social and technical systems are understood as being interdependent. Results: We conducted 21 interviews and these accounts suggested that there are significant opportunities for improving the safety, quality, and efficiency of health care through robotics, but our analysis identified 4 major barriers that need to be effectively negotiated to realize these: (1) no clear pull from professionals and patients, (2) appearance of robots and associated expectations and concerns, (3) disruption of the way work is organized and distributed, and (4) new ethical and legal challenges requiring flexible liability and ethical frameworks. Conclusions: Sociotechnical challenges associated with the effective integration of robotic applications in health care settings are likely to be significant, particularly for patient-facing functions. These need to be identified and addressed for effective innovation and adoption.",project-academic
10.1109/ICRA48506.2021.9561722,2021-05-30,p,IEEE,a scavenger hunt for service robots," Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",project-academic
,2021-03-09,a,,a scavenger hunt for service robots," Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",project-academic
10.3389/FNBOT.2018.00035,2018-07-06,a,Frontiers,a survey of robotics control based on learning inspired spiking neural networks," Biological intelligence processes information using impulses or spikes, which makes those living creatures able to perceive and act in the real world exceptionally well and outperform state-of-the-art robots in almost every aspect of life. To make up the deficit, emerging hardware technologies and software knowledge in the fields of neuroscience, electronics, and computer science have made it possible to design biologically realistic robots controlled by spiking neural networks (SNNs), inspired by the mechanism of brains. However, a comprehensive review on controlling robots based on SNNs is still missing. In this paper, we survey the developments of the past decade in the field of spiking neural networks for control tasks, with particular focus on the fast emerging robotics-related applications. We first highlight the primary impetuses of SNN-based robotics tasks in terms of speed, energy efficiency, and computation capabilities. We then classify those SNN-based robotic applications according to different learning rules and explicate those learning rules with their corresponding robotic applications. We also briefly present some existing platforms that offer an interaction between SNNs and robotics simulations for exploration and exploitation. Finally, we conclude our survey with a forecast of future challenges and some associated potential research topics in terms of controlling robots based on SNNs.",project-academic
,2020-08-08,a,,trifinger an open source robot for learning dexterity," Dexterous object manipulation remains an open problem in robotics, despite the rapid progress in machine learning during the past decade. We argue that a hindrance is the high cost of experimentation on real systems, in terms of both time and money. We address this problem by proposing an open-source robotic platform which can safely operate without human supervision. The hardware is inexpensive (about \SI{5000}[\$]{}) yet highly dynamic, robust, and capable of complex interaction with external objects. The software operates at 1-kilohertz and performs safety checks to prevent the hardware from breaking. The easy-to-use front-end (in C++ and Python) is suitable for real-time control as well as deep reinforcement learning. In addition, the software framework is largely robot-agnostic and can hence be used independently of the hardware proposed herein. Finally, we illustrate the potential of the proposed platform through a number of experiments, including real-time optimal control, deep reinforcement learning from scratch, throwing, and writing.",project-academic
10.1016/J.CHB.2017.02.064,2017-12-01,a,Pergamon,shopping with a robotic companion," In this paper, we present a robotic shopping assistant, designed with a cognitive architecture, grounded in machine learning systems, in order to study how the human-robot interaction (HRI) is changing the shopping behavior in smart technological stores. In the software environment of the NAO robot, connected to the Internet with cloud services, we designed a social-like interaction where the robot carries out actions with the customer. In particular, we focused our design on two main skills the robot has to learn: the first is the ability to acquire social input communicated by relevant clues that humans provide about their emotional state (emotions, emotional speech), or collected in the Social Media (such as, information on the customer's tastes, cultural background, etc.). The second is the skill to express in turn its own emotional state, so that it can affect the customer buying decision, refining in the user the sense of interacting with a human-like companion. By combining social robotics and machine learning systems the potential of robotics to assist people in real life situations will increase, providing a gentle customers' acceptance of advanced technologies. We designed an assistant humanoid robot to help customers in the shop activity.The robot's architecture is a complex and synchronized machine learning system.The customer-robot interaction has been evaluated in the shopping scenario.The robot's learns the tasks in order to behave as a social companion.The robot assistant provides a gentle customers' acceptance of advanced technologies.",project-academic
,2013-07-04,,,message service provision system and method," PROBLEM TO BE SOLVED: To provide a messaging service provision system which transmits conversation with users through an instant messaging application and simultaneously provides, within a talk session, contents of translated conversation among the users.SOLUTION: An information provision system allows a user, through an instant messaging application executed in a user terminal, to add as a friend an interpreter software robot acting as a virtual friend realized with an artificial intelligence software program. Accordingly, when a user inputs and transmits a message in a first language in a talk session with the interpreter software robot, the information provision system generates, by translating the message into a second language, a message in the second language, and provides it to the user and its conversation partners together with or instead of the message in the first language.",project-academic
10.1109/TII.2019.2945012,2020-02-01,a,Institute of Electrical and Electronics Engineers (IEEE),online gmm clustering and mini batch gradient descent based optimization for industrial iot 4 0," The future fifth-generation (5G) networks are expected to support a huge number of connected devices with various and multitude services having different quality of service (QoS) requirements. Communication in Industry 4.0 is one of the flagships and special applications of the 5G due to the specificity of the industrial environment as well as the variety of its services such as safety communication, robot's communications, and machine monitoring. In this context, we propose a new resource allocation for the future Industry 4.0 based on software-defined networking and network function virtualization technologies, machine learning tools and the slicing paradigm where each slice of the network is dedicated to a category of services having similar QoS requirement level. In this article, the proposed solution ensures the allocation of the resources to the slices depending on their requirements in terms of bandwidth, delay, and reliability. Toward this goal, our solution is performed in three main steps: first, Internet of Things (IoT) devices assignment to the slices step based on online Gaussian mixture model clustering algorithm, second, inter-slices resources reservations step based on mini-batch gradient descent, and third, intra-slices resources allocations based on the max-utility algorithm. We have performed extensive simulations in a realistic industrial scenario using NS3 simulator. Numerical results show the effectiveness of our proposed solution in terms of reducing packet error rate, energy consumption, and in terms of increasing the percentage of served devices in delay comparing to the traditional approaches.",project-academic
10.1109/ROMAN.2006.314459,2006-09-01,p,IEEE,reinforcement learning with human teachers understanding how people want to teach robots," While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a robot a task through Reinforcement Learning: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback ? possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. In conclusion, we discuss future extensions to RL to accommodate these lessons.",project-academic
10.1007/978-3-319-30279-9,2016-03-23,b,"Springer Publishing Company, Incorporated",advances and applications in chaotic systems," This book reports on the latest advances and applications of chaotic systems. It consists of 25 contributed chapters by experts who are specialized in the various topics addressed in this book. The chapters cover a broad range of topics of chaotic systems such as chaos, hyperchaos, jerk systems, hyperjerk systems, conservative and dissipative systems, circulant chaotic systems, multi-scroll chaotic systems, finance chaotic system, highly chaotic systems, chaos control, chaos synchronization, circuit realization and applications of chaos theory in secure communications, mobile robot, memristors, cellular neural networks, etc. Special importance was given to chapters offering practical solutions, modeling and novel control methods for the recent research problems in chaos theory. This book will serve as a reference book for graduate students and researchers with a basic knowledge of chaos theory and control systems. The resulting design procedures on the chaotic systems are emphasized using MATLAB software.",project-academic
,2010-01-01,a,,the smach high level executive," Personal robotics applications often require the integration of hundreds of components. In robot operating systems (ROSs), such subsystems and primitive capabilities are usually encapsulated in ROS nodes. Even with encapsulation and well-documented messaging interfaces, writing maintainable code to make a large set of ROS nodes to act together to solve a problem is difficult. Solution strategies range from writing code in big if/else cascades and nested switch statements to using more powerful inference and task-planning systems. In this column, we introduce an approach based on nested state machines that has proven very effective at building real-ROS applications. Complex Appications Over the past couple of years, we have been exploring the trade-offs between task scripting and task planning for highlevel control in robot applications written on top of ROS. Scripting approaches let the programmer not only say exactly what the robot should do, but also require the programmer to explicitly describe recovery logic for all failure modes. Although these methods can be rapid for developing small applications, they do not scale well. When failures arise, robots are not like pure software systems: they cannot just reset the state of the world and retry. As a result, autonomous robotics applications require a large amount of additional work to describe how to recover from these failures in addition to the application’s nominal execution. Furthermore, our experience has shown that maintaining, extending, and fixing such scripts over time makes it more and more challenging to analyze or model the application. On the other end of the spectrum, instead of explicitly describing which actions to execute in an imperative programming language, more autonomy can be given to the robot to plan and execute tasks. There exist model-based task planning and inference systems based on classic artificial intelligence (AI), constraint satisfaction, and model checking. The model, in this case, describes constraints and relations relevant to the set of actions at the robot’s disposal. These systems aim to shift the burden of solving the application-specific problems from the developer to the autonomous system.",project-academic
10.1109/ICRA40945.2020.9196608,2020-05-01,p,,gershgorin loss stabilizes the recurrent neural network compartment of an end to end robot learning scheme," Traditional robotic control suits require profound task-specific knowledge for designing, building and testing control software. The rise of Deep Learning has enabled end-to-end solutions to be learned entirely from data, requiring minimal knowledge about the application area. We design a learning scheme to train end-to-end linear dynamical systems (LDS)s by gradient descent in imitation learning robotic domains. We introduce a new regularization loss component together with a learning algorithm that improves the stability of the learned autonomous system, by forcing the eigenvalues of the internal state updates of an LDS to be negative reals. We evaluate our approach on a series of real-life and simulated robotic experiments, in comparison to linear and nonlinear Recurrent Neural Network (RNN) architectures. Our results show that our stabilizing method significantly improves test performance of LDS, enabling such linear models to match the performance of contemporary nonlinear RNN architectures. A video of the obstacle avoidance performance of our method on a mobile robot, in unseen environments, compared to other methods can be viewed at https://youtu.be/mhEsCoNao5E.",project-academic
10.3389/FNHUM.2014.00444,2014-06-19,a,Frontiers,toward a new cognitive neuroscience modeling natural brain dynamics," Decades of brain imaging experiments have revealed important insights into the architecture of the human brain and the detailed anatomic basis for the neural dynamics supporting human cognition. However, technical restrictions of traditional brain imaging approaches including functional magnetic resonance tomography (fMRI), positron emission tomography (PET), and magnetoencephalography (MEG) severely limit participants' movements during experiments (Makeig et al., 2009). As a consequence, our knowledge of the neural basis of human cognition is rooted in a dissociation of human cognition from what is arguably its foremost, and certainly its most evolutionarily determinant function—organizing our behavior so as to optimize its consequences in our complex, multi-scale, and ever-changing environment. The concept of natural cognition, therefore, should not be separated from our fundamental experience and role as an embodied agent acting in a complex, partly unpredictable world.

To gain new insights into the brain dynamics supporting natural cognition requires overcoming restrictions of traditional brain imaging technologies (Gramann et al., 2011). First, the sensors must be lightweight and untethered to allow monitoring of brain activity during free movements. Fortunately, new electroencephalography (EEG) and near infrared spectroscopy (NIRS) sensors and sensing devices allow recording both electrical and hemodynamic brain and body activity while participants are freely moving (Lin et al., 2011; Liao et al., 2012; Ayaz et al., 2013). New data-driven analysis approaches must allow separation of signals arriving at the sensors from the brain as well as non-brain sources like neck muscles, eyes, heart, and the electrical environment (Makeig et al., 2004). Independent component analysis (ICA) and related blind source separation methods have proven effective for separating brain from non-brain activities from electrophysiological data recorded during experimental paradigms that stimulate natural cognition (Gramann et al., 2014). ICA has also proven valuable for separating other multi-channel signals including electromyographic (EMG) and electrocardiographic (ECG) activities (Gramann et al., 2010; Gwin et al., 2010; Kline et al., 2014).

Adequate study of natural cognition also requires synchronous recording of participants' motor actions as well as the physical environment and external events influencing cognition. Recording what the brain does (via EEG and fNIRS brain imaging), what it senses (via scene and event recording), and what it organizes (via motor, ocular, and autonomic activity recording) may be termed mobile brain/body imaging (“MoBI”). Technically, recording MoBI data is now possible at reasonable cost and convenience. However, joint multi-stream analysis of the data recorded in MoBI paradigms presents major conceptual, mathematical, and data processing challenges (Ojeda et al., 2014).

To overcome restrictions of established brain imaging methods and to facilitate further development of mobile brain/body imaging, a group of researchers from all over the world gathered in the beautiful scientific retreat of the Hanse-Wissenschaftskolleg in Delmenhorst, Germany in September 2013 for the first international meeting on Mobile Brain/Body Imaging. During a stimulating and intense workshop, attendees presented and discussed newest developments in mobile brain imaging technologies, novel software architectures for recording and analyzing multidimensional data streams, and other topics relevant to MoBI. Most attendees at the Delmenhorst meeting contributed to this Research Topic; other research groups have added contributions sharing related ideas. The present Research Topic thus provides an excellent overview of the current state of the art in mobile brain/body imaging. The topics cover the three main pillars of MoBI research, i.e., hardware for imaging mobile brain and body dynamics, software to record and analyze complex multi-dimensional data streams, and applications of MoBI to such diverse fields as neuroergonomics, gait rehabilitation, spatial cognition, and dance.

Starting with the technical aspects of MoBI, Reis et al. (2014), provide an overview on existing hardware and software solutions for MoBI recordings. Focusing on new sensor technology and analysis approaches, Lin et al. report a test of a new mobile EEG headgear using steady-state visual-evoked potentials in participants during treadmill walking (Lin et al., 2014). With the aim to include gaze tracking as an important information channel for investigations of natural cognition and associated brain dynamics Browatzki and colleagues describe and compare two different approaches to measuring eye movements in mobile participants (Browatzki et al., 2014).

The second pillar of MoBI, software frameworks for recording and analyses of multi-modal imaging data is addressed by Ojeda and colleagues providing a description of a new open source toolbox (Ojeda et al., 2014). MoBILAB interoperates with EEGLAB (Delorme and Makeig, 2004) and allows for analysis and visualization of multidimensional mobile brain/body imaging data. Zao et al. (2014) introduce an exciting new perspective on distributed computing describing a novel network system approach to remote monitoring of brain/body activity of one or many mobile participants.

The majority of contributions to this Research Topic can be summarized under the pillar of MoBI applications. The review by Mehta and Parasuraman (2013) provides an overview of the advantages and disadvantages of existing imaging modalities in the area of neuroergonomics, describing differing temporal and spatial resolutions and the degree of immobility that brain imaging method imposes on participants. Ayaz et al. (2013) describe the development and application of a mobile fNIRS device for investigating changes in workload in real operating environments providing an example of mobile recordings of hemodynamics. The first investigation of kinesthetic and vestibular information processing in actively navigating participants is given by Ehinger et al. (2014). The authors dissociate the brain dynamics underlying different proprioceptive senses during movements. Wagner et al. (2014) use MoBI to describe the cortical networks activated during robot-assisted walking and investigate the potential impact of movement-related feedback for gait rehabilitation. Cruz-Garza and colleagues investigate professional dancers during different whole body movements and derive distinct expressive qualities of movement from surface EEG (Cruz-Garza et al., 2014). While the previous studies used whole body movement, Amengual and colleagues describe the brain dynamics associated with the preparation and execution of multi-joint self-paced arm movements (Amengual et al., 2014). Finally, in their paper Derix et al. elucidate the neuronal basis of mental processes during natural communication based on electrocorticography in pre-neurosurgical patients (Derix et al., 2014).

All contributions in this Research Topic go beyond the state of the art in brain imaging and provide new approaches to recording and analyzing multi-modal data. The authors describe new insights into the neural basis of cognitive processes beyond traditional laboratory research. We hope this Research Topic may inspire new research that uses the MoBI paradigm to investigate natural cognition by recording and analyzing brain dynamics and behavior of participants performing a wide range of naturally motivated actions and interactions.",project-academic
10.1109/SII46433.2020.9025951,2020-01-01,p,IEEE,gym ignition reproducible robotic simulations for reinforcement learning," This paper presents Gym-Ignition, a new framework to create reproducible robotic environments for reinforcement learning research. It interfaces with the new generation of Gazebo, part of the Ignition Robotics suite, which provides three main improvements for reinforcement learning applications compared to the alternatives: 1) the modular architecture enables using the simulator as a C++ library, simplifying the interconnection with external software; 2) multiple physics and rendering engines are supported as plugins, simplifying their selection during the execution; 3) the new distributed simulation capability allows simulating complex scenarios while sharing the load on multiple workers and machines. The core of Gym-Ignition is a component that contains the Ignition Gazebo simulator and exposes a simple interface for its configuration and execution. We provide a Python package that allows developers to create robotic environments simulated in Ignition Gazebo. Environments expose the common OpenAI Gym interface, making them compatible out-of-the-box with third-party frameworks containing reinforcement learning algorithms. Simulations can be executed in both headless and GUI mode, the physics engine can run in accelerated mode, and instances can be parallelized. Furthermore, the Gym-Ignition software architecture provides abstraction of the Robot and the Task, making environments agnostic on the specific runtime. This abstraction allows their execution also in a real-time setting on actual robotic platforms, even if driven by different middlewares.",project-academic
10.1109/MRA.2016.2535081,2016-08-26,a,IEEE,musculoskeletal robots scalability in neural control," Anthropomimetic robots sense, behave, interact, and feel like humans. By this definition, they require human-like physical hardware and actuation but also brain-like control and sensing. The most self-evident realization to meet those requirements would be a human-like musculoskeletal robot with a brain-like neural controller. While both musculoskeletal robotic hardware and neural control software have existed for decades, a scalable approach that could be used to build and control an anthropomimetic human-scale robot has not yet been demonstrated. Combining Myorobotics, a framework for musculoskeletal robot development, with SpiNNaker, a neuromorphic computing platform, we present the proof of principle of a system that can scale to dozens of neurally controlled, physically compliant joints. At its core, it implements a closed-loop cerebellar model that provides real-time, low-level, neural control at minimal power consumption and maximal extensibility. Higher-order (e.g., cortical) neural networks and neuromorphic sensors like silicon retinae or cochleae can be incorporated.",project-academic
10.14429/DSJ.60.11,2010-01-01,a,Defense Scientific Information and Documentation Centre,controlling a mobile robot with a biological brain," The intelligent controlling mechanism of a typical mobile robot is usually a computer system. Some recent research is ongoing in which biological neurons are being cultured and trained to act as the brain of an interactive real world robotthereby either completely replacing, or operating in a cooperative fashion with, a computer system. Studying such hybrid systems can provide distinct insights into the operation of biological neural structures, and therefore, such research has immediate medical implications as well as enormous potential in robotics. The main aim of the research is to assess the computational and learning capacity of dissociated cultured neuronal networks. A hybrid system incorporating closed-loop control of a mobile robot by a dissociated culture of neurons has been created. The system is flexible and allows for closed-loop operation, either with hardware robot or its software simulation. The paper provides an overview of the problem area, gives an idea of the breadth of present ongoing research, establises a new system architecture and, as an example, reports on the results of conducted experiments with real-life robots. None None Defence Science Journal, 2010, 60(1), pp.5-14 None None , DOI:http://dx.doi.org/10.14429/dsj.60.11",project-academic
10.1016/J.PATREC.2013.05.019,2014-01-01,a,NIH Public Access,towards a real time interface between a biomimetic model of sensorimotor cortex and a robotic arm," Brain-machine interfaces can greatly improve the performance of prosthetics. Utilizing biomimetic neuronal modeling in brain machine interfaces (BMI) offers the possibility of providing naturalistic motor-control algorithms for control of a robotic limb. This will allow finer control of a robot, while also giving us new tools to better understand the brain's use of electrical signals. However, the biomimetic approach presents challenges in integrating technologies across multiple hardware and software platforms, so that the different components can communicate in real-time. We present the first steps in an ongoing effort to integrate a biomimetic spiking neuronal model of motor learning with a robotic arm. The biomimetic model (BMM) was used to drive a simple kinematic two-joint virtual arm in a motor task requiring trial-and-error convergence on a single target. We utilized the output of this model in real time to drive mirroring motion of a Barrett Technology WAM robotic arm through a user datagram protocol (UDP) interface. The robotic arm sent back information on its joint positions, which was then used by a visualization tool on the remote computer to display a realistic 3D virtual model of the moving robotic arm in real time. This work paves the way towards a full closed-loop biomimetic brain-effector system that can be incorporated in a neural decoder for prosthetic control, to be used as a platform for developing biomimetic learning algorithms for controlling real-time devices.",project-academic
,2020-07-28,,,robot software system and robot thereof," The embodiment of the invention discloses a robot software system. The system comprises an operating system and an application program; the operating system operates in the microcomputer of a robot control system; the application program corresponds to specific functions, functions and capabilities of a robot; the operating system is a running environment of the application program; the operating system realizes the preset capability or preset function of the robot by calling and terminating the application program. The invention further discloses a robot adopting the robot software system; and the robot has the artificial intelligence capacity. The robot is enabled to be interconnected and intercommunicated with people or things of a new generation of information technology, interconnected and intercommunicated with a cloud platform, and compatible with the previous generation of information technology; the system is provided with a super-intelligent ''brain'', so that the systemcan perceive people and exert partial or all effects or capabilities like real people.",project-academic
10.1109/MRA.2016.2535081,2016-01-19,a,,scalability in neural control of musculoskeletal robots," Anthropomimetic robots are robots that sense, behave, interact and feel like humans. By this definition, anthropomimetic robots require human-like physical hardware and actuation, but also brain-like control and sensing. The most self-evident realization to meet those requirements would be a human-like musculoskeletal robot with a brain-like neural controller. While both musculoskeletal robotic hardware and neural control software have existed for decades, a scalable approach that could be used to build and control an anthropomimetic human-scale robot has not been demonstrated yet. Combining Myorobotics, a framework for musculoskeletal robot development, with SpiNNaker, a neuromorphic computing platform, we present the proof-of-principle of a system that can scale to dozens of neurally-controlled, physically compliant joints. At its core, it implements a closed-loop cerebellar model which provides real-time low-level neural control at minimal power consumption and maximal extensibility: higher-order (e.g., cortical) neural networks and neuromorphic sensors like silicon-retinae or -cochleae can naturally be incorporated.",project-academic
,2016-01-01,a,,scalability in neural control of musculoskeletal robots," Anthropomimetic robots are robots that sense, behave, interact and feel like humans. By this definition, anthropomimetic robots require human-like physical hardware and actuation, but also brain-like control and sensing. The most self-evident realization to meet those requirements would be a human-like musculoskeletal robot with a brain-like neural controller. While both musculoskeletal robotic hardware and neural control software have existed for decades, a scalable approach that could be used to build and control an anthropomimetic human-scale robot has not been demonstrated yet. Combining Myorobotics, a framework for musculoskeletal robot development, with SpiNNaker, a neuromorphic computing platform, we present the proof-of-principle of a system that can scale to dozens of neurally-controlled, physically compliant joints. At its core, it implements a closed-loop cerebellar model which provides real-time low-level neural control at minimal power consumption and maximal extensibility: higher-order (e.g., cortical) neural networks and neuromorphic sensors like silicon-retinae or -cochleae can naturally be incorporated.",project-academic
10.1016/J.JCLEPRO.2021.125834,2021-03-20,a,Elsevier,artificial intelligence in sustainable energy industry status quo challenges and opportunities," Abstract None None The energy industry is at a crossroads. Digital technological developments have the potential to change our energy supply, trade, and consumption dramatically. The new digitalization model is powered by the artificial intelligence (AI) technology. The integration of energy supply, demand, and renewable sources into the power grid will be controlled autonomously by smart software that optimizes decision-making and operations. AI will play an integral role in achieving this goal. This study focuses on the use of AI techniques in the energy sector. This study aims to present a realistic baseline that allows researchers and readers to compare their AI efforts, ambitions, new state-of-the-art applications, challenges, and global roles in policymaking. We covered three major aspects, including: i) the use of AI in solar and hydrogen power generation; (ii) the use of AI in supply and demand management control; and (iii) recent advances in AI technology. This study explored how AI techniques outperform traditional models in controllability, big data handling, cyberattack prevention, smart grid, IoT, robotics, energy efficiency optimization, predictive maintenance control, and computational efficiency. Big data, the development of a machine learning model, and AI will play an important role in the future energy market. Our study’s findings show that AI is becoming a key enabler of a complex, new and data-related energy industry, providing a key magic tool to increase operational performance and efficiency in an increasingly cut-throat environment. As a result, the energy industry, utilities, power system operators, and independent power producers may need to focus more on AI technologies if they want meaningful results to remain competitive. New competitors, new business strategies, and a more active approach to customers would require informed and flexible regulatory engagement with the associated complexities of customer safety, privacy, and information security. Given the pace of development in information technology, AI and data analysis, regulatory approvals for new services and products in the new Era of digital energy markets can be enforced as quickly and efficiently as possible.",project-academic
10.1016/J.COLA.2020.100970,2020-05-20,a,Elsevier,visual programming environments for end user development of intelligent and social robots a systematic review," Abstract None None Robots are becoming interactive and robust enough to be adopted outside laboratories and in industrial scenarios as well as interacting with humans in social activities. However, the design of engaging robot-based applications requires the availability of usable, flexible and accessible development frameworks, which can be adopted and mastered by researchers and practitioners in social sciences and adult end users as a whole. This paper surveys Visual Programming Environments aimed at enabling a paradigm fostering the so-called End-User Development of applications involving robots with social capabilities. The focus of this article is on those Visual Programming Environments that are designed to support social research goals as well as to cater for professional needs of people not trained in more traditional text-based computer programming languages. This survey excludes interfaces aimed at supporting expert programmers, at allowing industrial robots to perform typical industrial tasks (such as pick and place operations), and at teaching children how to code. After having performed a systematic search, sixteen programming environments have been included in this survey. Our goal is two-fold: first, to present these software tools with their technical features and Authoring Artificial Intelligence modeling approaches, and second, to present open challenges in the development of Visual Programming Environments for end users and social researchers, which can be informative and valuable to the community. The results show that the most recent such tools are adopting distributed and Component-Based Software Engineering approaches and web technologies. However, few of them have been designed to enable the independence of end users from high-tech scribes. Moreover, findings indicate the need for (i) more objective and comparative evaluations, as well as usability and user experience studies with real end users; and (ii) validations of these tools for designing applications aimed at working “in-the-wild” rather than only in laboratories and structured settings.",project-academic
10.5772/54129,2012-11-30,a,SAGE Publications,biomimetics micro robot with active hardware neural networks locomotion control and insect like switching behaviour," In this paper, we presented the 4.0, 2.7, 2.5 mm, width, length, height size biomimetics micro robot system which was inspired by insects. The micro robot system was made from silicon wafer fabricated by micro electro mechanical systems (MEMS) technology. The mechanical system of the robot was equipped with small size rotary type actuators, link mechanisms and six legs to realize the insect-like switching behaviour. In addition, we constructed the active hardware neural networks (HNN) by analogue CMOS circuits as a locomotion controlling system. The HNN utilized the pulse-type hardware neuron model (P-HNM) as a basic component. The HNN outputs the driving pulses using synchronization phenomena None such as biological neural networks. The driving pulses can operate the actuators of None the biomimetics micro robot directly. Therefore, the HNN realized the robot control without using any software programs or A/D converters. The micro robot emulated the locomotion method and the neural networks of an insect with rotary type actuators, link mechanisms and HNN. The micro robot performed forward and backward locomotion, and also changed direction by inputting an external trigger pulse. The locomotion speed was 26.4 None mm/min when the step width was 0.88 mm.",project-academic
,2016-03-30,,,machine vision based intelligent artistic paint robot," The invention discloses a machine-vision-based intelligent artistic paint robot system that is applied to various souvenirs or ornaments. According to the intelligent artistic paint robot, a scenery or portrait image that is captured by a camera is processed into an image with high light-shade contrast by built-in programming software; an arm is controlled to hold a pen to paint a seen scenery or portrait based on a complex algorithm, so that the artistic painting becomes vivid; and then the paint amount of an inflator is controlled by a line segment interpolation algorithm and a running speed, thereby realizing a clear and coherent painting effect. According to the invention, the advanced computer software, computer vision system and the artificial intelligence are combined. When the provided robot is used for replacing the manual operation, time consumed for painting one picture by the robot is less than ten minutes and the speed is much faster than the street artist. Meanwhile, the interestingness of artistic ornament production is enhanced and the application market of the artistic decoration industry can be seized. Therefore, the provided robot has the wide application range and broad development prospects.",project-academic
10.1186/S13007-017-0246-7,2017-11-08,a,BioMed Central,a robot assisted imaging pipeline for tracking the growths of maize ear and silks in a high throughput phenotyping platform," In maize, silks are hundreds of filaments that simultaneously emerge from the ear for collecting pollen over a period of 1–7 days, which largely determines grain number especially under water deficit. Silk growth is a major trait for drought tolerance in maize, but its phenotyping is difficult at throughputs needed for genetic analyses. We have developed a reproducible pipeline that follows ear and silk growths every day for hundreds of plants, based on an ear detection algorithm that drives a robotized camera for obtaining detailed images of ears and silks. We first select, among 12 whole-plant side views, those best suited for detecting ear position. Images are segmented, the stem pixels are labelled and the ear position is identified based on changes in width along the stem. A mobile camera is then automatically positioned in real time at 30 cm from the ear, for a detailed picture in which silks are identified based on texture and colour. This allows analysis of the time course of ear and silk growths of thousands of plants. The pipeline was tested on a panel of 60 maize hybrids in the PHENOARCH phenotyping platform. Over 360 plants, ear position was correctly estimated in 86% of cases, before it could be visually assessed. Silk growth rate, estimated on all plants, decreased with time consistent with literature. The pipeline allowed clear identification of the effects of genotypes and water deficit on the rate and duration of silk growth. The pipeline presented here, which combines computer vision, machine learning and robotics, provides a powerful tool for large-scale genetic analyses of the control of reproductive growth to changes in environmental conditions in a non-invasive and automatized way. It is available as Open Source software in the OpenAlea platform.",project-academic
10.1088/1741-2552/AAE186,2018-10-10,a,IOP Publishing,gumpy a python toolbox suitable for hybrid brain computer interfaces," Objective None The objective of this work is to present gumpy, a new free and open source Python toolbox designed for hybrid brain-computer interface (BCI). None Approach None Gumpy provides state-of-the-art algorithms and includes a rich selection of signal processing methods that have been employed by the BCI community over the last 20 years. In addition, a wide range of classification methods that span from classical machine learning algorithms to deep neural network models are provided. Gumpy can be used for both EEG and EMG biosignal analysis, visualization, real-time streaming and decoding. None Results None The usage of the toolbox was demonstrated through two different offline example studies, namely movement prediction from EEG motor imagery, and the decoding of natural grasp movements with the applied finger forces from surface EMG (sEMG) signals. Additionally, gumpy was used for real-time control of a robot arm using steady-state visually evoked potentials (SSVEP) as well as for real-time prosthetic hand control using sEMG. Overall, obtained results with the gumpy toolbox are comparable or better than previously reported results on the same datasets. None Significance None Gumpy is a free and open source software, which allows end-users to perform online hybrid BCIs and provides different techniques for processing and decoding of EEG and EMG signals. More importantly, the achieved results reveal that gumpy's deep learning toolbox can match or outperform the state-of-the-art in terms of accuracy. This can therefore enable BCI researchers to develop more robust decoding algorithms using novel techniques and hence chart a route ahead for new BCI improvements.",project-academic
10.4018/IJCINI.2011070101,2011-07-01,a,IGI Global,semantic manipulations and formal ontology for machine learning based on concept algebra," Towards the formalization of ontological methodologies for dynamic machine learning and semantic analyses, a new form of denotational mathematics known as concept algebra is introduced. Concept Algebra CA is a denotational mathematical structure for formal knowledge representation and manipulation in machine learning and cognitive computing. CA provides a rigorous knowledge modeling and processing tool, which extends the informal, static, and application-specific ontological technologies to a formal, dynamic, and general mathematical means. An operational semantics for the calculus of CA is formally elaborated using a set of computational processes in real-time process algebra RTPA. A case study is presented on how machines, cognitive robots, and software agents may mimic the key ability of human beings to autonomously manipulate knowledge in generic learning using CA. This work demonstrates the expressive power and a wide range of applications of CA for both humans and machines in cognitive computing, semantic computing, machine learning, and computational intelligence.",project-academic
10.2139/SSRN.2931828,2017-03-01,a,,when artificial intelligence systems produce inventions the 3a era and an alternative model for patent law," Currently, robots, Artificial Intelligence and machine learning systems (hereinafter referred to collectively as “AI” or “AI systems”) can create inventions, which, had they been created by humans, would be eligible for patent protection. This study addresses the patentability of these inventions created by AI systems. We argue that traditional patent law has become outdated, inapplicable and irrelevant with respect to inventions created by AI systems. We call on policy makers to rethink current patent law governing AI systems and replace it with tools more applicable to the new (3A) era of advanced automated and autonomous AI systems. Our argument is based on three pillars: the features of AI systems, the Multiplayer Model and the irrelevance of theoretical justifications concerning intellectual property. In order to fully convey the ability of AI systems to create inventions, the article explains, for one the first times in the legal literature, what AI systems are, how they work and what makes them (so) intelligent. This understanding is crucial to any further discourse about AI systems. 

We identify eight crucial features of AI systems they are:

(1) creative; 

(2) unpredictable; 

(3) independent and autonomous; 

(4) rational; 

(5) evolving; 

(6) capable of data collection and communication; 

(7) efficient and accurate; and they 

(8) freely choose among alternative options. 

We argue that, due to these features, AI systems are capable of independently developing inventions which, had they been created by humans, would be patentable (and able to registered as patents). The traditional approach to patent law in which policy makers seek to identify the human inventor behind the patent is, therefore, no longer relevant. We are facing a new era of machines “acting” independently, with no human being behind the inventive act itself. 

The second pillar of our argument is the Multiplayer Model, which characterizes the long process through which inventions are created by AI systems. The Multiplayer Model, which is also almost absent in the current legal publications, describes the multiple participants and stakeholders, both overlapping and independent, involved in the process, including software programmers, data and feedback suppliers, trainers, system owners and operators, employers, the public and the government. The model conveys that the efforts of traditional patent law to identify a single inventor of these products and processes are no longer applicable. 

The third pillar of our argument is the irrelevancy of theoretical justifications such as personality and inventiveness/efficiency to inventions created by AI systems. In contrast to other scholars, we argue that traditional patent law is irrelevant and inapplicable to these situations, that these inventions should not be patentable at all and that other tools can achieve the same ends while promoting innovation and public disclosure. These other, non-patent incentives include commercial tools such as electronic and cyber controls over inventions, first-mover market advantages and license agreements. This proposal serves a gatekeeping function and is superior to a revision of the non-obviousness standard used by other scholars to afford patent protection to inventions by AI systems. In maintaining the traditional patents system by hunting for a “real” human inventor, policy makers exhibit a misunderstanding of advanced technology and AI systems features. We conclude with a discussion of the implications of our analysis for different legal regimes, such as tort, contracts and even criminal law.",project-academic
,2019-01-15,,,robot obstacle avoidance trajectory planning method and system based on deep learning," The invention provides a robot obstacle avoidance trajectory planning method and system based on deep learning. The robot obstacle avoidance trajectory planning method based on the deep learning comprises the following steps: adding a camera to a simulation environment, taking images from multiple angles and simultaneously inputting the images into a convolutional neural network; obtaining information of a robot arm updated angle according to the input information, and calling a simulation software to update through an interface to obtain a posture; and performing convolutional neural networktraining by means of the deep learning, transferring an obtained characteristic pattern to a one-dimensional vector after convolution operation is performed on the input images, inputting the one-dimensional vector into a subsequent fully connected layer to obtain a q value corresponding to each action, selecting the action with the largest q value and updating the posture, and sending the updatedposture to the simulation environment to obtain a new image input, and executing circularly until the target point is reached. The invention can realize the autonomous obstacle avoidance of an industrial robot and improve the industrial automation production capacity.",project-academic
10.1007/S10846-009-9329-7,2009-12-01,a,Springer Netherlands,closed loop control of robotic arc welding system with full penetration monitoring," The real-time detection of the state of the gap and weld penetration control are two fundamental issues in robotic arc welding. However, traditional robotic arc welding lacks external information feedback and the function of real-time adjusting. The objective of this research is to adopt new sensing techniques and artificial intelligence to ensure the stability of the welding process through controlling penetration depth and weld pool geometry. A novel arc welding robot system including function modules (visual modules, data acquisition modules) and corresponding software system was developed. Thus, the autonomy and intelligence of the arc welding robot system is realized. Aimed at solving welding penetration depth, a neural network (NN) model is developed to calculate the full penetration state, which is specified by the back-side bead width (Wb), from the top-side vision sensing technique. And then, a versatile algorithm developed to provide robust real-time processing of images for use with a vision-based computer control system is discussed. To this end, the peak current self adaptive regulating controller with weld gap compensation was designed in the robotic arc welding control system. Using this closed-loop control experiments have been conducted to verify the effectiveness of the proposed control system for the robotic arc welding process. The results show that the standard error of the Wb is 0.124 regardless of the variations in the state of the gap.",project-academic
,2018-10-17,p,"Institute of Control, Robotics and Systems (ICROS)",development of simulator for autonomous underwater vehicles utilizing underwater acoustic and optical sensing emulators," This paper addresses an autonomous underwater vehicle (AUV) simulator with underwater image sonar and optical vision emulation. Recently, various underwater missions have been automated through the great improvement in underwater image sonar and optical vision technology along with utilization of artificial intelligence. Development of the simulator that emulates underwater image sonar and optical vision can support intelligent underwater missions by visualizing and simulating virtual scenarios and reproducing real missions. In order to benefit from existing software, the presented simulator is based on ROS (Robot Operating System) environment integrated with our image sonar and optical vision emulators. When an underwater virtual scenario of terrain, target objects, and AUVs with sensors is plotted using standard 3-D modeling programs, the simulator configures the scenario and displays sonar and optical images. The ultrasound and light Beams are modeled as a set of rays each, and the image sonar and optical vision are modeled as objects detecting collisions between the rays and target objects at certain positions and orientations. The sonar images generated by the simulator are compared with real images to confirm the validity of the models.",project-academic
10.1109/ROMAN.2005.1513775,2005-10-03,p,IEEE,modularity and integration in the design of a socially interactive robot," Designing robots that are capable of interacting with humans in real life settings is a challenging task. One key issue is the integration of multiple modalities (e.g., mobility, physical structure, navigation, vision, audition, dialogue, reasoning) into a coherent framework. Taking the AAAI mobile robot challenge (making a robot attend the national conference on artificial intelligence) as the experimental context, we are currently addressing hardware, software and computation integration issues involved in designing a robot capable of sophisticated interaction with humans. This paper reports on our design solutions and the current status of the work, along with the potential impacts this design on human-robot interaction research.",project-academic
,2021-03-03,a,,learning to fly a gym environment with pybullet physics for reinforcement learning of multi agent quadcopter control," Robotic simulators are crucial for academic research and education as well as the development of safety-critical applications. Reinforcement learning environments -- simple simulations coupled with a problem specification in the form of a reward function -- are also important to standardize the development (and benchmarking) of learning algorithms. Yet, full-scale simulators typically lack portability and parallelizability. Vice versa, many reinforcement learning environments trade-off realism for high sample throughputs in toy-like problems. While public data sets have greatly benefited deep learning and computer vision, we still lack the software tools to simultaneously develop -- and fairly compare -- control theory and reinforcement learning approaches. In this paper, we propose an open-source OpenAI Gym-like environment for multiple quadcopters based on the Bullet physics engine. Its multi-agent and vision based reinforcement learning interfaces, as well as the support of realistic collisions and aerodynamic effects, make it, to the best of our knowledge, a first of its kind. We demonstrate its use through several examples, either for control (trajectory tracking with PID control, multi-robot flight with downwash, etc.) or reinforcement learning (single and multi-agent stabilization tasks), hoping to inspire future research that combines control theory and machine learning.",project-academic
10.1109/EEEI.2014.7005895,2014-12-01,p,IEEE,verification of safety for autonomous unmanned ground vehicles," The existing tools for hardware and software reliability and safety engineering do not supply sufficient solutions regarding AI (Artificial Intelligent) adaptive and learning algorithms, which are being used in autonomous robotics and massively rely on designer experience and include methods such as Heuristic, Rules based decision, Fuzzy Logic, Neural Networks, and Genetic Algorithms, Bayes Networks, etc. Since it is obvious that only this kind of algorithms can deal with the complexity and the uncertainty of the real world environment, suitable safety validation methodology is required. In this paper we present the limitation of the existing reliability and safety engineering tools in dealing with autonomous systems and propose a novel methodology based on statistical testing in simulated environment.",project-academic
,2020-02-11,a,,a single rgb camera based gait analysis with a mobile tele robot for healthcare," With the increasing awareness of high-quality life, there is a growing need for health monitoring devices running robust algorithms in home environment. Health monitoring technologies enable real-time analysis of users' health status, offering long-term healthcare support and reducing hospitalization time. The purpose of this work is twofold, the software focuses on the analysis of gait, which is widely adopted for joint correction and assessing any lower limb or spinal problem. On the hardware side, we design a novel marker-less gait analysis device using a low-cost RGB camera mounted on a mobile tele-robot. As gait analysis with a single camera is much more challenging compared to previous works utilizing multi-cameras, a RGB-D camera or wearable sensors, we propose using vision-based human pose estimation approaches. More specifically, based on the output of two state-of-the-art human pose estimation models (Openpose and VNect), we devise measurements for four bespoke gait parameters: inversion/eversion, dorsiflexion/plantarflexion, ankle and foot progression angles. We thereby classify walking patterns into normal, supination, pronation and limp. We also illustrate how to run the purposed machine learning models in low-resource environments such as a single entry-level CPU. Experiments show that our single RGB camera method achieves competitive performance compared to state-of-the-art methods based on depth cameras or multi-camera motion capture system, at smaller hardware costs.",project-academic
10.1109/IROS.2010.5650765,2010-12-03,p,IEEE,the design of leo a 2d bipedal walking robot for online autonomous reinforcement learning," Real robots demonstrating online Reinforcement Learning (RL) to learn new tasks are hard to find. The specific properties and limitations of real robots have a large impact on their suitability for RL experiments. In this work, we derive the main hardware and software requirements that a RL robot should fulfill, and present our biped robot LEO that was specifically designed to meet these requirements. We verify its aptitude in autonomous walking experiments using a pre-programmed controller. Although there is room for improvement in the design, the robot was able to walk, fall and stand up without human intervention for 8 hours, during which it made over 43; 000 footsteps.",project-academic
10.3390/SU10093142,2018-09-01,a,MDPI AG,a systematic review of smart real estate technology drivers of and barriers to the use of digital disruptive technologies and online platforms," Real estate needs to improve its adoption of disruptive technologies to move from traditional to smart real estate (SRE). This study reviews the adoption of disruptive technologies in real estate. It covers the applications of nine such technologies, hereby referred to as the Big9. These are: drones, the internet of things (IoT), clouds, software as a service (SaaS), big data, 3D scanning, wearable technologies, virtual and augmented realities (VR and AR), and artificial intelligence (AI) and robotics. The Big9 are examined in terms of their application to real estate and how they can furnish consumers with the kind of information that can avert regrets. The review is based on 213 published articles. The compiled results show the state of each technology’s practice and usage in real estate. This review also surveys dissemination mechanisms, including smartphone technology, websites and social media-based online platforms, as well as the core components of SRE: sustainability, innovative technology and user centredness. It identifies four key real estate stakeholders—consumers, agents and associations, government and regulatory authorities, and complementary industries—and their needs, such as buying or selling property, profits, taxes, business and/or other factors. Interactions between these stakeholders are highlighted, and the specific needs that various technologies address are tabulated in the form of a what, who and how analysis to highlight the impact that the technologies have on key stakeholders. Finally, stakeholder needs as identified in the previous steps are matched theoretically with six extensions of the traditionally accepted technology adoption model (TAM), paving the way for a smoother transition to technology-based benefits for consumers. The findings pertinent to the Big9 technologies in the form of opportunities, potential losses and exploitation levels (OPLEL) analyses highlight the potential utilisation of each technology for addressing consumers’ needs and minimizing their regrets. Additionally, the tabulated findings in the form of what, how and who links the Big9 technologies to core consumers’ needs and provides a list of resources needed to ensure proper information dissemination to the stakeholders. Such high-quality information can bridge the gap between real estate consumers and other stakeholders and raise the state of the industry to a level where its consumers have fewer or no regrets. The study, being the first to explore real estate technologies, is limited by the number of research publications on the SRE technologies that has been compensated through incorporation of online reports.",project-academic
10.2196/REHAB.3151,2014-10-07,a,"JMIR Publications Inc., Toronto, Canada",therapist towards an autonomous socially interactive robot for motor and neurorehabilitation therapies for children," Background: Neurorehabilitation therapies exploiting the use-dependent plasticity of our neuromuscular system are devised to help patients who suffer from injuries or diseases of this system. These therapies take advantage of the fact that the motor activity alters the properties of our neurons and muscles, including the pattern of their connectivity, and thus their functionality. Hence, a sensor-motor treatment where patients makes certain movements will help them (re)learn how to move the affected body parts. But these traditional rehabilitation processes are usually repetitive and lengthy, reducing motivation and adherence to the treatment, and thus limiting the benefits for the patients. Objective: Our goal was to create innovative neurorehabilitation therapies based on THERAPIST, a socially assistive robot. THERAPIST is an autonomous robot that is able to find and execute plans and adapt them to new situations in real-time. The software architecture of THERAPIST monitors and determines the course of action, learns from previous experiences, and interacts with people using verbal and non-verbal channels. THERAPIST can increase the adherence of the patient to the sessions using serious games. Data are recorded and can be used to tailor patient sessions. Methods: We hypothesized that pediatric patients would engage better in a therapeutic non-physical interaction with a robot, facilitating the design of new therapies to improve patient motivation. We propose RoboCog, a novel cognitive architecture. This architecture will enhance the effectiveness and time-of-response of complex multi-degree-of-freedom robots designed to collaborate with humans, combining two core elements: a deep and hybrid representation of the current state, own, and observed; and a set of task-dependent planners, working at different levels of abstraction but connected to this central representation through a common interface. Using RoboCog, THERAPIST engages the human partner in an active interactive process. But RoboCog also endows the robot with abilities for high-level planning, monitoring, and learning. Thus, THERAPIST engages the patient through different games or activities, and adapts the session to each individual. Results: RoboCog successfully integrates a deliberative planner with a set of modules working at situational or sensorimotor levels. This architecture also allows THERAPIST to deliver responses at a human rate. The synchronization of the multiple interaction modalities results from a unique scene representation or model. THERAPIST is now a socially interactive robot that, instead of reproducing the phrases or gestures that the developers decide, maintains a dialogue and autonomously generate gestures or expressions. THERAPIST is able to play simple games with human partners, which requires humans to perform certain movements, and also to capture the human motion, for later analysis by clinic specialists. Conclusions: The initial hypothesis was validated by our experimental studies showing that interaction with the robot results in highly attentive and collaborative attitudes in pediatric patients. We also verified that RoboCog allows the robot to interact with patients at human rates. However, there remain many issues to overcome. The development of novel hands-off rehabilitation therapies will require the intersection of multiple challenging directions of research that we are currently exploring. None [JMIR Rehabil Assist Technol 2014;1(1):e1]",project-academic
10.1109/TLT.2018.2833111,2019-07-01,a,IEEE,inquiry based learning with robogen an open source software and hardware platform for robotics and artificial intelligence," It has often been found that students appreciate hands-on work, and find that they learn more with courses that include a project than those relying solely on conventional lectures and tests. This type of project driven learning is a key component of “Inquiry-based learning” (IBL), which aims at teaching methodology as well as content by incorporating the student as an actor rather than a spectator. Robotics applications are especially well-suited for IBL due to the value of trial and error experience, the multiple possibilities for students to implement their own ideas, and the importance of programming, problem-solving, and electro-mechanical skills in real world engineering and science jobs. Furthermore, robotics platforms can be useful teaching media and learning tools for a variety of topics. Here, we present RoboGen: an open-source, web-based, software, and hardware platform for Robotics and Artificial Intelligence with a particular focus on Evolutionary Robotics. We describe the platform in detail, compare it to existing alternatives, and present results of its use as a platform for Inquiry-based learning within a master's level course at the Ecole Polytechnique Federale de Lausanne.",project-academic
10.3390/INFO5010001,2013-12-24,a,MDPI AG,the sp theory of intelligence benefits and applications," This article describes existing and expected benefits of the SP theory ofintelligence, and some potential applications. The theory aims to simplify and integrate ideasacross artificial intelligence, mainstream computing, and human perception and cognition,with information compression as a unifying theme. It combines conceptual simplicitywith descriptive and explanatory power across several areas of computing and cognition.In the SP machine—an expression of the SP theory which is currently realized in theform of a computer model—there is potential for an overall simplification of computingsystems, including software. The SP theory promises deeper insights and better solutions inseveral areas of application including, most notably, unsupervised learning, natural languageprocessing, autonomous robots, computer vision, intelligent databases, software engineering,information compression, medical diagnosis and big data. There is also potential inareas such as the semantic web, bioinformatics, structuring of documents, the detection ofcomputer viruses, data fusion, new kinds of computer, and the development of scientifictheories. The theory promises seamless integration of structures and functions within andbetween different areas of application. The potential value, worldwide, of these benefits andapplications is at least $190 billion each year. Further development would be facilitatedby the creation of a high-parallel, open-source version of the SP machine, available toresearchers everywhere.",project-academic
10.1109/IROS40897.2019.8968514,2019-11-01,p,IEEE,timepix radiation detector for autonomous radiation localization and mapping by micro unmanned vehicles," A system for measuring radiation intensity and for radiation mapping by a micro unmanned robot using the Timepix detector is presented in this paper. Timepix detectors are extremely small, but powerful 14 × 14 mm, 256 × 256 px CMOS hybrid pixel detectors, capable of measuring ionizing alpha, beta, gamma radiation, and heaving ions. The detectors, developed at CERN, produce an image free of any digital noise thanks to per-pixel calibration and signal digitization. Traces of individual ionizing particles passing through the sensors can be resolved in the detector images. Particle type and energy estimates can be extracted automatically using machine learning algorithms. This opens unique possibilities in the task of flexible radiation detection by very small unmanned robotic platforms. The detectors are well suited for the use of mobile robots thanks to their small size, lightweight, and minimal power consumption. This sensor is especially appealing for micro aerial vehicles due to their high maneuverability, which can increase the range and resolution of such novel sensory system. We present a ROS-based readout software and real-time image processing pipeline and review options for 3-D localization of radiation sources using pixel detectors. The provided software supports off-the-shelf FITPix, USB Lite readout electronics with Timepix detectors.",project-academic
,2019-03-14,a,,gym gazebo2 a toolkit for reinforcement learning using ros 2 and gazebo," This paper presents an upgraded, real world application oriented version of gym-gazebo, the Robot Operating System (ROS) and Gazebo based Reinforcement Learning (RL) toolkit, which complies with OpenAI Gym. The content discusses the new ROS 2 based software architecture and summarizes the results obtained using Proximal Policy Optimization (PPO). Ultimately, the output of this work presents a benchmarking system for robotics that allows different techniques and algorithms to be compared using the same virtual conditions. We have evaluated environments with different levels of complexity of the Modular Articulated Robotic Arm (MARA), reaching accuracies in the millimeter scale. The converged results show the feasibility and usefulness of the gym-gazebo 2 toolkit, its potential and applicability in industrial use cases, using modular robots.",project-academic
10.1023/A:1008607721339,1997-01-01,p,Kluwer Academic Publishers,test case generation as an ai planning problem," While Artificial Intelligence techniques have been applied to a variety of software engineering applications, the area of automated software testing remains largely unexplored. Yet, test cases for certain types of systems (e.g., those with command language interfaces and transaction based systems) are similar to plans. We have exploited this similarity by constructing an automated test case generator with an AI planning system at its core. We compared the functionality and output of two systems, one based on Software Engineering techniques and the other on planning, for a real application: the StorageTek robot tape library command language. From this, we showed that AI planning is a viable technique for test case generation and that the two approaches are complementary in their capabilities.",project-academic
,2007-08-08,,,intelligent labyrinth robot," The utility model relates to an intelligent labyrinth robot belonging to artificial intelligence field, which comprises two independently controlled driving wheels (6), a front middle universal wheel (1), a holding frame (9), a microprocessor and a sensor system, wherein, the two driving wheels (6) are connected with the universal wheel (1) through the holding frame (9) to form the chassis of the robot; the sensor system includes three sets of infrared transmitting-receiving sensors 4, first photoelectric sensors 2 and second photoelectric sensors 7 all connected with the microprocessor; the microprocessor controls the operating of the electrical motor according to input signals so as to control the walking and steering of the robot. The utility model realizes independent labyrinth search and intelligent memory and judgment of optimum path with the support of software; meanwhile, fewer sensors are adopted, thereby reducing probability of misoperation and improving systematic stability.",project-academic
10.15406/IRATJ.2019.05.00182,2019-05-16,p,"MedCrave Group, LLC",system retraining to professional competences of cognitive robots on basis of communicative associative logic of technological thinking, There are two main approaches to hardware software realization of imitative thinking of cognitive robots First approach is machine learning Such cognitive robots are used in services industry for the commercial and entertaining purposes In article approach to creation of cognitive robots on the basis of modeling of communicative and associative logic of imitative thinking of the person is considered Cognitive robots on the basis of modeling of communicative and associative logic of imitative thinking of the person are used as lecturers and consultants Also in professional activity when concepts and competences are strictly defined The communicative and associative logic of thinking allows to create the symbolical conceiving robot capable to study realize information requirements tasks to train subject areas to communicate with the help of the speech to read and write in various languages The robot on the basis of symbolical language communicative logic solves a problem of the automated imitation of imitative thinking with associative and communicative symbolical language elements of knowledge The main practical objectives of imitation of imitative thinking are drawing up the intrinsic focused dictionaries of the developed subject domains of knowledge and standard information requirements drawing up standard procedures of realization of information requirements formation of networks from communicative and associative symbolical language elements of knowledge of subject domains expansion of a natural language to functional creation of systems of speech and text communication in a natural language and recognitions of the speech of interlocutors In article the system of retraining to professional competences of robots androids is considered on the basis of communicative associative logic of technological thinking by cognitive methods,project-academic
10.1016/J.ESWA.2019.06.066,2019-12-15,a,Pergamon,double q pid algorithm for mobile robot control," Abstract None None Many expert systems have been developed for self-adaptive PID controllers of mobile robots. However, the high computational requirements of the expert systems layers, developed for the tuning of the PID controllers, still require previous expert knowledge and high efficiency in algorithmic and software execution for real-time applications. To address these problems, in this paper we propose an expert agent-based system, based on a reinforcement learning agent, for self-adapting multiple low-level PID controllers in mobile robots. For the formulation of the artificial expert agent, we develop an incremental model-free algorithm version of the double None Q -Learning algorithm for fast on-line adaptation of multiple low-level PID controllers. Fast learning and high on-line adaptability of the artificial expert agent is achieved by means of a proposed incremental active-learning exploration-exploitation procedure, for a non-uniform state space exploration, along with an experience replay mechanism for multiple value functions updates in the double None Q -learning algorithm. A comprehensive comparative simulation study and experiments in a real mobile robot demonstrate the high performance of the proposed algorithm for a real-time simultaneous tuning of multiple adaptive low-level PID controllers of mobile robots in real world conditions.",project-academic
10.1145/3159450.3162200,2018-02-21,p,ACM Press,calypso for cozmo robotic ai for everyone abstract only," In light of our field/s progress in making programming accessible to novices, we contemplate an even more ambitious goal: make AI accessible to all. The Cozmo robot by Anki is revolutionizing consumer and educational robotics through built-in computer vision and artificial intelligence algorithms. Calypso is a scaffolded robot programming environment for Cozmo inspired by Microsoft/s Kodu Game Lab. Calypso allows novices to program with advanced features such as visual recognition of objects and faces, simultaneous localization and mapping (SLAM), landmark-based navigation, and speech input. Like Kodu, Calypso emphasizes rule-based programming with high-level primitives such as ""see"", ""hear"", ""move toward"", and ""grab"", and it uses an Xbox game controller as its primary interface. User testing of Calypso has shown that children as young as eight can easily use it to program Cozmo. None None This demo will show off some of Calypso/s most striking features, including real-time graphical display of the robot/s world map, object detection with OpenCV, and speech recognition. We will share a Calypso curriculum that can be adapted to students from primary school through undergraduates. The demo will conclude with a discussion of the changes coming in both K-12 and undergraduate robotics instruction as we move from simple control of servos to true vision-guided mobile manipulators. For an advance look at Calypso, please see https://Calypso.software.",project-academic
,2007-01-01,p,,supporting interaction in the robocare intelligent assistive environment," The ROBOCARE project is aimed at creating an instance of integrated environment with software and robotic agents to actively assist an elderly person at home. In particular the project has synthesized a proactive environment for continuous daily activity monitoring in which an autonomous robot acts as a main interactor with the person. This paper accounts for the combination of features that create interactive capabilities for personalized and mixed-initiative interaction with the assisted person. A project with an intelligent assistant The use of intelligent technology for supporting elderly people at home has been addressed in various research projects in the last years (Pollack et al. 2003; Pineau et al. 2003; Haigh et al. 2003; Pollack 2005). Increasing attention is also given to the synthesis of Cognitive Systems to produce aids that enhance human cognition capabilities. As an example, the project CALO (Myers 2006; Myers & Yorke-Smith 2005) has as its primary goal the development of cognitive systems able to reason, learn from experience, be told what to do, explain what they are doing, reflect on their experience, and respond robustly to contingencies. Other projects somehow connected to different aspects of this research topic are CMRADAR (Modi et al. 2004), whose aim is to develop an intelligent scheduler assistant, and CAMEO (Rybski et al. 2004) whose main objective is to build a physical awareness system to be used by an agent-based electronic assistant. All these projects have required the orchestration of different intelligent software technologies and have highlighted a number of important issues that need to be addressed: the problem of coordinating the distributed components as well as the problem of providing intelligent interaction with the user, are undoubtedly among the most critical. The ROBOCARE project shares several of the challenges with the above mentioned projects. Indeed ROBOCARE’s main motivations can be summarized as follows: “The objective of this project is to build a distributed multi-agent system which provides assistance services Copyright c © 2007, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. Quote from the original project proposal. for elderly users at home. The agents are a highly heterogeneous collection of fixed and mobile robotic, sensory and problem solving components. The project is centered on obtaining a virtual community of human and artificial agents who cooperate in the continuous management of an enclosed environment.” The project has involved research groups with different background with the goal of investigating how state of the art AI techniques could be combined to create new homeservice integration for elderly people (Cesta et al. 2003; Cesta & Pecora 2006; Bahadori et al. 2004). As a target domain we have chosen a prototypical home environment where the presence of an intelligent assistant would be of concrete help in the daily life of a cognitively impaired user through the integrated performance of advanced distributed components. The most important capability of an intelligent assistant is the continuous maintenance of a high level of situation awareness. This objective is obtained through the interaction of a number of intelligent physical and/or software agents: among others, vision-based sensors, which ensure the acquisition of continuously updated data from the environment; a schedule management software agent, which analyzes the status of every activity being performed within the monitored space; a mobile robotic platform able to behave robustly and continuously in the environment. The ultimate goal of the overall system is to provide cognitive support both on-demand, by guaranteeing a real-time questiona Bahadori et al. 2004). In this light the demonstrator in Figure 1(a), is a basic example of home Activity Monitor grounded on scheduling technology. Notice that, on its own, the domestic activity monitor acts as a “silent observer” and does not take initiative with respect to the elder person in any way. In this paper, we show how its indications can be There is plenty of recent research on activity recognition with sensors, e.g., (Pentney et al. 2006), that could potentially impact this class of applications. Further details on the Activity Monitor will be presented later",project-academic
10.1007/978-3-030-00308-1_25,2017-07-27,p,"Springer, Cham",the nao backpack an open hardware add on for fast software development with the nao robot," We present an open-source accessory for the NAO robot, which enables to test computationally demanding algorithms in an external platform while preserving robot’s autonomy and mobility. The platform has the form of a backpack, which can be 3D printed and replicated, and holds an ODROID XU4 board to process algorithms externally with ROS compatibility. We provide also a software bridge between the B-Human’s framework and ROS to have access to the robot’s sensors close to real-time. We tested the platform in several robotics applications such as data logging, visual SLAM, and robot vision with deep learning techniques. The CAD model, hardware specifications and software are available online for the benefit of the community.",project-academic
10.1007/978-3-030-00308-1,2017-06-20,a,,the nao backpack an open hardware add on for fast software development with the nao robot," We present an open-source accessory for the NAO robot, which enables to test computationally demanding algorithms in an external platform while preserving robot's autonomy and mobility. The platform has the form of a backpack, which can be 3D printed and replicated, and holds an ODROID XU4 board to process algorithms externally with ROS compatibility. We provide also a software bridge between the B-Human's framework and ROS to have access to the robot's sensors close to real-time. We tested the platform in several robotics applications such as data logging, visual SLAM, and robot vision with deep learning techniques. The CAD model, hardware specifications and software are available online for the benefit of the community: this https URL",project-academic
10.1371/JOURNAL.PONE.0165600,2016-11-02,a,Public Library of Science,a novel robot system integrating biological and mechanical intelligence based on dissociated neural network controlled closed loop environment," We propose the architecture of a novel robot system merging biological and artificial intelligence based on a neural controller connected to an external agent. We initially built a framework that connected the dissociated neural network to a mobile robot system to implement a realistic vehicle. The mobile robot system characterized by a camera and two-wheeled robot was designed to execute the target-searching task. We modified a software architecture and developed a home-made stimulation generator to build a bi-directional connection between the biological and the artificial components via simple binomial coding/decoding schemes. In this paper, we utilized a specific hierarchical dissociated neural network for the first time as the neural controller. Based on our work, neural cultures were successfully employed to control an artificial agent resulting in high performance. Surprisingly, under the tetanus stimulus training, the robot performed better and better with the increasement of training cycle because of the short-term plasticity of neural network (a kind of reinforced learning). Comparing to the work previously reported, we adopted an effective experimental proposal (i.e. increasing the training cycle) to make sure of the occurrence of the short-term plasticity, and preliminarily demonstrated that the improvement of the robot’s performance could be caused independently by the plasticity development of dissociated neural network. This new framework may provide some possible solutions for the learning abilities of intelligent robots by the engineering application of the plasticity processing of neural networks, also for the development of theoretical inspiration for the next generation neuro-prostheses on the basis of the bi-directional exchange of information within the hierarchical neural networks.",project-academic
,2009-08-14,,,self evolving artificial intelligent cyber robot system," A self-evolving cyber robot is provided to make and evolve a personal cyber robot of a user to make various artificial intelligence robots. A user terminal(100) performs the creation and growth of a personal cyber robot having the knowledge of a user. An application software server(310) is connected with the user terminal through the cyber space(300) to perform the provision and management of all software. A robot management server(330) synchronizes information in real time, provides various robots, stores/manages the robot information, and guides the information of a connected user.",project-academic
,2017-06-23,,,intelligent decision making system applied to robot software engineer," An embodiment of the invention discloses an intelligent decision-making system applied to a robot software engineer. The system comprises an application interface unit, a software control unit, and a decision-making control unit, wherein the application interface unit is used for realizing logic connections between a man and a machine, between machines, between the machine and software, and between the machine and a network, and providing interfaces for mutual communication; and the software control unit cooperates with the application interface unit and the decision-making control unit, obtains a software design instruction through the man-machine interface, and writes software codes and design documents by applying artificial intelligence according to the software design instruction. The compilable software codes and software design documents are output. The system provides high-quality software and services with low price and shorter development cycle, changes a conventional software development concept, and forms a brand-new software development mode. A robot becomes a necessary new member of a software development team.",project-academic
10.1007/978-3-540-77465-5,2008-03-20,b,"Springer Publishing Company, Incorporated",soft computing applications in industry," Softcomputing techniques play a vital role in the industry. This book presents several important papers presented by some of the well-known scientists from all over the globe. The application domains discussed in this book include: agroecology, bioinformatics, branched fluid-transport network layout design, dam scheduling, data analysis and exploration, detection of phishing attacks, distributed terrestrial transportation, fault detection of motors, fault diagnosis of electronic circuits, fault diagnosis of power distribution systems, flood routing, hazard sensing, health care, industrial chemical processes, knowledge management in software development, local multipoint distribution systems, missing data estimation, parameter calibration of rainfall intensity models, parameter identification for systems engineering, petroleum vessel mooring, query answering in P2P systems, real-time strategy games, robot control, satellite heat pipe design, monsoon rainfall forecasting, structural design, tool condition monitoring, vehicle routing, water network design, etc. The softcomputing techniques presented in this book are on (or closely related to): ant-colony optimization, artificial immune systems, artificial neural networks, Bayesian models, case-based reasoning, clustering techniques, differential evolution, fuzzy classification, fuzzy neural networks, genetic algorithms, harmony search, hidden Markov models, locally weighted regression analysis, probabilistic principal component analysis, relevance vector machines, self-organizing maps, other machine learning and statistical techniques, and the combinations of the above techniques.",project-academic
10.1007/978-3-030-27544-0_36,2018-06-18,p,"Springer, Cham",nimbro robots winning robocup 2018 humanoid adultsize soccer competitions," Over the past few years, the Humanoid League rules have changed towards more realistic and challenging game environments, which encourage teams to advance their robot soccer performances. In this paper, we present the software and hardware designs that led our team NimbRo to win the competitions in the AdultSize league—including the soccer tournament, the drop-in games, and the technical challenges at RoboCup 2018 in Montreal. Altogether, this resulted in NimbRo winning the Best Humanoid Award. In particular, we describe our deep-learning approaches for visual perception and our new fully 3D printed robot NimbRo-OP2X.",project-academic
,2019-09-05,a,,nimbro robots winning robocup 2018 humanoid adultsize soccer competitions," Over the past few years, the Humanoid League rules have changed towards more realistic and challenging game environments, which encourage teams to advance their robot soccer performances. In this paper, we present the software and hardware designs that led our team NimbRo to win the competitions in the AdultSize league -- including the soccer tournament, the drop-in games, and the technical challenges at RoboCup 2018 in Montreal. Altogether, this resulted in NimbRo winning the Best Humanoid Award. In particular, we describe our deep-learning approaches for visual perception and our new fully 3D printed robot NimbRo-OP2X.",project-academic
10.3389/FNBOT.2016.00014,2016-11-02,a,Frontiers,developing dynamic field theory architectures for embodied cognitive systems with cedar," Embodied artificial cognitive systems such as autonomous robots or intelligent observers connect cognitive processes to sensory and effector systems in real time. Prime candidates for such embodied intelligence are neurally inspired architectures. While components such as forward neural networks are well established, designing pervasively autonomous neural architectures remains a challenge. This includes the problem of tuning the parameters of such architectures so that they deliver specified functionality under variable environmental conditions and retain these functions as the architectures are expanded. The scaling and autonomy problems are solved, in part, by dynamic field theory (DFT), a theoretical framework for the neural grounding of sensorimotor and cognitive processes. In this paper, we address how to efficiently build DFT architectures that control embodied agents and how to tune their parameters so that the desired cognitive functions emerge while such agents are situated in real environments. In DFT architectures, dynamic neural fields or nodes are assigned dynamic regimes, that is, attractor states and their instabilities, from which cognitive function emerges. Tuning thus amounts to determining values of the dynamic parameters for which the components of a DFT architecture are in the specified dynamic regime under the appropriate environmental conditions. The process of tuning is facilitated by the software framework cedar, which provides a graphical interface to build and execute DFT architectures. It enables to change dynamic parameters online and visualize the activation states of any component while the agent is receiving sensory inputs in real-time. Using a simple example, we take the reader through the workflow of conceiving of DFT architectures, implementing them on embodied agents, tuning their parameters, and assessing performance while the system is coupled to real sensory inputs.",project-academic
10.1007/S10514-006-9014-7,2007-05-01,a,Springer US,spartacus attending the 2005 aaai conference," Spartacus is our robot entry in the 2005 AAAI Mobile Robot Challenge, making a robot attend the National Conference on Artificial Intelligence. Designing robots that are capable of interacting with humans in real-life settings can be considered the ultimate challenge when it comes to intelligent autonomous systems. One key issue is the integration of multiple modalities (e.g., mobility, physical structure, navigation, vision, audition, dialogue, reasoning). Such integration increases the diversity and also the complexity of interactions the robot can generate. It also makes it difficult to monitor how such increased capabilities are used in unconstrained conditions, whether it is done while the robot is in operation of afterwards. This paper reports solutions and findings resulting from our hardware, software and decisional integration work on Spartacus. It also outlines perspectives in making intelligent and interaction capabilities evolve for autonomous robots.",project-academic
,2018-11-16,,,robot industrial sorting method based on cloud terminal deep learning," The invention discloses a robot industrial sorting method based on cloud terminal deep learning, and relates to the field of robot industrial automation. Relatively simple item refining and sorting can be realized. The robot industrial sorting method includes an industrial camera, a computer, a UR5 robot (mechanical arm bodies and a control box). The Gige industrial camera, the computer, and the UR5 robot are connected by using a PCi-E interface, wherein a Halcon software is further installed in the computer, and the UR5 robot is connected by using a socket communication mode. A sorting program is written on a demonstrator of the UR5 robot, and the programming language on the demonstrator is a UR-specific UR script. The robot industrial sorting method is suitable for automatic sorting of robots.",project-academic
10.15622/SP.18.1.123-147,2019-02-21,a,St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences,predictive assessment of operator s hand trajectory with the copying type of control for solution of the inverse dynamic problem," The most important task of modern robotics is the development of robots to perform the work in potentially dangerous fields which can cause the risk to human health. Currently robotic systems can not become a full replacement for man for solving complex problems in a dynamic environment despite an active development of artificial intelligence technologies.
The robots that implement the copying type of control or the so-called virtual presence of the operator are the most advanced for use in the nearest future. The principle of copying control is based on the motion capture of the remote operator and the formation of control signals for the robot’s drives. A tracking system or systems based on movement planning can be used to control the drives. The tracking systems are simpler, but systems based on motion planning allow to achieve more smooth motion and less wear on the parts of the control object. An artificial delay between the movements of the operator and the control object for necessary data collection  is used  to implement the control-based motion planning.
The aim of research is a reduction of delay, which appears when controlling the anthropomorphic manipulator drives based on the solution of the inverse dynamic problem, when real time copying type of control is used . For motion path planning it is proposed to use forecast values of the generalized coordinates for manipulator. Based on the measured values of the generalized coordinates of the operator's hand, time series are formed and their prediction is performed. Predictive values of generalized coordinates are used in planning the anthropomorphic manipulator trajectory and solving the inverse dynamic problem. Prediction is based on linear regression with relatively low computational complexity, which is an important criterion for the system operation in the real time operation mode. The developed mathematical apparatus, based on prediction parameters and maximum permissible accelerations of the manipulator drives, allows to find a theoretical estimate of error values limits for planning the operator's hand trajectory using the proposed approach for specific tasks. The adequacy of the maximum theoretical value of the prediction error, as well as the prospects of the proposed approach for testing in practice is confirmed by the software simulation in Matlab environment.",project-academic
10.1109/ACCESS.2015.2513822,2016-01-01,a,IEEE,the sp theory of intelligence distinctive features and advantages," This paper aims to highlight distinctive features of the SP theory of intelligence, realized in the SP computer model, and its apparent advantages compared with some AI-related alternatives. Perhaps most importantly, the theory simplifies and integrates observations and concepts in AI-related areas, and has potential to simplify and integrate of structures and processes in computing systems. Unlike most other AI-related theories, the SP theory is itself a theory of computing, which can be the basis for new architectures for computers. Fundamental in the theory is information compression via the matching and unification of patterns and, more specifically, via a concept of multiple alignment. The theory promotes transparency in the representation and processing of knowledge, and unsupervised learning of natural structures via information compression. It provides an interpretation of aspects of mathematics and an interpretation of phenomena in human perception and cognition. concepts in the theory may be realized in terms of neurons and their inter-connections (SP-neural). These features and advantages of the SP system are discussed in relation to AI-related alternatives: the concept of minimum length encoding and related concepts, how computational and energy efficiency in computing may be achieved, deep learning in neural networks, unified theories of cognition and related research, universal search, Bayesian networks and some other models for AI, IBM’s Watson, solving problems associated with big data and in the development of intelligence in autonomous robots, pattern recognition and vision, the learning and processing of natural language, exact and inexact forms of reasoning, representation and processing of diverse forms of knowledge, and software engineering. In conclusion, the SP system can provide a firm foundation for the long-term development of AI and related areas, and at the same time, it may deliver useful results on relatively short timescales.",project-academic
10.1007/S12083-015-0339-X,2016-03-01,a,Springer US,peer to peer trade in htm5 meta model for agent oriented cloud robotic systems," Cloud computing is a methodology and not a technology. Adaptation of cloud computing services for robotic applications is relatively straightforward while adaptation of underlying ideas will require a new design attitude. Cloud computing is a cost-effective and dynamic business model. Currently cloud robotics is understood as a client server methodology which enables robots utilize resources and services placed at centralized servers. These cloud servers treat robots as any other client computer offering them platform, infrastructure, process or algorithm as a service. HTM5 is an OMG MDA based multi-view meta-model for agent oriented development of cloud robotic systems. HTM5 encourages design of peer-to-peer service ecosystems based on an open registry and matchmaking mechanism. In peer-to-peer cloud robotics, a robot can trade its hardware, software and functional resources as a service to other robots in the ecosystem. The peer-to-peer trade in such systems may be driven by contracts and relationships between its member agents. This article discusses trade-view model of HTM5 methodology and its use in developing a cloud robotic ecosystem that implements peer-to-peer, contract based economy. The article also presents a case study with experiments that implement distributed artificial intelligence and peer-to-peer service oriented trade on simulated and real robot colonies.",project-academic
10.1016/J.PROCIR.2018.01.021,2018-01-01,a,Elsevier BV,industrial robot control with object recognition based on deep learning," Abstract None None Although existing industrial robots are able to work in challenging environments, accomplish high-precision assignments, as well as help to enhance and increase productivity, most of this are still operated with prebuilt commandos and robot programs. Given the pressure of labor costs and fierce competition, there is a tremendous shortage of autonomous and intelligent robots and cyber-physical systems with the ability of perception and decision in coming Industry 4.0 application. These intelligent robots are able to analyze their tasks by selecting appropriate tools, planning their movements and executing suitable operations, in the same way as a trained human worker would do. None In this paper, an industrial robot UR5 is allowed to perceive, locate and interact with different objects such as tools and office supplies. Using a stereo vision camera, it is possible to obtain both RGB- and Depth-data of the robots surrounding and workspace. This data is fed into a Deep Learning Faster-RCNN Network to realize the recognition and localization of present objects out of 50 different classes. With the derived information, proper operations can be planed and executed. None The experimental results prove a successful recognition and gripping of reachable objects in the robot’s workspace or suitable feedback for unreachable objects. This work confirms the possibility of using current Deep Learning algorithms in combination with industrial robots to build intelligent systems. The configuration will become increasingly useful for automation and assembly technologies in upcoming Industry 4.0 applications with further developed hardware and software algorithms. Thus representing a significant milestone in the construction of intelligent robots and laying the foundation for future work.",project-academic
10.1109/AHS.2007.37,2007-08-05,p,IEEE,automatic synthesis of fault detection modules for mobile robots," In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",project-academic
10.1097/SCS.0000000000005587,2020-03-01,a,Ovid Technologies (Wolters Kluwer Health),fully automatic robot assisted surgery for mandibular angle split osteotomy," With the development of computer-assisted surgery, preoperational design is detailed in software. However, it is still a challenge for surgeons to realize the surgical plan in the craniofacial surgery. Robot-assisted surgery has advantages of high accuracy and stability. It is suitable for the high-stress procedures like drilling, milling, and cutting. This study aims to verify the feasibility for automatic drilling without soft tissues in model test based on an industrial robot platform.This study chose the data from digital laboratory in Shanghai 9th People's Hospital. The mandibular was reconstructed in software and surgical plan was also designed. Then, the coordinate data was input to the robot's software and matrix conversion was calculated by 4 marked points. The trajectory generation was calculated by inverse kinematics for target coordinates and robot coordinates. The model was fixed and calibrated for automatic drilling. At last, the accuracy was calculated by optic scanning instrument.The installment and preparation cost 10 minutes, the drilling procedure cost 12 minutes. The outside position error was (1.71 ± 0.16) mm, the inside position error was (1.37 ± 0.28) mm, the orientation error was (3.04 ± 1.02)°. Additionally, a total of 5 beagles were tested, with an accuracy error of (2.78 ± 1.52) mm. No postoperative complications occurred.This is the first study reported for robot-assisted automatic surgery in craniofacial surgery. The result shows it is possible to realize the automatic drilling procedure under the condition of no interference like soft tissues. With the development of artificial intelligence and machine vision, robot-assisted surgery may help surgeons to fulfill more automatic procedures for craniofacial surgery.",project-academic
,2017-11-01,a,"University of Texas, Austin, School of Law Publications, Inc.",the foreseeability of human artificial intelligence interactions," Consider the following hypotheticals:(1) A hospital uses artificial intelligence software to analyze a patient's medical history and make a determination as to whether he or she needs surgery. One day, the artificial intelligence software incorrectly diagnoses a patient and recommends an unnecessary surgery. In preparation for the surgery, an anesthesiologist applies an incorrect dosage of the surgical anesthetic and kills the patient.(2) An investment firm uses artificial intelligence software to identify promising stocks for investment. Without any further research, an investment banker negligently recommends stocks off of the software's prepared list. Those stocks go bust, costing their new owners thousands of dollars.(3) A vehicle with autonomous-driving software is cruising down a two-lane road. The lane to its right is filled with cars driving in the same direction. A human driver is in oncoming traffic and recognizes the autonomous car as being from a notable autonomous car brand. The human driver decides it would be fun to ""play chicken"" with the car to see how it will react. The human driver proceeds to swerve into the autonomous vehicle's lane and the autonomous vehicle, thinking it best to avoid a head-on collision and not realizing the human driver won't hit it, swerves into the right lane, triggering a collision with an innocent third-party car.(4) A delivery drone, piloted with autonomous-piloting software, is en route to deliver a package. On its way, it passes the home of a paranoid man who is very concerned with his privacy. He proceeds to take a baseball, and with an impressive throw, knocks the drone out of the sky. The drone crashes down and hits a child playing in a nearby park.(5) A company selling artificial intelligence software sells its product to a racist. The racist proceeds to install the software onto a robot butler, and the robot butler proceeds to learn and develop under the teachings of its owner. One day, a black UPS driver delivers a package to the front door. The now-racist robot answers the door and upon seeing the black UPS driver, thinks, ""The only reason a black person would be on my front porch would be if he were here to burgle my owner."" The robot proceeds to attack the UPS driver under the mistaken assumption that he is a burglar.In each of the above hypotheticals, the use of artificial intelligence led to the injury of an innocent person. When faced with an injury caused by another, each of these persons may seek a remedy through the tort system. The tort system is designed to provide monetary damages for injured parties when they are harmed by the negligent conduct of another.1 In this way, the tort system assures that the costs of negligent conduct lie with those responsible for causing the injury.2 Each injured party in the hypotheticals above can sue the negligent actor who caused the harm-but who (or what) exactly caused the injured party's harm? In the above hypotheticals, there are human actors who cause the injured party's harm through obviously negligent conduct or even intentional conduct. These human actors present themselves as obvious targets, but what about the developers of the artificial intelligence software? When the injured parties sue in court, they are likely to sue whomever has the deepest pockets.3 This should strike fear into the hearts of many artificial intelligence companies, because in these tort suits, they are likely to be the parties in the best financial position to pay out damages.If artificial intelligence companies are sued for the negligent development of their software, courts will be faced with a difficult question of foreseeability. When proving a case of negligence, plaintiffs are required to show the harm that occurred was a foreseeable consequence of the defendant's negligent conduct.4 This is also called satisfying the proximate cause requirement of a negligence case.5 In each hypothetical, was the interaction between the artificial intelligence software and human actor foreseeable? …",project-academic
10.1017/PDS.2021.17,2021-08-01,a,Cambridge University Press (CUP),a multi agent reinforcement learning framework for intelligent manufacturing with autonomous mobile robots," Intelligent manufacturing (IM) embraces Industry 4.0 design principles to advance autonomy and increase manufacturing efficiency. However, many IM systems are created ad hoc, which limits the potential for generalizable design principles and operational guidelines. This work offers a standardizing framework for integrated job scheduling and navigation control in an autonomous mobile robot driven shop floor, an increasingly common IM paradigm. We specifically propose a multi-agent framework involving mobile robots, machines, humans. Like any cyberphysical system, the performance of IM systems is influenced by the construction of the underlying software platforms and the choice of the constituent algorithms. In this work, we demonstrate the use of reinforcement learning on a sub-system of the proposed framework and test its effectiveness in a dynamic scenario. The case study demonstrates collaboration amongst robots to maximize throughput and safety on the shop floor. Moreover, we observe nuanced behavior, including the ability to autonomously compensate for processing delays, and machine and robot failures in real time.",project-academic
,2019-06-27,a,,from self tuning regulators to reinforcement learning and back again," Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.",project-academic
10.1109/CDC40024.2019.9029916,2019-06-27,p,Institute of Electrical and Electronics Engineers Inc.,from self tuning regulators to reinforcement learning and back again," Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.",project-academic
10.2139/SSRN.3325115,2018-09-14,a,,artificial intelligence robotics synthetic brain in action," Artificial intelligence is a theory. It is the development of computer systems that are able to perform tasks that would require human intelligence. Examples of these tasks are visual perception, speech recognition, decision-making, and translation between languages. The base object in this reference is the agent who is the ""actor” taking birth in the software and culminating itself in the hardware body. The connection between those two is that the control of the robot is a software agent that reads data from the sensors decides what to do next and then directs the effectors to act in the physical world. The aim of this paper is to provide basic, background information on two emerging technologies: artificial intelligence (AI) and robotics and their scope in India. Thus, a first major feature of these two disciplines is product diversity. In addition, it is possible to characterize them as disruptive, enabling and interdisciplinary.",project-academic
10.3390/S20144005,2020-07-18,a,Multidisciplinary Digital Publishing Institute,designing a cyber physical system for ambient assisted living a use case analysis for social robot navigation in caregiving centers," The advances of the Internet of Things, robotics, and Artificial Intelligence, to give just a few examples, allow us to imagine promising results in the development of smart buildings in the near future. In the particular case of elderly care, there are new solutions that integrate systems that monitor variables associated with the health of each user or systems that facilitate physical or cognitive rehabilitation. In all these solutions, it is clear that these new environments, usually called Ambient Assisted Living (AAL), configure a Cyber-Physical System (CPS) that connects information from the physical world to the cyber-world with the primary objective of adding more intelligence to these environments. This article presents a CPS-AAL for caregiving centers, with the main novelty that includes a Socially Assistive Robot (SAR). The CPS-AAL presented in this work uses a digital twin world with the information acquired by all devices. The basis of this digital twin world is the CORTEX cognitive architecture, a set of software agents interacting through a Deep State Representation (DSR) that stored the shared information between them. The proposal is evaluated in a simulated environment with two use cases requiring interaction between the sensors and the SAR in a simulated caregiving center.",project-academic
