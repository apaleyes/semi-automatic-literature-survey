id,status,doi,publisher,database,query_name,query_value,url,publication_date,title,abstract,,,,
1,included,10.1109/mocast49295.2020.9200283,IEEE,ieeexplore,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9200283/,9/9/2020 0:00,a cloud based smart recycling bin for waste classification,"Due to the Earth's population rapid growth along with the modern lifestyle the urban waste constantly increases. People consume more and the products are designed to have shorter lifespans. Recycling is the only way to make a sustainable environment. The process of recycling requires the separation of waste materials, which is a time consuming procedure. However, most of the proposed research works found in literature are neither budget-friendly nor effective to be practical in real world applications. In this paper, we propose a solution: a low-cost and effective Smart Recycling Bin that utilizes the power of cloud to assist with waste classification. A centralized Information System (IS) collects measurements from smart bins that are deployed all around the city and classifies the waste of each bin using Artificial Intelligence and neural networks. Our implementation is capable of classifying different types of waste with an accuracy of 93.4% while keeping deployment cost and power consumption very low.",,,,
2,included,10.1109/icccn52240.2021.9522281,2021 International Conference on Computer Communications and Networks (ICCCN),semantic_scholar,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/e5db631b9237de584eadab60dd6529470438ad5d,1/1/2021 0:00,realization of an intrusion detection use-case in onap with acumos,"With Software-Defined Networking and Machine Learning/Artificial Intelligence (ML/AI) reaching new paradigms in their corresponding fields, both academia and industry have exhibited interests in discovering unique aspects of intelligent and autonomous communication networks. Transforming such intentions and interests to reality involves software development and deployment, which has its own story of significant evolution. There has been a notable shift in the strategies and approaches to software development. Today, the divergence of tools and technologies as per demand is so substantial that adapting a software application from one environment to another could involve tedious redesign and redevelopment. This implies enormous effort in migrating existing applications and research works to a modern industrial setup. Additionally, the struggles with sustainability maintenance of such applications could be painful. Concerning ML/AI, the capabilities to train, deploy, retrain, and re-deploy AI models as quickly as possible will be crucial for AI-driven network systems. An end-to-end workflow using unified open-source frameworks is the need of the hour to facilitate the integration of ML/AI models into the modern software-driven virtualized communication networks. Hence, in our paper, we present such a prototype by demonstrating the journey of a sample SVM classifier from being a python script to be deployed as a micro-service using ONAP and Acumos. While illustrating various features of Acumos and ONAP, this paper intends to make readers familiar with an end-to-end workflow taking advantage of the integration of both open-source platforms.",,,,
3,included,10.1109/isie45063.2020.9152441,IEEE,ieeexplore,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9152441/,6/19/2020 0:00,deployment of a smart and predictive maintenance system in an industrial case study,"Industrial manufacturing environments are often characterized as being stochastic, dynamic and chaotic, being crucial the implementation of proper maintenance strategies to ensure the production efficiency, since the machines' breakdown leads to a degradation of the system performance, causing the loss of productivity and business opportunities. In this context, the use of emergent ICT technologies, such as Internet of Things (IoT), machine learning and augmented reality, allows to develop smart and predictive maintenance systems, contributing for the reduction of unplanned machines' downtime by predicting possible failures and recovering faster when they occur. This paper describes the deployment of a smart and predictive maintenance system in an industrial case study, that considers IoT and machine learning technologies to support the online and real-time data collection and analysis for the earlier detection of machine failures, allowing the visualization, monitoring and schedule of maintenance interventions to mitigate the occurrence of such failures. The deployed system also integrates machine learning and augmented reality technologies to support the technicians during the execution of maintenance interventions.",,,,
4,included,10.1007/978-3-030-85867-4_4,Springer,springer,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85867-4_4,1/1/2021 0:00,airpa: an architecture to support the execution and maintenance of ai-powered rpa robots,"Robotic Process Automation (RPA) has quickly evolved from automating simple rule-based tasks. Nowadays, RPA is required to mimic more sophisticated human tasks, thus implying its combination with Artificial Intelligence (AI) technology, i.e., the so-called intelligent RPA. Putting together RPA with AI leads to a challenging scenario since (1) it involves professionals from both fields who typically have different skills and backgrounds, and (2) AI models tend to degrade over time which affects the performance of the overall solution. This paper describes the AIRPA project, which addresses these challenges by proposing a software architecture that enables (1) the abstraction of the robot development from the AI development and (2) the monitor, control, and maintain intelligent RPA developments to ensure its quality and performance over time. The project has been conducted in the Servinform context, a Spanish consultancy firm, and the proposed prototype has been validated with reality settings. The initial experiences yield promising results in reducing AHT (Average Handle Time) in processes where AIRPA deployed cognitive robots, which encourages exploring the support of intelligent RPA development.",,,,
5,included,10.1016/j.iot.2020.100185,scopus,sciencedirect,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85086362688,9/1/2020,highly-efficient fog-based deep learning aal fall detection system,"Falls is one of most concerning accidents in aged population due to its high frequency and serious repercussion; thus, quick assistance is critical to avoid serious health consequences. There are several Ambient Assisted Living (AAL) solutions that rely on the technologies of the Internet of Things (IoT), Cloud Computing and Machine Learning (ML). Recently, Deep Learning (DL) have been unknown for its high potential to improve accuracy on fall detection. Also, the use of fog devices for the ML inference (detecting falls) spares cloud drawback of high network latency, non-appropriate for delay-sensitive applications such as fall detectors. Though, current fall detection systems lack DL inference on the fog, and there is no evidence of it in real environments, nor documentation regarding the complex challenge of the deployment. Since DL requires considerable resources and fog nodes are resource-limited, a very efficient deployment and resource usage is critical. We present an innovative highly-efficient intelligent system based on a fog-cloud computing architecture to timely detect falls using DL technics deployed on resource-constrained devices (fog nodes). We employ a wearable tri-axial accelerometer to collect patient monitoring data. In the fog, we propose a smart-IoT-Gateway architecture to support the remote deployment and management of DL models. We deploy two DL models (LSTM/GRU) employing virtualization to optimize resources and evaluate their performance and inference time. The results prove the effectiveness of our fall system, that provides a more timely and accurate response than traditional fall detector systems, higher efficiency, 98.75% accuracy, lower delay, and service improvement.",,,,
6,included,10.1109/med.2017.7984310,IEEE,ieeexplore,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/7984310/,7/6/2017 0:00,cloud computing for big data analytics in the process control industry,"The aim of this article is to present an example of a novel cloud computing infrastructure for big data analytics in the Process Control Industry. Latest innovations in the field of Process Analyzer Techniques (PAT), big data and wireless technologies have created a new environment in which almost all stages of the industrial process can be recorded and utilized, not only for safety, but also for real time optimization. Based on analysis of historical sensor data, machine learning based optimization models can be developed and deployed in real time closed control loops. However, still the local implementation of those systems requires a huge investment in hardware and software, as a direct result of the big data nature of sensors data being recorded continuously. The current technological advancements in cloud computing for big data processing, open new opportunities for the industry, while acting as an enabler for a significant reduction in costs, making the technology available to plants of all sizes. The main contribution of this article stems from the presentation for a fist time ever of a pilot cloud based architecture for the application of a data driven modeling and optimal control configuration for the field of Process Control. As it will be presented, these developments have been carried in close relationship with the process industry and pave a way for a generalized application of the cloud based approaches, towards the future of Industry 4.0.",,,,
7,included,10.1016/j.jmsy.2021.04.005,scopus,sciencedirect,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85106283308,7/1/2021,learningadd: machine learning based acoustic defect detection in factory automation,"Defect inspection of glass bottles in the beverage industrial is of significance to prevent unexpected losses caused by the damage of bottles during manufacturing and transporting. The commonly used manual methods suffer from inefficiency, excessive space consumption, and beverage wastes after filling. To replace the manual operations in the pre-filling detection with improved efficiency and reduced costs, this paper proposes a machine learning based Acoustic Defect Detection (LearningADD) system. Moreover, to realize scalable deployment on edge and cloud computing platforms, deployment strategies especially partitioning and allocation of functionalities need to be compared and optimized under realistic constraints such as latency, complexity, and capacity of the platforms. In particular, to distinguish the defects in glass bottles efficiently, the improved Hilbert-Huang transform (HHT) is employed to extend the extracted feature sets, and then Shuffled Frog Leaping Algorithm (SFLA) based feature selection is applied to optimize the feature sets. Five deployment strategies are quantitatively compared to optimize real-time performances based on the constraints measured from a real edge and cloud environment. The LearningADD algorithms are validated by the datasets from a real-life beverage factory, and the F-measure of the system reaches 98.48 %. The proposed deployment strategies are verified by experiments on private cloud platforms, which shows that the Distributed Heavy Edge deployment outperforms other strategies, benefited from the parallel computing and edge computing, where the Defect Detection Time for one bottle is less than 2.061 s in 99 % probability.",,,,
8,included,http://arxiv.org/abs/1804.09914v1,arxiv,arxiv,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/1804.09914v1,4/26/2018 0:00,"itelescope: intelligent video telemetry and classification in real-time
  using software defined networking","Video continues to dominate network traffic, yet operators today have poor
visibility into the number, duration, and resolutions of the video streams
traversing their domain. Current approaches are inaccurate, expensive, or
unscalable, as they rely on statistical sampling, middle-box hardware, or
packet inspection software. We present {\em iTelescope}, the first intelligent,
inexpensive, and scalable SDN-based solution for identifying and classifying
video flows in real-time. Our solution is novel in combining dynamic flow rules
with telemetry and machine learning, and is built on commodity OpenFlow
switches and open-source software. We develop a fully functional system, train
it in the lab using multiple machine learning algorithms, and validate its
performance to show over 95\% accuracy in identifying and classifying video
streams from many providers including Youtube and Netflix. Lastly, we conduct
tests to demonstrate its scalability to tens of thousands of concurrent
streams, and deploy it live on a campus network serving several hundred real
users. Our system gives unprecedented fine-grained real-time visibility of
video streaming performance to operators of enterprise and carrier networks at
very low cost.",,,,
9,included,10.1007/s44196-021-00040-x,Springer,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/s44196-021-00040-x,11/20/2021 0:00,edge computing using embedded webserver with mobile device for diagnosis and prediction of metastasis in histopathological images,"Diagnosis of different breast cancer stages using histopathology whole slide images is the gold standard in grading the tissue metastasis. Traditional diagnosis involves labor intensive procedures and is prone to human errors. Computer aided diagnosis assists medical experts as a second opinion tool in early detection which prevents further proliferation. Computing facilities have emerged to an extent where algorithms can attain near human accuracy in prediction of diseases, offering better treatment to curb further proliferation. The work introduced in the paper provides an interface in mobile platform, which enables the user to input histopathology image and obtain the prediction results with its class probability through embedded web-server. The trained deep convolutional neural networks model is deployed into a microcomputer-based embedded system after hyper-parameter tuning, offering congruent performance. The implementation results show that the embedded platform with custom-trained CNN model is suitable for medical image classification, as it takes less execution time and mean prediction time. It is also noticed that customized CNN classifier model outperforms pre-trained models when used in embedded platforms for prediction and classification of histopathology images. This work also emphasizes the relevance of portable and flexible embedded device in real time clinical applications.",,,,
10,included,10.1145/3326285.3329051,IEEE,ieeexplore,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9068647/,6/25/2019 0:00,leap: learning-based smart edge with caching and prefetching for adaptive video streaming,"Dynamic Adaptive Streaming over HTTP (DASH) has emerged as a popular approach for video transmission, which brings a potential benefit for the Quality of Experience (QoE) because of its segment-based flexibility. However, the Internet can only provide no guaranteed delivery. The high dynamic of the available bandwidth may cause bitrate switching or video rebuffering, thus inevitably damaging the QoE. Besides, the frequently requested popular videos are transmitted for multiple times and contribute to most of the bandwidth consumption, which causes massive transmission redundancy. Therefore, we propose a Learning-based Edge with cAching and Prefetching (LEAP) to improve the online user QoE of adaptive video streaming. LEAP introduces caching into the edge to reduce the redundant video transmission and employs prefetching to fight against network jitters. Taking the state information of users into account, LEAP intelligently makes the most beneficial decisions of caching and prefetching by a QoE-oriented deep neural network model. To demonstrate the performance of our scheme, we deploy the implemented prototype of LEAP in both the simulated scenario and the real Internet. Compared with all selected schemes, LEAP at least raises average bitrate by 34.4&#x0025; and reduces video rebuffering by 42.7&#x0025;, which leads to at least 15.9&#x0025; improvement in the user QoE in the simulated scenario. The results in the real Internet scenario further confirm the superiority of LEAP.",,,,
11,included,10.1016/j.adhoc.2019.102047,scopus,sciencedirect,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85076174369,3/1/2020,an intelligent edge-iot platform for monitoring livestock and crops in a dairy farming scenario,"Today’s globalized and highly competitive world market has broadened the spectrum of requirements in all the sectors of the agri-food industry. This paper focuses on the dairy industry, on its need to adapt to the current market by becoming more resource efficient, environment-friendly, transparent and secure. The Internet of Things (IoT), Edge Computing (EC) and Distributed Ledger Technologies (DLT) are all crucial to the achievement of those improvements because they allow to digitize all parts of the value chain, providing detailed information to the consumer on the final product and ensuring its safety and quality. In Smart Farming environments, IoT and DLT enable resource monitoring and traceability in the value chain, allowing producers to optimize processes, provide the origin of the produce and guarantee its quality to consumers. In comparison to a centralized cloud, EC manages the Big Data generated by IoT devices by processing them at the network edge, allowing for the implementation of services with shorter response times, and a higher Quality of Service (QoS) and security. This work presents a platform oriented to the application of IoT, Edge Computing, Artificial Intelligence and Blockchain techniques in Smart Farming environments, by means of the novel Global Edge Computing Architecture, and designed to monitor the state of dairy cattle and feed grain in real time, as well as ensure the traceability and sustainability of the different processes involved in production. The platform is deployed and tested in a real scenario on a dairy farm, demonstrating that the implementation of EC contributes to a reduction in data traffic and an improvement in the reliability in communications between the IoT-Edge layers and the Cloud.",,,,
12,included,10.1109/qrs51102.2020.00018,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9282796/,12/14/2020 0:00,phm technology for memory anomalies in cloud computing for iaas,"The IaaS (Infrastructure as a Service) is one of the most popular services from todays cloud service providers, where the virtual machines (VM) are rented by users who can deploy any program they want in the VMs to make their own websites or use as their remote desktops. However, this poses a major challenge for cloud IaaS providers who cannot control the software programs that users develop, install or download on their rented VMs. Those programs may not be well developed with various bugs or even downloaded/installed together with virus, which often make damages to the VMs or infect the cloud platform. To keep the health of a cloud IaaS platform, it is very important to implement the PHM (Prognostics and Health Management) technology for detecting those software problems and self-healing them in an intelligent and timely way. This paper realized a novel PHM technology inspired by biological autonomic nervous system to deal with the memory anomalies of those programs running on the cloud IaaS platform. We first present an innovative autonomic computing technology called Bionic Autonomic Nervous System (BANS) to endow the cloud system with distinctive capabilities of perception, detection, reflection, and learning. Then, we propose a BANS-based Prognostics and Health Management (BPHM) technology to enable the cloud system self-dealing with various memory anomalies. AI-based failure prognostics, immediate self-healing, self-learning ability and self-improvement functions are implemented. Experimental results illustrate that the designed BPHM can automatically and intelligently deal with complex memory anomalies in a real cloud system for IaaS, to keep the system much more reliable and healthier.",,,,
13,included,10.1016/j.cie.2019.06.040,scopus,sciencedirect,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85067600850,9/1/2019,"bernard, an energy intelligent system for raising residential users awareness","Energy efficiency is still a hot topic today. Coming roughly the 25% of the energy consumption in EU from the residential sector, very few cheap and simple tools to promote energy efficiency in home users have been developed. The purpose of this paper is to present Bernard, a concept proof designed for filling this gap. This aims that householders become aware of their energy habits and have useful information that help them to redirect their consumption pattern. To achieve these goals, Bernard offers, through a mobile application, the home energy consumption monitoring in real time, the energy price forecast for the next hour and the appliances which are switched on, among others. Furthermore, it is important to highlight that the system has been designed with the premises of being cheap, non-intrusive, reliable and easily scalable, in order that utilities can gradually deploy and provide it to their customers, gaining at the same time valuable information for decision making and improving its corporate social image. Therefore, the adopted solution is based on a real time streaming data architecture suitable for handling huge volumes of data and applying predictive techniques on a cloud-computing environment. The paper provides a detailed description of the system and experimental results evaluating the performance of the predictive modules built. As case study, REFIT and REDD datasets were used.",,,,
14,included,10.1109/aiiot52608.2021.9454183,IEEE,ieeexplore,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9454183/,5/13/2021 0:00,image classification with knowledge-based systems on the edge for real-time danger avoidance in robots,"Mobile robots are increasingly common in society and are increasingly being used for complex and high-stakes tasks such as search and rescue. The growing requirements for these robots demonstrate a need for systems which can review and react in real time to environmental hazards, which will allow robots to handle environments that are both dynamic and dangerous. We propose and test a system which allows mobile robots to reclassify environmental objects during operation in conjunction with an edge system. We train an image classification model with 99 percent accuracy and deploy it in conjunction with an edge server and JSON-based ruleset to allow robots to react to and avoid hazards.",,,,
15,included,10.1109/isaect50560.2020.9523700,IEEE,ieeexplore,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9523700/,11/27/2020 0:00,edge-cloud architectures using uavs dedicated to industrial iot monitoring and control applications,"The deployment of new technologies to ease the control and management of a massive data volume and its uncertainty is a very significant challenge in the industry. Under the name ""Smart Factory"", the Industrial Internet of Things (IoT) aims to send data from systems that monitor and control the physical world to data processing systems for which cloud computing has proven to be an important tool to meet processing needs. unmanned aerial vehicles (UAVs) are now being introduced as part of IIoT and can perform important tasks. UAVs are now considered one of the best remote sensing techniques for collecting data over large areas. In the field of fog and edge computing, the IoT gateway connects various objects and sensors to the Internet. It function as a common interface for different networks and support different communication protocols. Edge intelligence is expected to replace Deep Learning (DL) computing in the cloud, providing a variety of distributed, low-latency and reliable intelligent services. In this paper, An unmanned aerial vehicle is automatically integrated into an industrial control system through an IoT gateway platform. Rather than sending photos from the UAV to the cloud for processing, an AI cloud trained model is deployed in the IoT gateway and used to process the taken photos. This model is designed to overcome the latency channels of the cloud computing architecture. The results show that the monitoring and tracking process using advanced computing in the IoT gateway is significantly faster than in the cloud.",,,,
16,included,10.1109/icdmw.2019.00123,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8955523/,11/11/2019 0:00,implementation of mobile-based real-time heart rate variability detection for personalized healthcare,"The ubiquity of wearable devices together with areas like internet of things, big data and machine learning have promoted the development of solutions for personalized healthcare that use digital sensors. However, there is a lack of an implemented framework that is technically feasible, easily scalable and that provides meaningful variables to be used in applications for translational medicine. This paper describes the implementation and early evaluation of a physiological sensing tool that collects and processes photoplethysmography data from a wearable smartwatch to calculate heart rate variability in real-time. A technical open-source framework is outlined, involving mobile devices for collection of heart rate data, feature extraction and execution of data mining or machine learning algorithms that ultimately deliver mobile health interventions tailored to the users. Eleven volunteers participated in the empirical evaluation that was carried out using an existing mobile virtual reality application for mental health and under controlled slow-paced breathing exercises. The results validated the feasibility of implementation of the proposed framework in the stages of signal acquisition and real-time calculation of heart rate variability (HRV). The analysis of data regarding packet loss, peak detection and overall system performance provided considerations to enhance the real-time calculation of HRV features. Further studies are planned to validate all the stages of the proposed framework.",,,,
17,included,10.1109/isc2.2016.7580798,IEEE,ieeexplore,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/7580798/,9/15/2016 0:00,smartseal: a ros based home automation framework for heterogeneous devices interconnection in smart buildings,"With this paper we present the SmartSEAL inter-connection system developed for the nationally founded SEAL project. SEAL is a research project aimed at developing Home Automation (HA) solutions for building energy management, user customization and improved safety of its inhabitants. One of the main problems of HA systems is the wide range of communication standards that commercial devices use. Usually this forces the designer to choose devices from a few brands, limiting the scope of the system and its capabilities. In this context, SmartSEAL is a framework that aims to integrate heterogeneous devices, such as sensors and actuators from different vendors, providing networking features, protocols and interfaces that are easy to implement and dynamically configurable. The core of our system is a Robotics middleware called Robot Operating System (ROS). We adapted the ROS features to the HA problem, designing the network and protocol architectures for this particular needs. These software infrastructure allows for complex HA functions that could be realized only levering the services provided by different devices. The system has been tested in our laboratory and installed in two real environments, Palazzo Fogazzaro in Schio and “Le Case” childhood school in Malo. Since one of the aim of the SEAL project is the personalization of the building environment according to the user needs, and the learning of their patterns of behaviour, in the final part of this work we also describe the ongoing design and experiments to provide a Machine Learning based re-identification module implemented with Convolutional Neural Networks (CNNs). The description of the adaptation module complements the description of the SmartSEAL system and helps in understanding how to develop complex HA services through it.",,,,
18,included,10.1016/j.engappai.2018.03.016,scopus,sciencedirect,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85045475454,6/1/2018,proa: an intelligent multi-criteria personalized route assistant,"Personalization of pedestrian routes becomes a necessity due to the wide variety of user profiles that may differ on preferences or requirements to choose a route. Several software applications offer routes usually based on single criterion like distance or time; however, these criteria do not often fit the pedestrian needs.
                  Here, we will first focus on the Personalized Routes Problem and then we will approach the specific case of designing accessible and green pedestrian routes.
                  The proposal is implemented as a freely available Android application (named as PRoA, by intelligent multi-criteria Personalized Route Assistant), which automatically obtains geographical data and information for the decision criteria from open datasets.
                  The proposal is evaluated using real cases at the city of Granada, Spain.",,,,
19,included,10.1109/access.2020.2970178,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8974224/,1/1/2020 0:00,a novel software engineering approach toward using machine learning for improving the efficiency of health systems,"Recently, machine learning has become a hot research topic. Therefore, this study investigates the interaction between software engineering and machine learning within the context of health systems. We proposed a novel framework for health informatics: the framework and methodology of software engineering for machine learning in health informatics (SEMLHI). The SEMLHI framework includes four modules (software, machine learning, machine learning algorithms, and health informatics data) that organize the tasks in the framework using a SEMLHI methodology, thereby enabling researchers and developers to analyze health informatics software from an engineering perspective and providing developers with a new road map for designing health applications with system functions and software implementations. Our novel approach sheds light on its features and allows users to study and analyze the user requirements and determine both the function of objects related to the system and the machine learning algorithms that must be applied to the dataset. Our dataset used in this research consists of real data and was originally collected from a hospital run by the Palestine government covering the last three years. The SEMLHI methodology includes seven phases: designing, implementing, maintaining and defining workflows; structuring information; ensuring security and privacy; performance testing and evaluation; and releasing the software applications.",,,,
20,included,10.1109/syscon.2018.8369547,IEEE,ieeexplore,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8369547/,4/26/2018 0:00,an interactive architecture for industrial scale prediction: industry 4.0 adaptation of machine learning,"According to wiki definition, there are four design principles in Industry 4.0. These principles support companies in identifying and implementing Industry 4.0 scenarios, namely, Interoperability, Information transparency, Technical assistance, Decentralized decisions. In this paper we have discussed our work on an implementation of a machine learning based interactive architecture for industrial scale prediction for dynamic distribution of water resources across the continent, keeping the four corners of Industry 4.0 in place. We report the possibility of producing most probable high resolution estimation regarding the water balance in any region within Australia by implementation of an intelligent system that can integrate spatial-temporal data from various independent sensors and models, with the ground truth data produced by 250 practitioners from the irrigation industry across Australia. This architectural implementation on a cloud computing platform linked with a freely distributed mobile application, allowing interactive ground truthing of a machine learning model on a continental scale, shows accuracy of 90% with 85% sensitivity of correct surface soil moisture estimation with end users at its complete control. Along with high level of information transparency and interoperability, providing on-demand technical supports and motivating users by allowing them to customize and control their own local predictive models, show the successfulness of principles in Industry 4.0 in real environmental issues in the future adaptation in various industries starting from resource management to modern generation soft robotics.",,,,
21,included,10.1007/978-3-030-77070-9_10,Springer,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77070-9_10,1/1/2021 0:00,smart and intelligent chatbot assistance for future industry 4.0,"Chatbot is an implementation of artificial intelligence (AI) technology that is used to interact with human beings and make them feel like they are talking to the real person, and the chatbot helps them to solve their queries. A chatbot can provide 24 × 7 customer support so that the customer may have a good service experience by any organization. Chatbot helps to resolve the queries and respond to the questions of users. The user is providing the input to the chatbot first, and then, the same input will be processed further; this input can be in the form of text or voice. Therefore, on the basis of the given input and after processing it, the chatbot application will generate the response to the user, and the same response will be the best answer found by the chat application. This response can be in any format like text or a voice output. In this chapter, various approaches of chatbots and how they interact with users are discussed. The proposed approach is also defined using Dialogflow, and it can be accessible through mobile phones, laptops, and portable devices. Chatbots such as Facebook chatbot, WeChat chatbot, Hike chatbot called Natasha, etc. are available in the marker and will respond on the basis of their local databases (DBs). In the proposed method, the focus will be on the scalability, user interactivity, and flexibility of the system, which can be provided by adding both local and Web databases due to which our system will be more fast and accurate. Chatbot uses unification of emerging technologies like machine learning and artificial intelligence. The motive of this chapter is to improve the chatbot system to support and scale businesses and industry domain and maintain relations with customers.",,,,
22,included,10.1109/rweek.2018.8473535,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8473535/,8/23/2018 0:00,framework for data driven health monitoring of cyber-physical systems,"Modern infrastructure is heavily reliant on systems with interconnected computational and physical resources, named Cyber-Physical Systems (CPSs). Hence, building resilient CPSs is a prime need and continuous monitoring of the CPS operational health is essential for improving resilience. This paper presents a framework for calculating and monitoring of health in CPSs using data driven techniques. The main advantages of this data driven methodology is that the ability of leveraging heterogeneous data streams that are available from the CPSs and the ability of performing the monitoring with minimal a priori domain knowledge. The main objective of the framework is to warn the operators of any degradation in cyber, physical or overall health of the CPS. The framework consists of four components: 1) Data acquisition and feature extraction, 2) state identification and real time state estimation, 3) cyber-physical health calculation and 4) operator warning generation. Further, this paper presents an initial implementation of the first three phases of the framework on a CPS testbed involving a Microgrid simulation and a cyber-network which connects the grid with its controller. The feature extraction method and the use of unsupervised learning algorithms are discussed. Experimental results are presented for the first two phases and the results showed that the data reflected different operating states and visualization techniques can be used to extract the relationships in data features.",,,,
23,included,10.1109/itc-egypt52936.2021.9513888,IEEE,ieeexplore,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9513888/,7/15/2021 0:00,a proposed end to end telemedicine system based on embedded system and mobile application using cmos wearable sensors,"Internet of things (IoT) and Embedded systems have extensive applications in healthcare markets. Integration of IoT with healthcare started with wearable smartwatches monitoring some signals and storing this data in the cloud. With 4G/5G and WiFi 6 networks. Healthcare data can be analyzed with Artificial Intelligence providing new era Internet of Medical Things (IoMT) that encompass an array of internet-capable medical devices that are in constant communication with each other or with the cloud; Internet of Healthcare Things (IoHT) that is the digital transformation of the healthcare industry. This article presents an end-to-end architecture with realization of three modules for key IoT aspects for healthcare and telemedicine. Results from a real implementation of application Platform for Data Processing including patient and doctor data base-based web site, MySQL data base, Android based mobile App, and PHP webserver.",,,,
24,included,10.1016/j.compag.2018.09.037,scopus,sciencedirect,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85054181612,11/1/2018,a decision support tool to enhance agricultural growth in the mékrou river basin (west africa),"We describe in this paper the implementation of E-Water, an open software Decision Support System (DSS), designed to help local managers assess the Water Energy Food Environment (WEFE) nexus. E-Water aims at providing optimal management solutions to enhance food crop production at river basin level. The DSS was applied in the transboundary Mékrou river basin, shared among Benin, Burkina Faso and Niger. The primary sector for local economy in the region is agriculture, contributing significantly to income generation and job creation. Fostering the productivity of regional agricultural requires the intensification of farming practices, promoting additional inputs (mainly nutrient fertilizers and water irrigation) but, also, a more efficient allocation of cropland.
                  In order to cope with the heterogeneity of data, and the analyses and issues required by the WEFE nexus approach, our DSS integrates the following modules: (1) the EPIC biophysical agricultural model; (2) a simplified regression metamodel, linking crop production with external inputs; (3) a linear programming and a multiobjective genetic algorithm optimization routines for finding efficient agricultural strategies; and (4) a user-friendly interface for input/output analysis and visualization.
                  To test the main features of the DSS, we apply it to various real and hypothetical scenarios in the Mékrou river basin. The results obtained show how food unavailability due to insufficient local production could be reduced by, approximately, one third by enhancing the application and optimal distribution of fertilizers and irrigation. That would also affect the total income of the farming sector, eventually doubling it in the best case scenario. Furthermore, the combination of optimal agricultural strategies and modified optimal cropland allocation across the basin would bring additional moderate increases in food self-sufficiency, and more substantial gains in the total agricultural income.
                  The proposed software framework proves to be effective, enabling decision makers to identify efficient and site-specific agronomic management strategies for nutrients and water. Such practices would augment crop productivity, which, in turn, would allow to cope with increasing future food demands, and find a balanced use of natural resources, also taking other economic sectors—like livestock, urban or energy—into account.",,,,
25,included,10.1109/smartworld.2018.00106,IEEE,ieeexplore,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8560084/,10/12/2018 0:00,real-time data processing architecture for multi-robots based on differential federated learning,"The emergency of ubiquitous intelligence in various things has become the ultimate cornerstone in building a smart interconnection of the physical world and the human world, which also caters to the idea of Internet of Things (IoT). Nowadays, robots as a new type of ubiquitous IoT devices have gained much attention. With the increasing number of distributed multi-robots, such smart environment generates unprecedented amounts of data. Robotic applications are faced with challenges of such big data: the serious real-time assurance and data privacy. Therefore, in order to obtain the big data values via knowledge sharing under the premise of ensuring the real-time data processing and data privacy, we propose a real-time data processing architecture for multi-robots based on the differential federated learning, called RT-robots architecture. A global shared model with differential privacy protection is trained on the cloud iteratively and distributed to multiple edge robots in each round, and the robotic tasks are processed locally in real time. Our implementation and experiments demonstrate that our architecture can be applied on multiple robotic recognition tasks, balance the trade-off between the performance and privacy.",,,,
26,included,10.1109/iceccme52200.2021.9591113,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9591113/,10/8/2021 0:00,cobots for fintech,"Embedded devices enabling payments transaction processing in Financial Services industry cannot have any margin for error. These devices need to be tested & validated by replicating production like environment to the extent possible. This means literally handling payments related events like swiping a credit card, tapping a mobile phone or pressing buttons amongst many other things like in real world. Embedded Software development is time consuming as it involves multiple man-machine interactions and dependencies such as managing and handling embedded devices, operating devices (Push buttons, interpret display panels, read receipt printouts etc.) and sharing devices for collaboration within team. During the current pandemic, it was impossible for software teams to travel to office, share devices or even procure necessary devices on time for project related tasks. This caused delay to project delivery and increased Time to market. The paper describes how the team used Capgemini's flexible Robotics as a Service (RaaS) platform that helped during pandemic to automate feasible man-machine interactions using Robotic arms. The paper provides details of the work done by the team that involves internet of things (IoT), Artificial Intelligence (AI) to remotely handle and operate hardware and devices thereby completing embedded software development life cycles faster and well within budget while ensuring superior product quality and importantly ensuring team's health and safety. This is novel in Financial Services space.",,,,
27,included,10.1007/s42979-021-00726-1,Nature,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.nature.com/articles/s42979-021-00726-1,6/19/2021 0:00,towards regulatory-compliant mlops: oravizio’s journey from a machine learning experiment to a deployed certified medical product,"Agile software development embraces change and manifests working software over comprehensive documentation and responding to change over following a plan. The ability to continuously release software has enabled a development approach where experimental features are put to use, and, if they stand the test of real use, they remain in production. Examples of such features include machine learning (ML) models, which are usually pre-trained, but can still evolve in production. However, many domains require more plan-driven approach to avoid hazard to environment and humans, and to mitigate risks in the process. In this paper, we start by presenting continuous software engineering practices in a regulated context, and then apply the results to the emerging practice of MLOps, or continuous delivery of ML features. Furthermore, as a practical contribution, we present a case study regarding Oravizio, first CE-certified medical software for assessing the risks of joint replacement surgeries. Towards the end of the paper, we also reflect the Oravizio experiences to MLOps in regulatory context.",,,,
28,included,10.1184/r1/6710654.v1,core,core,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://kilthub.cmu.edu/articles/Software_and_System_Health_Management_for_Autonomous_Robotics_Missions/6710654/files/12241643.pdf,6/30/2018 0:00,software and system health management for autonomous robotics missions,"Advanced autonomous robotics space missions rely heavily on the flawless interaction of complex hardware, multiple sensors, and a mission-critical software system.  This software system consists of an operating system, device drivers, controllers, and executives; recently highly complex AI-based autonomy software have also been introduced. Prior to launch, this software has to undergo rigorous verification and validation (V&V).  Nevertheless, dormant software bugs, failing sensors, unexpected hardware-software interactions, and unanticipated environmental conditions—likely on a space exploration mission—can cause major software faults that can endanger the entire mission.

Our Integrated Software Health Management (ISWHM) system continuously monitors the hardware sensors and the software in real-time. The ISWHM uses Bayesian networks, compiled to arithmetic circuits, to model software and hardware interactions. Advanced reasoning algorithms using arithmetic circuits not only enable the ISWHM to handle large, hierarchical models that are necessary in the realm of complex autonomous systems, but also enable efficient execution on small embedded processors. The latter capability is of extreme importance for small (mobile) autonomous units with limited computational power and low telemetry bandwidth.  In this paper, we discuss the requirements of ISWHM.  As our initial demonstration platform, we use a primitive Lego rover. A Lego 
Mindstorms microcontroller is used to implement a highly simplified autonomous rover driving system, running on the OSEK real-time operating system. We demonstrate that our ISWHM, running on this small embedded microcontroller, can perform fault detection as well as on-board reasoning for advanced diagnosis and root-cause detection in real time",,,,
29,included,http://arxiv.org/abs/2007.02351v1,arxiv,arxiv,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/2007.02351v1,7/5/2020 0:00,offline model guard: secure and private ml on mobile devices,"Performing machine learning tasks in mobile applications yields a challenging
conflict of interest: highly sensitive client information (e.g., speech data)
should remain private while also the intellectual property of service providers
(e.g., model parameters) must be protected. Cryptographic techniques offer
secure solutions for this, but have an unacceptable overhead and moreover
require frequent network interaction. In this work, we design a practically
efficient hardware-based solution. Specifically, we build Offline Model Guard
(OMG) to enable privacy-preserving machine learning on the predominant mobile
computing platform ARM - even in offline scenarios. By leveraging a trusted
execution environment for strict hardware-enforced isolation from other system
components, OMG guarantees privacy of client data, secrecy of provided models,
and integrity of processing algorithms. Our prototype implementation on an ARM
HiKey 960 development board performs privacy-preserving keyword recognition
using TensorFlow Lite for Microcontrollers in real time.",,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
242,unknown,10.1109/icmlc.2004.1380629,IEEE,ieeexplore,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/1380629/,8/29/2004 0:00,fault tolerance for communication-based multirobot formation,"This paper investigates the ability of fault tolerance for multirobot formation, which is important for practical formation in complex environment. Our model enables mobile robots group to continue to complete given tasks by reorganizing their formation, when some members are in failure. First, to build such model, a multi-agent architecture is presented, which is implemented through communication. Second, we introduce the hierarchy graph of multirobot formation to be the theoretical foundation of the fault tolerance system. The graph analysis is suitable for general leader-follower formation format. And then, the failure detection mechanism for formation is discussed. Finally, integrated fault tolerance algorithm is investigated, including supplement for faulty robots and formation reconfiguration. The improved agent architecture adding the fault tolerance module is also presented. The experiments on real multiple mobile robots demonstrate our design is feasible."
243,unknown,10.1109/smartnets48225.2019.9069763,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9069763/,12/19/2019 0:00,management of smart water treatment plant using iot cloud services,"Water Treatment Plant (WTP) is an important infrastructure to ensure human health and the environment. In its development, aspects of environmental safety and health are of great importance. Smart WTP is a water station that is managed using software-based tools such as data analytics, visualization, and predictive analytics. WTP smart management system is developed to manage Big Data information flows from many sensors and smart devices that allow for real-time responses and connectivity to Internet of Things (IoT) Cloud platforms services. The performance of the Smart WTP operations should be consistently evaluated to ensure that the plant is operating efficiently, thus minimizing energy costs and improving water purity and quality conservation parameters. Our proposed solution is based on sensors monitoring and Big Data analysis of Smart Water Treatment Plant (SWTP) using IoT hardware devices that have an internet connection to an IoT Cloud platform. The Cloud platform such as Thing Speak has the capability to analyze, visualize and react based on the Big Data analytics to send risk alarms and operate risk management plans to overcome the failure scenarios and minimize the downtime operation of the Smart WTP."
244,unknown,10.23919/iccas.2017.8204282,IEEE,ieeexplore,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8204282/,10/21/2017 0:00,machine learning based pattern recognition and classification framework development,"In this paper we describe implementation of several step pattern recognition framework. Pattern recognition is the main aspect for different important areas such as video surveillance, biometrics, interactive game applications, human computer interaction and access control systems. These systems require fast real time detection and recognition with high recognition rate. In this paper we propose implementation of the pattern recognition system. In order to increase recognition rate of the system we apply image preprocessing and neural networks."
245,unknown,10.1109/cns48642.2020.9162219,IEEE,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9162219/,7/1/2020 0:00,deepbloc: a framework for securing cps through deep reinforcement learning on stochastic games,"One important aspect in protecting Cyber Physical System (CPS) is ensuring that the proper control and measurement signals are propagated within the control loop. The CPS research community has been developing a large set of check blocks that can be integrated within the control loop to check signals against various types of attacks (e.g., false data injection attacks). Unfortunately, it is not possible to integrate all these “checks” within the control loop as the overhead introduced when checking signals may violate the delay constraints of the control loop. Moreover, these blocks do not completely operate in isolation of each other as dependencies exist among them in terms of their effectiveness against detecting a subset of attacks. Thus, it becomes a challenging and complex problem to assign the proper checks, especially with the presence of a rational adversary who can observe the check blocks assigned and optimizes her own attack strategies accordingly. This paper tackles the inherent state-action space explosion that arises in securing CPS through developing DeepBLOC (DB)-a framework in which Deep Reinforcement Learning algorithms are utilized to provide optimal/sub-optimal assignments of check blocks to signals. The framework models stochastic games between the adversary and the CPS defender and derives mixed strategies for assigning check blocks to ensure the integrity of the propagated signals while abiding to the real-time constraints dictated by the control loop. Through extensive simulation experiments and a real implementation on a water purification system, we show that DB achieves assignment strategies that outperform other strategies and heuristics."
246,unknown,10.1016/j.jbi.2016.09.015,scopus,sciencedirect,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/84989166008,12/1/2016,smart environment architecture for emotion detection and regulation,"This paper introduces an architecture as a proof-of-concept for emotion detection and regulation in smart health environments. The aim of the proposal is to detect the patient’s emotional state by analysing his/her physiological signals, facial expression and behaviour. Then, the system provides the best-tailored actions in the environment to regulate these emotions towards a positive mood when possible. The current state-of-the-art in emotion regulation through music and colour/light is implemented with the final goal of enhancing the quality of life and care of the subject. The paper describes the three main parts of the architecture, namely “Emotion Detection”, “Emotion Regulation” and “Emotion Feedback Control”. “Emotion Detection” works with the data captured from the patient, whereas “Emotion Regulation” offers him/her different musical pieces and colour/light settings. “Emotion Feedback Control” performs as a feedback control loop to assess the effect of emotion regulation over emotion detection. We are currently testing the overall architecture and the intervention in real environments to achieve our final goal."
247,unknown,10.3390/ijerph18137087,International journal of environmental research and public health,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/176d31f73bc65e07dc6e650b75404c31666dcdbb,1/1/2021 0:00,design of a spark big data framework for pm2.5 air pollution forecasting,"In recent years, with rapid economic development, air pollution has become extremely serious, causing many negative effects on health, environment and medical costs. PM2.5 is one of the main components of air pollution. Therefore, it is necessary to know the PM2.5 air quality in advance for health. Many studies on air quality are based on the government’s official air quality monitoring stations, which cannot be widely deployed due to high cost constraints. Furthermore, the update frequency of government monitoring stations is once an hour, and it is hard to capture short-term PM2.5 concentration peaks with little warning. Nevertheless, dealing with short-term data with many stations, the volume of data is huge and is calculated, analyzed and predicted in a complex way. This alleviates the high computational requirements of the original predictor, thus making Spark suitable for the considered problem. This study proposes a PM2.5 instant prediction architecture based on the Spark big data framework to handle the huge data from the LASS community. The Spark big data framework proposed in this study is divided into three modules. It collects real time PM2.5 data and performs ensemble learning through three machine learning algorithms (Linear Regression, Random Forest, Gradient Boosting Decision Tree) to predict the PM2.5 concentration value in the next 30 to 180 min with accompanying visualization graph. The experimental results show that our proposed Spark big data ensemble prediction model in next 30-min prediction has the best performance (R2 up to 0.96), and the ensemble model has better performance than any single machine learning model. Taiwan has been suffering from a situation of relatively poor air pollution quality for a long time. Air pollutant monitoring data from LASS community can provide a wide broader monitoring, however the data is large and difficult to integrate or analyze. The proposed Spark big data framework system can provide short-term PM2.5 forecasts and help the decision-maker to take proper action immediately."
244,unknown,10.1016/j.simpat.2019.102015,scopus,sciencedirect,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85074521783,2020-05-01,a fog computing model for implementing motion guide to visually impaired,"A guide dog robot system for visually impaired often needs to process many kinds of information, such as image, voice and other sensor information. Information processing methods based on deep neural network can achieve better results. However, it requires expensive computing and communication resources to meet the real-time requirement. Fog computing has emerged as a promising solution for applications that are data-intensive and delay-sensitive. We propose a fog computing framework named PEN (Phone + Embedded board + Neural compute stick) for the guide dog robot system. The robot’s functions in PEN are wrapped as services and deployed on the appropriate devices. Services are combined as an application in a visual programming language environment. Neural compute stick accelerates image processing speed at low power consumption. A simulation environment and a prototype are built on the framework. The simulated guide dog system is developed for operating in a miniature environment, including a small robot dog, a small wheelchair, model cars, traffic lights, and traffic blockage. The prototype is a full-sized portable guide system that can be used by a visually impaired person in a real environment. Simulation and experiments show that the framework can meet the functional and performance requirements for implementing the guide systems for visually impaired."
245,unknown,10.1109/pccc.2018.8710834,IEEE,ieeexplore,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8710834/,2018-11-19 00:00:00,socialite: social activity mining and friend auto-labeling,"As people's friend lists grow longer, it becomes more and more difficult to manage a friend list by labeling or grouping friends manually. In this paper, we leverage on-board sensors of smart devices and propose a social activity mining framework Socialite, which is able to achieve social group discovering and friend auto-labeling by exploring users' interactions in physical word. Socialite considers different deployment strategies and mainly contains two stages: social activity recognition and social group detection. Together with several data analysis approaches, a voting based lightweight neural network is designed for high accuracy diverse activity recognition. Then we propose a novel algorithm for social interaction feature generation and measure correlation among features of even asynchronous social activities. For system evaluation, we conduct extensive real life experiments. Results demonstrate that Socialite can recognize diverse social activities with above 94% accuracy, and 100% accuracy with our voting scheme. Socialite can also detect social groups in different scenarios with high accuracy. For example in two people activities, our proposed method achieves 92.2% accuracy for walk and 92.6% accuracy for table tennis."
246,unknown,10.1038/s42256-021-00337-8,Nature,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.nature.com/articles/s42256-021-00337-8,2021-06-01 00:00:00,end-to-end privacy preserving deep learning on multi-institutional medical imaging,"Using large, multi-national datasets for high-performance medical imaging AI systems requires innovation in privacy-preserving machine learning so models can train on sensitive data without requiring data transfer. Here we present PriMIA (Privacy-preserving Medical Image Analysis), a free, open-source software framework for differentially private, securely aggregated federated learning and encrypted inference on medical imaging data. We test PriMIA using a real-life case study in which an expert-level deep convolutional neural network classifies paediatric chest X-rays; the resulting model’s classification performance is on par with locally, non-securely trained models. We theoretically and empirically evaluate our framework’s performance and privacy guarantees, and demonstrate that the protections provided prevent the reconstruction of usable data by a gradient-based model inversion attack. Finally, we successfully employ the trained model in an end-to-end encrypted remote inference scenario using secure multi-party computation to prevent the disclosure of the data and the model. Gaining access to medical data to train AI applications can present problems due to patient privacy or proprietary interests. A way forward can be privacy-preserving federated learning schemes. Kaissis, Ziller and colleagues demonstrate here their open source framework for privacy-preserving medical image analysis in a remote inference scenario."
247,unknown,10.1109/ijcnn.2015.7280718,IEEE,ieeexplore,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/7280718/,2015-07-17 00:00:00,real-time video object recognition using convolutional neural network,"A convolutional neural network (CNN) is implemented on a field-programmable gate array (FPGA) and used for recognizing objects in real-time video streams. In this system, an image pyramid is constructed by successively down-scaling the input video stream. Image blocks are extracted from the image pyramid and classified by the CNN core. The detected parts are then marked on the output video frames. The CNN core is composed of six hardware neurons and two receptor units. The hardware neurons are designed as fully-pipelined digital circuits synchronized with the system clock, and are used to compute the model neurons in a time-sharing manner. The receptor units scan the input image for local receptive fields and continuously supply data to the hardware neurons as inputs. The CNN core module is controlled according to the contents of a table describing the sequence of computational stages and containing the system parameters required to control each stage. The use of this table makes the hardware system more flexible, and various CNN configurations can be accommodated without re-designing the system. The system implemented on a mid-range FPGA achieves a computational speed greater than 170,000 classifications per second, and performs scale-invariant object recognition from a 720×480 video stream at a speed of 60 fps. This work is a part of a commercial project, and the system is targeted for recognizing any pre-trained objects with a small physical volume and low power consumption."
248,unknown,http://arxiv.org/abs/2202.07475v1,arxiv,arxiv,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/2202.07475v1,2022-02-14 00:00:00,"a real-time system for detecting landslide reports on social media using
  artificial intelligence","This paper presents an online system that leverages social media data in real
time to identify landslide-related information automatically using
state-of-the-art artificial intelligence techniques. The designed system can
(i) reduce the information overload by eliminating duplicate and irrelevant
content, (ii) identify landslide images, (iii) infer geolocation of the images,
and (iv) categorize the user type (organization or person) of the account
sharing the information. The system was deployed in February 2020 online at
https://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter
data stream and has been running continuously since then to provide
time-critical information to partners such as British Geological Survey and
European Mediterranean Seismological Centre. We trust this system can both
contribute to harvesting of global landslide data for further research and
support global landslide maps to facilitate emergency response and decision
making."
249,unknown,10.1007/s00521-021-05726-z,Springer,springer,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-05726-z,2021-01-25 00:00:00,towards design and implementation of industry 4.0 for food manufacturing,"Today’s factories are considered as smart ecosystems with humans, machines and devices interacting with each other for efficient manufacturing of products. Industry 4.0 is a suite of enabler technologies for such smart ecosystems that allow transformation of industrial processes. When implemented, Industry 4.0 technologies have a huge impact on efficiency, productivity and profitability of businesses. The adoption and implementation of Industry 4.0, however, require to overcome a number of practical challenges, in most cases, due to the lack of modernisation and automation in place with traditional manufacturers. This paper presents a first of its kind case study for moving a traditional food manufacturer, still using the machinery more than one hundred years old, a common occurrence for small- and medium-sized businesses, to adopt the Industry 4.0 technologies. The paper reports the challenges we have encountered during the transformation process and in the development stage. The paper also presents a smart production control system that we have developed by utilising AI, machine learning, Internet of things, big data analytics, cyber-physical systems and cloud computing technologies. The system provides novel data collection, information extraction and intelligent monitoring services, enabling improved efficiency and consistency as well as reduced operational cost. The platform has been developed in real-world settings offered by an Innovate UK-funded project and has been integrated into the company’s existing production facilities. In this way, the company has not been required to replace old machinery outright, but rather adapted the existing machinery to an entirely new way of operating. The proposed approach and the lessons outlined can benefit similar food manufacturing industries and other SME industries."
250,unknown,10.2118/204794-ms,"Day 4 Wed, December 01, 2021",semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/d11c7341d3bcc4b0c73076048dcd10b35748f355,2021-01-01 00:00:00,satellite fields digitalization & als optimization with edge & advance analytics application,"
 Data monitoring in remote satellite field without any DOF platform is a challenging task but critical for ALS monitoring and optimization. In SRP wells the VFD data collection is important for analysis of downhole pump behavior and system health. SRP maintenance crew collects data from VFDs daily, but it is time consuming and can target only few wells in a day. The steps from requirement of dyna to final decision taken for ALS optimization are mobilizing team, permits approvals, download data, e-mail dynacards, dyna visualization, final decision.
 The problems with above process were: -
 Insufficient and discrete data for any post-failure analysis or ALS-optimization Minimal data to investigate the pre failure events
 The lack of real time monitoring was resulting in well downtime and associated production loss. The combination of IOT, Cloud Computing and Machine learning was implemented to shift from the reactive to proactive approach which helped in ALS Optimization and reduced production loss.
 The data was transmitted to a Cloud server and further it was transmitted to web-based app. Since thousands of Dynacards are generated in a day, hence it requires automated classification using computer driven pattern recognition techniques. The real time data is used for analysis involving basic statistic and Machine learning algorithms. The critical pump signatures were identified using machine learning libraries and email is generated for immediate action. Several informative dashboards were developed which provide quick analysis of ALS performance. The types of dashboard are as below
 Well Operational Status Dynacards Interpretation module SRP parameters visualization Machine Learning model calibration module Pump Performance Statistics
 After collection of enough data and creation of analytical dashboards on the three wells using domain knowledge the gained insights were used for ALS optimization. To keep the model in an evergreen high-confidence prediction state, inputs from domain experts are often required. After regular fine-tuning the prediction accuracy of the ML model increased to 80-85 %. In addition, system was made flexible so that a new algorithm can be deployed when required. Smart Alarms were generated involving statistic and Machine Learning by the system which gives alerts by e-mail if an abnormal behavior or erratic dynacards were identified. This helped in reduction of well downtime in some events which were treated instinctively before.
 The integration of domain knowledge and digitalization enables an engineer to take informed and effective decisions. The techniques discussed above can be implemented in marginal fields where DOF implementation is logistically and economically challenged. EDGE along with advanced analytics will gain more technological advances and can be used in other potential domains as well in near future."
251,unknown,10.1016/j.robot.2021.103830,scopus,sciencedirect,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85109177424,2021-09-01,visual recognition of gymnastic exercise sequences. application to supervision and robot learning by demonstration,"This work presents a novel software architecture to autonomously identify and evaluate the gymnastic activity that people are carrying out. It is composed of three different interconnected layers. The first corresponds to a Multilayer Perceptron (MLP) trained from a set of angular magnitudes derived from the information provided by the OpenPose library. This library works frame by frame, so some postures may be incorrectly detected due to eventual occlusions. The MLP layer makes it possible to accurately identify the posture a person is performing. A second layer, based on a Hidden Markov Model (HMM) and the Viterbi algorithm, filters the incorrect spurious postures. Thus, the accuracy of the algorithm is improved, leading to a precise sequence of postures. A third layer identifies the current exercise and evaluates whether the person is doing it at a correct speed. This layer uses an innovative Modified Levenshtein Distance (MLD), which considers not only the number of operations to transform a given sequence, but also the nature of the elements participating in the comparison. The system works in real time with little delay, thus recognizing sequences of arbitrary length and providing continuous feedback on the exercises being performed. An experiment carried out consisted in reproducing the output of the second layer on an autonomous Pepper robot that can be used in environments where physical exercise is performed, such as a residence for the elderly or others. It has reproduced different exercises previously executed by an instructor so that people can copy the robot. The article analyzes the current situation of the automated gymnastic activities recognition, presents the architecture, the different experiments carried out and the results obtained. The integration of the three components (MLP, HMM and MLD) results in a robust system that has allowed us to improve the results of previous works."
252,unknown,10.1016/j.chemolab.2021.104329,scopus,sciencedirect,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85105292476,2021-07-15,a novel approach for water quality classification based on the integration of deep learning and feature extraction techniques,"Water quality monitoring plays a vital role in the protection of water resources, environmental management, and decision-making. Artificial intelligence (AI) based on machine learning techniques has been widely used to evaluate and classify water quality for the last two decades. However, traditional machine learning techniques face many limitations, the most important of which is the inability to apply these techniques with big data generated by smart water quality monitoring stations to improve the prediction. Real-time water quality monitoring with high accuracy and efficiency for intelligent water quality monitoring stations requires new and sophisticated techniques based on machine and deep learning techniques. For this purpose, we propose a novel approach based on the integration of deep learning and feature extraction techniques to improve water quality classification. In this paper, was chosen the Tilesdit dam in Bouira (Algeria) as a case study. Moreover, we implemented the advanced deep learning method - Long Short Term Memory Recurrent Neural Networks (LSTM RNNs) to construct an intelligent model for drinking water quality classification. Furthermore, principal component analysis (PCA), linear discriminant analysis (LDA) and independent component analysis (ICA) techniques were used for features extraction and data reduction from original features. Additionally, we used three methods of cross-validation and two methods of the out-of-sample test to estimate the performance of LSTM RNNs model. From the results we found that the integration of LSTM RNNs with LDA, and LSTM RNNs with ICA yields an accuracy of 99.72%, using Random-Holdout technique."
253,unknown,http://arxiv.org/abs/1807.00139v1,arxiv,arxiv,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/1807.00139v1,2018-06-30 00:00:00,harnessing constrained resources in service industry via video analytics,"Service industries contribute significantly to many developed and developing
- economies. As their business activities expand rapidly, many service
companies struggle to maintain customer's satisfaction due to sluggish service
response caused by resource shortages. Anticipating resource shortages and
proffering solutions before they happen is an effective way of reducing the
adverse effect on operations. However, this proactive approach is very
expensive in terms of capacity and labor costs. Many companies fall into
productivity conundrum as they fail to find sufficient strong arguments to
justify the cost of a new technology yet cannot afford not to invest in new
technologies to match up with competitors. The question is whether there is an
innovative solution to maximally utilize available resources and drastically
reduce the effect that the shortages of resources may cause yet achieving high
level of service quality at a low cost. This work demonstrates with a practical
analysis of a trolley tracking system we designed and deployed at Hong Kong
International Airport (HKIA) on how video analytics helps achieve management's
goal of satisfying customer's needs via real-time detection and prevention of
problems they may encounter during the service consumption process using
existing video technology rather than adopting new technologies. This paper
presents the integration of commercial video surveillance system with deep
learning algorithms for video analytics. We show that our system can provide
accurate decision when faced with total or partial occlusion with high accuracy
and it significantly improves daily operation. It is envisioned that this work
will heighten the appreciation of integrative technologies for resource
management within the service industries and as a measure for real-time
customer assistance."
254,unknown,http://arxiv.org/abs/2207.03066v1,arxiv,arxiv,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/2207.03066v1,2022-07-07 00:00:00,device-cloud collaborative recommendation via meta controller,"On-device machine learning enables the lightweight deployment of
recommendation models in local clients, which reduces the burden of the
cloud-based recommenders and simultaneously incorporates more real-time user
features. Nevertheless, the cloud-based recommendation in the industry is still
very important considering its powerful model capacity and the efficient
candidate generation from the billion-scale item pool. Previous attempts to
integrate the merits of both paradigms mainly resort to a sequential mechanism,
which builds the on-device recommender on top of the cloud-based
recommendation. However, such a design is inflexible when user interests
dramatically change:
  the on-device model is stuck by the limited item cache while the cloud-based
recommendation based on the large item pool do not respond without the new
re-fresh feedback.
  To overcome this issue, we propose a meta controller to dynamically manage
the collaboration between the on-device recommender and the cloud-based
recommender, and introduce a novel efficient sample construction from the
causal perspective to solve the dataset absence issue of meta controller. On
the basis of the counterfactual samples and the extended training, extensive
experiments in the industrial recommendation scenarios show the promise of meta
controller in the device-cloud collaboration."
255,unknown,http://arxiv.org/abs/2107.13473v3,arxiv,arxiv,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/2107.13473v3,2021-07-28 00:00:00,"the portiloop: a deep learning-based open science tool for closed-loop
  brain stimulation","Closed-loop brain stimulation refers to capturing neurophysiological measures
such as electroencephalography (EEG), quickly identifying neural events of
interest, and producing auditory, magnetic or electrical stimulation so as to
interact with brain processes precisely. It is a promising new method for
fundamental neuroscience and perhaps for clinical applications such as
restoring degraded memory function; however, existing tools are expensive,
cumbersome, and offer limited experimental flexibility. In this article, we
propose the Portiloop, a deep learning-based, portable and low-cost closed-loop
stimulation system able to target specific brain oscillations. We first
document open-hardware implementations that can be constructed from
commercially available components. We also provide a fast, lightweight neural
network model and an exploration algorithm that automatically optimizes the
model hyperparameters to the desired brain oscillation. Finally, we validate
the technology on a challenging test case of real-time sleep spindle detection,
with results comparable to off-line expert performance on the Massive Online
Data Annotation spindle dataset (MODA; group consensus). Software and plans are
available to the community as an open science initiative to encourage further
development and advance closed-loop neuroscience research."
256,unknown,10.3929/ethz-b-000347534,,semantic_scholar,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/478928b128cc8cd15515d348b644746bb0197b98,2018-01-01 00:00:00,"first analyses of rainfall patterns retrieved by a newly installed x-band radar over the metropolitan area of cagliari (sardinia, italy)","The growing urbanization and aggregation of metropolitan territorial communities, sustainable development, citizen engagement, economic and cultural attractiveness and governance are among the most important issues for modern cities. The increasing complexity of these problems and technological development are leading to an urgent need and the opportunity to radically rethink the way we build and manage our cities. The recent institution of the Metropolitan area of Cagliari, that counts more than 500 thousands inhabitants, stimulated the government of the Sardinian region to fund an innovative project (Tessuto Digitale Metropolitano), that will be developed jointly between the Center for advanced studies, research and development in Sardinia and the University of Cagliari. Specifically, the project aims at studying and developing innovative methods and technologies to offer new smart solutions to improve the attractiveness of the city, the management of resources and the safety and quality of life of citizens. These objectives can be pursued through the synergic use and experimentation of advanced communication infrastructures and widespread sensors, and the development of innovative vertical solutions. Among the others, the improvement of citizens’ safety against environmental risks is a priority objective, with a special regard to the development of monitoring and prediction systems of extreme precipitation events. In general, common characteristic of these phenomena is that their occurrence cannot be predicted with sufficient accuracy using traditional weather forecasting methods nor monitored by punctual traditional tipping buckets raingauges. This introduces the need for rainfall monitoring continuously in time and space, both to check their evolution in real time, and to dispose the necessary measures of civil protection. At the same time, the analysis of past observations, in terms of patterns and principal directions, allow to forecast (nowcasting) the occurrence of similar phenomena 30 minutes1hour ahead the rain hits the ground. Following these premises, the Department of Civil, Environmental Engineering and Architecture (DICAAR) of the University of Cagliari installed a weather radar (figure 1, left panel) over the towershaft elevator of a building of the Faculty of Engineering and Architecture, University of Cagliari (Lon 9.108720°, Lat 39.228991°). The radar is the SuperGauge model, produced by Envisens Technologies: it is an X-band radar characterized by a single elevation and single polarization, with 1 minute resolution in time and 60 m resolution in range. The radar can monitor an area within a radius of 30 km, with an azimuth resolution linearly increasing with distance up to 1500 m at the maximum distance (30 km). Hence, from the current position the instrument can monitor the whole Cagliari metropolitan area. Each scan is then processed to return the retrieved rainfall field in a regular grid with 60x60 meter grid-cells every minute. UrbanRain18 11 International Workshop on Precipitation in Urban Areas Fig 1: Left: Radar installation site. Right: Rainfall field observed during the 02-05-2018 event. The radar position was decided in order to limit electromagnetic interferences and minimize the ground clutter effects, which in turns are due to morphology and surrounding buildings. Initially, the radar was set with 0° elevation for the antenna. The first instrument run was during the rain events occurred throughout Sardinia at the beginning of May 2018, which showed high rainfall rates and precipitation volumes. Meteorological models correctly forecasted the storm occurrences and the civil protection issued several warnings of severe weather conditions; as a consequence, several damages were registered. A snapshot of the rainfall field as recorded by the radar during the event of 02-05-2018 is reported in figure 1 (right panel), showing some areas where the rainfall rate exceeds 40 mm/h. The comparison between the above observations and those collected by the National Radar Network supports the correct functioning of the instrument, at least in terms of registered rainfall patterns. Some adjustments and calibration are still needed: first, in order to minimize the ground clutter, hence improving the quality of the measurements, the elevation angle will be increased up to 3°. Second, rainfall observations inferred by the radar will be accurately adjusted taking the advantage of the Sardinia’s rain gauges network. When retrievals of other events will be collected and available, some nowcasting procedures will be implemented in order to use radar observations also to issue real time warnings. Traditional methods, based on cell tracking, area tracking, and stochastic algorithms will be compared to innovative methods, based on machine learning. Finally, radar and rain gauge data will be integrated with the sensor network envisaged by the abovementioned project, aimed at monitoring multiple environmental parameters (temperature, water level, wind speed, relative humidity). This complete data set will improve the forecast reliability, not only in terms of precipitation fields but also for many other quantities related to environmental security. Acknowledgments: This research was supported under the ROP Sardegna ERDF Action 1.2.2 (project “Tessuto Digitale Metropolitano”) and by Sardinian Regional Authorities."
257,unknown,10.1007/978-981-15-5784-2_16,Springer,springer,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5784-2_16,2021-01-01 00:00:00,automatic classification of rotating machinery defects using machine learning (ml) algorithms,"Electric machines and motors have been the subject of enormous development. New concepts in design and control allow expanding their applications in different fields. The vast amount of data have been collected almost in any domain of interest. They can be static; that is to say, they represent real-world processes at a fixed point of time. Vibration analysis and vibration monitoring, including how to detect and monitor anomalies in vibration data are widely used techniques for predictive maintenance in high-speed rotating machines. However, accurately identifying the presence of a bearing fault can be challenging in practice, especially when the failure is still at its incipient stage, and the signal-to-noise ratio of the monitored signal is small. The main objective of this work is to design a system that will analyze the vibration signals of a rotating machine, based on recorded data from sensors, in the time/frequency domain. As a consequence of such substantial interest, there has been a dramatic increase of interest in applying Machine Learning (ML) algorithms to this task. An ML system will be used to classify and detect abnormal behavior and recognize the different levels of machine operation modes (normal, degraded, and faulty). The proposed solution can be deployed as predictive maintenance for Industry 4.0."
258,unknown,10.1007/978-981-16-7498-3_8,Springer,springer,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7498-3_8,2022-01-01 00:00:00,application of ai/iot for smart renewable energy management in smart cities,"A city is considered to be smart when the application of Artificial Intelligence (AI) and the Internet of Things (IoT) is integrated with it. This enables the collection of data from people, devices, and buildings, then analyses are performed to optimize control over infrastructure, traffic, energy, etc. A smart city is a collective framework with the integration of Information and Communication Technologies (ICT) and Cloud that makes interaction easily with one another. In this chapter, smart energy infrastructure is studied to monitor energy utilization in the city and to reduce costs and carbon emissions. Energy usage has recently shifted focus to renewable energy sources with minimal carbon emissions, emphasizing the necessity for ongoing environmental and human health preservation. Renewable energy is becoming more abundant, and the issue is to recognize and understand it in meeting the increasing demand for clean, affordable energy. Customers, distributors, and government bodies are all concerned about cost and the climate. Artificial intelligence proclaimed a new age in technology as well as in sustainable development. So, in this chapter, an implication of AI is presented and analyzed for RE research in smart environments. Along with that, an analytical study is also presented with the application of AI or IoT for smart energy management for smart cities. The main aim is to focus on and explore the efficiency level of ML/IoT techniques. This work will also provide an in-depth analysis of innovative development, deployment, analysis, and management of smart energy in smart cities."
259,unknown,10.1007/978-3-030-10997-4_12,Springer,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy'),http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-10997-4_12,2019-01-01 00:00:00,a practical deep online ranking system in e-commerce recommendation,"User online shopping experience in modern e-commerce websites critically relies on real-time personalized recommendations. However, building a productionized recommender system still remains challenging due to a massive collection of items, a huge number of online users, and requirements for recommendations to be responsive to user actions. In this work, we present our relevant, responsive, and scalable deep online ranking system (DORS) that we developed and deployed in our company. DORS is implemented in a three-level architecture which includes (1) candidate retrieval that retrieves a board set of candidates with various business rules enforced; (2) deep neural network ranking model that takes advantage of available user and item specific features and their interactions; (3) multi-arm bandits based online re-ranking that dynamically takes user real-time feedback and re-ranks the final recommended items in scale. Given a user as a query, DORS is able to precisely capture users’ real-time purchasing intents and help users reach to product purchases. Both offline and online experimental results show that DORS provides more personalized online ranking results and makes more revenue."
260,unknown,http://arxiv.org/abs/1911.05771v1,arxiv,arxiv,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),http://arxiv.org/abs/1911.05771v1,2019-11-13 00:00:00,"machine learning based network vulnerability analysis of industrial
  internet of things","It is critical to secure the Industrial Internet of Things (IIoT) devices
because of potentially devastating consequences in case of an attack. Machine
learning and big data analytics are the two powerful leverages for analyzing
and securing the Internet of Things (IoT) technology. By extension, these
techniques can help improve the security of the IIoT systems as well. In this
paper, we first present common IIoT protocols and their associated
vulnerabilities. Then, we run a cyber-vulnerability assessment and discuss the
utilization of machine learning in countering these susceptibilities. Following
that, a literature review of the available intrusion detection solutions using
machine learning models is presented. Finally, we discuss our case study, which
includes details of a real-world testbed that we have built to conduct
cyber-attacks and to design an intrusion detection system (IDS). We deploy
backdoor, command injection, and Structured Query Language (SQL) injection
attacks against the system and demonstrate how a machine learning based anomaly
detection system can perform well in detecting these attacks. We have evaluated
the performance through representative metrics to have a fair point of view on
the effectiveness of the methods."
261,unknown,10.1186/s12859-018-2300-5,BioMed Central,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.biomedcentral.com/openurl?doi=10.1186/s12859-018-2300-5,2018-10-15 00:00:00,an infrastructure for precision medicine through analysis of big data,"Background Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients’ data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed. Results In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010–2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses. Conclusions The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses."
262,unknown,10.1016/j.cie.2019.106031,scopus,sciencedirect,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://api.elsevier.com/content/abstract/scopus_id/85071975175,2019-11-01,machine learning based concept drift detection for predictive maintenance,"In this work we present a machine learning based approach for detecting drifting behavior – so-called concept drifts – in continuous data streams. The motivation for this contribution originates from the currently intensively investigated topic Predictive Maintenance (PdM), which refers to a proactive way of triggering servicing actions for industrial machinery. The aim of this maintenance strategy is to identify wear and tear, and consequent malfunctioning by analyzing condition monitoring data, recorded by sensor equipped machinery, in real-time. Recent developments in this area have shown potential to save time and material by preventing breakdowns and improving the overall predictability of industrial processes. However, due to the lack of high quality monitoring data and only little experience concerning the applicability of analysis methods, real-world implementations of Predictive Maintenance are still rare. Within this contribution, we present a method, to detect concept drift in data streams as potential indication for defective system behavior and depict initial tests on synthetic data sets. Further on, we present a real-world case study with industrial radial fans and discuss promising results gained from applying the detailed approach in this scope."
263,unknown,10.1109/icct46805.2019.8947193,IEEE,ieeexplore,industry,'industry' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8947193/,2019-10-19 00:00:00,edge ai for heterogeneous and massive iot networks,"By combining multiple sensing and wireless access technologies, the Internet of Things (IoT) shall exhibit features with large-scale, massive, and heterogeneous sensors and data. To integrate diverse radio access technologies, we present the architecture of heterogeneous IoT system for smart industrial parks and build an IoT experimental platform. Various sensors are installed on the IoT devices deployed on the experimental platform. To efficiently process the raw sensor data and realize edge artificial intelligence (AI), we describe four statistical features of the raw sensor data that can be effectively extracted and processed at the network edge in real time. The statistical features are calculated and fed into a back-propagation neural network (BPNN) for sensor data classification. By comparing to the k-nearest neighbor classification algorithm, we examine the BPNN-based classification method with a great amount of raw data gathered from various sensors. We evaluate the system performance according to the classification accuracy of BPNN and the performance indicators of the cloud server, which shows that the proposed approach can effectively enable the edge-AI-based heterogeneous IoT system to process the sensor data at the network edge in real time while reducing the demand for computing and network resources of the cloud."
264,unknown,10.1109/ic3i44769.2018.9007294,2018 3rd International Conference on Contemporary Computing and Informatics (IC3I),semantic_scholar,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/db2783813c1071e47f55385454f13cc55dc8fb16,2018-01-01 00:00:00,iot based precision horticulture in north india,"Horticulture incorporates a major impact on economy of the country. It is a subdivision of agriculture which deals with plant gardening under controlled environment. Heap of analysis has been dole out in automating the irrigation system by using wireless device and mobile computing. Conjointly analysis has been done in applying machine learning in Horticultural system too. Machine to Machine (M2M) communication is a growing technology that permits devices, objects to speak among one another and send knowledge to Server or Cloud through the Core Network. Therefore, consequently we tend to have developed a Brainy IOT primarily based machine-controlled Irrigation system. Wherever device knowledge is touching wet soil, temperature is captured and consequently machine learning algorithmic is deployed for analysing the device knowledge for prediction towards irrigating the soil with water or switching ON/OFF fan to control temperature. This can be a totally machine-controlled wherever devices communicate among themselves and apply the intelligence in real time monitoring & analysis. Making data available online through Cloud to Scientists to remotely make smart decisions on Precision Horticulture. System has been developed using low value embedded devices like Raspberry Pi3, Arduino and successfully implemented in Delhi."
265,unknown,246686767,Risk management and healthcare policy,semantic_scholar,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/86041f9ba7e725862af6c84126d6d0122be799e5,2022-01-01 00:00:00,a sustainable model for emergency medical services in developing countries: a novel approach using partial outsourcing and machine learning,"Introduction Unlike Western countries, many low- and middle-income countries (LMIC), like India, have a de-centralized emergency medical services (EMS) involving both semi-government and non-government organizations. It is alarming that due to the absence of a common ecosystem, the utilization of resources is inefficient, which leads to shortage of available vehicles and larger response time. Fragmentation of emergency supply chain resources motivates us to propose a new vehicle routing and scheduling model equipped with novel features to ensure minimal response time using existing resources. Materials and Methods The data set of medical and fire-related emergencies from January 2018 to May 2018 of Uttarakhand State in India was provided by GVK Emergency Management and Research Institute (GVK EMRI) also known as 108 EMSs was used in the study. The proposed model integrates all the available EMS vehicles including partial outsourcing to non-ambulatory vehicles like police vans, taxis, etc., using a novel two-echelon heuristic approach. In the first stage, an offline learning model is developed to yield the deployment strategy for EMS vehicles. Seven well researched machine learning (ML) algorithms were analyzed for parameter prediction namely random forest (RF), convolutional neural network (CNN), k-nearest neighbor (KNN), classification and regression tree (CART), support vector machine (SVM), logistic regression (LR), and linear discriminant analysis (LDA). In the second stage, a real-time routing model is proposed for EMS vehicle routing at the time of emergency, considering partial outsourcing. Results and Discussion The results indicate that the RF classifier outperforms the LR, LDA, SVM, CNN, CART and NB classifier in terms of both accuracy as well as F-1 score. The proposed vehicle routing and scheduling model for automated decision-making shows an improvement of 42.1%, 54%, 27.9% and 62% in vehicle assignment time, vehicle travel time from base to scene, travel time from scene to hospital, and total response time, respectively, in urban areas."
266,unknown,10.23919/splitech.2019.8783138,2019 4th International Conference on Smart and Sustainable Technologies (SpliTech),semantic_scholar,smart cities,'smart cities' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/41fa513e87ab7ccede01f16245c7d4b74000193f,2019-01-01 00:00:00,a context agnostic air quality service to exploit data in the ioe era,"The upcoming IoE paradigm is taking the IoT era to a new shift, and that because of the natural inter-connection of processes, people, devices and stakeholders. From the smart city perspective, the main goal is to make well-informed decisions, on the base of a variable number of sensors and sources, exposing different data with different protocols and structures. The urban contexts may change, and with them, the number of sensors deployed. The novel smart city service must go beyond an integration strategy, it needs an exploitation model to optimally retrieve useful and highly contextualized information. In this paper we focus on the development of a model which fuses together the IoE potential and machine learning techniques for the cognitive smart city: retrive useful intelligent information, optimally exploiting the infrastructure the specific physical context may offer. We propose an approach and related techniques for realizing context agnostic services, namely services that do not depend on the enabling infrastructure beneath. The purpose is to create an IoE-based self-contextualizing service, which potentially consider the entire range of data that is being collected in smart cities and use such data to provide highly-personalized information about each environment, i.e., information that best suits the context of each Smart City. To prove the proposed context agnostic service, we take into account the air quality observation issue: we provide two high-contextualized informative services to leverage data related to two different physical environments, thus building location awareness for different geographic areas and stakeholders. But still managed by the same application which can adapts itself. Finally we present the evaluation of this prototype to illustrate the benefits of our solution and the future work."
267,unknown,10.4043/29335-ms,"Day 2 Tue, May 07, 2019",semantic_scholar,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy'),https://www.semanticscholar.org/paper/095aeceba84ba188a2b3bb6e086d3755f11e824a,2019-01-01 00:00:00,"using augmented intelligence to automate subsea inspection data acquisition, processing, analysis, reporting and access","
 Augmented Intelligence (AI2) involves fusing Analyst Intuition with Artificial Intelligence to deliver an optimised combination of human-machine decision support.
 AI2 is being incorporated by i-Tech Services / Leidos into the physical inspection of offshore Oil, Gas, and Renewables assets, delivering valuable data driven insights that contribute to greater efficiency, enhanced condition monitoring, improved asset integrity and asset life extension.
 The deployment of vehicular and diver assets to obtain such inspection data, with associated support vessels, remains a major cost challenge for Operators.
 We believe the industry needs to approach this challenge from two key directions. Firstly, through the application of autonomous systems for data acquisition and delivery, reducing vessel reliance, and secondly through automating the acquisition and processing of data and maximising the insight provided by the data.
 This paper will examine the use of Augmented Intelligence to optimise the Subsea Inspection data workflow as a key use case, to demonstrate the principles.
 The historic paradigm consists of a fragmented evolving approach, with insufficient consideration and design across all the sensors, processing analytical engines and data visualisation. The approach being adopted is to closely link all aspects of the data workflow, within the context of delivering the data and beyond in terms of harvesting additional insight and value.
 To achieve the optimum workflow a number of developmental initiatives are being knitted into a modular platform, each element providing standalone value but the sum of the parts generates the most significant value and cost reduction.
 The elements being combined are automatic data quality control at acquisition source and through the full workflow, automated processing, machine vision for object recognition and reporting and machine learning to optimise the system intelligence. All of these are designed to augment the expertise of the analyst / user, detecting change to learnt parameters, by using real time data and critically by referencing large historical data sets and as-built data.
 The outputs from a system holistic approach will be improved data acquisition with more efficient high quality right first time data reporting. In addition layers of analytics, with smart, intuitive data access and retrieval will optimise delivery of key information within large data sets, together with maximising value and insight."
268,unknown,10.1109/srii.2012.76,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/6311047/,2012-07-27 00:00:00,an innovative decision support service for improving pharmaceutical acquisition capabilities,"The cost of pharmaceutical products is one of the largest contributors of operating costs in providing healthcare services in Thailand. As drug prices change according to shifting market forces, the distribution of purchase prices for each drug varies according to the type of medication and the purchasing power of the healthcare provider. These changes can have significant impact on how well healthcare providers can effectively provide services. PAC-DSS (Pharmaceutical Acquisition Capability Decision Support Service) is an innovative decision support service that enables hospitals to pool together and share information to better understand current market prices and run analytics on drug prices in order to improve their operating costs. Our service allows users to interact with real pricing data to dissect various factors that can contribute to acquisition capabilities of individual drugs such as specific brand names or groups of drugs such as all brands of a given generic drug, without sacrificing individual providers' privacy as we do not disclose individual purchase prices. In developing PAC-DSS, we have had to address a range of technical challenges such as data privacy and alignment of disparate drug ontologies. In this paper, we describe PAC-DSS's service architecture, analytic services, and the benefit of PAC-DSS on improving healthcare services by lowering operating cost without sacrificing service quality. We also discuss the initial benefits from deployment of the service currently hosted by the Ministry of Public Health."
269,unknown,10.1109/cds49703.2020.00012,IEEE,ieeexplore,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/9275963/,2020-08-02 00:00:00,welding seam recognition robots based on edge computing,"In order to meet the requirements of the accuracy and real-time performance during the working process of underwater welding robots, a scheme of welding seam recognition robots system based on the edge computing is proposed in this paper. A number of pre-processing methods for capturing welding seam image were designed, including Thresholding, Filtering and Edge Detect. A Convolutional Neural Network(CNN) model for welding seam recognition was also created. In the experiments, the image pre-processing and CNN algorithms were integrated in and deployed to the robots, and the learning and training algorithms of the CNN were deployed to the cloud servers. The image pre-processing methods filtered the interference in underwater operations and achieved the image compression and feature extraction. The cloud servers fulfilled the training and parameter optimization of the CNN, which improved the accuracy of welding seam image recognition."
270,unknown,10.1109/icoei.2019.8862754,IEEE,ieeexplore,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy'),https://ieeexplore.ieee.org/document/8862754/,2019-04-25 00:00:00,machine learning based health prediction system using ibm cloud as paas,"Adaptable Critical Patient Caring system is a key concern for hospitals in developing countries like Bangladesh. Most of the hospital in Bangladesh lack serving proper health service due to unavailability of appropriate, easy and scalable smart systems. The aim of this project is to build an adequate system for hospitals to serve critical patients with a real-time feedback method. In this paper, we propose a generic architecture, associated terminology and a classificatory model for observing critical patient's health condition with machine learning and IBM cloud computing as Platform as a service (PaaS). Machine Learning (ML) based health prediction of the patients is the key concept of this research. IBM Cloud, IBM Watson studio is the platform for this research to store and maintain our data and ml models. For our ml models, we have chosen the following Base Predictors: Naïve Bayes, Logistic Regression, KNeighbors Classifier, Decision Tree Classifier, Random Forest Classifier, Gradient Boosting Classifier, and MLP Classifier. For improving the accuracy of the model, the bagging method of ensemble learning has been used. The following algorithms are used for ensemble learning: Bagging Random Forest, Bagging Extra Trees, Bagging KNeighbors, Bagging SVC, and Bagging Ridge. We have developed a mobile application named “Critical Patient Management System - CPMS” for real-time data and information view. The system architecture is designed in such a way that the ml models can train and deploy in a real-time interval by retrieving the data from IBM Cloud and the cloud information can also be accessed through CPMS in a requested time interval. To help the doctors, the ml models will predict the condition of a patient. If the prediction based on the condition gets worse, the CPMS will send an SMS to the duty doctor and nurse for getting immediate attention to the patient. Combining with the ml models and mobile application, the project may serve as a smart healthcare solution for the hospitals."
