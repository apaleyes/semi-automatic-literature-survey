id,datePublished,description,journals,publisher,title,doi,downloadUrl,database,query_name,query_value
201404438,2019-01-01T00:00:00,"There is currently great interest in applying neural networks to prediction tasks in medicine. It is important for predictive models to be able to use survival data, where each patient has a known follow-up time and event/censoring indicator. This avoids information loss when training the model and enables generation of predicted survival curves. In this paper, we describe a discrete-time survival model that is designed to be used with neural networks, which we refer to as Nnet-survival. The model is trained with the maximum likelihood method using mini-batch stochastic gradient descent (SGD). The use of SGD enables rapid convergence and application to large datasets that do not fit in memory. The model is flexible, so that the baseline hazard rate and the effect of the input data on hazard probability can vary with follow-up time. It has been implemented in the Keras deep learning framework, and source code for the model and several examples is available online. We demonstrate the performance of the model on both simulated and real data and compare it to existing models Cox-nnet and Deepsurv","[{'title': 'PeerJ', 'identifiers': ['issn:2167-8359', '2167-8359']}]",'PeerJ',A scalable discrete-time survival model for neural networks,10.7717/peerj.6257,https://core.ac.uk/download/201404438.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
428894003,2019-01-01T00:00:00,"1: ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations.Weak recommendation, high quality evidence. 2: ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome.Strong recommendation, high quality evidence. 3: ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis.Strong recommendation, moderate quality evidence. 4: ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (</= 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited.Weak recommendation, high quality evidence. 5: ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6: ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7: ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence",,'Georg Thieme Verlag KG',Advanced imaging for detection and differentiation of colorectal neoplasia: European Society of Gastrointestinal Endoscopy (ESGE) Guideline - Update 2019,10.1055/a-1031-7657,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
304693960,2020-01-01T00:00:00,Fault detection and fault diagnosis are crucial subsystems to be integrated within the control architecture of modern industrial processes to ensure high quality standards. In this paper we present a two-stage unsupervised approach for fault detection and diagnosis in household appliances. In particular a suitable testing procedure has been implemented on a real industrial production line in order to extract the most meaningful features that allow to efficiently classify different types of fault by consecutively exploiting deep autoencoder neural network and k-means or hierarchical clustering techniques,,,A deep learning unsupervised approach for fault diagnosis of household appliances,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
475059757,2021-07-01T00:00:00,"Electronic health records (EHRs) have been widely adopted in recent years, but often include a high proportion of missing data, which can create difficulties in implementing machine learning and other tools of personalized medicine. Completed datasets are preferred for a number of analysis methods, and successful imputation of missing EHR data can improve interpretation and increase our power to predict health outcomes. However, use of the most popular imputation methods mainly require scripting skills, and are implemented using various packages and syntax. Thus, the implementation of a full suite of methods is generally out of reach to all except experienced data scientists. Moreover, imputation is often considered as a separate exercise from exploratory data analysis, but should be considered as art of the data exploration process. We have created a new graphical tool, ImputEHR, that is based on a Python base and allows implementation of a range of simple and sophisticated (e.g., gradient-boosted tree-based and neural network) data imputation approaches. In addition to imputation, the tool enables data exploration for informed decision-making, as well as implementing machine learning prediction tools for response data selected by the user. Although the approach works for any missing data problem, the tool is primarily motivated by problems encountered for EHR and other biomedical data. We illustrate the tool using multiple real datasets, providing performance measures of imputation and downstream predictive analysis","[{'title': 'Frontiers in Genetics', 'identifiers': ['1664-8021', 'issn:1664-8021']}]",'Frontiers Media SA',ImputEHR: A Visualization Tool of Imputation for the Prediction of Biomedical Data,10.3389/fgene.2021.691274,https://core.ac.uk/download/475059757.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
304119006,2019-01-01T00:00:00,"Prognostic Health Management (PHM) is a maintenance policy aimed at predicting the occurrence of a failure in components in order to minimize unexpected downtimes of complex systems and maximize their availability. Recent developments in condition monitoring (CM) techniques and Artificial Intelligence (AI) tools enabled the collection of a huge amount of data in real-time and its transformation into meaningful information that will support the maintenance decision-making process. The emerging Cyber-Physical Systems (CPS) technologies connect distributed physical systems with their virtual representations in the cyber computational world. The PHM assumes a key role in the implementation of CPS in manufacturing contexts, since it allows to keep CPS and its machines in proper conditions. On the other hand, CPS-based PHM provide an efficient solution to maximize availability of machines and production systems.
In this paper, evolving and unsupervised approaches for the implementation of PHM at a component level are described, which are able to process streaming data in real-time and with almost-zero prior knowledge about the monitored component. A case study from a real industrial context is presented. Different unsupervised and online anomaly detection methods are combined with evolving clustering models in order to detect anomalous behaviors in streaming vibration data and integrate the so-generated knowledge into supervised and adaptive models; then, the degradation model for each identified fault is built and the resulting RUL prediction model integrated into the online analysis. Supervised methods are applied to the same dataset, in batch mode, to validate the proposed procedure",,'Elsevier BV',Prognostic Health Management of Production Systems. New Proposed Approach and Experimental Evidences,10.1016/j.promfg.2020.01.333,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
490875871,2021-10-01T00:00:00,"The classic monitoring methods for detecting faults in automotive vehicles based on on-board diagnostics (OBD) are insufficient when diagnosing several mechanical failures. Other sensing techniques present drawbacks such as high invasiveness and limited physical range. The present work presents a fully noninvasive system for fault detection and isolation in internal combustion engines through sound signals processing. An acquisition system was developed, whose data are transmitted to a smartphone in which the signal is processed, and the user has access to the information. A study of the chaotic behavior of the vehicle was carried out, and the feasibility of using fractal dimensions as a tool to diagnose engine misfire and problems in the alternator belt was verified. An artificial neural network was used for fault classification using the fractal dimension data extracted from the sound of the engine. For comparison purposes, a strategy based on wavelet multiresolution analysis was also implemented. The proposed solution allows a diagnosis without having any contact with the vehicle, with low computational cost, without the need for installing sensors, and in real time. The system and method were validated through experimental tests, with a success rate of 99% for the faults under consideration","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',Noninvasive Methods for Fault Detection and Isolation in Internal Combustion Engines Based on Chaos Analysis,10.3390/s21206925,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440882566,2021-01-01T00:00:00,"An axial piston pump fault diagnosis algorithm based on empirical wavelet transform (EWT) and one-dimensional convolutional neural network (1D-CNN) is presented. The fault vibration signals and pressure signals of axial piston pump are taken as the analysis objects. Firstly, the original signals are decomposed by EWT, and each signal component is screened and reconstructed according to the energy characteristics. Then, the time-domain features and the frequency-domain features of the denoised signal are extracted, and features of time domain and frequency domain are fused. Finally, the 1D-CNN model was deployed to the WISE-Platform as a Service (WISE-PaaS) cloud platform to realize the real-time fault diagnosis of axial piston pump based on the cloud platform. Compared with ensemble empirical mode decomposition (EEMD) and complementary ensemble empirical mode decomposition (CEEMD), the results show that the axial piston pump fault diagnosis algorithm based on EWT and 1D-CNN has higher fault identification accuracy","[{'title': 'Shock and Vibration', 'identifiers': ['issn:1070-9622', '1875-9203', '1070-9622', 'issn:1875-9203']}]",'Hindawi Limited',Hydraulic Pump Fault Diagnosis Method Based on EWT Decomposition Denoising and Deep Learning on Cloud Platform,10.1155/2021/6674351,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
352152004,2019-03-20T00:00:00,"Robotic Process Automation (RPA) is a new wave of the future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering, and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available on google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching from the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment, and onboarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor onboarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea",,"Universidade de São Paulo. Faculdade de Economia, Administração e Contabilidade",The future digital work force: Robotic Process Automation (Rpa),,https://core.ac.uk/download/352152004.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
389983439,2020-05-06T00:00:00,"Блокчейн – це відкритий розподілений реєстр, яким користуються усі користувачі в мережі.Штучний інтелект – це один з найперспективніших напрямків комп'ютерних наук, який вивчає методи розв'язання задач, для яких не існує способів вирішення. Блокчейн має чимало слабких місць, в тому числі з точки зору безпеки, масштабованості і ефективності, а штучний інтелект, в свою чергу, страждає від проблем, пов'язаних з можливістю порушення приватності, а також з відсутністю довіри і можливості пояснити принцип дії. Об'єднання цих двох технологій, схоже, неминуче - вони могли б взаємно доповнити один одного для створення принципово нового покоління цифрових систем.Сombination of blockchain and artificial intelligence  technology for improvement data clarity and privacy  Blockchain - a chain of custody of registrations, yakimit to corrode beyond the years of usa by the corridors to the extent. As a rule, there is a real basis for a new server-free internet technology, which is the basis for a new serverless internet technology.  And particular intellect - as if it were a la carte, like a software program or a machine and the manifestations of ""intellectual"" health",,Institute of telecommunications Igor Sikorsky Kyiv Polytechnic Institute,ПОЄДНАННЯ ТЕХНОЛОГІЙ БЛОКЧЕЙН ТА ШТУЧНОГО ІНТЕЛЕКТУ ДЛЯ ПОКРАЩЕННЯ ПРОЗОРОСТІ ТА ПРИВАТНОСТІ ДАНИX,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491329314,2021-08-11T19:44:40,"Advances in Deep Neural Network (DNN) techniques have revolutionized video analytics and unlocked the potential for querying
and mining video event patterns. This paper details GNOSIS, an
event processing platform to perform near-real-time video event
detection in a distributed setting. GNOSIS follows a serverless approach where its component acts as independent microservices
and can be deployed at multiple nodes. GNOSIS uses a declarative
query-driven approach where users can write customize queries
for spatiotemporal video event reasoning. The system converts the
incoming video streams into a continuous evolving graph stream
using machine learning (ML) and DNN models pipeline and applies graph matching for video event pattern detection. GNOSIS
can perform both stateful and stateless video event matching. To
improve Quality of Service (QoS), recent work in GNOSIS incorporates optimization techniques like adaptive scheduling, energy
efficiency, and content-driven windows. This paper demonstrates
the Occupational Health and Safety query use cases to show the
GNOSIS efficacyThis work was supported with the financial support of the Science
Foundation Ireland (SFI) grant SFI/12/RC/2289_P2.peer-reviewe","[{'title': 'Proceedings of the VLDB Endowment', 'identifiers': ['issn:2150-8097', '2150-8097']}]",'VLDB Endowment',Query-driven video event processing for the internet of multimedia things,10.14778/3476311.3476360,https://core.ac.uk/download/491329314.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
287429785,2019-01-01T00:00:00,"International audienceThe use of wireless sensor networks, which are the key ingredient in the growing Internet of Things (IoT), has surged over the past few years with a widening range of applications in the industry, healthcare, agriculture, with a special attention to monitoring and tracking, often tied with security issues. In some applications, sensors can be deployed in remote, large unpopulated areas, whereas in others, they serve to monitor confined busy spaces. In either case, clustering the sensor network’s nodes into several clusters is of fundamental benefit for obvious scalability reasons, and also for helping to devise maintenance or usage schedules that might greatly improve the network’s lifetime. In the present paper, we survey and compare popular and advanced clustering schemes and provide a detailed analysis of their performance as a function of scale, type of collected data or their heterogeneity, and noise level. The testing is performed on real sensor data provided by the UCI Machine Learning Repository, using various external validation metrics",,HAL CCSD,Introducing and Comparing Recent Clustering Methods for Massive Data Management in the Internet of Things,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
226908873,2019-07-08T00:00:00,"International audienceThe Industry 4.0 framework needs new intelligent approaches. Thus, the manufacturing industries more and more pay close attention to artificial intelligence (AI). For example, smart monitoring and diagnosis, real time evaluation and optimization of the whole production and raw materials management can be improved by using machine learning and big data tools. An accurate milling process implies a high quality of the obtained material surface (roughness, flatness). With the involvement of AI-based algorithms, milling process is expected to be more accurate during complex operations.In this work, a smart milling diagnosis has been developed for composite sandwich structures based on honey-comb core. The use of such material has grown considerably in recent years, especially in the aeronautic, aerospace, sporting and automotive industries. But the precise milling of such material presents many difficulties. The objective of this work is to develop a data-driven industrial surface quality diagnosis for the milling of honey-comb material, by using supervised machine learning methods. Therefore, cutting forces and workpiece material vibrations are online measured in order to predict the resulting surface flatness.The workpiece material studied in this investigation is Nomex® honeycomb cores with thin cell walls. The Nomex® honeycomb machining presents several defects related to its composite nature (uncut fiber, tearing of the walls), the cutting conditions and to the alveolar geometry of the structure which causes vibration on the different components of the cutting effort.Given the low level of cutting forces, the quality of the obtained machined surface allows to establish criteria for determining the machinability of the honeycomb structures. Nearly 40 features are calculated in time domain and frequency domain from the raw signal in steady state behavior (transient zones are not taken into account). The features are then normalized. The input parameters for each experiment are: the tool rotation speed, the cutting speed and the depth of cut. It is then necessary to make a dimensional reduction of that feature table in order to avoid overfitting and to reduce the computing time of the learning algorithm.In this work, several classification algorithms have been implemented such as : k-nearest neighbor (kNN), Decision trees (DT), Support Vector Machine (SVM). The different supervised learning algorithms have been implemented and compared. Each AI-based model has been applied to a set of features. From the prediction results, SVM algorithm seems to be the most efficient algorithm in this application",,HAL CCSD,Milling diagnosis using machine learning approaches,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
220589792,2019-01-01T00:00:00,"Abstract The Robotic Process Automation (RPA) is a new wave of the future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available in google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching of the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in the organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment and on boarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor on boarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea",,,The Future Digital Work Force: Robotic Process Automation (RPA),,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
333569035,2020,"Integrated clinical pathways (ICPs) are task-oriented care plans detailing the essential steps of the therapeutic pathway referring to a specific clinical problem with a patient’s expected clinical course. ICPs represent an effective tool for resource management in the public and private health domains. To be automatically executed, the ICP process has to be described by means of complex general purpose description language (GPDL) formalisms. However, GPDLs make the process model difficult to grasp by a human. On the other hand, the adoption of a reduced set of graphical constructs prevents a fully automated process execution due to the lack of information required by a machine. Unfortunately, it is difficult to find a balance between modelling language expressiveness and the automated execution of the modelled processes. In this paper, we present a meta-model based on a GPDL to organize the ICP process knowledge. This meta-model allows the management of ICP information in a way that is independent from the graphic representation of the adopted modelling standard. We also propose a general framework and a methodology that aim to guarantee a high degree of automation in process execution. In particular, the corresponding execution engine is implemented as a chatbot (integrated with social media), which plays a two-fold role: during the actual execution of the entire ICP, it acts as a virtual assistant and gathers the patient’s health data. Tests performed on a real ICP showed that, thanks to the proposed solution, the chatbot engine is able to engage in a dialogue with the patient. We provide discussion about how the system could be extended and how it could be seen as an alternative to Artificial Intelligence (AI) and Natural Language Processing (NLP)-based approaches",,'MDPI AG',Design and Execution of Integrated Clinical Pathway: A Simplified Meta-Model and Associated Methodology,10.3390/info11070362,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440354135,2020-01-01T00:00:00,"This study proposes a Raspberry Pi-based system for the diagnosis of heart valve diseases as a primary tool to improve the diagnostic accuracy of physicians. The proposed system is able to detect and classify nine common valvular heart cases encompassing eight types of heart valve diseases as well as the normal case of valves. The design and development of the proposed system are mainly divided into two phases, namely development of a disease classification approach, and design and implementation of the diagnostic hardware system. The developed disease classification approach is comprised of five stages, namely obtaining phonocardiogram (PCG) signals, preprocessing, segmentation using a proposed automatic algorithm, feature extraction in three domains (time, frequency, and wavelet decomposition domains) and classification using a backpropagation neural network. The hardware of the diagnostic system consists of a PCG signal acquisition module connected to a processing and displaying unit, which is represented by a Raspberry Pi connected to a touch screen. Where the developed disease classification approach is implemented in the software of the Raspberry Pi to enable it to detect the diseases in real time and fully automatically. The proposed system was clinically tested on 50 real subjects encompassing the nine cases. The performance of the diagnostic system is obtained with an accuracy of 96%, sensitivity of 95.23%, and specificity of 100%","[{'title': 'Cogent Engineering', 'identifiers': ['issn:2331-1916', '2331-1916']}]",'Informa UK Limited',A portable Raspberry Pi-based system for diagnosis of heart valve diseases using automatic segmentation and artificial neural networks,10.1080/23311916.2020.1856757,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491003696,2021-11-01T00:00:00,"Abstract Since 2017, we have used IonTorrent NGS platform in our hospital to diagnose and treat cancer. Analyzing variants at each run requires considerable time, and we are still struggling with some variants that appear correct on the metrics at first, but are found to be negative upon further investigation. Can any machine learning algorithm (ML) help us classify NGS variants? This has led us to investigate which ML can fit our NGS data and to develop a tool that can be routinely implemented to help biologists. Currently, one of the greatest challenges in medicine is processing a significant quantity of data. This is particularly true in molecular biology with the advantage of next-generation sequencing (NGS) for profiling and identifying molecular tumors and their treatment. In addition to bioinformatics pipelines, artificial intelligence (AI) can be valuable in helping to analyze mutation variants. Generating sequencing data from patient DNA samples has become easy to perform in clinical trials. However, analyzing the massive quantities of genomic or transcriptomic data and extracting the key biomarkers associated with a clinical response to a specific therapy requires a formidable combination of scientific expertise, biomolecular skills and a panel of bioinformatic and biostatistic tools, in which artificial intelligence is now successful in developing future routine diagnostics. However, cancer genome complexity and technical artifacts make identifying real variants challenging. We present a machine learning method for classifying pathogenic single nucleotide variants (SNVs), single nucleotide polymorphisms (SNPs), multiple nucleotide variants (MNVs), insertions, and deletions detected by NGS from different types of tumor specimens, such as: colorectal, melanoma, lung and glioma cancer. We compared our NGS data to different machine learning algorithms using the k-fold cross-validation method and to neural networks (deep learning) to measure the performance of the different ML algorithms and determine which one is a valid model for confirming NGS variant calls in cancer diagnosis. We trained our machine learning with 70% of our data samples, extracted from our local database (our data structure had 7 parameters: chromosome, position, exon, variant allele frequency, minor allele frequency, coverage and protein description) and validated it with the 30% remaining data. The model offering the best accuracy was chosen and implemented in the NGS analysis routine. Artificial intelligence was developed with the R script language version 3.6.0. We trained our model on 70% of 102,011 variants. Our best error rate (0.22%) was found with random forest machine learning (ntree = 500 and mtry = 4), with an AUC of 0.99. Neural networks achieved some good scores. The final trained model with the neural network achieved an accuracy of 98% and an ROC-AUC of 0.99 with validation data. We tested our RF model to interpret more than 2000 variants from our NGS database: 20 variants were misclassified (error rate < 1%). The errors were nomenclature problems and false positives. After adding false positives to our training database and implementing our RF model routinely, our error rate was always < 0.5%. The RF model shows excellent results for oncosomatic NGS interpretation and can easily be implemented in other molecular biology laboratories. AI is becoming increasingly important in molecular biomedical analysis and can be very helpful in processing medical data. Neural networks show a good capacity in variant classification, and in the future, they may be useful in predicting more complex variants","[{'title': 'Scientific Reports', 'identifiers': ['2045-2322', 'issn:2045-2322']}]",'Springer Science and Business Media LLC',Machine learning random forest for predicting oncosomatic variant NGS analysis,10.1038/s41598-021-01253-y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
428925085,2020-10-01T00:00:00,"Background: Blood donors are at risk for reduced iron stores, because of which donor iron monitoring received increased attention in the last decade. Despite the importance for donor health, international consensus on an appropriate policy for iron monitoring is lacking. Therefore, we conduct a trial to evaluate to what extent ferritin-guided donation intervals are effective in increasing haemoglobin and ferritin levels, decreasing low-haemoglobin deferral, increasing donor return and improving the health of whole blood donors in the Netherlands. Methods: Sanquin Blood Bank is implementing ferritin-guided donation intervals to prevent donors from increasing iron loss at repeated donations. Using a stepped wedge cluster randomised trial approach, the design involves a random crossover of 29 clusters of blood collection centres from the existing policy without ferritin measurements to a ferritin-guided donation interval policy. This new policy includes ferritin measurements for all new donors and at every 5th whole blood donation, extending donation intervals to 6 months if ferritin is 15-≤ 30 ng/mL and to 12 months if ferritin is < 15 ng/mL. We measure ferritin levels of whole blood donors from stored plasma samples and collect haemoglobin levels and information on low-haemoglobin deferral and donor return from the donor database before, during and after the implementation period. We measure donor health during and after the implementation period using questionnaires, assessing physical and mental wellbeing and iron deficiency- and donation-related symptoms. We use multilevel analyses to investigate differences in ferritin and haemoglobin levels, low-haemoglobin deferral rates, donor return and donor health from whole blood donors, between blood collection centres that have versus those that have not yet implemented the ferritin-guided donation interval policy. Discussion: This stepped wedge cluster randomised trial will provide insight into the effectiveness of ferritin-guided donation intervals in lowering iron deficiency, decreasing donor deferrals due to low haemoglobin and improving donor health. We will evaluate a policy that is implemented nationwide in a real-life setting. Our study is therefore not limited to a small experimental setting and the results will guide policymakers seeking an appropriate policy for iron monitoring. Trial registration: The Dutch trial registry NTR6738. Registered on 29 September 2017. Retrospectively registered",,'Springer Science and Business Media LLC',Ferritin measurement IN Donors—Effectiveness of iron Monitoring to diminish iron deficiency and low haemoglobin in whole blood donors (FIND’EM): study protocol for a stepped wedge cluster randomised trial,10.1186/s13063-020-04648-w,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491193342,2022-01-31T01:52:07,"The history of medicine shows that myocardial infarction is one of the significant causes of death in humans. The rapid evolution in autonomous technologies, the rise of computer vision, and edge computing offers intriguing possibilities in healthcare monitoring systems. The major motivation of the work is to improve the survival rate during a cardiac arrest through an automatic emergency recognition system under ambient intelligence. We present a novel approach to chest pain and fall posture-based vital sign detection using an intelligence surveillance camera to address the emergency during myocardial infarction. A real-time embedded solution persuaded from ""edge AI""is implemented using the state-of-the-art convolution neural networks: single shot detector Inception V2, single shot detector MobileNet V2, and Internet of Things embedded GPU platform NVIDIA's Jetson Nano. The deep learning algorithm is implemented for 3000 indoor color image datasets: Nanyang Technological University Red Blue Green and Depth, NTU RGB + D dataset, and private RMS dataset. The research mainly pivots on two key factors in creating and training a CNN model to detect the vital signs and evaluate its performance metrics. We propose a model, which is cost-effective and consumes low power for onboard detection of vital signs of myocardial infarction and evaluated the metrics to achieve a mean average precision of 76.4% and an average recall of 80%","[{'title': 'Advances in Human-Computer Interaction', 'identifiers': ['issn:1687-5907', '1687-5893', '1687-5907', 'issn:1687-5893']}]",'Hindawi Limited',Edge Artificial Intelligence: Real-Time Noninvasive Technique for Vital Signs of Myocardial Infarction Recognition Using Jetson Nano,10.1155/2021/6483003,http://hdl.handle.net/10453/153906,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201292349,2019-02-01T00:00:00,"Monitoring animal health worldwide, especially the early detection of outbreaks of emerging pathogens, is one of the means of preventing the introduction of infectious diseases in countries (Collier et al., 2008) [3]. In this context, we developed PADI-web, a Platform for Automated extraction of animal Disease Information from the Web (Arsevska et al., 2016, 2018). PADI-web is a text-mining tool that automatically detects, categorizes and extracts disease outbreak information from Web news articles. PADI-web currently monitors the Web for five emerging animal infectious diseases, i.e., African swine fever, avian influenza including highly pathogenic and low pathogenic avian influenza, foot-and-mouth disease, bluetongue, and Schmallenberg virus infection. PADI-web collects Web news articles in near-real time through RSS feeds. Currently, PADI-web collects disease information from Google News because of its international and multiple language coverage. We implemented machine learning techniques to identify the relevant disease information in texts (i.e., location and date of an outbreak, affected hosts, their numbers and clinical signs). In order to train the model for Information Extraction (IE) from news articles, a corpus in English has been manually labeled by domain experts. This labeled corpus (Rabatel et al., 2017) is presented in this data paper","[{'title': 'Data in Brief', 'identifiers': ['2352-3409', 'issn:2352-3409']}]",'Elsevier BV',PADI-web corpus: Labeled textual data in animal health domain,10.1016/j.dib.2018.12.063,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
300365238,2019-01-01T00:00:00,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ""VA-assisted ML"". The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly.publishe",,'Institute of Electrical and Electronics Engineers (IEEE)',VIS4ML : An Ontology for Visual Analytics Assisted Machine Learning,10.1109/TVCG.2018.2864838,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
483522738,2021-11-02T00:00:00,"Developers proposing new machine learning for health (ML4H) tools often pledge to match or even surpass the performance of existing tools, yet the reality is usually more complicated. Reliable deployment of ML4H to the real world is challenging as examples from diabetic retinopathy or Covid-19 screening show. We envision an integrated framework of algorithm auditing and quality control that provides a path towards the effective and reliable application of ML systems in healthcare. In this editorial, we give a summary of ongoing work towards that vision and announce a call for participation to the special issue  Machine Learning for Health: Algorithm Auditing & Quality Control in this journal to advance the practice of ML4H auditing",,'Springer Science and Business Media LLC',Machine Learning for Health: Algorithm Auditing & Quality Control.,10.1007/s10916-021-01783-y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
487585666,2021-10-02T00:00:00,"International audienceBackground: Artificial intelligence (AI) has the potential to transform our healthcare systems significantly. New AI technologies based on machine learning approaches should play a key role in clinical decision-making in the future. However, their implementation in health care settings remains limited, mostly due to a lack of robust validation procedures. There is a need to develop reliable assessment frameworks for the clinical validation of AI. We present here an approach for assessing AI for predicting treatment response in triple-negative breast cancer (TNBC), using real-world data and molecular-omics data from clinical data warehouses and biobanks. Methods: The European ""ITFoC (Information Technology for the Future Of Cancer)"" consortium designed a framework for the clinical validation of AI technologies for predicting treatment response in oncology. Results: This framework is based on seven key steps specifying: (1) the intended use of AI, (2) the target population, (3) the timing of AI evaluation, (4) the datasets used for evaluation, (5) the procedures used for ensuring data safety (including data quality, privacy and security), (6) the metrics used for measuring performance, and (7) the procedures used to ensure that the AI is explainable. This framework forms the basis of a validation platform that we are building for the ""ITFoC Challenge"". This community-wide competition will make it possible to assess and compare AI algorithms for predicting the response to TNBC treatments with external real-world datasets. Conclusions: The predictive performance and safety of AI technologies must be assessed in a robust, unbiased and transparent manner before their implementation in healthcare settings. We believe that the consideration of the ITFoC consortium will contribute to the safe transfer and implementation of AI in clinical settings, in the context of precision oncology and personalized care",,'Springer Science and Business Media LLC',A framework for validating AI in precision medicine: considerations from the European ITFoC consortium,10.1186/s12911-021-01634-3,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
429033224,2021-01-01T00:00:00,"Artificial intelligence (AI), machine learning (ML) and big data are consistently called upon to analyze and comprehend many facets of modern daily life. AI and ML in particular are widely used in animal husbandry to monitor both the animals and environment around the clock, which leads to a better understanding of animal behavior and distress, disease control and prevention, and effective business decisions for the farmer. One particularly promising area that advances upon AI is digital twin technology, which is currently used to improve efficiencies and reduce costs across multiple industries and sectors. In contrast to a model, a digital twin is a digital replica of a real-world entity that is kept current with a constant influx of data. The application of digital twins within the livestock farming sector is the next frontier and has the potential to be used to improve large-scale precision livestock farming practices, machinery and equipment usage, and the health and well-being of a wide variety of farm animals. The mental and emotional states of animals can be monitored using recognition technology that examines facial features, such as ear postures and eye white regions. Used with modeling, simulation and augmented reality technologies, digital twins can help farmers to build more energy-efficient housing structures, predict heat cycles for breeding, discourage negative behaviors of livestock, and potentially much more. As with all disruptive technological advances, the implementation of digital twin technology will demand a thorough cost and benefit analysis of individual farms. Our goal in this review is to assess the progress toward the use of digital twin technology in livestock farming, with the goal of revolutionizing animal husbandry in the future. View Full-Tex",,'MDPI AG',Digital Twins in Livestock Farming,10.3390/ani11041008,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
389359328,2021-01-14T00:00:00,"Cardiovascular diseases have been reported to be the leading cause of mortality across the globe. Among such diseases, Myocardial Infarction (MI), also known as “heart attack”, is of main interest among researchers, as its early diagnosis can prevent life threatening cardiac conditions and potentially save human lives. Analyzing the Electrocardiogram (ECG) can provide valuable diagnostic information to detect different types of cardiac arrhythmia. Real-time ECG monitoring systems with advanced machine learning methods provide information about the health status in real-time and have improved user’s experience. However, advanced machine learning methods have put a burden on portable and wearable devices due to their high computing requirements. We present an improved, less complex Convolutional Neural Network (CNN)-based classifier model that identifies multiple arrhythmia types using the two-dimensional image of the ECG wave in real-time. The proposed model is presented as a three-layer ECG signal analysis model that can potentially be adopted in real-time portable and wearable monitoring devices. We have designed, implemented, and simulated the proposed CNN network using Matlab. We also present the hardware implementation of the proposed method to validate its adaptability in real-time wearable systems. The European ST-T database recorded with single lead L3 is used to validate the CNN classifier and achieved an accuracy of 99.23%, outperforming most existing solutions.https://doi.org/10.3390/electronics1002017",,'MDPI AG',Multiclass ECG Signal Analysis Using Global Average-Based 2-D Convolutional Neural Network Modeling,,https://core.ac.uk/download/389359328.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
437429008,2022-03-31T00:00:00,"The Internet of Things (IoT), in combination with advancements in Big Data, communications and networked systems, offers a positive impact across a range of sectors including health, energy, manufacturing and transport. By virtue of current business models adopted by manufacturers and ICT operators, IoT devices are deployed over various networked infrastructures with minimal security, opening up a range of new attack vectors. Conventional rule-based intrusion detection mechanisms used by network management solutions rely on pre-defined attack signatures and hence are unable to identify new attacks. In parallel, anomaly detection solutions tend to suffer from high false positive rates due to the limited statistical validation of ground truth data, which is used for profiling normal network behaviour. In this work we go beyond current solutions and leverage the coupling of anomaly detection and Cyber Threat Intelligence (CTI) with parallel processing for the profiling and detection of emerging cyber attacks. We demonstrate the design, implementation, and evaluation of Citrus: a novel intrusion detection framework which is adept at tackling emerging threats through the collection and labelling of live attack data by utilising diverse Internet vantage points in order to detect and classify malicious behaviour using graph-based metrics as well as a range of machine learning (ML) algorithms. Citrus considers the importance of ground truth data validation and its flexible software architecture enables both the real-time and offline profiling, detection and classification of emerging cyber-attacks under optimal computational costs. Thus, establishing it as a viable and practical solution for next generation network defence and resilience strategies",,'Institute of Electrical and Electronics Engineers (IEEE)',Practical Intrusion Detection of Emerging Threats,10.1109/TNSM.2021.3091517,https://core.ac.uk/download/437429008.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
342671590,2020-11-01T00:00:00,"Intelligent fault diagnosis methods have replaced time consuming and unreliable human analysis, increasing anomaly detection efficiency. Deep learning models are clear cut techniques for this purpose. This paper’s fundamental purpose is to automatically detect leakage in tanks during production with more reliability than a manual inspection, a common practice in industries. This research proposes an inspection system to predict tank leakage using hydrophone sensor data and deep learning algorithms after production. In this paper, leak detection was investigated using an experimental setup consisting of a plastic tank immersed underwater. Three different techniques for this purpose were implemented and compared with each other, including fast Fourier transform (FFT), wavelet transforms, and time-domain features, all of which are followed with 1D convolution neural network (1D-CNN). Applying FFT and converting the signal to a 1D image followed by 1D-CNN showed better results than other methods. Experimental results demonstrate the effectiveness and the superiority of the proposed methodology for detecting real-time leakage inaccuracy",,'MDPI AG',Deep Learning Model for Industrial Leakage Detection Using Acoustic Emission Signal,10.3390/informatics7040049,https://core.ac.uk/download/342671590.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
427382360,2019-09-19T00:00:00,"Driven by the demand to accommodate today’s growing mobile traffic, 5G is designed to

be a key enabler and a leading infrastructure provider in the information and communication technology

industry by supporting a variety of forthcoming services with diverse requirements. Considering the everincreasing

complexity of the network, and the emergence of novel use cases such as autonomous cars,

industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML)

is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential

solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised,

unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of

ML in the context of mobile and wireless communication, organizing the literature in terms of the types of

learning.We then discuss the promising approaches for how ML can contribute to supporting each target 5G

network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have

on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G),

providing future research directions for how ML can contribute to realizing B5G. This article is intended

to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of

autonomous 5G/B5G mobile and wireless communications",,'Institute of Electrical and Electronics Engineers (IEEE)',"Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions",10.1109/ACCESS.2019.2942390,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
334966798,2021-07-01T00:00:00,"Timed Failure Propagation Graphs (TFPGs) have been widely used for the failure modeling and diagnosis of safety-critical systems. Currently most TFPGs are manually constructed by system experts, a process that can be time-consuming, error-prone, and even impossible for systems with highly nonlinear and machine-learning-based components. This letter proposes a new type of TFPGs, called Real-Valued Timed Failure Propagation Graphs (rTFPGs), designed for continuous-state systems. More importantly, it presents a systematic way of constructing rTFPGs by combining the powers of human experts and data-driven methods: first, an expert constructs a partial rTFPG based on his/her expertise; then a data-driven algorithm refines the rTFPG by adding nodes and edges based on a given set of labeled signals. The proposed approach has been successfully implemented and evaluated on three case studies",,"eScholarship, University of California",Data-Driven Real-Valued Timed-Failure-Propagation-Graph Refinement for Complex System Fault Diagnosis,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481464351,2021-01-01T00:00:00,"The concentration of fine particulate matter (PM2.5) has a significant impact on the environment and human health. However, strong spatial heterogeneity and spatiotemporal dependence increases the difficulty of prediction. Moreover, due to the lag of the update of auxiliary variables at national scale in the prediction application, it is still difficult to achieve the timely nationwide PM2.5 prediction at present. To better model and predict real time concentrations and spatial distributions of PM2.5, this study developed a workflow of future PM2.5 concentrations prediction based on long short-term memory (LSTM) model. Using ground-based station PM2.5 data in 2014–2018, the 1 km Multi-Angle Implementation of Atmospheric Correction (MAIAC) aerosol optical depth (AOD) product and other auxiliary data to predict PM2.5 concentrations in the next year and generate a high-resolution national PM2.5 concentration spatial distribution map. The LSTM model outperformed random forest (RF) and Cubist approaches for prediction PM2.5 because of its recurrent neural network structure that can capture time dependence and nonlinear relationships among PM2.5 concentrations and other independent variables, and exhibited a stable accuracy with an R2 of 0.83, by applying the annual time series, with an improvement of 0.04–0.09, compared to daily and monthly data. The results indicated that PM2.5 pollution had gradually decreased in 2019 after application of pollution controls, with annual mean PM2.5 concentrations of 27.33 ± 15.56 μg m−3, although there were still some areas with severe pollution, including the North China Plain, parts of the Loess Plateau, and the Taklimakan Desert. The LSTM model makes it possible to predict fine-scale PM2.5 spatial distributions nationwide in the future and may thus be useful for sustainable management and control of air pollution at a national scale",,'Elsevier BV',High-resolution prediction of the spatial distribution of PM2.5 concentrations in China using a long short-term memory model,10.1016/j.jclepro.2021.126493,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
347252513,2020-04-28T00:00:00,"International audienceBackground: High-throughput sequencing techniques are used to analyse the diversity of the respiratory microbiota in health and disease. Although extensive data are available regarding bacterial respiratory microbiota, its fungal component remains poorly studied. This is partly due to the technical issues associated with fungal metagenomics analyses. In this study, we compared two DNA extraction protocols and two fungal amplification targets for combined bacterial and fungal targeted amplicon sequencing analyses of the respiratory microbiota.Methods: Six sputa, randomly selected from routine samples in Mondor Hospital (Creteil, France) and treated anonymously, were tested after bacterial and fungal routine culture. Two of which were spiked with Aspergillus Fumigati and Aspergillus Nigri (105 conidia/mL). After mechanical lysis, DNA was extracted using automated QIAsymphony® extraction (AQE) or manual PowerSoil® MoBio extraction (MPE). DNA yield and purity were compared. DNA extracted from spiked sputa was subjected to (i) real-time PCR for Aspergillus DNA detection and (ii) combined metagenomic analyses targeting barcoded primers for fungal ITS1 and ITS2, and bacterial V1-V2 and V3-V4 16S regions. Amplicon libraries were prepared using MiSeq Reagent V3 kit on Illumina platform. Data were analysed using PyroMIC© and SHAMAN software, and compared with culture results.Results: AQE extraction provided a higher yield of DNA (AQE/MPE DNA ratio = 4.5 [1.3-11]) in a shorter time. The yield of Aspergillus DNA detected by qPCR was similar for spiked sputa regardless of extraction protocol. The extraction moderately impacted the diversity or relative abundances of bacterial communities using targeted amplicon sequencing (2/43 taxa impacted). For fungi, the relative abundances of 4/11 major taxa were impacted and AQE results were closer to culture results. The V1-V2 or V3-V4 and ITS1 or ITS2 targets assessed similarly the diversity of bacterial and fungal major taxa, but ITS2 and V3-V4 detected more minor taxa.Conclusion: Our results showed the importance of DNA extraction for combined bacterial and fungal targeted metagenomics of respiratory samples. The extraction protocol can affect DNA yield and the relative abundances of few bacterial but more fungal taxa. For fungal analysis, ITS2 allowed the detection of a greater number of minor taxa compared with ITS1",,'Public Library of Science (PLoS)',Combined bacterial and fungal targeted amplicon sequencing of respiratory samples: Does the DNA extraction method matter?,10.1371/journal.pone.0232215,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
490870289,2021-03-01T00:00:00,"Recent advancements in the field of artificial intelligence have demonstrated success in a variety of clinical tasks secondary to the development and application of big data, supercomputing, sensor networks, brain science, and other technologies. However, no projects can yet be used on a large scale in real clinical practice because of the lack of standardized processes, lack of ethical and legal supervision, and other issues. We analyzed the existing problems in the field of artificial intelligence and herein propose possible solutions. We call for the establishment of a process framework to ensure the safety and orderly development of artificial intelligence in the medical industry. This will facilitate the design and implementation of artificial intelligence products, promote better management via regulatory authorities, and ensure that reliable and safe artificial intelligence products are selected for application","[{'title': 'Journal of International Medical Research', 'identifiers': ['issn:1473-2300', '1473-2300']}]",'SAGE Publications',"Opportunities and challenges of artificial intelligence in the medical field: current application, emerging problems, and problem-solving strategies",10.1177/03000605211000157,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440767050,2020-01-01T00:00:00,"Modern buildings usually have an air-tight envelope. Therefore mechanical ventilation is very often necessary. A crucial part of the system is the filter, which allows creating an atmosphere that is free of dust, aerosols, and pollen. As organic material accumulates on the filter surface, the risk of micro-organism growth rises. This may yield health issues especially for the occupants of buildings.
The method was implemented in both a test rig and the HVAC system supplying different laboratories with fresh air in order to aggregate data for different abnormal and normal operation conditions. Subsequent considerations focuses on the test-rig measurements. The machine learning algorithm was trained successfully to detect anomalies of the filter behavior.
Finally, the change intervals of the filter may be adapted to the real degree of pollution without the requirement for visual observation in order to provide best air conditions. This algorithm is part of a general strategy for machine-learning processes for HVAC systems","[{'title': 'MATEC Web of Conferences', 'identifiers': ['issn:2261-236X', '2261-236x']}]",'EDP Sciences',Machine learning for filter pollution control,10.1051/matecconf/202032403002,https://core.ac.uk/download/440767050.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275782095,2019,"International audienceBACKGROUND: Mortality surveillance is of fundamental importance to public health surveillance. The real-time recording of death certificates, thanks to Electronic Death Registration System (EDRS), provides valuable data for reactive mortality surveillance based on medical causes of death in free-text format. Reactive mortality surveillance is based on the monitoring of mortality syndromic groups (MSGs). An MSG is a cluster of medical causes of death (pathologies, syndromes or symptoms) that meets the objectives of early detection and impact assessment of public health events. The aim of this study is to implement and measure the performance of a rule-based method and two supervised models for automatic free-text cause of death classification from death certificates in order to implement them for routine surveillance.METHOD: A rule-based method was implemented using four processing steps: standardization rules, splitting causes of death using delimiters, spelling corrections and dictionary projection. A supervised machine learning method using a linear Support Vector Machine (SVM) classifier was also implemented. Two models were produced using different features (SVM1 based solely on surface features and SVM2 combining surface features and MSGs classified by the rule-based method as feature vectors). The evaluation was conducted using an annotated subset of electronic death certificates received between 2012 and 2016. Classification performance was evaluated on seven MSGs (Influenza, Low respiratory diseases, Asphyxia/abnormal respiration, Acute respiratory disease, Sepsis, Chronic digestive diseases, and Chronic endocrine diseases).RESULTS: The rule-based method and the SVM2 model displayed a high performance with F-measures over 0.94 for all MSGs. Precision and recall were slightly higher for the rule-based method and the SVM2 model. An error-analysis shows that errors were not specific to an MSG.CONCLUSION: The high performance of the rule-based method and SVM2 model will allow us to set-up a reactive mortality surveillance system based on free-text death certificates. This surveillance will be an added-value for public health decision making",,Elsevier,Automatic classification of free-text medical causes from death certificates for reactive mortality surveillance in France,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
475700206,2021-08-12T09:43:26,"Advances in Deep Neural Network (DNN) techniques have revolutionized video analytics and unlocked the potential for querying
and mining video event patterns. This paper details GNOSIS, an
event processing platform to perform near-real-time video event
detection in a distributed setting. GNOSIS follows a serverless approach where its component acts as independent microservices
and can be deployed at multiple nodes. GNOSIS uses a declarative
query-driven approach where users can write customize queries
for spatiotemporal video event reasoning. The system converts the
incoming video streams into a continuous evolving graph stream
using machine learning (ML) and DNN models pipeline and applies graph matching for video event pattern detection. GNOSIS
can perform both stateful and stateless video event matching. To
improve Quality of Service (QoS), recent work in GNOSIS incorporates optimization techniques like adaptive scheduling, energy
efficiency, and content-driven windows. This paper demonstrates
the Occupational Health and Safety query use cases to show the
GNOSIS efficacyThis work was supported with the financial support of the Science
Foundation Ireland (SFI) grant SFI/12/RC/2289_P2",,'VLDB Endowment',Query-driven video event processing for the internet of multimedia things,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
479628118,2021-01-01T00:00:00,"This paper discusses the development and implementation of the architecture of a Framework for Aerospace Vehicle Reasoning, &#x2018;FAVER&#x2019;. Integrated Vehicle Health Management systems require a holistic view of the aircraft to isolate faults cascading between aircraft systems. FAVER is a system-agnostic framework developed to isolate such propagating faults by incorporating Digital Twins (DTs) and reasoning techniques. The flexibility of FAVER to work with different types and scales of DTs and diagnostics, and its ability to adapt and expand for previously unknown faults and new systems are demonstrated in this paper. The paper also shows the novel combination of relationship matrix and fault attributes database used to structure the knowledge of FAVER&#x2019;s expert system. The paper provides the working mechanism of FAVER&#x2019;s reasoning and its ability to isolate faults at the system level, identify their root causes, and predict the cascading effects at the vehicle level. Four aircraft systems are used for demonstration purposes: i) the Electrical Power System, ii) the Fuel System, iii) the Engine, and iv) the Environmental Control System, and the use case scenarios are adapted from real aircraft incidents. The paper also discusses the pros and cons of FAVER&#x2019;s reasoning via demonstrations and evaluates the performance of FAVER&#x2019;s reasoning through a comparative study with a supervised neural network model","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Development and Implementation of a <underline>F</underline>ramework for <underline>A</underline>erospace <underline>Ve</underline>hicle <underline>R</underline>easoning (FAVER),10.1109/ACCESS.2021.3100865,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
482096742,2021-09-01T00:00:00,"In recent times, health applications have been gaining rapid popularity in smart cities using the Internet of Medical Things (IoMT). Many real-time solutions are giving benefits to both patients and professionals for remote data accessibility and suitable actions. However, timely medical decisions and efficient management of big data using IoT-based resources are the burning research challenges. Additionally, the distributed nature of data processing in many proposed solutions explicitly increases the threats of information leakages and damages the network integrity. Such solutions impose overhead on medical sensors and decrease the stability of the real-time transmission systems. Therefore, this paper presents a machine-learning model with SDN-enabled security to predict the consumption of network resources and improve the delivery of sensors data. Additionally, it offers centralized-based software define network (SDN) architecture to overcome the network threats among deployed sensors with nominal management cost. Firstly, it offers an unsupervised machine learning technique and decreases the communication overheads for IoT networks. Secondly, it predicts the link status using dynamic metrics and refines its strategies using SDN architecture. In the end, a security algorithm is utilized by the SDN controller that efficiently manages the consumption of the IoT nodes and protects it from unidentified occurrences. The proposed model is verified using simulations and improves system performance in terms of network throughput by 13%, data drop ratio by 39%, data delay by 11%, and faulty packets by 46% compared to HUNA and CMMA schemes","[{'title': 'Electronics', 'identifiers': ['issn:2079-9292', '2079-9292']}]",'MDPI AG',A Machine Learning SDN-Enabled Big Data Model for IoMT Systems,10.3390/electronics10182228,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491079861,2021-11-01T00:00:00,"Today, artificial intelligence (AI) and machine learning (ML) have dramatically advanced in various industries, especially medicine. AI describes computational programs that mimic and simulate human intelligence, for example, a person’s behavior in solving problems or his ability for learning. Furthermore, ML is a subset of artificial intelligence. It extracts patterns from raw data automatically. The purpose of this paper is to help researchers gain a proper understanding of machine learning and its applications in healthcare. In this paper, we first present a classification of machine learning-based schemes in healthcare. According to our proposed taxonomy, machine learning-based schemes in healthcare are categorized based on data pre-processing methods (data cleaning methods, data reduction methods), learning methods (unsupervised learning, supervised learning, semi-supervised learning, and reinforcement learning), evaluation methods (simulation-based evaluation and practical implementation-based evaluation in real environment) and applications (diagnosis, treatment). According to our proposed classification, we review some studies presented in machine learning applications for healthcare. We believe that this review paper helps researchers to familiarize themselves with the newest research on ML applications in medicine, recognize their challenges and limitations in this area, and identify future research directions","[{'title': 'Mathematics', 'identifiers': ['issn:2227-7390', '2227-7390']}]",'MDPI AG',"Machine Learning (ML) in Medicine: Review, Applications, and Challenges",10.3390/math9222970,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
305118535,2020-04-01T00:00:00,"Real-world epidemiology gives us the unique opportunity to observe large numbers of people, and the actions and events that characterize their encounters with healthcare providers. However, the heterogeneity and sheer diversity of the population and healthcare systems makes it impossible for researchers to compare “like with like” when attempting to draw causal inferences about interventions and outcomes. The critical issue in epidemiological datasets relates to high risk of bias due to confounders that stem from baseline differences between groups. Propensity score (PS) techniques are statistical approaches that have been used to tackle potential imbalance in the comparison groups. The PS is the estimated probability (based on measured baseline covariates) that the patient receives a particular intervention. Patients that share similar PS will most likely have the same distributions of underlying covariates included in the PS. Implementation of PS methods may achieve better balance of covariates, but there is no consensus on the best way of capturing all relevant confounders for incorporation into the PS model. Should covariates be selected by clinical or epidemiological experts, or would data-driven algorithms (machine learning) offer more efficient and reliable methods of estimating PS and controlling for confounding? The PS can be incorporated into the analysis in different ways, each with its own strengths and limitations, and researchers must choose the best fit for their study objectives. PS methods are particularly advantageous in situations where there are large numbers of measured covariates but relatively few outcome events captured in healthcare administrative databases",,'Wiley',Propensity score methods in real-world epidemiology:A practical guide for first-time users,10.1111/dom.13926,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
479162137,2021-06-11T00:00:00,"Introduction: Disease behaviour may guide diagnosis and treatment decisions in patients with interstitial lung disease (ILD). STARLINER aimed to characterise disease behaviour in patients with suspected ILD during the peri-diagnostic period using real-time home-based assessments. Methods: STARLINER (NCT03261037) was an international, multicentre study. Patients ≥ 50 years old with suspected ILD were followed throughout the peri-diagnostic period, consisting of a pre-diagnostic period (from enrolment to diagnosis) and a post-diagnostic period (from diagnosis to treatment initiation). Study length was variable (≤ 18 months). The primary endpoint was time-adjusted semi-annual forced vital capacity (FVC) change measured during the peri-diagnostic period using daily home spirometry in patients with idiopathic pulmonary fibrosis (IPF). Secondary outcomes included changes in FVC (home spirometry) in patients with non-IPF ILD, changes in FVC (site spirometry), changes in physical functional capacity measured by daily home accelerometry and site 6-min walk distance (6MWD), and changes in patient-reported outcomes (PROs) in IPF or non-IPF ILD. Results: Of the 178 patients enrolled in the study, 68 patients were diagnosed with IPF, 62 patients were diagnosed with non-IPF ILD, 9 patients received a non-ILD diagnosis and 39 patients did not receive a diagnosis. Technical and analytical issues led to problems in applying the prespecified linear regression model to analyse the home FVC data. Time-adjusted median (quartile [Q]1, Q3) semi-annual FVC change during the peri-diagnostic period measured using home and site spirometry, respectively, was – 147.7 (– 723.8, 376.2) ml and – 149.0 (– 314.6, 163.9) ml for IPF and 19.1 (– 194.9, 519.0) ml and – 23.4 (– 117.9, 133.5) ml in non-IPF ILD. A greater decline in steps per day was observed for IPF versus non-IPF ILD, whereas an increase in 6MWD was observed for patients with IPF versus a decline in 6MWD for patients with non-IPF ILD. No clear patterns of disease behaviour were observed for IPF versus non-IPF ILD for PROs. Conclusions: Despite home spirometry being feasible for most patients and centres, technical and analytical challenges in the home-based assessments prevented firm conclusions regarding disease behaviour. This highlights that further optimisation of the technology and analysis methods is required before widespread implementation. Trial Registration: NCT03261037.</p",,'Springer Science and Business Media LLC',Disease Behaviour During the Peri-Diagnostic Period in Patients with Suspected Interstitial Lung Disease,10.1007/s12325-021-01790-y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
387260665,2020-01-01T00:00:00,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions. (C) 2020 The Author(s). Published by Elsevier Ltd.Funding Agencies|National Natural Science Foundation of ChinaNational Natural Science Foundation of China (NSFC) [71971030]; Shaanxi Provincial Natural Science Foundation of China [2019JM-495]; Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities [300102220203]</p",,'Elsevier BV',An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,10.1016/j.jclepro.2020.123365,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
492719501,2022-03-22T00:00:00,"The recent development in the areas of deep learning and deep convolutional neural networks has significantly progressed and advanced the field of computer vision (CV) and image analysis and understanding. Complex tasks such as classifying and segmenting medical images and localising and recognising objects of interest have become much less challenging. This progress has the potential of accelerating research and deployment of multitudes of medical applications that utilise CV. However, in reality, there are limited practical examples being physically deployed into front-line health facilities. In this paper, we examine the current state of the art in CV as applied to the medical domain. We discuss the main challenges in CV and intelligent data-driven medical applications and suggest future directions to accelerate research, development, and deployment of CV applications in health practices. First, we critically review existing literature in the CV domain that addresses complex vision tasks, including: medical image classification; shape and object recognition from images; and medical segmentation. Second, we present an in-depth discussion of the various challenges that are considered barriers to accelerating research, development, and deployment of intelligent CV methods in real-life medical applications and hospitals. Finally, we conclude by discussing future directions",,Artificial Intelligence Surgery,"Computer vision and machine learning for medical image analysis: recent advances, challenges, and way forward",,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
329118121,2020-12-01T00:00:00,"This paper puts forward a real-time smart fault diagnosis system (SFDS) intended for high-speed protection of power system transmission lines. This system is based on advanced signal processing techniques, traveling wave theory results, and machine learning algorithms. The simulation results show that the SFDS can provide an accurate internal/external fault discrimination, fault inception time estimation, fault type identification, and fault location. This paper presents also the hardware requirements and software implementation of the SFDS",,'Institute of Advanced Engineering and Science',A real-time fault diagnosis system for high-speed power system protection based on machine learning algorithms,10.11591/ijece.v10i6.pp6122-6138,https://core.ac.uk/download/329118121.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
477990915,2020-08-01T00:00:00,"[EN] We show a simple model of the dynamics of a viral process based, on the determination of the Kaplan-Meier curvePof the virus. Together with the function of the newly infected individualsI, this model allows us to predict the evolution of the resulting epidemic process in terms of the numberEof the death patients plus individuals who have overcome the disease. Our model has as a starting point the representation ofEas the convolution ofIandP. It allows introducing information about latent patients-patients who have already been cured but are still potentially infectious, and re-infected individuals. We also provide three methods for the estimation ofPusing real data, all of them based on the minimization of the quadratic error: the exact solution using the associated Lagrangian function and Karush-Kuhn-Tucker conditions, a Monte Carlo computational scheme acting on the total set of local minima, and a genetic algorithm for the approximation of the global minima. Although the calculation of the exact solutions of all the linear systems provided by the use of the Lagrangian naturally gives the best optimization result, the huge number of such systems that appear when the time variable increases makes it necessary to use numerical methods. We have chosen the genetic algorithms. Indeed, we show that the results obtained in this way provide good solutions for the model.This research was funded by Ministerio de Ciencia, Innovacion y Universidades: MTM2016-77054-C2-1-P and Generalitat Valenciana: Catedra de Transparencia y Gestion de Datos (U.P.V.). The authors would like to thank the referees for their valuable comments which helped
to improve the manuscript. The author gratefully acknowledge the support of Cátedra de Transparencia y
Gestión de Datos, Universitat Politècnica de València y Generalitat Valenciana, Spain. The last author gratefully
acknowledges the support of the Ministerio de Ciencia, Innovación y Universidades (Spain) and FEDER under
grant MTM2016-77054-C2-1-P.Calabuig, JM.; García-Raffi, LM.; García-Valiente, A.; Sánchez Pérez, EA. (2020). Evolution Model for Epidemic Diseases Based on the Kaplan-Meier Curve Determination. Mathematics. 8(8):1-25. https://doi.org/10.3390/math8081260S12588Ai, T., Yang, Z., Hou, H., Zhan, C., Chen, C., Lv, W., … Xia, L. (2020). Correlation of Chest CT and RT-PCR Testing for Coronavirus Disease                     2019 (COVID-19) in China: A Report of 1014 Cases. Radiology, 296(2), E32-E40. doi:10.1148/radiol.2020200642Chen, D., Xu, W., Lei, Z., Huang, Z., Liu, J., Gao, Z., & Peng, L. (2020). Recurrence of positive SARS-CoV-2 RNA in COVID-19: A case report. International Journal of Infectious Diseases, 93, 297-299. doi:10.1016/j.ijid.2020.03.003Kaplan, E. L., & Meier, P. (1958). Nonparametric Estimation from Incomplete Observations. Journal of the American Statistical Association, 53(282), 457-481. doi:10.1080/01621459.1958.10501452Kenah, E. (2010). Contact intervals, survival analysis of epidemic data, and estimation of R0. Biostatistics, 12(3), 548-566. doi:10.1093/biostatistics/kxq068Kenah, E. (2012). Non-parametric survival analysis of infectious disease data. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 75(2), 277-303. doi:10.1111/j.1467-9868.2012.01042.xOgłuszka, M., Orzechowska, M., Jędroszka, D., Witas, P., & Bednarek, A. K. (2019). Evaluate Cutpoints: Adaptable continuous data distribution system for determining survival in Kaplan-Meier estimator. Computer Methods and Programs in Biomedicine, 177, 133-139. doi:10.1016/j.cmpb.2019.05.023Hethcote, H. W. (2000). The Mathematics of Infectious Diseases. SIAM Review, 42(4), 599-653. doi:10.1137/s0036144500371907Silal, S. P., Little, F., Barnes, K. I., & White, L. J. (2016). Sensitivity to model structure: a comparison of compartmental models in epidemiology. Health Systems, 5(3), 178-191. doi:10.1057/hs.2015.2Kamvar, Z. N., Cai, J., Pulliam, J. R. C., Schumacher, J., & Jombart, T. (2019). Epidemic curves made easy using the R package incidence. F1000Research, 8, 139. doi:10.12688/f1000research.18002.1Lectures on Mathematical Modelling of Biological Systemshttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.8665&rep=rep1&type=pdfKeeling, M. J., & Danon, L. (2009). Mathematical modelling of infectious diseases. British Medical Bulletin, 92(1), 33-42. doi:10.1093/bmb/ldp038Brown, G. D., Oleson, J. J., & Porter, A. T. (2015). An empirically adjusted approach to reproductive number estimation for stochastic compartmental models: A case study of two Ebola outbreaks. Biometrics, 72(2), 335-343. doi:10.1111/biom.12432Huppert, A., & Katriel, G. (2013). Mathematical modelling and prediction in infectious disease epidemiology. Clinical Microbiology and Infection, 19(11), 999-1005. doi:10.1111/1469-0691.12308Paul, M. (2013). Foreseeing the future in infectious diseases: can we? Clinical Microbiology and Infection, 19(11), 991-992. doi:10.1111/1469-0691.12300Roosa, K., Lee, Y., Luo, R., Kirpich, A., Rothenberg, R., Hyman, J. M., … Chowell, G. (2020). Short-term Forecasts of the COVID-19 Epidemic in Guangdong and Zhejiang, China: February 13–23, 2020. Journal of Clinical Medicine, 9(2), 596. doi:10.3390/jcm9020596Package ‘GA’-CRAN-R Projecthttps://luca-scr.github.io/GA/Scrucca, L. (2013). GA: A Package for Genetic Algorithms inR. Journal of Statistical Software, 53(4). doi:10.18637/jss.v053.i0",,'MDPI AG',Evolution Model for Epidemic Diseases Based on the Kaplan-Meier Curve Determination,10.3390/math8081260,https://riunet.upv.es/bitstream/10251/172000/1/CalabuigGarcia-RaffiGarcia-Valiente%20-%20Evolution%20Model%20for%20Epidemic%20Diseases%20Based%20on%20the%20Kaplan-M....pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
489480182,2021-03-26T00:00:00,"Portuguese legislation states the compulsory reporting of the addition of
amenities, such as swimming pools, to the Portuguese tax authority. The purpose is
to update the property tax value, to be charged annually to the owner of each real estate.
According to MarketWatch, this decade will bring a global rise to the number of swimming
pools due to certain factors such as: cost reduction, increasing health consciousness, and
others. The need for inspections to ensure that all new constructions are communicated
to the competent authorities is therefore rapidly increasing and new solutions are needed
to address this problem. Typically, supervision is done by sending human resources to the
field, involving huge time and resource consumption, and preventing the catalogue from
updating at a rate close to the speed of construction. Automation is rapidly becoming an
absolute requirement to improve task efficiency and affordability. Recently, Deep Learn-
ing algorithms have shown incredible performance results when used for object detection
tasks. Based on the above, this work presents a study on the various existing object detec-
tion algorithms and the implementation of a Deep Learning model capable of recognizing
swimming pools from satellite images. To achieve the best results for this specific task, the
RetinaNet algorithm was chosen. To provide a smooth user experience with the developed
model, a simple graphical user interface was also created",,,Development of a machine learning model and a user interface to detect illegal swimming pools,,https://core.ac.uk/download/489480182.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
511317478,2021-07-01T00:00:00,"Making the transition to long-term interaction with social-robot systems has been identified as one of the main challenges in human-robot interaction. This article identifies four design principles to address this challenge and applies them in a real-world implementation: cloud-based robot control, a modular design, one common knowledge base for all applications, and hybrid artificial intelligence for decision making and reasoning. The control architecture for this robot includes a common Knowledge-base (ontologies), Data-base, “Hybrid Artificial Brain” (dialogue manager, action selection and explainable AI), Activities Centre (Timeline, Quiz, Break and Sort, Memory, Tip of the Day, ), Embodied Conversational Agent (ECA, i.e., robot and avatar), and Dashboards (for authoring and monitoring the interaction). Further, the ECA is integrated with an expandable set of (mobile) health applications. The resulting system is a Personal Assistant for a healthy Lifestyle (PAL), which supports diabetic children with self-management and educates them on health-related issues (48 children, aged 6–14, recruited via hospitals in the Netherlands and in Italy). It is capable of autonomous interaction “in the wild” for prolonged periods of time without the need for a “Wizard-of-Oz” (up until 6 months online). PAL is an exemplary system that provides personalised, stable and diverse, long-term human-robot interaction","[{'title': 'ACM Transactions on Human-Robot Interaction', 'identifiers': ['2573-9522', 'issn:2573-9522']}]",'Association for Computing Machinery (ACM)',"A cloud-based robot system for long-term interaction: principles, implementation, lessons learned",10.1145/3481585,https://core.ac.uk/download/511317478.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
464949051,2021-07-01T00:00:00,"Computer aided diagnosis for mammogram images have seen positive results through the usage of deep learning architectures. However, limited sample sizes for the target datasets might prevent the usage of a deep learning model under real world scenarios. The usage of unlabeled data to improve the accuracy of the model can be an approach to tackle the lack of target data. Moreover, important model attributes for the medical domain as model uncertainty might be improved through the usage of unlabeled data. Therefore, in this work we explore the impact of using unlabeled data through the implementation of a recent approach known as MixMatch, for mammogram images.
We evaluate the improvement on accuracy and uncertainty of
the model using popular and simple approaches to estimate
uncertainty. For this aim, we propose the usage of the uncertainty
balanced accuracy metric.Universidad de Málaga. Campus de Excelencia Internacional Andalucía Tech",,,Improving Uncertainty Estimations for Mammogram Classification using Semi-Supervised Learning,,https://core.ac.uk/download/464949051.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
395143868,2021-02-01T00:00:00,"[EN] Wetlands play a key role in preserving biodiversity and preventing climate change. Their conservation poses an important and pressing challenge. In the Mediterranean region, one of the key threats to wetland survival is the lack of water due to competition for resources. The selection of the most sustainable water resources for wetland conservation is a complex elicitation problem. A novel Water Resources Sustainability Model (WRSM) focused on water quality has been developed to support the decision-making. This collaborative elicitation model is based on the analytical hierarchy process and uses the reference environmental status of the wetland. The model can be used to discriminate which water resources are more sustainable for the conservation of the wetland. The WRSM has been applied successfully to Las Tablas de Daimiel National Park. The framework enables establishing priorities when analyzing in terms of water quality any surface, recycled or underground water resources.Canto-Perello, J.; Benitez-Navio, A.; Martín Utrillas, MG.; Martinez-Leon, J.; Curiel Esparza, J. (2021). Water resources sustainability model for wetland conservation based on anonymous expert elicitation. Environmental Modelling & Software. 136:1-12. https://doi.org/10.1016/j.envsoft.2020.104952S112136Aguilera, H., & Merino, L. M. (2018). Data on chemical composition of soil and water in the semiarid wetland of Las Tablas de Damiel National Park (Spain) during a drought period. Data in Brief, 19, 2481-2486. doi:10.1016/j.dib.2018.04.085Aguilera, H., Moreno, L., Wesseling, J. G., Jiménez-Hernández, M. E., & Castaño, S. (2016). Soil moisture prediction to support management in semiarid wetlands during drying episodes. CATENA, 147, 709-724. doi:10.1016/j.catena.2016.08.007Alafifi, A. H., & Rosenberg, D. E. (2020). Systems modeling to improve river, riparian, and wetland habitat quality and area. Environmental Modelling & Software, 126, 104643. doi:10.1016/j.envsoft.2020.104643Alvarez Etxeberria, I., Garayar, A., & Calvo Sánchez, J. A. (2015). Development of sustainability reports for farming operations in the Basque Country using the Delphi method. Revista de Contabilidad, 18(1), 44-54. doi:10.1016/j.rcsar.2014.03.004Bilotta, G. S., & Brazier, R. E. (2008). Understanding the influence of suspended solids on water quality and aquatic biota. Water Research, 42(12), 2849-2861. doi:10.1016/j.watres.2008.03.018Bilotta, G. S., Burnside, N. G., Cheek, L., Dunbar, M. J., Grove, M. K., Harrison, C., … Davy-Bowker, J. (2012). Developing environment-specific water quality guidelines for suspended particulate matter. Water Research, 46(7), 2324-2332. doi:10.1016/j.watres.2012.01.055Blaas, H., & Kroeze, C. (2016). Excessive nitrogen and phosphorus in European rivers: 2000–2050. Ecological Indicators, 67, 328-337. doi:10.1016/j.ecolind.2016.03.004Caen, A., Latour, D., & Mathias, J. D. (2019). Dynamical effects of retention structures on the mitigation of lake eutrophication. Environmental Modelling & Software, 119, 309-326. doi:10.1016/j.envsoft.2019.06.012Camargo, J. A., & Alonso, Á. (2006). Ecological and toxicological effects of inorganic nitrogen pollution in aquatic ecosystems: A global assessment. Environment International, 32(6), 831-849. doi:10.1016/j.envint.2006.05.002Canto-Perello, J., Martinez-Leon, J., Curiel-Esparza, J., & Martin-Utrillas, M. (2017). Consensus in prioritizing river rehabilitation projects through the integration of social, economic and landscape indicators. Ecological Indicators, 72, 659-666. doi:10.1016/j.ecolind.2016.09.004Canto-Perello, J., Morera-Escrich, J. L., Martin-Utrillas, M., & Curiel-Esparza, J. (2018). Restoration prioritization framework for roadway high cut slopes to reverse land degradation and fragmentation. Land Use Policy, 71, 470-479. doi:10.1016/j.landusepol.2017.11.020Cirujano, S., Casado, C., Bernués, M., & Camargo, J. A. (1996). Ecological study of Las Tablas de Daimiel National Park (Ciudad Real, central Spain): Differences in water physico-chemistry and vegetation between 1974 and 1989. Biological Conservation, 75(3), 211-215. doi:10.1016/0006-3207(95)00079-8Curiel-Esparza, J., Gonzalez-Utrillas, N., Canto-Perello, J., & Martin-Utrillas, M. (2015). Integrating climate change criteria in reforestation projects using a hybrid decision-support system. Environmental Research Letters, 10(9), 094022. doi:10.1088/1748-9326/10/9/094022Curiel-Esparza, J., Mazario-Diez, J. L., Canto-Perello, J., & Martin-Utrillas, M. (2016). Prioritization by consensus of enhancements for sustainable mobility in urban areas. Environmental Science & Policy, 55, 248-257. doi:10.1016/j.envsci.2015.10.015Curiel-Esparza, J., Reyes-Medina, M., Martin-Utrillas, M., Martinez-Garcia, M. P., & Canto-Perello, J. (2019). Collaborative elicitation to select a sustainable biogas desulfurization technique for landfills. Journal of Cleaner Production, 212, 1334-1344. doi:10.1016/j.jclepro.2018.12.095Dong, Y., Zhang, G., Hong, W.-C., & Xu, Y. (2010). Consensus models for AHP group decision making under row geometric mean prioritization method. Decision Support Systems, 49(3), 281-289. doi:10.1016/j.dss.2010.03.003Forman, E., & Peniwati, K. (1998). Aggregating individual judgments and priorities with the analytic hierarchy process. European Journal of Operational Research, 108(1), 165-169. doi:10.1016/s0377-2217(97)00244-0Gu, S., Gruau, G., Dupas, R., Petitjean, P., Li, Q., & Pinay, G. (2019). Respective roles of Fe-oxyhydroxide dissolution, pH changes and sediment inputs in dissolved phosphorus release from wetland soils under anoxic conditions. Geoderma, 338, 365-374. doi:10.1016/j.geoderma.2018.12.034Haas, M. B., Guse, B., & Fohrer, N. (2017). Assessing the impacts of Best Management Practices on nitrate pollution in an agricultural dominated lowland catchment considering environmental protection versus economic development. Journal of Environmental Management, 196, 347-364. doi:10.1016/j.jenvman.2017.02.060Thi Minh Hanh, P., Sthiannopkao, S., The Ba, D., & Kim, K.-W. (2011). Development of Water Quality Indexes to Identify Pollutants in Vietnam’s Surface Water. Journal of Environmental Engineering, 137(4), 273-283. doi:10.1061/(asce)ee.1943-7870.0000314Hes, E. M., & van Dam, A. A. (2019). Modelling nitrogen and phosphorus cycling and retention in Cyperus papyrus dominated natural wetlands. Environmental Modelling & Software, 122, 104531. doi:10.1016/j.envsoft.2019.104531Juston, J. M., & Kadlec, R. H. (2019). Data-driven modeling of phosphorus (P) dynamics in low-P stormwater wetlands. Environmental Modelling & Software, 118, 226-240. doi:10.1016/j.envsoft.2019.05.002Juwana, I., Muttil, N., & Perera, B. J. C. (2012). Indicator-based water sustainability assessment — A review. Science of The Total Environment, 438, 357-371. doi:10.1016/j.scitotenv.2012.08.093Kløve, B., Allan, A., Bertrand, G., Druzynska, E., Ertürk, A., Goldscheider, N., … Schipper, P. (2011). Groundwater dependent ecosystems. Part II. Ecosystem services and management in Europe under risk of climate change and land use intensification. Environmental Science & Policy, 14(7), 782-793. doi:10.1016/j.envsci.2011.04.005Koskiaho, J., & Puustinen, M. (2019). Suspended solids and nutrient retention in two constructed wetlands as determined from continuous data recorded with sensors. Ecological Engineering, 137, 65-75. doi:10.1016/j.ecoleng.2019.04.006Lefebvre, G., Redmond, L., Germain, C., Palazzi, E., Terzago, S., Willm, L., & Poulin, B. (2019). Predicting the vulnerability of seasonally-flooded wetlands to climate change across the Mediterranean Basin. Science of The Total Environment, 692, 546-555. doi:10.1016/j.scitotenv.2019.07.263Zhuang, L.-L., Yang, T., Zhang, J., & Li, X. (2019). The configuration, purification effect and mechanism of intensified constructed wetland for wastewater treatment from the aspect of nitrogen removal: A review. Bioresource Technology, 293, 122086. doi:10.1016/j.biortech.2019.122086Liu, Z., Tai, P., Li, X., Kong, L., Matthews, T. G., Lester, R. E., & Mondon, J. A. (2019). Deriving site-specific water quality criteria for ammonia from national versus international toxicity data. Ecotoxicology and Environmental Safety, 171, 665-676. doi:10.1016/j.ecoenv.2018.12.078Lobanova, A., Liersch, S., Tàbara, J. D., Koch, H., Hattermann, F. F., & Krysanova, V. (2017). Harmonizing human-hydrological system under climate change: A scenario-based approach for the case of the headwaters of the Tagus River. Journal of Hydrology, 548, 436-447. doi:10.1016/j.jhydrol.2017.03.015Martin-Utrillas, M., Reyes-Medina, M., Curiel-Esparza, J., & Canto-Perello, J. (2014). Hybrid method for selection of the optimal process of leachate treatment in waste treatment and valorization plants or landfills. Clean Technologies and Environmental Policy, 17(4), 873-885. doi:10.1007/s10098-014-0834-4Man, Y., Hu, Y., & Ren, J. (2019). Forecasting COD load in municipal sewage based on ARMA and VAR algorithms. Resources, Conservation and Recycling, 144, 56-64. doi:10.1016/j.resconrec.2019.01.030Martinez-Martinez, E., Nejadhashemi, A. P., Woznicki, S. A., Adhikari, U., & Giri, S. (2015). Assessing the significance of wetland restoration scenarios on sediment mitigation plan. Ecological Engineering, 77, 103-113. doi:10.1016/j.ecoleng.2014.11.031Mayo, A. W., Muraza, M., & Norbert, J. (2018). Modelling nitrogen transformation and removal in mara river basin wetlands upstream of lake Victoria. Physics and Chemistry of the Earth, Parts A/B/C, 105, 136-146. doi:10.1016/j.pce.2018.03.005Moreno, L., Jiménez, M.-E., Aguilera, H., Jiménez, P., & de la Losa, A. (2010). The 2009 Smouldering Peat Fire in Las Tablas de Daimiel National Park (Spain). Fire Technology, 47(2), 519-538. doi:10.1007/s10694-010-0172-yNagisetty, R. M., Flynn, K. F., & Uecker, D. (2019). Dissolved oxygen modeling of effluent-dominated macrophyte-rich Silver Bow Creek. Ecological Modelling, 393, 85-97. doi:10.1016/j.ecolmodel.2018.12.009Navarro, V., García, B., Sánchez, D., & Asensio, L. (2011). An evaluation of the application of treated sewage effluents in Las Tablas de Daimiel National Park, Central Spain. Journal of Hydrology, 401(1-2), 53-64. doi:10.1016/j.jhydrol.2011.02.008Norouzian-Maleki, S., Bell, S., Hosseini, S.-B., & Faizi, M. (2015). Developing and testing a framework for the assessment of neighbourhood liveability in two contrasting countries: Iran and Estonia. Ecological Indicators, 48, 263-271. doi:10.1016/j.ecolind.2014.07.033Novakowski, N., & Wellar, B. (2008). Using the Delphi Technique in Normative Planning Research: Methodological Design Considerations. Environment and Planning A: Economy and Space, 40(6), 1485-1500. doi:10.1068/a39267Okoli, C., & Pawlowski, S. D. (2004). The Delphi method as a research tool: an example, design considerations and applications. Information & Management, 42(1), 15-29. doi:10.1016/j.im.2003.11.002O’Neil, G. L., Goodall, J. L., Behl, M., & Saby, L. (2020). Deep learning Using Physically-Informed Input Data for Wetland Identification. Environmental Modelling & Software, 126, 104665. doi:10.1016/j.envsoft.2020.104665Pérez-Martín, M. A., Estrela, T., & del-Amo, P. (2016). Measures required to reach the nitrate objectives in groundwater based on a long-term nitrate model for large river basins (Júcar, Spain). Science of The Total Environment, 566-567, 122-133. doi:10.1016/j.scitotenv.2016.04.206Pottinger, T. G. (2017). Modulation of the stress response in wild fish is associated with variation in dissolved nitrate and nitrite. Environmental Pollution, 225, 550-558. doi:10.1016/j.envpol.2017.03.021Prăvălie, R., Patriche, C., & Bandoc, G. (2017). Quantification of land degradation sensitivity areas in Southern and Central Southeastern Europe. New results based on improving DISMED methodology with new climate data. CATENA, 158, 309-320. doi:10.1016/j.catena.2017.07.006Restuccia, F., Huang, X., & Rein, G. (2017). Self-ignition of natural fuels: Can wildfires of carbon-rich soil start by self-heating? Fire Safety Journal, 91, 828-834. doi:10.1016/j.firesaf.2017.03.052Rivers-Moore, N. A., Dallas, H. F., & Morris, C. (2013). Towards setting environmental water temperature guidelines: A South African example. Journal of Environmental Management, 128, 380-392. doi:10.1016/j.jenvman.2013.04.059Rusydi, A. F. (2018). Correlation between conductivity and total dissolved solid in various type of water: A review. IOP Conference Series: Earth and Environmental Science, 118, 012019. doi:10.1088/1755-1315/118/1/012019Sánchez-Montoya, M. del M., Arce, M. I., Vidal-Abarca, M. R., Suárez, M. L., Prat, N., & Gómez, R. (2012). Establishing physico-chemical reference conditions in Mediterranean streams according to the European Water Framework Directive. Water Research, 46(7), 2257-2269. doi:10.1016/j.watres.2012.01.042Sanchez-Ramos, D., Sánchez-Emeterio, G., & Florín Beltrán, M. (2015). Changes in water quality of treated sewage effluents by their receiving environments in Tablas de Daimiel National Park, Spain. Environmental Science and Pollution Research, 23(7), 6082-6090. doi:10.1007/s11356-015-4660-ySapriza-Azuri, G., Jódar, J., Carrera, J., & Gupta, H. V. (2015). Toward a comprehensive assessment of the combined impacts of climate change and groundwater pumping on catchment dynamics. Journal of Hydrology, 529, 1701-1712. doi:10.1016/j.jhydrol.2015.08.015Singh, S., Ghosh, N. C., Krishan, G., Galkate, R., Thomas, T., & Jaiswal, R. K. (2015). Development of an Overall Water Quality Index (OWQI) for Surface Water in Indian Context. Current World Environment, 10(3), 813-822. doi:10.12944/cwe.10.3.12Singh, S., Ghosh, N. C., Gurjar, S., Krishan, G., Kumar, S., & Berwal, P. (2017). Index-based assessment of suitability of water quality for irrigation purpose under Indian conditions. Environmental Monitoring and Assessment, 190(1). doi:10.1007/s10661-017-6407-3Sperotto, A., Molina, J. L., Torresan, S., Critto, A., Pulido-Velazquez, M., & Marcomini, A. (2019). A Bayesian Networks approach for the assessment of climate change impacts on nutrients loading. Environmental Science & Policy, 100, 21-36. doi:10.1016/j.envsci.2019.06.004Sun, B., Tang, J., Yu, D., Song, Z., & Wang, P. (2019). Ecosystem health assessment: A PSR analysis combining AHP and FCE methods for Jiaozhou Bay, China1. Ocean & Coastal Management, 168, 41-50. doi:10.1016/j.ocecoaman.2018.10.026Sutadian, A. D., Muttil, N., Yilmaz, A. G., & Perera, B. J. C. (2015). Development of river water quality indices—a review. Environmental Monitoring and Assessment, 188(1). doi:10.1007/s10661-015-5050-0Sutadian, A. D., Muttil, N., Yilmaz, A. G., & Perera, B. J. C. (2017). Using the Analytic Hierarchy Process to identify parameter weights for developing a water quality index. Ecological Indicators, 75, 220-233. doi:10.1016/j.ecolind.2016.12.043Tooth, S. (2018). The geomorphology of wetlands in drylands: Resilience, nonresilience, or …? Geomorphology, 305, 33-48. doi:10.1016/j.geomorph.2017.10.017Tyagi, S., Sharma, B., Singh, P., & Dobhal, R. (2020). Water Quality Assessment in Terms of Water Quality Index. American Journal of Water Resources, 1(3), 34-38. doi:10.12691/ajwr-1-3-3Viaroli, S., Mastrorillo, L., Lotti, F., Paolucci, V., & Mazza, R. (2018). The groundwater budget: A tool for preliminary estimation of the hydraulic connection between neighboring aquifers. Journal of Hydrology, 556, 72-86. doi:10.1016/j.jhydrol.2017.10.066Wang, H.-J., Xiao, X.-C., Wang, H.-Z., Li, Y., Yu, Q., Liang, X.-M., … Jeppesen, E. (2017). Effects of high ammonia concentrations on three cyprinid fish: Acute and whole-ecosystem chronic tests. Science of The Total Environment, 598, 900-909. doi:10.1016/j.scitotenv.2017.04.070Xu, Y., Wang, Y., Li, S., Huang, G., & Dai, C. (2018). Stochastic optimization model for water allocation on a watershed scale considering wetland’s ecological water requirement. Ecological Indicators, 92, 330-341. doi:10.1016/j.ecolind.2017.02.019Yuan, L., Ge, Z., Fan, X., & Zhang, L. (2014). Ecosystem-based coastal zone management: A comprehensive assessment of coastal ecosystems in the Yangtze Estuary coastal zone. Ocean & Coastal Management, 95, 63-71. doi:10.1016/j.ocecoaman.2014.04.005Zhang, R., Zhang, X., Yang, J., & Yuan, H. (2013). Wetland ecosystem stability evaluation by using Analytical Hierarchy Process (AHP) approach in Yinchuan Plain, China. Mathematical and Computer Modelling, 57(3-4), 366-374. doi:10.1016/j.mcm.2012.06.014ZHANG, L. (2016). CALCULATION OF WETLANDS ECOLOGICAL WATER REQUIREMENT IN CHINA’S WESTERN JILIN PROVINCE BASED ON REGIONALIZATION AND GRADATION TECHNIQUES. Applied Ecology and Environmental Research, 14(3), 463-478. doi:10.15666/aeer/1403_463478Zhang, B., Zhao, D., Zhou, P., Qu, S., Liao, F., & Wang, G. (2020). Hydrochemical Characteristics of Groundwater and Dominant Water–Rock Interactions in the Delingha Area, Qaidam Basin, Northwest China. Water, 12(3), 836. doi:10.3390/w1203083",,'Elsevier BV',Water resources sustainability model for wetland conservation based on anonymous expert elicitation,10.1016/j.envsoft.2020.104952,http://hdl.handle.net/10251/164063,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
478503769,2021-05-11T00:00:00,"PurposeThe COVID-19 pandemic showed an urgent need for decision support systems to help doctors at a time of stress and uncertainty. However, significant differences in hospital conditions, as well as skepticism of doctors about machine learning algorithms, limit their introduction into clinical practice. Our goal was to test and apply the principle of ”patient-like-mine” decision support in rapidly changing conditions of a pandemic.MethodsIn the developed system we implemented a fuzzy search that allows a doctor to compare their medical case with similar cases recorded in their medical center since the beginning of the pandemic. Various distance metrics were tried for obtaining clinically relevant search results. With the use of R programming language, we designed the first version of the system in approximately a week. A set of features for the comparison of the cases was selected with the use of random forest algorithm implemented in Caret. Shiny package was chosen for the design of GUI.ResultsThe deployed tool allowed doctors to quickly estimate the current conditions of their patients by means of studying the most similar previous cases stored in the local health information system. The extensive testing of the system during the first wave of COVID-19 showed that this approach helps not only to draw a conclusion about the optimal treatment tactics and to train medical staff in real-time but also to optimize patients’ individual testing plans.ConclusionsThis project points to the possibility of rapid prototyping and effective usage of ”patient-like-mine” search systems at the time of a pandemic caused by a poorly known pathogen",,,Fast prototyping of a local fuzzy search system for decision support and retraining of hospital staff during pandemic,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
323090695,2019-09-01T00:00:00,"[EN] An intelligent virtual environment simulates a physical world inhabited by autonomous intelligent entities. Multi-agent systems have been usually employed to design systems of this kind. One of the key aspects in the design of intelligent virtual environments is the use of appropriate ontologies which offer a richer and more expressive representation of knowledge. In this sense, this paper proposes an ontology comprising concepts for modelling intelligent virtual environments enhanced with concepts for describing agent-based organisational features. This new ontology, called MAMbO5, is used as an input of the JaCalIVE framework, which is a toolkit for the design and implementation of agent-based intelligent virtual environments.This work was supported by the project TIN2015-65515-C4-1-R of the Spanish government. This work has been supported in part by the Croatian Science Foundation under the project number 8537.Duric, BO.; Rincon, JA.; Carrascosa Casamayor, C.; Schatten, M.; Julian Inglada, VJ. (2019). MAMbO5: A new Ontology Approach for Modelling and Managing Intelligent Virtual Environments Based on Multi-Agent Systems. Journal of Ambient Intelligence and Humanized Computing. 10(9):3629-3641. https://doi.org/10.1007/s12652-018-1089-4S36293641109Ahmed Abbas H (2015) Organization of multi-agent systems: an overview. Int J Intell Inf Syst 4(3):46 (ISSN: 2328-7675)Amiribesheli M, Bouchachia H (2017) A tailored smart home for dementia care. J Ambient Intell Hum Comput 1:1–28 (ISSN: 1868-5137, 1868-5145)Amiribesheli M, Benmansour A, Bouchachia A (2015) A review of smart homes in healthcare. J Ambient Intell Hum Comput 6(4):495–517 (ISSN: 18685145) arXiv: TSMCC.2012.2189204 [10.1109]Barella A, Ricci A, Boissier O, Carrascosa C (2012) MAM5: multi-agent model for intelligent virtual environments. In: 10th European workshop on multi-agent systems (EUMAS 2012), pp 16–30Bordel B (2017) Self-configuration in humanized cyber-physical systems. J Ambient Intell Hum Comput 8(4):485–496 (ISSN: 1868-5137)Chaib A, Boussebough I, Chaoui A (2018) Adaptive service composition in an ambient environment with a multi-agent system. J Ambient Intell Hum Comput 9(2):367–380 (ISSN: 1868-5137)Chen X (2017) A multiagent-based model for pedestrian simulation in subway stations. Simul Modell Pract Theory 71:134–148 (ISSN: 1569-190X)Chen T, Chiu MC (2018) Smart technologies for assisting the life quality of persons in a mobile environment: a review. J Ambient Intell Hum Comput 9(2):319–327 (ISSN: 1868-5137)Corkill DD, Lander SE (1998) Diversity in agent organizations. Obj Mag 8(4):41–47De Wolf T (2004) Emergence and self-organisation: a statement of similarities and differences. In: Proceedings of of the 2nd international workshop on engineering self, pp 96–110Dignum V (2009) The role of organization in agent systems. English. In: Dignum V (ed) Handbook of research on multi-agent systems. Hershey, IGI Global, pp 1–16 (ISBN: 9781605662565)Fishwick PA, Miller JA (2004) Ontologies for modeling and simulation: issues and approaches. In: Simulation conference, 2004. Proceedings of the 2004 Winter, vol 1. IEEEFurfaro A (2016) Using virtual environments for the assessment of cybersecurity issues in IoT scenarios. Simul Modell Pract Theory 0:1–12Gabriele D, Ferretti S, Ghini V (2016) Multi-level simulation of Internet of Things on smart territories. Simul Modell Pract Theory 0:1–19Hadfi R, Ito T (2016) Holonic multiagent simulation of complex adaptive systems. In: Javier B(Ed) Highlights of practical applications of scalable multi-agent systems. The PAAMS collection: international workshops of PAAMS 2016, Sevilla, Spain, June 1-3, 2016. Proceedings. Springer, Cham, pp 137-147 (ISBN: 978-3-319-39387-2)Hofmann M, Palii J, Mihelcic G (2011) Epistemic and normative aspects of ontologies in modelling and simulation. J Simul 5(3):135–146Hui TKL, Sherratt RS (2017) Towards disappearing user interfaces for ubiquitous computing: human enhancement from sixth sense to super senses. J Ambient Intell Hum Comput 8(3):449–465 (ISSN: 1868-5137, 1868-5145)Kim S, Lee I (2018) IoT device security based on proxy re-encryption. J Ambient Intell Hum Comput 9(4):1267–1273 (ISSN: 1868-5137, 1868-5145)Ko E, Kim T, Kim H (2018) Management platform of threats information in IoT environment. J Ambient Intell Hum Comput 9(4):1167–1176 (ISSN: 1868-5137, 1868-5145)Liu Y, Xu C, Zhan Y, Liu Z, Guan J, Zhang H (2017) Incentive mechanism for computation offloading using edge computing: a stackelberg game approach. Comput Netw 129:399–409Liu Y, Bashar AAE, Wu B, Wu H (2018a) Delay-constrained profit maximization for data deposition in mobile opportunistic device-to-device networks. In: 2018 IEEE 19th international symposium on” a world of wireless, mobile and multimedia networks (WoWMoM), IEEE, pp 1–10Liu Y, et al (2018b) Delay-constrained utility maximization for video ads push in mobile opportunistic D2D networks. IEEE Internet Things JLuck M, Aylett R (2000) Applying artificial intelligence to virtual reality: intelligent virtual environments. Appl Artif Intell 14(1):3–32Marcon E (2017) A multi-agent system based on reactive decision rules for solving the caregiver routing problem in home health care. Simul Modell Pract Theory 74:134–151 (ISSN: 1569-190X)Mulero R (2018) Towards ambient assisted cities using linked data and data analysis. J Ambient Intell Hum Comput 9(5):1573–1591 (ISSN: 1868-5137, 1868-5145)Okreša Đ B, Schatten M (2016) Defining ontology combining concepts of massive multi-player online role playing games and organization of large-scale multi-agent systems. In: Opatija HR (ed) 39th international convention on information and communication technology, electronics and microelectronics (MIPRO). IEEE, pp 1330–1335 (ISBN: 978-953-233-086-1)Ricci A, Viroli M, Omicini A (2007) Give agents their artifacts: the A&A approach for engineering working environments in MAS. In: Proceedings of the 6th international joint conference on autonomous agents and multiagent systems, p 150Rincon JA, Carrascosa C, Garcia E (2014) Developing intelligent virtual environments using MAM5 meta-model. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics) 8473 LNAI, pp 379–382 (ISSN: 16113349)Rincon J (2016) Extending MAM5 meta-model and JaCalIV E framework to integrate smart devices from real environments. PLoS One 11:e0149665. https://doi.org/10.1371/journal.pone.0149665Rincon J, Garcia E, Julian V, Carrascosa C (2018) The jacalive framework for mas in IVE: a case study in evolving modular robotics. Neurocomputing 275:608–617Rodriguez S (2011) Holonic multi-agent systems. In: Di Marzo SG, Gleizes MP, Karageorgos A (eds) Natural computing series, natural computing series, vol 37. Springer, Heidelberg, pp 251–279 (ISBN: 978-3-642-17347-9)Samara A, et al. (2017) Affective state detection via facial expression analysis within a human–computer interaction context. J Ambient Intell Hum Comput (ISSN: 1868-5137, 1868-5145)Schatten M (2014) Organizational architectures for large-scale multi-agent systems’ development: an initial ontology. In: Sigeru O, et al (Ed) Advances in intelligent systems and computing, vol 290, pp 261–268Schatten M (2014) Towards a formal conceptualization of organizational design techniques for large scale multi agent systems. Procedia Technol 15:577–586 (ISSN: 22120173)Sharpanskykh A, Treur J (2012) An ambient agent architecture exploiting automated cognitive analysis. J Ambient Intell Hum Comput 3(3):219–237 (ISSN: 1868-5137, 1868-5145)Weyns D, Haesevoets R, Helleboogh A (2010) The MACODO organization model for context-driven dynamic agent organizations. ACM Trans Auton Adapt Syst 5(4):1–29 (ISSN: 15564665)Yang G, Kifer M, Zhao C (2003) Flora-2: a rule-based knowledge representation and inference infrastructure for the semantic web. In: Robert M, Zahir T, Douglas CS(Ed) On the move to meaningful internet systems 2003: CoopIS, DOA, and ODBASE: OTM confederated international conferences, CoopIS, DOA, and ODBASE 2003, Catania, Sicily, Italy, November 3-7, 2003. Proceedings. Springer, Berlin, pp 671-688 (ISBN: 978-3-540-39964-3)Zehe D, et al (2015) SEMSim cloud service: large-scale urban systems simulation in the cloud. In: 58, pp 157–17",,'Springer Science and Business Media LLC',MAMbO5: A new Ontology Approach for Modelling and Managing Intelligent Virtual Environments Based on Multi-Agent Systems,10.1007/s12652-018-1089-4,http://hdl.handle.net/10251/143142,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481177708,2021-10-02T00:00:00,"International audienceBackground: Artificial intelligence (AI) has the potential to transform our healthcare systems significantly. New AI technologies based on machine learning approaches should play a key role in clinical decision-making in the future. However, their implementation in health care settings remains limited, mostly due to a lack of robust validation procedures. There is a need to develop reliable assessment frameworks for the clinical validation of AI. We present here an approach for assessing AI for predicting treatment response in triple-negative breast cancer (TNBC), using real-world data and molecular-omics data from clinical data warehouses and biobanks. Methods: The European ""ITFoC (Information Technology for the Future Of Cancer)"" consortium designed a framework for the clinical validation of AI technologies for predicting treatment response in oncology. Results: This framework is based on seven key steps specifying: (1) the intended use of AI, (2) the target population, (3) the timing of AI evaluation, (4) the datasets used for evaluation, (5) the procedures used for ensuring data safety (including data quality, privacy and security), (6) the metrics used for measuring performance, and (7) the procedures used to ensure that the AI is explainable. This framework forms the basis of a validation platform that we are building for the ""ITFoC Challenge"". This community-wide competition will make it possible to assess and compare AI algorithms for predicting the response to TNBC treatments with external real-world datasets. Conclusions: The predictive performance and safety of AI technologies must be assessed in a robust, unbiased and transparent manner before their implementation in healthcare settings. We believe that the consideration of the ITFoC consortium will contribute to the safe transfer and implementation of AI in clinical settings, in the context of precision oncology and personalized care",,'Springer Science and Business Media LLC',A framework for validating AI in precision medicine: considerations from the European ITFoC consortium,10.1186/s12911-021-01634-3,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
483816328,2021-01-01T00:00:00,"Background
Uncertainty in patients' COVID-19 status contributes to treatment delays, nosocomial transmission, and operational pressures in hospitals. However, the typical turnaround time for laboratory PCR remains 12–24 h and lateral flow devices (LFDs) have limited sensitivity. Previously, we have shown that artificial intelligence-driven triage (CURIAL-1.0) can provide rapid COVID-19 screening using clinical data routinely available within 1 h of arrival to hospital. Here, we aimed to improve the time from arrival to the emergency department to the availability of a result, do external and prospective validation, and deploy a novel laboratory-free screening tool in a UK emergency department.
Methods
We optimised our previous model, removing less informative predictors to improve generalisability and speed, developing the CURIAL-Lab model with vital signs and readily available blood tests (full blood count [FBC]; urea, creatinine, and electrolytes; liver function tests; and C-reactive protein) and the CURIAL-Rapide model with vital signs and FBC alone. Models were validated externally for emergency admissions to University Hospitals Birmingham, Bedfordshire Hospitals, and Portsmouth Hospitals University National Health Service (NHS) trusts, and prospectively at Oxford University Hospitals, by comparison with PCR testing. Next, we compared model performance directly against LFDs and evaluated a combined pathway that triaged patients who had either a positive CURIAL model result or a positive LFD to a COVID-19-suspected clinical area. Lastly, we deployed CURIAL-Rapide alongside an approved point-of-care FBC analyser to provide laboratory-free COVID-19 screening at the John Radcliffe Hospital (Oxford, UK). Our primary improvement outcome was time-to-result, and our performance measures were sensitivity, specificity, positive and negative predictive values, and area under receiver operating characteristic curve (AUROC).
Findings
72 223 patients met eligibility criteria across the four validating hospital groups, in a total validation period spanning Dec 1, 2019, to March 31, 2021. CURIAL-Lab and CURIAL-Rapide performed consistently across trusts (AUROC range 0·858–0·881, 95% CI 0·838–0·912, for CURIAL-Lab and 0·836–0·854, 0·814–0·889, for CURIAL-Rapide), achieving highest sensitivity at Portsmouth Hospitals (84·1%, Wilson's 95% CI 82·5–85·7, for CURIAL-Lab and 83·5%, 81·8–85·1, for CURIAL-Rapide) at specificities of 71·3% (70·9–71·8) for CURIAL-Lab and 63·6% (63·1–64·1) for CURIAL-Rapide. When combined with LFDs, model predictions improved triage sensitivity from 56·9% (51·7–62·0) for LFDs alone to 85·6% with CURIAL-Lab (81·6–88·9; AUROC 0·925) and 88·2% with CURIAL-Rapide (84·4–91·1; AUROC 0·919), thereby reducing missed COVID-19 cases by 65% with CURIAL-Lab and 72% with CURIAL-Rapide. For the prospective deployment of CURIAL-Rapide, 520 patients were enrolled for point-of-care FBC analysis between Feb 18 and May 10, 2021, of whom 436 received confirmatory PCR testing and ten (2·3%) tested positive. Median time from arrival to a CURIAL-Rapide result was 45 min (IQR 32–64), 16 min (26·3%) sooner than with LFDs (61 min, 37–99; log-rank p<0·0001), and 6 h 52 min (90·2%) sooner than with PCR (7 h 37 min, 6 h 5 min to 15 h 39 min; p<0·0001). Classification performance was high, with sensitivity of 87·5% (95% CI 52·9–97·8), specificity of 85·4% (81·3–88·7), and negative predictive value of 99·7% (98·2–99·9). CURIAL-Rapide correctly excluded infection for 31 (58·5%) of 53 patients who were triaged by a physician to a COVID-19-suspected area but went on to test negative by PCR.
Interpretation
Our findings show the generalisability, performance, and real-world operational benefits of artificial intelligence-driven screening for COVID-19 over standard-of-care in emergency departments. CURIAL-Rapide provided rapid, laboratory-free screening when used with near-patient FBC analysis, and was able to reduce the number of patients who tested negative for COVID-19 but were triaged to COVID-19-suspected areas",,'Elsevier BV',Real-world evaluation of AI driven COVID-19 triage for emergency admissions: External validation & operational assessment of lab-free and high-throughput screening solutions,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481637846,2020-03-01T00:00:00,"Background:  Cardiac arrest is the most serious death-related event in intensive care units (ICUs), but it is not easily predicted because of the complex and time-dependent data characteristics of intensive care patients. Given the complexity and time dependence of ICU data, deep learning-based methods are expected to provide a good foundation for developing risk prediction models based on large clinical records. 

 Objective:  This study aimed to implement a deep learning model that estimates the distribution of cardiac arrest risk probability over time based on clinical data and assesses its potential. 

 Methods:  A retrospective study of 759 ICU patients was conducted between January 2013 and July 2015. A character-level gated recurrent unit with a Weibull distribution algorithm was used to develop a real-time prediction model. Fivefold cross-validation testing (training set: 80% and validation set: 20%) determined the consistency of model accuracy. The time-dependent area under the curve (TAUC) was analyzed based on the aggregation of 5 validation sets. 

 Results:  The TAUCs of the implemented model were 0.963, 0.942, 0.917, 0.875, 0.850, 0.842, and 0.761 before cardiac arrest at 1, 8, 16, 24, 32, 40, and 48 hours, respectively. The sensitivity was between 0.846 and 0.909, and specificity was between 0.923 and 0.946. The distribution of risk between the cardiac arrest group and the non-cardiac arrest group was generally different, and the difference rapidly increased as the time left until cardiac arrest reduced. 

 Conclusions:  A deep learning model for forecasting cardiac arrest was implemented and tested by considering the cumulative and fluctuating effects of time-dependent clinical data gathered from a large medical center. This real-time prediction model is expected to improve patient's care by allowing early intervention in patients at high risk of unexpected cardiac arrests.ope","[{'title': 'JMIR Medical Informatics', 'identifiers': ['2291-9694', 'issn:2291-9694']}]",'JMIR Publications Inc.',Development of a Real-Time Risk Prediction Model for In-Hospital Cardiac Arrest in Critically Ill Patients Using Deep Learning: Retrospective Study,10.2196/16349,https://core.ac.uk/download/481637846.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
363911500,2020-01-01T00:00:00,"Abstract

Abdominal cancer is a widely prevalent group of tumours with a high level of mortality if diagnosed at a late stage. Although the cancer death rates have in general declined over the past few decades, the mortality from tumours in the hepatoduodenal area has significantly increased in recent years. The broader use of minimal access surgery (MAS) for diagnostics and treatment can significantly improve the survival rate and quality of life of patients after surgery. This work aims to develop and characterise an appropriate technical implementation for tissue endogenous fluorescence (TEF) and assess the efficiency of machine learning methods for the real-time diagnosis of tumours in the hepatoduodenal area. In this paper, we present the results of the machine learning approach applied to the optically guided MAS. We have elaborated tissue fluorescence approach with a fibre-optic probe to record the TEF and blood perfusion parameters during MAS in patients with cancers in the hepatoduodenal area. The measurements from the laser Doppler flowmetry (LDF) channel were used as a sensor of the tissue vitality to reduce variability in TEF data. Also, we evaluated how the blood perfusion oscillations are changed in the tumour tissue. The evaluated amplitudes of the cardiac (0.6–1.6 Hz) and respiratory (0.2–0.6 Hz) oscillations was significantly higher in intact tissues (p %lt; 0.001) compared to the cancerous ones, while the myogenic (0.2–0.06 Hz) oscillation did not demonstrate any statistically significant difference. Our results demonstrate that a fibre-optic TEF probe accompanied with ML algorithms such as k-Nearest Neighbours or AdaBoost is highly promising for the real-time in situ differentiation between cancerous and healthy tissues by detecting the information about the tissue type that is encoded in the fluorescence spectrum. Also, we show that the detection can be supplemented and enhanced by parallel collection and classification of blood perfusion oscillations",,Multidisciplinary Digital Publishing Institute,Machine learning aided photonic diagnostic system for minimally invasive optically guided surgery in the hepatoduodenal area,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
442071865,2021-03-01T00:00:00,"BackgroundImmunohistochemistry (IHC) remains the gold standard for the diagnosis of pathological diseases. This technique has been supporting pathologists in making precise decisions regarding differential diagnosis and subtyping, and in creating personalized treatment plans. However, the interpretation of IHC results presents challenges in complicated cases. Furthermore, rapidly increasing amounts of IHC data are making it even harder for pathologists to reach to definitive conclusions.MethodsWe developed ImmunoGenius, a machine-learning-based expert system for the pathologist, to support the diagnosis of tumors of unknown origin. Based on Bayesian theorem, the most probable diagnoses can be drawn by calculating the probabilities of the IHC results in each disease. We prepared IHC profile data of 584 antibodies in 2009 neoplasms based on the relevant textbooks. We developed the reactive native mobile application for iOS and Android platform that can provide 10 most possible differential diagnoses based on the IHC input.ResultsWe trained the software using 562 real case data, validated it with 382 case data, tested it with 164 case data and compared the precision hit rate. Precision hit rate was 78.5, 78.0 and 89.0% in training, validation and test dataset respectively. Which showed no significant difference. The main reason for discordant precision was lack of disease-specific IHC markers and overlapping IHC profiles observed in similar diseases.ConclusionThe results of this study showed a potential that the machine-learning algorithm based expert system can support the pathologic diagnosis by providing second opinion on IHC interpretation based on IHC database. Incorporation with contextual data including the clinical and histological findings might be required to elaborate the system in the future.11Nsciescopu","[{'title': 'Diagnostic Pathology', 'identifiers': ['1746-1596', 'issn:1746-1596']}]",'Springer Science and Business Media LLC',"Diagnosis prediction of tumours of unknown origin using ImmunoGenius, a machine learning-based expert system for immunohistochemistry profile interpretation",10.1186/s13000-021-01081-8,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481408824,2021-08-01T00:00:00,"Advances in sensors and internet of things promise broad opportunities in many areas and one of them is health care. There are many solutions to manage health care data based on cloud computing. However, high response latency, large volumes of data transferred and security are the main issues of such approach. Fog computing provides immediate response and ways to process large amounts of data using real time analytics which includes machine learning and AI. Fog computing has not yet fully matured and there are still many challenges when managing health care data. It was chosen to investigate the most relevant e­health fog computing topics by analyzing review articles to explain the fog computing model and present the current trends – fog computing e­health technology application environments, deployment cases, infrastructure technologies, data processing challenges, problems and future directions. 38 scientific review articles published in the last 5 years were selected for analysis, filtering the most significant works with Web of Science article search tool.



Article in Lithuanian.



Rūko kompiuterijos technologijos pacientų jutiklių tinklams – tendencijos, problemos ir ateities kryptys



Santrauka



Jutiklių ir daiktų interneto pažanga žada plačias galimybes daugelyje sričių, viena iš jų – sveikatos priežiūra. Sukurta daugybė sprendimų, kaip valdyti sveikatos priežiūros duomenis, pagrįstus debesų kompiuterija, tačiau didelė delsa, didelis perduodamų duomenų kiekis ir jų saugumas yra pagrindinės nutolusių duomenų centrų problemos norint perduoti sveikatos duomenis. Rūko kompiuterija pasižymi greitu atsaku ir leidžia apdoroti didelius duomenų kiekius atliekant realaus laiko analizę, apimančią mašininį mokymąsi ir dirbtinį intelektą. Rūko kompiuterija dar nėra visiškai įsitvirtinusi, o tvarkant sveikatos duomenis vis dar kyla daug problemų. Šiame straipsnyje pateikiama rūko kompiuterijos sveikatos priežiūros srityje apžvalga. Pasirinkta ištirti aktualiausias e. sveikatos rūko kompiuterijos tematikos kryptis išanalizuojant apžvalginius straipsnius, paaiškinti rūko kompiuterijos architektūros modelį ir pateikti dabartines tendencijas – rūko kompiuterijos e. sveikatos technologijų taikymo aplinkas, diegimo atvejus, infrastruktūros technologijas, duomenų apdorojimo uždavinius, problemas ir ateities kryptis. Atrinkti 38 per pastaruosius 5 metus publikuoti mokslinės apžvalgos straipsniai darbų analizei, filtruojant reikšmingiausius darbus taikant Web of Science straipsnių paieškos įrankį.



Reikšminiai žodžiai: rūko kompiuterija, daiktų internetas, sveikatos priežiūra, apžvalga","[{'title': 'Mokslas - Lietuvos ateitis', 'identifiers': ['2029-2341', '2029-2252', 'issn:2029-2252', 'issn:2029-2341']}]",'Vilnius Gediminas Technical University',"Fog computing technologies for patient sensor networks – trends, issues and future directions",10.3846/mla.2021.15174,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426057075,2020-01-01T00:00:00,"Objective: Chronic diseases (CDs) are major causes of deaths, disabilities and healthcare expenditure worldwide. Interventions aimed to prevent or mitigate the impact of CDs need to be added to the traditional healthcare methods. The main purpose of the CHANGE project is the development and validation of a new Nudge theory-based Information and Communications Technology (ICT) coach system for monitoring and empowering patients with CDs. Methods: A randomized controlled clinical trial involving 200 patients with CDs will be implemented. Online assessment of demographic, psychological, neuropsychological, and behavioral outcomes will be carried out through the users' device (smartwatches). A machine learning algorithm-based profile will elaborate specific nudge-based notifications, and suggestions will be returned to par- ticipants via the CHANGE App. Expected results: real-time monitoring and tutoring will prevent/ decelerate the worsening of clinical conditions and will improve the physical and psychosocial health of patients with CDs. Moreover, the provision of tailored care actions will contribute to a more sustainable healthcare system",,"place:Aachen, Germany",Nudging CHronic disease mANaGemEnt for empowering citizens: The CHANGE project,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
429990396,2021-01-01T00:00:00,"Multiple sclerosis (MS) is a chronic autoimmune, inflammatory neurological disease of the central nervous system. Its diagnosis nowadays commonly includes performing an MRI scan, as it is the most sensitive imaging test for MS. MS plaques are commonly identified from fluid-attenuated inversion recovery (FLAIR) images as hyperintense regions that are highly varying in terms of their shapes, sizes and locations, and are routinely classified in accordance to the McDonald criteria. Recent years have seen an increase in works that aimed at development of various semi-automatic and automatic methods for detection, segmentation and classification of MS plaques. In this paper, we present an automatic combined method, based on two pipelines: a traditional unsupervised machine learning technique and a deep-learning attention-gate 3D U-net network. The deep-learning network is specifically trained to address the weaker points of the traditional approach, namely difficulties in segmenting infratentorial and juxtacortical plaques in real-world clinical MRIs. It was trained and validated on a multi-center multi-scanner dataset that contains 159 cases, each with T1 weighted (T1w) and FLAIR images, as well as manual delineations of the MS plaques, segmented and validated by a panel of raters. The detection rate was quantified using lesion-wise Dice score. A simple label fusion is implemented to combine the output segmentations of the two pipelines. This combined method improves the detection of infratentorial and juxtacortical lesions by 14% and 31% respectively, in comparison to the unsupervised machine learning pipeline that was used as a performance assessment baseline","[{'title': 'NeuroImage Clinical', 'identifiers': ['2213-1582', 'issn:2213-1582']}]",'Elsevier BV',icobrain ms 5.1: Combining unsupervised and supervised approaches for improving the detection of multiple sclerosis lesions,10.1016/j.nicl.2021.102707,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
480199312,2021-08-01T00:00:00,"Social distancing and the shortage of healthcare professionals during the COVID-19 pandemic, the impact of population aging on the healthcare system, as well as the rapid pace of digital innovation are catalyzing the development and implementation of new technologies and digital services in psychiatry. Is this transformation a blessing or a curse for psychiatry? To answer this question, we conducted a literature review covering a broad range of new technologies and eHealth services, including telepsychiatry; computer-, internet-, and app-based cognitive behavioral therapy; virtual reality; digital applied games; a digital medicine system; omics; neuroimaging; machine learning; precision psychiatry; clinical decision support; electronic health records; physician charting; digital language translators; and online mental health resources for patients. We found that eHealth services provide effective, scalable, and cost-efficient options for the treatment of people with limited or no access to mental health care. This review highlights innovative technologies spearheading the way to more effective and safer treatments. We identified artificially intelligent tools that relieve physicians from routine tasks, allowing them to focus on collaborative doctor–patient relationships. The transformation of traditional clinics into digital ones is outlined, and the challenges associated with the successful deployment of digitalization in psychiatry are highlighted","[{'title': 'International Journal of Environmental Research and Public Health', 'identifiers': ['issn:1660-4601', '1660-4601', '1661-7827', 'issn:1661-7827']}]",'MDPI AG',Psychiatry in the Digital Age: A Blessing or a Curse?,10.3390/ijerph18168302,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
480137986,2021-01-01T00:00:00,"Schizophrenia is a chronic mental illness, characterized by the loss of the notion of reality, failing to distinguish it from the imaginary. It affects the patient in life’s major areas, such as work, interpersonal relationships, or self-care, and the usual treatment is performed with the help of anti-psychotic medication, which targets primarily the hallucinations, delirium, etc. Other symptoms, such as the decreased emotional expression or avolition, require a multidisciplinary approach, including psychopharmacology, cognitive training, and many forms of therapy. In this context, this paper addresses the use of digital technologies to design and develop innovative rehabilitation techniques, particularly focusing on mental health rehabilitation, and contributing for the promotion of well-being and health from a holistic perspective. In this context, serious games and virtual reality allows for creation of immersive environments that contribute to a more effective and lasting recovery, with improvements in terms of quality of life. The use of machine learning techniques will allow the real-time analysis of the data collected during the execution of the rehabilitation procedures, as well as enable their dynamic and automatic adaptation according to the profile and performance of the patients, by increasing or reducing the exercises’ difficulty. It relies on the acquisition of biometric and physiological signals, such as voice, heart rate, and game performance, to estimate the stress level, thus adapting the difficulty of the experience to the skills of the patient. The system described in this paper is currently in development, in collaboration with a health unit, and is an engineering effort that combines hardware and software to develop a rehabilitation tool for schizophrenic patients. A clinical trial is also planned for assessing the effectiveness of the system among negative symptoms in schizophrenia patients.info:eu-repo/semantics/publishedVersio","[{'title': 'Electronics', 'identifiers': ['issn:2079-9292', '2079-9292']}]",Jungong Han,Digital technologies for innovative mental health rehabilitation,,https://core.ac.uk/download/480137986.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
483522852,2021-12-06T00:00:00,"BACKGROUND : The European Society of Gastrointestinal Endoscopy (ESGE) has developed a core curriculum for high quality optical diagnosis training for practice across Europe. The development of easy-to-measure competence standards for optical diagnosis can optimize clinical decision-making in endoscopy. This manuscript represents an official Position Statement of the ESGE aiming to define simple, safe, and easy-to-measure competence standards for endoscopists and artificial intelligence systems performing optical diagnosis of diminutive colorectal polyps (1 - 5 mm). METHODS : A panel of European experts in optical diagnosis participated in a modified Delphi process to reach consensus on Simple Optical Diagnosis Accuracy (SODA) competence standards for implementation of the optical diagnosis strategy for diminutive colorectal polyps. In order to assess the clinical benefits and harms of implementing optical diagnosis with different competence standards, a systematic literature search was performed. This was complemented with the results from a recently performed simulation study that provides guidance for setting alternative competence standards for optical diagnosis. Proposed competence standards were based on literature search and simulation study results. Competence standards were accepted if at least 80 % agreement was reached after a maximum of three voting rounds. RECOMMENDATION 1:  In order to implement the leave-in-situ strategy for diminutive colorectal lesions (1-5 mm), it is clinically acceptable if, during real-time colonoscopy, at least 90 % sensitivity and 80 % specificity is achieved for high confidence endoscopic characterization of colorectal neoplasia of 1-5 mm in the rectosigmoid. Histopathology is used as the gold standard.Level of agreement 95 %. RECOMMENDATION 2:  In order to implement the resect-and-discard strategy for diminutive colorectal lesions (1-5 mm), it is clinically acceptable if, during real-time colonoscopy, at least 80 % sensitivity and 80 % specificity is achieved for high confidence endoscopic characterization of colorectal neoplasia of 1-5 mm. Histopathology is used as the gold standard.Level of agreement 100 %. CONCLUSION : The developed SODA competence standards define diagnostic performance thresholds in relation to clinical consequences, for training and for use when auditing the optical diagnosis of diminutive colorectal polyps",,'Georg Thieme Verlag KG',Definition of competence standards for optical diagnosis of diminutive colorectal polyps: European Society of Gastrointestinal Endoscopy (ESGE) Position Statement.,10.1055/s-00000012,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
483523107,2021-12-14T00:00:00,"الضمور البقعي المرتبط بالعمر (AMD) هو اضطراب في العين قد يطمس الرؤية المركزية الواضحة التي تستخدمها لأشياء مثل القراءة والقيادة. وهو أحد الاضطرابات العديدة التي تؤثر على شبكية العين. تنطبق كلمة ""متعلق بالعمر"" على حقيقة أنها أكثر انتشارًا بين كبار السن. يشير مصطلح ""البقعة الصفراء"" إلى منطقة من عينك تسمى البقعة. يشير مصطلح ""التنكس"" إلى نوع إصابة العين التي تحدث. أحد الأمراض التي تصيب كبار السن هو الضمور البقعي المرتبط بالعمر (AMD). في AMD ، تنتج البقعة تراكمًا تدريجيًا من الرواسب الصفراء المسماة drusen. يسمح التشخيص باستخدام تصوير الأوعية بالفلورسين بتحديد وتحديد عمليات الأوعية الدموية غير الطبيعية. يستخدم معظم أطباء العيون الآن التصوير المقطعي البصري المتسق لتشخيص وتقييم المتابعة استجابة للعلاج بأفاستين أو لوسنتيس، والتي يتم حقنها في الجسم الزجاجي للعين على فترات مختلفة. وُجد أن الاكتشاف المبكر والرعاية، كما هو الحال في اضطرابات العين الأخرى، يقللان من خطر الإصابة بالعمى وفقدان البصر. توفر أجهزة فحص الشبكية الآلية وقت المرضى ومواردهم ورؤيتهم بدلاً من إجراءات التشخيص اليدوية. الغرض من هذه الدراسة هو اقتراح طريقة آلية باستخدام طريقة التعلم الآلي (CNN) لتحديد المرضى الذين يعانون من الضمور البقعي AMD باستخدام صور مجموعة بيانات ODIR. تم تطبيق شبكة عصبية تلافيفية (CNN) لاستخراج السمات العميقة من صور قاع العين الموجودة في مجموعة البيانات لتصنيف الصور إلى مراحل مختلفة من AMD مبكر، متوسط، متأخر)، بجانب الحالة الطبيعية للعين. تم استخدام مقاييس الخصوصية والحساسية والدقة ودرجة F والدقة لتقدير كفاءة التصنيف. وقد تم تحقيق أعلى دقة نحصل عليها هي الدقة: 97٪ ، الحساسية: 98.52٪ ، الخصوصية: 89.29٪ ، المنطقة الواقعة تحت المنحنى: 93.9
الاستنتاجات:
قدمت CNN هذه الدراسة لتشخيصات AMD والصور العادية في مجموعة بيانات ODIR

تم تدريب شبكة سي إن إن على مجموعة الصور هذه لتقليل التجهيز الزائد.

أعلى دقة نحصل عليها هي الدقة: 97٪ ، الحساسية: 98.52٪ ، الخصوصية: 89.29٪ ، المنطقة الواقعة تحت المنحنى: 93.9٪. تم الحصول عليها لمجموعة صور ODIR التي تم تدريب الشبكة عليها. منحنيات التعلم للتدريب على الدقة والاختبار عند تنفيذ الطريقة على صور.ODIRAge-related macular degeneration (AMD) is an eye disorder that may blur the clear, central vision you use for things like reading and driving. It is one of several disorders that influence the retina. The word ""age-related"" applies to the reality that it is more prevalent among older persons. The term ""macular"" refers to a region of your eye named the macula. The term ""degeneration"" refers to the kind of eye injury that occurs. A disease that affects older people is age-related macular degeneration (AMD). In AMD, the macula produces a gradual accumulation of yellow deposits named drusen. Diagnosis with fluorescein angiography allows identifying and locating abnormal vascular processes. Most ophthalmologists now use consistent optical tomography to diagnose and evaluate follow-up in response to treatment with Avastin or Lucentis, which are injected into the eye's vitreous at different intervals. Early detection and care, as in other eye disorders, were found to reduce the risk of blindness and vision loss. Automated retinal examination devices save patients, time, resources, and vision as opposed to manual diagnosis procedures. The purpose of this study is to suggest an automated method using the Machine Learning (CNN) method to identify patients with macular degeneration AMD using images of the ODIR dataset. A convolutional neural network (CNN) was applied to extract the deep features from the fundus images present in the data set for the classification of the images to AMD different stages (Early, Intermediate, and Late), beside the Normal status of the eye. Specificity, Sensitivity, Accuracy, F-score, and Precision metrics were used to estimate classification efficiency the highest accuracy we will get is accuracy: 97%, sensitivity: 98.52%, specificity: 89.29%, area under the curve: 93.9%.
Conclusion:
CNN provided this study for AMD Diagnostics and Normal On images in the ODIR dataset

CNN Network was trained on this image set to minimize the overfitting.
The highest accuracy we will get is accuracy: 97%, sensitivity: 98.52%, specificity: 89.29%, area under the curve: 93.9% was obtained for the group of ODIR images on which the network was trained. Learning curves for accuracy training and test when the method was implemented on ODIR images",,'University of Babylon - Physical Education and Sports Sciences',Convolutional Neural Network in Classifying Three Stages of Age-Related Macula Degeneration,,https://core.ac.uk/download/483523107.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481121923,2021-12-01T00:00:00,"International audienceSince 2017, we have used IonTorrent NGS platform in our hospital to diagnose and treat cancer. Analyzing variants at each run requires considerable time, and we are still struggling with some variants that appear correct on the metrics at first, but are found to be negative upon further investigation. Can any machine learning algorithm (ML) help us classify NGS variants? This has led us to investigate which ML can fit our NGS data and to develop a tool that can be routinely implemented to help biologists. Currently, one of the greatest challenges in medicine is processing a significant quantity of data. This is particularly true in molecular biology with the advantage of next-generation sequencing (NGS) for profiling and identifying molecular tumors and their treatment. In addition to bioinformatics pipelines, artificial intelligence (AI) can be valuable in helping to analyze mutation variants. Generating sequencing data from patient DNA samples has become easy to perform in clinical trials. However, analyzing the massive quantities of genomic or transcriptomic data and extracting the key biomarkers associated with a clinical response to a specific therapy requires a formidable combination of scientific expertise, biomolecular skills and a panel of bioinformatic and biostatistic tools, in which artificial intelligence is now successful in developing future routine diagnostics. However, cancer genome complexity and technical artifacts make identifying real variants challenging. We present a machine learning method for classifying pathogenic single nucleotide variants (SNVs), single nucleotide polymorphisms (SNPs), multiple nucleotide variants (MNVs), insertions, and deletions detected by NGS from different types of tumor specimens, such as: colorectal, melanoma, lung and glioma cancer. We compared our NGS data to different machine learning algorithms using the k-fold cross-validation method and to neural networks (deep learning) to measure the performance of the different ML algorithms and determine which one is a valid model for confirming NGS variant calls in cancer diagnosis. We trained our machine learning with 70% of our data samples, extracted from our local database (our data structure had 7 parameters: chromosome, position, exon, variant allele frequency, minor allele frequency, coverage and protein description) and validated it with the 30% remaining data. The model offering the best accuracy was chosen and implemented in the NGS analysis routine. Artificial intelligence was developed with the R script language version 3.6.0. We trained our model on 70% of 102,011 variants. Our best error rate (0.22%) was found with random forest machine learning (ntree = 500 and mtry = 4), with an AUC of 0.99. Neural networks achieved some good scores. The final trained model with the neural network achieved an accuracy of 98% and an ROC-AUC of 0.99 with validation data. We tested our RF model to interpret more than 2000 variants from our NGS database: 20 variants were misclassified (error rate < 1%). The errors were nomenclature problems and false positives. After adding false positives to our training database and implementing our RF model routinely, our error rate was always < 0.5%. The RF model shows excellent results for oncosomatic NGS interpretation and can easily be implemented in other molecular biology laboratories. AI is becoming increasingly important in molecular biomedical analysis and can be very helpful in processing medical data. Neural networks show a good capacity in variant classification, and in the future, they may be useful in predicting more complex variants",,'Springer Science and Business Media LLC',Machine learning random forest for predicting oncosomatic variant NGS analysis,10.1038/s41598-021-01253-y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
519747193,2021-01-01T00:00:00,"This paper describes a decision support system designed for a Belgian Human Resource (HR) and Well-Being Service Provider. Their goal is to improve health and well-being in the workplace, and to this end, the task is to identify groups of employees at risk of sickness absence who can then be targeted with interventions aiming to reduce or prevent absences. To facilitate deployment, we apply a range of existing machine-learning methods to obtain predictions at monthly intervals using real HR and payroll data that contains no health-related predictors. We model employee absence as a binary classification problem with loss asymmetry and conceptualise a misclassification cost matrix of employee sickness absence. Model performance is evaluated using cost-based metrics, which have intuitive interpretation. We also demonstrate how this problem can be approached when costs are unknown. The proposed flexible evaluation procedure is not restricted to a specific model or domain and can be applied to address other HR analytics questions when deployed. Our approach of considering a wider range of methods and cost-based performance evaluation is novel in the domain of absenteeism prediction.publishedVersio",,'Elsevier BV',Predicting employee absenteeism for cost effective interventions,10.1016/j.dss.2021.113539,https://core.ac.uk/download/519747193.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
489831304,2021-07-29T00:00:00,"The development and implementation of artificial intelligence (AI) applications in health care contexts is a concurrent research and management question. Especially for hospitals, the expectations regarding improved efficiency and effectiveness by the introduction of novel AI applications are huge. However, experiences with real-life AI use cases are still scarce. As a first step towards structuring and comparing such experiences, this paper is presenting a comparative approach from nine European hospitals and eleven different use cases with possible application areas and benefits of hospital AI technologies. This is structured as a current review and opinion article from a diverse range of researchers and health care professionals. This contributes to important improvement options also for pandemic crises challenges, e.g., the current COVID-19 situation. The expected advantages as well as challenges regarding data protection, privacy, or human acceptance are reported. Altogether, the diversity of application cases is a core characteristic of AI applications in hospitals, and this requires a specific approach for successful implementation in the health care sector. This can include specialized solutions for hospitals regarding human-computer interaction, data management, and communication in AI implementation projects",,'MDPI AG',Artificial Intelligence for Hospital Health Care: Application Cases and Answers to Challenges in European Hospitals.,10.3390/healthcare9080961,https://core.ac.uk/download/489831304.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
490909377,2021-01-01T00:00:00,"Background: One of the common limitations in the treatment of cancer is in the early detection of this disease. The customary medical practice of cancer examination is a visual examination by the dermatologist followed by an invasive biopsy. Nonetheless, this symptomatic approach is time-consuming and prone to human errors. An automated machine learning model is essential to capacitate fast diagnoses and early treatment. Objective: The key objective of this study is to establish a fully automatic model that helps Dermatologists in skin cancer handling process in a way that could improve skin lesion classification accuracy. Method: The work is conducted following an implementation of a Deep Convolutional Generative Adversarial Network (DCGAN) using the Python-based deep learning library Keras. We incorporated effective image filtering and enhancement algorithms such as bilateral filter to enhance feature detection and extraction during training. The Deep Convolutional Generative Adversarial Network (DCGAN) needed slightly more fine-tuning to ripe a better return. Hyperparameter optimization was utilized for selecting the best-performed hyperparameter combinations and several network hyperparameters. In this work, we decreased the learning rate from the default 0.001 to 0.0002, and the momentum for Adam optimization algorithm from 0.9 to 0.5, in trying to reduce the instability issues related to GAN models and at each iteration the weights of the discriminative and generative network were updated to balance the loss between them. We endeavour to address a binary classification which predicts two classes present in our dataset, namely benign and malignant. More so, some well-known metrics such as the receiver operating characteristic -area under the curve and confusion matrix were incorporated for evaluating the results and classification accuracy. Results: The model generated very conceivable lesions during the early stages of the experiment and we could easily visualise a smooth transition in resolution along the way. Thus, we have achieved an overall test accuracy of 93.5% after fine-tuning most parameters of our network. Conclusion: This classification model provides spatial intelligence that could be useful in the future for cancer risk prediction. Unfortunately, it is difficult to generate high quality images that are much like the synthetic real samples and to compare different classification methods given the fact that some methods use non-public datasets for training","[{'title': 'Journal of Medical Signals & Sensors', 'identifiers': ['issn:2228-7477', '2228-7477']}]",'Medknow',Generative adversarial network image synthesis method for skin lesion generation and classification,10.4103/jmss.JMSS_53_20,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491102519,2021-11-01T00:00:00,"Abstract Paper-based biosensors based on lateral flow immunoassay (LFI) are promising candidates for POC diagnosis because of their ease of use and rapid target detection. However, the low sensitivity of LFI limits its application, and signal amplification has been used in numerous studies to increase its sensitivity. We developed an advanced trap LFI (α-trapLFI), a simple-to-use sensor, with an additional step for signal amplification. Here, signal amplification is automatically implemented following delayed release of enhancement solution induced by water-soluble polyvinyl alcohol tape. As the polyvinyl alcohol tape is exposed to water, its polymer structure is perturbed (within 5 min), allowing ions to pass through. This new sensor was designed to have a short time delay between the flow of solutions used for the immunoassay and signal amplification. The α-trapLFI was subsequently used to detect cortisol with high sensitivity (9.1 pg∙mL−1) over a broad detection range (0.01–1000 ng∙mL−1) in bodily fluids. Furthermore, an excellent correlation was obtained by analyzing 20 human real saliva samples using this sensor and a conventional ELISA (R 2 = 0.90). The new sensor will be helpful in detecting various small molecules for simple, rapid, and portable POC diagnosis of stress disorders","[{'title': 'Scientific Reports', 'identifiers': ['2045-2322', 'issn:2045-2322']}]",'Springer Science and Business Media LLC',Advanced trap lateral flow immunoassay sensor for the detection of cortisol in human bodily fluids,10.1038/s41598-021-02084-7,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
477990133,2020-12-01T00:00:00,"[EN] Identifying deceptive online reviews is a challenging tasks for Natural Language Processing (NLP). Collecting corpora for the task is difficult, because normally it is not possible to know whether reviews are genuine. A common workaround involves collecting (supposedly) truthful reviews online and adding them to a set of deceptive reviews obtained through crowdsourcing services. Models trained this way are generally successful at discriminating between `genuine¿ online reviews and the crowdsourced deceptive reviews. It has been argued that the deceptive reviews obtained via crowdsourcing are very different from real fake reviews, but the claim has never been properly tested. In this paper, we compare (false) crowdsourced reviews with a set of `real¿ fake reviews published on line. We evaluate their degree of similarity and their usefulness in training models for the detection of untrustworthy reviews. We find that the deceptive reviews collected via crowdsourcing are significantly different from the fake reviews published online. In the case of the artificially produced deceptive texts, it turns out that their domain similarity with the targets affects the models¿ performance, much more than their untruthfulness. This suggests that the use of crowdsourced datasets for opinion spam detection may not result in models applicable to the real task of detecting deceptive reviews. As an alternative method to create large-size datasets for the fake reviews detection task, we propose methods based on the probabilistic annotation of unlabeled texts, relying on the use of meta-information generally available on the e-commerce sites. Such methods are independent from the content of the reviews and allow to train reliable models for the detection of fake reviews.Leticia Cagnina thanks CONICET for the continued financial support. This work was funded by MINECO/FEDER (Grant No. SomEMBED TIN2015-71147-C2-1-P). The work of Paolo Rosso was partially funded by the MISMIS-FAKEnHATE Spanish MICINN research project (PGC2018-096212-B-C31). Massimo Poesio was in part supported by the UK Economic and Social Research Council (Grant Number ES/M010236/1).Fornaciari, T.; Cagnina, L.; Rosso, P.; Poesio, M. (2020). Fake Opinion Detection: How Similar are Crowdsourced Datasets to Real Data?. Language Resources and Evaluation. 54(4):1019-1058. https://doi.org/10.1007/s10579-020-09486-5S10191058544Baeza-Yates, R. (2018). Bias on the web. Communications of the ACM, 61(6), 54–61.Banerjee, S., & Chua, A. Y. (2014). Applauses in hotel reviews: Genuine or deceptive? In: Science and Information Conference (SAI), 2014 (pp. 938–942). New York: IEEE.Bhargava, R., Baoni, A., & Sharma, Y. (2018). Composite sequential modeling for identifying fake reviews. Journal of Intelligent Systems,. https://doi.org/10.1515/jisys-2017-0501.Bickel, P. J., & Doksum, K. A. (2015). Mathematical statistics: Basic ideas and selected topics (2nd ed., Vol. 1). Boca Raton: Chapman and Hall/CRC Press.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of Machine Learning Research, 3(Jan), 993–1022.Blum, A., & Mitchell, T. (1998). Combining labeled and unlabeled data with co-training. In: Proceedings of the eleventh annual conference on computational learning theory (pp. 92–100). New York: ACM.Cagnina, L. C., & Rosso, P. (2017). Detecting deceptive opinions: Intra and cross-domain classification using an efficient representation. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 25(Suppl. 2), 151–174. https://doi.org/10.1142/S0218488517400165.Cardoso, E. F., Silva, R. M., & Almeida, T. A. (2018). Towards automatic filtering of fake reviews. Neurocomputing, 309, 106–116. https://doi.org/10.1016/j.neucom.2018.04.074.Carpenter, B. (2008). Multilevel bayesian models of categorical data annotation. Retrieved from http://lingpipe.files.wordpress.com/2008/11/carp-bayesian-multilevel-annotation.pdf.Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20, 273–297.Costa, P. T., & MacCrae, R. R. (1992). Revised NEO personality inventory (NEO PI-R) and NEO five-factor inventory (NEO FFI): Professional manual. Psychological Assessment Resources.Dawid, A. P., & Skene, A. M. (1979). Maximum likelihood estimation of observer error-rates using the EM algorithm. Applied Statistics, 28(1), 20–28.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society Series B (Methodological), 39(1), 1–38.Elkan, C., & Noto, K. (2008). Learning classifiers from only positive and unlabeled data. In: Proceedings of the 14th ACM SIGKDD international conference on knowledge discovery and data mining (pp. 213–220). New York: ACM.Fei, G., Mukherjee, A., Liu, B., Hsu, M., Castellanos, M., & Ghosh, R. (2013). Exploiting burstiness in reviews for review spammer detection. In: Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media (Vol. 13, pp. 175–184).Feng, S., Banerjee, R., & Choi, Y. (2012). Syntactic stylometry for deception detection. In: Proceedings of the 50th annual meeting of the association for computational linguistics (Vol. 2: Short Papers, pp. 171–175). Jeju Island: Association for Computational Linguistics.Forman, G. (2003). An extensive empirical study of feature selection metrics for text classification. Journal of Machine Learning Research, 3, 1289–1305.Fornaciari, T., & Poesio, M. (2013). Automatic deception detection in Italian court cases. Artificial intelligence and law, 21(3), 303–340. https://doi.org/10.1007/s10506-013-9140-4.Fornaciari, T., & Poesio, M. (2014). Identifying fake amazon reviews as learning from crowds. In: Proceedings of the 14th conference of the European chapter of the Association for Computational Linguistics (pp. 279–287). Gothenburg: Association for Computational Linguistics. Retrieved from http://www.aclweb.org/anthology/E14-1030.Gelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models., Analytical methods for social research Cambridge: Cambridge University Press.Graves, A., Jaitly, N., & Mohamed, A. R. (2013). Hybrid speech recognition with deep bidirectional LSTM. In: 2013 IEEE workshop on automatic speech recognition and understanding (ASRU) (pp. 273–278). New York: IEEE.Hernández-Castañeda, Á., & Calvo, H. (2017). Deceptive text detection using continuous semantic space models. Intelligent Data Analysis, 21(3), 679–695.Hernández Fusilier, D., Guzmán, R., Móntes y Gomez, M., & Rosso, P. (2013). Using pu-learning to detect deceptive opinion spam. In: Proc. of the 4th workshop on computational approaches to subjectivity, sentiment and social media analysis (pp. 38–45).Hernández Fusilier, D., Montes-y Gómez, M., Rosso, P., & Cabrera, R. G. (2015). Detecting positive and negative deceptive opinions using pu-learning. Information Processing & Management, 51(4), 433–443.Hovy, D. (2016). The enemy in your own camp: How well can we detect statistically-generated fake reviews–an adversarial study. In: The 54th annual meeting of the association for computational linguistics (p 351).Jelinek, F., Lafferty, J. D., & Mercer, R. L. (1992). Basic methods of probabilistic context free grammars. Speech recognition and understanding (pp. 345–360). New York: Springer.Jindal, N., & Liu, B. (2008). Opinion spam and analysis. In: Proceedings of the 2008 international conference on web search and data mining (pp. 219–230). New York: ACM.Karatzoglou, A., Meyer, D., & Hornik, K. (2006). Support vector machines in R. Journal of Statistical Software, 15(9), 1–28.Kim, S., Lee, S., Park, D., & Kang, J. (2017). Constructing and evaluating a novel crowdsourcing-based paraphrased opinion spam dataset. In: Proceedings of the 26th international conference on world wide web (pp. 827–836). Geneva: International World Wide Web Conferences Steering Committee.Li, F., Huang, M., Yang, Y., & Zhu, X. (2011). Learning to identify review spam. IJCAI Proceedings-International Joint Conference on Artificial Intelligence, 22(3), 2488–2493.Li, H., Chen, Z., Liu, B., Wei, X., & Shao, J. (2014a). Spotting fake reviews via collective positive-unlabeled learning. In: 2014 IEEE international conference on data mining (ICDM) (pp. 899–904). New York: IEEE.Li, H., Fei, G., Wang, S., Liu, B., Shao, W., Mukherjee, A., & Shao, J. (2017). Bimodal distribution and co-bursting in review spam detection. In: Proceedings of the 26th international conference on world wide web (pp. 1063–1072). Geneva: International World Wide Web Conferences Steering Committee.Li, H., Liu, B., Mukherjee, A., & Shao, J. (2014b). Spotting fake reviews using positive-unlabeled learning. Computación y Sistemas, 18(3), 467–475.Li, J., Ott, M., Cardie, C., & Hovy, E. H. (2014c). Towards a general rule for identifying deceptive opinion spam. In: ACL (Vol. 1, pp. 1566–1576).Lin, C. H., Hsu, P. Y., Cheng, M. S., Lei, H. T., & Hsu, M. C. (2017). Identifying deceptive review comments with rumor and lie theories. In: International conference in swarm intelligence (pp. 412–420). New York: Springer.Liu, B., Dai, Y., Li, X., Lee, W. S., & Yu, P. S. (2003). Building text classifiers using positive and unlabeled examples. In: Third IEEE international conference on data mining (pp. 179–186). New York: IEEE.Liu, B., Lee, W. S., Yu, P. S., & Li, X. (2002). Partially supervised classification of text documents. ICML, 2, 387–394.Martens, D., & Maalej, W. (2019). Towards understanding and detecting fake reviews in app stores. Empirical Software Engineering,. https://doi.org/10.1007/s10664-019-09706-9.Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:13013781.Mukherjee, A., Kumar, A., Liu, B., Wang, J., Hsu, M., Castellanos, M., & Ghosh, R. (2013a). Spotting opinion spammers using behavioral footprints. In: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 632–640) New York: ACM.Mukherjee, A., Venkataraman, V., Liu, B., & Glance, N. S. (2013b). What yelp fake review filter might be doing? In: Proceedings of the seventh international AAAI conference on weblogs and social media.Negri, M., Bentivogli, L., Mehdad, Y., Giampiccolo, D., & Marchetti, A. (2011). Divide and conquer: Crowdsourcing the creation of cross-lingual textual entailment corpora. In: Proceedings of the conference on empirical methods in natural language processing (pp. 670–679). Stroudsburg: Association for Computational Linguistics.Ott, M., Cardie, C., & Hancock, J. T. (2013). Negative deceptive opinion spam. In: Proceedings of the 2013 conference of the North American chapter of the association for computational linguistics: human language technologies (pp. 497–501).Ott, M., Choi, Y., Cardie, C., & Hancock, J. (2011). Finding deceptive opinion spam by any stretch of the imagination. In: Proceedings of the 49th Annual meeting of the association for computational linguistics: human language technologies (pp. 309–319). Portland, Oregon: Association for Computational Linguistics.Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001). Linguistic inquiry and word count (LIWC): LIWC2001. Mahwah: Lawrence Erlbaum Associates.Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global vectors for word representation. In: Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532–1543).Raykar, V. C., Yu, S., Zhao, L. H., Valadez, G. H., Florin, C., Bogoni, L., et al. (2010). Learning from crowds. Journal of Machine Learning Research, 11, 1297–1322.Ren, Y., & Ji, D. (2017). Neural networks for deceptive opinion spam detection: An empirical study. Information Sciences, 385, 213–224.Rout, J. K., Dalmia, A., Choo, K. K. R., Bakshi, S., & Jena, S. K. (2017). Revisiting semi-supervised learning for online deceptive review detection. IEEE Access, 5(1), 1319–1327.Saini, M., & Sharan, A. (2017). Ensemble learning to find deceptive reviews using personality traits and reviews specific features. Journal of Digital Information Management, 12(2), 84–94.Salloum, W., Edwards, E., Ghaffarzadegan, S., Suendermann-Oeft, D., & Miller, M. (2017). Crowdsourced continuous improvement of medical speech recognition. In: The AAAI-17 workshop on crowdsourcing, deep learning, and artificial intelligence agents.Schmid, H. (1994). Probabilistic part-of-speech tagging using decision trees. In: Proceedings of international conference on new methods in language processing. Retrieved from http://www.ims.uni-stuttgart.de/ftp/pub/corpora/tree-tagger1.pdf.Shehnepoor, S., Salehi, M., Farahbakhsh, R., & Crespi, N. (2017). Netspam: A network-based spam detection framework for reviews in online social media. IEEE Transactions on Information Forensics and Security, 12(7), 1585–1595.Skeppstedt, M., Peldszus, A., & Stede, M. (2018). More or less controlled elicitation of argumentative text: Enlarging a microtext corpus via crowdsourcing. In: Proceedings of the 5th workshop on argument mining (pp. 155–163).Strapparava, C., & Mihalcea, R. (2009). The lie detector: Explorations in the automatic recognition of deceptive language. In: Proceedings of the 47th annual meeting of the association for computational linguistics and the 4th international joint conference on natural language processing.Streitfeld, D. (August $$25{{\rm th}}$$, 2012). The best book reviews money can buy. The New York Times.Whitehill, J., Wu, T., Bergsma, F., Movellan, J. R., & Ruvolo, P. L. (2009). Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. Advances in neural information processing systems (pp. 2035–2043). Cambridge: MIT Press.Xie, S., Wang, G., Lin, S., & Yu, P. S. (2012). Review spam detection via temporal pattern discovery. In: Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining (pp 823–831). New York: ACM.Yang, Y., & Liu, X. (1999). A re-examination of text categorization methods. In: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’99 (pp. 42–49). New York: ACM.Zhang, W., Bu, C., Yoshida, T., & Zhang, S. (2016). Cospa: A co-training approach for spam review identification with support vector machine. Information, 7(1), 12.Zhang, W., Du, Y., Yoshida, T., & Wang, Q. (2018). DRI-RCNN: An approach to deceptive review identification using recurrent convolutional neural network. Information Processing & Management, 54(4), 576–592.Zhou, L., Shi, Y., & Zhang, D. (2008). A Statistical Language Modeling Approach to Online Deception Detection. IEEE Transactions on Knowledge and Data Engineering, 20(8), 1077–1081",,'Springer Science and Business Media LLC',Fake Opinion Detection: How Similar are Crowdsourced Datasets to Real Data?,10.1007/s10579-020-09486-5,https://riunet.upv.es/bitstream/10251/171117/1/FornaciariCagninaRosso%20-%20Fake%20Opinion%20Detection%20How%20Similar%20are%20Crowdsourced%20Datasets%20to%20Real%20Data.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
370074707,2020-01-01T00:00:00,"The high capacity of neural networks allows fitting models to data with high precision, but makes generalization to unseen data a challenge. If a domain shift exists, i.e. differences in image statistics between training and test data, care needs to be taken to ensure reliable deployment in real-world scenarios. In digital pathology, domain shift can be manifested in differences between whole-slide images, introduced by for example differences in acquisition pipeline - between medical centers or over time. In order to harness the great potential presented by deep learning in histopathology, and ensure consistent model behavior, we need a deeper understanding of domain shift and its consequences, such that a model's predictions on new data can be trusted. This work focuses on the internal representation learned by trained convolutional neural networks, and shows how this can be used to formulate a novel measure - the representation shift - for quantifying the magnitude of model specific domain shift. We perform a study on domain shift in tumor classification of hematoxylin and eosin stained images, by considering different datasets, models, and techniques for preparing data in order to reduce the domain shift. The results show how the proposed measure has a high correlation with drop in performance when testing a model across a large number of different types of domain shifts, and how it improves on existing techniques for measuring data shift and uncertainty. The proposed measure can reveal how sensitive a model is to domain variations, and can be used to detect new data that a model will have problems generalizing to. We see techniques for measuring, understanding and overcoming the domain shift as a crucial step towards reliable use of deep learning in the future clinical pathology applications",,'Institute of Electrical and Electronics Engineers (IEEE)',Measuring Domain Shift for Deep Learning in Histopathology,10.1109/JBHI.2020.3032060,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491214310,2021-01-01T00:00:00,"Aims The world hospital systems are presently facing many unprecedented challenges from COVID‐19 disease. Prediction the deteriorating or critical cases can help triage patients and assist in effective medical resource allocation. This study aimed to develop and validate a prediction model based on Machine Learning algorithms to predict hospitalized COVID-19 patients for transfer to ICU based on clinical parameters. Materials & Methods This retrospective, single-center study was conducted based on cumulative data of COVID-19 patients (N=1225) who were admitted from March 9, 2020, to December 20, 2020, to Mostafa Khomeini Hospital, affiliated to Ilam University of Medical Sciences (ILUMS), focal point center for COVID-19 care and treatment in Ilam, West of Iran. 13 ML techniques from six different groups applied to predict ICU admission. To evaluate the performances of models, the metrics derived from the confusion matrix were calculated. The algorithms were implemented using WEKA 3.8 software. Findings This retrospective study’s median age was 50.9 years, and 664 (54.2) were male. The experimental results indicate that Meta algorithms have the best performance in ICU admission risk prediction with an accuracy of 90.37, a sensitivity of 90.35, precision of 88.25, F-measure of 88.35, and ROC of 91. Conclusion Machine Learning algorithms are helpful predictive tools for real-time and accurate ICU risk prediction in patients with COVID-19 at hospital admission. This model enables and potentially facilitates more responsive health systems that are beneficial to high-risk COVID-19 patients. © 2021, the Authors | Publishing Rights, ASPI",,,Comparing of machine learning algorithms for predicting icu admission in covid-19 hospitalized patients,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
478072019,2021-09-22T10:48:31,"Since SARS-CoV-2 is likely to become endemic in many countries, it will require not only short-term
support but also long-term support, as social distancing policies cannot be extended for long. Therefore, a technological
platform for epidemiological surveillance can represent a fundamental tool. The impact of the project is essential for public
health actors to design and evaluate policies aimed at the safe reactivation of social activities after social distancing policies
are suspended. We also consider this software service as a basic piece in the digital Transformation strategy, since it allows
us to anticipate the behaviors and necessary resources that adapt the needs with the provision in a dynamic way, but
adjusted to reality. This anticipation approach becomes a pillar in the digital strategy of any company, Administration and
education center. The tool includes a mechanism based on Artificial Intelligence for data analysis in order to have a
dynamic understanding of symptoms, evolution, social space-time data and the relationships between them, which will
allow the relevant entities to optimize resources such as virus detection tests and positive test controls.dado que resulta probable que el SARS-CoV-2 se vuelva endémico en muchos países, requerirá no sólo
apoyo a corto plazo sino también a largo plazo, ya que las políticas de distanciamiento social no pueden extenderse por
mucho tiempo. Por lo tanto, una plataforma tecnológica de vigilancia epidemiológica puede representar una herramienta
fundamental. El impacto del proyecto resulta esencial para que los actores relacionados con la salud pública diseñen y
evalúen políticas destinadas a la reactivación segura de las actividades sociales después de que se suspendan las políticas
de distanciamiento social. Consideramos también este servicio software como una pieza básica en la estrategia de
Transformación digital, ya que permite anticipar comportamientos y recursos necesarios que amolden las necesidades con
la provisión de manera dinámica, pero ajustada a la realidad. Este enfoque de anticipación se vuelve un pilar en la
estrategia digital de cualquier empresa, Administración y centro de educación. La herramienta incluye un mecanismo
basado en Inteligencia Artificial para el análisis de datos con el fin de tener una comprensión dinámica de los síntomas, la
evolución, los datos espacio-temporales sociales y las relaciones entre ellos, lo que permitirá a las entidades relevantes
optimizar recursos como las pruebas de detección de virus y controles de prueba positivo","[{'title': None, 'identifiers': ['2255-1514', 'issn:2255-1514']}]",Campus Virtuales,Conceptual architecture of the epidemiological surveillance technology platform for COVID-19,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491201752,2020-01-01T00:00:00,"An image is worth a thousand words; hence, a face image illustrates extensive details about the specification, gender, age, and emotional states of mind. Facial expressions play an important role in community-based interactions and are often used in the behavioral analysis of emotions. Recognition of automatic facial expressions from a facial image is a challenging task in the computer vision community and admits a large set of applications, such as driver safety, human-computer interactions, health care, behavioral science, video conferencing, cognitive science, and others. In this work, a deep-learning-based scheme is proposed for identifying the facial expression of a person. The proposed method consists of two parts. The former one finds out local features from face images using a local gravitational force descriptor, while, in the latter part, the descriptor is fed into a novel deep convolution neural network (DCNN) model. The proposed DCNN has two branches. The first branch explores geometric features, such as edges, curves, and lines, whereas holistic features are extracted by the second branch. Finally, the score-level fusion technique is adopted to compute the final classification score. The proposed method along with 25 state-of-the-art methods is implemented on five benchmark available databases, namely, Facial Expression Recognition 2013, Japanese Female Facial Expressions, Extended CohnKanade, Karolinska Directed Emotional Faces, and Real-world Affective Faces. The databases consist of seven basic emotions: neutral, happiness, anger, sadness, fear, disgust, and surprise. The proposed method is compared with existing approaches using four evaluation metrics, namely, accuracy, precision, recall, and f1-score. The obtained results demonstrate that the proposed method outperforms all state-of-the-art methods on all the databases",,'Institute of Electrical and Electronics Engineers (IEEE)',Facial Expression Recognition Using Local Gravitational Force Descriptor-Based Deep Convolution Neural Networks,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
511382804,2021-01-01T00:00:00,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.Scopu",,'Elsevier BV',1D convolutional neural networks and applications: A survey,10.1016/j.ymssp.2020.107398,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
480463001,2021-07-17T00:00:00,"Non-invasive strategies that can identify oral malignant and dysplastic oral potentially-malignant lesions (OPML) are necessary in cancer screening and long-term surveillance. Optical coherence tomography (OCT) can be a rapid, real time and non-invasive imaging method for frequent patient surveillance. Here, we report the validation of a portable, robust OCT device in 232 patients (lesions: 347) in different clinical settings. The device deployed with algorithm-based automated diagnosis, showed efficacy in delineation of oral benign and normal (n = 151), OPML (n = 121), and malignant lesions (n = 75) in community and tertiary care settings. This study showed that OCT images analyzed by automated image processing algorithm could distinguish the dysplastic-OPML and malignant lesions with a sensitivity of 95% and 93%, respectively. Furthermore, we explored the ability of multiple (n = 14) artificial neural network (ANN) based feature extraction techniques for delineation high grade-OPML (moderate/severe dysplasia). The support vector machine (SVM) model built over ANN, delineated high-grade dysplasia with sensitivity of 83%, which in turn, can be employed to triage patients for tertiary care. The study provides evidence towards the utility of the robust and low-cost OCT instrument as a point-of-care device in resource-constrained settings and the potential clinical application of device in screening and surveillance of oral cancer",,"eScholarship, University of California",Validation of a Point-of-Care Optical Coherence Tomography Device with Machine Learning Algorithm for Detection of Oral Potentially Malignant and Malignant Lesions.,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440364083,2021-01-01T00:00:00,"Artificial intelligence (AI) systems have become critical in support of decision-making. This systematic review summarizes all the data currently available on the AI-assisted CT-Scan prediction accuracy for COVID-19. The ISI Web of Science, Cochrane Library, PubMed, Scopus, CINAHL, Science Direct, PROSPERO, and EMBASE were systematically searched. We used the revised Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool to assess all included studies' quality and potential bias. A hierarchical receiver-operating characteristic summary (HSROC) curve and a summary receiver operating characteristic (SROC) curve have been implemented. The area under the curve (AUC) was computed to determine the diagnostic accuracy. Finally, 36 studies (a total of 39,246 image data) were selected for inclusion into the final meta-analysis. The pooled sensitivity for AI was 0.90 (95% CI, 0.90–0.91), specificity was 0.91 (95% CI, 0.90–0.92) and the AUC was 0.96 (95% CI, 0.91–0.98). For deep learning (DL) method, the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.88 (95% CI, 0.87–0.88) and the AUC was 0.96 (95% CI, 0.93–0.97). In case of machine learning (ML), the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.95 (95% CI, 0.94–0.95) and the AUC was 0.97 (95% CI, 0.96–0.99). AI in COVID-19 patients is useful in identifying symptoms of lung involvement. More prospective real-time trials are required to confirm AI's role for high and quick COVID-19 diagnosis due to the possible selection bias and retrospective existence of currently available studies","[{'title': 'Informatics in Medicine Unlocked', 'identifiers': ['2352-9148', 'issn:2352-9148']}]",'Elsevier BV',The diagnostic accuracy of Artificial Intelligence-Assisted CT imaging in COVID-19 disease: A systematic review and meta-analysis,10.1016/j.imu.2021.100591,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
345013744,,"Serija: Annals of computer science and information systems, vol. 21The lack of dopamine in the human brain is the cause of Parkinson disease (PD) which is a degenerative disorder common globally to older citizens. However, late detection of this disease before the first clinical diagnosis has led to increased mortality rate. Research effort towards the early detection of PD has encountered challenges such as: small dataset size, class imbalance, overfitting, high false detection rate, model complexity, etc. This paper aims to improve early detection of PD using machine learning through data augmentation for very small datasets. We propose using Spline interpolation and Piecewise Cubic Hermite Interpolating Polynomial (Pchip) interpolation methods to generate synthetic data instances. We further investigate on reducing dimensionality of features for effective and real-time classification while considering computational complexity of implementation on real-life mobile phones. For classification we use Bidirectional LSTM (BiLSTM) deep learning network and compare the results with traditional machine learning algorithms like Support Vector Machine (SVM), Decision Tree, Logistic regression, KNN and Ensemble bagged tree. For experimental validation we use the Oxford Parkinson disease dataset with 195 data samples, which we have augmented with 571 synthetic data samples. The results for BiLSTM shows that even with a holdout of 90%, the model was still able to effectively recognize PD with an average accuracy for ten rounds experiment using 22 features as 82.86%, 97.1%, and 96.37% for original, augmented (Spline) and augmented (Pchip) datasets, respectively. Our results show that proposed data augmentation schemes have significantly (p < 0.001) improved the accuracy of PD recognition on a small dataset using both classical machine learning models and BiLSTMInformatikos fakultetasKauno technologijos universitetasVytauto Didžiojo universiteta",,'Polish Information Processing Society PTI',BiLSTM with data augmentation using interpolation methods to improve early detection of Parkinson disease,10.15439/2020F188,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
490584732,2021-12-21T00:00:00,"The discipline of remote working has been characterized from the beginning by a significant participatory presence in collective bargaining, from the European Framework Agreement on Telework of 2002, to its national implementation within the Interconfederal Agreement of 2004, passing through the propulsive role that the bargaining, especially that within the company realities, had regarding the preparatory work that led to the enactment of the law 22 May 2017, n. 81 about the “smart working”. This role could also affect the reform of the discipline, made indispensable because the wide appeal that the agile type, also known as «smart working» anglicism, has had due to the spread of SARS-CoV-19. It is precisely the experimentation throughout the national territory that has rekindled the debate on the subject and stimulated bargaining again with the aim of regulating a «method of execution of the employment relationship» (Article 18, l. 81/2017) which seems to have become an integral part of the current and future organization of work. This contribution aims to investigate the first solutions born in corporate bargaining. The fil rouge that binds the 25 company agreements – selected for the innovativeness of the solutions adopted, for the completeness of the discipline or for the occupational relevance – is the intent to regulate, considering the peculiarities of the workers in force in the individual companies, not simplified smart working, and that is the one that should be resorted when the health emergency will be over – indeed already practiced by someone. Three topical study topics for post-emergency labour law have been identified: access to agile mode, workplace safety and working time flexibility. With respect to the first profile, corporate collective bargaining has expanded the number of workers with priority access to this remote working method, recognizing real rights to smart working in favour of some categories. With respect to the second profile, the agreements have more or less strictly limited the freedom of the agile worker to choose the workplace independently, also with the aim of limiting the employer’s responsibility for health and safety in the workplace, the perimeter of which does not appear sufficiently clear in line with the doctrinal debate on the subject. With respect to the third profile, the contractual practice examined has kept normal working time firm, while variously developing the possibility of placing it flexibly within the working day, abdicating instead the task of fully defining the right to disconnect and, therefore, suitable and mandatory «technical and organizational measures».La disciplina de los casos de teletrabajo se ha caracterizado desde el principio por una importante presencia participativa en la negociación colectiva, desde el Acuerdo Marco Europeo sobre Teletrabajo de 2002, hasta su implementación nacional dentro del Acuerdo Interconfederal de 2004, pasando por el papel propulsor que la negociación, especialmente que dentro de las realidades de la empresa, con respecto al trabajo preparatorio que condujo a la promulgación de la ley 22 de mayo de 2017 n. 81 sobre el trabajo ágil y que también podría afectar la reforma de la disciplina, indispensable a raíz del amplio atractivo que ha tenido el tipo ágil, también conocido con el anglicismo «smart working», debido a la propagación del SARS-CoV-19. Es precisamente la experimentación que tuvo lugar en todo el territorio nacional la que ha reavivado el debate sobre el tema y ha estimulado nuevamente la negociación con el objetivo de regular un «método de ejecución de la relación laboral» (artículo 18 de la l. 81/2017), que parece haberse convertido en parte integrante de la organización del trabajo actual y futura. Esta contribución tiene como objetivo investigar las primeras soluciones nacidas de la negociación de proximidad. El fil rouge que une los 25 convenios de empresa - seleccionados por la innovación de las soluciones adoptadas, por la integridad de la disciplina o por la relevancia ocupacional - es la intención de regular, considerando las peculiaridades de los trabajadores vigentes en las empresas individuales, el smart working no simplificado, y que es lo que se utilizará cuando la emergencia sanitaria haya pasada - de hecho ya lo practican algunos. Se han identificado tres temas de estudio de actualidad para la legislación laboral posterior a emergencias: acceso al modo ágil, seguridad en el lugar de trabajo y flexibilidad horaria. En comparación con el primer perfil, la negociación colectiva corporativa ha ampliado el número de trabajadores con acceso prioritario a este método de trabajo a distancia, reconociendo derechos reales al trabajo inteligente a favor de algunas categorías. Con respecto al segundo perfil, los acuerdos han limitado más o menos estrictamente la libertad del trabajador ágil para elegir el lugar de trabajo, también con el objetivo de limitar la responsabilidad del empleador en la salud y seguridad en el lugar de trabajo, que no parece suficientemente claro en consonancia con el debate doctrinal sobre el tema. En comparación con el tercer perfil, la práctica contractual examinada ha mantenido firme el horario normal, al tiempo que desarrolló de diversas maneras la posibilidad de ubicarlo en manera flexible dentro de la jornada laboral, abdicando en cambio de la tarea de definir plenamente el derecho a desconectarse y, por lo tanto, la idoneidad y obligatoriedad de «técnicas y medidas organizativas»La disciplina delle fattispecie di lavoro da remoto è stata sin ab origine contraddistinta da una significativa presenza partecipativa della contrattazione collettiva, dall’Accordo Quadro Europeo sul Telelavoro del 2002, al suo recepimento nazionale all’interno dell’Accordo Interconfederale del 2004, passando per il ruolo propulsivo che la contrattazione, specie quella in seno alle realtà aziendali, ha avuto rispetto ai lavori preparatori che hanno condotto all’emanazione della legge 22 maggio 2017 n. 81 sul lavoro agile e che potrebbe altresì influire sulla riforma della disciplina, resa indispensabile a seguito dell’ampio ricorso che la fattispecie agile, nota anche con l’anglicismo «smart working», ha avuto a causa della diffusione del SARS-CoV-19.
È proprio la sperimentazione avutasi sull’intero territorio nazionale che ha riacceso il dibattito in materia e stimolato nuovamente la contrattazione con l’intento di regolare una «modalità di esecuzione del rapporto di lavoro subordinato» (art. 18 l. n. 81/2017), che pare sia divenuta parte integrante dell’attuale e futura organizzazione del lavoro. Il presente contributo si propone di indagare le prime soluzioni nate in seno alla contrattazione aziendale. Il fil rouge che lega i 25 accordi aziendali – selezionati per l’innovatività delle soluzioni adottate, per la completezza della disciplina o per la rilevanza occupazionale – è l’intento di regolare, considerando le peculiarità dei lavoratori in forza nelle singole realtà aziendali, lo smart working non semplificato, e cioè quello a cui si dovrebbe ricorrere ad emergenza sanitaria conclusa – invero già da alcuni praticato.
Sono stati enucleati tre temi di studio di attualità per il diritto del lavoro post-emergenziale: l’accesso alla modalità agile, la sicurezza sul luogo di lavoro e la flessibilità oraria. Rispetto al primo profilo, la contrattazione collettiva aziendale ha ampliato la platea dei lavoratori aventi accesso prioritario a tale modalità di lavoro da remoto, riconoscendo in favore di alcune categorie veri e propri diritti allo smart working. Rispetto al secondo profilo, gli accordi hanno circoscritto in maniera più o meno stringente la libertà del lavoratore agile di scegliere autonomamente il luogo di lavoro, anche con l’intento di limitare la responsabilità del datore di lavoro in materia di salute e sicurezza nei luoghi di lavoro, il cui perimetro non appare sufficientemente chiaro in linea con il dibattito dottrinale in materia. Rispetto al terzo profilo, la prassi contrattuale esaminata ha mantenuto fermo l’orario normale, pur sviluppando variamente la possibilità di collocarlo in maniera flessibile all’interno della giornata lavorativa, abdicando invece al compito di definire compiutamente il diritto alla disconnessione e, dunque, «misure tecniche e organizzative» idonee e cogenti",,Dipartimento di Scienze Giuridiche. Alma Mater Studiorum - Università di Bologna,La contrattazione collettiva e i nodi irrisolti in materia di lavoro agile,10.6092/issn.2421-2695/14112,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481416303,2021-10-20T00:00:00,"Background: One of the common limitations in the treatment of cancer is in the early detection of this disease. The customary medical practice of cancer examination is a visual examination by the dermatologist followed by an invasive biopsy. Nonetheless, this symptomatic approach is time-consuming and prone to human errors. An automated machine learning model is essential to capacitate fast diagnoses and early treatment. Objective: The key objective of this study is to establish a fully automatic model that helps Dermatologists in skin cancer handling process in a way that could improve skin lesion classification accuracy. Method: The work is conducted following an implementation of a Deep Convolutional Generative Adversarial Network (DCGAN) using the Python-based deep learning library Keras. We incorporated effective image filtering and enhancement algorithms such as bilateral filter to enhance feature detection and extraction during training. The Deep Convolutional Generative Adversarial Network (DCGAN) needed slightly more fine-tuning to ripe a better return. Hyperparameter optimization was utilized for selecting the best-performed hyperparameter combinations and several network hyperparameters. In this work, we decreased the learning rate from the default 0.001 to 0.0002, and the momentum for Adam optimization algorithm from 0.9 to 0.5, in trying to reduce the instability issues related to GAN models and at each iteration the weights of the discriminative and generative network were updated to balance the loss between them. We endeavour to address a binary classification which predicts two classes present in our dataset, namely benign and malignant. More so, some well-known metrics such as the receiver operating characteristic -area under the curve and confusion matrix were incorporated for evaluating the results and classification accuracy. Results: The model generated very conceivable lesions during the early stages of the experiment and we could easily visualise a smooth transition in resolution along the way. Thus, we have achieved an overall test accuracy of 93.5% after fine-tuning most parameters of our network. Conclusion: This classification model provides spatial intelligence that could be useful in the future for cancer risk prediction. Unfortunately, it is difficult to generate high quality images that are much like the synthetic real samples and to compare different classification methods given the fact that some methods use non-public datasets for training","[{'title': 'Journal of Medical Signals & Sensors', 'identifiers': ['issn:2228-7477', '2228-7477']}]",'Medknow',Generative adversarial network image synthesis method for skin lesion generation and classification,10.4103/jmss.JMSS_53_20.,https://core.ac.uk/download/481416303.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
333919275,2020-04-28T00:00:00,"International audienceBackground: High-throughput sequencing techniques are used to analyse the diversity of the respiratory microbiota in health and disease. Although extensive data are available regarding bacterial respiratory microbiota, its fungal component remains poorly studied. This is partly due to the technical issues associated with fungal metagenomics analyses. In this study, we compared two DNA extraction protocols and two fungal amplification targets for combined bacterial and fungal targeted amplicon sequencing analyses of the respiratory microbiota.Methods: Six sputa, randomly selected from routine samples in Mondor Hospital (Creteil, France) and treated anonymously, were tested after bacterial and fungal routine culture. Two of which were spiked with Aspergillus Fumigati and Aspergillus Nigri (105 conidia/mL). After mechanical lysis, DNA was extracted using automated QIAsymphony® extraction (AQE) or manual PowerSoil® MoBio extraction (MPE). DNA yield and purity were compared. DNA extracted from spiked sputa was subjected to (i) real-time PCR for Aspergillus DNA detection and (ii) combined metagenomic analyses targeting barcoded primers for fungal ITS1 and ITS2, and bacterial V1-V2 and V3-V4 16S regions. Amplicon libraries were prepared using MiSeq Reagent V3 kit on Illumina platform. Data were analysed using PyroMIC© and SHAMAN software, and compared with culture results.Results: AQE extraction provided a higher yield of DNA (AQE/MPE DNA ratio = 4.5 [1.3-11]) in a shorter time. The yield of Aspergillus DNA detected by qPCR was similar for spiked sputa regardless of extraction protocol. The extraction moderately impacted the diversity or relative abundances of bacterial communities using targeted amplicon sequencing (2/43 taxa impacted). For fungi, the relative abundances of 4/11 major taxa were impacted and AQE results were closer to culture results. The V1-V2 or V3-V4 and ITS1 or ITS2 targets assessed similarly the diversity of bacterial and fungal major taxa, but ITS2 and V3-V4 detected more minor taxa.Conclusion: Our results showed the importance of DNA extraction for combined bacterial and fungal targeted metagenomics of respiratory samples. The extraction protocol can affect DNA yield and the relative abundances of few bacterial but more fungal taxa. For fungal analysis, ITS2 allowed the detection of a greater number of minor taxa compared with ITS1",,'Public Library of Science (PLoS)',Combined bacterial and fungal targeted amplicon sequencing of respiratory samples: Does the DNA extraction method matter?,10.1371/journal.pone.0232215,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
479728860,2021-01-01T00:00:00,"As the core power for the aviation industry, shipbuilding industry, and power station industry, it is essential to ensure that the gas turbines operate safely, reliably, greenly and efficiently. Learn from the advantages and disadvantages of the thermodynamic model based and data-driven artificial intelligence based gas-path diagnosis methods, a newfangled gas turbine gas-path diagnosis approach on the basis of knowledge data-driven artificial intelligence is proposed. That is a hybrid method of deep learning and gas path analysis. First, gas turbine thermodynamic model of the object to be diagnosed is constructed by adaptation modeling strategy. And the engine thermodynamic model is taken as the basal model to simulate various gas path faults. Secondly, a large number of knowledge data corresponding to component health parameters and gas turbine boundary condition parameters &#x0026; gas-path measurable parameters are simulated by setting different component health parameter values and different boundary conditions based on this basal model. And next, define the vector composed of the boundary condition parameters &#x0026; the gas path measurable parameters in the knowledge database as the input vector, and the component health parameter vector as the output vector, and a deep learning model for regression modeling of this knowledge database is designed. At last, along with the gas turbine engine runs, the trained model outputs component health parameters in real time after trained deep learning model is deployed to the corresponding gas turbine power plant. The simulation experiment results show that, accurate and quantified health parameters of each gas path component can be obtained by the proposed method in this paper, and the overall root mean square error does not exceed 0.033&#x0025;, and the maximum relative error does not exceed 0.36&#x0025;, which illustrates the proposed method has great application potential","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Gas Path Fault Diagnosis of Gas Turbine Engine Based on Knowledge Data-Driven Artificial Intelligence Algorithm,10.1109/ACCESS.2021.3101647,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
479465616,2021-01-01T00:00:00,"Robotics, Artificial Intelligence (AI), and the Internet of Things (IoT) support various processes in many scenarios of modern life such as e-health and psychological treatments. This article presents the design, development, implementation, and assessment of a Robotic Assistant (RA), named &#x201C;Atent&#x0040;&#x201D;, as a support tool in the homework activities of children with Attention Deficit Hyperactivity Disorder (ADHD). Interacting with the children the RA helps them correct their bad habits and misbehavior caused by the disorder. Its features and functionalities were designed by therapists, implementing AI algorithms to process information and make decisions in real-time to help children to be focused on their homework. This RA interacts with smart objects deployed at home, which are associated with the activity under observation (desk and chair). This solution allows therapists to receive more accurate information about the homework sessions inside the home. At the same time, remote interaction with the child is made possible (through the RA) to provide new instructions and support him/her along with the sessions. This RA is a significant evolution of an earlier version. All the improvements brought to the project by the modifications in technical and qualitative features are explained. Furthermore, the experiment and its results are presented to illustrate the clinical potential. This project shows that the RA can not only make observations with a high degree of precision like an expert (teacher/therapist) but also positively influences the homework performance of children with and without ADHD","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Assessment of a Robotic Assistant for Supporting Homework Activities of Children With ADHD,10.1109/ACCESS.2021.3093233,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
479370071,2021-07-01T00:00:00,"Abstract A real-time reverse transcription polymerase chain reaction (RT-qPCR) assay that does not require Emergency Use Authorization (EUA) reagents was tested and validated for the detection of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) during the early stages of the outbreak of coronavirus disease 2019 (COVID-19) in the Republic of Korea. Early diagnosis of COVID-19 enables timely treatment and the implementation of public health measures. We validated the sensitivity, specificity, precision, linearity, accuracy, and robustness of the RT-qPCR assay for SARS-CoV-2 detection and compared its performance with that of several EUA-approved kits. Our RT-qPCR assay was highly specific for SARS-CoV-2 as demonstrated by not amplifying 13 other viruses that cause respiratory diseases. The assay showed high linearity using a viral isolate from a patient with known COVID-19 as well as plasmids containing target SARS-CoV-2 genes as templates. The assay showed good repeatability and reproducibility with a coefficient of variation of 3%, and a SARS-CoV-2 limit of detection of 1 PFU/mL. The RT-qPCR-based assay is highly effective and can facilitate the early diagnosis of COVID-19 without the use of EUA-approved kits or reagents in the Republic of Korea","[{'title': 'Scientific Reports', 'identifiers': ['2045-2322', 'issn:2045-2322']}]",'Springer Science and Business Media LLC',Validation of real-time RT-PCR for detection of SARS-CoV-2 in the early stages of the COVID-19 outbreak in the Republic of Korea,10.1038/s41598-021-94196-3,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
480427223,2021-10-02T00:00:00,"Funding Information: This work was supported by the ITFoC project (Information Technology for the Future of Cancer) – FLAG-ERA support. Publisher Copyright: © 2021, The Author(s).Background Artificial intelligence (AI) has the potential to transform our healthcare systems significantly. New AI technologies based on machine learning approaches should play a key role in clinical decision-making in the future. However, their implementation in health care settings remains limited, mostly due to a lack of robust validation procedures. There is a need to develop reliable assessment frameworks for the clinical validation of AI. We present here an approach for assessing AI for predicting treatment response in triple-negative breast cancer (TNBC), using real-world data and molecular -omics data from clinical data warehouses and biobanks. Methods The European “ITFoC (Information Technology for the Future Of Cancer)” consortium designed a framework for the clinical validation of AI technologies for predicting treatment response in oncology. Results This framework is based on seven key steps specifying: (1) the intended use of AI, (2) the target population, (3) the timing of AI evaluation, (4) the datasets used for evaluation, (5) the procedures used for ensuring data safety (including data quality, privacy and security), (6) the metrics used for measuring performance, and (7) the procedures used to ensure that the AI is explainable. This framework forms the basis of a validation platform that we are building for the “ITFoC Challenge”. This community-wide competition will make it possible to assess and compare AI algorithms for predicting the response to TNBC treatments with external real-world datasets. Conclusions The predictive performance and safety of AI technologies must be assessed in a robust, unbiased and transparent manner before their implementation in healthcare settings. We believe that the consideration of the ITFoC consortium will contribute to the safe transfer and implementation of AI in clinical settings, in the context of precision oncology and personalized care.publishersversionPeer reviewe","[{'title': 'BMC Medical Informatics and Decision Making', 'identifiers': ['1472-6947', 'issn:1472-6947']}]",'Springer Science and Business Media LLC',A framework for validating AI in precision medicine : considerations from the European ITFoC consortium,10.1186/s12911-021-01634-3,https://core.ac.uk/download/480427223.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426867658,2020-10-01T00:00:00,"Acoustic pollution has been associated with adverse effects on the health and life expectancy of people, especially when noise exposure happens during the nighttime. With over half of the world population living in urban areas, acoustic pollution is an important concern for city administrators, especially those focused on transportation and leisure noise. Advances in sensor and network technologies made the deployment of Wireless Acoustic Sensor Networks (WASN) possible in cities, which, combined with artificial intelligence (AI), can enable smart services for their citizens. However, the creation of such services often requires structured environmental audio databases to train AI algorithms. This paper reports on an environmental audio dataset of 363 min and 53 s created in a lively area of the Barcelona city center, which targeted traffic and leisure events. This dataset, which is free and publicly available, can provide researchers with real-world acoustic data to help the development and testing of sound monitoring solutions for urban environments",,'MDPI AG',BCNDataset: Description and Analysis of an Annotated Night Urban Leisure Sound Dataset,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
490938445,2021-01-01T00:00:00,"Among various medical imaging tools, chest radiographs are the most important and widely used diagnostic tool for the detection of thoracic pathologies. Remarkable research is being carried out to propose robust automatic diagnostic tools for the detection of pathologies from the chest radiographs. Artificial Intelligence techniques have been found to give promising results in automating the field of medicine. Lot of research has been done for automatic detection of pneumothorax from chest radiographs while proposing several frameworks based on artificial intelligence techniques. Undoubtedly, several models are available for automatic diagnosis of pneumothorax, however a summarized review of the existing literature is still missing. This study summarizes the existing literature for pneumothorax detection from chest x-rays along with describing the available chest radiographs datasets. It will help the researchers to select the optimal and most effective model with respect to the real-time scenarios. The comparative analysis of the literature is provided in terms of goodness, usability, and quality along with highlighting the research gaps for further investigation. From the literature, it is evident that pneumothorax is more common in men as compared to women. Additionally, the proposed models have achieved incredible results for pneumothorax detection on selected datasets, however, the effectiveness of proposed models in real-time cases cannot be claimed, as none of the models have been implemented clinically yet. This issue can be solved by external validation of the models. Furthermore, the class-imbalance problem in most of the medical image dataset has been solved by algorithm-level-techniques. Moreover, there is need to put more effort in combined detection and localization of pneumothorax as mostly research is limited to either classification or localization of pathology. So far, best results have been achieved by deep-learning based models with Area-under-receiver-operating-characteristic-curve (AUC) of 88.87&#x0025; for classification, and Dice-similarity-coefficient (DSC) of 88.21&#x0025; for localization of pneumothorax. Thus, the outstanding abilities of deep learning techniques can be deployed for developing robust models for pneumothorax detection","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Automatic Diagnosis of Pneumothorax From Chest Radiographs: A Systematic Literature Review,10.1109/ACCESS.2021.3122998,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491003984,2021-11-01T00:00:00,"Abstract Background The aim of the present paper is to construct an emulator of a complex biological system simulator using a machine learning approach. More specifically, the simulator is a patient-specific model that integrates metabolic, nutritional, and lifestyle data to predict the metabolic and inflammatory processes underlying the development of type-2 diabetes in absence of familiarity. Given the very high incidence of type-2 diabetes, the implementation of this predictive model on mobile devices could provide a useful instrument to assess the risk of the disease for aware individuals. The high computational cost of the developed model, being a mixture of agent-based and ordinary differential equations and providing a dynamic multivariate output, makes the simulator executable only on powerful workstations but not on mobile devices. Hence the need to implement an emulator with a reduced computational cost that can be executed on mobile devices to provide real-time self-monitoring. Results Similarly to our previous work, we propose an emulator based on a machine learning algorithm but here we consider a different approach which turn out to have better performances, indeed in terms of root mean square error we have an improvement of two order magnitude. We tested the proposed emulator on samples containing different number of simulated trajectories, and it turned out that the fitted trajectories are able to predict with high accuracy the entire dynamics of the simulator output variables. We apply the emulator to control the level of inflammation while leveraging on the nutritional input. Conclusion The proposed emulator can be implemented and executed on mobile health devices to perform quick-and-easy self-monitoring assessments","[{'title': 'BMC Bioinformatics', 'identifiers': ['1471-2105', 'issn:1471-2105']}]",'Springer Science and Business Media LLC',Emulating complex simulations by machine learning methods,10.1186/s12859-021-04354-7,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491037081,2021-11-01T00:00:00,"Since consuming gutter oil does great harm to people’s health, the Food Safety Administration has always been seeking for a more effective and timely supervision. As laboratory tests consume much time, and existing field tests have excessive limitations, a more comprehensive method is in great need. This is the first time a study proposes machine learning algorithms for real-time gutter oil detection under multiple feature dimensions. Moreover, it is deployed on FPGA to be low-power and portable for actual use. Firstly, a variety of oil samples are generated by simulating the real detection environment. Next, based on previous studies, sensors are used to collect significant features that help distinguish gutter oil. Then, the acquired features are filtered and compared using a variety of classifiers. The best classification result is obtained by k-NN with an accuracy of 97.18%, and the algorithm is deployed to FPGA with no significant loss of accuracy. Power consumption is further reduced with the approximate multiplier we designed. Finally, the experimental results show that compared with all other platforms, the whole FPGA-based classification process consumes 4.77 µs and the power consumption is 65.62 mW. The dataset, source code and the 3D modeling file are all open-sourced","[{'title': 'PeerJ Computer Science', 'identifiers': ['2376-5992', 'issn:2376-5992']}]",'PeerJ',Gutter oil detection for food safety based on multi-feature machine learning and implementation on FPGA with approximate multipliers,10.7717/peerj-cs.774,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
475070866,2021-06-01T00:00:00,"Multi-class classification is one of the major challenges in machine learning and an ongoing research issue. Classification algorithms are generally binary, but they must be extended to multi-class problems for real-world application. Multi-class classification is more complex than binary classification. In binary classification, only the decision boundaries of one class are to be known, whereas in multiclass classification, several boundaries are involved. The objective of this investigation is to propose a metaheuristic, optimized, multi-level classification learning system for forecasting in civil and construction engineering. The proposed system integrates the firefly algorithm (FA), metaheuristic intelligence, decomposition approaches, the one-against-one (OAO) method, and the least squares support vector machine (LSSVM). The enhanced FA automatically fine-tunes the hyperparameters of the LSSVM to construct an optimized LSSVM classification model. Ten benchmark functions are used to evaluate the performance of the enhanced optimization algorithm. Two binary-class datasets related to geotechnical engineering, concerning seismic bumps and soil liquefaction, are then used to clarify the application of the proposed system to binary problems. Further, this investigation uses multi-class cases in civil engineering and construction management to verify the effectiveness of the model in the diagnosis of faults in steel plates, quality of water in a reservoir, and determining urban land cover. The results reveal that the system predicts faults in steel plates with an accuracy of 91.085%, the quality of water in a reservoir with an accuracy of 93.650%, and urban land cover with an accuracy of 87.274%. To demonstrate the effectiveness of the proposed system, its predictive accuracy is compared with that of a non-optimized baseline model, single multi-class classification algorithms (sequential minimal optimization (SMO), the Multiclass Classifier, the Naïve Bayes, the library support vector machine (LibSVM) and logistic regression) and prior studies. The analytical results show that the proposed system is promising project analytics software to help decision makers solve multi-level classification problems in engineering applications","[{'title': 'Applied Sciences', 'identifiers': ['2076-3417', 'issn:2076-3417']}]",'MDPI AG',Metaheuristic Optimized Multi-Level Classification Learning System for Engineering Management,10.3390/app11125533,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440978332,2020-01-01T00:00:00,"BACKGROUND:High-throughput sequencing techniques are used to analyse the diversity of the respiratory microbiota in health and disease. Although extensive data are available regarding bacterial respiratory microbiota, its fungal component remains poorly studied. This is partly due to the technical issues associated with fungal metagenomics analyses. In this study, we compared two DNA extraction protocols and two fungal amplification targets for combined bacterial and fungal targeted amplicon sequencing analyses of the respiratory microbiota. METHODS:Six sputa, randomly selected from routine samples in Mondor Hospital (Creteil, France) and treated anonymously, were tested after bacterial and fungal routine culture. Two of which were spiked with Aspergillus Fumigati and Aspergillus Nigri (105 conidia/mL). After mechanical lysis, DNA was extracted using automated QIAsymphony® extraction (AQE) or manual PowerSoil® MoBio extraction (MPE). DNA yield and purity were compared. DNA extracted from spiked sputa was subjected to (i) real-time PCR for Aspergillus DNA detection and (ii) combined metagenomic analyses targeting barcoded primers for fungal ITS1 and ITS2, and bacterial V1-V2 and V3-V4 16S regions. Amplicon libraries were prepared using MiSeq Reagent V3 kit on Illumina platform. Data were analysed using PyroMIC© and SHAMAN software, and compared with culture results. RESULTS:AQE extraction provided a higher yield of DNA (AQE/MPE DNA ratio = 4.5 [1.3-11]) in a shorter time. The yield of Aspergillus DNA detected by qPCR was similar for spiked sputa regardless of extraction protocol. The extraction moderately impacted the diversity or relative abundances of bacterial communities using targeted amplicon sequencing (2/43 taxa impacted). For fungi, the relative abundances of 4/11 major taxa were impacted and AQE results were closer to culture results. The V1-V2 or V3-V4 and ITS1 or ITS2 targets assessed similarly the diversity of bacterial and fungal major taxa, but ITS2 and V3-V4 detected more minor taxa. CONCLUSION:Our results showed the importance of DNA extraction for combined bacterial and fungal targeted metagenomics of respiratory samples. The extraction protocol can affect DNA yield and the relative abundances of few bacterial but more fungal taxa. For fungal analysis, ITS2 allowed the detection of a greater number of minor taxa compared with ITS1","[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",'Public Library of Science (PLoS)',Combined bacterial and fungal targeted amplicon sequencing of respiratory samples: Does the DNA extraction method matter?,10.1371/journal.pone.0232215,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426057424,2021-01-01T00:00:00,"Clinical trials in cancer treatment are imperative in enhancing patients\u2019 survival and quality of life outcomes. The lack of communication among professionals may produce a non-optimization of patients\u2019 accrual in clinical trials. We developed a specific platform, called \u201cDigital Research Assistant\u201d (DRA), to report real-time every available clinical trial and support clinician. Healthcare professionals involved in breast cancer working group agreed nine minimal fields of interest to preliminarily classify the characteristics of patients\u2019 records (including omic data, such as genomic mutations). A progressive web app (PWA) was developed to implement a cross-platform software that was scalable on several electronic devices to share the patients\u2019 records and clinical trials. A specialist is able to use and populate the platform. An AI algorithm helps in the matchmaking between patient\u2019s data and clinical trial\u2019s inclusion criteria to personalize patient enrollment. At the same time, an easy configuration allows the application of the DRA in different oncology working groups (from breast cancer to lung cancer). The DRA might represent a valid research tool supporting clinicians and scientists, in order to optimize the enrollment of patients in clinical trials. User Experience and Technology The acceptance of participants using the DRA is topic of a future analysis",,'MDPI AG',Development of a digital research assistant for the management of patients\u2019 enrollment in oncology clinical trials within a research hospital,10.3390/jpm11040244,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481363236,2021-11-29T00:00:00,"Tourism is one of the sectors that have been hit hard during the current Covid-19 pandemic. However, in 2021 the tourism sector is slowly rising marked by the number of tourist attractions that are starting to open to the public with the implementation of strict health protocols. However, in practice there are still many cases of violations of health protocols in various tourist attractions, ranging from the undisciplined use of masks, not keeping a distance (social distancing), and the absence of setting the ideal number of visitors during a pandemic like the current one. Managers of tourist attractions tend to ignore restrictions on the number of visitors due to the absence of an management system to run. There needs to be an application that can inform the condition of visitors to tourist attractions in real-time so that people have self-awareness of their personal health so that people can make early plans before traveling. In good governance, this application contributes to controlling the risk of Covid-19 transmission originating from crowded centers (tourist spots). The government can easily monitor the distribution of tourist visitor density in the area so that it can then be used as a basis for carrying out policies and handling in the field.
This study proposes the development of an application platform (software and hardware) monitoring the density of visitors to tourist attractions using the concept of object detection based on image processing and deep learning. The integration of hardware with web-based software will provide information on the density of visitors to tourist attractions that are easily accessible to the public so that they are expected to contribute to the handling of the current Covid-19 pandemic",,'Galaxy Science',Tourist Attractions Visitor Density Monitoring Platform,10.11594/10.11594/ijer.02.02.06,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
429956590,2021-01-01T00:00:00,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap. (C) 2020 The Author(s). Published by Elsevier Ltd",,'Elsevier BV',1D convolutional neural networks and applications : A survey,10.1016/j.ymssp.2020.107398,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
370074721,2020-01-01T00:00:00,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions. (C) 2020 The Author(s). Published by Elsevier Ltd.Funding Agencies|National Natural Science Foundation of ChinaNational Natural Science Foundation of China (NSFC) [71971030]; Shaanxi Provincial Natural Science Foundation of China [2019JM-495]; Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities [300102220203]</p",,'Elsevier BV',An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,10.1016/j.jclepro.2020.123365,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
482634030,2021-09-01T00:00:00,"Access to health data, important for population health planning, basic and clinical research and health industry utilization, remains problematic. Legislation intended to improve access to personal data across national borders has proven to be a double-edged sword, where complexity and implications from misinterpretations have paradoxically resulted in data becoming more siloed. As a result, the potential for development of health specific AI and clinical decision support tools built on real-world data have yet to be fully realized. In this perspective, we propose federated networks as a solution to enable access to diverse data sets and tackle known and emerging health problems. The perspective draws on experience from the World Economic Forum Breaking Barriers to Health Data project, the Personal Health Train and Vantage6 infrastructures, and industry insights. We first define the concept of federated networks in a healthcare context, present the value they can bring to multiple stakeholders, and discuss their establishment, operation and implementation. Challenges of federated networks in healthcare are highlighted, as well as the resulting need for and value of an independent orchestrator for their safe, sustainable and scalable implementation","[{'title': 'Frontiers in Public Health', 'identifiers': ['2296-2565', 'issn:2296-2565']}]",'Frontiers Media SA',Federated Networks for Distributed Analysis of Health Data,10.3389/fpubh.2021.712569,https://core.ac.uk/download/482634030.pdf,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
442048635,2020-01-01T00:00:00,"Roll-to-Roll (R2R) processing is a common processing method for flexible photoelectric film materials. Due to the physical properties of the materials, the change in the performance of the R2R processing equipment can easily cause deformation of the flexible film material, it is particularly important to predict the performance degradation of the processing equipment. Based on the accuracy and real-time requirements of performance degradation prediction, a PTS-FNN model for performance degradation prediction was proposed in this paper, which combines the Possibilistic C-Means (PCM) fuzzy clustering and Takagi–Sugeno Fuzzy Neural Network (TS-FNN). We also studied the PCM classification algorithm of input data of PTS-FNN model, the predecessor network of TS-FNN prediction model and the construction method of post-component network. Finally, the implementation process of PCM classification algorithm and TS-FNN prediction model were given. The R2R processing equipment health prediction experiment system was built and the PTS-FNN model experiment was carried out. The experimental results showed that the training time of PTS-FNN model was 50.37% less than the standard TS-FNN prediction model. The prediction accuracy increased by 5.48%, and the PTS-FNN had no error in the judgment of state 1 and state 4","[{'title': 'Mathematical Problems in Engineering', 'identifiers': ['issn:1024-123X', '1024-123x', '1563-5147', 'issn:1563-5147']}]",'Hindawi Limited',PTS-FNN-Based Health Prediction Method for Flexible Photoelectric Film Material Processing Equipment,10.1155/2020/9232561,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491213899,2021-01-01T00:00:00,"Fault diagnosis of rolling bearings is an essential process for improving the reliability and safety of the rotating machinery. It is always a major challenge to ensure fault diag- nosis accuracy in particular under severe working conditions. In this article, a deep adversarial domain adaptation (DADA) model is proposed for rolling bearing fault diagnosis. This model con- structs an adversarial adaptation network to solve the commonly encountered problem in numerous real applications: the source domain and the target domain are inconsistent in their distribution. First, a deep stack autoencoder (DSAE) is combined with representative feature learning for dimensionality reduction, and such a combination provides an unsupervised learning method to effectively acquire fault features. Meanwhile, domain adaptation and recognition classification are implemented using a Softmax classifier to augment classification accuracy. Second, the effects of the number of hidden layers in the stack autoencoder network, the number of neurons in each hidden layer, and the hyperparameters of the proposed fault diagnosis algorithm are analyzed. Third, comprehensive analysis is performed on real data to vali- date the performance of the proposed method; the experimental results demonstrate that the new method outperforms the existing machine learning and deep learning methods, in terms of classification accuracy and generalization ability",,'Institute of Electrical and Electronics Engineers (IEEE)',Deep adversarial domain adaptation model for bearing fault diagnosis,10.1109/TSMC.2019.2932000,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
430687431,2021-09-01T00:00:00,"Readmission of patients within a specific period after their discharge from a hospital is a cause of concern for the healthcare industry due to the cost involved. Most of the work done for predicting such readmissions using machine learning (ML) have been based on EHR, claims or authorization data from specific sources, which are mostly snapshot data at one static point in time and hence delayed. ADT being dynamic as the data is available instantaneous on occurrence of a medical event/visit adds value. Our goal is to utilize machine learning on unlabeled ADT data to identify patients who are at a high risk of being readmitted. We approached the problem in three parts. First, we labeled patient events using logical rules and finalized one of many readmission definitions that was more encapsulating of varied scenarios. Second, feature engineering was done which encapsulates the longitudinal timeline of each patient in a representative way considering all the contextual information. Third, we developed an automated machine learning pipeline which takes modeling inputs from the user, runs various models to generate readmission prediction, does a cross validation and returns the best model. We tried multiple combinations of models and cross-validation strategies and decided on a random forest model with specific hyper-parameter values and to be the most effective method to classify high risk patients. It had a test AUC-ROC of 72% which is better than quite a few industry standards. The model currently implemented in the client environment identifies the high-risk patients in real-time to care nurses who in turn take proper interventions to reduce their chances of readmission","[{'title': None, 'identifiers': ['issn:2666-8270', '2666-8270']}]",'Elsevier BV',"Using hospital Admission, Discharge &amp; Transfer (ADT) data for predicting readmissions",10.1016/j.mlwa.2021.100055,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
387851240,2020-01-01T00:00:00,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions. (C) 2020 The Author(s). Published by Elsevier Ltd.Funding Agencies|National Natural Science Foundation of ChinaNational Natural Science Foundation of China (NSFC) [71971030]; Shaanxi Provincial Natural Science Foundation of China [2019JM-495]; Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities [300102220203]</p",,'Elsevier BV',An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,10.1016/j.jclepro.2020.123365,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
483736284,2021-01-01T00:00:00,"Parkinson’s disease (PD) is a progressive neurodegenerative disorder that causes abnormal movements and an array ofother symptoms. An accurate PD diagnosis can be a challenging task as the signs and symptoms, particularly at an earlystage, can be similar to other medical conditions or the physiological changes of normal ageing. This work aims tocontribute to the PD diagnosis process by using a convolutional neural network, a type of deep neural network architecture,to differentiate between healthy controls and PD patients. Our approach focuses on discovering deviations in patient’smovements with the use of drawing tasks. In addition, this work explores which of two drawing tasks, wire cube or spiralpentagon, are more effective in the discrimination process. With 93:5% accuracy, our convolutional classifier, trained withimages of the pentagon drawing task and augmentation techniques, can be used as an objective method to discriminate PDfrom healthy controls. Our compact model has the potential to be developed into an offline real-time automated single-taskdiagnostic tool, which can be easily deployed within a clinical setting",,'Springer Science and Business Media LLC',Parkinson’s disease diagnosis using convolutional neural networks and figure-copying tasks,10.1007/s00521-021-06469-7,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426887297,2021-01-01T00:00:00,"In the field of Artificial Intelligence, Bayesian Networks (BN) are a well-known framework for reasoning under uncertain knowledge. BN have been applied in a wide range of real-world domains, such as medical diagnosis, forensic analysis, dependability assessment, risk management, etc. With respect to other types of models, BN provide relevant advantages: at the modelling level, the compact representation of the joint distribution of the system variables leads to the factorization of the set of possible states, avoiding the generation of the complete state space of the system; at the analysis level, inference algorithms can compute the probability distribution of any variable, possibly conditioned on the observation of the value (state) of other variables, so that predictive and diagnostic measures can be easily evaluated. During the years, BN have been extended in order to increase their modelling and analysis power; for instance, Dynamic Bayesian Networks and Continuous-Time Bayesian Networks take time into account, Hybrid Bayesian Networks deal with both discrete and continuous variables, Decision Networks contain decision nodes and value nodes. The aim of this Special Issue is to collect recent developments about inference algorithms, their applications to real-case studies, and their implementation in software tools",,'MDPI AG',"Editorial for the Special Issue on \u201cBayesian Networks: Inference Algorithms, Applications, and Software Tools\u201d",10.3390/a14050138,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
344303516,2020-05-01T00:00:00,"International audience18F-FDOPA PET has demonstrated its additional value during the clinical course of glioma, at initial diagnosis, for treatment planning or follow-up. The aim of the current review was to summarize current applications of 18F-FDOPA PET in gliomas and constitute, as a perspective, a first step in harmonizing clinical practices in French centers. In France, the indication for 18F-FDOPA PET is restricted to the assessment of primary brain tumor recurrence. According to the literature, this indication could be expanded to primary diagnosis and, to a lesser extent, treatment monitoring. There is a real need to harmonize standard procedures among French centers. The objective is to increase the availability of data for this rare entity of glioma and to develop multi-parametric PET analyses (static, dynamic and textural), also known as radiomics, by using artificial intelligence algorithms. For this purpose, kinetics analysis with dynamic PET acquisition should be implemented in routine practice because it has demonstrated its additional value for initial diagnosis in gliomas. Therefore, this review proposes a workflow based on acquisition and reconstruction parameters that can be implemented in each center to increase the amount of standardized 18F-FDOPA PET data in neuro-oncology imaging in France. This would help in creating a national database and developing national multi-center studies that can respond to the challenge of using multi-parametric PET in glioma",,'Elsevier BV',La TEP à la 18F-FDOPA dans les gliomes : applications actuelles et perspectives,10.1016/j.mednuc.2020.02.006,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
304935586,2018-06-30T22:22:06,"Advanced autonomous robotics space missions rely heavily on the flawless interaction of complex hardware, multiple sensors, and a mission-critical software system.  This software system consists of an operating system, device drivers, controllers, and executives; recently highly complex AI-based autonomy software have also been introduced. Prior to launch, this software has to undergo rigorous verification and validation (V&V).  Nevertheless, dormant software bugs, failing sensors, unexpected hardware-software interactions, and unanticipated environmental conditions—likely on a space exploration mission—can cause major software faults that can endanger the entire mission.

Our Integrated Software Health Management (ISWHM) system continuously monitors the hardware sensors and the software in real-time. The ISWHM uses Bayesian networks, compiled to arithmetic circuits, to model software and hardware interactions. Advanced reasoning algorithms using arithmetic circuits not only enable the ISWHM to handle large, hierarchical models that are necessary in the realm of complex autonomous systems, but also enable efficient execution on small embedded processors. The latter capability is of extreme importance for small (mobile) autonomous units with limited computational power and low telemetry bandwidth.  In this paper, we discuss the requirements of ISWHM.  As our initial demonstration platform, we use a primitive Lego rover. A Lego 
Mindstorms microcontroller is used to implement a highly simplified autonomous rover driving system, running on the OSEK real-time operating system. We demonstrate that our ISWHM, running on this small embedded microcontroller, can perform fault detection as well as on-board reasoning for advanced diagnosis and root-cause detection in real time",Software and System Health Management for Autonomous Robotics Missions,10.1184/r1/6710654.v1,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201404438,2019-01-01T00:00:00,"There is currently great interest in applying neural networks to prediction tasks in medicine. It is important for predictive models to be able to use survival data, where each patient has a known follow-up time and event/censoring indicator. This avoids information loss when training the model and enables generation of predicted survival curves. In this paper, we describe a discrete-time survival model that is designed to be used with neural networks, which we refer to as Nnet-survival. The model is trained with the maximum likelihood method using mini-batch stochastic gradient descent (SGD). The use of SGD enables rapid convergence and application to large datasets that do not fit in memory. The model is flexible, so that the baseline hazard rate and the effect of the input data on hazard probability can vary with follow-up time. It has been implemented in the Keras deep learning framework, and source code for the model and several examples is available online. We demonstrate the performance of the model on both simulated and real data and compare it to existing models Cox-nnet and Deepsurv",A scalable discrete-time survival model for neural networks,10.7717/peerj.6257,https://core.ac.uk/download/201404438.pdf,"[{'title': 'PeerJ', 'identifiers': ['issn:2167-8359', '2167-8359']}]",'PeerJ',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201123894,2018-03-01T00:00:00,"Abstract Age-related physiological changes in humans are linearly associated with age. Naturally, linear combinations of physiological measures trained to estimate chronological age have recently emerged as a practical way to quantify aging in the form of biological age. In this work, we used one-week long physical activity records from a 2003–2006 National Health and Nutrition Examination Survey (NHANES) to compare three increasingly accurate biological age models: the unsupervised Principal Components Analysis (PCA) score, a multivariate linear regression, and a state-of-the-art deep convolutional neural network (CNN). We found that the supervised approaches produce better chronological age estimations at the expense of a loss of the association between the aging acceleration and all-cause mortality. Consequently, we turned to the NHANES death register directly and introduced a novel way to train parametric proportional hazards models suitable for out-of-the-box implementation with any modern machine learning software. As a demonstration, we produced a separate deep CNN for mortality risks prediction that outperformed any of the biological age or a simple linear proportional hazards model. Altogether, our findings demonstrate the emerging potential of combined wearable sensors and deep learning technologies for applications involving continuous health risk monitoring and real-time feedback to patients and care providers",Extracting biological age from biomedical data via deep learning: too much of a good thing?,10.1038/s41598-018-23534-9,,"[{'title': 'Scientific Reports', 'identifiers': ['2045-2322', 'issn:2045-2322']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
428894003,2019-01-01T00:00:00,"1: ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations.Weak recommendation, high quality evidence. 2: ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome.Strong recommendation, high quality evidence. 3: ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis.Strong recommendation, moderate quality evidence. 4: ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (</= 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited.Weak recommendation, high quality evidence. 5: ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6: ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7: ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence",Advanced imaging for detection and differentiation of colorectal neoplasia: European Society of Gastrointestinal Endoscopy (ESGE) Guideline - Update 2019,10.1055/a-1031-7657,,,'Georg Thieme Verlag KG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
304119006,2019-01-01T00:00:00,"Prognostic Health Management (PHM) is a maintenance policy aimed at predicting the occurrence of a failure in components in order to minimize unexpected downtimes of complex systems and maximize their availability. Recent developments in condition monitoring (CM) techniques and Artificial Intelligence (AI) tools enabled the collection of a huge amount of data in real-time and its transformation into meaningful information that will support the maintenance decision-making process. The emerging Cyber-Physical Systems (CPS) technologies connect distributed physical systems with their virtual representations in the cyber computational world. The PHM assumes a key role in the implementation of CPS in manufacturing contexts, since it allows to keep CPS and its machines in proper conditions. On the other hand, CPS-based PHM provide an efficient solution to maximize availability of machines and production systems.
In this paper, evolving and unsupervised approaches for the implementation of PHM at a component level are described, which are able to process streaming data in real-time and with almost-zero prior knowledge about the monitored component. A case study from a real industrial context is presented. Different unsupervised and online anomaly detection methods are combined with evolving clustering models in order to detect anomalous behaviors in streaming vibration data and integrate the so-generated knowledge into supervised and adaptive models; then, the degradation model for each identified fault is built and the resulting RUL prediction model integrated into the online analysis. Supervised methods are applied to the same dataset, in batch mode, to validate the proposed procedure",Prognostic Health Management of Production Systems. New Proposed Approach and Experimental Evidences,10.1016/j.promfg.2020.01.333,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
352152004,2019-03-20T00:00:00,"Robotic Process Automation (RPA) is a new wave of the future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering, and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available on google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching from the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment, and onboarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor onboarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea",The future digital work force: Robotic Process Automation (Rpa),,https://core.ac.uk/download/352152004.pdf,,"Universidade de São Paulo. Faculdade de Economia, Administração e Contabilidade",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
162582664,2018-01-01T00:00:00,"International audienceThis paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature",Fast statistical model-based classification of epileptic EEG signals,,,,HAL CCSD,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
287429785,2019-01-01T00:00:00,"International audienceThe use of wireless sensor networks, which are the key ingredient in the growing Internet of Things (IoT), has surged over the past few years with a widening range of applications in the industry, healthcare, agriculture, with a special attention to monitoring and tracking, often tied with security issues. In some applications, sensors can be deployed in remote, large unpopulated areas, whereas in others, they serve to monitor confined busy spaces. In either case, clustering the sensor network’s nodes into several clusters is of fundamental benefit for obvious scalability reasons, and also for helping to devise maintenance or usage schedules that might greatly improve the network’s lifetime. In the present paper, we survey and compare popular and advanced clustering schemes and provide a detailed analysis of their performance as a function of scale, type of collected data or their heterogeneity, and noise level. The testing is performed on real sensor data provided by the UCI Machine Learning Repository, using various external validation metrics",Introducing and Comparing Recent Clustering Methods for Massive Data Management in the Internet of Things,,,,HAL CCSD,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
226908873,2019-07-08T00:00:00,"International audienceThe Industry 4.0 framework needs new intelligent approaches. Thus, the manufacturing industries more and more pay close attention to artificial intelligence (AI). For example, smart monitoring and diagnosis, real time evaluation and optimization of the whole production and raw materials management can be improved by using machine learning and big data tools. An accurate milling process implies a high quality of the obtained material surface (roughness, flatness). With the involvement of AI-based algorithms, milling process is expected to be more accurate during complex operations.In this work, a smart milling diagnosis has been developed for composite sandwich structures based on honey-comb core. The use of such material has grown considerably in recent years, especially in the aeronautic, aerospace, sporting and automotive industries. But the precise milling of such material presents many difficulties. The objective of this work is to develop a data-driven industrial surface quality diagnosis for the milling of honey-comb material, by using supervised machine learning methods. Therefore, cutting forces and workpiece material vibrations are online measured in order to predict the resulting surface flatness.The workpiece material studied in this investigation is Nomex® honeycomb cores with thin cell walls. The Nomex® honeycomb machining presents several defects related to its composite nature (uncut fiber, tearing of the walls), the cutting conditions and to the alveolar geometry of the structure which causes vibration on the different components of the cutting effort.Given the low level of cutting forces, the quality of the obtained machined surface allows to establish criteria for determining the machinability of the honeycomb structures. Nearly 40 features are calculated in time domain and frequency domain from the raw signal in steady state behavior (transient zones are not taken into account). The features are then normalized. The input parameters for each experiment are: the tool rotation speed, the cutting speed and the depth of cut. It is then necessary to make a dimensional reduction of that feature table in order to avoid overfitting and to reduce the computing time of the learning algorithm.In this work, several classification algorithms have been implemented such as : k-nearest neighbor (kNN), Decision trees (DT), Support Vector Machine (SVM). The different supervised learning algorithms have been implemented and compared. Each AI-based model has been applied to a set of features. From the prediction results, SVM algorithm seems to be the most efficient algorithm in this application",Milling diagnosis using machine learning approaches,,,,HAL CCSD,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
220589792,2019-01-01T00:00:00,"Abstract The Robotic Process Automation (RPA) is a new wave of the future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available in google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching of the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in the organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment and on boarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor on boarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea",The Future Digital Work Force: Robotic Process Automation (RPA),,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201292349,2019-02-01T00:00:00,"Monitoring animal health worldwide, especially the early detection of outbreaks of emerging pathogens, is one of the means of preventing the introduction of infectious diseases in countries (Collier et al., 2008) [3]. In this context, we developed PADI-web, a Platform for Automated extraction of animal Disease Information from the Web (Arsevska et al., 2016, 2018). PADI-web is a text-mining tool that automatically detects, categorizes and extracts disease outbreak information from Web news articles. PADI-web currently monitors the Web for five emerging animal infectious diseases, i.e., African swine fever, avian influenza including highly pathogenic and low pathogenic avian influenza, foot-and-mouth disease, bluetongue, and Schmallenberg virus infection. PADI-web collects Web news articles in near-real time through RSS feeds. Currently, PADI-web collects disease information from Google News because of its international and multiple language coverage. We implemented machine learning techniques to identify the relevant disease information in texts (i.e., location and date of an outbreak, affected hosts, their numbers and clinical signs). In order to train the model for Information Extraction (IE) from news articles, a corpus in English has been manually labeled by domain experts. This labeled corpus (Rabatel et al., 2017) is presented in this data paper",PADI-web corpus: Labeled textual data in animal health domain,10.1016/j.dib.2018.12.063,,"[{'title': 'Data in Brief', 'identifiers': ['2352-3409', 'issn:2352-3409']}]",'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
300365238,2019-01-01T00:00:00,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ""VA-assisted ML"". The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly.publishe",VIS4ML : An Ontology for Visual Analytics Assisted Machine Learning,10.1109/TVCG.2018.2864838,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
163105483,2018-01-01T00:00:00,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature",Fast statistical model-based classification of epileptic EEG signals,10.1016/j.bbe.2018.08.002,https://core.ac.uk/download/163105483.pdf,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
427382360,2019-09-19T00:00:00,"Driven by the demand to accommodate today’s growing mobile traffic, 5G is designed to

be a key enabler and a leading infrastructure provider in the information and communication technology

industry by supporting a variety of forthcoming services with diverse requirements. Considering the everincreasing

complexity of the network, and the emergence of novel use cases such as autonomous cars,

industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML)

is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential

solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised,

unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of

ML in the context of mobile and wireless communication, organizing the literature in terms of the types of

learning.We then discuss the promising approaches for how ML can contribute to supporting each target 5G

network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have

on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G),

providing future research directions for how ML can contribute to realizing B5G. This article is intended

to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of

autonomous 5G/B5G mobile and wireless communications","Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions",10.1109/ACCESS.2019.2942390,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
217804495,2018-01-01T00:00:00,"A new compact diagnostic device exploiting the integration of screen printed electrode-based immunosensors and remote-controlled IoT-WiFi acquisition board has been realized and validated for diagnosis of Celiac Disease as case of study. The immunodevice is based on chemisorption of open tissue transglutaminase enzyme on the surface of gold nanoparticles-functionalized carbon screen printed electrodes. IgA and IgG anti-tissue transglutaminase target antibodies are recognized by the immobilized bioreceptor as highly specific biomarkers related to Celiac Disease. The signal from the amperometric sensor is acquired and processed through on-purpose developed IoT-WiFi integrated board, allowing for real-time data sharing on cloud services to directly notify all users (physicians, caregivers, etc.) on device outcome. The proposed solution does not require customized hardware or software. The analytical performances of the immunosensors were optimized by experimental design, obtaining diagnostically useful limit of detection (LOD) and limit of quantitation (LOQ) values (LODIgA=3.2 AU mL−1; LODIgG=1.4 AU mL−1; LOQIgA=4.6 AU mL−1; LOQIgG =2.3 AU mL−1) as well as good intermediate precision (RSD &lt; 5%). The high discrimination capability of the IoT-Wi-Fi device between positive and negative serum control resulted to be suitable for diagnostic purposes, with outstanding statistical significance (p &lt; 0,001",An integrated IoT-Wi-Fi board for remote data acquisition and sharing from innovative immunosensors. Case of study: Diagnosis of celiac disease,10.1016/j.snb.2018.07.056,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
390006579,2018-11-28T00:00:00,"According to statistics, every fifth married couple is faced with the inability to conceive a child. Male germ cells are very vulnerable, and the growing number of cases of male infertility confirms that in today's world there are many factors that affect the activity of spermatozoa and their number. But the important thing is not so much their quantity, but quality. The spermogram is an objective method of laboratory diagnosis, which allows  to accurately assess the man’s ability to fertilize by analyzing ejaculate for a number of key parameters. Only a spermogram can answer the question of a possible male infertility and the presence of urological diseases. When constructing spermograms, it is important to determine not only the number of good spermatozoa, but also their morphology and mobility. Therefore, research and improvement of some stages of spermogramm is the purpose of the study. This article addresses the problem of classification of spermatozoa in good and bad ones, taking into account their mobility and morphology, using methods of machine learning. In order to implement the first stage of machine learning (with a teacher) in the graphic editor, educational specimens (training sample) were created. The training was implemented by three methods: the method of support vector machine, the logistic regression and the method of K - the nearest neighbors. As a result of testing, the method K - the nearest neighbors is chosen. At the testing stage, a sample of 15 different spermatozoa was used in different variations of rotation around their axis. The test sample did not contain specimens from the training sample and was formed taking into account the morphological characteristics of the spermatozoa, but did not copy them from the training sample. At the final stage of study, the program's functioning was tested on real data.По статистике, каждая пятая супружеская пара сталкивается с невозможностью зачатия ребенка. Мужские половые клетки очень уязвимы, растущее число случаев мужского бесплодия подтверждает, что в современном мире очень много факторов, которые влияют и на активность сперматозоидов и на их количество.  И важно не столько их количество, сколько качество. Спермограмма является объективным методом лабораторной диагностики, что позволяет максимально точно оценить способность к оплодотворению человека, проанализировав эякулят по ряду важнейших параметров. Только спермограмма способна ответить на вопрос о возможном мужском бесплодии и о наличии урологических заболеваний. При построении спермограммы, важно определять не только количество хороших сперматозоидов, но и их морфологию и подвижность. Поэтому исследования и совершенствования некоторых этапов спермограммы и является целью исследования. В данной статье решается задача классификации сперматозоидов на добрые и плохие, с учетом их подвижности и морфологии, с применением методов машинного обучения. Для реализации первого этапа машинного обучения (с учителем) в графическом редакторе были созданы учебные экземпляры (тренировочная выборка). Обучение было реализована тремя методами: методом опорных векторов, логистическая регрессия и метод К - ближайших соседей. По результатам тестирования выбран метод К - ближайших соседей. На этапе тестирования использовалась выборка из 15 различных сперматозоидов в различных вариациях вращения вокруг своей оси. Тестовая выборка не содержала экземпляров с тренировочной выборки и была сформирована с учетом морфологических особенностей сперматозоидов, но не копировала их с тренировочной выборки. На завершающем этапе обучения работе программы были протестированы на реальных данных.За статистикою, кожна п'ята подружня пара стикається з неможливістю зачаття дитини. Чоловічі статеві клітини дуже вразливі, зростаюче число випадків чоловічого безпліддя підтверджує, що в сучасному світі дуже багато чинників, які впливають і на активність сперматозоїдів і на їх кількість. Та важливою є  не стільки їх кількість, скільки якість. Спермограма є об'єктивним методом лабораторної діагностики, що дозволяє максимально точно оцінити здатність до запліднення чоловіка, проаналізувавши еякулят за рядом найважливіших параметрів. Тільки спермограма здатна відповісти на питання про можливе чоловіче безпліддя та про наявність урологічних захворювань. При побудові спермограми, важливо визначати не тільки кількість добрих сперматозоїдів, але й їх морфологію та рухливість. Тому дослідження та вдосконалення деяких етапів спермограми і є метою дослідження. У даній статті вирішується задача класифікації сперматозоїдів на добрі та погані, з урахуванням їх рухливості та морфології, із застосуванням методів машинного навчання. Для реалізації першого етапу машинного навчання (з вчителем) у графічному редакторі були створені навчальні екземпляри (тренувальна вибірка). Навчання було реалізована трьома методами: методом опорних векторів, логістична регресія та метод К – найближчих сусідів. За результатами тестування обрано  метод К – найближчих сусідів. На етапі тестування використовувалася вибірка з 15 різних сперматозоїдів в різних варіаціях обертання навколо своєї осі. Тестова вибірка не містила примірників з тренувальної вибірки і була сформована з урахуванням морфологічних особливостей сперматозоїдів, але не копіювала їх з тренувальної вибірки. На завершальному етапі навчання роботу програми було протестовано на реальних даних",Застосування методів машинного навчання для вирішення задачі аналізу біологічних даних,,,,"NTU ""KhPI""",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275782095,2019,"International audienceBACKGROUND: Mortality surveillance is of fundamental importance to public health surveillance. The real-time recording of death certificates, thanks to Electronic Death Registration System (EDRS), provides valuable data for reactive mortality surveillance based on medical causes of death in free-text format. Reactive mortality surveillance is based on the monitoring of mortality syndromic groups (MSGs). An MSG is a cluster of medical causes of death (pathologies, syndromes or symptoms) that meets the objectives of early detection and impact assessment of public health events. The aim of this study is to implement and measure the performance of a rule-based method and two supervised models for automatic free-text cause of death classification from death certificates in order to implement them for routine surveillance.METHOD: A rule-based method was implemented using four processing steps: standardization rules, splitting causes of death using delimiters, spelling corrections and dictionary projection. A supervised machine learning method using a linear Support Vector Machine (SVM) classifier was also implemented. Two models were produced using different features (SVM1 based solely on surface features and SVM2 combining surface features and MSGs classified by the rule-based method as feature vectors). The evaluation was conducted using an annotated subset of electronic death certificates received between 2012 and 2016. Classification performance was evaluated on seven MSGs (Influenza, Low respiratory diseases, Asphyxia/abnormal respiration, Acute respiratory disease, Sepsis, Chronic digestive diseases, and Chronic endocrine diseases).RESULTS: The rule-based method and the SVM2 model displayed a high performance with F-measures over 0.94 for all MSGs. Precision and recall were slightly higher for the rule-based method and the SVM2 model. An error-analysis shows that errors were not specific to an MSG.CONCLUSION: The high performance of the rule-based method and SVM2 model will allow us to set-up a reactive mortality surveillance system based on free-text death certificates. This surveillance will be an added-value for public health decision making",Automatic classification of free-text medical causes from death certificates for reactive mortality surveillance in France,,,,Elsevier,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201354035,2018-07-01T00:00:00,"Abstract Background The use of big data and machine learning within clinical decision support systems (CDSSs) has the potential to transform medicine through better prognosis, diagnosis and automation of tasks. Real-time application of machine learning algorithms, however, is dependent on data being present and entered prior to, or at the point of, CDSS deployment. Our aim was to determine the feasibility of automating CDSSs within electronic health records (EHRs) by investigating the timing, data categorization, and completeness of documentation of their individual components of two common Clinical Decision Rules (CDRs) in the Emergency Department. Methods The CURB-65 severity score and HEART score were randomly selected from a list of the top emergency medicine CDRs. Emergency department (ED) visits with ICD-9 codes applicable to our CDRs were eligible. The charts were reviewed to determine the categorization components of the CDRs as structured and/or unstructured, median times of documentation, portion of charts with all data components documented as structured data, portion of charts with all structured CDR components documented before ED departure. A kappa score was calculated for interrater reliability. Results The components of the CDRs were mainly documented as structured data for the CURB-65 severity score and HEART score. In the CURB-65 group, 26.8% of charts had all components documented as structured data, and 67.8% in the HEART score. Documentation of some CDR components often occurred late for both CDRs. Only 21 and 11% of patients had all CDR components documented as structured data prior to ED departure for the CURB-65 and HEART score groups, respectively. The interrater reliability for the CURB-65 score review was 0.75 and 0.65 for the HEART score. Conclusion Our study found that EHRs may be unable to automatically calculate popular CDRs—such as the CURB-65 severity score and HEART score—due to missing components and late data entry","Assessment of the Feasibility of automated, real-time clinical decision support in the emergency department using electronic health record data",10.1186/s12873-018-0170-9,,"[{'title': 'BMC Emergency Medicine', 'identifiers': ['issn:1471-227X', '1471-227x']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
395001096,2019-05-30T14:40:46,"When an infection spreads in a community, an individual's probability of becoming infected depends on both her susceptibility and exposure to the contagion through contact with others. While one often has knowledge regarding an individual's susceptibility, in many cases, whether or not an individual's contacts are contagious is unknown. We study the problem of predicting if an individual will adopt a contagion in the presence of multiple modes of infection (exposure/susceptibility) and latent neighbor influence. We present a generative probabilistic model and a variational inference method to learn the parameters of our model. Through a series of experiments on synthetic data, we measure the ability of the proposed model to identify latent spreaders, and predict the risk of infection. Applied to a real dataset of 20,000 hospital patients, we demonstrate the utility of our model in predicting the onset of a healthcare associated infection using patient room-sharing and nurse-sharing networks. Our model outperforms existing benchmarks and provides actionable insights for the design and implementation of targeted interventions to curb the spread of infection.NSF (Award IIS-1553146)NIAID of the NIH (Grant U01AI124255)NIH (Award P50-0267666-0002",Learning the probability of activation in the presence of latent spreaders,,,"[{'title': 'Proceedings of the AAAI Conference on Artificial Intelligence', 'identifiers': ['issn:2374-3468', '2374-3468']}]",'Association for the Advancement of Artificial Intelligence (AAAI)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
195779112,2018-01-01T00:00:00,"According to statistics, every fifth married couple is faced with the inability to conceive a child. Male germ cells are very vulnerable, and the growing number of cases of male infertility confirms that in today's world there are many factors that affect the activity of spermatozoa and their number. But the important thing is not so much their quantity, but quality. The spermogram is an objective method of laboratory diagnosis, which allows to accurately assess the man’s ability to fertilize by analyzing ejaculate for a number of key parameters. Only a spermogram can answer the question of a possible male infertility and the presence of urological diseases. When constructing spermograms, it is important to determine not only the number of good spermatozoa, but also their morphology and mobility. Therefore, research and improvement of some stages of spermogramm is the purpose of the study. This article addresses the problem of classification of spermatozoa in good and bad ones, taking into account their mobility and morphology, using methods of machine learning. In order to implement the first stage of machine learning (with a teacher) in the graphic editor, educational specimens (training sample) were created. The training was implemented by three methods: the method of support vector machine, the logistic regression and the method of K - the nearest neighbors. As a result of testing, the method K - the nearest neighbors is chosen. At the testing stage, a sample of 15 different spermatozoa was used in different variations of rotation around their axis. The test sample did not contain specimens from the training sample and was formed taking into account the morphological characteristics of the spermatozoa, but did not copy them from the training sample. At the final stage of study, the program's functioningwas tested on real data.За статистикою, кожна п'ята подружня пара стикається з неможливістю зачаття дитини. Чоловічі статеві клітини дуже вразливі, зростаюче число випадків чоловічого безпліддя підтверджує, що в сучасному світі дуже багато чинників, які впливають і на активність сперматозоїдів і на їх кількість. Та важливою є не стільки їх кількість, скільки якість. Спермограма є об'єктивним методом лабораторної діагностики, що дозволяє максимально точно оцінити здатність до запліднення чоловіка, проаналізувавши еякулят за рядом найважливіших параметрів. Тільки спермограма здатна відповісти на питання про можливе чоловіче безпліддя та про наявність урологічних захворювань. При побудові спермограми, важливо визначати не тільки кількість добрих сперматозоїдів, але й їх морфологію та рухливість. Тому дослідження та вдосконалення деяких етапів спермограми і є метою дослідження. У даній статті вирішується задача класифікації сперматозоїдів на добрі та погані, з урахуванням їх рухливості та морфології, із застосуванням методів машинного навчання. Для реалізації першого етапу машинного навчання (з вчителем) у графічному редакторі були створені навчальні екземпляри (тренувальна вибірка). Навчання було реалізована трьома методами: методом опорних векторів, логістична регресія та метод К - найближчих сусідів. За результатами тестування обрано метод К - найближчих сусідів. На етапі тестування використовувалася вибірка з 15 різних сперматозоїдів в різних варіаціях обертання навколо своєї осі. Тестова вибірка не містила примірників з тренувальної вибірки і була сформована з урахуванням морфологічних особливостей сперматозоїдів, але не копіювала їх з тренувальної вибірки. На завершальному етапі навчання роботу програми було протестовано на реальних даних",Застосування методів машинного навчання для вирішення задачі аналізу біологічних даних,10.20998/2522-9052.2018.3.01,,,'National Technical University Kharkiv Polytechnic Institute',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
286600336,2018-01-01T00:00:00,": Deep learning is the most recent approach to achieve artificial intelligence. Especially neural networks are used for solving many human problems - from repetitive operations to intelligent recognizing in image, sound and text processing. They are used in medicine, car industry, game industry and robotics. Business companies also try to find the way of exploitation of the latest technology despite the fact that it is the long way to the point where machines will be capable to replace the human intelligence. Authors of this paper explore possibilities of semi-supervised learning application in accounting. One of the latest deep learning algorithm is successfully used to reconstruct the journal entry key columns. The model was trained and tested on a real-world dataset so it could become base for developing the wide pallet of accounting and audit applications - as anomaly detection module of Enterprise Resource Planning (ERP) software or as a standalone application",Journal entries with deep learning model,,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
189855542,2018-01-01T00:00:00,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature",Fast statistical model-based classification of epileptic EEG signals,10.1016/j.bbe.2018.08.002,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
323090695,2019-09-01T00:00:00,"[EN] An intelligent virtual environment simulates a physical world inhabited by autonomous intelligent entities. Multi-agent systems have been usually employed to design systems of this kind. One of the key aspects in the design of intelligent virtual environments is the use of appropriate ontologies which offer a richer and more expressive representation of knowledge. In this sense, this paper proposes an ontology comprising concepts for modelling intelligent virtual environments enhanced with concepts for describing agent-based organisational features. This new ontology, called MAMbO5, is used as an input of the JaCalIVE framework, which is a toolkit for the design and implementation of agent-based intelligent virtual environments.This work was supported by the project TIN2015-65515-C4-1-R of the Spanish government. This work has been supported in part by the Croatian Science Foundation under the project number 8537.Duric, BO.; Rincon, JA.; Carrascosa Casamayor, C.; Schatten, M.; Julian Inglada, VJ. (2019). MAMbO5: A new Ontology Approach for Modelling and Managing Intelligent Virtual Environments Based on Multi-Agent Systems. Journal of Ambient Intelligence and Humanized Computing. 10(9):3629-3641. https://doi.org/10.1007/s12652-018-1089-4S36293641109Ahmed Abbas H (2015) Organization of multi-agent systems: an overview. Int J Intell Inf Syst 4(3):46 (ISSN: 2328-7675)Amiribesheli M, Bouchachia H (2017) A tailored smart home for dementia care. J Ambient Intell Hum Comput 1:1–28 (ISSN: 1868-5137, 1868-5145)Amiribesheli M, Benmansour A, Bouchachia A (2015) A review of smart homes in healthcare. J Ambient Intell Hum Comput 6(4):495–517 (ISSN: 18685145) arXiv: TSMCC.2012.2189204 [10.1109]Barella A, Ricci A, Boissier O, Carrascosa C (2012) MAM5: multi-agent model for intelligent virtual environments. In: 10th European workshop on multi-agent systems (EUMAS 2012), pp 16–30Bordel B (2017) Self-configuration in humanized cyber-physical systems. J Ambient Intell Hum Comput 8(4):485–496 (ISSN: 1868-5137)Chaib A, Boussebough I, Chaoui A (2018) Adaptive service composition in an ambient environment with a multi-agent system. J Ambient Intell Hum Comput 9(2):367–380 (ISSN: 1868-5137)Chen X (2017) A multiagent-based model for pedestrian simulation in subway stations. Simul Modell Pract Theory 71:134–148 (ISSN: 1569-190X)Chen T, Chiu MC (2018) Smart technologies for assisting the life quality of persons in a mobile environment: a review. J Ambient Intell Hum Comput 9(2):319–327 (ISSN: 1868-5137)Corkill DD, Lander SE (1998) Diversity in agent organizations. Obj Mag 8(4):41–47De Wolf T (2004) Emergence and self-organisation: a statement of similarities and differences. In: Proceedings of of the 2nd international workshop on engineering self, pp 96–110Dignum V (2009) The role of organization in agent systems. English. In: Dignum V (ed) Handbook of research on multi-agent systems. Hershey, IGI Global, pp 1–16 (ISBN: 9781605662565)Fishwick PA, Miller JA (2004) Ontologies for modeling and simulation: issues and approaches. In: Simulation conference, 2004. Proceedings of the 2004 Winter, vol 1. IEEEFurfaro A (2016) Using virtual environments for the assessment of cybersecurity issues in IoT scenarios. Simul Modell Pract Theory 0:1–12Gabriele D, Ferretti S, Ghini V (2016) Multi-level simulation of Internet of Things on smart territories. Simul Modell Pract Theory 0:1–19Hadfi R, Ito T (2016) Holonic multiagent simulation of complex adaptive systems. In: Javier B(Ed) Highlights of practical applications of scalable multi-agent systems. The PAAMS collection: international workshops of PAAMS 2016, Sevilla, Spain, June 1-3, 2016. Proceedings. Springer, Cham, pp 137-147 (ISBN: 978-3-319-39387-2)Hofmann M, Palii J, Mihelcic G (2011) Epistemic and normative aspects of ontologies in modelling and simulation. J Simul 5(3):135–146Hui TKL, Sherratt RS (2017) Towards disappearing user interfaces for ubiquitous computing: human enhancement from sixth sense to super senses. J Ambient Intell Hum Comput 8(3):449–465 (ISSN: 1868-5137, 1868-5145)Kim S, Lee I (2018) IoT device security based on proxy re-encryption. J Ambient Intell Hum Comput 9(4):1267–1273 (ISSN: 1868-5137, 1868-5145)Ko E, Kim T, Kim H (2018) Management platform of threats information in IoT environment. J Ambient Intell Hum Comput 9(4):1167–1176 (ISSN: 1868-5137, 1868-5145)Liu Y, Xu C, Zhan Y, Liu Z, Guan J, Zhang H (2017) Incentive mechanism for computation offloading using edge computing: a stackelberg game approach. Comput Netw 129:399–409Liu Y, Bashar AAE, Wu B, Wu H (2018a) Delay-constrained profit maximization for data deposition in mobile opportunistic device-to-device networks. In: 2018 IEEE 19th international symposium on” a world of wireless, mobile and multimedia networks (WoWMoM), IEEE, pp 1–10Liu Y, et al (2018b) Delay-constrained utility maximization for video ads push in mobile opportunistic D2D networks. IEEE Internet Things JLuck M, Aylett R (2000) Applying artificial intelligence to virtual reality: intelligent virtual environments. Appl Artif Intell 14(1):3–32Marcon E (2017) A multi-agent system based on reactive decision rules for solving the caregiver routing problem in home health care. Simul Modell Pract Theory 74:134–151 (ISSN: 1569-190X)Mulero R (2018) Towards ambient assisted cities using linked data and data analysis. J Ambient Intell Hum Comput 9(5):1573–1591 (ISSN: 1868-5137, 1868-5145)Okreša Đ B, Schatten M (2016) Defining ontology combining concepts of massive multi-player online role playing games and organization of large-scale multi-agent systems. In: Opatija HR (ed) 39th international convention on information and communication technology, electronics and microelectronics (MIPRO). IEEE, pp 1330–1335 (ISBN: 978-953-233-086-1)Ricci A, Viroli M, Omicini A (2007) Give agents their artifacts: the A&A approach for engineering working environments in MAS. In: Proceedings of the 6th international joint conference on autonomous agents and multiagent systems, p 150Rincon JA, Carrascosa C, Garcia E (2014) Developing intelligent virtual environments using MAM5 meta-model. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics) 8473 LNAI, pp 379–382 (ISSN: 16113349)Rincon J (2016) Extending MAM5 meta-model and JaCalIV E framework to integrate smart devices from real environments. PLoS One 11:e0149665. https://doi.org/10.1371/journal.pone.0149665Rincon J, Garcia E, Julian V, Carrascosa C (2018) The jacalive framework for mas in IVE: a case study in evolving modular robotics. Neurocomputing 275:608–617Rodriguez S (2011) Holonic multi-agent systems. In: Di Marzo SG, Gleizes MP, Karageorgos A (eds) Natural computing series, natural computing series, vol 37. Springer, Heidelberg, pp 251–279 (ISBN: 978-3-642-17347-9)Samara A, et al. (2017) Affective state detection via facial expression analysis within a human–computer interaction context. J Ambient Intell Hum Comput (ISSN: 1868-5137, 1868-5145)Schatten M (2014) Organizational architectures for large-scale multi-agent systems’ development: an initial ontology. In: Sigeru O, et al (Ed) Advances in intelligent systems and computing, vol 290, pp 261–268Schatten M (2014) Towards a formal conceptualization of organizational design techniques for large scale multi agent systems. Procedia Technol 15:577–586 (ISSN: 22120173)Sharpanskykh A, Treur J (2012) An ambient agent architecture exploiting automated cognitive analysis. J Ambient Intell Hum Comput 3(3):219–237 (ISSN: 1868-5137, 1868-5145)Weyns D, Haesevoets R, Helleboogh A (2010) The MACODO organization model for context-driven dynamic agent organizations. ACM Trans Auton Adapt Syst 5(4):1–29 (ISSN: 15564665)Yang G, Kifer M, Zhao C (2003) Flora-2: a rule-based knowledge representation and inference infrastructure for the semantic web. In: Robert M, Zahir T, Douglas CS(Ed) On the move to meaningful internet systems 2003: CoopIS, DOA, and ODBASE: OTM confederated international conferences, CoopIS, DOA, and ODBASE 2003, Catania, Sicily, Italy, November 3-7, 2003. Proceedings. Springer, Berlin, pp 671-688 (ISBN: 978-3-540-39964-3)Zehe D, et al (2015) SEMSim cloud service: large-scale urban systems simulation in the cloud. In: 58, pp 157–17",MAMbO5: A new Ontology Approach for Modelling and Managing Intelligent Virtual Environments Based on Multi-Agent Systems,10.1007/s12652-018-1089-4,http://hdl.handle.net/10251/143142,,'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
322372256,2019-01-01T00:00:00,"Timely and accurate bearing fault detection and diagnosis is important for reliable and safe operation of industrial systems. In this study, performance of a generic real-time induction bearing fault diagnosis system employing compact adaptive 1D Convolutional Neural Network (CNN) classifier is extensively studied. In the literature, although many studies have developed highly accurate algorithms for detecting bearing faults, their results have generally been limited to relatively small train/test data sets. As opposed to conventional intelligent fault diagnosis systems that usually encapsulate feature extraction, feature selection and classification as distinct blocks, the proposed system takes directly raw time-series sensor data as input and it can efficiently learn optimal features with the proper training. The main advantages of the 1D CNN based approach are 1) its compact architecture configuration (rather than the complex deep architectures) which performs only 1D convolutions making it suitable for real-time fault detection and monitoring, 2) its cost effective and practical real-time hardware implementation, 3) its ability to work without any pre-determined transformation (such as FFT or DWT), hand-crafted feature extraction and feature selection, and 4) its capability to provide efficient training of the classifier with limited size of training data set and limited number of BP iterations. Effectiveness and feasibility of the 1D CNN based fault diagnosis method is validated by applying it to two commonly used benchmark real vibration data sets and comparing the results with the other competing intelligent fault diagnosis methods.Scopu",A Generic Intelligent Bearing Fault Diagnosis System Using Compact Adaptive 1D CNN Classifier,10.1007/s11265-018-1378-3,,,'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481645603,2019-07-01T00:00:00,"Commercially available health monitors rely on rigid electronic housing coupled with aggressive adhesives and conductive gels, causing discomfort and inducing skin damage. Also, research-level skin-wearable devices, while excelling in some aspects, fall short as concept-only presentations due to the fundamental challenges of active wireless communication and integration as a single device platform. Here, an all-in-one, wireless, stretchable hybrid electronics with key capabilities for real-time physiological monitoring, automatic detection of signal abnormality via deep-learning, and a long-range wireless connectivity (up to 15 m) is introduced. The strategic integration of thin-film electronic layers with hyperelastic elastomers allows the overall device to adhere and deform naturally with the human body while maintaining the functionalities of the on-board electronics. The stretchable electrodes with optimized structures for intimate skin contact are capable of generating clinical-grade electrocardiograms and accurate analysis of heart and respiratory rates while the motion sensor assesses physical activities. Implementation of convolutional neural networks for real-time physiological classifications demonstrates the feasibility of multifaceted analysis with a high clinical relevance. Finally, in vivo demonstrations with animals and human subjects in various scenarios reveal the versatility of the device as both a health monitor and a viable research tool.ope","All-in-One, Wireless, Stretchable Hybrid Electronics for Smart, Connected, and Ambulatory Physiological Monitoring",10.1002/advs.201900939,https://core.ac.uk/download/481645603.pdf,,'Wiley',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
481637846,2020-03-01T00:00:00,"Background:  Cardiac arrest is the most serious death-related event in intensive care units (ICUs), but it is not easily predicted because of the complex and time-dependent data characteristics of intensive care patients. Given the complexity and time dependence of ICU data, deep learning-based methods are expected to provide a good foundation for developing risk prediction models based on large clinical records. 

 Objective:  This study aimed to implement a deep learning model that estimates the distribution of cardiac arrest risk probability over time based on clinical data and assesses its potential. 

 Methods:  A retrospective study of 759 ICU patients was conducted between January 2013 and July 2015. A character-level gated recurrent unit with a Weibull distribution algorithm was used to develop a real-time prediction model. Fivefold cross-validation testing (training set: 80% and validation set: 20%) determined the consistency of model accuracy. The time-dependent area under the curve (TAUC) was analyzed based on the aggregation of 5 validation sets. 

 Results:  The TAUCs of the implemented model were 0.963, 0.942, 0.917, 0.875, 0.850, 0.842, and 0.761 before cardiac arrest at 1, 8, 16, 24, 32, 40, and 48 hours, respectively. The sensitivity was between 0.846 and 0.909, and specificity was between 0.923 and 0.946. The distribution of risk between the cardiac arrest group and the non-cardiac arrest group was generally different, and the difference rapidly increased as the time left until cardiac arrest reduced. 

 Conclusions:  A deep learning model for forecasting cardiac arrest was implemented and tested by considering the cumulative and fluctuating effects of time-dependent clinical data gathered from a large medical center. This real-time prediction model is expected to improve patient's care by allowing early intervention in patients at high risk of unexpected cardiac arrests.ope",Development of a Real-Time Risk Prediction Model for In-Hospital Cardiac Arrest in Critically Ill Patients Using Deep Learning: Retrospective Study,10.2196/16349,https://core.ac.uk/download/481637846.pdf,"[{'title': 'JMIR Medical Informatics', 'identifiers': ['2291-9694', 'issn:2291-9694']}]",'JMIR Publications Inc.',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201813349,2018-09-01T00:00:00,"The clinical decision support system provides an automatic diagnosis of human diseases using machine learning techniques to analyze features of patients and classify patients according to different diseases. An analysis of real-world electronic health record (EHR) data has revealed that a patient could be diagnosed as having more than one disease simultaneously. Therefore, to suggest a list of possible diseases, the task of classifying patients is transferred into a multi-label learning task. For most multi-label learning techniques, the class imbalance that exists in EHR data may bring about performance degradation. Cross-Coupling Aggregation (COCOA) is a typical multi-label learning approach that is aimed at leveraging label correlation and exploring class imbalance. For each label, COCOA aggregates the predictive result of a binary-class imbalance classifier corresponding to this label as well as the predictive results of some multi-class imbalance classifiers corresponding to the pairs of this label and other labels. However, class imbalance may still affect a multi-class imbalance learner when the number of a coupling label is too small. To improve the performance of COCOA, a regularized ensemble approach integrated into a multi-class classification process of COCOA named as COCOA-RE is presented in this paper. To provide disease diagnosis, COCOA-RE learns from the available laboratory test reports and essential information of patients and produces a multi-label predictive model. Experiments were performed to validate the effectiveness of the proposed multi-label learning approach, and the proposed approach was implemented in a developed system prototype",Decision Support System for Medical Diagnosis Utilizing Imbalanced Clinical Data,10.3390/app8091597,,"[{'title': 'Applied Sciences', 'identifiers': ['2076-3417', 'issn:2076-3417']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201392715,2018-11-01T00:00:00,"Abstract Machine learning has become an increasingly powerful tool for solving complex problems, and its application in public health has been underutilized. The objective of this study is to test the efficacy of a machine-learned model of foodborne illness detection in a real-world setting. To this end, we built FINDER, a machine-learned model for real-time detection of foodborne illness using anonymous and aggregated web search and location data. We computed the fraction of people who visited a particular restaurant and later searched for terms indicative of food poisoning to identify potentially unsafe restaurants. We used this information to focus restaurant inspections in two cities and demonstrated that FINDER improves the accuracy of health inspections; restaurants identified by FINDER are 3.1 times as likely to be deemed unsafe during the inspection as restaurants identified by existing methods. Additionally, FINDER enables us to ascertain previously intractable epidemiological information, for example, in 38% of cases the restaurant potentially causing food poisoning was not the last one visited, which may explain the lower precision of complaint-based inspections. We found that FINDER is able to reliably identify restaurants that have an active lapse in food safety, allowing for implementation of corrective actions that would prevent the potential spread of foodborne illness",Machine-learned epidemiology: real-time detection of foodborne illness at scale,10.1038/s41746-018-0045-1,,"[{'title': 'npj Digital Medicine', 'identifiers': ['2398-6352', 'issn:2398-6352']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
390020643,2019-07-30T00:00:00,"The economic-legal analysis of the state and trends of the development of technologies of artificial intelligence (AI) has been carried out. The influence of AI on the development of society, eco­nomic effect, methods and the field of application, the state of developments in the world and Ukraine are analyzed. In the next decade, AI will become the main mar­ket trend and the best business tool. The contribution of intellectual technologies to global GDP is estimated at 15.7 trillion. dollars In the next 5-10 years, China will be the leader in the successful operation and adaptation of AI technologies. Ac­cording to analysts, the most benefit from AI technologies will be in the areas of fi­nancial services, retail and medicine.The scientific and inventive activity in the sphere of AI, the role of protection of in­tellectual property (patent and copyright), and the maintenance of the balance of com­peting interests are researched. Recently, the number of inventions based on AI has sharply increased. The leaders in the number of such inventions are American compa­nies IBM and Microsoft. This growth is due to the fact that in recent years AI has evolved from the theoretical concept into a real product that gains the world market. Since the advent of AI in the 50’s of the last century, inventors and researchers have applied for almost 340 thousand inventions based on AI (as of the end of 2016) and published more than 1.6 million scientific articles. The transport sector, including au­tonomous vehicles, is one of the sectors with the highest rates of growth in the appli­cation of AI. China has become a global leader in increasing the number of patents in the AI sphere over the past five years.By the number of companies working in the sphere of AI, Ukraine is among the three leaders among the countries of Eastern Europe. There are 57 AI companies in Ukraine and it has 11 investorsGeneralized practice of state regulation of activity in the sphere of AI in indus­trialized countries and EU countries. More and more countries are developing na­tional AI strategies. Thus, 17 countries, including Canada, China, Denmark, France, India, South Korea and Taiwan, have already announced their AI strate­gies. Some of them invest billions of dollars in this area. China, for example, has invested more than $ 10 billion in this technological trend, followed by South Korea — $ 2 billion and France — $ 1.5 billion. Governmental structures from dif­ferent countries are concerned about the need to develop relevant national strate­gies, programs and regulation of AI legislative level. Identified existing problems and suggested ways to solve them. Problems constraining the development of AI in Ukraine: the absence of a strategy for the development of AI, the domestic infra­structure for its work and the weakness of the business about existing fundamen­tal scientific developments in the field of AI, insufficient for the implementation of AI level of digitalization of companies, the lack of a high level of data work, and is also a misunderstanding of the implementation guidance in the AI company.В статье представлен экономико-правовой анализ состояния и тенденций развития технологий искусственного интеллекта (ИИ). Проанализировано влияние ИИ на развитие общества, экономический эф­фект, методы и области применения, состояние разработок в мире и Украине. Ис­следована научная и изобретательская активность в сфере ИИ, роль охраны ин­теллектуальной собственности (патентного и авторского права), обеспечение ба­ланса конкурирующих интересов. Обобщена практика государственного регулирования деятельности в сфере ИИ в промышленно развитых странах и странах ЕС. Выявлены существующие проблемы и предложены пути их решения.У статті подано економіко-правовий аналіз стану і тенденцій розвитку технологій штучного інтелекту (далі — ШІ). Проаналізовано вплив ШІ на розвиток суспільства, економічний ефект, методи і галузі застосування, стан розробок у світі та Україні. Досліджено наукову та винахідницьку активність у сфері ШІ, роль охорони інтелек­туальної власності (патентного і авторського права), забезпечення балансу конкурую­чих інтересів. Узагальнено практику державного регулювання діяльності у сфері ШІ в промислово розвинених країнах і країнах ЄС. Виявлено проблеми та запропонова­но шляхи їх вирішення",Тенденції розвитку технологій штучного інтелекту: економіко-правовий аспект (ч. 2),,,,Науково-дослідний інститут інтелектуальної власності НAПрН України,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
251203367,2018-10-11T00:00:00,"BACKGROUND: Logistic regression is a popular technique used in machine learning to construct classification models. Since the construction of such models is based on computing with large datasets, it is an appealing idea to outsource this computation to a cloud service. The privacy-sensitive nature of the input data requires appropriate privacy preserving measures before outsourcing it. Homomorphic encryption enables one to compute on encrypted data directly, without decryption and can be used to mitigate the privacy concerns raised by using a cloud service. METHODS: In this paper, we propose an algorithm (and its implementation) to train a logistic regression model on a homomorphically encrypted dataset. The core of our algorithm consists of a new iterative method that can be seen as a simplified form of the fixed Hessian method, but with a much lower multiplicative complexity. RESULTS: We test the new method on two interesting real life applications: the first application is in medicine and constructs a model to predict the probability for a patient to have cancer, given genomic data as input; the second application is in finance and the model predicts the probability of a credit card transaction to be fraudulent. The method produces accurate results for both applications, comparable to running standard algorithms on plaintext data. CONCLUSIONS: This article introduces a new simple iterative algorithm to train a logistic regression model that is tailored to be applied on a homomorphically encrypted dataset. This algorithm can be used as a privacy-preserving technique to build a binary classification model and can be applied in a wide range of problems that can be modelled with logistic regression. Our implementation results show that our method can handle the large datasets used in logistic regression training.status: publishe",Privacy-preserving logistic regression training,10.1186/s12920-018-0398-y,,"[{'title': 'BMC Medical Genomics', 'identifiers': ['1755-8794', 'issn:1755-8794']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
363911500,2020-01-01T00:00:00,"Abstract

Abdominal cancer is a widely prevalent group of tumours with a high level of mortality if diagnosed at a late stage. Although the cancer death rates have in general declined over the past few decades, the mortality from tumours in the hepatoduodenal area has significantly increased in recent years. The broader use of minimal access surgery (MAS) for diagnostics and treatment can significantly improve the survival rate and quality of life of patients after surgery. This work aims to develop and characterise an appropriate technical implementation for tissue endogenous fluorescence (TEF) and assess the efficiency of machine learning methods for the real-time diagnosis of tumours in the hepatoduodenal area. In this paper, we present the results of the machine learning approach applied to the optically guided MAS. We have elaborated tissue fluorescence approach with a fibre-optic probe to record the TEF and blood perfusion parameters during MAS in patients with cancers in the hepatoduodenal area. The measurements from the laser Doppler flowmetry (LDF) channel were used as a sensor of the tissue vitality to reduce variability in TEF data. Also, we evaluated how the blood perfusion oscillations are changed in the tumour tissue. The evaluated amplitudes of the cardiac (0.6–1.6 Hz) and respiratory (0.2–0.6 Hz) oscillations was significantly higher in intact tissues (p %lt; 0.001) compared to the cancerous ones, while the myogenic (0.2–0.06 Hz) oscillation did not demonstrate any statistically significant difference. Our results demonstrate that a fibre-optic TEF probe accompanied with ML algorithms such as k-Nearest Neighbours or AdaBoost is highly promising for the real-time in situ differentiation between cancerous and healthy tissues by detecting the information about the tissue type that is encoded in the fluorescence spectrum. Also, we show that the detection can be supplemented and enhanced by parallel collection and classification of blood perfusion oscillations",Machine learning aided photonic diagnostic system for minimally invasive optically guided surgery in the hepatoduodenal area,,,,Multidisciplinary Digital Publishing Institute,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426057075,2020-01-01T00:00:00,"Objective: Chronic diseases (CDs) are major causes of deaths, disabilities and healthcare expenditure worldwide. Interventions aimed to prevent or mitigate the impact of CDs need to be added to the traditional healthcare methods. The main purpose of the CHANGE project is the development and validation of a new Nudge theory-based Information and Communications Technology (ICT) coach system for monitoring and empowering patients with CDs. Methods: A randomized controlled clinical trial involving 200 patients with CDs will be implemented. Online assessment of demographic, psychological, neuropsychological, and behavioral outcomes will be carried out through the users' device (smartwatches). A machine learning algorithm-based profile will elaborate specific nudge-based notifications, and suggestions will be returned to par- ticipants via the CHANGE App. Expected results: real-time monitoring and tutoring will prevent/ decelerate the worsening of clinical conditions and will improve the physical and psychosocial health of patients with CDs. Moreover, the provision of tailored care actions will contribute to a more sustainable healthcare system",Nudging CHronic disease mANaGemEnt for empowering citizens: The CHANGE project,,,,"place:Aachen, Germany",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
478671759,2019-01-01T00:00:00,"The industry is moving towards maintenance strategies that consider component health, which require extensive collection and analysis of data. Condition monitoring methods that require manual feature extraction and analysis, become infeasible on an industrial scale. Machine learning algorithms can be used to automatically detect and classify faults, however, obtaining sufficient data for training is required for deep learning and other data-driven classification approaches. Data from healthy machine operation is generally available in abundance, while data from representative fault- and operating conditions is limited. This limits both development and deployment of deep learning-based CM systems on an industrial scale. This paper addresses both the challenges of automated analysis and lack of training data. A deep learning classifier architecture utilizing 1-dimensional dilated convolutions is proposed. Dilation of the convolution kernel allows for analysis of raw vibration signals while simultaneously maintaining the receptive field of the classifier enough to capture temporal patterns. The proposed method performs classification in time domain on signal segments of 1 second or shorter. With knowledge of the bearing specification, artificial vibration signals with similar characteristics as an actual bearing fault can be created. In this work, generated fault signals are combined with healthy operational data to obtain training data for a deep classifier. Parameters of the vibration model is chosen as distributions rather than fixed values. By using a range parameters in the vibration model, the classifier learns to recognize temporal features from the training data that generalize to unseen data. The effectiveness of the proposed method is demonstrated by training classifiers on generated data and testing on real signals from faulty bearings at both low and high speed. One dataset containing seeded faults and three run-to-failure tests are used for the demonstration",Simulation-driven Deep Classification of Bearing Faults from Raw Vibration Data,,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
344301156,2020-05-01T00:00:00,"International audience18F-FDOPA PET has demonstrated its additional value during the clinical course of glioma, at initial diagnosis, for treatment planning or follow-up. The aim of the current review was to summarize current applications of 18F-FDOPA PET in gliomas and constitute, as a perspective, a first step in harmonizing clinical practices in French centers. In France, the indication for 18F-FDOPA PET is restricted to the assessment of primary brain tumor recurrence. According to the literature, this indication could be expanded to primary diagnosis and, to a lesser extent, treatment monitoring. There is a real need to harmonize standard procedures among French centers. The objective is to increase the availability of data for this rare entity of glioma and to develop multi-parametric PET analyses (static, dynamic and textural), also known as radiomics, by using artificial intelligence algorithms. For this purpose, kinetics analysis with dynamic PET acquisition should be implemented in routine practice because it has demonstrated its additional value for initial diagnosis in gliomas. Therefore, this review proposes a workflow based on acquisition and reconstruction parameters that can be implemented in each center to increase the amount of standardized 18F-FDOPA PET data in neuro-oncology imaging in France. This would help in creating a national database and developing national multi-center studies that can respond to the challenge of using multi-parametric PET in glioma",Joint SFMN/ANOCEF focus on 18F-FDOPA PET imaging in glioma: Current applications and perspectives,10.1016/j.mednuc.2020.02.006,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
200859408,2019-05-01T00:00:00,"Intracranial hemorrhage is a medical emergency that requires urgent diagnosis and immediate treatment to improve patient outcome. Machine learning algorithms can be used to perform medical image classification and assist clinicians in diagnosing radiological scans. In this paper, we apply 3-dimensional convolutional neural networks (3D CNN) to classify computed tomography (CT) brain scans into normal scans (N) and abnormal scans containing subarachnoid hemorrhage (SAH), intraparenchymal hemorrhage (IPH), acute subdural hemorrhage (ASDH) and brain polytrauma hemorrhage (BPH). The dataset used consists of 399 volumetric CT brain images representing approximately 12,000 images from the National Neuroscience Institute, Singapore. We used a 3D CNN to perform both 2-class (normal versus a specific abnormal class) and 4-class classification (between normal, SAH, IPH, ASDH). We apply image thresholding at the image pre-processing step, that improves 3D CNN classification accuracy and performance by accentuating the pixel intensities that contribute most to feature discrimination. For 2-class classification, the F1 scores for various pairs of medical diagnoses ranged from 0.706 to 0.902 without thresholding. With thresholding implemented, the F1 scores improved and ranged from 0.919 to 0.952. Our results are comparable to, and in some cases, exceed the results published in other work applying 3D CNN to CT or magnetic resonance imaging (MRI) brain scan classification. This work represents a direct application of a 3D CNN to a real hospital scenario involving a medically emergent CT brain diagnosis",Image Thresholding Improves 3-Dimensional Convolutional Neural Network Diagnosis of Different Acute Brain Hemorrhages on Computed Tomography Scans,10.3390/s19092167,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
226925383,2019-10-01T00:00:00,"International audiencePurpose - Annotation of surgical activities becomes increasingly important for many recent applications such as surgical workflow analysis, surgical situation awareness, and the design of the operating room of the future, especially to train machine learning methods in order to develop intelligent assistance. Currently, annotation is mostly performed by observers with medical background and is incredibly costly and time-consuming, creating a major bottleneck for the above-mentioned technologies. In this paper, we propose a way to eliminate, or at least limit, the human intervention in the annotation process.  Methods - Meaningful information about interaction between objects is inherently available in virtual reality environments. We propose a strategy to convert automatically this information into annotations in order to provide as output individual surgical process models.  Validation - We implemented our approach through a peg-transfer task simulator and compared it to manual annotations. To assess the impact of our contribution, we studied both intra- and inter-observer variability.  Results and conclusion - In average, manual annotations took more than 12 min for 1 min of video to achieve low-level physical activity annotation, whereas automatic annotation is achieved in less than a second for the same video period. We also demonstrated that manual annotation introduced mistakes as well as intra- and inter-observer variability that our method is able to suppress due to the high precision and reproducibility",Automatic annotation of surgical activities using virtual reality environments,10.1007/s11548-019-02008-x,,,'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
302679903,2018-08-17T00:00:00,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ""VA-assisted ML"". The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly",VIS4ML: an ontology for visual analytics assisted machine learning,10.1109/TVCG.2018.2864838,,"[{'title': 'IEEE Transactions on Visualization and Computer Graphics', 'identifiers': ['1077-2626', 'issn:1077-2626']}]",'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
387851465,2020-01-01T00:00:00,"Significance: Multi-exposure laser speckle contrast imaging (MELSCI) estimates microcirculatory blood perfusion more accurately than single-exposure LSCI. However, the technique has been hampered by technical limitations due to massive data throughput requirements and nonlinear inverse search algorithms, limiting it to an offline technique where data must be postprocessed. Aim: To present an MELSCI system capable of continuous acquisition and processing of MELSCI data, enabling real-time video-rate perfusion imaging with high accuracy. Approach: The MELSCI algorithm was implemented in programmable hardware (field programmable gate array) closely interfaced to a high-speed CMOS sensor for real-time calculation. Perfusion images were estimated in real-time from the MELSCI data using an artificial neural network trained on simulated data. The MELSCI perfusion was compared to two existing single-exposure metrics both quantitatively in a controlled phantom experiment and qualitatively in vivo. Results: The MELSCI perfusion shows higher signal dynamics compared to both single-exposure metrics, both spatially and temporally where heartbeat-related variations are resolved in much greater detail. The MELSCI perfusion is less susceptible to measurement noise and is more linear with respect to laser Doppler perfusion in the phantom experiment (R-2 = 0.992). Conclusions: The presented MELSCI system allows for real-time acquisition and calculation of high-quality perfusion at 15.6 frames per second. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.Funding Agencies|Swedish Research CouncilSwedish Research Council [2014-6141]; Swedens Innovation Agency VINNOVAvia the programs Swelife and MedTech4Health [2017-01435, 2019-01522]</p",Real-time video-rate perfusion imaging using multi-exposure laser speckle contrast imaging and machine learning,10.1117/1.JBO.25.11.116007,,,'SPIE-Intl Soc Optical Eng',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
296215771,2019-07-01T00:00:00,"This article covers radar signal processing for sensing in the context of assisted living (AL). This is presented through three example applications: human activity recognition (HAR) for activities of daily living (ADL), respiratory disorders, and sleep stages (SSs) classification. The common challenge of classification is discussed within a framework of measurements/preprocessing, feature extraction, and classification algorithms for supervised learning. Then, the specific challenges of the three applications from a signal processing standpoint are detailed in their specific data processing and ad hoc classification strategies. Here, the focus is on recent trends in the field of activity recognition (multidomain, multimodal, and fusion), health-care applications based on vital signs (superresolution techniques), and comments related to outstanding challenges. Finally, this article explores challenges associated with the real-time implementation of signal processing/classification algorithms",Radar signal processing for sensing in assisted living: the challenges associated with real-time implementation of emerging algorithms,10.1109/MSP.2019.2903715,https://core.ac.uk/download/pdf/296215771.pdf,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
200849732,2019-05-01T00:00:00,"The increasing rate of diabetes is found across the planet. Therefore, the diagnosis of pre-diabetes and diabetes is important in populations with extreme diabetes risk. In this study, a machine learning technique was implemented over a data mining platform by employing Rule classifiers (PART and Decision table) to measure the accuracy and logistic regression on the classification results for forecasting the prevalence in diabetes mellitus patients suffering simultaneously from other chronic disease symptoms. The real-life data was collected in Nigeria between December 2017 and February 2019 by applying ten non-intrusive and easily available clinical variables. The results disclosed that the Rule classifiers achieved a mean accuracy of 98.75%. The error rate, precision, recall, F-measure, and Matthew&#8217;s correlation coefficient MCC were 0.02%, 0.98%, 0.98%, 0.98%, and 0.97%, respectively. The forecast decision, achieved by employing a set of 23 decision rules (DR), indicates that age, gender, glucose level, and body mass are fundamental reasons for diabetes, followed by work stress, diet, family diabetes history, physical exercise, and cardiovascular stroke history. The study validated that the proposed set of DR is practical for quick screening of diabetes mellitus patients at the initial stage without intrusive medical tests and was found to be effective in the initial diagnosis of diabetes",An Accurate Clinical Implication Assessment for Diabetes Mellitus Prevalence Based on a Study from Nigeria,10.3390/pr7050289,,"[{'title': 'Processes', 'identifiers': ['2227-9717', 'issn:2227-9717']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201304183,2019-02-01T00:00:00,"Abstract This paper presents the deep reinforcement learning (DRL) framework to estimate the optimal Dynamic Treatment Regimes from observational medical data. This framework is more flexible and adaptive for high dimensional action and state spaces than existing reinforcement learning methods to model real-life complexity in heterogeneous disease progression and treatment choices, with the goal of providing doctors and patients the data-driven personalized decision recommendations. The proposed DRL framework comprises (i) a supervised learning step to predict expert actions, and (ii) a deep reinforcement learning step to estimate the long-term value function of Dynamic Treatment Regimes. Both steps depend on deep neural networks. As a key motivational example, we have implemented the proposed framework on a data set from the Center for International Bone Marrow Transplant Research (CIBMTR) registry database, focusing on the sequence of prevention and treatments for acute and chronic graft versus host disease after transplantation. In the experimental results, we have demonstrated promising accuracy in predicting human experts’ decisions, as well as the high expected reward function in the DRL-based dynamic treatment regimes",Learning the Dynamic Treatment Regimes from Medical Registry Data through Deep Q-network,10.1038/s41598-018-37142-0,,"[{'title': 'Scientific Reports', 'identifiers': ['2045-2322', 'issn:2045-2322']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
153477433,2019-01-01T00:00:00,"Recurrent vulvovaginal candidiasis (RVVC) is a common opportunistic, mucosal fungal infection, predominantly caused by the fungus Candida albicans. Mannose-binding lectin (MBL) is an acute-phase protein that plays a key role in the innate immunity defence against infectious disease. This study was conducted to evaluate the relationship between the MBL serum level and the relative expression of MBL mRNA in RVVC using real-time PCR for the first time. The case-control study included 40 female participants suffering from RVVC and 40 healthy individuals. The MBL serum level was measured using a commercial ELISA kit. The relative mRNA expression of the MBL gene was quantified using real-time PCR. Data analysis was carried out by spss software. The MBL concentration was significantly higher in the participants suffering from RVVC compared to the control group (0.330 ng/mL vs 0.253 ng/mL). The prognostic value (P < .001) for RVVC diagnosis has been calculated. Quantitative RT-PCR results from 35 samples showed a low to significant values for mRNA levels corresponding to MBL gene expression (1-352 folds) (P < .001). The results of this study suggest that MBL plays a main role in the innate immunity and it is also affected by environmental factors and other genetic variations. Therefore, the MBL gene expression profile does not reflect precise phenotypic levels in the serum",Is mannose-binding lectin serum concentration a reliable predictor for recurrent vulvovaginal candidiasis?,10.1111/myc.12723,,,'Wiley',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
477990133,2020-12-01T00:00:00,"[EN] Identifying deceptive online reviews is a challenging tasks for Natural Language Processing (NLP). Collecting corpora for the task is difficult, because normally it is not possible to know whether reviews are genuine. A common workaround involves collecting (supposedly) truthful reviews online and adding them to a set of deceptive reviews obtained through crowdsourcing services. Models trained this way are generally successful at discriminating between `genuine¿ online reviews and the crowdsourced deceptive reviews. It has been argued that the deceptive reviews obtained via crowdsourcing are very different from real fake reviews, but the claim has never been properly tested. In this paper, we compare (false) crowdsourced reviews with a set of `real¿ fake reviews published on line. We evaluate their degree of similarity and their usefulness in training models for the detection of untrustworthy reviews. We find that the deceptive reviews collected via crowdsourcing are significantly different from the fake reviews published online. In the case of the artificially produced deceptive texts, it turns out that their domain similarity with the targets affects the models¿ performance, much more than their untruthfulness. This suggests that the use of crowdsourced datasets for opinion spam detection may not result in models applicable to the real task of detecting deceptive reviews. As an alternative method to create large-size datasets for the fake reviews detection task, we propose methods based on the probabilistic annotation of unlabeled texts, relying on the use of meta-information generally available on the e-commerce sites. Such methods are independent from the content of the reviews and allow to train reliable models for the detection of fake reviews.Leticia Cagnina thanks CONICET for the continued financial support. This work was funded by MINECO/FEDER (Grant No. SomEMBED TIN2015-71147-C2-1-P). The work of Paolo Rosso was partially funded by the MISMIS-FAKEnHATE Spanish MICINN research project (PGC2018-096212-B-C31). Massimo Poesio was in part supported by the UK Economic and Social Research Council (Grant Number ES/M010236/1).Fornaciari, T.; Cagnina, L.; Rosso, P.; Poesio, M. (2020). Fake Opinion Detection: How Similar are Crowdsourced Datasets to Real Data?. Language Resources and Evaluation. 54(4):1019-1058. https://doi.org/10.1007/s10579-020-09486-5S10191058544Baeza-Yates, R. (2018). Bias on the web. Communications of the ACM, 61(6), 54–61.Banerjee, S., & Chua, A. Y. (2014). Applauses in hotel reviews: Genuine or deceptive? In: Science and Information Conference (SAI), 2014 (pp. 938–942). New York: IEEE.Bhargava, R., Baoni, A., & Sharma, Y. (2018). Composite sequential modeling for identifying fake reviews. Journal of Intelligent Systems,. https://doi.org/10.1515/jisys-2017-0501.Bickel, P. J., & Doksum, K. A. (2015). Mathematical statistics: Basic ideas and selected topics (2nd ed., Vol. 1). Boca Raton: Chapman and Hall/CRC Press.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of Machine Learning Research, 3(Jan), 993–1022.Blum, A., & Mitchell, T. (1998). Combining labeled and unlabeled data with co-training. In: Proceedings of the eleventh annual conference on computational learning theory (pp. 92–100). New York: ACM.Cagnina, L. C., & Rosso, P. (2017). Detecting deceptive opinions: Intra and cross-domain classification using an efficient representation. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 25(Suppl. 2), 151–174. https://doi.org/10.1142/S0218488517400165.Cardoso, E. F., Silva, R. M., & Almeida, T. A. (2018). Towards automatic filtering of fake reviews. Neurocomputing, 309, 106–116. https://doi.org/10.1016/j.neucom.2018.04.074.Carpenter, B. (2008). Multilevel bayesian models of categorical data annotation. Retrieved from http://lingpipe.files.wordpress.com/2008/11/carp-bayesian-multilevel-annotation.pdf.Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20, 273–297.Costa, P. T., & MacCrae, R. R. (1992). Revised NEO personality inventory (NEO PI-R) and NEO five-factor inventory (NEO FFI): Professional manual. Psychological Assessment Resources.Dawid, A. P., & Skene, A. M. (1979). Maximum likelihood estimation of observer error-rates using the EM algorithm. Applied Statistics, 28(1), 20–28.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society Series B (Methodological), 39(1), 1–38.Elkan, C., & Noto, K. (2008). Learning classifiers from only positive and unlabeled data. In: Proceedings of the 14th ACM SIGKDD international conference on knowledge discovery and data mining (pp. 213–220). New York: ACM.Fei, G., Mukherjee, A., Liu, B., Hsu, M., Castellanos, M., & Ghosh, R. (2013). Exploiting burstiness in reviews for review spammer detection. In: Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media (Vol. 13, pp. 175–184).Feng, S., Banerjee, R., & Choi, Y. (2012). Syntactic stylometry for deception detection. In: Proceedings of the 50th annual meeting of the association for computational linguistics (Vol. 2: Short Papers, pp. 171–175). Jeju Island: Association for Computational Linguistics.Forman, G. (2003). An extensive empirical study of feature selection metrics for text classification. Journal of Machine Learning Research, 3, 1289–1305.Fornaciari, T., & Poesio, M. (2013). Automatic deception detection in Italian court cases. Artificial intelligence and law, 21(3), 303–340. https://doi.org/10.1007/s10506-013-9140-4.Fornaciari, T., & Poesio, M. (2014). Identifying fake amazon reviews as learning from crowds. In: Proceedings of the 14th conference of the European chapter of the Association for Computational Linguistics (pp. 279–287). Gothenburg: Association for Computational Linguistics. Retrieved from http://www.aclweb.org/anthology/E14-1030.Gelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models., Analytical methods for social research Cambridge: Cambridge University Press.Graves, A., Jaitly, N., & Mohamed, A. R. (2013). Hybrid speech recognition with deep bidirectional LSTM. In: 2013 IEEE workshop on automatic speech recognition and understanding (ASRU) (pp. 273–278). New York: IEEE.Hernández-Castañeda, Á., & Calvo, H. (2017). Deceptive text detection using continuous semantic space models. Intelligent Data Analysis, 21(3), 679–695.Hernández Fusilier, D., Guzmán, R., Móntes y Gomez, M., & Rosso, P. (2013). Using pu-learning to detect deceptive opinion spam. In: Proc. of the 4th workshop on computational approaches to subjectivity, sentiment and social media analysis (pp. 38–45).Hernández Fusilier, D., Montes-y Gómez, M., Rosso, P., & Cabrera, R. G. (2015). Detecting positive and negative deceptive opinions using pu-learning. Information Processing & Management, 51(4), 433–443.Hovy, D. (2016). The enemy in your own camp: How well can we detect statistically-generated fake reviews–an adversarial study. In: The 54th annual meeting of the association for computational linguistics (p 351).Jelinek, F., Lafferty, J. D., & Mercer, R. L. (1992). Basic methods of probabilistic context free grammars. Speech recognition and understanding (pp. 345–360). New York: Springer.Jindal, N., & Liu, B. (2008). Opinion spam and analysis. In: Proceedings of the 2008 international conference on web search and data mining (pp. 219–230). New York: ACM.Karatzoglou, A., Meyer, D., & Hornik, K. (2006). Support vector machines in R. Journal of Statistical Software, 15(9), 1–28.Kim, S., Lee, S., Park, D., & Kang, J. (2017). Constructing and evaluating a novel crowdsourcing-based paraphrased opinion spam dataset. In: Proceedings of the 26th international conference on world wide web (pp. 827–836). Geneva: International World Wide Web Conferences Steering Committee.Li, F., Huang, M., Yang, Y., & Zhu, X. (2011). Learning to identify review spam. IJCAI Proceedings-International Joint Conference on Artificial Intelligence, 22(3), 2488–2493.Li, H., Chen, Z., Liu, B., Wei, X., & Shao, J. (2014a). Spotting fake reviews via collective positive-unlabeled learning. In: 2014 IEEE international conference on data mining (ICDM) (pp. 899–904). New York: IEEE.Li, H., Fei, G., Wang, S., Liu, B., Shao, W., Mukherjee, A., & Shao, J. (2017). Bimodal distribution and co-bursting in review spam detection. In: Proceedings of the 26th international conference on world wide web (pp. 1063–1072). Geneva: International World Wide Web Conferences Steering Committee.Li, H., Liu, B., Mukherjee, A., & Shao, J. (2014b). Spotting fake reviews using positive-unlabeled learning. Computación y Sistemas, 18(3), 467–475.Li, J., Ott, M., Cardie, C., & Hovy, E. H. (2014c). Towards a general rule for identifying deceptive opinion spam. In: ACL (Vol. 1, pp. 1566–1576).Lin, C. H., Hsu, P. Y., Cheng, M. S., Lei, H. T., & Hsu, M. C. (2017). Identifying deceptive review comments with rumor and lie theories. In: International conference in swarm intelligence (pp. 412–420). New York: Springer.Liu, B., Dai, Y., Li, X., Lee, W. S., & Yu, P. S. (2003). Building text classifiers using positive and unlabeled examples. In: Third IEEE international conference on data mining (pp. 179–186). New York: IEEE.Liu, B., Lee, W. S., Yu, P. S., & Li, X. (2002). Partially supervised classification of text documents. ICML, 2, 387–394.Martens, D., & Maalej, W. (2019). Towards understanding and detecting fake reviews in app stores. Empirical Software Engineering,. https://doi.org/10.1007/s10664-019-09706-9.Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:13013781.Mukherjee, A., Kumar, A., Liu, B., Wang, J., Hsu, M., Castellanos, M., & Ghosh, R. (2013a). Spotting opinion spammers using behavioral footprints. In: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 632–640) New York: ACM.Mukherjee, A., Venkataraman, V., Liu, B., & Glance, N. S. (2013b). What yelp fake review filter might be doing? In: Proceedings of the seventh international AAAI conference on weblogs and social media.Negri, M., Bentivogli, L., Mehdad, Y., Giampiccolo, D., & Marchetti, A. (2011). Divide and conquer: Crowdsourcing the creation of cross-lingual textual entailment corpora. In: Proceedings of the conference on empirical methods in natural language processing (pp. 670–679). Stroudsburg: Association for Computational Linguistics.Ott, M., Cardie, C., & Hancock, J. T. (2013). Negative deceptive opinion spam. In: Proceedings of the 2013 conference of the North American chapter of the association for computational linguistics: human language technologies (pp. 497–501).Ott, M., Choi, Y., Cardie, C., & Hancock, J. (2011). Finding deceptive opinion spam by any stretch of the imagination. In: Proceedings of the 49th Annual meeting of the association for computational linguistics: human language technologies (pp. 309–319). Portland, Oregon: Association for Computational Linguistics.Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001). Linguistic inquiry and word count (LIWC): LIWC2001. Mahwah: Lawrence Erlbaum Associates.Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global vectors for word representation. In: Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532–1543).Raykar, V. C., Yu, S., Zhao, L. H., Valadez, G. H., Florin, C., Bogoni, L., et al. (2010). Learning from crowds. Journal of Machine Learning Research, 11, 1297–1322.Ren, Y., & Ji, D. (2017). Neural networks for deceptive opinion spam detection: An empirical study. Information Sciences, 385, 213–224.Rout, J. K., Dalmia, A., Choo, K. K. R., Bakshi, S., & Jena, S. K. (2017). Revisiting semi-supervised learning for online deceptive review detection. IEEE Access, 5(1), 1319–1327.Saini, M., & Sharan, A. (2017). Ensemble learning to find deceptive reviews using personality traits and reviews specific features. Journal of Digital Information Management, 12(2), 84–94.Salloum, W., Edwards, E., Ghaffarzadegan, S., Suendermann-Oeft, D., & Miller, M. (2017). Crowdsourced continuous improvement of medical speech recognition. In: The AAAI-17 workshop on crowdsourcing, deep learning, and artificial intelligence agents.Schmid, H. (1994). Probabilistic part-of-speech tagging using decision trees. In: Proceedings of international conference on new methods in language processing. Retrieved from http://www.ims.uni-stuttgart.de/ftp/pub/corpora/tree-tagger1.pdf.Shehnepoor, S., Salehi, M., Farahbakhsh, R., & Crespi, N. (2017). Netspam: A network-based spam detection framework for reviews in online social media. IEEE Transactions on Information Forensics and Security, 12(7), 1585–1595.Skeppstedt, M., Peldszus, A., & Stede, M. (2018). More or less controlled elicitation of argumentative text: Enlarging a microtext corpus via crowdsourcing. In: Proceedings of the 5th workshop on argument mining (pp. 155–163).Strapparava, C., & Mihalcea, R. (2009). The lie detector: Explorations in the automatic recognition of deceptive language. In: Proceedings of the 47th annual meeting of the association for computational linguistics and the 4th international joint conference on natural language processing.Streitfeld, D. (August $$25{{\rm th}}$$, 2012). The best book reviews money can buy. The New York Times.Whitehill, J., Wu, T., Bergsma, F., Movellan, J. R., & Ruvolo, P. L. (2009). Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. Advances in neural information processing systems (pp. 2035–2043). Cambridge: MIT Press.Xie, S., Wang, G., Lin, S., & Yu, P. S. (2012). Review spam detection via temporal pattern discovery. In: Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining (pp 823–831). New York: ACM.Yang, Y., & Liu, X. (1999). A re-examination of text categorization methods. In: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’99 (pp. 42–49). New York: ACM.Zhang, W., Bu, C., Yoshida, T., & Zhang, S. (2016). Cospa: A co-training approach for spam review identification with support vector machine. Information, 7(1), 12.Zhang, W., Du, Y., Yoshida, T., & Wang, Q. (2018). DRI-RCNN: An approach to deceptive review identification using recurrent convolutional neural network. Information Processing & Management, 54(4), 576–592.Zhou, L., Shi, Y., & Zhang, D. (2008). A Statistical Language Modeling Approach to Online Deception Detection. IEEE Transactions on Knowledge and Data Engineering, 20(8), 1077–1081",Fake Opinion Detection: How Similar are Crowdsourced Datasets to Real Data?,10.1007/s10579-020-09486-5,https://riunet.upv.es/bitstream/10251/171117/1/FornaciariCagninaRosso%20-%20Fake%20Opinion%20Detection%20How%20Similar%20are%20Crowdsourced%20Datasets%20to%20Real%20Data.pdf,,'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
370074707,2020-01-01T00:00:00,"The high capacity of neural networks allows fitting models to data with high precision, but makes generalization to unseen data a challenge. If a domain shift exists, i.e. differences in image statistics between training and test data, care needs to be taken to ensure reliable deployment in real-world scenarios. In digital pathology, domain shift can be manifested in differences between whole-slide images, introduced by for example differences in acquisition pipeline - between medical centers or over time. In order to harness the great potential presented by deep learning in histopathology, and ensure consistent model behavior, we need a deeper understanding of domain shift and its consequences, such that a model's predictions on new data can be trusted. This work focuses on the internal representation learned by trained convolutional neural networks, and shows how this can be used to formulate a novel measure - the representation shift - for quantifying the magnitude of model specific domain shift. We perform a study on domain shift in tumor classification of hematoxylin and eosin stained images, by considering different datasets, models, and techniques for preparing data in order to reduce the domain shift. The results show how the proposed measure has a high correlation with drop in performance when testing a model across a large number of different types of domain shifts, and how it improves on existing techniques for measuring data shift and uncertainty. The proposed measure can reveal how sensitive a model is to domain variations, and can be used to detect new data that a model will have problems generalizing to. We see techniques for measuring, understanding and overcoming the domain shift as a crucial step towards reliable use of deep learning in the future clinical pathology applications",Measuring Domain Shift for Deep Learning in Histopathology,10.1109/JBHI.2020.3032060,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
196260400,2019-01-01T00:00:00,"Cardiovascular diseases (CVD) are the leading causes of death worldwide. Cardiac troponin I (cTnI) is a cardiac biomarker exploited extensively for the early diagnosis of acute myocardial infarction (AMI). We report a highly sensitive microfluidic biosensor for electrochemical detection of human cTnI in real patient samples. In this device, a patterned mesoporous nickel vanadate hollow-nanospheres modified chitosan (Ch-Ni3V2O8) was integrated with microfluidic structure. With excellent redox activity and biocompatibility, larger surface, tunable oxidation states (V5+, V4+, and V3+), the Ch-Ni3V2O8 matrix was used to functionalize the cardiac antibodies of troponin I (cAb) and amplify the electrochemical readouts. This device offered a high sensitivity of 38.88 µA/ng mL-1/cm2 for a wide range of cTnI concentration (0.005‒100 ng mL‒1). A low limit-of-detection of 5 pg mL‒1 and high stability, high reproducibility and good selectivity were achieved due to integration of microfluidic elements with hollow-nanosphere Ch-Ni3V2O8. This microfluidic device can be implemented to detect B-type natriuretic peptide, myoglobin, cardiac troponin C, and cardiac troponin T by functionalizing the specific antibody recognition elements and used for real point-of-care application in bio-medicine",Hollow-nanospheres-based microfluidic biosensors for biomonitoring of cardiac troponin I,10.1039/C9TB00126C,,,'Royal Society of Chemistry (RSC)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
491201752,2020-01-01T00:00:00,"An image is worth a thousand words; hence, a face image illustrates extensive details about the specification, gender, age, and emotional states of mind. Facial expressions play an important role in community-based interactions and are often used in the behavioral analysis of emotions. Recognition of automatic facial expressions from a facial image is a challenging task in the computer vision community and admits a large set of applications, such as driver safety, human-computer interactions, health care, behavioral science, video conferencing, cognitive science, and others. In this work, a deep-learning-based scheme is proposed for identifying the facial expression of a person. The proposed method consists of two parts. The former one finds out local features from face images using a local gravitational force descriptor, while, in the latter part, the descriptor is fed into a novel deep convolution neural network (DCNN) model. The proposed DCNN has two branches. The first branch explores geometric features, such as edges, curves, and lines, whereas holistic features are extracted by the second branch. Finally, the score-level fusion technique is adopted to compute the final classification score. The proposed method along with 25 state-of-the-art methods is implemented on five benchmark available databases, namely, Facial Expression Recognition 2013, Japanese Female Facial Expressions, Extended CohnKanade, Karolinska Directed Emotional Faces, and Real-world Affective Faces. The databases consist of seven basic emotions: neutral, happiness, anger, sadness, fear, disgust, and surprise. The proposed method is compared with existing approaches using four evaluation metrics, namely, accuracy, precision, recall, and f1-score. The obtained results demonstrate that the proposed method outperforms all state-of-the-art methods on all the databases",Facial Expression Recognition Using Local Gravitational Force Descriptor-Based Deep Convolution Neural Networks,,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
346563008,2019-01-01T00:00:00,"OBJECTIVES:Artificial Intelligence (AI) offers significant potential for improving healthcare. This paper discusses how an ""open science"" approach to AI tool development, data sharing, education, and research can support the clinical adoption of AI systems. METHOD:In response to the call for participation for the 2019 International Medical Informatics Association (IMIA) Yearbook theme issue on AI in healthcare, the IMIA Open Source Working Group conducted a rapid review of recent literature relating to open science and AI in healthcare and discussed how an open science approach could help overcome concerns about the adoption of new AI technology in healthcare settings. RESULTS:The recent literature reveals that open science approaches to AI system development are well established. The ecosystem of software development, data sharing, education, and research in the AI community has, in general, adopted an open science ethos that has driven much of the recent innovation and adoption of new AI techniques. However, within the healthcare domain, adoption may be inhibited by the use of ""black-box"" AI systems, where only the inputs and outputs of those systems are understood, and clinical effectiveness and implementation studies are missing. CONCLUSIONS:As AI-based data analysis and clinical decision support systems begin to be implemented in healthcare systems around the world, further openness of clinical effectiveness and mechanisms of action may be required by safety-conscious healthcare policy-makers to ensure they are clinically effective in real world use",An Open Science Approach to Artificial Intelligence in Healthcare,,,,Thieme Publishing,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
333581042,2020-01-01T00:00:00,"Background: The detection of infectious diseases through the analysis of free text on electronic health reports (EHRs) can provide prompt and accurate background information for the implementation of preventative measures, such as advertising and monitoring the effectiveness of vaccination campaigns. Objective: The purpose of this paper is to compare machine learning techniques in their application to EHR analysis for disease detection. Methods: The Pedianet database was used as a data source for a real-world scenario on the identification of cases of varicella. The models' training and test sets were based on two different Italian regions' (Veneto and Sicilia) data sets of 7631 patients and 1,230,355 records, and 2347 patients and 569,926 records, respectively, for whom a gold standard of varicella diagnosis was available. Elastic-net regularized generalized linear model (GLMNet), maximum entropy (MAXENT), and LogitBoost (boosting) algorithms were implemented in a supervised environment and 5-fold cross-validated. The document-term matrix generated by the training set involves a dictionary of 1,871,532 tokens. The analysis was conducted on a subset of 29,096 tokens, corresponding to a matrix with no more than a 99% sparsity ratio. Results: The highest predictive values were achieved through boosting (positive predicative value [PPV] 63.1, 95% CI 42.7-83.5 and negative predicative value [NPV] 98.8, 95% CI 98.3-99.3). GLMNet delivered superior predictive capability compared to MAXENT (PPV 24.5% and NPV 98.3% vs PPV 11.0% and NPV 98.0%). MAXENT and GLMNet predictions weakly agree with each other (agreement coefficient 1 [AC1]=0.60, 95% CI 0.58-0.62), as well as with LogitBoost (MAXENT: AC1=0.64, 95% CI 0.63-0.66 and GLMNet: AC1=0.53, 95% CI 0.51-0.55). Conclusions: Boosting has demonstrated promising performance in large-scale EHR-based infectious disease identification",Use of machine learning techniques for case-detection of varicella zoster using routinely collected textual ambulatory records: Pilot observational study,10.2196/14330,,,'JMIR Publications Inc.',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
212253632,2018-01-01T00:00:00,"Running has a positive impact on human health and is an accessible sport for most people. There is high demand for tracking running performance and progress for amateurs and professionals alike. The parameters velocity and distance are thereby of main interest. In this work, we evaluate the accuracy of four algorithms, which calculate the stride velocity and stride length during running using data of an inertial measurement unit (IMU) placed in the midsole of a running shoe. The four algorithms are based on stride time, foot acceleration, foot trajectory estimation, and deep learning, respectively. They are compared using two studies: a laboratory-based study comprising 2377 strides from 27 subjects with 3D motion tracking as a reference and a field study comprising 12 subjects performing a 3.2-km run in a real-world setup. The results show that the foot trajectory estimation algorithm performs best, achieving a mean error of 0.032 ± 0.274 m/s for the velocity estimation and 0.022 ± 0.157 m for the stride length. An interesting alternative for systems with a low energy budget is the acceleration-based approach. Our results support the implementation decision for running velocity and distance tracking using IMUs embedded in the sole of a running shoe",Comparison of Different Algorithms for Calculating Velocity and Stride Length in Running Using Inertial Measurement Units,10.3390/s18124194,,,'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
429086405,2019-01-01T00:00:00,"1:  ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations.Weak recommendation, high quality evidence. 2:  ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome.Strong recommendation, high quality evidence. 3:  ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis.Strong recommendation, moderate quality evidence. 4:  ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (≤ 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited.Weak recommendation, high quality evidence. 5:  ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6:  ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7:  ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence",Advanced imaging for detection and differentiation of colorectal neoplasia: European Society of Gastrointestinal Endoscopy (ESGE) Guideline - Update 2019,10.1055/a-1031-7657,,,'Georg Thieme Verlag KG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
478373242,2019-07-16T00:00:00,"Artificial Intelligence (AI) has wide range of applications in all areas and is gaining the understanding of the society as necessity instead of luxury. AI start ups are working to improve the quality of social interactions (social good), Education, Agriculture, manufacturing, health and medicine and public services. Hence the cost of not developing AI or developing it late is enormous. Despite the opportunities AI technologies may offer, there is a real risk that without thoughtful intervention it may in fact exacerbate structural, economic, social, and political imbalances, and further reinforce entrenched inequalities. For regulators and policymakers around the world, uneven access to technology remains a major concern because of its potential impacts on social and economic inequality. The author has conducted an exploratory research by reviewing related literatures on AI opportunities and challenges from experiences of the developed world and provided a discussion to identify the potential opportunities and expected challenges for AI adoption and implementation in Ethiopia. Finally the author has recommended what should be done.Keywords: Artificial, Intelligence,, Exploratory, Research, Skills, Infrastructure, Data, Privac",Artificial intelligence for Ethiopia: opportunities and challenges,10.4314/ict.v16i1.,,,'African Journals Online (AJOL)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
395142912,2019-11-01T00:00:00,"[EN] Falls represent a major public health risk worldwide for the elderly people. A fall not assisted in time can cause functional impairment in an elderly and a significant decrease in his mobility, independence, and life quality. In this sense, we propose IoTE-Fall system, an intelligent system for detecting falls of elderly people in indoor environments that takes advantages of the Internet of Thing and the ensemble machine learning algorithm. IoTE-Fall system employs a 3D-axis accelerometer embedded into a 6LowPAN wearable device capable of capturing in real time the data of the movements of elderly volunteers. To provide high efficiency in fall detection, in this paper, four machine learning algorithms (classifiers): decision trees, ensemble, logistic regression, and Deepnets are evaluated in terms of AUC ROC, training time and testing time. The acceleration readings are processed and analyzed at the edge of the network using an ensemble-based predictor model that is identified as the most suitable predictor for fall detection. The experiment results from collection data, interoperability services, data processing, data analysis, alert emergency service, and cloud services show that our system achieves accuracy, precision, sensitivity, and specificity above 94%.Research presented in this article has been partially funded by Horizon 2020 European Project grant INTER-IoT no. 687283, ACTIVAGE project under grant agreement no. 732679, the Escuela Politecnica Nacional, Ecuador, and Secretaria de Educacion Superior Ciencia, Tecnologia e Innovacion (SENESCYT), Ecuador.Yacchirema, D.; Suárez De Puga, J.; Palau Salvador, CE.; Esteve Domingo, M. (2019). Fall detection system for elderly people using IoT and ensemble machine learning algorithm. Personal and Ubiquitous Computing. 23(5-6):801-817. https://doi.org/10.1007/s00779-018-01196-8S801817235-6He W, Goodkind D, Kowal P (2016) U.S. Census Bureau, International Population Reports, P95/16-1, An Aging World: 2015. U.S. Government Publishing Office, Washington, DCBousquet J, Kuh D, Bewick M, Standberg T, Farrell J, Pengelly R, Joel ME, Rodriguez Mañas L, Mercier J, Bringer J, Camuzat T, Bourret R, Bedbrook A, Kowalski ML, Samolinski B, Bonini S, Brayne C, Michel JP, Venne J, Viriot-Durandal P, Alonso J, Avignon A, Ben-Shlomo Y, Bousquet PJ, Combe B, Cooper R, Hardy R, Iaccarino G, Keil T, Kesse-Guyot E, Momas I, Ritchie K, Robine JM, Thijs C, Tischer C, Vellas B, Zaidi A, Alonso F, Andersen Ranberg K, Andreeva V, Ankri J, Arnavielhe S, Arshad H, Augé P, Berr C, Bertone P, Blain H, Blasimme A, Buijs GJ, Caimmi D, Carriazo A, Cesario A, Coletta J, Cosco T, Criton M, Cuisinier F, Demoly P, Fernandez-Nocelo S, Fougère B, Garcia-Aymerich J, Goldberg M, Guldemond N, Gutter Z, Harman D, Hendry A, Heve D, Illario M, Jeande C, Krauss-Etschmann S, Krys O, Kula D, Laune D, Lehmann S, Maier D, Malva J, Matignon P, Melen E, Mercier G, Moda G, Nizinkska A, Nogues M, O’Neill M, Pelissier JY, Poethig D, Porta D, Postma D, Puisieux F, Richards M, Robalo-Cordeiro C, Romano V, Roubille F, Schulz H, Scott A, Senesse P, Slagter S, Smit HA, Somekh D, Stafford M, Suanzes J, Todo-Bom A, Touchon J, Traver-Salcedo V, van Beurden M, Varraso R, Vergara I, Villalba-Mora E, Wilson N, Wouters E, Zins M (2015) Operational definition of active and healthy ageing (AHA): a conceptual framework. J Nutr Health Aging 19(9):955–960Yacchirema DC, Sarabia-Jácome D, Palau CE, Esteve M (2018) A Smart System for sleep monitoring by integrating IoT with big data analytics. IEEE Access, p 1Robie K (2010) Falls in older people: risk factors and strategies for prevention. JAMA 304(17):1958–1959Jrad RBN, Ahmed MD, Sundaram D (2014) Insider Action Design Research a multi-methodological Information Systems research approach. 2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS). Marrakech, pp 1–12. https://doi.org/10.1109/RCIS.2014.6861053Chaccour K, Darazi R, El Hassani AH, Andrès E (2017) From fall detection to fall prevention: a generic classification of fall-related systems. IEEE Sensors J 17(3):812–822Min W, Cui H, Rao H, Li Z, Yao L (2018) Detection of human falls on furniture using scene analysis based on deep learning and activity characteristics. IEEE Access 6:9324–9335Ma X, Wang H, Xue B, Zhou M, Ji B, Li Y (2014) Depth-based human fall detection via shape features and improved extreme learning machine. IEEE J Biomed Heal Inform 18(6):1915–1922Yang L, Ren Y, Zhang W (2016) 3D depth image analysis for indoor fall detection of elderly people. Digit Commun Netw 2(1):24–34Mastorakis G, Makris D (2014) Fall detection system using Kinect’s infrared sensor. J Real-Time Image Process 9(4):635–646Kwolek B, Kepski M (2014) Human fall detection on embedded platform using depth maps and wireless accelerometer. Comput Methods Prog Biomed 117(3):489–501Wang Y, Wu K, Ni LM (2017) WiFall: device-free fall detection by wireless networks. IEEE Trans Mob Comput 16(2):581–594Sehairi K, Chouireb F, Meunier J (2018) Elderly fall detection system based on multiple shape features and motion analysis. 2018 International Conference on Intelligent Systems and Computer Vision (ISCV). Fez, pp 1–8. https://doi.org/10.1109/ISACV.2018.8354084Álvarez de la Concepción MÁ, Soria Morillo LM, Álvarez García JA, González-Abril L (2017) Mobile activity recognition and fall detection system for elderly people using Ameva algorithm. Pervasive Mob Comput 34:3–13Fortino G, Gravina R (2015) Fall-MobileGuard: a smart real-time fall detection system. In: Proceedings of the 10th EAI International Conference on Body Area Networks (BodyNets '15). ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering). ICST, Brussels, Belgium, pp 44–50. https://doi.org/10.4108/eai.28-9-2015.2261462Aguiar B, Rocha T, Silva J, Sousa I (2014) Accelerometer-based fall detection for smartphones. 2014 IEEE International Symposium on Medical Measurements and Applications (MeMeA). Lisboa, pp 1–6. https://doi.org/10.1109/MeMeA.2014.6860110Kau L, Chen C (2015) A smart phone-based pocket fall accident detection, positioning, and rescue system. IEEE J Biomed Heal Inform 19(1):44–56He J, Bai S, Wang X (2017) An Unobtrusive Fall Detection and Alerting System Based on Kalman Filter and Bayes Network Classifier. Sensors 17:1393. https://doi.org/10.3390/s17061393Santoyo-Ramón JA, Casilari E, Cano-García JM (2018) Analysis of a Smartphone-Based Architecture with Multiple Mobility Sensors for Fall Detection with Supervised Learning. Sensors 18:1155. https://doi.org/10.3390/s18041155Mao A, Ma X, He Y, Luo J (2017) Highly Portable, Sensor-Based System for Human Fall Monitoring. Sensors 17:2096. https://doi.org/10.3390/s17092096Casilari E, Oviedo-Jiménez MA (2015) Automatic fall detection system based on the combined use of a smartphone and a smartwatch. PLoS One 10(11):e0140929Dias PVGF, Costa EDM, Tcheou MP, Lovisolo L (2016) Fall detection monitoring system with position detection for elderly at indoor environments under supervision. 2016 8th IEEE Latin-American Conference on Communications (LATINCOM). Medellin, pp. 1–6. https://doi.org/10.1109/LATINCOM.2016.7811576Phu PT, Hai NT, Tam NT (2015) A Threshold Algorithm in a Fall Alert System for Elderly People. In: Toi V, Lien Phuong T (eds) 5th International Conference on Biomedical Engineering in Vietnam. IFMBE Proceedings, vol 46. Springer, Cham. https://doi.org/10.1007/978-3-319-11776-8_85 . ISBN:978-3-319-11775-1Santiago J, Cotto E, Jaimes LG, Vergara-Laurens, I (2017) Fall detection system for the elderly. 2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC). Las Vegas, NV, pp 1–4. https://doi.org/10.1109/CCWC.2017.7868363Malheiros L, Nze GDA, Cardoso LX (2017) Fall detection system and body positioning with heart rate monitoring. IEEE Lat Am Trans 15(6):1021–1026Ethem Alpaydin (2010) Introduction to Machine Learning, 2nd edn. The MIT PressMezghani N, Ouakrim Y, Islam MR, Yared R, Abdulrazak B (2017) Context aware adaptable approach for fall detection bases on smart textile. 2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI). Orlando, FL, pp 473–476. https://doi.org/10.1109/BHI.2017.7897308Pierleoni P, Belli A, Palma L, Pellegrini M, Pernini L, Valenti S (2015) A high reliability wearable device for elderly fall detection. IEEE Sensors J 15(8):4544–4553Aziz O, Musngi M, Park EJ, Mori G, Robinovitch SN (2017) A comparison of accuracy of fall detection algorithms (threshold-based vs. machine learning) using waist-mounted tri-axial accelerometer signals from a comprehensive set of falls and non-fall trials. Med Biol Eng Comput 55(1):45–55Nguyen LP, Saleh M, Le Bouquin Jeannès R (2018) An Efficient Design of a Machine Learning-Based Elderly Fall Detector. In: Ahmed M, Begum S, Fasquel JB (eds) Internet of Things (IoT) Technologies for HealthCare. HealthyIoT 2017. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, vol 225. Springer, ChamÖzdemir TA, Barshan B (2014) Detecting falls with wearable sensors using machine learning techniques. Sensors 14(6):10691–10708Tong L, Song Q, Ge Y, Liu M (2013) HMM-based human fall detection and prediction method using tri-axial accelerometer. IEEE Sensors J 13(5):1849–1856SISTEMIC: Research group on Embedded Systems and Computational Intelligence of the Electronics and Telecommunications Department at the Faculty of Engineering, University of Antioquia, “SisFall Dataset.” Online. Available: http://sistemic.udea.edu.co/investigacion/proyectos/english-falls/?lang=en . Accessed 2 Feb 2018Rubenstein L (2006) Falls in older people: epidemiology. Risk Factors and Strategies for Prev 35(Suppl 2):ii37–ii41Youn J, Okuma Y, Hwang M, Kim D, Cho JW (2017) Falling direction can predict the mechanism of recurrent falls in advanced Parkinson’s disease. Sci Rep 7(1):3921Nevitt S, Cummings MC (2018) Type of fall and risk of hip and wrist fractures: The study of osteoporotic fractures. J Am Geriatr Soc 41(11):1226–1234Karantonis DM, Narayanan MR, Mathie M, Lovell NH, Celler BG (2006) Implementation of a real-time human movement classifier using a triaxial accelerometer for ambulatory monitoring. IEEE Trans Inf Technol Biomed 10(1):156–167Khan AM, Lee YK, Kim TS (2008) Accelerometer signal-based human activity recognition using augmented autoregressive model coefficients and artificial neural nets in 2008 30th Annual International. Conf Proc IEEE Eng Med Biol Soc 2008:5172–5175Yoshida T, Mizuno F, Hayasaka T, Tsubota K, Wada S, Yamaguchi T (2005) A wearable computer system for a detection and prevention of elderly users from falling. In: Proceedings of the 12th international conference on biomedical engineering. Singapore, pp 179–182Kangas M, Konttila A, Winblad I, Jamsa T (2007) Determination of simple thresholds for accelerometry based parameters for fall detection. In: 2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. Lyon (France), pp 1367–1370. https://doi.org/10.1109/IEMBS.2007.4352552 . E- ISSN: 1558-4615Shan S, Yuan T (2010) A wearable pre-impact fall detector using feature selection and Support Vector Machine. In: IEEE 10th International Conference on Signal Processing Proceedings. Beijin (China), pp 1686–1689. https://doi.org/10.1109/ICOSP.2010.5656840 . E- ISSN: 2164-523XLombardi A, Ferri M, Rescio G, Grassi M, Malcovati P (2009) Wearable wireless accelerometer with embedded fall-detection logic for multi-sensor ambient assisted living applications. In: 2009 IEEE Sensors. Christchurch (New Zealand), pp. 1967–1970. https://doi.org/10.1109/ICSENS.2009.5398327 . E- ISSN: 1930-0395Aziz O, Klenk J, Schwickert L, Chiari L, Becker C, Park EJ, Mori G, Robinovitch SN (2017) Validation of accuracy of SVM-based fall detection system using real-world fall and non-fall datasets. PLoS One 12(7):e0180318Wang K, Delbaere K, Brodie MAD, Lovell NH, Kark L, Lord SR, Redmond SJ (2017) Differences between gait on stairs and flat surfaces in relation to fall risk and future falls. IEEE J Biomed Heal Inform 21(6):1479–1486Lindholm B, Hagell P, Hansson O, Nilsson MH (2015) Prediction of falls and/or near falls in people with mild Parkinson’s disease. PLoS One 10(1):e0117018Fan Y, Levine MD, Wen G, Qiu S (2017) A deep neural network for real-time detection of falling humans in naturally occurring scenes. Neurocomputing 260:43–58Jokanovic B, Amin M, Ahmad F (2016) Radar fall motion detection using deep learning. In: 2016 IEEE Radar Conference (RadarConf). Philadelphia (USA), pp 1–6. https://doi.org/10.1109/RADAR.2016.7485147 . E- ISSN: 2375-5318Jankowski S, Szymański Z, Dziomin U, Mazurek P, Wagner J (2015) Deep learning classifier for fall detection based on IR distance sensor data. In: 2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS), vol 2. Warsar (Polonia), pp. 723–727. https://doi.org/10.1109/IDAACS.2015.7341398Jokanović B, Amin M (2018) Fall detection using deep learning in range-Doppler radars. IEEE Trans Aerosp Electron Syst 54(1):180–189Shojaei-Hashemi A, Nasiopoulos P, Little JJ, Pourazad MT (2018) Video-based Human Fall Detection in Smart Homes Using Deep Learning. In: 2018 IEEE International Symposium on Circuits and Systems (ISCAS). Florence (Italy), pp 1–5. https://doi.org/10.1109/ISCAS.2018.8351648 . E- ISSN: 2379-447XLeu F-Y, Ko C-Y, Lin Y-C, Susanto H, Yu H-C (2017) Chapter 10 - Fall Detection and Motion Classification by Using Decision Tree on Mobile Phone. In: Xhafa F, Leu F-Y, Hung L-LBT-SSN (eds) Intelligent Data-Centric Systems Book. Academic Press, pp 205–237. https://doi.org/10.1016/B978-0-12-809859-2.00013-9Yacchirema D, Suárez de Puga J, Palau C, Esteve M (2018) Fall detection system for elderly people using IoT and Big Data. In: 9th International Conference on Ambient Systems, Networks and Technologies (ANT 2018), Porto (Portugal), available at Procedia Computer Science, vol 130, pp 603–610. https://doi.org/10.1016/j.procs.2018.04.110 E-ISSN:1877-0509Rougier C, Meunier J, St-Arnaud A, Rousseau J (2011) Robust video surveillance for fall detection based on human shape deformation. IEEE Trans Circuits Syst Video Technol 21(5):611–622Stone EE, Skubic M (2015) Fall detection in homes of older adults using the Microsoft Kinect. IEEE J Biomed Heal Inform 19(1):290–301Yuwono M, Moulton BD, Su SW, Celler BG, Nguyen HT (2012) Unsupervised machine-learning method for improving the performance of ambulatory fall-detection systems. Biomed Eng Online 11(1):9Friedman J, Hastie T, Tibshirani R (2001) The elements of statistical learning, vol. 1, no. 10. Springer series in statistics New York, NY, USA. https://doi.org/10.1007/b94608 . E-ISBN: 9780387848587Zhang C, Ma Y (2012) Ensemble machine learning: Methods and applications. Springer-Verlag New York, NY. https://doi.org/10.1007/978-1-4419-9326-7 . E-ISBN 978-1-4419-9326-7Big ML (2017) Inc. US “Comprehensive Machine Learning Platform”. Online. Available: https://bigml.com/features . Accessed 12 Aug 2018Ling CX, Huang J, Zhang H et al (2003) AUC: a statistically consistent and more discriminating measure than accuracy. In: 18th Int'l Joint Conf. Artificial Intelligence (IJCAI), Acapulco (mexico), vol 3, pp 519–524. ISBN:0-7695-2728-0Dai J, Bai X, Yang Z, Shen Z, Xuan D (2010) PerFallD: A pervasive fall detection system using mobile phones. In: 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops). Mannheim (Germany), pp 292–297. https://doi.org/10.1109/PERCOMW.2010.5470652 . E- ISBN: 978-1-4244-6606-1Li Y, Ho KC, Popescu M (2012) A microphone array system for automatic fall detection. IEEE Trans Biomed Eng 59(5):1291–1301Fawcett T (2006) An introduction to ROC analysis. Pattern Recogn Lett 27(8):861–874Pease SG, Trueman R, Davies C, Grosberg J, Yau KH, Kaur N, Conway P, West A (2018) An intelligent real-time cyber-physical toolset for energy and process prediction and optimisation in the future industrial Internet of Things. Futur Gener Comput Syst 79(Part 3):815–829Breiman L (1996) Bagging predictors. Mach Learn 24(2):123–140Hanke S, Mayer C, Hoeftberger O, Boos H, Wichert R, Tazari M-R, Wolf P, Furfari F (2011) universAAL -- An Open and Consolidated AAL Platform. In: Wichert R, Eberhardt B (eds) Ambient Assisted Living: 4. AAL-Kongress 2011, Berlin, Germany, January 25–26, 2011. Springer Berlin Heidelberg, Berlin, Heidelberg, pp. 127–140. https://doi.org/10.1007/978-3-642-18167-2_10 . E-ISBN: 978-3-642-18167-2Gjoreski H, Lustrek M, Gams M (2011) Accelerometer Placement for Posture Recognition and Fall Detection. In: 2011 Seventh International Conference on Intelligent Environments. Nottingham (UK), pp 47–54. doi: https://doi.org/10.1109/IE.2011.11 . E- ISBN: 978-0-7695-4452-6Parker C (2011) An Analysis of Performance Measures for Binary Classifiers. In: 2011 IEEE 11th International Conference on Data Mining, Vancouver (Canada), pp 517–526. doi: https://doi.org/10.1109/ICDM.2011.21 . E- ISSN: 2374-8486Han J, Kamber M, Pei J (2012) Data Mining Concepts and Techniques, Third Edit. Morgan Kaufmann Publishers in The Morgan Kaufmann Series in Data Management Systems. Waltham (USA). E-ISBN: 978012381480",Fall detection system for elderly people using IoT and ensemble machine learning algorithm,10.1007/s00779-018-01196-8,http://hdl.handle.net/10251/161870,,'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
322840422,2019-11-01T00:00:00,"International audienceWireless Body Area Network (WBAN) is a quite suitable communication tool for medical IoT devices that are deployed to collect physiological parameters and forecast real-time events in order to facilitate the diagnostic decision-making for the medical staff. However, sensor readings may be inaccurate due to resource-constrained devices, sensor misplacement, hardware faults, and other environmental factors. Therefore, anomaly detection is envisioned as a promising approach to deal with unreliable and malicious data injection to improve remote patient monitoring systems and reduce false medical diagnosis. In this context, several data analysis and machine learning tools have been proposed to detect abnormal deviations in WBAN. Nevertheless, no one considers the dynamic context changes of WBAN to provide adaptive and dynamic outlier detection. In addition, most of them ignore the co-existence of strong spatial and temporal correlations between monitored physiological attributes. To this end, we propose a two-level lightweight and adaptive anomaly detection approach to discard false alarms caused by faulty measurements and raise alarms only when a patient seems to be in emergency situations. In the first level, a game-theoretic technique is introduced wherein body-worn sensor nodes exploit the spatiotemporal correlation among readings to locally and adaptively detect anomalous events according to the dynamic context changes of WBAN. In the second level, we apply the Mahalanobis distance in the Local Processing Unit (LPU) which has a global view for multivariate analysis. Our main objective is to ensure a tradeoff between detection accuracy, false positive rates, and network performance while considering the WBAN environment constraints. The proposed approach is evaluated through numerical simulations on a real physiological data set. Simulation results prove the effectiveness of the proposed approach in terms of achieving high detection accuracy with low false alarm rate and energy consumption",Game-Based Adaptive Anomaly Detection in Wireless Body Area Networks,10.1016/j.comnet.2019.106870,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
334494250,2020-01-01T00:00:00,"International audienceObjectives. There is now on a service of online psychotherapy, Woebot, practised by an software. It results from twenty years of researches of a psychologists’ team in Stanford University and experts in artificial intelligence and interactive technology. It is based on the deployment of the positive thought advocated by CBT (cognitive-behavioural therapeutic).Methodology. We examine the promise of what is presented as the future of psychotherapy. We lean on the press kit, the elements collected on the site, the scientific, medical and other articles to which il sends back.Discussion. It seems to us that it consists in trying to stop the release and re-operate the repression. It is a soft method to evacuate subjectivity, remobilize desire and adopt the point of view of other one.Patients. This offer of freeing from speech and overtaking guilt addresses particularly to the three hundred million of depressed in the world, according to the World Health Organization.Results. It tends to set a special link with the machine, not without divine echo, and to reset a kind of confession.Conclusion. The real target is psychotherapists who appear as moralizing inquisitors out of reach, both unavailable and unaffordable. The issue is to be done with psychotherapy with the blessing of the medicine.Objectifs. Cet article étudie les principes de la première psychothérapie en ligne pratiquée par une intelligence artificielle. Elle résulte de vingt ans de recherches d’une équipe de psychologues de l’université de Stanford et d’experts en intelligence artificielle et technologie conversationnelle. Elle est basée sur le déploiement de la pensée positive prônée par les traitements cognitivo-comportementalistes.Méthode. Nous examinons la promesse de ce qui est présenté comme l’avenir de la psychothérapie. Nous nous appuyons sur le dossier de presse, les éléments recueillis sur le site, les articles scientifiques, médicaux et autres auxquels elle renvoie.Discussion. Il nous semble que cela consiste à essayer de stopper le défoulement et d’opérer un re-refoulement. Il s’agit d’une méthode douce pour évacuer la subjectivité, remobiliser le désir, adopter le point de vue de l’autre.Patients. Cette offre de libération d’avec la parole et de dépassement de la culpabilité s’adresse particulièrement aux quelque trois cents millions de déprimés dans le monde, selon l’Organisation mondiale de la santé.Résultats. Cela tend à instaurer un lien spécial à la machine, non sans résonance divine, et de restaurer une forme de confession.Conclusion. La véritable cible est les psychothérapeutes qui apparaissent comme des inquisiteurs moralisateurs et inaccessibles, à la fois hors d’atteinte et hors de prix. L’enjeu paraît être d’en finir avec la psychothérapie avec la bénédiction de la médecine","Woebot : psychothérapie, suite et fin ?",10.3917/psys.202.0071,,,'CAIRN',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
299968308,2019-01-01T00:00:00,"Intracranial hemorrhage is a medical emergency that requires urgent diagnosis and immediate treatment to improve patient outcome. Machine learning algorithms can be used to perform medical image classification and assist clinicians in diagnosing radiological scans. In this paper, we apply 3-dimensional convolutional neural networks (3D CNN) to classify computed tomography (CT) brain scans into normal scans (N) and abnormal scans containing subarachnoid hemorrhage (SAH), intraparenchymal hemorrhage (IPH), acute subdural hemorrhage (ASDH) and brain polytrauma hemorrhage (BPH). The dataset used consists of 399 volumetric CT brain images representing approximately 12,000 images from the National Neuroscience Institute, Singapore. We used a 3D CNN to perform both 2-class (normal versus a specific abnormal class) and 4-class classification (between normal, SAH, IPH, ASDH). We apply image thresholding at the image pre-processing step, that improves 3D CNN classification accuracy and performance by accentuating the pixel intensities that contribute most to feature discrimination. For 2-class classification, the F1 scores for various pairs of medical diagnoses ranged from 0.706 to 0.902 without thresholding. With thresholding implemented, the F1 scores improved and ranged from 0.919 to 0.952. Our results are comparable to, and in some cases, exceed the results published in other work applying 3D CNN to CT or magnetic resonance imaging (MRI) brain scan classification. This work represents a direct application of a 3D CNN to a real hospital scenario involving a medically emergent CT brain diagnosisPublished versio",Image thresholding improves 3-dimensional convolutional neural network diagnosis of different acute brain hemorrhages on computed tomography scans,10.3390/s19092167,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
302992032,2019-04-25T00:00:00,"OBJECTIVES:Artificial Intelligence (AI) offers significant potential for improving healthcare. This paper discusses how an ""open science"" approach to AI tool development, data sharing, education, and research can support the clinical adoption of AI systems. METHOD:In response to the call for participation for the 2019 International Medical Informatics Association (IMIA) Yearbook theme issue on AI in healthcare, the IMIA Open Source Working Group conducted a rapid review of recent literature relating to open science and AI in healthcare and discussed how an open science approach could help overcome concerns about the adoption of new AI technology in healthcare settings. RESULTS:The recent literature reveals that open science approaches to AI system development are well established. The ecosystem of software development, data sharing, education, and research in the AI community has, in general, adopted an open science ethos that has driven much of the recent innovation and adoption of new AI techniques. However, within the healthcare domain, adoption may be inhibited by the use of ""black-box"" AI systems, where only the inputs and outputs of those systems are understood, and clinical effectiveness and implementation studies are missing. CONCLUSIONS:As AI-based data analysis and clinical decision support systems begin to be implemented in healthcare systems around the world, further openness of clinical effectiveness and mechanisms of action may be required by safety-conscious healthcare policy-makers to ensure they are clinically effective in real world use",An Open Science Approach to Artificial Intelligence in Healthcare,10.1055/s-0039-1677898,,"[{'title': 'Yearbook of Medical Informatics', 'identifiers': ['issn:2364-0502', '2364-0502', 'issn:0943-4747', '0943-4747']}]",'Georg Thieme Verlag KG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201560160,2018-11-01T00:00:00,"Running has a positive impact on human health and is an accessible sport for most people. There is high demand for tracking running performance and progress for amateurs and professionals alike. The parameters velocity and distance are thereby of main interest. In this work, we evaluate the accuracy of four algorithms, which calculate the stride velocity and stride length during running using data of an inertial measurement unit (IMU) placed in the midsole of a running shoe. The four algorithms are based on stride time, foot acceleration, foot trajectory estimation, and deep learning, respectively. They are compared using two studies: a laboratory-based study comprising 2377 strides from 27 subjects with 3D motion tracking as a reference and a field study comprising 12 subjects performing a 3.2-km run in a real-world setup. The results show that the foot trajectory estimation algorithm performs best, achieving a mean error of 0.032 &#177; 0.274 m/s for the velocity estimation and 0.022 &#177; 0.157 m for the stride length. An interesting alternative for systems with a low energy budget is the acceleration-based approach. Our results support the implementation decision for running velocity and distance tracking using IMUs embedded in the sole of a running shoe",Comparison of Different Algorithms for Calculating Velocity and Stride Length in Running Using Inertial Measurement Units,10.3390/s18124194,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201582198,2018-09-01T00:00:00,"Abstract Automation and reliability are the crucial elements of any advance reverse osmosis plant to meet the environmental and economic demands. Early fault indication, diagnosis and regular maintenance are the key challenges with most of the reverse osmosis plants in the Indian scenario. The present work introduces a modern reverse osmosis (RO) plant status monitoring unit to monitor different plant parameters in real time and early prediction for faults and maintenance. Developed RO plant status monitoring unit consists of a touch screen-based embedded monitoring unit, water quality sensors (pH, TDS), sampling chamber for controlled water flow, flow sensors, pressure and level sensors. The present system has been developed in a modular fashion so that it could be integrated with any capacity of RO plant units. Developed embedded system monitors various parameters of the plant such as input power, efficiency of the plant, level of input and output water tank and also guides operator with instructions for plant operation. Other than this, a dedicated smartphone app interface has been developed for the operator to acquire data from status monitoring unit, storage on smartphone, and transfer it to the cloud. The developed smartphone-based app also provides facility to integrate plant data with Google map with location information for easy understanding and quick action. The system has also a backup facility to transfer data to the server using 2G GSM module during the unavailability of the operator. A dedicated centralized Web server has been developed for real-time visualization of all installed RO plant status monitoring units. Different machine learning techniques have been implemented on acquired sensors data to predict early warnings related to power failure, membrane fouling and scaling, input water shortage, pipe, tank leakage, water quality sensors damage, non-operation or wrong operation of the plant along with different maintenance actions such as membrane water and chemical wash. Developed RO status monitoring unit has been tested with various RO plants having capacity from 500 LPH to 2000 LPH and deployed at various nearby villages of Rajasthan",Design and development of reverse osmosis (RO) plant status monitoring system for early fault prediction and predictive maintenance,10.1007/s13201-018-0821-8,,"[{'title': 'Applied Water Science', 'identifiers': ['issn:2190-5495', '2190-5487', '2190-5495', 'issn:2190-5487']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440471214,2019-11-01T00:00:00,"Background. According to the literature data, acute coronary syndrome (ACS) in 2-20 % of cases is combined with atrial fibrillation (AF). According to the current guidelines of the European Society of Cardiology (ESC), patients with coexisting AF and ACS should receive dual antiplatelet therapy for the prevention of recurrent cardiovascular events and anticoagulant therapy for the prevention of thromboembolic complications. However, this combination is fraught with the development of hemorrhagic syndrome.Aim. To develop a model and software module for predicting possible bleeding in patients with ACS combined with AF taking three-component antithrombotic therapy.Materials and Methods. To build prognostic models for the development of hemorrhagic syndrome, a statistical method was used for classification trees and the neural network procedure implemented in the STATISTICA package. To build prognostic models, a sample was used consisting of 201 patients with a combination of ACS and AF with and without fatal outcome, the state of which was described by 42 quantitative and qualitative clinical indicators. The control group included 205 patients with ACS and intact sinus rhythm.Results. To identify predictors of predictive models of the possible development of hemorrhagic syndrome in patients with triple antithrombotic therapy, the Spearman correlation coefficient was used. The study of correlations allowed to reveal clinical indicators – predictors of prognostic models. After analyzing the predictive ability of the developed models, a software module was created in the Microsoft Visual C # 2015 programming environment that allows determining the possibility of hemorrhagic syndrome in patients with a combination of ACS and AF using classification trees and neural networks.Сonclusion. A classification model and a software module were developed to predict possible bleeding in patients taking three-component antithrombotic therapy. Models contain both quantitative and qualitative (categorical) clinical indicators. The current level of development of data analysis technologies opens up broad horizons for medicine in solving problems on real medical data, without translating them into scoring risk scales, including prediction of the diagnosis of the disease, stage of the disease, treatment outcome, possible complications, etc. High reliability of such systems can be provided by large volumes of medical data accumulated on servers",Prediction of the Possibility of Hemorrhagic Syndrome during Combined Antiplatelet Therapy According to the Krasnodar Region Registry,10.20996/1819-6446-2019-15-5-697-705,https://core.ac.uk/download/440471214.pdf,"[{'title': 'Rational Pharmacotherapy in Cardiology', 'identifiers': ['issn:1819-6446', '2225-3653', 'issn:2225-3653', '1819-6446']}]",'Stolichnaya Izdatelskaya Kompaniyaizdat',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
226908814,2019-07-08T00:00:00,"International audienceManufacturing companies are under a constant pressure due to multiple factors: new competition, disruptive innovations, cost reduction request, etc. To survive, they must strive to innovate and adapt their business model to improve their productivity. Recent developments based on the concept of Industry 4.0 such as big data, new communication protocols and artificial intelligence provide several new avenues to explore. In the specific context of machining, we are working toward the development of a system capable of making the prognostic of the quality (in terms of dimensional conformance) of a workpiece in real time while it is being manufactured. The goal of this paper is to showcase a prototype of the data acquisition aspect of this system and a case study presenting our first results. This case study has been conducted at our industrial partner facility (Quebec, Canada) and is based on the manufacturing of an aircraft component made from Inconel alloy 625 (AMS5666). The proposed prototype is a data acquisition system installed on a 5 axis CNC machines (GROB model G352) used to acquire and to contextualize the vibration signal obtained from the CNC machine sensor. The contextualization of the data is a key component for future work regarding the development of a prognostic system based on supervised machine learning algorithms. In the end, this paper depicts the system architecture as well as its interactions between the multiple systems and software already in place at our industrial partner. This paper also shows preliminary results describing the relationship between the workpiece quality (in terms of respect toward the dimensional requirements) and the extracted features from the sensors signals. We conclude that it is now possible to do the diagnostic of a cutting operation. Additionally, with the same information we show that it is possible to quickly do the general diagnostic of the health state of the machine. Future work regarding this project will include data acquisition from a wider range of products (i.e. different shapes, materials, processes, etc.) and the development of a machine learning based prognostic model",Toward the quality prognostic of an aircraft engine workpiece in Inconel Alloy 625: case study and proposed system architecture,,,,HAL CCSD,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
365584409,2019-11-07T00:00:00,"Purpose

Recently, several attempts were conducted to transfer deep learning to medical image reconstruction. An increasingly number of publications follow the concept of embedding the computed tomography (CT) reconstruction as a known operator into a neural network. However, most of the approaches presented lack an efficient CT reconstruction framework fully integrated into deep learning environments. As a result, many approaches use workarounds for mathematically unambiguously solvable problems.





Methods

PYRO‐NN is a generalized framework to embed known operators into the prevalent deep learning framework Tensorflow. The current status includes state‐of‐the‐art parallel‐, fan‐, and cone‐beam projectors, and back‐projectors accelerated with CUDA provided as Tensorflow layers. On top, the framework provides a high‐level Python API to conduct FBP and iterative reconstruction experiments with data from real CT systems.





Results

The framework provides all necessary algorithms and tools to design end‐to‐end neural network pipelines with integrated CT reconstruction algorithms. The high‐level Python API allows a simple use of the layers as known from Tensorflow. All algorithms and tools are referenced to a scientific publication and are compared to existing non‐deep learning reconstruction frameworks. To demonstrate the capabilities of the layers, the framework comes with baseline experiments, which are described in the supplementary material. The framework is available as open‐source software under the Apache 2.0 licence at https://github.com/csyben/PYRO-NN.





Conclusions

PYRO‐NN comes with the prevalent deep learning framework Tensorflow and allows to setup end‐to‐end trainable neural networks in the medical image reconstruction context. We believe that the framework will be a step toward reproducible research and give the medical physics community a toolkit to elevate medical image reconstruction with new deep learning techniques",Technical Note: PYRO‐NN: Python reconstruction operators in neural networks,10.1002/mp.13753,,,'Wiley',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
296208145,2018-08-11,"In this paper, we aim to develop a low-computational system for real-time image processing and analysis in endoscopy images for the early detection of the human esophageal adenocarcinoma and colorectal cancer. Rich statistical features are used to train an improved machine-learning algorithm. Our algorithm can achieve a real-time classification of malign and benign cancer tumours with a significantly improved detection precision compared to the classical HOG method as a reference when it is implemented on real time embedded system NVIDIA TX2 platform. Our approach can help to avoid unnecessary biopsies for patients and reduce the over diagnosis of clinically insignificant cancers in the future",A low computational approach for assistive esophageal adenocarcinoma and colorectal cancer detection,10.1007/978-3-319-97982-3_14,,,Springer,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
333919275,2020-04-28T00:00:00,"International audienceBackground: High-throughput sequencing techniques are used to analyse the diversity of the respiratory microbiota in health and disease. Although extensive data are available regarding bacterial respiratory microbiota, its fungal component remains poorly studied. This is partly due to the technical issues associated with fungal metagenomics analyses. In this study, we compared two DNA extraction protocols and two fungal amplification targets for combined bacterial and fungal targeted amplicon sequencing analyses of the respiratory microbiota.Methods: Six sputa, randomly selected from routine samples in Mondor Hospital (Creteil, France) and treated anonymously, were tested after bacterial and fungal routine culture. Two of which were spiked with Aspergillus Fumigati and Aspergillus Nigri (105 conidia/mL). After mechanical lysis, DNA was extracted using automated QIAsymphony® extraction (AQE) or manual PowerSoil® MoBio extraction (MPE). DNA yield and purity were compared. DNA extracted from spiked sputa was subjected to (i) real-time PCR for Aspergillus DNA detection and (ii) combined metagenomic analyses targeting barcoded primers for fungal ITS1 and ITS2, and bacterial V1-V2 and V3-V4 16S regions. Amplicon libraries were prepared using MiSeq Reagent V3 kit on Illumina platform. Data were analysed using PyroMIC© and SHAMAN software, and compared with culture results.Results: AQE extraction provided a higher yield of DNA (AQE/MPE DNA ratio = 4.5 [1.3-11]) in a shorter time. The yield of Aspergillus DNA detected by qPCR was similar for spiked sputa regardless of extraction protocol. The extraction moderately impacted the diversity or relative abundances of bacterial communities using targeted amplicon sequencing (2/43 taxa impacted). For fungi, the relative abundances of 4/11 major taxa were impacted and AQE results were closer to culture results. The V1-V2 or V3-V4 and ITS1 or ITS2 targets assessed similarly the diversity of bacterial and fungal major taxa, but ITS2 and V3-V4 detected more minor taxa.Conclusion: Our results showed the importance of DNA extraction for combined bacterial and fungal targeted metagenomics of respiratory samples. The extraction protocol can affect DNA yield and the relative abundances of few bacterial but more fungal taxa. For fungal analysis, ITS2 allowed the detection of a greater number of minor taxa compared with ITS1",Combined bacterial and fungal targeted amplicon sequencing of respiratory samples: Does the DNA extraction method matter?,10.1371/journal.pone.0232215,,,'Public Library of Science (PLoS)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
232888031,2019-01-01T00:00:00,"Проведено аналіз скатерограм добових тестових сигналів для нормального синусового ритму і аритмії, встановлено наявність сильного кореляційного зв’язку між показником фрактальної розмірності і стандартними показниками ВСР у нормі і його відсутність при аритмії. Розраховано стандартні показники варіабельності ритму серця і показник фрактальної розмірності скатерограм для 1-хвилинних інтервалів. За результатами розрахунків проведено кластерний аналіз даних методом k-means, визначено середні групові значення показника фрактальної розмірності і геометричних параметрів скатерограми. За результатами факторного аналізу визначено набір показників для оцінювання скатерограми 1-хвилинного інтервалу.Проведен анализ скатерограмм суточных тестовых сигналов с нормальным синусовым ритмом и аритмией, установлено наличие сильной корреляционной связи между показателем фрактальной размерности и стандартными показателями ВСР в норме и ее отсутствие при аритмии. Рассчитаны стандартные показатели вариабельности ритма сердца и показатель фрактальной размерности для 1-минутных интервалов. На основании полученных результатов проведен кластерный анализ данных методом k-means, определены средние групповые значения показателя фрактальной размерности и геометрических параметров скатерограммы. По результатам факторного анализа определен набор показателей для оценки скатерограммы 1-минутного интервала.The subjects of investigation are long time series and short time series of RR-intervals and their special distribution named as scatterogram. The objective of work is the investigation of one-minute intervals of RR data series to definite the dataset of parameters for estimation of physiological state in real time mode. The methodology of investigation is based on the data proc-essing of the standard indicators of heart rate variability (HRV), fractal analysis, machine learning methods (k-means) and fac-tor analysis. Testing signals were been taken from the European data base of medical signals PhysioNet. Scatterogram analysis of the testing diurnal record with normal sinus rhythm and arrhythmia was performed. A strong correlation between the coeffi-cient of fractal dimension and standard indications of HRV for normal sinus rhythm and null correlation for arythmia had been observed. Standard indicators of HRV and coefficient of fractal dimension for each one-minute interval were calculated and estimated with the Student’s average test that had shown inexpediency of scaterogram surface using. Cluster analysis based on the k-means method to determine general probabilistic data series groups was performed. Initial data for cluster analysis is a matrix of standard HRV indicators, coefficient of fractal dimension and geometric parameters of scatetogram. Entire objects from the one-minute dataset were grouped into six clusters. The average value of scatterogram parameters (coefficient of fractal dimension, long and short axes and their ration) for selected clusters were found with probability more than 95 %. Data set of parameters to analyze the one-minute intervals of RR-dataset was defined with fractal analysis. Proposed dataset of indicators for estimation one-minute intervals includes: pNN50 (the proportion derived by dividing the number of interval differences of successive NN intervals greater than 50 ms by the total number of NN intervals), long SD2 and short SD1 ellipse axes, ratio SD2/SD1, triangular index TI, mean heart rate and coefficient of fractal dimension Df. Gotten results may be used to develop mobile software for personal monitoring devices",Fractal analysis of scaterogram,,,,Kharkiv national Air Force University named after I. Kozhedub,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
395143458,2020-05-01T00:00:00,"[EN] This paper uses a two-fold multi-criteria decision-making (MCDM) approach applied for the first time to the field of microbial management of drinking water distribution systems (DWDS). Specifically, the decision-making trial and evaluation laboratory (DEMATEL) was applied removing the need for reliance on expert judgement, and analysed interdependencies among water quality parameters and microbiological characteristics of DWDS composed of different pipe materials. In addition, the fuzzy technique for order preference by similarity to ideal solution (FTOPSIS) ranked the most common bacteria identified during trials in a DWDS according to their relative abundance while managing vagueness affecting the measurements. The novel integrated approach presented and proven here for an initial real world data set provides new insights in the interdependence of environmental conditions and microbial populations. Specifically, the application shows as the bacteria having associated the most significant microbial impact may not be the most abundant. This offers the potential for integrated management strategies to promote favourable microbial conditions to help safeguard drinking water quality.The research reported here was supported by the UK Engineering and Physical Sciences Research Council (EPSRC), EPSRC-LWEC Challenge Fellowship EP/N02950X/1. We also would like to thank United Utilities for sampling sites, field work and physicochemical sample analysis.Carpitella, S.; Del Olmo, G.; Izquierdo Sebastián, J.; Husband, S.; Boxall, J.; Douterelo, I. (2020). Decision-Making Tools to Manage the Microbiology of Drinking Water Distribution Systems. Water. 12(5):1-18. https://doi.org/10.3390/w12051247S118125Guidelines for Drinking Water Quality, 4th Edition, Incorporating the 1st Addendum 2017 https://www.who.int/water_sanitation_health/publications/drinking-water-quality-guidelines-4-including-1st-addendum/en/Water Quality-Sampling-Part 5: Guidance on Sampling of Drinking Water from Treatment Works and Piped Distribution Systems https://www.iso.org/obp/ui/#iso:std:iso:5667:-5:ed-2:v1:enDeng, W., & Wang, G. (2017). A novel water quality data analysis framework based on time-series data mining. Journal of Environmental Management, 196, 365-375. doi:10.1016/j.jenvman.2017.03.024McClymont, K., Keedwell, E., & Savic, D. (2015). An analysis of the interface between evolutionary algorithm operators and problem features for water resources problems. A case study in water distribution network design. Environmental Modelling & Software, 69, 414-424. doi:10.1016/j.envsoft.2014.12.023Izquierdo, J., Montalvo, I., Pérez-García, R., & Matías, A. (2012). On the Complexities of the Design of Water Distribution Networks. Mathematical Problems in Engineering, 2012, 1-25. doi:10.1155/2012/947961Fox, S., Shepherd, W., Collins, R., & Boxall, J. (2016). Experimental Quantification of Contaminant Ingress into a Buried Leaking Pipe during Transient Events. Journal of Hydraulic Engineering, 142(1), 04015036. doi:10.1061/(asce)hy.1943-7900.0001040Mounce, S. R., Mounce, R. B., & Boxall, J. B. (2010). Novelty detection for time series data analysis in water distribution systems using support vector machines. Journal of Hydroinformatics, 13(4), 672-686. doi:10.2166/hydro.2010.144Vališ, D., Hasilová, K., Forbelská, M., & Vintr, Z. (2020). Reliability modelling and analysis of water distribution network based on backpropagation recursive processes with real field data. Measurement, 149, 107026. doi:10.1016/j.measurement.2019.107026Liu, G., Bakker, G. L., Li, S., Vreeburg, J. H. G., Verberk, J. Q. J. C., Medema, G. J., … Van Dijk, J. C. (2014). Pyrosequencing Reveals Bacterial Communities in Unchlorinated Drinking Water Distribution System: An Integral Study of Bulk Water, Suspended Solids, Loose Deposits, and Pipe Wall Biofilm. Environmental Science & Technology, 48(10), 5467-5476. doi:10.1021/es5009467Donlan, R. M., & Costerton, J. W. (2002). Biofilms: Survival Mechanisms of Clinically Relevant Microorganisms. Clinical Microbiology Reviews, 15(2), 167-193. doi:10.1128/cmr.15.2.167-193.2002Douterelo, I., Husband, S., Loza, V., & Boxall, J. (2016). Dynamics of Biofilm Regrowth in Drinking Water Distribution Systems. Applied and Environmental Microbiology, 82(14), 4155-4168. doi:10.1128/aem.00109-16Wang, H., Hu, C., Hu, X., Yang, M., & Qu, J. (2012). Effects of disinfectant and biofilm on the corrosion of cast iron pipes in a reclaimed water distribution system. Water Research, 46(4), 1070-1078. doi:10.1016/j.watres.2011.12.001Husband, S., Fish, K. E., Douterelo, I., & Boxall, J. (2016). Linking discolouration modelling and biofilm behaviour within drinking water distribution systems. Water Supply, 16(4), 942-950. doi:10.2166/ws.2016.045Wingender, J., & Flemming, H.-C. (2011). Biofilms in drinking water and their role as reservoir for pathogens. International Journal of Hygiene and Environmental Health, 214(6), 417-423. doi:10.1016/j.ijheh.2011.05.009Douterelo, I., Boxall, J. B., Deines, P., Sekar, R., Fish, K. E., & Biggs, C. A. (2014). Methodological approaches for studying the microbial ecology of drinking water distribution systems. Water Research, 65, 134-156. doi:10.1016/j.watres.2014.07.008Douterelo, I., Sharpe, R. L., & Boxall, J. B. (2013). Influence of hydraulic regimes on bacterial community structure and composition in an experimental drinking water distribution system. Water Research, 47(2), 503-516. doi:10.1016/j.watres.2012.09.053Harwani, D. (2012). The Great Plate Count Anomaly and the Unculturable Bacteria. International Journal of Scientific Research, 2(9), 350-351. doi:10.15373/22778179/sep2013/122Ikonen, J., Pitkänen, T., Kosse, P., Ciszek, R., Kolehmainen, M., & Miettinen, I. T. (2017). On-line detection of Escherichia coli intrusion in a pilot-scale drinking water distribution system. Journal of Environmental Management, 198, 384-392. doi:10.1016/j.jenvman.2017.04.090Wang, Z., Chen, Q., Zhang, J., Dong, J., Yan, H., Chen, C., & Feng, R. (2019). Characterization and source identification of tetracycline antibiotics in the drinking water sources of the lower Yangtze River. Journal of Environmental Management, 244, 13-22. doi:10.1016/j.jenvman.2019.04.070Yu, J., Kim, D., & Lee, T. (2010). Microbial diversity in biofilms on water distribution pipes of different materials. Water Science and Technology, 61(1), 163-171. doi:10.2166/wst.2010.813Rogers, J. W., & Louis, G. E. (2008). Risk and opportunity in upgrading the US drinking water infrastructure system. Journal of Environmental Management, 87(1), 26-36. doi:10.1016/j.jenvman.2007.01.002Henriques, J. J., & Louis, G. E. (2011). A decision model for selecting sustainable drinking water supply and greywater reuse systems for developing communities with a case study in Cimahi, Indonesia. Journal of Environmental Management, 92(1), 214-222. doi:10.1016/j.jenvman.2010.09.016Ramos-Martínez, E., Herrera, M., Gutiérrez-Pérez, J., Izquierdo, J., & Pérez-García, R. (2014). Rehabilitation Actions in Water Supply Systems: Effects on Biofilm Susceptibility. Procedia Engineering, 89, 225-231. doi:10.1016/j.proeng.2014.11.181Dalvi-Esfahani, M., Niknafs, A., Kuss, D. J., Nilashi, M., & Afrough, S. (2019). Social media addiction: Applying the DEMATEL approach. Telematics and Informatics, 43, 101250. doi:10.1016/j.tele.2019.101250Si, S.-L., You, X.-Y., Liu, H.-C., & Zhang, P. (2018). DEMATEL Technique: A Systematic Review of the State-of-the-Art Literature on Methodologies and Applications. Mathematical Problems in Engineering, 2018, 1-33. doi:10.1155/2018/3696457Chen, C.-T. (2000). Extensions of the TOPSIS for group decision-making under fuzzy environment. Fuzzy Sets and Systems, 114(1), 1-9. doi:10.1016/s0165-0114(97)00377-1Gul, M., & Ak, M. F. (2018). A comparative outline for quantifying risk ratings in occupational health and safety risk assessment. Journal of Cleaner Production, 196, 653-664. doi:10.1016/j.jclepro.2018.06.106Carpitella, S., Certa, A., Izquierdo, J., & La Fata, C. M. (2018). A combined multi-criteria approach to support FMECA analyses: A real-world case. Reliability Engineering & System Safety, 169, 394-402. doi:10.1016/j.ress.2017.09.017Palczewski, K., & Sałabun, W. (2019). The fuzzy TOPSIS applications in the last decade. Procedia Computer Science, 159, 2294-2303. doi:10.1016/j.procs.2019.09.404Sarkar, S., Pratihar, D. K., & Sarkar, B. (2018). An integrated fuzzy multiple criteria supplier selection approach and its application in a welding company. Journal of Manufacturing Systems, 46, 163-178. doi:10.1016/j.jmsy.2017.12.004Dinçer, H., Yüksel, S., & Martínez, L. (2019). Interval type 2-based hybrid fuzzy evaluation of financial services in E7 economies with DEMATEL-ANP and MOORA methods. Applied Soft Computing, 79, 186-202. doi:10.1016/j.asoc.2019.03.018Chen, J.-K., & Chen, I.-S. (2010). Using a novel conjunctive MCDM approach based on DEMATEL, fuzzy ANP, and TOPSIS as an innovation support system for Taiwanese higher education. Expert Systems with Applications, 37(3), 1981-1990. doi:10.1016/j.eswa.2009.06.079Nilashi, M., Samad, S., Manaf, A. A., Ahmadi, H., Rashid, T. A., Munshi, A., … Hassan Ahmed, O. (2019). Factors influencing medical tourism adoption in Malaysia: A DEMATEL-Fuzzy TOPSIS approach. Computers & Industrial Engineering, 137, 106005. doi:10.1016/j.cie.2019.106005Li, G., Ma, X., Chen, R., Yu, Y., Tao, H., & Shi, B. (2019). Field studies of manganese deposition and release in drinking water distribution systems: Insight into deposit control. Water Research, 163, 114897. doi:10.1016/j.watres.2019.114897Zhu, Y., Wang, H., Li, X., Hu, C., Yang, M., & Qu, J. (2014). Characterization of biofilm and corrosion of cast iron pipes in drinking water distribution system with UV/Cl2 disinfection. Water Research, 60, 174-181. doi:10.1016/j.watres.2014.04.035Du, Y.-W., & Zhou, W. (2019). New improved DEMATEL method based on both subjective experience and objective data. Engineering Applications of Artificial Intelligence, 83, 57-71. doi:10.1016/j.engappai.2019.05.001Carpitella, S., Carpitella, F., Certa, A., Benítez, J., & Izquierdo, J. (2018). Managing Human Factors to Reduce Organisational Risk in Industry. Mathematical and Computational Applications, 23(4), 67. doi:10.3390/mca23040067Gerami Seresht, N., & Fayek, A. R. (2019). Computational method for fuzzy arithmetic operations on triangular fuzzy numbers by extension principle. International Journal of Approximate Reasoning, 106, 172-193. doi:10.1016/j.ijar.2019.01.005Zadeh, L. A. (1965). Fuzzy sets. Information and Control, 8(3), 338-353. doi:10.1016/s0019-9958(65)90241-xProkopowicz, P. (2019). The use of Ordered Fuzzy Numbers for modelling changes in dynamic processes. Information Sciences, 470, 1-14. doi:10.1016/j.ins.2018.08.045Okunuki, S., Kawaharasaki, M., Tanaka, H., & Kanagawa, T. (2004). Changes in phosphorus removing performance and bacterial community structure in an enhanced biological phosphorus removal reactor. Water Research, 38(9), 2433-2439. doi:10.1016/j.watres.2004.02.008Rofner, C., Sommaruga, R., & Teresa Pérez, M. (2016). Phosphate and ATP uptake by lake bacteria: does taxonomical identity matter? Environmental Microbiology, 18(12), 4782-4793. doi:10.1111/1462-2920.13368Ferro, P., Vaz-Moreira, I., & Manaia, C. M. (2019). Betaproteobacteria are predominant in drinking water: are there reasons for concern? Critical Reviews in Microbiology, 45(5-6), 649-667. doi:10.1080/1040841x.2019.1680602Ertekin, E., Hatt, J. K., Konstantinidis, K. T., & Tezel, U. (2016). Similar Microbial Consortia and Genes Are Involved in the Biodegradation of Benzalkonium Chlorides in Different Environments. Environmental Science & Technology, 50(8), 4304-4313. doi:10.1021/acs.est.5b0595",Decision-Making Tools to Manage the Microbiology of Drinking Water Distribution Systems,10.3390/w12051247,https://riunet.upv.es/bitstream/10251/162955/1/Carpitella%3bDel%3bIzquierdo%20-%20Decision-Making%20Tools%20to%20Manage%20the%20Microbiology%20of%20Drinking%20Water%20Dis....pdf,,'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
429121482,2020-09-01T00:00:00,"[EN] Background and objective: As Computed Tomography scans are an essential medical test, many techniques have been proposed to reconstruct high-quality images using a smaller amount of radiation. One approach is to employ algebraic factorization methods to reconstruct the images, using fewer views than the traditional analytical methods. However, their main drawback is the high computational cost and hence the time needed to obtain the images, which is critical in the daily clinical practice. For this reason, faster methods for solving this problem are required.

Methods: In this paper, we propose a new reconstruction method based on the QR factorization that is very efficient on affordable equipment (standard multicore processors and standard Solid-State Drives) by using Out-Of-Core techniques.

Results: Combining both affordable hardware and the new software proposed in our work, the images can be reconstructed very quickly and with high quality. We analyze the reconstructions using real Computed Tomography images selected from a dataset, comparing the QR method to the LSQR and FBP. We measure the quality of the images using the metrics Peak Signal-To-Noise Ratio and Structural Similarity Index, obtaining very high values. We also compare the efficiency of using spinning disks versus Solid-State Drives, showing how the latter performs the Input/Output operations in a significantly lower amount of time. Conclusions: The results indicate that our proposed me thod and software are valid to efficiently solve large-scale systems and can be applied to the Computed Tomography reconstruction problem to obtain high-quality images.This research has been supported by ""Universitat Politecnica de Valencia"", ""Generalitat Valenciana"" under PROMETEO/2018/035 and ACIF/2017/075, co-financed by FEDER and FSE funds, and the ""Spanish Ministry of Science, Innovation and Universities"" under Grant RTI2018-098156-B-C54 co-financed by FEDER funds.Chillarón-Pérez, M.; Quintana Ortí, G.; Vidal-Gimeno, V.; Verdú Martín, GJ. (2020). Computed tomography medical image reconstruction on affordable equipment by using Out-Of-Core techniques. Computer Methods and Programs in Biomedicine. 193:1-11. https://doi.org/10.1016/j.cmpb.2020.105488S111193Berrington de González, A. (2009). Projected Cancer Risks From Computed Tomographic Scans Performed in the United States in 2007. Archives of Internal Medicine, 169(22), 2071. doi:10.1001/archinternmed.2009.440HALL, E. J., & BRENNER, D. J. (2008). Cancer risks from diagnostic radiology. The British Journal of Radiology, 81(965), 362-378. doi:10.1259/bjr/01948454Tang, X., Hsieh, J., Nilsen, R. A., Dutta, S., Samsonov, D., & Hagiwara, A. (2006). A three-dimensional-weighted cone beam filtered backprojection (CB-FBP) algorithm for image reconstruction in volumetric CT—helical scanning. Physics in Medicine and Biology, 51(4), 855-874. doi:10.1088/0031-9155/51/4/007Zhuang, T., Leng, S., Nett, B. E., & Chen, G.-H. (2004). Fan-beam and cone-beam image reconstruction via filtering the backprojection image of differentiated projection data. Physics in Medicine and Biology, 49(24), 5489-5503. doi:10.1088/0031-9155/49/24/007Mori, S., Endo, M., Komatsu, S., Kandatsu, S., Yashiro, T., & Baba, M. (2006). A combination-weighted Feldkamp-based reconstruction algorithm for cone-beam CT. Physics in Medicine and Biology, 51(16), 3953-3965. doi:10.1088/0031-9155/51/16/005Willemink, M. J., de Jong, P. A., Leiner, T., de Heer, L. M., Nievelstein, R. A. J., Budde, R. P. J., & Schilham, A. M. R. (2013). Iterative reconstruction techniques for computed tomography Part 1: Technical principles. European Radiology, 23(6), 1623-1631. doi:10.1007/s00330-012-2765-yWillemink, M. J., Leiner, T., de Jong, P. A., de Heer, L. M., Nievelstein, R. A. J., Schilham, A. M. R., & Budde, R. P. J. (2013). Iterative reconstruction techniques for computed tomography part 2: initial results in dose reduction and image quality. European Radiology, 23(6), 1632-1642. doi:10.1007/s00330-012-2764-zWu, W., Liu, F., Zhang, Y., Wang, Q., & Yu, H. (2019). Non-Local Low-Rank Cube-Based Tensor Factorization for Spectral CT Reconstruction. IEEE Transactions on Medical Imaging, 38(4), 1079-1093. doi:10.1109/tmi.2018.2878226Wu, W., Zhang, Y., Wang, Q., Liu, F., Chen, P., & Yu, H. (2018). Low-dose spectral CT reconstruction using image gradient ℓ0–norm and tensor dictionary. Applied Mathematical Modelling, 63, 538-557. doi:10.1016/j.apm.2018.07.006Andersen, A. H. (1989). Algebraic reconstruction in CT from limited views. IEEE Transactions on Medical Imaging, 8(1), 50-55. doi:10.1109/42.20361Andersen, A. H., & Kak, A. C. (1984). Simultaneous Algebraic Reconstruction Technique (SART): A Superior Implementation of the Art Algorithm. Ultrasonic Imaging, 6(1), 81-94. doi:10.1177/016173468400600107Yu, W., & Zeng, L. (2014). A Novel Weighted Total Difference Based Image Reconstruction Algorithm for Few-View Computed Tomography. PLoS ONE, 9(10), e109345. doi:10.1371/journal.pone.0109345Flores, L., Vidal, V., & Verdú, G. (2015). Iterative Reconstruction from Few-view Projections. Procedia Computer Science, 51, 703-712. doi:10.1016/j.procs.2015.05.188Flores, L. A., Vidal, V., Mayo, P., Rodenas, F., & Verdú, G. (2014). Parallel CT image reconstruction based on GPUs. Radiation Physics and Chemistry, 95, 247-250. doi:10.1016/j.radphyschem.2013.03.011Chillarón, M., Vidal, V., Segrelles, D., Blanquer, I., & Verdú, G. (2017). Combining Grid Computing and Docker Containers for the Study and Parametrization of CT Image Reconstruction Methods. Procedia Computer Science, 108, 1195-1204. doi:10.1016/j.procs.2017.05.065Sollmann, N., Mei, K., Schwaiger, B. J., Gersing, A. S., Kopp, F. K., Bippus, R., … Baum, T. (2018). Effects of virtual tube current reduction and sparse sampling on MDCT-based femoral BMD measurements. Osteoporosis International, 29(12), 2685-2692. doi:10.1007/s00198-018-4675-6Yan Liu, Zhengrong Liang, Jianhua Ma, Hongbing Lu, Ke Wang, Hao Zhang, & Moore, W. (2014). Total Variation-Stokes Strategy for Sparse-View X-ray CT Image Reconstruction. IEEE Transactions on Medical Imaging, 33(3), 749-763. doi:10.1109/tmi.2013.2295738Tang, J., Nett, B. E., & Chen, G.-H. (2009). Performance comparison between total variation (TV)-based compressed sensing and statistical iterative reconstruction algorithms. Physics in Medicine and Biology, 54(19), 5781-5804. doi:10.1088/0031-9155/54/19/008Vandeghinste, B., Vandenberghe, S., Vanhove, C., Staelens, S., & Van Holen, R. (2013). Low-Dose Micro-CT Imaging for Vascular Segmentation and Analysis Using Sparse-View Acquisitions. PLoS ONE, 8(7), e68449. doi:10.1371/journal.pone.0068449Qi, H., Chen, Z., & Zhou, L. (2015). CT Image Reconstruction from Sparse Projections Using Adaptive TpV Regularization. Computational and Mathematical Methods in Medicine, 2015, 1-8. doi:10.1155/2015/354869Wu, W., Chen, P., Vardhanabhuti, V. V., Wu, W., & Yu, H. (2019). Improved Material Decomposition With a Two-Step Regularization for Spectral CT. IEEE Access, 7, 158770-158781. doi:10.1109/access.2019.2950427Rodriguez-Alvarez, M. J., Sanchez, F., Soriano, A., Moliner, L., Sanchez, S., & Benlloch, J. (2018). QR-Factorization Algorithm for Computed Tomography (CT): Comparison With FDK and Conjugate Gradient (CG) Algorithms. IEEE Transactions on Radiation and Plasma Medical Sciences, 2(5), 459-469. doi:10.1109/trpms.2018.2843803Chillarón, M., Vidal, V., & Verdú, G. (2020). CT image reconstruction with SuiteSparseQR factorization package. Radiation Physics and Chemistry, 167, 108289. doi:10.1016/j.radphyschem.2019.04.039Joseph, P. M. (1982). An Improved Algorithm for Reprojecting Rays through Pixel Images. IEEE Transactions on Medical Imaging, 1(3), 192-196. doi:10.1109/tmi.1982.4307572S. Toledo, F. Gustavson, The design and implementation of solar, a portable library for scalable out-of-core linear algebra computations, in: Proceedings of the Annual Workshop on I/O in Parallel and Distributed Systems, IOPADS,D’Azevedo, E., & Dongarra, J. (2000). The design and implementation of the parallel out-of-core ScaLAPACK LU, QR, and Cholesky factorization routines. Concurrency: Practice and Experience, 12(15), 1481-1493. doi:10.1002/1096-9128(20001225)12:153.0.co;2-vGunter, B. C., & Van De Geijn, R. A. (2005). Parallel out-of-core computation and updating of the QR factorization. ACM Transactions on Mathematical Software, 31(1), 60-78. doi:10.1145/1055531.1055534Quintana-Ortí, G., Igual, F. D., Marqués, M., Quintana-Ortí, E. S., & van de Geijn, R. A. (2012). A Runtime System for Programming Out-of-Core Matrix Algorithms-by-Tiles on Multithreaded Architectures. ACM Transactions on Mathematical Software, 38(4), 1-25. doi:10.1145/2331130.2331133Marqués, M., Quintana-Ortí, G., Quintana-Ortí, E. S., & van de Geijn, R. (2010). Using desktop computers to solve large-scale dense linear algebra problems. The Journal of Supercomputing, 58(2), 145-150. doi:10.1007/s11227-010-0394-2G. Lauritsch, H. Bruder, FORBILD head phantom, http://www.imp.uni-erlangen.de/phantoms/head/head.html.Yan, K., Wang, X., Lu, L., & Summers, R. M. (2018). DeepLesion: automated mining of large-scale lesion annotations and universal lesion detection with deep learning. Journal of Medical Imaging, 5(03), 1. doi:10.1117/1.jmi.5.3.036501Miqueles, E., Koshev, N., & Helou, E. S. (2018). A Backprojection Slice Theorem for Tomographic Reconstruction. IEEE Transactions on Image Processing, 27(2), 894-906. doi:10.1109/tip.2017.2766785N. Koshev, E.S. Helou, E.X. Miqueles, Fast backprojection techniques for high resolution tomographyarXiv preprint: 1608.03589",Computed tomography medical image reconstruction on affordable equipment by using Out-Of-Core techniques,10.1016/j.cmpb.2020.105488,https://riunet.upv.es/bitstream/handle/10251/165764/CHILLAR%c3%93N-P%c3%89REZ%3bQuntana%3bVdal-Gmeno%20-%20Computed%20tomography%20medcalmage%20reconstructon%20on%20affordable%20e....pdf?sequence=7&isAllowed=y,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
326418186,2019-01-01T00:00:00,"International audienceMonitoring animal health worldwide, especially the early detec-tion of outbreaks of emerging pathogens, is one of the means ofpreventing the introduction of infectious diseases in countries(Collier et al., 2008)[3]. In this context, we developed PADI-web, aPlatform for Automated extraction of animal Disease Informationfrom the Web (Arsevska et al., 2016, 2018). PADI-web is a text-mining tool that automatically detects, categorizes and extractsdisease outbreak information from Web news articles. PADI-webcurrently monitors the Web forfive emerging animal infectiousdiseases, i.e., African swine fever, avian influenza including highlypathogenic and low pathogenic avian influenza, foot-and-mouthdisease, bluetongue, and Schmallenberg virus infection. PADI-webcollects Web news articles in near-real time through RSS feeds.Currently, PADI-web collects disease information from GoogleNews because of its international and multiple language coverage.We implemented machine learning techniques to identify therelevant disease information in texts (i.e., location and date of anoutbreak, affected hosts, their numbers and clinical signs). In orderto train the model for Information Extraction (IE) from newsarticles, a corpus in English has been manually labeled by domainexperts. This labeled corpus (Rabatel et al., 2017) is presented inthis data paper",PADI-web corpus: Labeled textual data in animal health domain,10.1016/j.dib.2018.12.063,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
225139215,2019,"Monitoring animal health worldwide, especially the early detec-tion of outbreaks of emerging pathogens, is one of the means ofpreventing the introduction of infectious diseases in countries(Collier et al., 2008)[3]. In this context, we developed PADI-web, aPlatform for Automated extraction of animal Disease Informationfrom the Web (Arsevska et al., 2016, 2018). PADI-web is a text-mining tool that automatically detects, categorizes and extractsdisease outbreak information from Web news articles. PADI-webcurrently monitors the Web forfive emerging animal infectiousdiseases, i.e., African swine fever, avian influenza including highlypathogenic and low pathogenic avian influenza, foot-and-mouthdisease, bluetongue, and Schmallenberg virus infection. PADI-webcollects Web news articles in near-real time through RSS feeds.Currently, PADI-web collects disease information from GoogleNews because of its international and multiple language coverage.We implemented machine learning techniques to identify therelevant disease information in texts (i.e., location and date of anoutbreak, affected hosts, their numbers and clinical signs). In orderto train the model for Information Extraction (IE) from newsarticles, a corpus in English has been manually labeled by domainexperts. This labeled corpus (Rabatel et al., 2017) is presented inthis data paper",PADI-web corpus: Labeled textual data in animal health domain,10.1016/j.dib.2018.12.063,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201193191,2019-03-01T00:00:00,"Medical Cyber-Physical Systems (MCPS) hold the promise of reducing human errors and optimizing healthcare by delivering new ways to monitor, diagnose and treat patients through integrated clinical environments (ICE). Despite the benefits provided by MCPS, many of the ICE medical devices have not been designed to satisfy cybersecurity requirements and, consequently, are vulnerable to recent attacks. Nowadays, ransomware attacks account for 85% of all malware in healthcare, and more than 70% of attacks confirmed data disclosure. With the goal of improving this situation, the main contribution of this paper is an automatic, intelligent and real-time system to detect, classify, and mitigate ransomware in ICE. The proposed solution is fully integrated with the ICE++ architecture, our previous work, and makes use of Machine Learning (ML) techniques to detect and classify the spreading phase of ransomware attacks affecting ICE. Additionally, Network Function Virtualization (NFV) and Software Defined Networking (SDN)paradigms are considered to mitigate the ransomware spreading by isolating and replacing infected devices. Different experiments returned a precision/recall of 92.32%/99.97% in anomaly detection, an accuracy of 99.99% in ransomware classification, and promising detection and mitigation times. Finally, different labelled ransomware datasets in ICE have been created and made publicly available",Intelligent and Dynamic Ransomware Spread Detection and Mitigation in Integrated Clinical Environments,10.3390/s19051114,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426867658,2020-10-01T00:00:00,"Acoustic pollution has been associated with adverse effects on the health and life expectancy of people, especially when noise exposure happens during the nighttime. With over half of the world population living in urban areas, acoustic pollution is an important concern for city administrators, especially those focused on transportation and leisure noise. Advances in sensor and network technologies made the deployment of Wireless Acoustic Sensor Networks (WASN) possible in cities, which, combined with artificial intelligence (AI), can enable smart services for their citizens. However, the creation of such services often requires structured environmental audio databases to train AI algorithms. This paper reports on an environmental audio dataset of 363 min and 53 s created in a lively area of the Barcelona city center, which targeted traffic and leisure events. This dataset, which is free and publicly available, can provide researchers with real-world acoustic data to help the development and testing of sound monitoring solutions for urban environments",BCNDataset: Description and Analysis of an Annotated Night Urban Leisure Sound Dataset,,,,'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440978332,2020-01-01T00:00:00,"BACKGROUND:High-throughput sequencing techniques are used to analyse the diversity of the respiratory microbiota in health and disease. Although extensive data are available regarding bacterial respiratory microbiota, its fungal component remains poorly studied. This is partly due to the technical issues associated with fungal metagenomics analyses. In this study, we compared two DNA extraction protocols and two fungal amplification targets for combined bacterial and fungal targeted amplicon sequencing analyses of the respiratory microbiota. METHODS:Six sputa, randomly selected from routine samples in Mondor Hospital (Creteil, France) and treated anonymously, were tested after bacterial and fungal routine culture. Two of which were spiked with Aspergillus Fumigati and Aspergillus Nigri (105 conidia/mL). After mechanical lysis, DNA was extracted using automated QIAsymphony® extraction (AQE) or manual PowerSoil® MoBio extraction (MPE). DNA yield and purity were compared. DNA extracted from spiked sputa was subjected to (i) real-time PCR for Aspergillus DNA detection and (ii) combined metagenomic analyses targeting barcoded primers for fungal ITS1 and ITS2, and bacterial V1-V2 and V3-V4 16S regions. Amplicon libraries were prepared using MiSeq Reagent V3 kit on Illumina platform. Data were analysed using PyroMIC© and SHAMAN software, and compared with culture results. RESULTS:AQE extraction provided a higher yield of DNA (AQE/MPE DNA ratio = 4.5 [1.3-11]) in a shorter time. The yield of Aspergillus DNA detected by qPCR was similar for spiked sputa regardless of extraction protocol. The extraction moderately impacted the diversity or relative abundances of bacterial communities using targeted amplicon sequencing (2/43 taxa impacted). For fungi, the relative abundances of 4/11 major taxa were impacted and AQE results were closer to culture results. The V1-V2 or V3-V4 and ITS1 or ITS2 targets assessed similarly the diversity of bacterial and fungal major taxa, but ITS2 and V3-V4 detected more minor taxa. CONCLUSION:Our results showed the importance of DNA extraction for combined bacterial and fungal targeted metagenomics of respiratory samples. The extraction protocol can affect DNA yield and the relative abundances of few bacterial but more fungal taxa. For fungal analysis, ITS2 allowed the detection of a greater number of minor taxa compared with ITS1",Combined bacterial and fungal targeted amplicon sequencing of respiratory samples: Does the DNA extraction method matter?,10.1371/journal.pone.0232215,,"[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",'Public Library of Science (PLoS)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
346545484,2018-01-01T00:00:00,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ""VA-assisted ML"". The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly",VIS4ML: an ontology for visual analytics assisted machine learning,,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
352943513,2019-01-01T00:00:00,"The use of machine learning techniques for early diseases diagnosis has attracted the attention of scholars worldwide. Parkinson's Disease (PD) is one of the most common neurological and complicated diseases affecting the central nervous system. Unified Parkinson's Disease Rating Scale (UPDRS) is widely used for tracking PD symptom progression. Motor- and Total-UPDRS are two important clinical scales of PD. The aim of this study is to predict UPDRS scores through analyzing the speech signal properties which is important in PD diagnosis. We take the advantages of ensemble learning and dimensionality reduction techniques and develop a new hybrid method to predict Total- and Motor-UPDRS. We accordingly improve the time complexity and accuracy of the PD diagnosis systems, respectively, by using Singular Value Decomposition (SVD) and ensembles of Adaptive Neuro-Fuzzy Inference System (ANFIS). We evaluate our method on a large PD dataset and present the results. The results showed that the proposed method is effective in predicting PD progression by improving the accuracy and computation time of the disease diagnosis. The method can be implemented as a medical decision support system for real-time PD diagnosis when big data from the patients is available in the medical datasets. Â© 2019 Elsevier Lt",An analytical method for measuring the Parkinson's disease progression: A case on a Parkinson's telemonitoring dataset,,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
299984454,2019-01-01T00:00:00,"Big data, coupled with the use of advanced analytical approaches, such as artificial intelligence (AI), have the potential to improve medical outcomes and population health. Data that are routinely generated from, for example, electronic medical records and smart devices have become progressively easier and cheaper to collect, process, and analyze. In recent decades, this has prompted a substantial increase in biomedical research efforts outside traditional clinical trial settings. Despite the apparent enthusiasm of researchers, funders, and the media, evidence is scarce for successful implementation of products, algorithms, and services arising that make a real difference to clinical care. This article collection provides concrete examples of how “big data” can be used to advance healthcare and discusses some of the limitations and challenges encountered with this type of research. It primarily focuses on real-world data, such as electronic medical records and genomic medicine, considers new developments in AI and digital health, and discusses ethical considerations and issues related to data sharing. Overall, we remain positive that big data studies and associated new technologies will continue to guide novel, exciting research that will ultimately improve healthcare and medicine—but we are also realistic that concerns remain about privacy, equity, security, and benefit to all.Published versio",Beyond the hype of big data and artificial intelligence : building foundations for knowledge and wisdom,10.1186/s12916-019-1382-x,,,'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201207793,2018-08-01T00:00:00,"Introduction
Current approaches to the development and application of predictive studies is inefficient and difficult to reproduce. Thousands of predictive health algorithms have been developed; however, less than 2\% have been assessed outside their original setting and even fewer have been applied and evaluated in practice.



Objectives and Approach
Objective: To develop a standardized workflow for algorithm development, dissemination and implementation.



Existing predictive analytics workflow and open standards were adapted and expanded for health research and health care settings. The approach was designed to work within multidisciplinary teams and to improve research transparency, reproducibility, quality, efficiency and application. Key components include standardized algorithm description files, documentation and code libraries. All libraries and programming packages, which were created for/with open-source software, can be used for a wide range of statistical and machine learning models. Publicly-available repositories contain the algorithms, validation data, R code and other supporting infrastructure.



Results
Algorithm development involves variable pre-specification and documentation of model variables, followed by creation of data preprocessing code to generate model variables from the study dataset. Preprocessing uses algorithm specification documentation and a function library, building upon and integrating with existing algorithms when possible to preventing code duplication. Models are output as a Predictive Modelling Markup Language (PMML) file, a portable industry standard for describing and scoring predictive models. A separate scoring ""engine"" is used to implement PMML-described algorithms in a range of settings, including algorithm validation at other research institutions. Algorithm applications currently include the Project Big Life (www.projectbiglife.ca) online calculators, population, health services and public health planning uses and an algorithm visualization tool. An API permits use of the calculator engine by other organizations.



Conclusion/Implications
Barriers to the implementation of predictive analytics in real-world settings—such as within electronic medical records or decision aid applications—can be mitigated with well described algorithms that are easy to replicate and implement, especially as access to big health data increases and algorithms become increasingly complex",A Data Science Approach to Predictive Analytic Research and Knowledge Translation,10.23889/ijpds.v3i4.797,https://core.ac.uk/download/201207793.pdf,"[{'title': 'International Journal for Population Data Science', 'identifiers': ['issn:2399-4908', '2399-4908']}]",'Swansea University',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201554895,2018-10-01T00:00:00,"Abstract Background Logistic regression is a popular technique used in machine learning to construct classification models. Since the construction of such models is based on computing with large datasets, it is an appealing idea to outsource this computation to a cloud service. The privacy-sensitive nature of the input data requires appropriate privacy preserving measures before outsourcing it. Homomorphic encryption enables one to compute on encrypted data directly, without decryption and can be used to mitigate the privacy concerns raised by using a cloud service. Methods In this paper, we propose an algorithm (and its implementation) to train a logistic regression model on a homomorphically encrypted dataset. The core of our algorithm consists of a new iterative method that can be seen as a simplified form of the fixed Hessian method, but with a much lower multiplicative complexity. Results We test the new method on two interesting real life applications: the first application is in medicine and constructs a model to predict the probability for a patient to have cancer, given genomic data as input; the second application is in finance and the model predicts the probability of a credit card transaction to be fraudulent. The method produces accurate results for both applications, comparable to running standard algorithms on plaintext data. Conclusions This article introduces a new simple iterative algorithm to train a logistic regression model that is tailored to be applied on a homomorphically encrypted dataset. This algorithm can be used as a privacy-preserving technique to build a binary classification model and can be applied in a wide range of problems that can be modelled with logistic regression. Our implementation results show that our method can handle the large datasets used in logistic regression training",Privacy-preserving logistic regression training,10.1186/s12920-018-0398-y,,"[{'title': 'BMC Medical Genomics', 'identifiers': ['1755-8794', 'issn:1755-8794']}]",'Springer Science and Business Media LLC',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201224818,2019-02-01T00:00:00,"Convergence of Machine Learning, Internet of Things, and computationally powerful single-board computers has boosted research and implementation of smart spaces. Smart spaces make predictions based on historical data to enhance user experience. In this paper, we present a low-cost, low-energy smart space implementation to detect static and dynamic human activities that require simple motions. We use low-resolution (4 &#215; 16) and non-intrusive thermal sensors to collect data. We train six machine learning algorithms, namely logistic regression, naive Bayes, support vector machine, decision tree, random forest and artificial neural network (vanilla feed-forward) on the dataset collected in our lab. Our experiments reveal a very high static activity detection rate with all algorithms, where the feed-forward neural network method gives the best accuracy of 99.96%. We also show how data collection methods and sensor placement plays an important role in the resulting accuracy of different machine learning algorithms. To detect dynamic activities in real time, we use cross-correlation and connected components of thermal images. Our smart space implementation, with its real-time properties, can be used in various domains and applications, such as conference room automation, elderly health-care, etc",Static and Dynamic Activity Detection with Ambient Sensors in Smart Spaces,10.3390/s19040804,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
302913733,2019-11-11T00:00:00,"1:  ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations.Weak recommendation, high quality evidence. 2:  ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome.Strong recommendation, high quality evidence. 3:  ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis.Strong recommendation, moderate quality evidence. 4:  ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (≤ 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited.Weak recommendation, high quality evidence. 5:  ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6:  ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7:  ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence",Advanced imaging for detection and differentiation of colorectal neoplasia: European Society of Gastrointestinal Endoscopy (ESGE) Guideline – Update 2019,10.1055/a-1031-7657,,"[{'title': 'Endoscopy', 'identifiers': ['issn:0013-726X', '0013-726x']}]",'Georg Thieme Verlag KG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
352943591,2019-01-01T00:00:00,"Recurrent vulvovaginal candidiasis (RVVC) is a common opportunistic, mucosal fungal infection, predominantly caused by the fungus Candida albicans. Mannose-binding lectin (MBL) is an acute-phase protein that plays a key role in the innate immunity defence against infectious disease. This study was conducted to evaluate the relationship between the MBL serum level and the relative expression of MBL mRNA in RVVC using real-time PCR for the first time. The case-control study included 40 female participants suffering from RVVC and 40 healthy individuals. The MBL serum level was measured using a commercial ELISA kit. The relative mRNA expression of the MBL gene was quantified using real-time PCR. Data analysis was carried out by spss software. The MBL concentration was significantly higher in the participants suffering from RVVC compared to the control group (0.330Â ng/mL vs 0.253Â ng/mL). The prognostic value (PÂ <.001) for RVVC diagnosis has been calculated. Quantitative RT-PCR results from 35 samples showed a low to significant values for mRNA levels corresponding to MBL gene expression (1-352 folds) (PÂ <.001). The results of this study suggest that MBL plays a main role in the innate immunity and it is also affected by environmental factors and other genetic variations. Therefore, the MBL gene expression profile does not reflect precise phenotypic levels in the serum. Â© 2018 Blackwell Verlag Gmb",Is mannose-binding lectin serum concentration a reliable predictor for recurrent vulvovaginal candidiasis?,,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
287732361,2019-12-01T00:00:00,"Accurate detection of pathological conditions in human subjects can be achieved through off-line analysis of recorded biological signals such as electrocardiograms (ECGs). However, human diagnosis is time-consuming and expensive, as it requires the time of medical professionals. This is especially inefficient when indicative patterns in the biological signals are infrequent. Moreover, patients with suspected pathologies are often monitored for extended periods, requiring the storage and examination of large amounts of non-pathological data, and entailing a difficult visual search task for diagnosing professionals. In this work we propose a compact and sub-mW low power neural processing system that can be used to perform on-line and real-time preliminary diagnosis of pathological conditions, to raise warnings for the existence of possible pathological conditions, or to trigger an off-line data recording system for further analysis by a medical professional. We apply the system to real-time classification of ECG data for distinguishing between healthy heartbeats and pathological rhythms. Multi-channel analog ECG traces are encoded as asynchronous streams of binary events and processed using a spiking recurrent neural network operated in a reservoir computing paradigm. An event-driven neuron output layer is then trained to recognize one of several pathologies. Finally, the filtered activity of this output layer is used to generate a binary trigger signal indicating the presence or absence of a pathological pattern. We validate the approach proposed using a Dynamic Neuromorphic Asynchronous Processor (DYNAP) chip, implemented using a standard 180 nm CMOS VLSI process, and present experimental results measured from the chi",Real-Time Ultra-Low Power ECG Anomaly Detection Using an Event-Driven Neuromorphic Processor,10.1109/tbcas.2019.2953001,https://www.zora.uzh.ch/id/eprint/184174/9/1911.05521.pdf,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
483665146,2020-01-01T00:00:00,"An image is worth a thousand words; hence, a face image illustrates extensive details about the speciﬁcation, gender, age, and emotional states of mind. Facial expressions play an important role in community-based interactions and are often used in the behavioral analysis of emotions. Recognition of automatic facial expressions from a facial image is a challenging task in the computer vision community and admits a large set of applications, such as driver safety, human–computer interactions, health care, behavioral science, video conferencing, cognitive science, and others. In this work, a deep-learning-based scheme is proposed for identifying the facial expression of a person. The proposed method consists of two parts. The former one ﬁnds out local features from face images using a local gravitational force descriptor, while, in the latter part, the descriptor is fed into a novel deep convolution neural network (DCNN) model. The proposed DCNN has two branches. The ﬁrst branch explores geo-metric features, such as edges, curves, and lines, whereas holistic features are extracted by the second branch. Finally, the score-level fusion technique is adopted to compute the ﬁnal classiﬁca-tion score. The proposed method along with 25 state-of-the-art methods is implemented on ﬁve benchmark available databases, namely, Facial Expression Recognition 2013, Japanese Female Facial Expressions, Extended CohnKanade, Karolinska Directed Emotional Faces, and Real-world Affective Faces. The data-bases consist of seven basic emotions: neutral, happiness, anger, sadness, fear, disgust, and surprise. The proposed method is compared with existing approaches using four evaluation metrics, namely, accuracy, precision, recall, and f1-score. The obtained results demonstrate that the proposed method outperforms all state-of-the-art methods on all the databases",Facial Expression Recognition Using Local Gravitational Force Descriptor-Based Deep Convolution Neural Networks,,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
440979163,2020-01-01T00:00:00,"Wrong-site surgeries can occur due to the absence of an appropriate surgical time-out. However, during a time-out, surgical participants are unable to review the patient's charts due to their aseptic hands. To improve the conditions in surgical time-outs, we introduce a deep learning-based smart speaker to confirm the surgical information prior to cataract surgeries. This pilot study utilized the publicly available audio vocabulary dataset and recorded audio data published by the authors. The audio clips of the target words, such as left, right, cataract, phacoemulsification, and intraocular lens, were selected to determine and confirm surgical information in the time-out speech. A deep convolutional neural network model was trained and implemented in the smart speaker that was developed using a mini development board and commercial speakerphone. To validate our model in the consecutive speeches during time-outs, we generated 200 time-out speeches for cataract surgeries by randomly selecting the surgical statuses of the surgical participants. After the training process, the deep learning model achieved an accuracy of 96.3% for the validation dataset of short-word audio clips. Our deep learning-based smart speaker achieved an accuracy of 93.5% for the 200 time-out speeches. The surgical and procedural accuracy was 100%. Additionally, on validating the deep learning model by using web-generated time-out speeches and video clips for general surgery, the model exhibited a robust and good performance. In this pilot study, the proposed deep learning-based smart speaker was able to successfully confirm the surgical information during the time-out speech. Future studies should focus on collecting real-world time-out data and automatically connecting the device to electronic health records. Adopting smart speaker-assisted time-out phases will improve the patients' safety during cataract surgeries, particularly in relation to wrong-site surgeries",Deep learning-based smart speaker to confirm surgical sites for cataract surgeries: A pilot study.,10.1371/journal.pone.0231322,,"[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",'Public Library of Science (PLoS)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
333580897,2020-01-01T00:00:00,"In the paper, application of Machine Learning (ML) techniques for the continuous monitoring of the health status of mild mission-critical industrial equipment is considered. A meaningful real-life case-study is presented in order to show how acquisition conditions may severely impact on the performance of the system. In particular, it is shown that a wrong estimate of noise effects in the deployed system may induce a wrong choice of the best features feeding the ML monitoring algorithm, hence affecting accuracy of the target devices. The discussed results may provide an useful guidance to the practitioner in the field during the design phase of ML-based devices depending of the equipment specifications and environmental conditions",Impact of Noise on Machine Learning-based Condition Monitoring Applications: a Case Study,10.1109/i2mtc43012.2020.9129119,,,'Institute of Electrical and Electronics Engineers (IEEE)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
200850496,2019-05-01T00:00:00,"Road transportation is the backbone of modern economies, albeit it annually costs     1.25     million deaths and trillions of dollars to the global economy, and damages public health and the environment. Deep learning is among the leading-edge methods used for transportation-related predictions, however, the existing works are in their infancy, and fall short in multiple respects, including the use of datasets with limited sizes and scopes, and insufficient depth of the deep learning studies. This paper provides a novel and comprehensive approach toward large-scale, faster, and real-time traffic prediction by bringing four complementary cutting-edge technologies together: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). We trained deep networks using over 11 years of data provided by the California Department of Transportation (Caltrans), the largest dataset that has been used in deep learning studies. Several combinations of the input attributes of the data along with various network configurations of the deep learning models were investigated for training and prediction purposes. The use of the pre-trained model for real-time prediction was explored. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for smart cities, big data, high performance computing, and their convergence","Smarter Traffic Prediction Using Big Data, In-Memory Computing, Deep Learning and GPUs",10.3390/s19092206,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201173231,2019-01-01T00:00:00,"Health status checkup is a crucial step towards early detection of diseases. Health status diagnosis, in university health centers, within the sub-Saharan African region, can be cumbersome and time consuming. In many cases, facilities for health checkup are not available. Traditional Chinese Medicine (TCM) is a promising approach, when integrated with in-silico methods. This study was conducted to implement a TCM-based computational health informatics diagnostic tool. The tool was applied to diagnose African students. This study was also conducted to stimulate further research into in-silico TCM diagnostics. Besides developing a reliable biometric verification system, to ascertain the real identities of patients brought to university health centers, it is assistive to create a platform that provides automated and complementary support for preliminary health diagnostic activities. It also mitigates stress, by helping to efficiently decipher and provide quick objective opinion from the perspective of a computerized decision support system. The diagnostic module of the computational health informatics diagnostic tool adopts knowledge from a TCM facial color diagnosis.A comprehensive literature search was conducted for relevant full-text research papers. Only research publications written in English language were reviewed. The present work was compared qualitatively and quantitatively with the existing works noted in the literature. Facial detection and matching algorithms were implemented for the TCM-based computational health informatics diagnostic tool by using Java programming language. Facial image acquisition processes were conducted. Captured facial images of African students were preprocessed. Facial feature extraction was performed by implementing feature extraction algorithms. An algorithm for the extraction of color information and measurement was also implemented. Knowledge of machine learning was applied to extract and collate facial features, and to machine learn from them. Facial classification and recognition algorithms were implemented. Finally, the results from the computational health informatics diagnostic tool were evaluated, by conducting a performance evaluation and validation.This study provides qualitative and quantitative information on facial recognition, facial color information measurement, as well as prediction of health status, for some sub-Saharan African University students. Performance evaluation was shown using confusion matrix and ROC curves. Statistical analysis of the experimental results was presented. The parameters in each diagnostic illustration were shown with valid range. In order to justify the effectiveness of the computational tool, further explanations were provided from relevant methodology guides on the evaluation of diagnostic tests.The computational health informatics diagnostic tool will complement the diagnostic efforts in university health centers of sub-Saharan African universities. It will also be useful for personal health diagnosis of interested individuals. The tool will also be viable for educating health professionals. TCM will be of immense benefit to developing countries by positively contributing towards diagnosing different non-communicable diseases and some infectious diseases in such countries. Keywords: Computational health informatics, Traditional Chinese medicine, Diagnostics, Non-communicable diseases, Infectious diseases, Facial image recognition, Informatic",Implementation of a TCM-based computational health informatics diagnostic tool for Sub-Saharan African students,10.1016/j.imu.2018.12.002,,"[{'title': 'Informatics in Medicine Unlocked', 'identifiers': ['2352-9148', 'issn:2352-9148']}]",'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
288328958,2019-01-01T00:00:00,"The industry is moving towards maintenance strategies that consider component health, which require extensive collection and analysis of data. Condition monitoring methods that require manual feature extraction and analysis, become infeasible on an industrial scale. Machine learning algorithms can be used to automatically detect and classify faults, however, obtaining sufficient data for training is required for deep learning and other data-driven classification approaches. Data from healthy machine operation is generally available in abundance, while data from representative fault- and operating conditions is limited. This limits both development and deployment of deep learning-based CM systems on an industrial scale. This paper addresses both the challenges of automated analysis and lack of training data. A deep learning classifier architecture utilizing 1-dimensional dilated convolutions is proposed. Dilation of the convolution kernel allows for analysis of raw vibration signals while simultaneously maintaining the receptive field of the classifier enough to capture temporal patterns. The proposed method performs classification in time domain on signal segments of 1 second or shorter. With knowledge of the bearing specification, artificial vibration signals with similar characteristics as an actual bearing fault can be created. In this work, generated fault signals are combined with healthy operational data to obtain training data for a deep classifier. Parameters of the vibration model is chosen as distributions rather than fixed values. By using a range parameters in the vibration model, the classifier learns to recognize temporal features from the training data that generalize to unseen data. The effectiveness of the proposed method is demonstrated by training classifiers on generated data and testing on real signals from faulty bearings at both low and high speed. One dataset containing seeded faults and three run-to-failure tests are used for the demonstration.publishedVersio",Simulation-driven Deep Classification of Bearing Faults from Raw Vibration Data,,https://core.ac.uk/download/288328958.pdf,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
370074721,2020-01-01T00:00:00,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions. (C) 2020 The Author(s). Published by Elsevier Ltd.Funding Agencies|National Natural Science Foundation of ChinaNational Natural Science Foundation of China (NSFC) [71971030]; Shaanxi Provincial Natural Science Foundation of China [2019JM-495]; Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities [300102220203]</p",An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,10.1016/j.jclepro.2020.123365,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
200793946,2019-01-01T00:00:00,"Augmented reality (AR) is a new technology. Very few people know about its development, which began in 1970s from massive and primitive devices. Now AR is at the very peak of its improvement in the form of various software. Augmented reality has its application in the following devices: glasses, phones, tablets. Augmented reality works on the basis of two stages: object recognition and marker tracking. Recognition occurs on the basis of machine learning and tracking of markers by finding certain elements or special markers. The analogue of this principle of operation is SLAM technology (Simultaneous Localization and Map Building). But the best results are achieved with the simultaneous use of two technologies. AR is involved in different areas: education, medicine, entertainment, military training. For education, three-dimensional 3D models are used, which are more visual for students and simplify their studies. In entertainment, AR has found a place for itself in various social networks in the form of masks (Snapchat), games (Pokemon GO) and others. In medicine, in addition to training, AR is used to visualize the internal organs of patients. Augmented reality has great potential for development in practical application in everyday life environments because it does not require high hardware characteristics.Дополненная реальность, или AR (augmented reality) – новая технология, развитие которой сейчас мало кому известно. Она начала развитие в 70-х годах прошлого века от массивных и примитивных устройств. Сейчас же находится на самом пике своего совершенствования в виде различных ПО. Дополненная реальность имеет свое применение в следующий устройствах: очки, телефоны, планшеты. AR работает на основе двух этапов: распознавание объектов и отслеживание маркеров. Распознавание происходит на базе машинного обучения, а отслеживание маркеров путем нахождения определенных элементов или специальных маркеров. Аналогом данного принципа работы является технология SLAM. Но наилучшие результаты достигаются при одновременном использовании двух технологий. AR заполняет все больше сфер. Для образования используют объемные 3D модели, которые являются более наглядными для студентов и упрощают их обучение. В развлечениях AR нашло себе место в различных социальных сетях в виде масок (Snapchat), игр (Pokemon GO) и других. В медицине, помимо обучения, AR используют для визуализации внутренних органов пациентов. Дополненная реальность имеет большие возможности для развития в практическом применение в повседневных средах жизни, потому что не требует высоких характеристик аппаратных средств",Дополненная реальность,,http://elar.urfu.ru/bitstream/10995/72058/1/978-5-91256-441-3_2019_082.pdf,,ООО «Издательский Дом «Ажур»,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275674058,2019-12-01T00:00:00,"1:  ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations.Weak recommendation, high quality evidence. 2:  ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome.Strong recommendation, high quality evidence. 3:  ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis.Strong recommendation, moderate quality evidence. 4:  ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (≤ 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited.Weak recommendation, high quality evidence. 5:  ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6:  ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7:  ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence.status: publishe",Advanced imaging for detection and differentiation of colorectal neoplasia: European Society of Gastrointestinal Endoscopy (ESGE) Guideline - Update 2019,10.1055/a-1031-7657,,"[{'title': 'Endoscopy', 'identifiers': ['issn:1438-8812', 'issn:0013-726X', '1438-8812', '0013-726x']}]",'Georg Thieme Verlag KG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
233670749,2019-04-30,"Background: Sepsis is a clinical condition involving an extreme inflammatory response to an infection, and is associated with high morbidity and mortality. Without intervention, this response can progress to septic shock, organ failure and death. Every hour that treatment is delayed mortality increases. Early identification of sepsis is therefore important for a positive outcome.
Methods: We constructed predictive models for sepsis detection and performed a register-based cohort study on patients from four Danish municipalities. We used event-sequences of raw electronic health record (EHR) data from 2013 to 2017, where each event consists of three elements: a timestamp, an event category (e.g. medication code), and a value. In total, we consider 25.622 positive (SIRS criteria) sequences and 25.622 negative sequences with a total of 112 million events distributed across 64 different hospital units. The number of potential predictor variables in raw EHR data easily exceeds 10.000 and can be challenging for predictive modeling due to this large volume of sparse, heterogeneous events. Traditional approaches have dealt with this complexity by curating a limited number of variables of importance; a labor-intensive process that may discard a vast majority of information. In contrast, we consider a deep learning system constructed as a combination of a convolutional neural network (CNN) and long short-term memory (LSTM) network. Importantly, our system learns representations of the key factors and interactions from the raw event sequence data itself.
Results: Our model predicts sepsis with an AUROC score of 0.8678, at 11 hours before actual treatment was started, outperforming all currently deployed approaches. At other prediction times, the model yields following AUROC scores. 15 min: 0.9058, 3 hours: 0.8803, 24 hours: 0.8073.
Conclusion: We have presented a novel approach for early detection of sepsis that has more true positives and fewer false negatives than existing alarm systems without introducing domain knowledge into the model. Importantly, the model does not require changes in the daily workflow of healthcare professionals at hospitals, as the model is based on data that is routinely captured in the EHR. This also enables real-time prediction, as healthcare professionals enters the raw events in the EHR",Early Sepsis Detection with Deep Learning on EHR Event Sequences,10.7146/akut.v2i3.112949,,,Dansk Selskab for Akutmedicin,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
442048635,2020-01-01T00:00:00,"Roll-to-Roll (R2R) processing is a common processing method for flexible photoelectric film materials. Due to the physical properties of the materials, the change in the performance of the R2R processing equipment can easily cause deformation of the flexible film material, it is particularly important to predict the performance degradation of the processing equipment. Based on the accuracy and real-time requirements of performance degradation prediction, a PTS-FNN model for performance degradation prediction was proposed in this paper, which combines the Possibilistic C-Means (PCM) fuzzy clustering and Takagi–Sugeno Fuzzy Neural Network (TS-FNN). We also studied the PCM classification algorithm of input data of PTS-FNN model, the predecessor network of TS-FNN prediction model and the construction method of post-component network. Finally, the implementation process of PCM classification algorithm and TS-FNN prediction model were given. The R2R processing equipment health prediction experiment system was built and the PTS-FNN model experiment was carried out. The experimental results showed that the training time of PTS-FNN model was 50.37% less than the standard TS-FNN prediction model. The prediction accuracy increased by 5.48%, and the PTS-FNN had no error in the judgment of state 1 and state 4",PTS-FNN-Based Health Prediction Method for Flexible Photoelectric Film Material Processing Equipment,10.1155/2020/9232561,,"[{'title': 'Mathematical Problems in Engineering', 'identifiers': ['issn:1024-123X', '1024-123x', '1563-5147', 'issn:1563-5147']}]",'Hindawi Limited',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
387851240,2020-01-01T00:00:00,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions. (C) 2020 The Author(s). Published by Elsevier Ltd.Funding Agencies|National Natural Science Foundation of ChinaNational Natural Science Foundation of China (NSFC) [71971030]; Shaanxi Provincial Natural Science Foundation of China [2019JM-495]; Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities [300102220203]</p",An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,10.1016/j.jclepro.2020.123365,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
401722781,2019-01-01T00:00:00,"Contains fulltext :
                  215384.pdf (publisher's version ) (Closed access)1: ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations.Weak recommendation, high quality evidence. 2: ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome.Strong recommendation, high quality evidence. 3: ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis.Strong recommendation, moderate quality evidence. 4: ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (</= 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited.Weak recommendation, high quality evidence. 5: ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6: ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7: ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence",Advanced imaging for detection and differentiation of colorectal neoplasia: European Society of Gastrointestinal Endoscopy (ESGE) Guideline - Update 2019,10.1055/a-1031-7657,,,'Georg Thieme Verlag KG',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
344303516,2020-05-01T00:00:00,"International audience18F-FDOPA PET has demonstrated its additional value during the clinical course of glioma, at initial diagnosis, for treatment planning or follow-up. The aim of the current review was to summarize current applications of 18F-FDOPA PET in gliomas and constitute, as a perspective, a first step in harmonizing clinical practices in French centers. In France, the indication for 18F-FDOPA PET is restricted to the assessment of primary brain tumor recurrence. According to the literature, this indication could be expanded to primary diagnosis and, to a lesser extent, treatment monitoring. There is a real need to harmonize standard procedures among French centers. The objective is to increase the availability of data for this rare entity of glioma and to develop multi-parametric PET analyses (static, dynamic and textural), also known as radiomics, by using artificial intelligence algorithms. For this purpose, kinetics analysis with dynamic PET acquisition should be implemented in routine practice because it has demonstrated its additional value for initial diagnosis in gliomas. Therefore, this review proposes a workflow based on acquisition and reconstruction parameters that can be implemented in each center to increase the amount of standardized 18F-FDOPA PET data in neuro-oncology imaging in France. This would help in creating a national database and developing national multi-center studies that can respond to the challenge of using multi-parametric PET in glioma",La TEP à la 18F-FDOPA dans les gliomes : applications actuelles et perspectives,10.1016/j.mednuc.2020.02.006,,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
477989381,2020-09-01T00:00:00,"[EN] Falls is one of most concerning accidents in aged population due to its high frequency and serious repercussion; thus, quick assistance is critical to avoid serious health consequences. There are several Ambient Assisted Living (AAL) solutions that rely on the technologies of the Internet of Things (IoT), Cloud Computing and Machine Learning (ML). Recently, Deep Learning (DL) have been included for its high potential to improve accuracy on fall detection. Also, the use of fog devices for the ML inference (detecting falls) spares cloud drawback of high network latency, non-appropriate for delay-sensitive applications such as fall detectors. Though, current fall detection systems lack DL inference on the fog, and there is no evidence of it in real environments, nor documentation regarding the complex challenge of the deployment. Since DL requires considerable resources and fog nodes are resource-limited, a very efficient deployment and resource usage is critical. We present an innovative highly-efficient intelligent system based on a fog-cloud computing architecture to timely detect falls using DL technics deployed on resource-constrained devices (fog nodes). We employ a wearable tri-axial accelerometer to collect patient monitoring data. In the fog, we propose a smart-IoT-Gateway architecture to support the remote deployment and management of DL models. We deploy two DL models (LSTM/GRU) employing virtualization to optimize resources and evaluate their performance and inference time. The results prove the effectiveness of our fall system, that provides a more timely and accurate response than traditional fall detector systems, higher efficiency, 98.75% accuracy, lower delay, and service improvement.This research was supported by the Ecuadorian Government through the Secretary of Higher Education, Science, Technology, and Innovation (SENESCYT) and has received funding from the European Union's Horizon 2020 research and innovation program as part of the ACTIVAGE project under Grant 732679.Sarabia-Jácome, D.; Usach, R.; Palau Salvador, CE.; Esteve Domingo, M. (2020). Highly-efficient fog-based deep learning AAL fall detection system. Internet of Things. 11:1-19. https://doi.org/10.1016/j.iot.2020.100185S11911“World Population Ageing.” [Online]. Available: http://www.un.org/esa/population/publications/worldageing19502050/. [Accessed: 23-Sep-2018].“Falls, ” World Health Organization. [Online]. Available: http://www.who.int/news-room/fact-sheets/detail/falls. [Accessed: 20-Sep-2018].Rashidi, P., & Mihailidis, A. (2013). A Survey on Ambient-Assisted Living Tools for Older Adults. IEEE Journal of Biomedical and Health Informatics, 17(3), 579-590. doi:10.1109/jbhi.2012.2234129Bousquet, J., Kuh, D., Bewick, M., Strandberg, T., Farrell, J., Pengelly, R., … Bringer, J. (2015). Operative definition of active and healthy ageing (AHA): Meeting report. Montpellier October 20–21, 2014. European Geriatric Medicine, 6(2), 196-200. doi:10.1016/j.eurger.2014.12.006“WHO | What is Healthy Ageing?”[Online]. Available: http://www.who.int/ageing/healthy-ageing/en/. [Accessed: 19-Sep-2018].Fei, X., Shah, N., Verba, N., Chao, K.-M., Sanchez-Anguix, V., Lewandowski, J., … Usman, Z. (2019). CPS data streams analytics based on machine learning for Cloud and Fog Computing: A survey. Future Generation Computer Systems, 90, 435-450. doi:10.1016/j.future.2018.06.042W. Zaremba, “Recurrent neural network regularization,” no. 2013, pp. 1–8, 2015.Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780. doi:10.1162/neco.1997.9.8.1735J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of gated recurrent neural networks on sequence modeling,” pp. 1–9, 2014.N. Zerrouki, F. Harrou, Y. Sun, and A. Houacine, “Vision-based human action classification,” vol. 18, no. 12, pp. 5115–5121, 2018.Panahi, L., & Ghods, V. (2018). Human fall detection using machine vision techniques on RGB–D images. Biomedical Signal Processing and Control, 44, 146-153. doi:10.1016/j.bspc.2018.04.014Y. Li, K.C. Ho, and M. Popescu, “A microphone array system for automatic fall detection,” vol. 59, no. 2, pp. 1291–1301, 2012.Taramasco, C., Rodenas, T., Martinez, F., Fuentes, P., Munoz, R., Olivares, R., … Demongeot, J. (2018). A Novel Monitoring System for Fall Detection in Older People. IEEE Access, 6, 43563-43574. doi:10.1109/access.2018.2861331C. Wang et al., “Low-power fall detector using triaxial accelerometry and barometric pressure sensing,” vol. 12, no. 6, pp. 2302–2311, 2016.S.B. Khojasteh and E. De Cal, “Improving fall detection using an on-wrist wearable accelerometer,” pp. 1–28.Theodoridis, T., Solachidis, V., Vretos, N., & Daras, P. (2017). Human Fall Detection from Acceleration Measurements Using a Recurrent Neural Network. IFMBE Proceedings, 145-149. doi:10.1007/978-981-10-7419-6_25F. Sposaro and G. Tyson, “iFall : an android application for fall monitoring and response,” pp. 6119–6122, 2009.A. Ngu, Y. Wu, H. Zare, A.P. B, B. Yarbrough, and L. Yao, “Fall detection using smartwatch sensor data with accessor architecture,” vol. 2, pp. 81–93.P. Jantaraprim and P. Phukpattaranont, “Fall detection for the elderly using a support vector machine,” no. 1, pp. 484–490, 2012.Aziz, O., Musngi, M., Park, E. J., Mori, G., & Robinovitch, S. N. (2016). A comparison of accuracy of fall detection algorithms (threshold-based vs. machine learning) using waist-mounted tri-axial accelerometer signals from a comprehensive set of falls and non-fall trials. Medical & Biological Engineering & Computing, 55(1), 45-55. doi:10.1007/s11517-016-1504-yV. Carletti, A. Greco, A. Saggese, and M. Vento, “A smartphone-based system for detecting falls using anomaly detection,” vol. 6978, 2017, pp. 490–499.Yacchirema, D., de Puga, J. S., Palau, C., & Esteve, M. (2018). Fall detection system for elderly people using IoT and Big Data. Procedia Computer Science, 130, 603-610. doi:10.1016/j.procs.2018.04.11",Highly-efficient fog-based deep learning AAL fall detection system,10.1016/j.iot.2020.100185,https://riunet.upv.es/bitstream/10251/169535/1/Sarabia-JacomeUsachPalau%20-%20Highly-efficient%20fog-based%20deep%20learning%20AAL%20fall%20detection%20system.pdf,,'Elsevier BV',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
389870030,2020-01-01T00:00:00,"One of the most actual and consistent drivers for the industry is sustainability, which includes three main pillars: environment, economics, and society. While numerous methods for environmental and economic sustainability assessment have been proposed, social sustainability assessment is still lacking in structured methods and tools, although human has always played a key role. Moreover, technological development is pushing the industrial world toward a new paradigm, the \u201cIndustry 4.0,\u201d which embeds topics such as data digitalization, cyber-physical systems, and machine learning. It entails significant changes in human resources management, without reducing their importance. Humans were part of the manufacturing system from the first industrial revolution, and no automation or digitalization can be possible without humans. The industry can no longer underestimate the reasonable application of human factors and ergonomics principles to the workplace. For this purpose, the paper provides a novel transdisciplinary engineering method to measure and promote social sustainability on production sites. It exploits Internet of Things technology to support the (re)design of manufacturing processes and plants toward human-centered connected factories. To improve the workers' well-being has positive effects on their health, satisfaction, and performance. The method has been implemented in a real industrial case study within the footwear industry. The sole finishing process has been analyzed from different perspectives to solve ergonomics-related problems and implement effective improvement strategies",A method to improve workers' well-being toward human-centered connected factories,10.1093/jcde/qwaa047,,,'Oxford University Press (OUP)',core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
203885835,2014-02-03,"Prediction and classification techniques have been well studied by machine learning researchers and developed for several real-word problems. However, the level of acceptance and success of prediction models are still below expectation due to some difficulties such as the low performance of prediction models when they are applied in different environments. Such a problem has been addressed by many researchers, mainly from the machine learning community. A second problem, principally raised by model users in different communities, such as managers, economists, engineers, biologists, and medical practitioners, etc., is the prediction models’ interpretability. The latter is the ability of a model to explain its predictions and exhibit the causality relationships between the inputs and the outputs. In the case of classification, a successful way to alleviate the low performance is to use ensemble classiers. It is an intuitive strategy to activate collaboration between different classifiers towards a better performance than individual classier. Unfortunately, ensemble classifiers method do not take into account the interpretability of the final classification outcome. It even worsens the original interpretability of the individual classifiers. In this paper we propose a novel implementation of classifiers combination approach that does not only promote the overall performance but also preserves the interpretability of the resulting model. We propose a solution based on Ant Colony Optimization and tailored for the case of Bayesian classifiers. We validate our proposed solution with case studies from medical domain namely, heart disease and Cardiotography-based predictions, problems where interpretability is critical to make appropriate clinical decisions.",Public Library of Science,Ant Colony Optimization Algorithm for Interpretable Bayesian Classifiers Combination: Application to Medical Predictions,10.1371/journal.pone.0086456,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
80959251,2017-01-01T00:00:00,"Mobile e-health applications provide users and healthcare practitioners with an insightful way to check users/patients’ status and monitor their daily calorie intake. Mobile e-health applications provide users and healthcare practitioners with an insightful way to check users/patients’ status and monitor their daily activities. This paper proposes a cloud-based mobile e-health calorie system that can classify food objects in the plate and further compute the overall calorie of each food object with high accuracy. The novelty in our system is that we are not only offloading heavy computational functions of the system to the cloud, but also employing an intelligent cloud-broker mechanism to strategically and efficiently utilize cloud instances to provide accurate and improved time response results. The broker system uses a dynamic cloud allocation mechanism that takes decisions on allocating and de-allocating cloud instances in real-time for ensuring the average response time stays within a predefined threshold. In this paper, we further demonstrate various scenarios to explain the workflow of the cloud components including: segmentation, deep learning, indexing food images, decision making algorithms, calorie computation, scheduling management as part of the proposed cloud broker model. The implementation results of our system showed that the proposed cloud broker results in a 45% gain in the overall time taken to process the images in the cloud. With the use of dynamic cloud allocation mechanism, we were able to reduce the average time consumption by 77.21% when 60 images were processed in parallel",'Elsevier BV',An intelligent cloud-based data processing broker for mobile e-health multimedia applications,10.1016/j.future.2016.03.019,,"[{'title': 'Future Generation Computer Systems', 'identifiers': ['issn:0167-739X', '0167-739x']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
211369644,2017-11-01T00:00:00,"Accurately detecting and counting sparse bacterial samples has many applications in the food, beverage, and pharmaceutical processing industries, in medical diagnostics, and for life detection by robotic missions to other planets and moons of the solar system. Currently, sparse bacterial samples are counted by culture plating or epifluorescence microscopy. Culture plates require long incubation times (days to weeks), and epifluorescence microscopy requires extensive staining and concentration of the sample. Here, we demonstrate how to use off-axis digital holographic microscopy (DHM) to enumerate bacteria in very dilute cultures (100-104 cells/mL). First, the construction of the custom DHM is discussed, along with detailed instructions on building a low-cost instrument. The principles of holography are discussed, and a statistical model is used to estimate how long videos should be to detect cells, based on the optical performance characteristics of the instrument and the concentration of the bacterial solution (Table 2). Video detection of cells at 105, 104, 103, and 100 cells/mL is demonstrated in real time using un-reconstructed holograms. Reconstruction of amplitude and phase images is demonstrated using an open-source software package",'MyJove Corporation',Quantifying Microorganisms at Low Concentrations Using Digital Holographic Microscopy (DHM),,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
144848064,2016-04-21,"In this paper, we present an architecture for recognizing events related to activities of daily living in the context of a health monitoring environment. The proposed approach explores the integration of a Raspberry PI single-board PC both as an audio acquisition and analysis unit. A set of real-time feature extraction and classification procedures has been implemented and integrated on the Raspberry PI device, in order to provide continuous and online audio event recognition. In addition, a tuning and calibration workflow is presented, according to which the technicians installing the device in a fast ans user-friendly manner, without any requirements for machine learning expertise. The proposed approach has been evaluated against a particular scenario that is rather important in the context of any healthcare monitoring system for the elder, namely the ""bathroom scenario"" according to which a single microphone installed on a Raspberry PI device is used to monitor bathroom activity in a 24/7 basis. Experimental results indicate a satisfactory performance rate on the classification process (around 70% for five bathroom-related audio classes) even when less than two minutes of annotated data are used for training in the installation procedure. This makes the whole procedure non demanding in terms of time and effort needed to be calibrated by the technician",,A Low-cost Approach for Detecting Activities of Daily Living using Audio Information: A Use Case on Bathroom Activity Monitoring,10.5220/0005803700260032,https://core.ac.uk/download/pdf/144848064.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98345401,2016-01-01T00:00:00,"IJMISSP promotes research in machine intelligence/signal processing, highlighting developments in randomised algorithms, deep learning, other learning techniques, sampling theory, transformations and data compression. Besides theory/fundamentals encountered in the main subject area, applications associated with cybersecurity, health sciences, finance and engineering are essential. Design of advanced computational intelligence systems for subtle pattern recognition/discovery, visual data understanding/retrieval, robust face recognition, streaming data processing and intelligent control/software is stressed. Submissions on technology development and real-world applications of complex machine intelligence systems are encouraged",,Editorial Board Member of International Journal of Machine Intelligence and Sensory Signal Processing,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54611646,2015,"Obiettivi: l’integrazione tra servizi sanitari e servizi socio-assistenziali è uno dei temi più rilevanti per l’amministrazione comunale di Cagliari che sta realizzando alcuni interventi di recupero funzionale di immobili dismessi in quartieri con particolari problematiche socio-economiche per creare Strutture Sanitarie Integrate denominate “Centri di salute”, rivolte in particolare modo agli anziani, ma capaci di avere ricadute sull’intera struttura sociale di riferimento.

Metodi: gli strumenti utilizzati sono quelli della pianificazione strategica e degli investimenti territoriali integrati, secondo una logica di intervento sulla struttura fisica della città coerente con la struttura demografica dei residenti e quindi capace di rispondere ai bisogni reali degli abitanti. I quartieri scelti per la sperimentazione sono “zone di margine” caratterizzati da una condizione di segregazione sociale e spaziale. Il modello di gestione è quello della medicina di iniziativa con intervento proattivo basato sulla partecipazione e coinvolgimento delle persone.

Risultati: i primi risultati mettono in evidenza che l’intervento messo in atto si presta particolarmente al coinvolgimento della popolazione anziana emarginata, che per presenza di barriere sociali, economiche, culturali ed ambientali, sottoutilizza o non si rivolge ai servizi di cura. Inoltre, alle azioni specifiche su target predefinito (ultra 70enni) vengono affiancate attività di promozione sociale del valore della salute e della cultura della responsabilità all’auto-cura individuale e collettiva.Objectives: the integration of health and social services is one of the most important issues for the municipal amministration of Cagliari which is building, restoration of functional abandoned buildings in neighborhoods with particular socio-economic problems to create Integrated Medical Information referred to as “health centers”, aimed particularly so for the elderly, but capable of having repercussions on the entire social structure of reference.

Methods: the instruments used are the strategic planning and investment territorial integrated, according to a logic of intervention on the physical structure of the city in line with the demographic structure of the residents and therefore able to respond to the real needs of the inhabitants. The districts chosen for testing are “marginal areas” characterized by a state of social and spatial segregation. The management model is one of medicine’s initiative with proactive intervention based on parteciapzione and involvement of people.

Results: the first results show that the intervention implemented is particularly the involvement of the elderly marginalized, that the presence of barriers to social, economic, and environmental culturalie, does not use care services. In addition, specific actions on target default (over 70years) are flanked promotion of social avlore health and culture of responsibility to self-care individual and collective",,Strategie e progettualità per Cagliari Città per la salute = Planning and strategies and for Cagliari Healthy City,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
160081036,2017-09-18T00:00:00,"Conference of European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017 ; Conference Date: 18 September 2017 Through 22 September 2017; Conference Code:209269International audienceWe present WHODID: a turnkey intuitive web-based interface for fault detection, identification and diagnosis in production units. Fault detection and identification is an extremely useful feature and is becoming a necessity in modern production units. Moreover, the large deployment of sensors within the stations of a production line has enabled the close monitoring of products being manufactured. In this context, there is a high demand for computer intelligence able to detect and isolate faults inside production lines, and to additionally provide a diagnosis for maintenance on the identified faulty production device, with the purpose of preventing subsequent faults caused by the diagnosed faulty device behavior. We thus introduce a system which has fault detection, isolation, and identification features, for retrospective and on-the-fly monitoring and maintenance of complex dynamical production processes. It provides real-time answers to the questions: "" is there a fault? "" , "" where did it happen? "" , "" for what reason? "". The method is based on a posteriori analysis of decision sequences in XGBoost tree models, using recurrent neural networks sequential models of tree paths. The particularity of the presented system is that it is robust to missing or faulty sensor measurements, it does not require any modeling of the underlying, possibly exogenous manufacturing process, and provides fault diagnosis along with confidence level in plain English formulations. The latter can be used as maintenance directions by a human operator in charge of production monitoring and control",'Springer Science and Business Media LLC',"WHODID: Web-based interface for Human-assisted factory Operations in fault Detection, Identification and Diagnosis",10.1007/978-3-319-71273-4_47,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
299976972,2014-01-01T00:00:00,"Machine health condition (MHC) prediction is useful for preventing unexpected failures and minimizing overall maintenance costs in condition-based maintenance. The neural network (NN)-based data-driven method has been considered to be promising for MHC prediction due to the adaptability, nonlinearity and universal approximation capability of NNs. This paper presents an online MHC prediction approach using online dynamic fuzzy NNs (OD-FNNs) with structure and parameters learning. To meet the requirement of real-time application, the original OD-FNN is simplified based on an extreme learning machine technique as follows: (1) initial fuzzy rules are randomly generated without the knowledge of training data; (2) fuzzy rules are added and pruned uniformly by fired strength-based criteria; (3) antecedent parameters are fixed after generation so that only consequent parameters are updated online. The modified OD-FNN is particularly suitable for MHC prediction since: (1) fuzzy rules can evolve as new training datum arrives, which enables us to cope with non-stationary processes in MHC; (2) learning mechanisms applied are simple and efficient for real-time implementation. The validity and superiority of the proposed MHC prediction approach has been evaluated by real-world monitoring data from the accelerated bearing life.ASTAR (Agency for Sci., Tech. and Research, S’pore",'Elsevier BV',Machine health condition prediction via online dynamic fuzzy neural networks,10.1016/j.engappai.2014.05.015,,"[{'title': 'Engineering Applications of Artificial Intelligence', 'identifiers': ['issn:0952-1976', '0952-1976']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
203947776,2015-04-21,"To evaluate the feasibility and effectiveness of dried blood spots (DBS) use for viral load (VL) monitoring, describing patient outcomes and programmatic challenges that are relevant for DBS implementation in sub-Saharan Africa.We recruited adult antiretroviral therapy (ART) patients from five district hospitals in Malawi. Eligibility reflected anticipated Ministry of Health VL monitoring criteria. Testing was conducted at a central laboratory. Virological failure was defined as >5000 copies/ml. Primary outcomes were program feasibility (timely result availability and patient receipt) and effectiveness (second-line therapy initiation).We enrolled 1,498 participants; 5.9% were failing at baseline. Median time from enrollment to receipt of results was 42 days; 79.6% of participants received results within 3 months. Among participants with confirmed elevated VL, 92.6% initiated second-line therapy; 90.7% were switched within 365 days of VL testing. Nearly one-third (30.8%) of participants with elevated baseline VL had suppressed (<5,000 copies/ml) on confirmatory testing. Median period between enrollment and specimen testing was 23 days. Adjusting for relevant covariates, participants on ART >4 years were more likely to be failing than participants on therapy 1–4 years (RR 1.7, 95% CI 1.0-2.8); older participants were less likely to be failing (RR 0.95, 95% CI 0.92-0.98). There was no difference in likelihood of failure based on clinical symptoms (RR 1.17, 95% CI 0.65-2.11).DBS for VL monitoring is feasible and effective in real-world clinical settings. Centralized DBS testing may increase access to VL monitoring in remote settings. Programmatic outcomes are encouraging, especially proportion of eligible participants switched to second-line therapy",Public Library of Science,Dried Blood Spots for Viral Load Monitoring in Malawi: Feasible and Effective,10.1371/journal.pone.0124748,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
161140829,2014-02-03,"Prediction and classification techniques have been well studied by machine learning researchers and developed for several real-word problems. However, the level of acceptance and success of prediction models are still below expectation due to some difficulties such as the low performance of prediction models when they are applied in different environments. Such a problem has been addressed by many researchers, mainly from the machine learning community. A second problem, principally raised by model users in different communities, such as managers, economists, engineers, biologists, and medical practitioners, etc., is the prediction models’ interpretability. The latter is the ability of a model to explain its predictions and exhibit the causality relationships between the inputs and the outputs. In the case of classification, a successful way to alleviate the low performance is to use ensemble classiers. It is an intuitive strategy to activate collaboration between different classifiers towards a better performance than individual classier. Unfortunately, ensemble classifiers method do not take into account the interpretability of the final classification outcome. It even worsens the original interpretability of the individual classifiers. In this paper we propose a novel implementation of classifiers combination approach that does not only promote the overall performance but also preserves the interpretability of the resulting model. We propose a solution based on Ant Colony Optimization and tailored for the case of Bayesian classifiers. We validate our proposed solution with case studies from medical domain namely, heart disease and Cardiotography-based predictions, problems where interpretability is critical to make appropriate clinical decisions.",Public Library of Science,Ant Colony Optimization Algorithm for Interpretable Bayesian Classifiers Combination: Application to Medical Predictions,10.1371/journal.pone.0086456,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
151089656,2016-01-01T00:00:00,"Telepresence Mobile Robots have prominent attributes in many fields as it provides virtual presence for human robot interaction. The deployment of this robot in healthcare sector has improved patient care and health. The vision system in a telepresence robot allows two way audiovisual communication between people at different location. In spite of such advancement, the manual way of controlling a robot to recognise and track people during an emergency is not favourable for a long duration. To circumvent this problem, biometric method using human face is proposed in this research which is implemented on Medical Telediagnosis Robot. This paper details the design of the face recognition and tracking system with four automated modules which are motion detection, face detection, face recognition and face tracking. The modules are developed with different algorithm and tested individually to ensure the stability of the system. Artificial Intelligence technique was applied at the face recognition stage while a two degree of freedom mechanism for actuator control was used at face tracking stage. A sequential mode operation is proposed to reduce the execution time in a real-time environment. To achieve this, only one module is operated at each time. A Graphical User Interface was developed to ease the users at the local and robot environment. The system is designed in LabVIEW platform. The biometric system proposed with hybrid algorithm at each module adapts for face images detected at different distances, poses and lighting condition. This system was tested in real-time and has an execution time of 55ms and 98% accuracy. The stand alone system designed for Medical Telediagnosis Robot can be will be very fruitful for various biometric system using facial technology",,Towards real-time visual biometric authentication using human face for healthcare telepresence mobile robots,,https://core.ac.uk/download/151089656.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
200007837,2015-01-01T00:00:00,"International audienceIn this article, we propose a deep neural network (DNN) architecture called Input Output Deep Architecture (IODA) for solving the problem of image labeling. IODA directly links a whole image to a whole label map, assigning a label to each pixel using a single neural network forward step. Instead of designing a handcrafted a priori model on labels (such as an atlas in the medical domain), we propose to automatically learn the dependencies between labels. The originality of IODA is to transpose DNN input pre-training trick to the output space, in order to learn a high level representation of labels. It allows a fast image labeling inside a fully neural network framework, without the need of any preprocessing such as feature designing or output coding. In this article, IODA is applied on both a toy texture problem and a real-world medical image dataset, showing promising results. We provide an open source implementation of IODA 12 ",'Elsevier BV',IODA: An input/output deep architecture for image labeling,10.1016/j.patcog.2015.03.017,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
202153885,2017-02-28,"AbstractA large part of the biomedical research spectrum is dedicated to develop electrocardiogram (ECG) signal processing techniques to contribute to early diagnosis. However, it is common to find that ECG analysis methods reported are confined to off-line PC host operation. The authors present an arrhythmia classification method implemented on a Digital Signal Processing (DSP) platform intended for on-line, real-time ambulatory operation to classify eight heartbeat conditions: normal sinus rhythm (N), auricular fibrillation (AF), premature atrial contraction (PAC), left bundle branch block (LBBB), right bundle branch block (RBBB), premature ventricular contraction (PVC), sinoauricular heart block (SHB) and supraventricular tachycardia (SVT). The algorithm uses a wavelet transform process based on quadratic wavelets for identifying individual ECG waves and obtain a fiducial marker array. Classification is conducted by means of a Probabilistic Neural Network. The algorithm is tested with 17 ECG records obtained from the PhysioNet repository. The proposed classification procedure was tested initially on MATLAB and the results where compared with the equivalent analogue data fed to a DSP-based ECG data acquisition prototype through an arbitrary waveform generator. The results derived from confusion matrix tests yielded on-line classification accuracy of 92.69% (AF), 97.15% (N), 76.82% (PAC), 91.06% (LBBB), 87.5% (RBBB), 71.04% (PVC), 91.94% (SHB) and 95.45% (SVT), overall classification rate of 92.746% and 100% agreement between the MATLAB and on-line DSP implementations. The results suggest that the method and prototype presented may be suitable for being implemented on wearable sensing applications auxiliary for on-line, real-time diagnosis",The Authors. Published by Elsevier Ltd.,DSP-based arrhythmia classification using wavelet transform and probabilistic neural network ,10.1016/j.bspc.2016.10.005,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
202876581,2013-12-31,AbstractWe developed a levee health monitoring system within the UrbanFlood project funded under the EU 7th Framework Programme. A novel real-time levee health assessment Artificial Intelligence system is developed using data-driven methods. The system is implemented in the UrbanFlood early warning system. We present the application of dedicated signal processing methods for detection of leakage through the water retaining dam and subsequent analysis of the measurements collected from one of the UrbanFlood pilot levees at the Rhine river in Germany,The Authors. Published by Elsevier B.V.,An Approach for Real-time Levee Health Monitoring Using Signal Processing Methods ,10.1016/j.procs.2013.05.407,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
323528435,2017-01-01T00:00:00,"Стаття висвітлює проблеми розробки універсальних та адаптивних систем аналізу даних. На прикладі побудови біомедичних систем моніторингу стану здоров’я людини виділені основні принципи, притаманні системам, які аналізують мультимодальні дані. До основних невирішених проблем створення адаптивних систем можна віднести необхідність переконфігурації системи в залежності від вхідної задачі. Для розв’язання задач переконфігурації була запропонована архітектура адаптивної системи аналізу даних. Особливістю запропонованої системи є дворівнева архітектура: незалежна референсна система та підсистема, яка відповідає за адаптивну роботу.The development of adaptive system has been researched for a decade, but only recently machine learning problems became solvable. In this paper is presented an overview of current smart systems and the problem of development real adaptive and versatile data analysis system. Such system has to analyze multivariate signals of different nature. That is why the overview part is based on examples of biomedical human health monitoring systems (BHMS). BHMS have complex internal structure, to simplify it can be divided into three big tiers: tier of data acquisition, communication and analytics tiers. In the first tier, all data acquisition steps are made, including placement sensors to the specific location. The communication tier is responsible for gathering data from all available hardware and send it via wireless channel to the third layer. The analytical tier is the final destination of acquired data. This layer includes all algorithms which will be used for processing data and interpretation of the results. Such simple division allow us to specify and select our potential field of study and improvements. Specifically, in this paper the analytics tier will be explored and new system architecture will be proposed.
The crucial step in the adaptive systems development is solving reconfiguration problem. Nowadays, almost all data analysis systems have specific applicable fields. The main advantages of the latter are that they are robust, fast, but the development of such system can take a lot of time and reconfiguration of currently used systems will allow speed up that process. The reconfiguration is process of creation a specific targeting system from general system setup or currently known system. In this paper we have investigated problems, related with reconfiguration and proposing the theoretical basis for creation the reconfigurable adaptive system. The output structure is two-tier system, which allow to analyze any task from different field of study and then process it in a single setup. Each of the tier is considered as independent components, however the combination of the general reference system (tier one) and training agent subsystem (tier two) creates a highly adaptive system with reconfiguration properties. The reference system itself is a big storage of available algorithms which can be applied for certain problem and the algorithms workflow can be tuned for specific problem. Such adjustments can be made because of system training agent, which main purpose is to process input task and defined which algorithms can be applied. Such task classification problem can be solved by using machine learning algorithms.
Since, this paper presents only theoretical basis there is no precise implementation of proposed system. Currently we just gave a small overview of the future development of adaptive and reconfigurable systems.В данной работе были исследованы проблемы разработки универсальных и адаптивных систем анализа данных. На примере построения биомедицинских систем мониторинга состояния здоровья человека были выделены основные особенности работы и построения систем, которые анализируют мультимодальные данные. К основным нерешенным проблемам создания адаптивных систем можно отнести необходимость переконфигурирования системы под входную задачу. Для решения задач переконфигурации была предложена теоретическая стратегия построения адаптивной системы анализа данных. Особенностью предложенной системы является двухуровневая архитектура: независимая референсная система и подсистема, отвечающая за адаптивную работу",'Kyiv Politechnic Institute',Reference system architecture for biomedical data analysis,10.20535/2523-4455.2017.22.5.92607,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
33499577,2015-01-01T00:00:00,"There is an increasing need in biology and clinical medicine to robustly and reliably measure tens-to-hundreds of peptides and proteins in clinical and biological samples with high sensitivity, specificity, reproducibility and repeatability. Previously, we demonstrated that LC-MRM-MS with isotope dilution has suitable performance for quantitative measurements of small numbers of relatively abundant proteins in human plasma, and that the resulting assays can be transferred across laboratories while maintaining high reproducibility and quantitative precision. Here we significantly extend that earlier work, demonstrating that 11 laboratories using 14 LC-MS systems can develop, determine analytical figures of merit, and apply highly multiplexed MRM-MS assays targeting 125 peptides derived from 27 cancer-relevant proteins and 7 control proteins to precisely and reproducibly measure the analytes in human plasma. To ensure consistent generation of high quality data we incorporated a system suitability protocol (SSP) into our experimental design. The SSP enabled real-time monitoring of LC-MRM-MS performance during assay development and implementation, facilitating early detection and correction of chromatographic and instrumental problems. Low to sub-nanogram/mL sensitivity for proteins in plasma was achieved by one-step immunoaffinity depletion of 14 abundant plasma proteins prior to analysis. Median intra- and inter-laboratory reproducibility was <20%, sufficient for most biological studies and candidate protein biomarker verification. Digestion recovery of peptides was assessed and quantitative accuracy improved using heavy isotope labeled versions of the proteins as internal standards. Using the highly multiplexed assay, participating laboratories were able to precisely and reproducibly determine the levels of a series of analytes in blinded samples used to simulate an inter-laboratory clinical study of patient samples. Our study further establishes that LC-MRM-MS using stable isotope dilution, with appropriate attention to analytical validation and appropriate quality c`ontrol measures, enables sensitive, specific, reproducible and quantitative measurements of proteins and peptides in complex biological matrices such as plasma",'American Society for Biochemistry & Molecular Biology (ASBMB)',"Large-scale inter-laboratory study to develop, analytically validate and apply highly multiplexed, quantitative peptide assays to measure cancer-relevant proteins in plasma",10.1074/mcp.M114.047050,https://core.ac.uk/download/33499577.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275635798,2017-01-01T00:00:00,"[EN] Wellness state is affected by the habitability state of the domestic environment. Monitoring it can help to discover the causes of a low wellness levels aiding people in the improvement of their quality of life. In this paper, we propose a system to monitor the wellness state of people utilizing Likert¿s scale to determine the state of the user through an emoticon-based human¿computer interaction. The system is intended for domestic environments and measures the habitability conditions of the dwelling (such as temperature, humidity, luminosity and noise) employing sensors. An algorithm is designed in order to establish how to measure those conditions and to calculate the statistics that allows tracking their progress. The obtained information is presented to the user to compare his/her wellness state with the habitability conditions. Measures in a real domestic environment were performed in order to determine the configuration of our system. The energy efficiency of the algorithm provides an improvement between 99.36 and 99.62% in the energy consumption depending on the selected parameters.This work has been partially supported by the “Ministerio de Ciencia e Innovación”, through the “Plan Nacional de I+D+i 2008–2011” and by the “Ministerio de Educación, Cultura y Deporte”, through the grand “Ayudas para contratos predoctorales de Formación del Profesorado Universitario FPU14/02953”.García-García, L.; Parra-Boronat, L.; Romero Martínez, JO.; Lloret, J. (2017). System for monitoring the wellness state of people in domestic environments employing emoticon-based HCI. The Journal of Supercomputing. 1-25. https://doi.org/10.1007/s11227-017-2214-4S125Sendra S, Parra L, Lloret J, Tomás J (2017) Smart system for children’s chronic illness monitoring. Inf Fusion 40:76–86Lloret J, Parra L, Taha M, Tomás J (2017) An architecture and protocol for smart continuous eHealth monitoring using 5G. Comput Netw. https://doi.org/10.1016/j.comnet.2017.05.018 (in press)Hettler B (1976) The six dimensions of wellness. National Wellness Institute. http://c.ymcdn.com/sites/www.nationalwellness.org/resource/resmgr/docs/sixdimensionsfactsheet.pdf . Accessed 12 Dec 2017Dunn HL (1959) What high-level wellness means. Can J Public Health 50(11):447–457Herbes DJ, Mulder CH (2016) Housing and subjective well-being of older adults in Europe. J Hous Built Environ. https://doi.org/10.1007/s10901-016-9526-1OECD (2015) How’s life? measuring well-being. http://www.oecd-ilibrary.org/economics/how-s-life_23089679;jsessionid=55pjippucpjrq.x-oecd-live-02 . Accessed 12 Dec 2017Donaldson GC, Seemungal T, Jeffries DJ, Wedzicha JA (1999) Effect of temperature on lung function and symptoms in chronic obstructive pulmonary disease. Eur Respir J ERS 13(4):844–849Schwartz J, Samet J, Patz J (2004) Hospital admissions for heart disease: the effects of temperature and humidity. Epidemiology 15(6):755–761National Institute of Statistics of Spain (2005) Defunciones según causa de muerte en 2003. http://www.ine.es/prensa/np393.pdf . Accessed 12 Dec 2017Grimes A, Denne T, Howden-Dhapman P, Arnold R, Telfar-Barnard L, Preval N, Young C (2012) Cost benefit analysis of the warm up New Zealand: heat smart programme. University of Wellington, Wellington. http://sustainablecities.org.nz/wp-content/uploads/NZIF_CBA_report2.pdf . Accessed 12 Dec 2017Martínez-Pérez B, de la Torre-Díez I, Candelas-Plasencia S, López-Coronado M (2013) Developement and evaluation of tools for measuring the quality of experience (QoE) in mHealth applications. J Med Syst 37(5):9976Walther JB, D’addario KP (2001) The impacts of emotions on message interpretation in computer-mediated communication. Soc Sci Comput Rev 19(3):324–347Ghayvat H, Liu J, Mukhopadhay SC, Gui X (2015) Wellness sensor networks: a proposal and implementation for smart home for assisted living. IEEE Sens J 15(12):7341–7348Forkan ARM, Hu W (2016) A context-aware, predictive and protective approach for wellness monitoring of cardiac patients. In: Computing in Cardiology Conference, Vancouver, Canada, pp 369–372Booc CER, San Diego CMD, Tee ML, Caro JDL (2016) A mobile application for campus-based psychosocial wellness program. In: 7th International Conference on Information, Systems and Applications, Chalkidiki, Greece, pp 1–4Khan WA, Idris M, Ali T, Ali R, Hussain S, Hussain M, Amin MB, Khattak AM, Weiwei Y, Afzal M, Lee S, Kang BH, (2015) Correlating health and wellness analytics for personalized decision making. Boston, USA, pp 256–261Lim C, Kim ZM, Choi H (2017) Context-based healthy lifestyle recommendation for enhancing user’s wellness. In: IEEE International Conference on Big Data and Smart Computing, Jeju, South Korea, pp 418–421Tulu B, Strong D, Wang L, He Q, Agu E, Pedersen P, Djamasbi S (2016) Design implications of user experience studies: the case of a diabetes wellness app. In: 49th Hawaii International Conference on System Sciences, Koloa, USA, pp 3473–3482Kaur D, Siddaraju GS (2016) Experimental study of cardiac functionality for the wellness of individual by developing an android application. In: International Conference on Computation System and Information Technology for Sustainable Solutions, Bangalore, India, pp 174–183Arshad A, Khan S, Alam AHMZ, Tasnim R, Boby RI (2016) Health and wellness monitoring of elderly people using intelligent sensing technique. In: International Conference on Computer and Communications Engineering, Kuala Lumpur, Malaysia, pp 231–235Martin CJ, Platt SD, Hunt SM (1987) Housing conditions and ill health. Br Med J (Clin Res Ed) 294(6580):1125–1127Evans GW, Wells NM, Moch A (2003) Housing and mental health: a review of the evidence and a methodological and conceptual critique. J Soc Issues 59(3):475–500Shaw M (2004) Housing and public health. Annu Rev Public Health 25:397–418Thomson H, Thomas S (2015) Developing empirically supported theories of change for housing investment and health. Soc Sci Med 124:205–214Gustafson CJ, Feldman SR, Quandt SA, Isom S, Chem H, Spears CR, Arcury TA (2014) The association of skin conditions with housing conditions among North Carolina Latino migrant farm workers. Int J Dermatol 53(9):1091–1097Laquesta R, Garcia L, Garcia-Magarino I, Lloret J (2017) System to recommend the best place to life based on wellness state of the user employing the heart rate variability. IEEE Access 5:10594–10604Isiaka F, Mwitondi K, Ibrahim A (2015) Automatic prediction and detection of affect state based on invariant human computer interaction and human physiological response. In: Seventh International Conference on Computational Intelligence, Modelling and Simulation, Kuantan, Malaysia, pp 19–25Han S, Liu R, Zhu C, Soo YG, Yu H, Liu T, Duan F (2016) Development of a human computer interaction system based on multi-modal gaze tracking methods. In: IEEE International Conference on Robotics and Biomimetics, Qingdao, China, pp 1894–1899Chen B, Huang S, Tsai W (2017) Eliminating driving distractions: human–computer interaction with built-in applications. IEEE Veh Technol Mag 12(1):20–29Kamal S, Sayeed F, Rafeeq M (2016) Facial emotion recognition for human–computer interactions using hybrid feature extraction technique. In: International Conference on Data Mining and Advanced Computing, Ernakulam, India, pp 180–184Agrawal R, Gupta N (2016) Real time hand gesture recognition for human computer interaction. In: IEEE 6th International Conference on Advanced Computing, Bhimavaram, India, pp 470–475Sánchez CS, Mavrogianni A, González FJN (2017) On the minimal thermal habitability conditions in low income dwellings in Spain for a new definition of fuel poverty. Build Environ 114:344–356Ministry of Health, Social Services and Equality of Spain (2015) Plan Nacional de Actuaciones Preventivas de los Efectos del Exceso de Temperaturas Sobre la Salud. http://www.msssi.gob.es/ciudadanos/saludAmbLaboral/planAltasTemp/2015/docs/Plan_Nacional_de_Exceso_de_Temperaturas_2015.pdf . Accessed 12 Dec 2017Bornehag CG, Blomquist G, Gyntelberg F, Järvholm B, Malmberg P, Nordvall L, Nielsen A, Pershagen G, Sundell J (2001) Dampness in buildings and health. Indoor Air 11(2):72–86Garret MH, Rayment PR, Hooper MA, Abramson MJ, Hooper BM (1997) Indoor airborne fungal spores, house dampness and associations with environmental factors and respiratory health in children. Clin Exp Allergy 28:459–467Ariës MBC, Zonneveldt L (2004) Architectural aspects of healthy lighting. In: 21th Conference on Passive and Low Energy Architecture, The Netherlands, pp 1–5Boubekri M, Cheung IN, Reid KJ, Wang C, Zee PC (2014) Impact of windows and daylight exposure on overall health and sleep quality of office workers: a case-control pilot study. J Clin Sleep Med 10(6):603–611Beute F, de Kort YAW (2014) Salutogenic effects of the environments: review of health protective effects of nature and daylight. Appl Psychol Health Well Being 6(1):67–95Boyce P, Hunter C, Howlett O (2003) The benefits of daylight through windows. Rensselaer Polytechnic Institute, TroyHoogendijk WJG, Lips P, Dik MG, Deeg DJH, Beekman ATF, Penninx BWJH (2008) Depression is associated with decreased 25-hydroxyvitamin D and increased parathyroid hormone levels in older adults. Arch Gen Psychiatry 65(5):508–512Ising H, Kruppa B (2004) Health effects caused by noise: evidence in the literature from the past 25 years. Noise Health 6(22):5–13Sandra S, Lloret J, Garcia M, Toledo JF (2011) Power saving and energy optimization techniques for wireless sensor networks. J Commun 6(6):439–459Heinzelman WR, Chandrakasan A, Balakrishnan H (2000) Energy-efficient communication protocol for wireless microsensor networks. In: Proceedings of the IEEE 33rd Annual Hawaii International Conference on System Sciences, Maui, HawaiiKaps JP, Sunar B (2006) Energy comparison of AES and SHA-1 for ubiquitous computing. In: Proceedings of the EUC 2006 Workshops: NCUS, SecUbiq, USN, TRUST, ESO, and MSA, Seoul, KoreaParra L, Sendra S, Jiménez JM, Lloret J (2016) Multimedia sensors embedded in smartphones for ambient assisted living and e-health. Multimed Tools Appl 75(21):13271–1329",'Springer Science and Business Media LLC',System for monitoring the wellness state of people in domestic environments employing emoticon-based HCI,10.1007/s11227-017-2214-4,https://riunet.upv.es/bitstream/10251/102349/2/System%20for%20monitoring%20the%20wellness%20state%20of%20people_v11.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275634127,2017-01-01T00:00:00,"[EN] In this paper, we describe a new low-cost and portable electronic nose instrument, the Multisensory Odor Olfactory System MOOSY4. This prototype is based on only four metal oxide semiconductor (MOS) gas sensors suitable for IoT technology. The system architecture consists of four stages: data acquisition, data storage, data processing, and user interfacing. The designed eNose was tested with experiment for detection of volatile components in water pollution, as a dimethyl disulphide or dimethyl diselenide or sulphur. Therefore, the results provide evidence that odor information can be recognized with around 86% efficiency, detecting smells unwanted in the water and improving the quality control in bottled water factories.This work was supported by the I+D+i Program of the Generalitat Valenciana, Spain [AICO/2016/046], and the II Program UPV-La Fe [2013/0504].Climent-Martí, E.; Pelegrí Sebastiá, J.; Sogorb Devesa, T.; Talens-Felis, J.; Chilo, J. (2017). Development of the MOOSY4 eNose IoT for Sulphur-Based VOC Water Pollution Detection. Sensors. 17(8):1-10. https://doi.org/10.3390/s17081917S110178Babovic, Z. B., Protic, J., & Milutinovic, V. (2016). Web Performance Evaluation for Internet of Things Applications. IEEE Access, 4, 6974-6992. doi:10.1109/access.2016.2615181Getting Startedhttps://docs.smartcitizen.me/#/start/detailed-specificationsXu, L. D., He, W., & Li, S. (2014). Internet of Things in Industries: A Survey. IEEE Transactions on Industrial Informatics, 10(4), 2233-2243. doi:10.1109/tii.2014.2300753Huang, J., Meng, Y., Gong, X., Liu, Y., & Duan, Q. (2014). A Novel Deployment Scheme for Green Internet of Things. IEEE Internet of Things Journal, 1(2), 196-205. doi:10.1109/jiot.2014.2301819Gardner, J. W., & Bartlett, P. N. (1994). A brief history of electronic noses. Sensors and Actuators B: Chemical, 18(1-3), 210-211. doi:10.1016/0925-4005(94)87085-3Gardner, J. W., & Bartlett, P. N. (1996). Performance definition and standardization of electronic noses. Sensors and Actuators B: Chemical, 33(1-3), 60-67. doi:10.1016/0925-4005(96)01819-9Wilson, A., & Baietto, M. (2009). Applications and Advances in Electronic-Nose Technologies. Sensors, 9(7), 5099-5148. doi:10.3390/s90705099Jia, X.-M., Meng, Q.-H., Jing, Y.-Q., Qi, P.-F., Zeng, M., & Ma, S.-G. (2016). A New Method Combining KECA-LDA With ELM for Classification of Chinese Liquors Using Electronic Nose. IEEE Sensors Journal, 16(22), 8010-8017. doi:10.1109/jsen.2016.2606163Jing, Y.-Q., Meng, Q.-H., Qi, P.-F., Cao, M.-L., Zeng, M., & Ma, S.-G. (2016). A Bioinspired Neural Network for Data Processing in an Electronic Nose. IEEE Transactions on Instrumentation and Measurement, 65(10), 2369-2380. doi:10.1109/tim.2016.2578618Fine, G. F., Cavanagh, L. M., Afonja, A., & Binions, R. (2010). Metal Oxide Semi-Conductor Gas Sensors in Environmental Monitoring. Sensors, 10(6), 5469-5502. doi:10.3390/s100605469Santra, S., Guha, P. K., Ali, S. Z., Hiralal, P., Unalan, H. E., Covington, J. A., … Udrea, F. (2010). ZnO nanowires grown on SOI CMOS substrate for ethanol sensing. Sensors and Actuators B: Chemical, 146(2), 559-565. doi:10.1016/j.snb.2010.01.009Wilson, A. (2013). Diverse Applications of Electronic-Nose Technologies in Agriculture and Forestry. Sensors, 13(2), 2295-2348. doi:10.3390/s130202295Lorwongtragool, P., Sowade, E., Watthanawisuth, N., Baumann, R., & Kerdcharoen, T. (2014). A Novel Wearable Electronic Nose for Healthcare Based on Flexible Printed Chemical Sensor Array. Sensors, 14(10), 19700-19712. doi:10.3390/s141019700Son, M., Cho, D., Lim, J. H., Park, J., Hong, S., Ko, H. J., & Park, T. H. (2015). Real-time monitoring of geosmin and 2-methylisoborneol, representative odor compounds in water pollution using bioelectronic nose with human-like performance. Biosensors and Bioelectronics, 74, 199-206. doi:10.1016/j.bios.2015.06.053Gardner, J. W., Shin, H. W., Hines, E. L., & Dow, C. S. (2000). An electronic nose system for monitoring the quality of potable water. Sensors and Actuators B: Chemical, 69(3), 336-341. doi:10.1016/s0925-4005(00)00482-2Goschnick, J., Koronczi, I., Frietsch, M., & Kiselev, I. (2005). Water pollution recognition with the electronic nose KAMINA. Sensors and Actuators B: Chemical, 106(1), 182-186. doi:10.1016/j.snb.2004.05.055Guadayol, M., Cortina, M., Guadayol, J. M., & Caixach, J. (2016). Determination of dimethyl selenide and dimethyl sulphide compounds causing off-flavours in bottled mineral waters. Water Research, 92, 149-155. doi:10.1016/j.watres.2016.01.016Wilson, A. D. (2012). Review of Electronic-nose Technologies and Algorithms to Detect Hazardous Chemicals in the Environment. Procedia Technology, 1, 453-463. doi:10.1016/j.protcy.2012.02.101Becher, C., Kaul, P., Mitrovics, J., & Warmer, J. (2010). The detection of evaporating hazardous material released from moving sources using a gas sensor network. Sensors and Actuators B: Chemical, 146(2), 513-520. doi:10.1016/j.snb.2009.12.030Berrueta, L. A., Alonso-Salces, R. M., & Héberger, K. (2007). Supervised pattern recognition in food analysis. Journal of Chromatography A, 1158(1-2), 196-214. doi:10.1016/j.chroma.2007.05.024Lajara, R. J., Perez-Solano, J. J., & Pelegri-Sebastia, J. (2015). A Method for Modeling the Battery State of Charge in Wireless Sensor Networks. IEEE Sensors Journal, 15(2), 1186-1197. doi:10.1109/jsen.2014.2361151Batista, B. L., da Silva, L. R. S., Rocha, B. A., Rodrigues, J. L., Berretta-Silva, A. A., Bonates, T. O., … Barbosa, F. (2012). Multi-element determination in Brazilian honey samples by inductively coupled plasma mass spectrometry and estimation of geographic origin with data mining techniques. Food Research International, 49(1), 209-215. doi:10.1016/j.foodres.2012.07.015Benedetti, S., Mannino, S., Sabatini, A. G., & Marcazzan, G. L. (2004). Electronic nose and neural network use for the classification of honey. Apidologie, 35(4), 397-402. doi:10.1051/apido:200402",'MDPI AG',Development of the MOOSY4 eNose IoT for Sulphur-Based VOC Water Pollution Detection,10.3390/s17081917,https://riunet.upv.es/bitstream/10251/98785/1/sensors-17-01917.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
163105483,2018-01-01T00:00:00,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature",'Elsevier BV',Fast statistical model-based classification of epileptic EEG signals,10.1016/j.bbe.2018.08.002,https://core.ac.uk/download/163105483.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
188607378,2017-11-19T00:00:00,"What methodologies are most effective inclusive education? What are the framework conditions that favor the inclusion in the daily school reality? The partial results of the research are presented in this article. On a sample of 109 students, aged 8 to 16 years, we were measured the effects of teaching methods “feedback” and “collaborative learning”, recognized as effective by the international literature. Estimated variables are the skills and abilities to cross disciplines, cognitive-emotional factors of academic success, self-esteem. Rating bio psychosocial which opposes the prevailing bio-medical evaluation in Italy. Observe all students, to transform the special response in normal, measure the school environment variables favorable to inclusion can help to improve, in Italy, the effectiveness of public investment estimated in 2013 at  4,7B. They were later assessed the organizational and relational conditions of the school environment, also examined through the perception of the operators. The context is essential to the deployment of effective interventions for inclusion. The experimental design of research using methods recognized at international and European level (EBE), which allow you to compare the results and replicate the model in a supranational context, first of all in the pilot project “RA4AL” European Agency For Special Needs, It started in three countries, including Italy, which has just ended.Quali metodologie sono più efficaci nell’educazione inclusiva? Quali sono le condizioni di contesto che favoriscono l’inclusione nella quotidiana realtà scolastica? I risultati parziali della ricerca vengono presentati in questo articolo. Su un campione di 109 studenti, dagli 8 ai 16 anni, sono stati misurati gli effetti delle metodologie didattiche “feedback” e “collaborative learning”, riconosciute come efficaci dalla letteratura internazionale. Variabili stimate sono le competenze e le abilità trasversali alle discipline, i fattori cognitivo-emozionali del successo scolastico, l’autostima. Valutazione bio psico-sociale che si oppone alla valutazione bio-medica prevalente in Italia. Osservare tutti gli allievi, trasformare la risposta speciale in normalità, misurare le variabili del contesto scolastico favorevoli all’inclusione può contribuire a migliorare, in Italia, l’efficacia di investimenti pubblici stimati nel 2013 in  4,7B. Sono state poi valutate le condizioni organizzative e relazionali del contesto scolastico, esaminate anche attraverso la percezione degli operatori. Il contesto si rivela essenziale per la messa in campo di efficaci interventi per l’inclusione. Il disegno sperimentale della ricerca utilizza metodologie riconosciute a livello internazionale ed europeo (EBE), che consentono di confrontare i risultati e replicare il modello in un contesto sovranazionale, innanzitutto nell’ambito del progetto pilota “ RA4AL” dell’European Agency For Special Needs, avviato in tre paesi, tra cui l’Italia, e che si è appena concluso",'Asociacion INFAD',Primi risultati di uno studio EBE sull’inclusione in due scuole italiane,10.17060/ijodaep.2017.n1.v4.1066,https://core.ac.uk/download/188607378.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
74320701,2017-01-01T00:00:00,"The increasing application of process-oriented approaches in new challenging dynamic domains beyond business computing (e.g., healthcare, emergency management, factories of the future, home automation, etc.) has led to reconsider the level of flexibility and support required to manage complex knowledge-intensive processes in such domains. A knowledge-intensive process is influenced by user decision making and coupled with contextual data and knowledge production, and involves performing complex tasks in the “physical” real world to achieve a common goal. The physical world, however, is not entirely predictable, and knowledge-intensive processes must be robust to unexpected conditions and adaptable to unanticipated exceptions, recognizing that in real-world environments it is not adequate to assume that all possible recovery activities can be predefined for dealing with the exceptions that can ensue. To tackle this issue, in this paper we present SmartPM, a model and a prototype Process Management System featuring a set of techniques providing support for automated adaptation of knowledge-intensive processes at runtime. Such techniques are able to automatically adapt process instances when unanticipated exceptions occur, without explicitly defining policies to recover from exceptions and without the intervention of domain experts at runtime, aiming at reducing error-prone and costly manual ad-hoc changes, and thus at relieving users from complex adaptations tasks. To accomplish this, we make use of well-established techniques and frameworks from Artificial Intelligence, such as situation calculus, IndiGolog and classical planning. The approach, which is backed by a formal model, has been implemented and validated with a case study based on real knowledge-intensive processes coming from an emergency management domain",'Association for Computing Machinery (ACM)',Intelligent Process Adaptation in the SmartPM System,10.1145/2948071,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
217804495,2018-01-01T00:00:00,"A new compact diagnostic device exploiting the integration of screen printed electrode-based immunosensors and remote-controlled IoT-WiFi acquisition board has been realized and validated for diagnosis of Celiac Disease as case of study. The immunodevice is based on chemisorption of open tissue transglutaminase enzyme on the surface of gold nanoparticles-functionalized carbon screen printed electrodes. IgA and IgG anti-tissue transglutaminase target antibodies are recognized by the immobilized bioreceptor as highly specific biomarkers related to Celiac Disease. The signal from the amperometric sensor is acquired and processed through on-purpose developed IoT-WiFi integrated board, allowing for real-time data sharing on cloud services to directly notify all users (physicians, caregivers, etc.) on device outcome. The proposed solution does not require customized hardware or software. The analytical performances of the immunosensors were optimized by experimental design, obtaining diagnostically useful limit of detection (LOD) and limit of quantitation (LOQ) values (LODIgA=3.2 AU mL−1; LODIgG=1.4 AU mL−1; LOQIgA=4.6 AU mL−1; LOQIgG =2.3 AU mL−1) as well as good intermediate precision (RSD &lt; 5%). The high discrimination capability of the IoT-Wi-Fi device between positive and negative serum control resulted to be suitable for diagnostic purposes, with outstanding statistical significance (p &lt; 0,001",'Elsevier BV',An integrated IoT-Wi-Fi board for remote data acquisition and sharing from innovative immunosensors. Case of study: Diagnosis of celiac disease,10.1016/j.snb.2018.07.056,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
211847002,2017-01-01T00:00:00,"Krautenbacher N, Theis FJ, Fuchs C. Correcting Classifiers for Sample Selection Bias in Two-Phase Case-Control Studies. Computational and Mathematical Methods in Medicine. 2017;2017: 7847531.Epidemiological studies often utilize stratified data in which rare outcomes or exposures are artificially enriched. This design can increase precision in association tests but distorts predictions when applying classifiers on nonstratified data. Several methods correct for this so-called sample selection bias, but their performance remains unclear especially for machine learning classifiers. With an emphasis on two-phase case-control studies, we aim to assess which corrections to perform in which setting and to obtain methods suitable for machine learning techniques, especially the random forest. We propose two new resampling-based methods to resemble the original data and covariance structure: stochastic inverse-probability oversampling and parametric inverse-probability bagging. We compare all techniques for the random forest and other classifiers, both theoretically and on simulated and real data. Empirical results show that the random forest profits from only the parametric inverse-probability bagging proposed by us. For other classifiers, correction is mostly advantageous, and methods perform uniformly. We discuss consequences of inappropriate distribution assumptions and reason for different behaviors between the random forest and other classifiers. In conclusion, we provide guidance for choosing correction methods when training classifiers on biased samples. For random forests, our method outperforms state-of-the-art procedures if distribution assumptions are roughly fulfilled. We provide our implementation in the R package sambia",'Hindawi Limited',Correcting Classifiers for Sample Selection Bias in Two-Phase Case-Control Studies,10.1155/2017/7847531,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
390006579,2018-11-28T00:00:00,"According to statistics, every fifth married couple is faced with the inability to conceive a child. Male germ cells are very vulnerable, and the growing number of cases of male infertility confirms that in today's world there are many factors that affect the activity of spermatozoa and their number. But the important thing is not so much their quantity, but quality. The spermogram is an objective method of laboratory diagnosis, which allows  to accurately assess the man’s ability to fertilize by analyzing ejaculate for a number of key parameters. Only a spermogram can answer the question of a possible male infertility and the presence of urological diseases. When constructing spermograms, it is important to determine not only the number of good spermatozoa, but also their morphology and mobility. Therefore, research and improvement of some stages of spermogramm is the purpose of the study. This article addresses the problem of classification of spermatozoa in good and bad ones, taking into account their mobility and morphology, using methods of machine learning. In order to implement the first stage of machine learning (with a teacher) in the graphic editor, educational specimens (training sample) were created. The training was implemented by three methods: the method of support vector machine, the logistic regression and the method of K - the nearest neighbors. As a result of testing, the method K - the nearest neighbors is chosen. At the testing stage, a sample of 15 different spermatozoa was used in different variations of rotation around their axis. The test sample did not contain specimens from the training sample and was formed taking into account the morphological characteristics of the spermatozoa, but did not copy them from the training sample. At the final stage of study, the program's functioning was tested on real data.По статистике, каждая пятая супружеская пара сталкивается с невозможностью зачатия ребенка. Мужские половые клетки очень уязвимы, растущее число случаев мужского бесплодия подтверждает, что в современном мире очень много факторов, которые влияют и на активность сперматозоидов и на их количество.  И важно не столько их количество, сколько качество. Спермограмма является объективным методом лабораторной диагностики, что позволяет максимально точно оценить способность к оплодотворению человека, проанализировав эякулят по ряду важнейших параметров. Только спермограмма способна ответить на вопрос о возможном мужском бесплодии и о наличии урологических заболеваний. При построении спермограммы, важно определять не только количество хороших сперматозоидов, но и их морфологию и подвижность. Поэтому исследования и совершенствования некоторых этапов спермограммы и является целью исследования. В данной статье решается задача классификации сперматозоидов на добрые и плохие, с учетом их подвижности и морфологии, с применением методов машинного обучения. Для реализации первого этапа машинного обучения (с учителем) в графическом редакторе были созданы учебные экземпляры (тренировочная выборка). Обучение было реализована тремя методами: методом опорных векторов, логистическая регрессия и метод К - ближайших соседей. По результатам тестирования выбран метод К - ближайших соседей. На этапе тестирования использовалась выборка из 15 различных сперматозоидов в различных вариациях вращения вокруг своей оси. Тестовая выборка не содержала экземпляров с тренировочной выборки и была сформирована с учетом морфологических особенностей сперматозоидов, но не копировала их с тренировочной выборки. На завершающем этапе обучения работе программы были протестированы на реальных данных.За статистикою, кожна п'ята подружня пара стикається з неможливістю зачаття дитини. Чоловічі статеві клітини дуже вразливі, зростаюче число випадків чоловічого безпліддя підтверджує, що в сучасному світі дуже багато чинників, які впливають і на активність сперматозоїдів і на їх кількість. Та важливою є  не стільки їх кількість, скільки якість. Спермограма є об'єктивним методом лабораторної діагностики, що дозволяє максимально точно оцінити здатність до запліднення чоловіка, проаналізувавши еякулят за рядом найважливіших параметрів. Тільки спермограма здатна відповісти на питання про можливе чоловіче безпліддя та про наявність урологічних захворювань. При побудові спермограми, важливо визначати не тільки кількість добрих сперматозоїдів, але й їх морфологію та рухливість. Тому дослідження та вдосконалення деяких етапів спермограми і є метою дослідження. У даній статті вирішується задача класифікації сперматозоїдів на добрі та погані, з урахуванням їх рухливості та морфології, із застосуванням методів машинного навчання. Для реалізації першого етапу машинного навчання (з вчителем) у графічному редакторі були створені навчальні екземпляри (тренувальна вибірка). Навчання було реалізована трьома методами: методом опорних векторів, логістична регресія та метод К – найближчих сусідів. За результатами тестування обрано  метод К – найближчих сусідів. На етапі тестування використовувалася вибірка з 15 різних сперматозоїдів в різних варіаціях обертання навколо своєї осі. Тестова вибірка не містила примірників з тренувальної вибірки і була сформована з урахуванням морфологічних особливостей сперматозоїдів, але не копіювала їх з тренувальної вибірки. На завершальному етапі навчання роботу програми було протестовано на реальних даних","NTU ""KhPI""",Застосування методів машинного навчання для вирішення задачі аналізу біологічних даних,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
82199343,2016-12-31,"AbstractThis paper describes the design and evaluation of a mobile software library, HealthTracker, which aims to produce activity and energy expenditure estimations in real-time from accelerometer and gyroscope data provided by wearable sensors. Using feature extraction together with a classifier trained using machine learning, the system will automatically and periodically send all the produced estimations to a cloud-based platform that will allow later evaluation by both the user and a physician or caretaker. The system is presented within the DAPHNE platform, an ICT ecosystem designed to provide a means for remote health and lifestyle monitoring and guidance between physicians and their patients",The Author(s). Published by Elsevier B.V.,Designing and Testing HealthTracker for Activity Recognition and Energy Expenditure Estimation within the DAPHNE Platform ,10.1016/j.procs.2016.09.052,https://core.ac.uk/download/pdf/82199343.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
379236211,2017-11-01T00:00:00,"Accurately detecting and counting sparse bacterial samples has many applications in the food, beverage, and pharmaceutical processing industries, in medical diagnostics, and for life detection by robotic missions to other planets and moons of the solar system. Currently, sparse bacterial samples are counted by culture plating or epifluorescence microscopy. Culture plates require long incubation times (days to weeks), and epifluorescence microscopy requires extensive staining and concentration of the sample. Here, we demonstrate how to use off-axis digital holographic microscopy (DHM) to enumerate bacteria in very dilute cultures (100-104 cells/mL). First, the construction of the custom DHM is discussed, along with detailed instructions on building a low-cost instrument. The principles of holography are discussed, and a statistical model is used to estimate how long videos should be to detect cells, based on the optical performance characteristics of the instrument and the concentration of the bacterial solution (Table 2). Video detection of cells at 105, 104, 103, and 100 cells/mL is demonstrated in real time using un-reconstructed holograms. Reconstruction of amplitude and phase images is demonstrated using an open-source software package",'MyJove Corporation',Quantifying Microorganisms at Low Concentrations Using Digital Holographic Microscopy (DHM),,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201354035,2018-07-01T00:00:00,"Abstract Background The use of big data and machine learning within clinical decision support systems (CDSSs) has the potential to transform medicine through better prognosis, diagnosis and automation of tasks. Real-time application of machine learning algorithms, however, is dependent on data being present and entered prior to, or at the point of, CDSS deployment. Our aim was to determine the feasibility of automating CDSSs within electronic health records (EHRs) by investigating the timing, data categorization, and completeness of documentation of their individual components of two common Clinical Decision Rules (CDRs) in the Emergency Department. Methods The CURB-65 severity score and HEART score were randomly selected from a list of the top emergency medicine CDRs. Emergency department (ED) visits with ICD-9 codes applicable to our CDRs were eligible. The charts were reviewed to determine the categorization components of the CDRs as structured and/or unstructured, median times of documentation, portion of charts with all data components documented as structured data, portion of charts with all structured CDR components documented before ED departure. A kappa score was calculated for interrater reliability. Results The components of the CDRs were mainly documented as structured data for the CURB-65 severity score and HEART score. In the CURB-65 group, 26.8% of charts had all components documented as structured data, and 67.8% in the HEART score. Documentation of some CDR components often occurred late for both CDRs. Only 21 and 11% of patients had all CDR components documented as structured data prior to ED departure for the CURB-65 and HEART score groups, respectively. The interrater reliability for the CURB-65 score review was 0.75 and 0.65 for the HEART score. Conclusion Our study found that EHRs may be unable to automatically calculate popular CDRs—such as the CURB-65 severity score and HEART score—due to missing components and late data entry",'Springer Science and Business Media LLC',"Assessment of the Feasibility of automated, real-time clinical decision support in the emergency department using electronic health record data",10.1186/s12873-018-0170-9,,"[{'title': 'BMC Emergency Medicine', 'identifiers': ['issn:1471-227X', '1471-227x']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201478044,2017-11-01T00:00:00,"Monitoring of mechanical structures is a Big Data challenge and includes Structural Health Monitoring (SHM) and Non-destructive Testing (NDT). The sensor data produced by common measuring techniques, e.g., guided wave propagation analysis, is characterized by a high dimensionality in the temporal and spatial domain. There are off- and on-line methods applied at maintenance- or run-time, respectively. On-line methods (SHM) usually are constrained by low-resource processing platforms, sensor noise, unreliability, and real-time operation requiring advanced and efficient sensor data processing. Commonly, structural monitoring is a task that maps high-dimensional input data on low-dimensional output data (information, which is feature extraction), e.g., in the simplest case a Boolean output variable “Damaged”. Machine Learning (ML), e.g., supervised learning, can be used to derive such a mapping function. But ML quality and performance depends strongly on the input data size. Therefore, adaptive and reliable input data reduction (that is feature selection) is required at the first layer of an automatic structural monitoring system. Assuming some kind of two-dimensional sensor data (or n-dimensional data in general), image segmentation can be used to identify Regions of Interest (ROI), e.g., of wave propagation fields. Wave propagation in materials underlie reflections that must be distinguished, especially in hybrid materials (e.g., combining metal and fibre-plastic composites) there are complex wave propagation fields. The image segmentation is one of the most crucial parts of image processing. Major difficulties in image segmentation are noise and the differing homogeneity (fuzziness and signal gradients) of regions, complicating the definition of suitable threshold conditions for the edge detection or region splitting/clustering. Many traditional image segmentation algorithms are constrained by this issue. Artificial Intelligence can aid to overcome this limitation by using autonomous agents as an adaptive and self-organizing software architecture, presented in this work. Using a collection of co-operating agents decomposes a large and complex problem in smaller and simpler problems with a Divide-and-Conquer approach. Related to the image segmentation scenario, agents are working mostly autonomous (de-coupled) on dynamically bounded data from different regions of a signal or an image (i.e., distributed with simulated mobility), adapted to the locality, being reliable and less sensitive to noisy sensor data. In this work, self-organizing agents perform segmentation. They are evaluated with measured high-dimensional data from piezo-electric acusto-ultrasonic sensors recording the wave propagation in plate-like structures. Commonly, SHM deploys only a small set of sensors and actuators at static positions delivering only a few temporal resolved sensor signals (1D), whereas NDT methods additionally can use spatial scanning to create images of wave signals (2D). Both one-dimensional temporal and two-dimensional spatial segmentation are considered to find characteristic ROI",'MDPI AG',Robust and Adaptive Signal Segmentation for Structural Monitoring Using Autonomous Agents,10.3390/ecsa-4-04917,,"[{'title': 'Proceedings', 'identifiers': ['issn:2504-3900', '2504-3900']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
480370142,2015-08-01T00:00:00,"Background: In the telemedicine process, using digital techniques in disease diagnosis caused to have felt needs of archiving and storing patient information and high bandwidth in data transfer.



Methods: This study aimed at introducing an efficient way of multi-stage compression of mammographic image data based LM algorithm and artificial neural networks. At First, data derived from mammographic images given to multi-layer neural network has achieved the possibility of forming with minimum damage and  high degree of compaction in the first layer.



Results: The compression process of the mammography images was implemented using images of 128 women aged 46.41±6.55 yrs with BMI 36.78 ±5.5 from three specialized clinics in Sabzevar. The analysis yielded a mean square error (MSE) of 4.24 with the highest difference ratio of 33.46 and compression ratio of 8: 1in the output of the algorithm. The system performance based on the accurate design of the software was acceptable therefore; it demonstrated high efficiency in practice. 

             

Conclusion: The diagnosis in the discovery stage is highly consistent with the diagnosis in real based on reliability of software output in the compression and release, and considering the fact of mammographic images are not completely degraded during compression; therefore, this system has the capacity to be implemented achieving mammography images in hospitals and justify its application",Tehran University of Medical Sciences,"Designing an Efficient Method of Multi-Stage Compression of Mammography Images for Optimal Storage, Transmission and LM Algorithm",,,"[{'title': None, 'identifiers': ['2008-1928', 'issn:2228-7450', 'issn:2008-1928', '2228-7450']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
195779112,2018-01-01T00:00:00,"According to statistics, every fifth married couple is faced with the inability to conceive a child. Male germ cells are very vulnerable, and the growing number of cases of male infertility confirms that in today's world there are many factors that affect the activity of spermatozoa and their number. But the important thing is not so much their quantity, but quality. The spermogram is an objective method of laboratory diagnosis, which allows to accurately assess the man’s ability to fertilize by analyzing ejaculate for a number of key parameters. Only a spermogram can answer the question of a possible male infertility and the presence of urological diseases. When constructing spermograms, it is important to determine not only the number of good spermatozoa, but also their morphology and mobility. Therefore, research and improvement of some stages of spermogramm is the purpose of the study. This article addresses the problem of classification of spermatozoa in good and bad ones, taking into account their mobility and morphology, using methods of machine learning. In order to implement the first stage of machine learning (with a teacher) in the graphic editor, educational specimens (training sample) were created. The training was implemented by three methods: the method of support vector machine, the logistic regression and the method of K - the nearest neighbors. As a result of testing, the method K - the nearest neighbors is chosen. At the testing stage, a sample of 15 different spermatozoa was used in different variations of rotation around their axis. The test sample did not contain specimens from the training sample and was formed taking into account the morphological characteristics of the spermatozoa, but did not copy them from the training sample. At the final stage of study, the program's functioningwas tested on real data.За статистикою, кожна п'ята подружня пара стикається з неможливістю зачаття дитини. Чоловічі статеві клітини дуже вразливі, зростаюче число випадків чоловічого безпліддя підтверджує, що в сучасному світі дуже багато чинників, які впливають і на активність сперматозоїдів і на їх кількість. Та важливою є не стільки їх кількість, скільки якість. Спермограма є об'єктивним методом лабораторної діагностики, що дозволяє максимально точно оцінити здатність до запліднення чоловіка, проаналізувавши еякулят за рядом найважливіших параметрів. Тільки спермограма здатна відповісти на питання про можливе чоловіче безпліддя та про наявність урологічних захворювань. При побудові спермограми, важливо визначати не тільки кількість добрих сперматозоїдів, але й їх морфологію та рухливість. Тому дослідження та вдосконалення деяких етапів спермограми і є метою дослідження. У даній статті вирішується задача класифікації сперматозоїдів на добрі та погані, з урахуванням їх рухливості та морфології, із застосуванням методів машинного навчання. Для реалізації першого етапу машинного навчання (з вчителем) у графічному редакторі були створені навчальні екземпляри (тренувальна вибірка). Навчання було реалізована трьома методами: методом опорних векторів, логістична регресія та метод К - найближчих сусідів. За результатами тестування обрано метод К - найближчих сусідів. На етапі тестування використовувалася вибірка з 15 різних сперматозоїдів в різних варіаціях обертання навколо своєї осі. Тестова вибірка не містила примірників з тренувальної вибірки і була сформована з урахуванням морфологічних особливостей сперматозоїдів, але не копіювала їх з тренувальної вибірки. На завершальному етапі навчання роботу програми було протестовано на реальних даних",'National Technical University Kharkiv Polytechnic Institute',Застосування методів машинного навчання для вирішення задачі аналізу біологічних даних,10.20998/2522-9052.2018.3.01,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
286600336,2018-01-01T00:00:00,": Deep learning is the most recent approach to achieve artificial intelligence. Especially neural networks are used for solving many human problems - from repetitive operations to intelligent recognizing in image, sound and text processing. They are used in medicine, car industry, game industry and robotics. Business companies also try to find the way of exploitation of the latest technology despite the fact that it is the long way to the point where machines will be capable to replace the human intelligence. Authors of this paper explore possibilities of semi-supervised learning application in accounting. One of the latest deep learning algorithm is successfully used to reconstruct the journal entry key columns. The model was trained and tested on a real-world dataset so it could become base for developing the wide pallet of accounting and audit applications - as anomaly detection module of Enterprise Resource Planning (ERP) software or as a standalone application",,Journal entries with deep learning model,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
189855542,2018-01-01T00:00:00,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature",'Elsevier BV',Fast statistical model-based classification of epileptic EEG signals,10.1016/j.bbe.2018.08.002,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
196618218,2015-01-01T00:00:00,"Complex real problems increasingly require intelligent systems that combine knowledge, techniques and methodologies from various sources. Intelligent systems based on artificial intelligence techniques that are associated with the behavior of people can perform the processes of learning, reasoning and solving all kinds of problems. Such systems, which automatically can perform tasks set by the user or other software, today thankfully called intelligent agents. Independent, intelligent agents on the Internet can be very successful to perform some search work on behalf of and for the needs of different users. For efficient collection, manipulation and management of data, such software can be very interesting from the standpoint of intelligent data analysis in many areas the police. Analysis of the data collected by an intelligent agent (a software robot-bot) can be successfully utilized, among many jobs in the police, and in the field of crime and in particular manifestation of cyber­crime, traffic safety, emergencies, etc. To make the collection and analysis of data from criminal activities on the Internet effective, it is necessary to examine the existing artificial intelligence techniques to be used for the conclusion of the intelligent agents. On the other hand, using of methods of artificial intelligence in finding data along with intelligent data analysis (data mining) should be used, which has found wide use in the area of business, economics, mechanics, medicine, genetics, transport etc.Kompleksni realni problemi sve češće zahtevaju inteligentne sisteme koji kombinuju znanje, tehnike i metodologije iz različitih izvora. Inteligentni sistemi bazirani na tehnikama veštačke inteligencije koje asociraju na ponašanje ljudi mogu da obavljaju procese učenja, zaključivanja i rešavanje raznovrsnih problema. Ovakvi sistemi, koji automatski mogu da izvrše zadatke zadate od strane korisnika ili drugih softvera, danas se sreću pod imenom inteligentni agenti. Samostalno, inteligentni agenti na Internetu mogu veoma uspešno da izvode neki pretraživački posao u ime i za potrebe raznih korisnika. Zbog efikasnog sakupljanja, manipulisanja i upravljanja podacima, ovakvi softveri mogu biti veoma interesantni sa stanovišta inteligentne analize podataka u mnogim oblastima policije. Analiza podataka sakupljenih od strane inteligentnog agenta (softverskog robota - bota) može se uspešno iskoristiti, između mnogih poslova u policiji, i na polju kriminala i naročito pojavnog oblika sajber kriminala, bezbednosti saobraćaja, vanrednih situacija itd. Kako bi sakupljanje i analiza podataka iz kriminalnih aktivnosti na Internetu bila efikasna, neophodno je sagledati postojeće tehnike veštačke inteligencije koje se koriste za zaključivanje u inteligentnim agentima. S druge strane, treba iskoristiti metode veštačke inteligencije u pronalaženju podataka pri inteligentnoj analizi podataka (data mining-u) koja je našla široku primenu u oblasti poslovanja preduzeća, ekonomije, mehanike, medicine, genetike, saobraćaja i sl",'Centre for Evaluation in Education and Science (CEON/CEES)',Veštačka intelegencija u prikupljanju i analizi podataka u policiji,10.5937/NBP1503131K,https://core.ac.uk/download/196618218.pdf,"[{'title': 'Nauka bezbednost policija', 'identifiers': ['issn:0354-8872', '0354-8872']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
158449286,2017-02-01T00:00:00,"BACKGROUND AND OBJECTIVE: Human error and timeless in conventional techniques to identify species Enterococcus faecium and Enterococcus faecalis are two species of the pathogenic species in humans, more accurate techniques is essential. The aim of this study is to design a method of quickly and accurately using DNA melting by Real Time PCR technique to identify and separate the two species in clinical isolates.

METHODS: In this experimental study, the bacterial isolates in the Department of Microbiology Bank of Hamadan University of Medical Sciences was used. Design of primers was done by proprietary software and selecting DivIVA gene for Enterococcus faecalis and alanine racemase for Enterococcus faecium was performed. Isolates identification was evaluated by using Real Time PCR test and melting curve temperature of DNA.

FINDINGS: Susceptibility of primers designed in divIVA gene (specific for E. faecalis) and alanine-racemase gene (specific for E. faecium) was 15CFU/ml per reaction. Specificity of designed primers by using DNA melting curve analysis was 76.6 for E. faecalis and 80.93 for E. faecium which showed considerable different in comparison with another microorganism.

CONCLUSION: Using the results obtained in this study, primers designed were sensitivity and specificity for diagnosis and differentiation of Enterococcus faecium and Enterococcus faecalis species in clinical isolates",Babol University of Medical Sciences,Evaluation of Real-time PCR-based DNA melting method for detection of Enterococcus faecalis and Enterococcus faecium in clinical isolates,,,"[{'title': None, 'identifiers': ['2251-7170', 'issn:2251-7170', '1561-4107', 'issn:1561-4107']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275602954,2014-12-01T00:00:00,"This paper presents a novel markerless monocular tracking system aimed at guiding ophthalmologists
during external eye surgery. This new tracking system performs a very accurate tracking of the eye by
detecting invariant points using only textures that are present in the sclera, i.e., without using traditional
features like the pupil and/or cornea reflections, which remain partially or totally occluded in most
surgeries. Two known algorithms that compute invariant points and correspondences between pairs of
images were implemented in our system: Scalable Invariant Feature Transforms (SIFT) and Speed Up
Robust Features (SURF). The results of experiments performed on phantom eyes show that, with either
algorithm, the developed system tracks a sphere at a 360◦ rotation angle with an error that is lower than
0.5%. Some experiments have also been carried out on images of real eyes showing promising behavior
of the system in the presence of blood or surgical instruments during real eye surgery.
© 2014 Elsevier Ltd. All rights reserved.Monserrat Aranda, C.; Rupérez Moreno, MJ.; Alcañiz Raya, ML.; Mataix, J. (2014). Markerless monocular tracking system for guided external eye surgery. Computerized Medical Imaging and Graphics. 38(8):785-792. doi:10.1016/j.compmedimag.2014.08.001S78579238",'Elsevier BV',Markerless monocular tracking system for guided external eye surgery,10.1016/j.compmedimag.2014.08.001,https://riunet.upv.es/bitstream/10251/50882/3/Manuscript.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
42968298,2015-08-01T00:00:00,"Tree nut allergies are considered an important health issue in developed countries. To comply with the regulations on food labeling, reliable allergen detection methods are required. In this work we isolated almond-specific recombinant antibody fragments (scFv) from a commercial phage display library bypassing the use of live animals, hence being consistent with the latest policies on animal welfare. To this end an iterative selection procedure employing the Tomlinson I phage display library and a crude almond protein extract was carried out. Two different almond-specific scFv (named PD1F6 and PD2C9) were isolated after two rounds of biopanning, and an indirect phage ELISA was implemented to detect the presence of almond protein in foodstuffs. The isolated scFvs demonstrated to be highly specific and allowed detection of 40 ng mL?1 and 100 ng mL?1 of raw and roasted almond protein, respectively. The practical detection limit of the assay in almond spiked food products was 0.1 mg g?1 (110e120 ppm). The developed indirect phage ELISA was validated by analysis of 92 commercial food products, showing good correlation with the results obtained by a previously developed real-time PCR method for the detection of almond in foodstuffs. The selected phage clones can be affinity maturated to improve their sensitivity and genetically engineered to be employed in different assay formats",'Elsevier BV',Isolation of recombinant antibody fragments (scFv) by phage display technology for detection of almond allergens in food products,10.1016/j.foodcont.2015.02.011,http://oa.upm.es/41191/1/INVE_MEM_2015_227428.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201813349,2018-09-01T00:00:00,"The clinical decision support system provides an automatic diagnosis of human diseases using machine learning techniques to analyze features of patients and classify patients according to different diseases. An analysis of real-world electronic health record (EHR) data has revealed that a patient could be diagnosed as having more than one disease simultaneously. Therefore, to suggest a list of possible diseases, the task of classifying patients is transferred into a multi-label learning task. For most multi-label learning techniques, the class imbalance that exists in EHR data may bring about performance degradation. Cross-Coupling Aggregation (COCOA) is a typical multi-label learning approach that is aimed at leveraging label correlation and exploring class imbalance. For each label, COCOA aggregates the predictive result of a binary-class imbalance classifier corresponding to this label as well as the predictive results of some multi-class imbalance classifiers corresponding to the pairs of this label and other labels. However, class imbalance may still affect a multi-class imbalance learner when the number of a coupling label is too small. To improve the performance of COCOA, a regularized ensemble approach integrated into a multi-class classification process of COCOA named as COCOA-RE is presented in this paper. To provide disease diagnosis, COCOA-RE learns from the available laboratory test reports and essential information of patients and produces a multi-label predictive model. Experiments were performed to validate the effectiveness of the proposed multi-label learning approach, and the proposed approach was implemented in a developed system prototype",'MDPI AG',Decision Support System for Medical Diagnosis Utilizing Imbalanced Clinical Data,10.3390/app8091597,,"[{'title': 'Applied Sciences', 'identifiers': ['2076-3417', 'issn:2076-3417']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201392715,2018-11-01T00:00:00,"Abstract Machine learning has become an increasingly powerful tool for solving complex problems, and its application in public health has been underutilized. The objective of this study is to test the efficacy of a machine-learned model of foodborne illness detection in a real-world setting. To this end, we built FINDER, a machine-learned model for real-time detection of foodborne illness using anonymous and aggregated web search and location data. We computed the fraction of people who visited a particular restaurant and later searched for terms indicative of food poisoning to identify potentially unsafe restaurants. We used this information to focus restaurant inspections in two cities and demonstrated that FINDER improves the accuracy of health inspections; restaurants identified by FINDER are 3.1 times as likely to be deemed unsafe during the inspection as restaurants identified by existing methods. Additionally, FINDER enables us to ascertain previously intractable epidemiological information, for example, in 38% of cases the restaurant potentially causing food poisoning was not the last one visited, which may explain the lower precision of complaint-based inspections. We found that FINDER is able to reliably identify restaurants that have an active lapse in food safety, allowing for implementation of corrective actions that would prevent the potential spread of foodborne illness",'Springer Science and Business Media LLC',Machine-learned epidemiology: real-time detection of foodborne illness at scale,10.1038/s41746-018-0045-1,,"[{'title': 'npj Digital Medicine', 'identifiers': ['2398-6352', 'issn:2398-6352']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
146965571,2015-09,"There is an increasing need in biology and clinical medicine to robustly and reliably measure tens-to-hundreds of peptides and proteins in clinical and biological samples with high sensitivity, specificity, reproducibility and repeatability. Previously, we demonstrated that LC-MRM-MS with isotope dilution has suitable performance for quantitative measurements of small numbers of relatively abundant proteins in human plasma, and that the resulting assays can be transferred across laboratories while maintaining high reproducibility and quantitative precision. Here we significantly extend that earlier work, demonstrating that 11 laboratories using 14 LC-MS systems can develop, determine analytical figures of merit, and apply highly multiplexed MRM-MS assays targeting 125 peptides derived from 27 cancer-relevant proteins and 7 control proteins to precisely and reproducibly measure the analytes in human plasma. To ensure consistent generation of high quality data we incorporated a system suitability protocol (SSP) into our experimental design. The SSP enabled real-time monitoring of LC-MRM-MS performance during assay development and implementation, facilitating early detection and correction of chromatographic and instrumental problems. Low to sub-nanogram/mL sensitivity for proteins in plasma was achieved by one-step immunoaffinity depletion of 14 abundant plasma proteins prior to analysis. Median intra- and inter-laboratory reproducibility was <20%, sufficient for most biological studies and candidate protein biomarker verification. Digestion recovery of peptides was assessed and quantitative accuracy improved using heavy isotope labeled versions of the proteins as internal standards. Using the highly multiplexed assay, participating laboratories were able to precisely and reproducibly determine the levels of a series of analytes in blinded samples used to simulate an inter-laboratory clinical study of patient samples. Our study further establishes that LC-MRM-MS using stable isotope dilution, with appropriate attention to analytical validation and appropriate quality c`ontrol measures, enables sensitive, specific, reproducible and quantitative measurements of proteins and peptides in complex biological matrices such as plasma","American Society for Biochemistry and Molecular Biology, Inc.","Large-scale interlaboratory study to develop, analytically validate and apply highly multiplexed, quantitative peptide assays to measure cancer-relevant proteins in plasma",10.1074/mcp.M114.047050,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
390020517,2017-12-25T00:00:00,"The economic-legal aspects of the state and trends of the Internet-based technologies (IP) technology, the place of intellectual property in it are considered. It is shown that the Internet of Things creates conditions for the emergence of a synergetic effect from the combination of possibilities of artificial intelligence, cloud computing, set of sensors, mathematical algorithms for processing large data (Big Data), robotic devices of various purposes, data transmission systems (Internet), which allows to provide various services and perform various work with or without the participation of people. The role of the state in promoting the development of IP, the existing problems and ways of their solution are shown. Many governments in recent years are taking measures to analyze the state of affairs with the introduction of IP technologies, the localization of problems and threats that may or may occur in the future in order to formulate a common strategy for the development of industry for the production of IP technologies and their application in various sectors of the economy and public life. The patent landscape of the IP is analyzed, the most productive companies and inventors of IP are discovered, the dynamics of patenting in the IP environment, the value of patents, patent research problems are shown. The problems of intellectual property protection in the sphere of IP, in particular, copyright, inventions, trademarks, commercial secrets, information security are considered. The intellectual potential and untapped potential of Ukraine in the development of IP technologies are considered. It is concluded that in the widespread use of IP technologies, there is a significant potential for increasing the efficiency of any type of human activity. It concerns the real economy, industry and agriculture, health care, public administration, education, financial turnover, etc. The development of IP technologies is the most powerful stimulating factor in the innovative development of nanotechnologies, microelectronics, semiconductor technologies, microiminating of executive devices, telecommunications, radio technologies, software computing, robotics, and moreРассмотрены экономико-правовые аспекты состояния и тенденций развития технологий Интернета вещей (ИВ), места в нем интеллектуальной собственности. Показано, что ИВ создает условия для появления синергетического эффекта от сочетания возможностей искусственного интеллекта, облачных вычислений, множества сенсоров, математических алгоритмов обработки больших данных (Big Data), роботизированных устройств различного назначения, систем передачи данных (сети Интернет), что позволяет предоставлять разнообразные услуги и осуществлять различные работы с участием или без участия людей. Показана роль государства в содействии развитию ИВ, существующие проблемы и пути их решения. Правительства многих стран в последнее время принимают меры по анализу состояния дел с внедрением ИВ-технологий, локализации проблем и угроз, имеющих место или могущих возникнуть в будущем, с целью формирования общей стратегии развития промышленности производства технологий ИВ и их применение в различных секторах экономики и общественной жизни. Проанализированы патентный ландшафт ИВ, выявлены наиболее продуктивные компании и изобретатели ИВ, показана динамика патентования в среде ИВ, ценность патентов, проблемы патентного поиска. Рассмотрены проблемы охраны интеллектуальной собственности в сфере ИВ, в частности, авторских прав, изобретений, торговых марок, коммерческой тайны, информационной безопасности. Рассмотрены интеллектуальный потенциал и неиспользованные возможности Украины в развитии технологий ИВ. Делается вывод, что в широком применении технологий ИВ заложен значительный потенциал повышения эффективности любого вида человеческой деятельности. Это касается сферы реальной экономики, промышленности и сельского хозяйства, системы здравоохранения, государственного управления, образования, финансового оборота и т. п. Развитие технологий ИВ является мощным стимулирующим фактором инновационного развития нанотехнологий, микроэлектроники, полупроводниковых технологий, микроминиатюризации исполнительных устройств, телекоммуникаций, радиотехнологий, программных вычислительных средств, робототехники и многого другого.Розглянуто економіко-правові аспекти стану та тенденцій розвитку технологій Інтернет речей (ІР), місця в ньому інтелектуальної власності. Показано роль держави у сприянні розвитку ІР, існуючі проблеми та шляхи їх вирішення. Проаналізовано патентний ландшафт ІР, виявлені найбільш продуктивні компанії та винахідники ІР, показано динаміку патентування в середовищі ІР, цінність патентів, проблеми патентного пошуку. Визначено проблеми охорони інтелектуальної власності у сфері ІР, зокрема, авторських прав, винаходів, торгових марок, комерційної таємниці, інформаційної безпеки. Розглянуто інтелектуальний потенціал та невикористані можливості України у розвитку технологій ІР.Робиться висновок, що у широкому застосуванні технологій ІР закладено значний потенціал підвищення ефективності економіки",Науково-дослідний інститут інтелектуальної власності НAПрН України,ІНТЕЛЕКТУАЛЬНА ВЛАСНІСТЬ В СИСТЕМІ ІНТЕРНЕТ РЕЧЕЙ: ЕКОНОМІКО-ПРАВОВИЙ АСПЕКТ,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
251203367,2018-10-11T00:00:00,"BACKGROUND: Logistic regression is a popular technique used in machine learning to construct classification models. Since the construction of such models is based on computing with large datasets, it is an appealing idea to outsource this computation to a cloud service. The privacy-sensitive nature of the input data requires appropriate privacy preserving measures before outsourcing it. Homomorphic encryption enables one to compute on encrypted data directly, without decryption and can be used to mitigate the privacy concerns raised by using a cloud service. METHODS: In this paper, we propose an algorithm (and its implementation) to train a logistic regression model on a homomorphically encrypted dataset. The core of our algorithm consists of a new iterative method that can be seen as a simplified form of the fixed Hessian method, but with a much lower multiplicative complexity. RESULTS: We test the new method on two interesting real life applications: the first application is in medicine and constructs a model to predict the probability for a patient to have cancer, given genomic data as input; the second application is in finance and the model predicts the probability of a credit card transaction to be fraudulent. The method produces accurate results for both applications, comparable to running standard algorithms on plaintext data. CONCLUSIONS: This article introduces a new simple iterative algorithm to train a logistic regression model that is tailored to be applied on a homomorphically encrypted dataset. This algorithm can be used as a privacy-preserving technique to build a binary classification model and can be applied in a wide range of problems that can be modelled with logistic regression. Our implementation results show that our method can handle the large datasets used in logistic regression training.status: publishe",'Springer Science and Business Media LLC',Privacy-preserving logistic regression training,10.1186/s12920-018-0398-y,,"[{'title': 'BMC Medical Genomics', 'identifiers': ['1755-8794', 'issn:1755-8794']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
37023053,2013-01-01T08:00:00,"Diesel exhaust emission is a major health concern because of the complex nature of its gaseous content (e.g., NO2, NO, CO, and CO2) and high concentration of particulate matter (PM) less than 2.5 μm which allows for deeper penetration into the human pulmonary system upon inhalation. The aim of this research was to elucidate the potential toxic effects of diesel exhaust on a human pulmonary-based cellular system. Validation of a dynamic direct exposure method for both laboratory (230 hp Volvo truck engine) and field (Volkswagen Passat passenger car) diesel engines, at idle mode, was implemented. Human pulmonary type II epithelial cells (A549) grown on porous membranes were exposed to unmodified diesel exhaust at a low flow rate (37.5 mL/min). In parallel, diesel emission sampling was also conducted using real-time air monitoring techniques. Induced cellular effects were assessed using a range of in vitro cytotoxicity assays (MTS, ATP, and NRU). Reduction of cell viability was observed in a time-dependent manner following 30–60 mins of exposure with NRU as the most sensitive assay. The results suggest that the dynamic direct exposure method has the potential to be implemented for both laboratory- and field-based in vitro toxicity studies of diesel exhaust emissions",'Sociological Research Online',Validation of the dynamic direct exposure method for toxicity testing of diesel exhaust in vitro,,https://core.ac.uk/download/37023053.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
143643223,2018-02-01T00:00:00,"Objective: To train a generic deep learning software (DLS) to classify breast cancer on ultrasound images and to compare its performance to human readers with variable breast imaging experience.

Methods: In this retrospective study, all breast ultrasound examinations from January 1, 2014 to December 31, 2014 at our institution were reviewed. Patients with post-surgical scars, initially indeterminate, or malignant lesions with histological diagnoses or 2-year follow-up were included. The DLS was trained with 70% of the images, and the remaining 30% were used to validate the performance. Three readers with variable expertise also evaluated the validation set (radiologist, resident, medical student). Diagnostic accuracy was assessed with a receiver operating characteristic analysis.

Results: 82 patients with malignant and 550 with benign lesions were included. Time needed for training was 7 min (DLS). Evaluation time for the test data set were 3.7 s (DLS) and 28, 22 and 25 min for human readers (decreasing experience). Receiver operating characteristic analysis revealed non-significant differences (p-values 0.45–0.47) in the area under the curve of 0.84 (DLS), 0.88 (experienced and intermediate readers) and 0.79 (inexperienced reader).

Conclusion: DLS may aid diagnosing cancer on breast ultrasound images with an accuracy comparable to radiologists, and learns better and faster than a human reader with no prior experience. Further clinical trials with dedicated algorithms are warranted.

Advances in knowledge: DLS can be trained classify cancer on breast ultrasound images high accuracy even with comparably few training cases. The fast evaluation speed makes real-time image analysis feasible",'British Institute of Radiology',Classification of breast cancer from ultrasound imaging using a generic deep learning analysis software: a pilot study,10.1259/bjr.20170576,https://www.zora.uzh.ch/id/eprint/143409/,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
82487224,2014-08-31,"AbstractBovine mastitis is a frequent problem in Swiss dairy herds. One of the main pathogens causing significant economic loss is Staphylococcus aureus. Various Staph. aureus genotypes with different biological properties have been described. Genotype B (GTB) of Staph. aureus was identified as the most contagious and one of the most prevalent strains in Switzerland. The aim of this study was to identify risk factors associated with the herd-level presence of Staph. aureus GTB and Staph. aureus non-GTB in Swiss dairy herds with an elevated yield-corrected herd somatic cell count (YCHSCC). One hundred dairy herds with a mean YCHSCC between 200,000 and 300,000cells/mL in 2010 were recruited and each farm was visited once during milking. A standardized protocol investigating demography, mastitis management, cow husbandry, milking system, and milking routine was completed during the visit. A bulk tank milk (BTM) sample was analyzed by real-time PCR for the presence of Staph. aureus GTB to classify the herds into 2 groups: Staph. aureus GTB-positive and Staph. aureus GTB-negative. Moreover, quarter milk samples were aseptically collected for bacteriological culture from cows with a somatic cell count ≥150,000cells/mL on the last test-day before the visit. The culture results allowed us to allocate the Staph. aureus GTB-negative farms to Staph. aureus non-GTB and Staph. aureus-free groups. Multivariable multinomial logistic regression models were built to identify risk factors associated with the herd-level presence of Staph. aureus GTB and Staph. aureus non-GTB. The prevalence of Staph. aureus GTB herds was 16% (n=16), whereas that of Staph. aureus non-GTB herds was 38% (n=38). Herds that sent lactating cows to seasonal communal pastures had significantly higher odds of being infected with Staph. aureus GTB (odds ratio: 10.2, 95% CI: 1.9–56.6), compared with herds without communal pasturing. Herds that purchased heifers had significantly higher odds of being infected with Staph. aureus GTB (rather than Staph. aureus non-GTB) compared with herds without purchase of heifers. Furthermore, herds that did not use udder ointment as supportive therapy for acute mastitis had significantly higher odds of being infected with Staph. aureus GTB (odds ratio: 8.5, 95% CI: 1.6–58.4) or Staph. aureus non-GTB (odds ratio: 6.1, 95% CI: 1.3–27.8) than herds that used udder ointment occasionally or regularly. Herds in which the milker performed unrelated activities during milking had significantly higher odds of being infected with Staph. aureus GTB (rather than Staph. aureus non-GTB) compared with herds in which the milker did not perform unrelated activities at milking. Awareness of 4 potential risk factors identified in this study guides implementation of intervention strategies to improve udder health in both Staph. aureus GTB and Staph. aureus non-GTB herds",American Dairy Science Association®.,Genotype-specific risk factors for Staphylococcus aureus in Swiss dairy herds with an elevated yield-corrected herd somatic cell count ,10.3168/jds.2013-7760,https://core.ac.uk/download/pdf/82487224.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
302679903,2018-08-17T00:00:00,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ""VA-assisted ML"". The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly",'Institute of Electrical and Electronics Engineers (IEEE)',VIS4ML: an ontology for visual analytics assisted machine learning,10.1109/TVCG.2018.2864838,,"[{'title': 'IEEE Transactions on Visualization and Computer Graphics', 'identifiers': ['1077-2626', 'issn:1077-2626']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
301151642,2016-05-01T00:00:00,"This paper is an extended version of one paper published in the 4th IEEE International Work Conference on Bioinspired Intelligence, Donostia, Spain, 9–12 June 2015Biomedical systems produce biosignals that arise from interaction mechanisms. In a general form, those mechanisms occur across multiple scales, both spatial and temporal, and contain linear and non-linear information. In this framework, entropy measures are good candidates in order provide useful evidence about disorder in the system, lack of information in time-series and/or irregularity of the signals. The most common movement disorder is essential tremor (ET), which occurs 20 times more than Parkinson's disease. Interestingly, about 50%-70% of the cases of ET have a genetic origin. One of the most used standard tests for clinical diagnosis of ET is Archimedes' spiral drawing. This work focuses on the selection of non-linear biomarkers from such drawings and handwriting, and it is part of a wider cross study on the diagnosis of essential tremor, where our piece of research presents the selection of entropy features for early ET diagnosis. Classic entropy features are compared with features based on permutation entropy. Automatic analysis system settled on several Machine Learning paradigms is performed, while automatic features selection is implemented by means of ANOVA (analysis of variance) test. The obtained results for early detection are promising and appear applicable to real environments.This work has been partially supported by the University of the Basque Country under project ref. UPV/EHU-58/14, SAIOTEK program and others from the Basque Government, the Spanish Ministerio de Ciencia e Innovacion TEC2012-38630-C04-03, the University of Vic-Central University of Catalonia under the research grant R0904, INNPACTO program from the Spanish Government, and UPV/EHU Summer Courses Foundation",'MDPI AG',Selection of Entropy Based Features for Automatic Analysis of Essential Tremor,10.3390/e18050184,,"[{'title': 'Entropy', 'identifiers': ['1099-4300', 'issn:1099-4300']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
161502228,2016,"The paper provides a state of the art review of guided wave based structural health monitoring (SHM). First, the fundamental concepts of guided wave propagation and its implementation for SHM is explained. Following sections present the different modeling schemes adopted, developments in the area of transducers for generation, and sensing of wave, signal processing and imaging technique, statistical and machine learning schemes for feature extraction. Next, a section is presented on the recent advancements in nonlinear guided wave for SHM. This is followed by section on Rayleigh and SH waves. Next is a section on real-life implementation of guided wave for industrial problems. The paper, though briefly talks about the early development for completeness,. is primarily focussed on the recent progress made in the last decade. The paper ends by discussing and highlighting the future directions and open areas of research in guided wave based SHM",IOP PUBLISHING LTD,Guided wave based structural health monitoring: A review,10.1088/0964-1726/25/5/053001,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
203932409,2016-12-31,"AbstractThis paper describes the design and evaluation of a mobile software library, HealthTracker, which aims to produce activity and energy expenditure estimations in real-time from accelerometer and gyroscope data provided by wearable sensors. Using feature extraction together with a classifier trained using machine learning, the system will automatically and periodically send all the produced estimations to a cloud-based platform that will allow later evaluation by both the user and a physician or caretaker. The system is presented within the DAPHNE platform, an ICT ecosystem designed to provide a means for remote health and lifestyle monitoring and guidance between physicians and their patients",The Author(s). Published by Elsevier B.V.,Designing and Testing HealthTracker for Activity Recognition and Energy Expenditure Estimation within the DAPHNE Platform ,10.1016/j.procs.2016.09.052,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
35286866,2015-01-01T00:00:00,"Computational breath analysis is a growing research area aiming at identifying volatile organic compounds (VOCs) in human breath to assist medical diagnostics of the next generation. While inexpensive and non-invasive bioanalytical technologies for metabolite detection in exhaled air and bacterial/fungal vapor exist and the first studies on the power of supervised machine learning methods for profiling of the resulting data were conducted, we lack methods to extract hidden data features emerging from confounding factors. Here, we present Carotta, a new cluster analysis framework dedicated to uncovering such hidden substructures by sophisticated unsupervised statistical learning methods. We study the power of transitivity clustering and hierarchical clustering to identify groups of VOCs with similar expression behavior over most patient breath samples and/or groups of patients with a similar VOC intensity pattern. This enables the discovery of dependencies between metabolites. On the one hand, this allows us to eliminate the effect of potential confounding factors hindering disease classification, such as smoking. On the other hand, we may also identify VOCs associated with disease subtypes or concomitant diseases. Carotta is an open source software with an intuitive graphical user interface promoting data handling, analysis and visualization. The back-end is designed to be modular, allowing for easy extensions with plugins in the future, such as new clustering methods and statistics. It does not require much prior knowledge or technical skills to operate. We demonstrate its power and applicability by means of one artificial dataset. We also apply Carotta exemplarily to a real-world example dataset on chronic obstructive pulmonary disease (COPD). While the artificial data are utilized as a proof of concept, we will demonstrate how Carotta finds candidate markers in our real dataset associated with confounders rather than the primary disease (COPD) and bronchial carcinoma (BC). Carotta is publicly available at http://carotta.compbio.sdu.dk",'MDPI AG',Carotta : revealing hidden confounder markers in metabolic breath profiles,10.3390/metabo5020344,https://core.ac.uk/download/35286866.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
81990661,2017-02-28,"AbstractA large part of the biomedical research spectrum is dedicated to develop electrocardiogram (ECG) signal processing techniques to contribute to early diagnosis. However, it is common to find that ECG analysis methods reported are confined to off-line PC host operation. The authors present an arrhythmia classification method implemented on a Digital Signal Processing (DSP) platform intended for on-line, real-time ambulatory operation to classify eight heartbeat conditions: normal sinus rhythm (N), auricular fibrillation (AF), premature atrial contraction (PAC), left bundle branch block (LBBB), right bundle branch block (RBBB), premature ventricular contraction (PVC), sinoauricular heart block (SHB) and supraventricular tachycardia (SVT). The algorithm uses a wavelet transform process based on quadratic wavelets for identifying individual ECG waves and obtain a fiducial marker array. Classification is conducted by means of a Probabilistic Neural Network. The algorithm is tested with 17 ECG records obtained from the PhysioNet repository. The proposed classification procedure was tested initially on MATLAB and the results where compared with the equivalent analogue data fed to a DSP-based ECG data acquisition prototype through an arbitrary waveform generator. The results derived from confusion matrix tests yielded on-line classification accuracy of 92.69% (AF), 97.15% (N), 76.82% (PAC), 91.06% (LBBB), 87.5% (RBBB), 71.04% (PVC), 91.94% (SHB) and 95.45% (SVT), overall classification rate of 92.746% and 100% agreement between the MATLAB and on-line DSP implementations. The results suggest that the method and prototype presented may be suitable for being implemented on wearable sensing applications auxiliary for on-line, real-time diagnosis",The Authors. Published by Elsevier Ltd.,DSP-based arrhythmia classification using wavelet transform and probabilistic neural network ,10.1016/j.bspc.2016.10.005,https://core.ac.uk/download/pdf/81990661.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
227981804,2016-01-01T00:00:00,"Background: It has been revealed that Staphylococcus aureus enterotoxin B (SEB) may feature anti-cancer and anti-metastatic advantages due to its ability to modify cell immunity processes and signaling pathways. Glioblastoma is one of the most aggressive human cancers; it has a high mortality nature, which makes it an attractive area for the development of novel therapies. Objectives: We examined whether the SEB could exert its growth inhibitory effects on glioblastoma cells partially through the manipulation of a key tumor growth factor termed transforming growth factor-beta (TGF-Î²). Materials and Methods: A human primary glioblastoma cell line, U87, was treated with different concentrations of SEB. The cell quantity was measured by the MTT assay at different exposure times. For molecular assessments, total ribonucleic acid (RNA) was extracted from either non-treated or SEB-treated cells. Subsequently, the gene expression of TGF-Î² transducers, smad2/3, at the messenger RNA (mRNA) level, was analyzed via a quantitative real-time polymerase chain reaction (qPCR) using the SYBR Green method. Significant differences between cell viability and gene expression levels were determined (Prism 5.0 software) using a one-way analysis of variance (ANOVA) test. Results: We reported that SEB could effectively down-regulate smad2/3 expression in glioblastoma cells at concentrations as quantity as 1 Âµg/mL and 2 Âµg/mL (P < 0.05 and P < 0.01, respectively). The SEB concentrations effective at regulating smad2/3 expression were correlated with those used to inhibit the proliferation of glioblastoma cells. Our results also showed that SEB was able to decrease smad2/3 expression at the mRNA level in a concentration- and time-dependent manner. Conclusions: We suggested that SEB could represent an agent that can significantly decrease smad2/3 expression in glioblastoma cells, leading to moderate TGF-Î² growth signaling and the reduction of tumor cell proliferation. Â© 2016, Ahvaz Jundishapur University of Medical Sciences",,Staphylococcus aureus enterotoxin b down-regulates the expression of transforming growth factor-beta (TGF-Î²) signaling transducers in human glioblastoma,,https://core.ac.uk/download/227981804.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275623012,2016-10-26T00:00:00,"[EN] Lack of water in water supply systems forces people to take risk behaviors to health, which is very common in rural water supply systems (WSS-rural). The objective of this research was to develop and apply a multi-objective optimization model for WSS-rural in the county of Cuiabá, Mato Grosso State, Brazil. The research methodology consisted of: (1) formulation of the optimization model (OM); (2) application of OM; (3) analysis of results; and (4) computer implementation of OM. To solve the problem, it was proposed and used a load loss generator part. It was found that the problem of water shortage can be solved by small operational and structural modifications. It was developed a multi-objective OM for WSS-rural based on Multi-objective Nonlinear Integer Programming technique (MONLIP) implemented in OpenOffice.org environment. The developed OM was applied to a real case with satisfactory results.[PT] A falta de água em sistemas de abastecimento de água obriga a população a assumir comportamentos de risco à saúde, o que é muito frequente em sistemas de abastecimento de água rural (SAA-rural). O objetivo desta pesquisa foi desenvolver e aplicar um modelo de otimização multiobjetivo para SAA-rural no município de Cuiabá, Estado de Mato Grosso, Brasil. A metodologia de pesquisa constou de: (1) formulação do modelo de otimização (MO); (2) aplicação do MO; (3) análise de resultados; e (4) implementação computacional do MO. Para resolução do problema, foi proposta e utilizada uma peça geradora de perda de carga. Constatou-se que o problema de falta de água pode ser resolvido por meio de pequenas modificações operacionais e estruturais. Foi desenvolvido um MO multiobjetivo para SAA-rural, baseado na técnica de Programação Não Linear Inteira Multiobjetivo (PNLIMO) implementado em ambiente OpenOffice.org. O MO foi aplicado a um caso real, apresentando resultados satisfatórios.Silva, W.; Vieira, L.; Rosa, D.; Campos, M.; Santos, A.; Souza, M. (2016). Otimização multiobjetivo de sistema de abastecimento de água rural. Ingeniería del Agua. 20(4):217-232. doi:10.4995/ia.2016.5915.SWORD217232204Azevedo, R.P. (2004). Caracterização de sistema de abastecimento de água em comunidades rurais de várzea na Amazônia. Anais do 2° Seminário Internacional de Engenharia de Saúde Pública, Dezembro 1-3, Goiânia, Brasil, 705-710.Beinat, E. (1997). Value Functions for Environmental Managment. Kluwer Academic Publishers, Dordrecht, NED. doi:10.1007/978-94-015-8885-0Cuiabá. (2014). Prefeitura de Cuiabá: Bairros. Disponível em: http://www.cuiaba.mt.gov.br/imprime.php?cid=7884&sid=377. Acesso em: 05 de nov. 2014.Farmani, R., Walters, G., Savic, D. (2006). Evolutionary multi-objective optimization of the design and operation of water distribution network: total cost vs. reliability vs. water quality. Journal of Hydroinformatics, 8(3), 165-179. doi:10.2166/hydro.2006.019Ferreira, E.P., Ferreira, Y.P., Venturini, A.F., Moura, A.S., Rolim Neto, F.C. (2015). Saneamento rural - o desafio para o abastecimento de água em comunidades quilombolas no Estado de Alagoas. Anais do 28° Congresso Brasileiro de Engenharia Sanitária e Ambiental, Outubro 4-8, Rio de Janeiro, Brasil, 1-5.Francato, A.L., Barbosa, P.S.F. (2004). Soluções de compromisso na tomada de decisão sobre a operação diária de sistemas urbanos de abastecimento de água. Revista Brasileira de Recursos Hídricos, 9(2), 39-50. doi:10.21168/rbrh.v9n2.p39-50Fu, G., Butler, D., Khu, S.T. (2008). Multiple objectives optimal control of integrated urban wastewater systems. Environmental Modelling & Software, 23(2), 225-234. doi:10.1016/j.envsoft.2007.06.003Goicoechea, A., Hansen, D.R., Duckstein, L. (1982). Multiobjective Decision Analysis with Engineering and Business Applications. John Wiley & Sons, New York, USA.Jowitt, P.W., Germanopoulos, G. (1992). Optimal pump scheduling in water-supply networks. Journal of Water Resources Planning and Management, 118(4), 406-422. doi:10.1061/(ASCE)0733-9496(1992)118:4(406)Larock, B.E., Jeppson, R.W., Watters, G.Z. (2000). Hydraulics of Pipeline Systems. CRC Press LLC, Washington D.C., USA.León, C., Martín, S., Elena, J.M., Luque, J. (2000). EXPLORE - Hybrid expert system for water networks management. Journal of Water Resources Planning and Management, 126(2), 65-74. doi:10.1061/(ASCE)0733-9496(2000)126:2(65)Mackintosh, G., Colvin, C. (2003). Failure of rural schemes in South Africa to provide potable water. Environmental Geology, 44(1), 101-105. doi:10.1007/s00254-002-0704-yMakropoulos, C.K., Natsis, K., Liu, S., Mittas, K., Butler, D. (2008). Decision support for sustainable option selection in integrated urban water management. Environmental Modelling & Software, 23(12), 1448-1460. doi:10.1016/j.envsoft.2008.04.010Muthusi, F.M., Mahamud, G., Abdalle, A., Gadain, H.M. (2007). Rural Water Supply Assessment, Technical Report No-08, FAOSWALIM, Nairobi, Kenya. Disponível em: http://sddr.faoswalim.org/Documents_Repository/water_reports/W-08%20Rural%20Water%20Supply%20Assessment.pdf. Acesso em: 12 de mai. 2016.Nicochelli, L.M., Siqueira, A.J.B., Migliorini, R.B., Albrecht, K.J., Delguingaro, A.R. (2009). Análise de vulnerabilidade à contaminação de aqüífero no Distrito Industrial de Cuiabá - MT, através do método GOD. Anais do 14° Simpósio Brasileiro de Sensoriamento Remoto, Abril 25-30, São José dos Campos, Brasil, 4109-4116.PMSS. (2008). Municipalização dos Serviços de Abastecimento de Água e de Esgotamento Sanitário no Estado de Mato Grosso. Brasília. Disponível em: http://www.pmss.gov.br/. Acesso em: 29 de abr. 2011.Porto, A.L.L., Lanna, A.E.L., Braga Jr., B.P.F., Cirilo, J.A., Jahed Filho, K., Gobetti, L., Azevedo, L.G.T., Barros, M.T.L., Barbosa, P.S.F. (2002). Técnicas quantitativas para o gerenciamento de recursos hídricos. UFRGS/ABRH, Porto Alegre, BRA.Porto, R.M. (2001). Sistemas hidráulicos de tubulações. Em: Hidráulica Básica (R.M. Porto, ed.). EESC-USP, São Paulo, BRA, 93-117.Reis, M.G.C. (2004). Estabelecendo parcerias - ampliação da rede de abastecimento de água e implantação de sistema de esgotamento sanitário por meio de mutirão - a experiência do serviço autônomo de água e esgoto de Alagoinhas-BA. Anais do 2° Seminário Internacional de Engenharia de Saúde Pública, Dezembro 1-3, Goiânia, Brasil, 929-935.RWSN. (2010). Myths of the Rural Water Supply Sector. St.Gallen. Disponível em: http://www.ircwash.org/sites/default/files/RWSN-2010-Myths.pdf. Acesso em: 14 de mai. 2016.Sadeghi, G.H., Mohammadian, M., Nouran, M., Peyda, M., Eslami, A. (2007). Microbiological Quality Assessment of Rural Drinking Water Supplies in Iran. Journal of Agriculture & Social Sciences, 3(1), 31-33.Souza, K.S., Dutra, L.K.A., Rêgo, N.F.L., Silva, J.F. (2015). Levantamento das condições de saneamento na comunidade km 32, zona rural de Barreiras-BA. Anais do 21° Simpósio Brasileiro de Recursos Hídricos, Novembro 22-27, Brasília. Brasil, 1-8.Tsutiya, M.T. (2006). Redes de distribuição de água. Em: Abastecimento de água (M.T. Tsutiya, ed.). PHA-EPUSP, São Paulo, São Paulo, BRA, 389-455.Xie, X.F., Zhang, W.J., Yang, Z.L., (2002). Social cognitive optimization for nonlinear programming problems. Proceedings of the First International Conference on Machine Learning and Cybernetics, November 4-5, Beijing, CHN, 779-783.Zyl, J.E., Savic, D.A., Walters, G.A. (2004). Operational optimization of water distribution systems using a hybrid genetic algorithm. Journal of Water Resources Planning and Management, 130(2), 160-170. doi:10.1061/(ASCE)0733-9496(2004)130:2(160",'Universitat Politecnica de Valencia',Multi-objective optimization of rural water supply system,10.4995/ia.2016.5915,https://riunet.upv.es/bitstream/handle/10251/79492/5915-22789-1-PB.pdf?sequence=1&isAllowed=y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
304881195,2015,"Aquéllos que practican cualquier deporte, ya sea con objetivos competitivos o de salud, al tratar de mantener su condición física, se encuentran en un nivel que les permite ser útiles y al mismo tiempo prevenir sucesos traumáticos (Scotton et al 2006; Viru 2002). El atleta que compite, amateur o profesional, debe seguir estrictamente la periodización (Scotton, Gollin 2006) y el programa más adecuado para sus propósitos, privilegiando los medios y métodos de entrenamiento más afines y útiles para la formación durante el período especificado. Se sabe que al acercarse una carrera, el tipo de entrenamiento seguido se parece cada vez más a la competición. Se trata de un hábito establecido para aquéllos que realizan cualquier actividad deportiva (Scotton 2003) con fines competitivos, tratar de mantener la eficiencia en el sistema músculo-esquelético y los sistemas conectados a él (Wilmore, Costill 2005), para obtener diversión y, de paso, condición física, sin considerar demasiado las reglas que regulan la formación deportiva. Un sujeto no profesional que usa el monitor de frecuencia cardíaca Polar S710i ha realizado dos sesiones de entrenamiento en una bicicleta de montaña de recorrido libre en dos días separados y en la misma ruta. El software del instrumento permite superponer los archivos del mismo para resaltar las similitudes de las secciones principales de las sesiones: duración de ascenso y descenso con la velocidad obtenida y los kilómetros recorridos, la frecuencia cardíaca media y máxima para las fracciones individuales, y el entrenamiento total. Objetivo: En este trabajo se propone usar los datos recogidos en un recorrido ""real"" para permitir que el atleta pueda replicarlos en casa o en el gimnasio, manteniendo los ritmos cardíacos durante el tiempo indicado mediante la combinación del uso de rodillos, sobre los que se coloca la bicicleta, y el uso del monitor de frecuencia cardíaca (Wirnitzer, Kornexl 2008).Who practice sports, whether with competitive or health objectives, while trying to maintain their physical condition, are at a level that allows them to be useful and at the same time prevent traumatic events (Scotton et al 2006; Viru 2002). The athlete who competes, amateur or professional, must strictly follow the periodization (Scotton, Gollin 2006) and the most suitable program for his purposes, privileging the most compatible and useful means and training methods during the specified period. It is known that when a race is approaching, the type of training followed looks more and more like competition. It is a habit established for those who practice any sports activity (Scotton 2003) for competitive purposes, trying to maintain efficiency in the musculoskeletal system and the systems connected to it (Wilmore, Costill 2005), to get fun and, in passing, physical condition, without considering too much the rules that regulate sports training. A non-professional subject using the Polar S710i heart rate monitor has performed two training sessions on a free-riding mountain bike on two separate days and on the same route. The software of the instrument allows superimposing the files of the same to highlight the similarities of the main sections of the sessions: duration of ascent and descent with the speed obtained and the kilometers traveled, the average and maximum heart rates for the individual fractions, and the training total. Objective: In this work we propose to use the data collected in a ""real"" route to allow the athlete to replicate them at home or in the gym, maintaining the heart rhythms during the indicated time by combining the use of rollers, on which the bicycle is placed, and the use of the heart rate monitor is used (Wirnitzer, Kornexl 2008).Chi pratica sport, sia con obiettivi agonistici sia di fitness, cerca di mantenere il proprio stato di forma ad un livello che gli permetta di essere prestativo e contemporaneamente di prevenire eventi traumatici (Scotton et al. 2006; Viru 2002). L’atleta che compete, amatore o professionista, dovrebbe seguire scrupolosamente la periodizzazione (Scotton, Gollin 2006) e la programmazione più idonee ai propri scopi, privilegiando i mezzi e i metodi di allenamento più congeniali a lui e più utili per lo specifico periodo. E’ noto che quando si avvicinano le gare il tipo di allenamento seguito assomiglia sempre più alla tipologia di competizione. E’ abitudine consolidata per chi svolge una qualsiasi specialità sportiva (Scotton 2003) con finalità non agonistiche cercare di mantenere efficiente l’apparato locomotore ed i sistemi ad esso collegati (Wilmore, Costill 2005) per ottenere divertimento e, appunto, il fitness, senza considerare troppo le norme che regolano l’allenamento sportivo. Un soggetto, non professionista, indossando il cardiofrequenzimetro Polar S710i ha effettuato due sessioni di allenamento su una mountain bike da free-ride in due distinte giornate e sullo stesso percorso. Il software dello strumento consente di sovrapporre i files del medesimo giro evidenziando le somiglianze dei tratti principali delle sedute: la durata della salita e della discesa con le velocità ottenute e i km percorsi, le frequenze cardiache medie e massime relative alle singole frazioni dell’allenamento e nel totale. Obiettivo: Nel lavoro si propone di utilizzare i dati raccolti sul percorso “reale” per permettere all’atleta di replicarlo a casa o in palestra mantenendo le frequenze cardiache per il tempo indicato abbinando all’uso dei rulli, su cui è posizionata la bicicletta, anche l’impiego del cardiofrequenzimetro (Wirnitzer, Kornexl 2008).peerReviewe",Federación Extremeña de Balonmano y Universidad de Extremadura,"Mountain bike, monitoring and heart rate monitor",,,"[{'title': None, 'identifiers': ['issn:1885-7019', '1885-7019']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
212253632,2018-01-01T00:00:00,"Running has a positive impact on human health and is an accessible sport for most people. There is high demand for tracking running performance and progress for amateurs and professionals alike. The parameters velocity and distance are thereby of main interest. In this work, we evaluate the accuracy of four algorithms, which calculate the stride velocity and stride length during running using data of an inertial measurement unit (IMU) placed in the midsole of a running shoe. The four algorithms are based on stride time, foot acceleration, foot trajectory estimation, and deep learning, respectively. They are compared using two studies: a laboratory-based study comprising 2377 strides from 27 subjects with 3D motion tracking as a reference and a field study comprising 12 subjects performing a 3.2-km run in a real-world setup. The results show that the foot trajectory estimation algorithm performs best, achieving a mean error of 0.032 ± 0.274 m/s for the velocity estimation and 0.022 ± 0.157 m for the stride length. An interesting alternative for systems with a low energy budget is the acceleration-based approach. Our results support the implementation decision for running velocity and distance tracking using IMUs embedded in the sole of a running shoe",'MDPI AG',Comparison of Different Algorithms for Calculating Velocity and Stride Length in Running Using Inertial Measurement Units,10.3390/s18124194,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201982431,2015-12-31,"AbstractThe quality of machine translation is rapidly evolving. Today one can find several machine translation systems on the web that provide reasonable translations, although the systems are not perfect. In some specific domains, the quality may decrease. A recently proposed approach to this domain is neural machine translation. It aims at building a jointly-tuned single neural network that maximizes translation performance, a very different approach from traditional statistical machine translation. Recently proposed neural machine translation models often belong to the encoder-decoder family in which a source sentence is encoded into a fixed length vector that is, in turn, decoded to generate a translation. The present research examines the effects of different training methods on a Polish-English Machine Translation system used for medical data. The European Medicines Agency parallel text corpus was used as the basis for training of neural and statistical network-based translation systems. The main machine translation evaluation metrics have also been used in analysis of the systems. A comparison and implementation of a real-time medical translator is the main focus of our experiments",The Authors. Published by Elsevier B.V.,Neural-based Machine Translation for Medical Text Domain. Based on European Medicines Agency Leaflet Texts ,10.1016/j.procs.2015.08.456,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
216279954,2017-11-01T00:00:00,"Accurately detecting and counting sparse bacterial samples has many applications in the food, beverage, and pharmaceutical processing industries, in medical diagnostics, and for life detection by robotic missions to other planets and moons of the solar system. Currently, sparse bacterial samples are counted by culture plating or epifluorescence microscopy. Culture plates require long incubation times (days to weeks), and epifluorescence microscopy requires extensive staining and concentration of the sample. Here, we demonstrate how to use off-axis digital holographic microscopy (DHM) to enumerate bacteria in very dilute cultures (100-104 cells/mL). First, the construction of the custom DHM is discussed, along with detailed instructions on building a low-cost instrument. The principles of holography are discussed, and a statistical model is used to estimate how long videos should be to detect cells, based on the optical performance characteristics of the instrument and the concentration of the bacterial solution (Table 2). Video detection of cells at 105, 104, 103, and 100 cells/mL is demonstrated in real time using un-reconstructed holograms. Reconstruction of amplitude and phase images is demonstrated using an open-source software package",'MyJove Corporation',Quantifying Microorganisms at Low Concentrations Using Digital Holographic Microscopy (DHM),,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
82220257,2015-12-31,"AbstractThe quality of machine translation is rapidly evolving. Today one can find several machine translation systems on the web that provide reasonable translations, although the systems are not perfect. In some specific domains, the quality may decrease. A recently proposed approach to this domain is neural machine translation. It aims at building a jointly-tuned single neural network that maximizes translation performance, a very different approach from traditional statistical machine translation. Recently proposed neural machine translation models often belong to the encoder-decoder family in which a source sentence is encoded into a fixed length vector that is, in turn, decoded to generate a translation. The present research examines the effects of different training methods on a Polish-English Machine Translation system used for medical data. The European Medicines Agency parallel text corpus was used as the basis for training of neural and statistical network-based translation systems. The main machine translation evaluation metrics have also been used in analysis of the systems. A comparison and implementation of a real-time medical translator is the main focus of our experiments",The Authors. Published by Elsevier B.V.,Neural-based Machine Translation for Medical Text Domain. Based on European Medicines Agency Leaflet Texts ,10.1016/j.procs.2015.08.456,https://core.ac.uk/download/pdf/82220257.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275615551,2014-11-01T00:00:00,"© ACM (2014). This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in {Source Publication}, http://dx.doi.org/10.1145/2693787.2693794Looking for effective ways to understand how animals interact with computer-mediated systems, Animal-Computer Interaction (ACI) research should rely on the most natural and intrinsic behavior among the majority of living species: play. Animals are naturally motivated towards playing. Playful environments are, therefore, a promising scenario in which to start developing animal-centered ecosystems, and there are plenty of circumstances where playful environments could help to improve animals  well-being. However, developing a custom system for each possible context remains unfeasible, and more appealing solutions are required. If playful environments were equipped with intelligent capabilities, they could learn from the animals  behavior and automatically adapt themselves to the animals  needs and preferences by creating engaging playful activities for different purposes. Hence, this work will define intelligent playful environments for animals and explain how Ambient Intelligence (AmI) can contribute to create adaptable playful experiences for animals in order to improve their quality of life.This work was partially funded by the Spanish Ministry of Science and Innovation under the National R&D&I Program within the project CreateWorlds (TIN2010-20488). It also received support from a postdoctoral fellowship within the VALi+d Program of the Conselleria d'Educació, Cultura i Esport (Generalitat Valenciana) awarded to Alejandro Catalá (APOSTD/2013/013). The work of Patricia Pons has been supported by the Universitat Politecnica de Valencia under the 'Beca de Excelencia"" program, and currently by an FPU fellowship from the Spanish Ministry of Education, Culture and Sports (FPU13/03831).Pons Tomás, P.; Jaén Martínez, FJ.; Catalá Bolós, A. (2014). Animal Ludens: Building Intelligent Playful Environments for Animals. ACM. https://doi.org/10.1145/2693787.2693794SAlfrink, K., Peer, I. van, Lagerweij, H., Driessen, C., Bracke, M., and Copier, M. Pig Chase. Playing with Pigs project. 2012. www.playingwithpigs.nl.Amat, M., Camps, T., Brech, S. Le, and Manteca, X. Separation anxiety in dogs: the implications of predictability and contextual fear for behavioural treatment. Animal Welfare 23, 3 (2014), 263--266.Barker, S. B. and Dawson, K. S. The effects of animal-assisted therapy on anxiety ratings of hospitalized psychiatric patients. Psychiatric services 49, 6 (1998), 797--801.Bateson, P. and Martin, P. Play, Playfulness, Creativity and Innovation. Cambridge University Press, 2013.Bekoff, M. and Allen, C. Intentional communication and social play: how and why animals negotiate and agree to play. In Animal play: Evolutionary, comparative, and ecological perspectives. Cambridge University Press, 1997.Burghardt, G. M. The genesis of animal play. Testing the limits. MIT Press, 2006.Catal&#225;, A., Ja&#233;n, J., Pons, P., and Garc&#237;a-Sanjuan, F. Playful Creativity: Playing to Create Games on Surfaces. In A. Nijholt, ed., Playful User Interfaces. Springer Singapore, Singapore, 2014, 293--315.Catal&#225;, A., Pons, P., Ja&#233;n, J., Mochol&#237;, J. A., and Navarro, E. A meta-model for dataflow-based rules in smart environments: Evaluating user comprehension and performance. Science of Computer Programming 78, 10 (2013), 1930--1950.Cheok, A. D., Tan, R. T. K. C., Peiris, R. L., et al. Metazoa Ludens: Mixed-Reality Interaction and Play for Small Pets and Humans. IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans 41, 5 (2011), 876--891.Costello, B. and Edmonds, E. A Study in Play, Pleasure and Interaction Design. Proceedings of the 2007 conference on Designing pleasurable products and interfaces, (2007), 76--91.Csikszentmihalyi, M. Beyond Boredom and Anxiety. The Experience of Play in Work and Games. Jossey-Bass Publishers, 1975.Filan, S. L. and Llewellyn-Jones, R. H. Animal-assisted therapy for dementia: a review of the literature. International psychogeriatrics / IPA 18, 4 (2006), 597--611.Huizinga, J. Homo ludens. 1985.Kamioka, H., Okada, S., Tsutani, K., et al. Effectiveness of animal-assisted therapy: A systematic review of randomized controlled trials. Complementary therapies in medicine 22, 2 (2014), 371--390.Lee, S. P., Cheok, A. D., James, T. K. S., et al. A mobile pet wearable computer and mixed reality system for human--poultry interaction through the internet. Personal and Ubiquitous Computing 10, 5 (2006), 301--317.Mancini, C., van der Linden, J., Bryan, J., and Stuart, A. Exploring interspecies sensemaking: Dog Tracking Semiotics and Multispecies Ethnography. Proceedings of the 2012 ACM Conference on Ubiquitous Computing - UbiComp '12, ACM Press (2012), 143--152.Mancini, C. Animal-computer interaction: a manifesto. Magazine interactions 18, 4 (2011), 69--73.Mancini, C. Animal-computer interaction (ACI): changing perspective on HCI, participation and sustainability. CHI '13 Extended Abstracts on Human Factors in Computing Systems, ACM Press (2013), 2227--2236.Mankoff, D., Dey, A. K., Mankoff, J., and Mankoff, K. Supporting Interspecies Social Awareness: Using peripheral displays for distributed pack awareness. Proceedings of the 18th annual ACM symposium on User interface software and technology, (2005), 253--258.Matsuzawa, T. The Ai project: historical and ecological contexts. Animal cognition 6, 4 (2003), 199--211.McGrath, R. E. Species-appropriate computer mediated interaction. Proceedings of the 27th international conference extended abstracts on Human factors in computing systems - CHI EA '09, ACM Press (2009), 2529--2534.Norman, D. A. The invisible computer. MIT Press, Cambridge, MA, USA, 1998.Noz, F. and An, J. Cat Cat Revolution: An Interspecies Gaming Experience. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, (2011), 2661--2664.Paldanius, M., K&#228;rkk&#228;inen, T., V&#228;&#228;n&#228;nen-Vainio-Mattila, K., Juhlin, O., and H&#228;kkil&#228;, J. Communication technology for human-dog interaction. Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11, ACM Press (2011), 2641--2650.Pons, P., Catala, A., and Jaen, J. Customizing smart environments: a tabletop approach. Journal of Ambient Intelligence and Smart Environments, in press.Rumbaugh, D. M. Language learning by a chimpanzee: the Lana Project. Academic Press, 1977.Schwartz, S. Separation anxiety syndrome in cats: 136 cases (1991--2000). Journal of the American Veterinary Medical Association 220, 7 (2002), 1028--1033.Schwartz, S. Separation anxiety syndrome in dogs and cats. Journal of the American Veterinary Medical Association 222, 11 (2003), 1526--1532.Solomon, O. What a Dog Can Do: Children with Autism and Therapy Dogs in Social Interaction. Ethos: Journal of the Society for Psychological Anthropology 38, 1 (2010), 143--166.Teh, K. S., Lee, S. P., and Cheok, A. D. Poultry. Internet: a remote human-pet interaction system. CHI '06 Extended Abstracts on Human Factors in Computing Systems, (2006), 251--254.Weilenmann, A. and Juhlin, O. Understanding people and animals. Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11, ACM Press (2011), 2631--2640.Weiser, M. The computer for the 21st century. Scientific American 265, 3 (1991), 94--104.Wingrave, C. A., Rose, J., Langston, T., and LaViola, J. J. J. Early explorations of CAT: canine amusement and training. CHI '10 Extended Abstracts on Human Factors in Computing Systems, (2010), 2661--2669.Young, J., Young, N., Greenberg, S., and Sharlin, E. Feline Fun Park: A Distributed Tangible Interface for Pets and Owners. 2013. https://www.youtube.com/watch?v=HB5LsSYkhCc",'Association for Computing Machinery (ACM)',Animal Ludens: Building Intelligent Playful Environments for Animals,10.1145/2693787.2693794,https://riunet.upv.es/bitstream/handle/10251/68376/Animal%20Ludens.%20Building%20Intelligent%20Pla...ments%20for%20Animals%20-%20author%20version.pdf?sequence=3&isAllowed=y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54818755,2015-01-01T00:00:00,"The topic of energy efficiency applied to buildings represents one of the key aspects in today\u2019s interna- tional energy policies. Emissions reduction and the achievement of the targets set by the Kyoto Protocol are becoming a fundamental concern in the work of engineers and technicians operating in the energy management field. Optimal energy management practices need to deal with uncertainties in generation and demand, hence the development of reliable forecasting methods is an important priority area of research in electric energy systems. This paper presents a load forecasting model and the way it was applied to a real case study, to forecast the electrical consumption of the Cellini medical clinic of Turin. The model can be easily integrated into a Building Management System or into a real time monitoring system. The load forecasting is performed through the implementation of an artificial neural network (ANN). The proposed multi-layer perceptron ANN, based on a back propagation training algorithm, is able to take as inputs: loads, data concerning the type of day (e.g. weekday/holiday), time of the day and weather data. In particular, this work focuses on providing a detailed analysis and an innovative formal procedure for the selection of all the ANN parameters",'Elsevier BV',Electrical consumption forecasting in hospital facilities: An application case,10.1016/j.enbuild.2015.05.056,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
151188608,2018-02-12T15:59:05,"This is the final version of the article. Available from BMJ Publishing Group via the DOI in this record.Objective Bisphenol A (BPA) has been associated with adverse human health outcomes and exposure to this compound is near-ubiquitous in the Western world. We aimed to examine whether self-moderation of BPA exposure is possible by altering diet in a real-world setting.

Design An Engaged Research dietary intervention study designed, implemented and analysed by healthy teenagers from six schools and undertaken in their own homes.

Participants A total of 94 students aged between 17 and 19 years from schools in the South West of the UK provided diet diaries and urine samples for analysis.

Intervention Researcher participants designed a set of literature-informed guidelines for the reduction of dietary BPA to be followed for 7 days.

Main outcome measures Creatinine-adjusted urinary BPA levels were taken before and after the intervention. Information on packaging and food/drink ingested was used to calculate a BPA risk score for anticipated exposure. A qualitative analysis was carried out to identify themes addressing long-term sustainability of the diet.

Results BPA was detected in urine of 86% of participants at baseline at a median value of 1.22 ng/mL (IQR 1.99). No effect of the intervention diet on BPA levels was identified overall (P=0.25), but there was a positive association in those participants who showed a drop in urinary BPA concentration postintervention and their initial BPA level (P=0.003). Qualitative analysis identified themes around feelings of lifestyle restriction and the inadequacy of current labelling practices.

Conclusions We found no evidence in this self-administered intervention study that it was possible to moderate BPA exposure by diet in a real-world setting. Furthermore, our study participants indicated that they would be unlikely to sustain such a diet long term, due to the difficulty in identifying BPA-free foods.This study was funded by a Wellcome Trust People Award to LWH and TSG (grant no 105162/Z/14/Z). TSG was additionally supported by NERC awards NE/L007010 and NE/N006178/",'BMJ',An engaged research study to assess the effect of a ‘real-world’ dietary intervention on urinary bisphenol A (BPA) levels in teenagers,10.1136/bmjopen-2017-018742,https://core.ac.uk/download/151188608.pdf,"[{'title': 'BMJ Open', 'identifiers': ['2044-6055', 'issn:2044-6055']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201560160,2018-11-01T00:00:00,"Running has a positive impact on human health and is an accessible sport for most people. There is high demand for tracking running performance and progress for amateurs and professionals alike. The parameters velocity and distance are thereby of main interest. In this work, we evaluate the accuracy of four algorithms, which calculate the stride velocity and stride length during running using data of an inertial measurement unit (IMU) placed in the midsole of a running shoe. The four algorithms are based on stride time, foot acceleration, foot trajectory estimation, and deep learning, respectively. They are compared using two studies: a laboratory-based study comprising 2377 strides from 27 subjects with 3D motion tracking as a reference and a field study comprising 12 subjects performing a 3.2-km run in a real-world setup. The results show that the foot trajectory estimation algorithm performs best, achieving a mean error of 0.032 &#177; 0.274 m/s for the velocity estimation and 0.022 &#177; 0.157 m for the stride length. An interesting alternative for systems with a low energy budget is the acceleration-based approach. Our results support the implementation decision for running velocity and distance tracking using IMUs embedded in the sole of a running shoe",'MDPI AG',Comparison of Different Algorithms for Calculating Velocity and Stride Length in Running Using Inertial Measurement Units,10.3390/s18124194,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201582198,2018-09-01T00:00:00,"Abstract Automation and reliability are the crucial elements of any advance reverse osmosis plant to meet the environmental and economic demands. Early fault indication, diagnosis and regular maintenance are the key challenges with most of the reverse osmosis plants in the Indian scenario. The present work introduces a modern reverse osmosis (RO) plant status monitoring unit to monitor different plant parameters in real time and early prediction for faults and maintenance. Developed RO plant status monitoring unit consists of a touch screen-based embedded monitoring unit, water quality sensors (pH, TDS), sampling chamber for controlled water flow, flow sensors, pressure and level sensors. The present system has been developed in a modular fashion so that it could be integrated with any capacity of RO plant units. Developed embedded system monitors various parameters of the plant such as input power, efficiency of the plant, level of input and output water tank and also guides operator with instructions for plant operation. Other than this, a dedicated smartphone app interface has been developed for the operator to acquire data from status monitoring unit, storage on smartphone, and transfer it to the cloud. The developed smartphone-based app also provides facility to integrate plant data with Google map with location information for easy understanding and quick action. The system has also a backup facility to transfer data to the server using 2G GSM module during the unavailability of the operator. A dedicated centralized Web server has been developed for real-time visualization of all installed RO plant status monitoring units. Different machine learning techniques have been implemented on acquired sensors data to predict early warnings related to power failure, membrane fouling and scaling, input water shortage, pipe, tank leakage, water quality sensors damage, non-operation or wrong operation of the plant along with different maintenance actions such as membrane water and chemical wash. Developed RO status monitoring unit has been tested with various RO plants having capacity from 500 LPH to 2000 LPH and deployed at various nearby villages of Rajasthan",'Springer Science and Business Media LLC',Design and development of reverse osmosis (RO) plant status monitoring system for early fault prediction and predictive maintenance,10.1007/s13201-018-0821-8,,"[{'title': 'Applied Water Science', 'identifiers': ['issn:2190-5495', '2190-5487', '2190-5495', 'issn:2190-5487']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
81924539,2016-12-31,"AbstractDetection and classification of electrocardiogram (ECG) signals are critically linked to the diagnosis abnormalities. Any abnormality in the wave shape and duration of the wave features of the ECG is considered as arrhythmia. This paper presents a diagnostic system for classification of cardiac arrhythmia from ECG data, using hybrid model of Artificial Neural Network and Fuzzy Logic. In an ECG, clinically useful information is obtained from the intervals and amplitudes of the cardiac waves. In an ECG, the non-stationary signal commonly changed its statistical property with time. In the proposed paper an algorithm based on wavelet packet tree classifier (for detection of QRS complex) has been implemented for the comparative study of automatic real-time ECG data. The amplitude and duration of the characteristic waves of the ECG can be more accurately obtained using Wavelet Packet Tree (WPT) analysis. WPT techniques have been employed to extract a set of linear (time and frequency domain) characteristics. Neuro-fuzzy techniques have been employed to extract a set of non-linear characteristic features from the transformed ECG signals. The real-time signals are obtained from various diagnostic centers. The hybrid model of Wavelet Packet Tree and Neuro-fuzzy network is proposed for the analysis and comparative study of an ECG signal",Published by Elsevier B.V.,A Neuro-fuzzy Based Model for Analysis of an ECG Signal Using Wavelet Packet Tree ,10.1016/j.procs.2016.07.343,https://core.ac.uk/download/pdf/81924539.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
93648242,2016-01-01T00:00:00,"Biomedical systems produce biosignals that arise from interaction mechanisms. In a
general form, those mechanisms occur across multiple scales, both spatial and temporal, and contain
linear and non-linear information. In this framework, entropy measures are good candidates in
order provide useful evidence about disorder in the system, lack of information in time-series
and/or irregularity of the signals. The most common movement disorder is essential tremor (ET),
which occurs 20 times more than Parkinson’s disease. Interestingly, about 50%–70% of the cases of ET
have a genetic origin. One of the most used standard tests for clinical diagnosis of ET is Archimedes’
spiral drawing. This work focuses on the selection of non-linear biomarkers from such drawings and
handwriting, and it is part of a wider cross study on the diagnosis of essential tremor, where our
piece of research presents the selection of entropy features for early ET diagnosis. Classic entropy
features are compared with features based on permutation entropy. Automatic analysis system
settled on several Machine Learning paradigms is performed, while automatic features selection is
implemented by means of ANOVA (analysis of variance) test. The obtained results for early detection
are promising and appear applicable to real environments",'MDPI AG',Selection of Entropy Based Features for Automatic Analysis of Essential Tremor,10.3390/e18050184,,"[{'title': 'Entropy', 'identifiers': ['1099-4300', 'issn:1099-4300']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
287755460,2015-12-30T00:00:00,"[EN] The Bachelor’s Degree in Agrifood and Rural Engineering at Universitat Jaume I of Castelló has implemented in the second academic year a multidisciplinary project using a Project-Based Learning as the teaching method. Its final purpose is the acquisition of skills that should help the students to cope with their future career. This teaching-learning system has been  used  for  three  consecutive  years since the degree was firstly implemented. Once  a  particular  farm  is  assigned,  the students are organized in groups and must   fulfill   their   assigned   tasks   in   a collaborative manner with the final goal of developing a project on that farm including viable improvements of the exploitation,   taking   into   account   the issues  related  to  the  different  subjects involved.  This  work  presents  the  results obtained along the three years, analyzed from two different points of view: student satisfaction    and    learning    outcomes. Besides,  the  proposals  for  impro[ES] El grado de Ingeniería Agroalimentaria y del Medio Rural de la Universitat Jaume I de Castelló viene aplicando, en su segundo curso, un proyecto multidisciplinar utilizando el Aprendizaje Basado en Proyectos como recurso docente y pretende que los estudiantes adquieran competencias que les ayuden a enfrentarse a su futuro profesional. Este sistema de enseñanza-aprendizaje se ha llevado a cabo durante los tres cursos que está implantado el grado. Una vez asignado un tipo de explotación agrícola concreta y utilizando las herramientas del trabajo en equipo, los estudiantes deben ser capaces de desarrollar un proyecto sobre la explotación con propuestas de mejora que sean factibles y que abarquen aspectos relacionados con las diferentes disciplinas implicadas, aplicando los conocimientos adquiridos en éstas. El presente trabajo incluye los resultados obtenidos durante los tres años del proyecto desde dos puntos de vista importantes: la satisfacción del estudiante y los resultados de aprendPina Desfilis, MT.; Aguilar Fenollosa, E.; Camañes Querol, G.; Marqués Marzal, AI.; Rodríguez-Sánchez, A.; Fernández-Crespo, E.; Llorens Vilarrocha, E.... (2015). Implementation of a Project-Based Learning to the coordination of subjects in the Agrifood and Rural Engineering Bachelor. REDU. Revista de Docencia Universitaria. 13(3):265-288. https://doi.org/10.4995/redu.2015.5429OJS265288133Akınoğlu, O. and Tandoğan, R. O. (2007). The effects of problema-based active learning in science education on student ́s acadèmic achivement, attitude and concept learning. Eurasia Journal of Mathematics, Science & Technology Education, 3, 1, pp. 71-81.Branda, L. A. (2009). L'aprenentatge basat en problemes, en AA.VV. L'aprenentatge basat en problemes, Cerdanyola del Vallès: IDES-UAB.Belbin, R. M. (1981). Management Teams: Why They Succeed or Fail, Oxford, UK: Butterworth-Heinemann.Blank, W. (1997). Authentic instruction. In W.E. Blank & S. Harwell (Eds.), Promising practices for connecting high school to the real world, pp. 15-21. Tampa, FL: University of South Florida. (ERIC Document Reproduction Service No. ED407586).Bouhuijs, P. A. J. (2011). Implementing Problem Based Learning: Why is it so hard? REDU - Revista de Docencia Universitaria, 9, 1, pp. 17-24.Buckley, F. J. (1998). Team Teaching: What, Why, and How? Thousand Oaks, CA, Sage.Buela-Casal, G. and Sierra, J. C. (2007). Criterios, indicadores y estándares para la acreditación de Profesores Titulares y Catedráticos de Universidad. Psicothema, 19, pp. 357-369Dickinson, K. P., Soukamneuth, S., Yu, H. C., Kimball, M., D'Amico, R., Perry, R., etal.(1998). Providing educational services in the Summer Youth Employment and Training Program (Technical assistance guide). Washington, DC: U.S. Department of Labor, Office of Policy & Research. (ERIC Document Reproduction Service No. ED420756)Esteban-Guitart, M. (2009). Un estudio empírico sobre las ventajas e inconvenientes del Aprendizaje Basado en Problemas (ABP) en grupos numerosos. Aprender. Caderno de Filosofia e Psicologia da educaçao, 7, pp. 131-145.Esteban-Guitart, M. (2011). Del ""Aprendizaje Basado En Problemas"" (ABP) al ""Aprendizaje Basado En La Acción"" (ABA). Claves para su complementariedad e implementación. Revista de Docencia Universitaria, 9, 1, pp. 91-107.Harwell, S. (1997). Project-based learning. In W.E. Blank & S. Harwell (Eds.), Promising practices for connecting high school to the real world (pp. 23-28). Tampa, FL: University of South Florida. (ERIC Document Reproduction Service No. ED407586).Hersey, P., Blanchard, K. H. and Johnson D. E. (2001). Management of Organizational Behavior: Leading Human Resources. (8th ed). New Jersey: Prentice-Hall, Inc.Ivins, J. R. (1997). Interdisciplinary project work: practice makes perfect? EEE Transactions on Education, 40 (3) pp. 179-183.Jones, C. (2009). Interdisciplinary Approach - Advantages, Disadvantages, and the Future Benefits of Interdisciplinary Studies, ESSAI: Vol. 7, Article 26. Available at: http://dc.cod.edu/essai/vol7/iss1/26.Kjersdam, F. and Enemark, S. (1994). The Aalborg experiment, project innovation in university education. Aalborg: The University of Aalborg Press.Kozlowski, S. W. J. and Ilgen, D. R. (2006). Enhancing the efectiveness of work groups and teams. Psychological Science in the Public Interest, 7(3), 77-124.László, E. (2004). Tú puedes cambiar el mundo: manual del ciudadano global para lograr un mundo sostenible y sin violencia. Budapest: Ediciones Nowtilus.Llorens, E. & Lapeña, L. (2014). Application of Google Drive software as a resource for teamwork. Proccedings of XVII International Congress EDUTEC (In press).Maynard, M. T., Mathieu, J. E., Rapp, T. L. and Gilson, L. L. (2012). Something(s) old and something(s) new: Modeling drivers of global virtual team effectiveness. Journal of Organizational Behavior, 33,342-365.Moursund, D., Bielefeldt, T. and Underwood, S. (1997). Foundations for The Road Ahead: Project-based learning and information technologies. Washington, DC: National foundation for the Improvement of Education. Available at: http://www.iste.org/research/roadahead/pbl.html.Nunes de Oliveira, J.M. (2011). Nine tears of Project-Based Learning in Engineering. REDU - Revista de Docencia Universitaria, 9(1). Número monográfico, especial dedicado al Aprendizaje basado en Problemas. Recuperado el 28 de julio de 2014 en http://red-u.net/redu/files/journals/1/articles/192/public/192-198-2-PB.pdf.Oakley, B. (2004). Coping with Hitchhikers and Couch Potatoes on Teams. Journal of Student Centered Learning, 2, 1, pp. 32-34.Parker, G. M. (2008). Team players and teamwork: New strategies for developing successful collaboration. John Wiley & Sons.Rosenfield, P. L. (1992). The potential of transdisciplinary research for sustaining and extending linkages between the health and social sciences. Social science & medicine, 35(11), 1343-1357.Rué, J., Font, A., Cebrián, G. (2011). El ABP, un enfoque estratégico para la formación en educación superior. Aportaciones de un análisis de la formación en derecho. REDU - Revista de Docencia Universitaria, 9, 1, pp. 25-44.Sáez de Cámara Oleaga, E., Guisasola Aranzabal, J., Garmendia Mujika, M. (2013). Implementación y resultados obtenidos en una propuesta de Aprendizaje Basado en Problemas en el Grado en Ingeniería Ambiental. REDU - Revista de Docencia Universitaria, 11, pp. 85-112.Valero, M., Navarro, J. (2009). La planificación del trabajo del estudiante y el desarrollo de su autonomía en el aprendizaje basado en proyectos en SEVILL A, J (coord.). La metodología del aprendizaje basado en problemas. Universidad de Murcia: Murcia.Velez de C. A. (1998). Aprendizaje basado en proyectos colaborativos en la educaión superior. IV Congresso RIBIE, Brasilia. Available at: http://hera.fed.uva.es/~ivanjo/bersatide/ayudas/APP%20EN%20EDUC%20SUPERIOR.pdfVera, M., Salanova, M. and Martín del Río, B. (2010). University faculty and work-related well-being: the importance of the triple work profile (Profesores universitarios y bienestar:La importancia del triple perfil laboral). Electronic Journal of Research in Educational Psychology, 8, pp. 581-602.Wageman, R., Gardner, H. and Mortensen, M. (2012). The changing ecology of teams: New directions for teams research. Journal of Organizational Behavior, 33, pp. 301-31",'Universitat Politecnica de Valencia',Utilización de Aprendizaje Basado en Proyectos en la coordinación de asignaturas en el Grado en Ingeniería Agroalimentaria y del Medio Rural,10.4995/redu.2015.5429,https://riunet.upv.es/bitstream/10251/137500/1/Pina%3bAguilar%3bCama%c3%b1es%20-%20Implementation%20of%20a%20Project-Based%20Learning%20to%20the%20coordination%20of%20subjects....pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275626014,2017-04-01T00:00:00,"Progress in biomechanical modelling of human soft tissue is the basis for the development of new clinical applications capable of improving the diagnosis and treatment of some diseases (e.g. cancer), as well as the surgical planning and guidance of some interventions. The finite element method (FEM) is one of the most popular techniques used to predict the deformation of the human soft tissue due to its high accuracy. However, FEM has an associated high computational cost, which makes it difficult its integration in real-time computer-aided surgery systems. An alternative for simulating the mechanical behaviour of human organs in real time comes from the use of machine learning (ML) techniques, which are much faster than FEM. This paper assesses the feasibility of ML methods for modelling the biomechanical behaviour of the human liver during the breathing process, which is crucial for guiding surgeons during interventions where it is critical to track this deformation (e.g. some specific kind of biopsies) or for the accurate application of radiotherapy dose to liver tumours. For this purpose, different ML regression models were investigated, including three tree-based methods (decision trees, random forests and extremely randomised trees) and other two simpler regression techniques (dummy model and linear regression). In order to build and validate the ML models, a labelled data set was constructed from modelling the deformation of eight ex-vivo human livers using FEM. The best prediction performance was obtained using extremely randomised trees, with a mean error of 0.07 mm and all the samples with an error under 1 mm. The achieved results lay the foundation for the future development of some real-time software capable of simulating the human liver deformation during the breathing process during clinical interventions.This work has been funded by the Spanish Ministry of Economy and Competitiveness (MINECO) through research projects TIN2014-52033-R and DPI2013-40859-R, both also supported by European FEDER funds. The authors acknowledge the kind collaboration of the personnel from the hospital involved in the research.Lorente, D.; Martínez-Martínez, F.; Rupérez Moreno, MJ.; Lago, MA.; Martínez-Sober, M.; Escandell-Montero, P.; Martínez-Martínez, JM.... (2017). A framework for modelling the biomechanical behaviour of the human liver during breathing in real time using machine learning. Expert Systems with Applications. 71:342-357. doi:10.1016/j.eswa.2016.11.037S3423577",'Elsevier BV',A framework for modelling the biomechanical behaviour of the human liver during breathing in real time using machine learning,10.1016/j.eswa.2016.11.037,https://riunet.upv.es/bitstream/10251/84603/2/manuscript.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
33081215,2014-08-01T00:00:00,"Bovine mastitis is a frequent problem in Swiss dairy herds. One of the main pathogens causing significant economic loss is Staphylococcus aureus. Various Staph. aureus genotypes with different biological properties have been described. Genotype B (GTB) of Staph. aureus was identified as the most contagious and one of the most prevalent strains in Switzerland. The aim of this study was to identify risk factors associated with the herd-level presence of Staph. aureus GTB and Staph. aureus non-GTB in Swiss dairy herds with an elevated yield-corrected herd somatic cell count (YCHSCC). One hundred dairy herds with a mean YCHSCC between 200,000 and 300,000cells/mL in 2010 were recruited and each farm was visited once during milking. A standardized protocol investigating demography, mastitis management, cow husbandry, milking system, and milking routine was completed during the visit. A bulk tank milk (BTM) sample was analyzed by real-time PCR for the presence of Staph. aureus GTB to classify the herds into 2 groups: Staph. aureus GTB-positive and Staph. aureus GTB-negative. Moreover, quarter milk samples were aseptically collected for bacteriological culture from cows with a somatic cell count ≥150,000cells/mL on the last test-day before the visit. The culture results allowed us to allocate the Staph. aureus GTB-negative farms to Staph. aureus non-GTB and Staph. aureus-free groups. Multivariable multinomial logistic regression models were built to identify risk factors associated with the herd-level presence of Staph. aureus GTB and Staph. aureus non-GTB. The prevalence of Staph. aureus GTB herds was 16% (n=16), whereas that of Staph. aureus non-GTB herds was 38% (n=38). Herds that sent lactating cows to seasonal communal pastures had significantly higher odds of being infected with Staph. aureus GTB (odds ratio: 10.2, 95% CI: 1.9-56.6), compared with herds without communal pasturing. Herds that purchased heifers had significantly higher odds of being infected with Staph. aureus GTB (rather than Staph. aureus non-GTB) compared with herds without purchase of heifers. Furthermore, herds that did not use udder ointment as supportive therapy for acute mastitis had significantly higher odds of being infected with Staph. aureus GTB (odds ratio: 8.5, 95% CI: 1.6-58.4) or Staph. aureus non-GTB (odds ratio: 6.1, 95% CI: 1.3-27.8) than herds that used udder ointment occasionally or regularly. Herds in which the milker performed unrelated activities during milking had significantly higher odds of being infected with Staph. aureus GTB (rather than Staph. aureus non-GTB) compared with herds in which the milker did not perform unrelated activities at milking. Awareness of 4 potential risk factors identified in this study guides implementation of intervention strategies to improve udder health in both Staph. aureus GTB and Staph. aureus non-GTB herds",'American Dairy Science Association',Genotype-specific risk factors for Staphylococcus aureus in Swiss dairy herds with an elevated yield-corrected herd somatic cell count,10.3168/jds.2013-7760,https://core.ac.uk/download/33081215.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
157743963,2016-05-01T00:00:00,"This paper is an extended version of one paper published in the 4th IEEE International Work Conference on Bioinspired Intelligence, Donostia, Spain, 9–12 June 2015Biomedical systems produce biosignals that arise from interaction mechanisms. In a general form, those mechanisms occur across multiple scales, both spatial and temporal, and contain linear and non-linear information. In this framework, entropy measures are good candidates in order provide useful evidence about disorder in the system, lack of information in time-series and/or irregularity of the signals. The most common movement disorder is essential tremor (ET), which occurs 20 times more than Parkinson's disease. Interestingly, about 50%-70% of the cases of ET have a genetic origin. One of the most used standard tests for clinical diagnosis of ET is Archimedes' spiral drawing. This work focuses on the selection of non-linear biomarkers from such drawings and handwriting, and it is part of a wider cross study on the diagnosis of essential tremor, where our piece of research presents the selection of entropy features for early ET diagnosis. Classic entropy features are compared with features based on permutation entropy. Automatic analysis system settled on several Machine Learning paradigms is performed, while automatic features selection is implemented by means of ANOVA (analysis of variance) test. The obtained results for early detection are promising and appear applicable to real environments.This work has been partially supported by the University of the Basque Country under project ref. UPV/EHU-58/14, SAIOTEK program and others from the Basque Government, the Spanish Ministerio de Ciencia e Innovacion TEC2012-38630-C04-03, the University of Vic-Central University of Catalonia under the research grant R0904, INNPACTO program from the Spanish Government, and UPV/EHU Summer Courses Foundation",'MDPI AG',Selection of Entropy Based Features for Automatic Analysis of Essential Tremor,10.3390/e18050184,https://core.ac.uk/download/157743963.pdf,"[{'title': 'Entropy', 'identifiers': ['1099-4300', 'issn:1099-4300']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
427372224,2017-06-23T00:00:00,"Automatic detection of fall events is vital to providing fast medical assistance to the causality, particularly when the injury causes loss of consciousness. Optimization of the energy consumption of mobile applications, especially those which run 24/7 in the background, is essential for longer use of smartphones. In order to improve energy-efficiency without compromising on the fall detection performance, we propose a novel 3-tier architecture that combines simple thresholding methods with machine learning algorithms. The proposed method is implemented on a mobile application, called uSurvive, for Android smartphones. It runs as a background service and monitors the activities of a person in daily life and automatically sends a notification to the appropriate authorities and/or user defined contacts when it detects a fall. The performance of the proposed method was evaluated in terms of fall detection performance and energy consumption. Real life performance tests conducted on two different models of smartphone demonstrate that our 3-tier architecture with feature reduction could save up to 62% of energy compared to machine learning only solutions. In addition to this energy saving, the hybrid method has a 93% of accuracy, which is superior to thresholding methods and better than machine learning only solutions",'MDPI AG',An Energy-Efficient Multi-Tier Architecture for Fall Detection on Smartphones,10.3390/s17071487,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
202045018,2014-08-31,"AbstractBovine mastitis is a frequent problem in Swiss dairy herds. One of the main pathogens causing significant economic loss is Staphylococcus aureus. Various Staph. aureus genotypes with different biological properties have been described. Genotype B (GTB) of Staph. aureus was identified as the most contagious and one of the most prevalent strains in Switzerland. The aim of this study was to identify risk factors associated with the herd-level presence of Staph. aureus GTB and Staph. aureus non-GTB in Swiss dairy herds with an elevated yield-corrected herd somatic cell count (YCHSCC). One hundred dairy herds with a mean YCHSCC between 200,000 and 300,000cells/mL in 2010 were recruited and each farm was visited once during milking. A standardized protocol investigating demography, mastitis management, cow husbandry, milking system, and milking routine was completed during the visit. A bulk tank milk (BTM) sample was analyzed by real-time PCR for the presence of Staph. aureus GTB to classify the herds into 2 groups: Staph. aureus GTB-positive and Staph. aureus GTB-negative. Moreover, quarter milk samples were aseptically collected for bacteriological culture from cows with a somatic cell count ≥150,000cells/mL on the last test-day before the visit. The culture results allowed us to allocate the Staph. aureus GTB-negative farms to Staph. aureus non-GTB and Staph. aureus-free groups. Multivariable multinomial logistic regression models were built to identify risk factors associated with the herd-level presence of Staph. aureus GTB and Staph. aureus non-GTB. The prevalence of Staph. aureus GTB herds was 16% (n=16), whereas that of Staph. aureus non-GTB herds was 38% (n=38). Herds that sent lactating cows to seasonal communal pastures had significantly higher odds of being infected with Staph. aureus GTB (odds ratio: 10.2, 95% CI: 1.9–56.6), compared with herds without communal pasturing. Herds that purchased heifers had significantly higher odds of being infected with Staph. aureus GTB (rather than Staph. aureus non-GTB) compared with herds without purchase of heifers. Furthermore, herds that did not use udder ointment as supportive therapy for acute mastitis had significantly higher odds of being infected with Staph. aureus GTB (odds ratio: 8.5, 95% CI: 1.6–58.4) or Staph. aureus non-GTB (odds ratio: 6.1, 95% CI: 1.3–27.8) than herds that used udder ointment occasionally or regularly. Herds in which the milker performed unrelated activities during milking had significantly higher odds of being infected with Staph. aureus GTB (rather than Staph. aureus non-GTB) compared with herds in which the milker did not perform unrelated activities at milking. Awareness of 4 potential risk factors identified in this study guides implementation of intervention strategies to improve udder health in both Staph. aureus GTB and Staph. aureus non-GTB herds",American Dairy Science Association®.,Genotype-specific risk factors for Staphylococcus aureus in Swiss dairy herds with an elevated yield-corrected herd somatic cell count ,10.3168/jds.2013-7760,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
296208145,2018-08-11,"In this paper, we aim to develop a low-computational system for real-time image processing and analysis in endoscopy images for the early detection of the human esophageal adenocarcinoma and colorectal cancer. Rich statistical features are used to train an improved machine-learning algorithm. Our algorithm can achieve a real-time classification of malign and benign cancer tumours with a significantly improved detection precision compared to the classical HOG method as a reference when it is implemented on real time embedded system NVIDIA TX2 platform. Our approach can help to avoid unnecessary biopsies for patients and reduce the over diagnosis of clinically insignificant cancers in the future",Springer,A low computational approach for assistive esophageal adenocarcinoma and colorectal cancer detection,10.1007/978-3-319-97982-3_14,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98345403,2017-01-01T00:00:00,"IJMISSP promotes research in machine intelligence/signal processing, highlighting developments in randomised algorithms, deep learning, other learning techniques, sampling theory, transformations and data compression. Besides theory/fundamentals encountered in the main subject area, applications associated with cybersecurity, health sciences, finance and engineering are essential. Design of advanced computational intelligence systems for subtle pattern recognition/discovery, visual data understanding/retrieval, robust face recognition, streaming data processing and intelligent control/software is stressed. Submissions on technology development and real-world applications of complex machine intelligence systems are encouraged",,Editorial Board Member of International Journal of Machine Intelligence and Sensory Signal Processing,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
391271841,2017-09-18T00:00:00,"Conference of European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017 ; Conference Date: 18 September 2017 Through 22 September 2017; Conference Code:209269International audienceWe present WHODID: a turnkey intuitive web-based interface for fault detection, identification and diagnosis in production units. Fault detection and identification is an extremely useful feature and is becoming a necessity in modern production units. Moreover, the large deployment of sensors within the stations of a production line has enabled the close monitoring of products being manufactured. In this context, there is a high demand for computer intelligence able to detect and isolate faults inside production lines, and to additionally provide a diagnosis for maintenance on the identified faulty production device, with the purpose of preventing subsequent faults caused by the diagnosed faulty device behavior. We thus introduce a system which has fault detection, isolation, and identification features, for retrospective and on-the-fly monitoring and maintenance of complex dynamical production processes. It provides real-time answers to the questions: "" is there a fault? "" , "" where did it happen? "" , "" for what reason? "". The method is based on a posteriori analysis of decision sequences in XGBoost tree models, using recurrent neural networks sequential models of tree paths. The particularity of the presented system is that it is robust to missing or faulty sensor measurements, it does not require any modeling of the underlying, possibly exogenous manufacturing process, and provides fault diagnosis along with confidence level in plain English formulations. The latter can be used as maintenance directions by a human operator in charge of production monitoring and control",'Springer Science and Business Media LLC',"WHODID: Web-based interface for Human-assisted factory Operations in fault Detection, Identification and Diagnosis",10.1007/978-3-319-71273-4_47,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
80561307,2015-01-01T00:00:00,"Для виявлення пошкодження в елементах конструкцій в експлуатації запропоновано використання
систем моніторингу на основі концепції SHM, які забезпечують контроль життєвого циклу
об‘єкту для його надійної та безпечної експлуатації. Наведена функціональна схема комплексної
інформаційної системи моніторингу, обґрунтовано сучасний підхід організації моніторингу з
використанням інтелектуального компоненту – штучних нейронних мереж, які надають
можливість реалізувати процес організації паралельності потоків інформації багатоканальної
системи. Наведені приклад функціональної схеми системи моніторингу резервуарів з еколого-
небезпечними речовинами та схема практичного використання нейронних мереж при вирішені
реальної задачі класифікації та розпізнавання. Наведено загальну схему та структуру
класифікатора стану системи моніторингу для вирішування завдання визначення технічного стану
об’єкту контролю. Для розпізнавання стану елементів конструкції за результатами аналізу
діагностичної інформації розроблено класифікатор на основі ймовірнісної нейронної мережі PNN,
архітектура якої складається з двох шарів: з радіально-базисними нейронами в першому шарі та
шару конкуренції. Встановлені класи для станів об’єкту контролю та відповідні параметри для
кожного з них. Сформовано навчальну множину, яка покладена в основу навчання «з учителем», для
кожного класу класифікатора системи діагностування. Наведено масив навчальних векторів у
матричному вигляді. Сформовано різні типи тестових множин векторів, щоб визначити
доцільність та ефективність використання побудованої нейронної мережі. Визначено вектор
індексів класів та повну матрицю зв’язності нейронної мережі, що встановлюють приналежність
вхідного масиву інформації до відповідного цільового класу. Наведено блок-схеми нейронної мережі
багатоканальної діагностики в програмному середовищі Matlab, складовими якої є два шари, вхідні
та вихідні масиви даних і матриці ваг. Встановлено кількість нейронів кожного шару побудованої
ймовірнісної мережі PNN багатоканальної діагностики.Для выявления повреждения в элементах конструкций в эксплуатации предложено использование
систем мониторинга на основе концепции SHM, которые обеспечивают контроль жизненного
цикла объекта для его надежной и безопасной эксплуатации. Приведена функциональная схема
комплексной информационной системы мониторинга и обоснован современный подход организации
мониторинга с использованием интеллектуального компонента . искусственных нейронных сетей,
которые предоставляют возможность реализовать процесс организации параллельности потоков
информации многоканальной системы. Приведены пример функциональной схемы системы
мониторинга резервуаров с эколого-опасными веществами и схема практического использования
нейронных сетей при решении реальной задачи классификации и распознавания. Приведена общая
схема и структура классификатора состояния системы мониторинга для решения задачи
определения технического состояния объекта контроля. Для распознавания состояния элементов
конструкции по результатам анализа диагностической информации разработан классификатор на
основе вероятностной нейронной сети PNN, архитектура которой состоит из двух слоев: с
радиально-базисными нейронами в первом слое и слоя конкуренции. Установлены классы для
состояний объекта контроля и соответствующие параметры для каждого из них. Сформировано
обучающее множество, которое положено в основу обучения «с учителем», для каждого класса
классификатора системы диагностирования. Приведены массивы обучающих векторов в
матричном виде. Сформированы различные типы тестовых множеств векторов для определения
целесообразности и эффективности использования построенной нейронной сети. Определены вектор индексов классов и полная матрица связности нейронной сети, устанавливающие
принадлежность входного массива информации соответствующему целевому классу. Приведены
блок-схемы нейронной сети многоканальной диагностики в программной среде Matlab,
составляющими которой являются два слоя, входные и выходные массивы данных и матрицы
весов. Установлено количество нейронов каждого слоя построенной вероятностной сети PNN
многоканальной диагностики.The process of identifying damage to the structural elements in operation proposed use of a monitoring
systems based on the concept of SHM that providing the structural health monitoring for its safe and
reliable operation. The functional diagram of an integrated information system for monitoring and
reasonably modern approach to the organization of monitoring the use of intelligent components - artificial
neural networks, which provide the opportunity to realize the process of organizing information flows
parallel multi-channel system. An example of a functional circuit monitoring system tanks ecological and
hazardous substances and the scheme of the practical use of neural networks for solving the real problem
of classification and recognition. Provides an overview of the status and structure of the classifier
monitoring system to address the problem of determining the technical condition of the object of control.
To detect the state of structural elements according to the analysis of diagnostic information developed
probabilistic classifier based on a neural network PNN, whose architecture consists of two layers: a
radially-basic neurons in the first layer and the layer of competition. Established classes for object state
control and the corresponding parameters for each of them. Formed training set, which forms the basis of
learning ""teacher"", for each class of classifier system diagnostics. Arrays are given training vectors in
matrix form. Formed by different types of sets of test vectors to determine the feasibility and effectiveness of
the built neural network. Determine the vector of indices of classes and a full array of connectivity of the
neural network, establish membership input array information corresponding to the target class. A block
diagram of a neural network diagnostic multichannel environment Matlab software, components of which
are two layers, the input and output arrays and the weight matrix. Established the number of neurons of
each layer constructed probabilistic network PNN multichannel diagnostics",ІФНТУНГ,Синтез нейронної мережі для багатоканальної діагностики елементів конструкції в експлуатації,,https://core.ac.uk/download/80561307.pdf,"[{'title': 'METHODS AND DEVICES OF QUALITY CONTROL', 'identifiers': ['issn:1993-9981', '1993-9981']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
296224748,2017-06,"Over the last decade, toxic events along the Mediterranean coast associated with exceptional harmful blooms of the dinoflagellate Ostreopsis cf. ovata have increased in frequency and distribution, causing not only the death of marine organisms and human health problems, but also economic loss on the tourism and aquaculture industries. In order to reduce the burden of routine algal counting, an innovative automated, low-cost, opto-electronic system called OvMeter was developed. It is able to speed up the monitoring process and therefore it enables early warning of incipient harmful algal blooms. An ad-hoc software tool provides automated cell recognition, counting and real-time calculation of the final algal concentration. The core of dinoflagellate recognition relies on a localization step which takes advantage of the synergistic exploitation of 2D bright-field and quantitative phase microscopy images, and a classification phase performed by a machine learning algorithm based on Boosted Trees approach. The architectural design of the OvMeter device is presented here, together with a performance evaluation on sea samples",Springer,OvMeter: an automated 3D-integrated opto-electronic system for Ostreopsis cf. ovata bloom monitoring,10.1007/s10811-017-1069-7,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98663631,2016,"The increasing application of process-oriented approaches in new challenging dynamic domains beyond business computing (e.g., healthcare, emergency management, factories of the future, home automation, etc.) has led to reconsider the level of flexibility and support required to manage complex knowledge-intensive processes in such domains. A knowledge-intensive process is influenced by user decision making and coupled with contextual data and knowledge production, and involves performing complex tasks in the &quot;physical&quot; real world to achieve a common goal. The physical world, however, is not entirely predictable, and knowledgeintensive processes must be robust to unexpected conditions and adaptable to unanticipated exceptions, recognizing that in real-world environments it is not adequate to assume that all possible recovery activities can be predefined for dealing with the exceptions that can ensue. To tackle this issue, in this paper we present SmartPM, a model and a prototype Process Management System featuring a set of techniques providing support for automated adaptation of knowledge-intensive processes at runtime. Such techniques are able to automatically adapt process instances when unanticipated exceptions occur, without explicitly defining policies to recover from exceptions and without the intervention of domain experts at runtime, aiming at reducing error-prone and costly manual ad-hoc changes, and thus at relieving users from complex adaptations tasks. To accomplish this, we make use of we ll-established techniques and frameworks from Artificial Intelligence, such as situation calculus, IndiGolog and classical planning. The approach, which is backed by a formal model, has been implemented and validated with a case study based on real knowledgeintensive processes coming from an emergency management domain",Association for Computer Machinery (United States),Intelligent process adaptation in the SmartPM system,10.1145/2948071,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
442510888,2015-01-01T00:00:00,"Complex real problems increasingly require intelligent systems that combine knowledge, techniques and methodologies from various sources. Intelligent systems based on artificial intelligence techniques that are associated with the behavior of people can perform the processes of learning, reasoning and solving all kinds of problems. Such systems, which automatically can perform tasks set by the user or other software, today thankfully called intelligent agents. Independent, intelligent agents on the Internet can be very successful to perform some search work on behalf of and for the needs of different users. For efficient collection, manipulation and management of data, such software can be very interesting from the standpoint of intelligent data analysis in many areas the police. Analysis of the data collected by an intelligent agent (a software robot-bot) can be successfully utilized, among many jobs in the police, and in the field of crime and in particular manifestation of cyber­crime, traffic safety, emergencies, etc. To make the collection and analysis of data from criminal activities on the Internet effective, it is necessary to examine the existing artificial intelligence techniques to be used for the conclusion of the intelligent agents. On the other hand, using of methods of artificial intelligence in finding data along with intelligent data analysis (data mining) should be used, which has found wide use in the area of business, economics, mechanics, medicine, genetics, transport etc","University of Criminal Investigation and Police Studies, Belgrade",Artificial intelligence in process of collecting and analyzing data within police works,,,"[{'title': 'Nauka bezbednost policija', 'identifiers': ['issn:0354-8872', 'issn:2620-0406', '2620-0406', '0354-8872']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
346545484,2018-01-01T00:00:00,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ""VA-assisted ML"". The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly",'Institute of Electrical and Electronics Engineers (IEEE)',VIS4ML: an ontology for visual analytics assisted machine learning,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275613405,2015-01-01T00:00:00,"The inclusion of embedded sensors into a networked system provides useful
information for many applications. A Distributed Control System (DCS) is one of the
clearest examples where processing and communications are constrained by the client s
requirements and the capacity of the system. An embedded sensor with advanced
processing and communications capabilities supplies high level information, abstracting
from the data acquisition process and objects recognition mechanisms. The implementation
of an embedded sensor/actuator as a Smart Resource permits clients to access sensor
information through distributed network services. Smart resources can offer sensor services
as well as computing, communications and peripheral access by implementing a self-aware
based adaptation mechanism which adapts the execution profile to the context. On the
other hand, information integrity must be ensured when computing processes are
dynamically adapted. Therefore, the processing must be adapted to perform tasks in a
certain lapse of time but always ensuring a minimum process quality. In the same way,
communications must try to reduce the data traffic without excluding relevant information.
The main objective of the paper is to present a dynamic configuration mechanism to adapt
the sensor processing and communication to the client s requirements in the DCS. This
paper describes an implementation of a smart resource based on a Red, Green, Blue, and
Depth (RGBD) sensor in order to test the dynamic configuration mechanism presented.This work has been supported by the Spanish Science and Innovation Ministry MICINN under the CICYT project M2C2: ""Codiseno de sistemas de control con criticidad mixta basado en misiones"" TIN2014-56158-C4-4-P and the Programme for Research and Development PAID of the Polytechnic University of Valencia: UPV-PAID-FPI-2013. The responsibility for the content remains with the authors.Munera Sánchez, E.; Poza-Lujan, J.; Posadas-Yagüe, J.; Simó Ten, JE.; Blanes Noguera, F. (2015). Dynamic Reconfiguration of a RGBD Sensor Based on QoS and QoC Requirements in Distributed Systems. Sensors. 15(8):18080-18101. https://doi.org/10.3390/s150818080S1808018101158Gupta, R. A., & Mo-Yuen Chow. (2010). Networked Control System: Overview and Research Trends. IEEE Transactions on Industrial Electronics, 57(7), 2527-2535. doi:10.1109/tie.2009.2035462Morales, R., Badesa, F. J., García-Aracil, N., Perez-Vidal, C., & Sabater, J. M. (2012). Distributed Smart Device for Monitoring, Control and Management of Electric Loads in Domotic Environments. Sensors, 12(5), 5212-5224. doi:10.3390/s120505212Zhang, Z. (2012). Microsoft Kinect Sensor and Its Effect. IEEE Multimedia, 19(2), 4-10. doi:10.1109/mmul.2012.24Gonzalez-Jorge, H., Riveiro, B., Vazquez-Fernandez, E., Martínez-Sánchez, J., & Arias, P. (2013). Metrological evaluation of Microsoft Kinect and Asus Xtion sensors. Measurement, 46(6), 1800-1806. doi:10.1016/j.measurement.2013.01.011Pordel, M., & Hellström, T. (2015). Semi-Automatic Image Labelling Using Depth Information. Computers, 4(2), 142-154. doi:10.3390/computers4020142Zuehlke, D. (2010). SmartFactory—Towards a factory-of-things. Annual Reviews in Control, 34(1), 129-138. doi:10.1016/j.arcontrol.2010.02.008Wang, X., Şekercioğlu, Y., & Drummond, T. (2014). Vision-Based Cooperative Pose Estimation for Localization in Multi-Robot Systems Equipped with RGB-D Cameras. Robotics, 4(1), 1-22. doi:10.3390/robotics4010001Gil, P., Kisler, T., García, G. J., Jara, C. A., & Corrales, J. A. (2013). Calibración de cámaras de tiempo de vuelo: Ajuste adaptativo del tiempo de integración y análisis de la frecuencia de modulación. Revista Iberoamericana de Automática e Informática Industrial RIAI, 10(4), 453-464. doi:10.1016/j.riai.2013.08.002Castrillón-Santan, M., Lorenzo-Navarro, J., & Hernández-Sosa, D. (2014). Conteo de personas con un sensor RGBD comercial. Revista Iberoamericana de Automática e Informática Industrial RIAI, 11(3), 348-357. doi:10.1016/j.riai.2014.05.006Vogel, A., Kerherve, B., von Bochmann, G., & Gecsei, J. (1995). Distributed multimedia and QOS: a survey. IEEE Multimedia, 2(2), 10-19. doi:10.1109/93.388195Eugster, P. T., Felber, P. A., Guerraoui, R., & Kermarrec, A.-M. (2003). The many faces of publish/subscribe. ACM Computing Surveys, 35(2), 114-131. doi:10.1145/857076.857078Aurrecoechea, C., Campbell, A. T., & Hauw, L. (1998). A survey of QoS architectures. Multimedia Systems, 6(3), 138-151. doi:10.1007/s005300050083Xu, W., Zhou, Z., Pham, D. T., Liu, Q., Ji, C., & Meng, W. (2012). Quality of service in manufacturing networks: a service framework and its implementation. The International Journal of Advanced Manufacturing Technology, 63(9-12), 1227-1237. doi:10.1007/s00170-012-3965-yKang, W., Son, S. H., & Stankovic, J. A. (2012). Design, Implementation, and Evaluation of a QoS-Aware Real-Time Embedded Database. IEEE Transactions on Computers, 61(1), 45-59. doi:10.1109/tc.2010.240Poza-Lujan, J.-L., Posadas-Yagüe, J.-L., Simó-Ten, J.-E., Simarro, R., & Benet, G. (2015). Distributed Sensor Architecture for Intelligent Control that Supports Quality of Control and Quality of Service. Sensors, 15(3), 4700-4733. doi:10.3390/s150304700Manzoor, A., Truong, H.-L., & Dustdar, S. (2014). Quality of Context: models and applications for context-aware systems in pervasive environments. The Knowledge Engineering Review, 29(2), 154-170. doi:10.1017/s0269888914000034Cardellini, V., Casalicchio, E., Grassi, V., Iannucci, S., Presti, F. L., & Mirandola, R. (2012). MOSES: A Framework for QoS Driven Runtime Adaptation of Service-Oriented Systems. IEEE Transactions on Software Engineering, 38(5), 1138-1159. doi:10.1109/tse.2011.68Nogueira, L., Pinho, L. M., & Coelho, J. (2012). A feedback-based decentralised coordination model for distributed open real-time systems. Journal of Systems and Software, 85(9), 2145-2159. doi:10.1016/j.jss.2012.04.033del-Hoyo, R., Martín-del-Brío, B., Medrano, N., & Fernández-Navajas, J. (2009). Computational intelligence tools for next generation quality of service management. Neurocomputing, 72(16-18), 3631-3639. doi:10.1016/j.neucom.2009.01.016Tian, Y.-C., Jiang, X., Levy, D. C., & Agrawala, A. (2012). Local Adjustment and Global Adaptation of Control Periods for QoC Management of Control Systems. IEEE Transactions on Control Systems Technology, 20(3), 846-854. doi:10.1109/tcst.2011.2141133Vilalta, R., & Drissi, Y. (2002). Artificial Intelligence Review, 18(2), 77-95. doi:10.1023/a:1019956318069Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20(3), 273-297. doi:10.1007/bf00994018Yélamos, I., Escudero, G., Graells, M., & Puigjaner, L. (2009). Performance assessment of a novel fault diagnosis system based on support vector machines. Computers & Chemical Engineering, 33(1), 244-255. doi:10.1016/j.compchemeng.2008.08.008Zhang, X., Qiu, D., & Chen, F. (2015). Support vector machine with parameter optimization by a novel hybrid method and its application to fault diagnosis. Neurocomputing, 149, 641-651. doi:10.1016/j.neucom.2014.08.010Iplikci, S. (2010). Support vector machines based neuro-fuzzy control of nonlinear systems. Neurocomputing, 73(10-12), 2097-2107. doi:10.1016/j.neucom.2010.02.008Ferrari, P., Flammini, A., & Sisinni, E. (2011). New Architecture for a Wireless Smart Sensor Based on a Software-Defined Radio. IEEE Transactions on Instrumentation and Measurement, 60(6), 2133-2141. doi:10.1109/tim.2011.2117090Munera Sánchez, E., Muñoz Alcobendas, M., Blanes Noguera, J., Benet Gilabert, G., & Simó Ten, J. (2013). A Reliability-Based Particle Filter for Humanoid Robot  Self-Localization in RoboCup Standard Platform League. Sensors, 13(11), 14954-14983. doi:10.3390/s131114954Adams, R., & Bischof, L. (1994). Seeded region growing. IEEE Transactions on Pattern Analysis and Machine Intelligence, 16(6), 641-647. doi:10.1109/34.295913JIMÉNEZ-GARCÍA, J.-L., BASELGA-MASIA, D., POZA-LUJÁN, J.-L., MUNERA, E., POSADAS-YAGÜE, J.-L., & SIMÓ-TEN, J.-E. (2014). Smart device definition and application on embedded system: performance and optimi-zation on a RGBD sensor. ADCAIJ: ADVANCES IN DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE JOURNAL, 3(8), 46. doi:10.14201/adcaij2014384655Feng-Li Lian, Moyne, J., & Tilbury, D. (2002). Network design consideration for distributed control systems. IEEE Transactions on Control Systems Technology, 10(2), 297-307. doi:10.1109/87.98707",'MDPI AG',Dynamic Reconfiguration of a RGBD Sensor Based on QoS and QoC Requirements in Distributed Systems,10.3390/s150818080,https://riunet.upv.es/bitstream/handle/10251/64912/-Munera%3bPoza-Lujan%3bPosadas-Yag%c3%bce%20-%20Dynamic%20Reconfiguration%20of%20a%20RGBD%20Sensor%20Based%20on%20QoS%20and%20QoC%20R....pdf?sequence=1&isAllowed=y,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201207793,2018-08-01T00:00:00,"Introduction
Current approaches to the development and application of predictive studies is inefficient and difficult to reproduce. Thousands of predictive health algorithms have been developed; however, less than 2\% have been assessed outside their original setting and even fewer have been applied and evaluated in practice.



Objectives and Approach
Objective: To develop a standardized workflow for algorithm development, dissemination and implementation.



Existing predictive analytics workflow and open standards were adapted and expanded for health research and health care settings. The approach was designed to work within multidisciplinary teams and to improve research transparency, reproducibility, quality, efficiency and application. Key components include standardized algorithm description files, documentation and code libraries. All libraries and programming packages, which were created for/with open-source software, can be used for a wide range of statistical and machine learning models. Publicly-available repositories contain the algorithms, validation data, R code and other supporting infrastructure.



Results
Algorithm development involves variable pre-specification and documentation of model variables, followed by creation of data preprocessing code to generate model variables from the study dataset. Preprocessing uses algorithm specification documentation and a function library, building upon and integrating with existing algorithms when possible to preventing code duplication. Models are output as a Predictive Modelling Markup Language (PMML) file, a portable industry standard for describing and scoring predictive models. A separate scoring ""engine"" is used to implement PMML-described algorithms in a range of settings, including algorithm validation at other research institutions. Algorithm applications currently include the Project Big Life (www.projectbiglife.ca) online calculators, population, health services and public health planning uses and an algorithm visualization tool. An API permits use of the calculator engine by other organizations.



Conclusion/Implications
Barriers to the implementation of predictive analytics in real-world settings—such as within electronic medical records or decision aid applications—can be mitigated with well described algorithms that are easy to replicate and implement, especially as access to big health data increases and algorithms become increasingly complex",'Swansea University',A Data Science Approach to Predictive Analytic Research and Knowledge Translation,10.23889/ijpds.v3i4.797,https://core.ac.uk/download/201207793.pdf,"[{'title': 'International Journal for Population Data Science', 'identifiers': ['issn:2399-4908', '2399-4908']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201554895,2018-10-01T00:00:00,"Abstract Background Logistic regression is a popular technique used in machine learning to construct classification models. Since the construction of such models is based on computing with large datasets, it is an appealing idea to outsource this computation to a cloud service. The privacy-sensitive nature of the input data requires appropriate privacy preserving measures before outsourcing it. Homomorphic encryption enables one to compute on encrypted data directly, without decryption and can be used to mitigate the privacy concerns raised by using a cloud service. Methods In this paper, we propose an algorithm (and its implementation) to train a logistic regression model on a homomorphically encrypted dataset. The core of our algorithm consists of a new iterative method that can be seen as a simplified form of the fixed Hessian method, but with a much lower multiplicative complexity. Results We test the new method on two interesting real life applications: the first application is in medicine and constructs a model to predict the probability for a patient to have cancer, given genomic data as input; the second application is in finance and the model predicts the probability of a credit card transaction to be fraudulent. The method produces accurate results for both applications, comparable to running standard algorithms on plaintext data. Conclusions This article introduces a new simple iterative algorithm to train a logistic regression model that is tailored to be applied on a homomorphically encrypted dataset. This algorithm can be used as a privacy-preserving technique to build a binary classification model and can be applied in a wide range of problems that can be modelled with logistic regression. Our implementation results show that our method can handle the large datasets used in logistic regression training",'Springer Science and Business Media LLC',Privacy-preserving logistic regression training,10.1186/s12920-018-0398-y,,"[{'title': 'BMC Medical Genomics', 'identifiers': ['1755-8794', 'issn:1755-8794']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
297620750,,"Telepresence Mobile Robots have prominent attributes in many fields as it provides virtual presence for human robot interaction. The deployment of this robot in healthcare sector has improved patient care and health. The vision system in a telepresence robot allows two way audiovisual communication between people at different location. In spite of such advancement, the manual way of controlling a robot to recognise and track people during an emergency is not favourable for a long duration. To circumvent this problem, biometric method using human face is proposed in this research which is implemented on Medical Telediagnosis Robot. This paper details the design of the face recognition and tracking system with four automated modules which are motion detection, face detection, face recognition and face tracking. The modules are developed with different algorithm and tested individually to ensure the stability of the system. Artificial Intelligence technique was applied at the face recognition stage while a two degree of freedom mechanism for actuator control was used at face tracking stage. A sequential mode operation is proposed to reduce the execution time in a real-time environment. To achieve this, only one module is operated at each time. A Graphical User Interface was developed to ease the users at the local and robot environment. The system is designed in LabVIEW platform. The biometric system proposed with hybrid algorithm at each module adapts for face images detected at different distances, poses and lighting condition. This system was tested in real-time and has an execution time of 55ms and 98% accuracy. The stand alone system designed for Medical Telediagnosis Robot can be will be very fruitful for various biometric system using facial technology","Journal of Telecommunication, Electronic and Computer Engineering, Universiti Teknikal Malaysia Melaka",Towards real-time visual biometric authentication using human face for healthcare Telepresence Mobile Robots,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201511049,2018-09-01T00:00:00,"Abstract Background Patients on dialysis are physically inactive, with most reporting activity levels below the fifth percentile of healthy age-matched groups. Several small studies have reported efficacy of diverse exercise interventions among persons with CKD and those on dialysis. However, no single intervention has been widely adopted in real-world practice, despite a clear need in this vulnerable population with high rates of mortality, frailty, and skilled nursing hospitalizations. Methods/design We describe a pragmatic clinical trial for an exercise intervention among patients transitioning to dialysis. We will use an existing framework – Exercise is Medicine (EIM) – developed by the American College of Sports Medicine. After undertaking formative qualitative research to tailor the EIM framework to the advanced CKD population (eGFR < 30 ml/min/1.73m2), we will randomize 96 patients from two regions—Atlanta and Bay Area—in two intervention arms with incremental levels of clinical-community integration: physical activity assessment during Nephrology clinical visit, brief counseling at pre-dialysis education, and physical activity wearable (group 1) versus group 1 intervention components plus a referral to a free, EIM practitioner-led group exercise program over 16 weeks (group 2; 8 week core intervention; 8-week follow up). We will assess efficacy by comparing between group differences in minutes/week of objectively measured moderate intensity physical activity. To evaluate implementation, we will use questionnaires for assessing barriers to referral, participation and retention along the path of the intervention. Further we will have a plan for dissemination of the intervention by partnering with relevant stakeholders. Discussion The overall goal is to inform the development of a practical, cost-conscious intervention “package” that addresses barriers and challenges to physical activity commonly faced by patients with advanced CKD and can be disseminated amongst interested practices. Trial registration ClinicalTrials.gov identifier (Dated:10/17/2017): NCT03311763",'Springer Science and Business Media LLC',Physical activity promotion for patients transitioning to dialysis using the “Exercise is Medicine” framework: a multi-center randomized pragmatic trial (EIM-CKD trial) protocol,10.1186/s12882-018-1032-0,,"[{'title': 'BMC Nephrology', 'identifiers': ['1471-2369', 'issn:1471-2369']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
230066664,2017-11-19T00:00:00,"What methodologies are most effective inclusive education? What are the framework conditions that favor the inclusion in the daily school reality? The partial results of the research are presented in this article. On a sample of 109 students, aged 8 to 16 years, we were measured the effects of teaching methods “feedback” and “collaborative learning”, recognized as effective by the international literature. Estimated variables are the skills and abilities to cross disciplines, cognitive-emotional factors of academic success, self-esteem. Rating bio psychosocial which opposes the prevailing bio-medical evaluation in Italy. Observe all students, to transform the special response in normal, measure the school environment variables favorable to inclusion can help to improve, in Italy, the effectiveness of public investment estimated in 2013 at  4,7B. They were later assessed the organizational and relational conditions of the school environment, also examined through the perception of the operators. The context is essential to the deployment of effective interventions for inclusion. The experimental design of research using methods recognized at international and European level (EBE), which allow you to compare the results and replicate the model in a supranational context, first of all in the pilot project “RA4AL” European Agency For Special Needs, It started in three countries, including Italy, which has just ended.Quali metodologie sono più efficaci nell’educazione inclusiva? Quali sono le condizioni di contesto che favoriscono l’inclusione nella quotidiana realtà scolastica? I risultati parziali della ricerca vengono presentati in questo articolo. Su un campione di 109 studenti, dagli 8 ai 16 anni, sono stati misurati gli effetti delle metodologie didattiche “feedback” e “collaborative learning”, riconosciute come efficaci dalla letteratura internazionale. Variabili stimate sono le competenze e le abilità trasversali alle discipline, i fattori cognitivo-emozionali del successo scolastico, l’autostima. Valutazione bio psico-sociale che si oppone alla valutazione bio-medica prevalente in Italia. Osservare tutti gli allievi, trasformare la risposta speciale in normalità, misurare le variabili del contesto scolastico favorevoli all’inclusione può contribuire a migliorare, in Italia, l’efficacia di investimenti pubblici stimati nel 2013 in  4,7B. Sono state poi valutate le condizioni organizzative e relazionali del contesto scolastico, esaminate anche attraverso la percezione degli operatori. Il contesto si rivela essenziale per la messa in campo di efficaci interventi per l’inclusione. Il disegno sperimentale della ricerca utilizza metodologie riconosciute a livello internazionale ed europeo (EBE), che consentono di confrontare i risultati e replicare il modello in un contesto sovranazionale, innanzitutto nell’ambito del progetto pilota “ RA4AL” dell’European Agency For Special Needs, avviato in tre paesi, tra cui l’Italia, e che si è appena concluso",'Asociacion INFAD',Primi risultati di uno studio EBE sull’inclusione in due scuole italiane,10.17060/ijodaep.2017.n1.v4.1066,https://core.ac.uk/download/230066664.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
300465489,2018-01-01T00:00:00,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature",'Elsevier BV',Fast statistical model-based classification of epileptic EEG signals,10.1016/j.bbe.2018.08.002,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
345222776,2015-01-01T00:00:00,"ObjectivesTo evaluate the feasibility and effectiveness of dried blood spots (DBS) use for viral load (VL) monitoring, describing patient outcomes and programmatic challenges that are relevant for DBS implementation in sub-Saharan Africa.MethodsWe recruited adult antiretroviral therapy (ART) patients from five district hospitals in Malawi. Eligibility reflected anticipated Ministry of Health VL monitoring criteria. Testing was conducted at a central laboratory. Virological failure was defined as >5000 copies/ml. Primary outcomes were program feasibility (timely result availability and patient receipt) and effectiveness (second-line therapy initiation).ResultsWe enrolled 1,498 participants; 5.9% were failing at baseline. Median time from enrollment to receipt of results was 42 days; 79.6% of participants received results within 3 months. Among participants with confirmed elevated VL, 92.6% initiated second-line therapy; 90.7% were switched within 365 days of VL testing. Nearly one-third (30.8%) of participants with elevated baseline VL had suppressed (4 years were more likely to be failing than participants on therapy 1–4 years (RR 1.7, 95% CI 1.0-2.8); older participants were less likely to be failing (RR 0.95, 95% CI 0.92-0.98). There was no difference in likelihood of failure based on clinical symptoms (RR 1.17, 95% CI 0.65-2.11).ConclusionsDBS for VL monitoring is feasible and effective in real-world clinical settings. Centralized DBS testing may increase access to VL monitoring in remote settings. Programmatic outcomes are encouraging, especially proportion of eligible participants switched to second-line therapy",,Dried Blood Spots for Viral Load Monitoring in Malawi: Feasible and Effective,10.17615/x6g7-v988,https://core.ac.uk/download/345222776.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
225416598,2015-01-01T00:00:00,"BACKGROUND: Left atrial (LA) sizing in patients with atrial fibrillation (AF) is crucial for follow-up and outcome. Recently, the automated quantification of LA using the novel three-beat averaging real-time three dimensional echocardiography (3BA-RT3DE) is introduced. The aim of this study was to assess the feasibility and accuracy of 3BA-RT3DE in patients with atrial fibrillation (AF).

METHODS: Thirty-one patients with AF (62.8 ± 11.7 years, 67.7 % male) were prospectively recruited to have two dimensional echocardiography (2DE) and 3BA-RT3DE (SC 2000, ACUSON, USA). The maximal left atrial (LA) volume was measured by the conventional prolate-ellipse (PE) and area-length (AL) method using three-beat averaging 2D transthoracic echocardiography and automated software analysis (eSie volume analysis, Siemens Medical Solution, Mountain view, USA); measurements were compared with those obtained by computed tomography (CT).

RESULTS: Maximal LA volume by 3BA-RT3DE was feasible for all patients. LA volume was 68.4 ± 28.2 by PE-2DE, 89.2 ± 33.1 by AL-2DE, 100.6 ± 31.8 by 3BA-RT3DE, and 131.2 ± 42.2 mL by CT. LA volume from PE-2DE (R(2) = 0.48, p < 0.001, ICC = 0.64, p < 0.001), AL-2DE (R(2) = 0.47, p < 0.001, ICC = 0.67, p < 0.001), and 3BA-RT3DE (R(2) = 0.50, p = 0.001, ICC = 0.65, p < 0.001) showed significant correlations with CT. However, 3BA-RT3DE demonstrated a small degree of underestimation (30.5 mL) of LA volume compared to 2DE-based measurements. Good-quality images from 3BA-RT3DE (n = 16) showed a significantly tighter correlation with images from CT scanning (R(2) = 0.60, p = 0.0004, ICC = 0.76, p < 0.001) compared to those of fair quality.

CONCLUSION: Automated quantification of LA volume using 3BA-RT3DE is feasible and accurate in patients with AF. An image of good quality is essential for maximizing the value of this method in clinical practice.ope",'Springer Science and Business Media LLC',Automated quantification of left atrial size using three-beat averaging real-time three dimensional Echocardiography in patients with atrial fibrillation,10.1186/s12947-015-0032-5,https://core.ac.uk/download/225416598.pdf,"[{'title': 'Cardiovascular Ultrasound', 'identifiers': ['1476-7120', 'issn:1476-7120']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
79183572,2016-04-01T00:00:00,"This paper proposes a modification to the analytic hierarchy process (AHP) to select the most informative genes that serve as inputs to an interval type-2 fuzzy logic system (IT2FLS) for cancer classification. Unlike the conventional AHP, the modified AHP allows us to process quantitative factors that are ranking outcomes of individual gene selection methods including t-test, entropy, receiver operating characteristic curve, Wilcoxon test, and signal-to-noise ratio. The IT2FLS is introduced for the classification task due to its great ability for handling nonlinear, noisy, and outlier data, which are common problems in cancer microarray gene expression profiles. An unsupervised learning strategy using the fuzzy c-means clustering is employed to initialize parameters of the IT2FLS. Other classifiers such as multilayer perceptron network, support vector machine, and fuzzy ARTMAP are also implemented for comparisons. Experiments are carried out on three well-known microarray datasets: diffuse large B-cell lymphoma, leukemia cancer, and prostate. Rather than the traditional cross validation, leave-one-out cross-validation strategy is applied for the experiments. Results demonstrate the performance dominance of the IT2FLS against the competing classifiers. More noticeably, the modified AHP improves the classification performance not only of the IT2FLS but of all other classifiers as well. Accordingly, the proposed combination between the modified AHP and IT2FLS is a powerful tool for cancer classification and can be implemented as a real clinical decision support system that is useful for medical practitioners",'Institute of Electrical and Electronics Engineers (IEEE)',Modified AHP for gene selection and cancer classification using type-2 fuzzy logic,10.1109/TFUZZ.2015.2453153,http://hdl.handle.net/10536/DRO/DU:30084985,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
289704177,2018-01-01T00:00:00,"This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing",'Elsevier BV',Arrhythmia detection using deep convolutional neural network with long duration ECG signals,10.1016/j.compbiomed.2018.09.009,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
390020542,2018-02-27T00:00:00,"The economic-legal aspects of the state and trends of the Internet-based technologies (IP) technology, the place of intellectual property in it are considered. It is shown that the Internet of Things creates conditions for the emergence of a synergetic effect from the combination of possibilities of artificial intelligence, cloud computing, set of sensors, mathematical algorithms for processing large data (Big Data), robotic devices of various purposes, data transmission systems (Internet), which allows to provide various services and perform various work with or without the participation of people. The role of the state in promoting the development of IP, the existing problems and ways of their solution are shown. Many governments in recent years are taking measures to analyze the state of affairs with the introduction of IP technologies, the localization of problems and threats that may or may occur in the future in order to formulate a common strategy for the development of industry for the production of IP technologies and their application in various sectors of the economy and public life. The patent landscape of the IP is analyzed, the most productive companies and inventors of IP are discovered, the dynamics of patenting in the IP environment, the value of patents, patent research problems are shown. The problems of intellectual property protection in the sphere of IP, in particular, copyright, inventions, trademarks, commercial secrets, information security are considered. The intellectual potential and untapped potential of Ukraine in the development of IP technologies are considered. It is concluded that in the widespread use of IP technologies, there is a significant potential for increasing the efficiency of any type of human activity. It concerns the real economy, industry and agriculture, health care, public administration, education, financial turnover, etc. The development of IP technologies is the most powerful stimulating factor in the innovative development of nanotechnologies, microelectronics, semiconductor technologies, microiminating of executive devices, telecommunications, radio technologies, software computing, robotics, and more.Рассмотрены экономико-правовые аспекты состояния и тенденций развития технологий Интернета вещей (ИВ), места в нем интеллектуальной собственности. Показано, что Интернет вещей создает условия для появления синергетического эффекта от сочетания возможностей искусственного интеллекта, облачных вычислений, множества сенсоров, математических алгоритмов обработки больших данных (Big Data), роботизированных устройств различного назначения, систем передачи данных (сети Интернет), что позволяет предоставлять разнообразные услуги и осуществлять различные работы с участием или без участия людей. Показана роль государства в содействии развитию ИВ, существующие проблемы и пути их решения. Правительства многих стран в последнее время принимают меры по анализу состояния дел с внедрением ИВ-технологий, локализации проблем и угроз, имеющих место или могущих возникнуть в будущем, с целью формирования общей стратегии развития промышленности производства технологий ИВ и их применения в различных секторах экономики и общественной жизни. Проанализированы патентный ландшафт ИВ, выявлены наиболее продуктивные компании и изобретатели ИВ, показана динамика патентования в среде ИВ, ценность патентов, проблемы патентного поиска. Рассмотрены проблемы охраны интеллектуальной собственности в сфере ИВ, в частности, авторских прав, изобретений, торговых марок, коммерческой тайны, информационной безопасности. Рассмотрены интеллектуальный потенциал и неиспользованные возможности Украины в развитии технологий ИВ. Делается вывод, что в широком применении технологий ИВ заложен значительный потенциал повышения эффективности любого вида человеческой деятельности. Это касается сферы реальной экономики, промышленности и сельского хозяйства, системы здравоохранения, государственного управления, образования, финансового оборота и т. п. Развитие технологий ИВ является мощным стимулирующим фактором инновационного развития нанотехнологий, микроэлектроники, полупроводниковых технологий, микроминиатюризации исполнительных устройств, телекоммуникаций, радиотехнологий, программных вычислительных средств, робототехники и многого другого.Розглянуто економіко-правові аспекти стану та тенденцій розвитку технологій Інтернету речей (ІР), місця в ньому інтелектуальної власності. Показано роль дер- жави у сприянні розвитку ІР, проблеми та шляхи їх вирішення. Проаналізовано патентний ландшафт ІР, виявлені найбільш продуктивні компанії та винахідники ІР, показано динаміку патентування в середовищі ІР, цінність патентів, проблеми патентного пошуку. Визначено проблеми охорони інтелектуальної власності у сфері ІР, зокрема, авторських прав, винаходів, торгових марок, комерційної таємниці, інформаційної безпеки. Розглянуто інтелектуальний потенціал і невикористані мож- ливості України в розвитку технологій ІР. Обґрунтовано висновок, що в широкому застосуванні технологій ІР закладено значний потенціал підвищення ефективності економіки",Науково-дослідний інститут інтелектуальної власності НAПрН України,ІНТЕЛЕКТУАЛЬНА ВЛАСНІСТЬ В СИСТЕМІ ІНТЕРНЕТУ РЕЧЕЙ: ЕКОНОМІКО-ПРАВОВИЙ АСПЕКТ,,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
196141017,2018,"According to statistics, every fifth married couple is faced with the inability to conceive a child. Male germ cells are very vulnerable, and the growing number of cases of male infertility confirms that in today's world there are many factors that affect the activity of spermatozoa and their number. But the important thing is not so much their quantity, but quality. The spermogram is an objective method of laboratory diagnosis, which allows to accurately assess the man’s ability to fertilize by analyzing ejaculate for a number of key parameters. Only a spermogram can answer the question of a possible male infertility and the presence of urological diseases. When constructing spermograms, it is important to determine not only the number of good spermatozoa, but also their morphology and mobility. Therefore, research and improvement of some stages of spermogramm is the purpose of the study. This article addresses the problem of classification of spermatozoa in good and bad ones, taking into account their mobility and morphology, using methods of machine learning. In order to implement the first stage of machine learning (with a teacher) in the graphic editor, educational specimens (training sample) were created. The training was implemented by three methods: the method of support vector machine, the logistic regression and the method of K - the nearest neighbors. As a result of testing, the method K - the nearest neighbors is chosen. At the testing stage, a sample of 15 different spermatozoa was used in different variations of rotation around their axis. The test sample did not contain specimens from the training sample and was formed taking into account the morphological characteristics of the spermatozoa, but did not copy them from the training sample. At the final stage of study, the program's functioningwas tested on real data.За статистикою, кожна п'ята подружня пара стикається з неможливістю зачаття дитини. Чоловічі статеві клітини дуже вразливі, зростаюче число випадків чоловічого безпліддя підтверджує, що в сучасному світі дуже багато чинників, які впливають і на активність сперматозоїдів і на їх кількість. Та важливою є не стільки їх кількість, скільки якість. Спермограма є об'єктивним методом лабораторної діагностики, що дозволяє максимально точно оцінити здатність до запліднення чоловіка, проаналізувавши еякулят за рядом найважливіших параметрів. Тільки спермограма здатна відповісти на питання про можливе чоловіче безпліддя та про наявність урологічних захворювань. При побудові спермограми, важливо визначати не тільки кількість добрих сперматозоїдів, але й їх морфологію та рухливість. Тому дослідження та вдосконалення деяких етапів спермограми і є метою дослідження. У даній статті вирішується задача класифікації сперматозоїдів на добрі та погані, з урахуванням їх рухливості та морфології, із застосуванням методів машинного навчання. Для реалізації першого етапу машинного навчання (з вчителем) у графічному редакторі були створені навчальні екземпляри (тренувальна вибірка). Навчання було реалізована трьома методами: методом опорних векторів, логістична регресія та метод К - найближчих сусідів. За результатами тестування обрано метод К - найближчих сусідів. На етапі тестування використовувалася вибірка з 15 різних сперматозоїдів в різних варіаціях обертання навколо своєї осі. Тестова вибірка не містила примірників з тренувальної вибірки і була сформована з урахуванням морфологічних особливостей сперматозоїдів, але не копіювала їх з тренувальної вибірки. На завершальному етапі навчання роботу програми було протестовано на реальних даних","Національний технічний університет ""Харківський політехнічний інститут""",Застосування методів машинного навчання для вирішення задачі аналізу біологічних даних,10.20998/2522-9052.2018.3.01,,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
201570597,2017-01-01T00:00:00,"Context: Bioprospection has become a dynamic scientific field that explores novel possibilities for the implementation of natural products in medicine and pharmacy. Compared to marine species from all kingdoms, freshwater species have been highly neglected. Objective: This work focuses on the screening of acetylcholinesterase inhibitory (AChE) and mutagenic activities of the acetone extract (obtained by maceration) of the freshwater sponge Ochridaspongia rotunda Arndt (Malawispongiidae) in vitro. Materials and methods: AChE inhibitory activity was evaluated both in liquid (five different concentrations of the extract, from 1 to 100 μg/mL) and in solid (seven different concentrations of the extract, from 0.5 to 10.0 μg) by methods well described in literature, while mutagenicity was estimated using the Ames test (four different concentrations of the extract, from 0.106 to 1.328 mg/plate). Results: Ochridaspongia rotunda acetone extract exhibited promising AChE inhibitory activity in a dose-dependent manner both in liquid (IC50 23.07 μg/mL) and in solid (1.50 μg). Furthermore, the Ames test revealed no sign of mutagenicity at any concentration tested. Its FTIR spectrum coupled with the positive Liebermann?Burchard, Salkowski and Zak color reactions (tests) indicated the presence of sterol compounds. Discussion and conclusion: The screened extract may inspire a search for novel anticholinesterase therapeutic agent(s) potentially used in the treatment of Alzheimer's disease. Further research will be directed toward its detailed chemical analysis along with addressing the issue of a real producer of the natural product(s) responsible for the AChE activity observed",'Informa UK Limited',Further insight into the bioactivity of the freshwater sponge Ochridaspongia rotunda,10.1080/13880209.2017.1297468,,"[{'title': 'Pharmaceutical Biology', 'identifiers': ['1388-0209', '1744-5116', 'issn:1744-5116', 'issn:1388-0209']}]",core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
275646428,2018-01-01T00:00:00,"[EN] Traditional interaction mechanisms in distributed digital spaces often fail to consider the intrinsic properties of action, perception, and communication among workgroups, which may affect access to the common resources used to mutually organize information. By developing suitable spatial geometries and natural interaction mechanisms, distributed spaces can become blended where the physical and virtual boundaries of local and remote spaces merge together to provide the illusion of a single unified space. In this paper, we discuss the importance of blended interaction in distributed spaces and the particular challenges faced when designing accessible technology. We illustrate this discussion through a new tangible interaction mechanism for collaborative spaces based on tabletop system technology implemented with optical frames. Our tangible elements facilitate the exchange of digital information in distributed collaborative settings by providing a physical manifestation of common digital operations. The tangibles are designed as passive elements that do not require the use of any additional hardware or external power while maintaining a high degree of accuracy.This work was supported by the Spanish Ministry of Economy and Competitiveness and the European Regional Development Fund, through the ANNOTA Project (Ref. TIN2013-46036-C3-1-R).Salvador-Herranz, G.; Camba, J.; Contero, M.; Naya Sanchis, F. (2018). Accessibility and tangible interaction in distributed workspaces based on multi-touch surfaces. Universal Access in the Information Society. 17(2):247-256. https://doi.org/10.1007/s10209-017-0563-7S247256172Arkin, E.M., Chew, L.P., Huttenlocher, D.P., Kedem, K., Mitchell, J.S.B.: An efficiently computable metric for comparing polygonal shapes. IEEE Trans. Acoust. Speech Signal Process. 13(3), 209–216 (1991)Benyon, D.: Presence in blended spaces. Interact. Comput. 24(4), 219–226 (2012)Bhalla, M.R., Bhalla, A.V.: Comparative study of various touchscreen technologies. Int. J. Comput. Appl. 6(8), 12–18 (2010)Bradski, G., Kaehler, A.: Learning OpenCV: Computer Vision with the OpenCV Library. O’Reilly Media Inc., Newton (2008)Candela, E.S., Pérez, M.O., Romero, C.M., López, D.C.P., Herranz, G.S., Contero, M., Raya, M.A.: Humantop: a multi-object tracking tabletop. Multimed. Tools Appl. 70(3), 1837–1868 (2014)Cohen, J., Withgott, M., Piernot, P.: Logjam: a tangible multi-person interface for video logging. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 128–135. ACM (1999)Couture, N., Rivière, G., Reuter, P.: Geotui: a tangible user interface for geoscience. In: Proceedings of the 2nd International Conference on Tangible and Embedded Interaction, pp. 89–96. ACM (2008)de la Guía, E., Lozano, M.D., Penichet, V.R.: Cognitive rehabilitation based on collaborative and tangible computer games. In: 2013 7th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth), pp. 389–392. IEEE (2013)Dietz, P., Leigh, D.: Diamondtouch: a multi-user touch technology. In: Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, pp. 219–226. ACM (2001)Falcão, T.P., Price, S.: What have you done! the role of ‘interference’ in tangible environments for supporting collaborative learning. In: Proceedings of the 9th International Conference on Computer Supported Collaborative Learning-Volume 1, pp. 325–334. International Society of the Learning Sciences (2009)Fallman, D.: Wear, point and tilt. In: Proceedings of the Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, pp. 293–302. ACM Press (2002)Fishkin, K.P., Gujar, A., Harrison, B.L., Moran, T.P., Want, R.: Embodied user interfaces for really direct manipulation. Commun. ACM 43(9), 74–80 (2000)Fitzmaurice, G.W., Buxton, W.: An empirical evaluation of graspable user interfaces: towards specialized, space-multiplexed input. In: Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pp. 43–50. ACM (1997)Fitzmaurice, G.W., Ishii, H., Buxton, W.A.: Bricks: laying the foundations for graspable user interfaces. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 442–449. ACM Press (1995)Graham, R.L., Yao, F.F.: Finding the convex hull of a simple polygon. J. Algorithms 4(4), 324–331 (1983)Hartigan, J.A., Wong, M.A.: Algorithm as 136: a k-means clustering algorithm. J. R. Stat. Soc.: Ser. C (Appl. Stat.) 28(1), 100–108 (1979)Higgins, S.E., Mercier, E., Burd, E., Hatch, A.: Multi-touch tables and the relationship with collaborative classroom pedagogies: a synthetic review. Int. J. Comput. Support. Collab. Learn. 6(4), 515–538 (2011)Hinckley, K., Pausch, R., Goble, J.C., Kassell, N.F.: Passive real-world interface props for neurosurgical visualization. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 452–458. ACM (1994)Hinske, S.: Determining the position and orientation of multi-tagged objects using RFID technology. In: 5th Annual IEEE International Conference on Pervasive Computing and Communications Workshops, 2007. PerCom Workshops’07, pp. 377–381. IEEE (2007)Hornecker, E.: A design theme for tangible interaction: embodied facilitation. In: ECSCW 2005, pp. 23–43. Springer (2005)Hoshi, K., Öhberg, F., Nyberg, A.: Designing blended reality space: conceptual foundations and applications. In: Proceedings of the 25th BCS Conference on Human–Computer Interaction, pp. 217–226. British Computer Society (2011)Ishii, H.: Tangible User Interfaces. CRC Press, Boca Raton (2007)Ishii, H., Ullmer, B.: Tangible bits: towards seamless interfaces between people, bits and atoms. In: Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pp. 234–241. ACM (1997)Jacob, R.J., Girouard, A., Hirshfield, L.M., Horn, M.S., Shaer, O., Solovey, E.T., Zigelbaum, J.: Reality-based interaction: a framework for post-wimp interfaces. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 201–210. ACM (2008)Jetter, H.C., Dachselt, R., Reiterer, H., Quigley, A., Benyon, D., Haller, M.: Blended Interaction: Envisioning Future Collaborative Interactive Spaces. ACM, New York (2013)Jin, X., Han, J.: Quality threshold clustering. In: Sammut, C., Webb, G.I. (eds.) Encyclopedia of Machine Learning, pp. 820–820. Springer, Boston, MA (2011)Jordà, S., Geiger, G., Alonso, M., Kaltenbrunner, M.: The reactable: exploring the synergy between live music performance and tabletop tangible interfaces. In: Proceedings of the 1st International Conference on Tangible and Embedded Interaction, pp. 139–146. ACM (2007)Kaltenbrunner, M., Bovermann, T., Bencina, R., Costanza, E.: Tuio: a protocol for table-top tangible user interfaces. In: Proceedings of the 6th International Workshop on Gesture in Human–Computer Interaction and Simulation, pp. 1–5 (2005)Kirk, D., Sellen, A., Taylor, S., Villar, N., Izadi, S.: Putting the physical into the digital: issues in designing hybrid interactive surfaces. In: Proceedings of the 23rd British HCI Group Annual Conference on People and Computers: Celebrating People and Technology, pp. 35–44. British Computer Society (2009)Marques, T., Nunes, F., Silva, P., Rodrigues, R.: Tangible interaction on tabletops for elderly people. In: International Conference on Entertainment Computing, pp. 440–443. Springer (2011)Müller, D.: Mixed reality systems. iJOE 5(S2), 10–11 (2009)Newton-Dunn, H., Nakano, H., Gibson, J.: Block jam: a tangible interface for interactive music. In: Proceedings of the 2003 Conference on New Interfaces for Musical Expression, pp. 170–177. National University of Singapore (2003)Patten, J., Recht, B., Ishii, H.: Audiopad: a tag-based interface for musical performance. In: Proceedings of the 2002 Conference on New Interfaces for Musical Expression, pp. 1–6. National University of Singapore (2002)Patten, J., Recht, B., Ishii, H.: Interaction techniques for musical performance with tabletop tangible interfaces. In: Proceedings of the 2006 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology, p. 27. ACM (2006)PQLabs: Inc. http://multitouch.com/ . Retrieved on 16 October 2016Ryokai, K., Marti, S., Ishii, H.: I/o brush: drawing with everyday objects as ink. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI’04, pp. 303–310. ACM, New York (2004). doi: 10.1145/985692.985731Salvador, G., Bañó, M., Contero, M., Camba, J.: Evaluation of a distributed collaborative workspace as a creativity tool in the context of design education. In: 2014 IEEE Frontiers in Education Conference (FIE) Proceedings, pp. 1–7. IEEE (2014)Salvador-Herranz, G., Contero, M., Camba, J.: Use of tangible marks with optical frame interactive surfaces in collaborative design scenarios based on blended spaces. In: International Conference on Cooperative Design, Visualization and Engineering, pp. 253–260. Springer (2014)Salvador-Herranz, G., Camba, J.D., Naya, F., Contero, M.: On the integration of tangible elements with multi-touch surfaces for the collaborative creation of concept maps. In: International Conference on Learning and Collaboration Technologies, pp. 177–186. Springer (2016)Schöning, J., Hook, J., Bartindale, T., Schmidt, D., Oliver, P., Echtler, F., Motamedi, N., Brandl, P., von Zadow, U.: Building interactive multi-touch surfaces. In: Müller-Tomfelde, C. (ed.) Tabletops-Horizontal Interactive Displays, pp. 27–49. Springer, London, UK (2010)Shaer, O., Hornecker, E.: Tangible user interfaces: past, present, and future directions. Found. Trends Hum. Comput. Interact. 3(1–2), 1–137 (2010)Shen, C., Everitt, K., Ryall, K.: Ubitable: Impromptu face-to-face collaboration on horizontal interactive surfaces. In: International Conference on Ubiquitous Computing, pp. 281–288. Springer (2003)Suzuki, H., Kato, H.: Algoblock: a tangible programming language, a tool for collaborative learning. In: Proceedings of 4th European Logo Conference, pp. 297–303 (1993)Suzuki, H., Kato, H.: Interaction-level support for collaborative learning: Algoblockan open programming language. In: The 1st International Conference on Computer Support for Collaborative Learning, pp. 349–355. L. Erlbaum Associates Inc. (1995)Terrenghi, L., Kirk, D., Richter, H., Krämer, S., Hilliges, O., Butz, A.: Physical handles at the interactive surface: exploring tangibility and its benefits. In: Proceedings of the Working Conference on Advanced Visual Interfaces, pp. 138–145. ACM (2008)Veltkamp, R.C.: Shape matching: similarity measures and algorithms. In: SMI 2001 International Conference on Shape Modeling and Applications, pp. 188–197. IEEE (2001)Weinberg, G., Gan, S.L.: The squeezables: Toward an expressive and interdependent multi-player musical instrument. Comput. Music J. 25(2), 37–45 (2001)Weiser, M.: Some computer science issues in ubiquitous computing. Commun. ACM 36(7), 75–84 (1993)Wilson, F.: The hand: how its use shapes the brain, language, and human culture. Vintage Series. Vintage Books (1998). https://books.google.es/books?id=l_Boy_-NkwUCZuckerman, O., Arida, S., Resnick, M.: Extending tangible interfaces for education: digital montessori-inspired manipulatives. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 859–868. ACM (2005",'Springer Science and Business Media LLC',Accessibility and tangible interaction in distributed workspaces based on multi-touch surfaces,10.1007/s10209-017-0563-7,https://riunet.upv.es/bitstream/10251/120351/9/Postprint%20UAIS%202018.pdf,,core,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
